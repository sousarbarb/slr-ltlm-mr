@conference{ali-et-al:2020:3389033,
  author = {A. J. B. Ali and Z. S. Hashemifar and K. Dantu},
  journal = {MobiSys 2020 - Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services},
  title = {Edge-SLAM: Edge-assisted visual simultaneous localization and mapping},
  pages = {325--337},
  doi = {10.1145/3386901.3389033},
  note = {cited By 11; Conference of 18th ACM International Conference on Mobile Systems, Applications, and Services, MobiSys 2020 ; Conference Date: 15 June 2020 Through 19 June 2020;  Conference Code:160682},
  publisher = {Association for Computing Machinery, Inc},
  year = {2020},
  abbrev_source_title = {MobiSys - Proc. Int. Conf. Mob. Syst., Appl., Serv.},
  abstract = {Localization in urban environments is becoming increasingly important and used in tools such as ARCore [11], ARKit [27] and others. One popular mechanism to achieve accurate indoor localization as well as a map of the space is using Visual Simultaneous Localization and Mapping (Visual-SLAM). However, Visual-SLAM is known to be resource-intensive in memory and processing time. Further, some of the operations grow in complexity over time, making it challenging to run on mobile devices continuously. Edge computing provides additional compute and memory resources to mobile devices to allow offloading of some tasks without the large latencies seen when offloading to the cloud. In this paper, we present Edge-SLAM, a system that uses edge computing resources to offload parts of Visual-SLAM. We use ORB-SLAM2 as a prototypical Visual-SLAM system and modify it to a split architecture between the edge and the mobile device. We keep the tracking computation on the mobile device and move the rest of the computation, i.e., local mapping and loop closure, to the edge. We describe the design choices in this effort and implement them in our prototype. Our results show that our split architecture can allow the functioning of the Visual-SLAM system long-term with limited resources without affecting the accuracy of operation. It also keeps the computation and memory cost on the mobile device constant which would allow for deployment of other end applications that use Visual-SLAM. © 2020 ACM.},
  affiliation = {University at Buffalo, Buffalo, United States},
  author_keywords = {Edge computing;  Localization;  Mapping;  Mobile Systems;  Split architecture;  Visual simultaneous localization and mapping},
  document_type = {Conference Paper},
  funding_details = {National Science FoundationNational Science Foundation, NSF, 1846320},
  isbn = {9781450379540},
  keywords = {Edge computing;  Mapping;  Memory architecture;  SLAM robotics, Computing resource;  Indoor localization;  Local mapping;  Memory resources;  Processing time;  Split architectures;  Urban environments;  Visual simultaneous localization and mappings, Indoor positioning systems},
  language = {English},
  references = {(2020) Computer Cpu Desktop-Free Vector Graphic on Pixabay, , https://pixabay.com/images/id-156768/; (2020) Interior Design Tv Multi-Screen-Free Image on Pixabay, , https://pixabaycom/images/id-828545/; (2020) Smartphone Android Technology-Free Vector Graphic on Pixabay, , https://pixabay.com/images/id-3358735/; Adhivarahan, C., Dantu, K., Wisdom: Wireless sensingassisted distributed online mapping (2019) 2019 International Conference on Robotics and Automation (ICRA), pp. 8026-8033; Bailey, T., Durrant-Whyte, H., Simultaneous localization and mapping (SLAM): Part II (2006) IEEE Robotics Automation Magazine, 13 (3), pp. 108-117. , https://doi.org/10.1109/MRA.2006.1678144, Sep 2006; Bujanca, M., Gafton, P., Saeedi, S., Nisbet, A., Bodin, B., O'Boyle, M.F.P., Davison, A.J., Furber, S., Slambench 3. 0: Systematic automated reproducible evaluation of slam systems for robot vision challenges and scene understanding (2019) 2019 International Conference on Robotics and Automation (ICRA), pp. 6351-6358. , https://doi.org/10.1109/ICRA.2019.8794369; Chen, K., Li, T., Kim, H., Culler, D.E., Katz, R.H., Marvel: Enabling mobile augmented reality with low energy and low latency (2018) Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems (Shenzhen, China) (SenSys '18), pp. 292-304. , https://doi.org/10.1145/3274783.3274834, ACM, New York, NY, USA; Chun, B., Ihm, S., Maniatis, P., Naik, M., Patti, A., Clonecloud: Elastic execution between mobile device and cloud (2011) Proceedings of the Sixth Conference on Computer Systems (Salzburg, Austria) (EuroSys '11), pp. 301-314. , https://doi.org/10.1145/1966445.1966473, ACM, New York, NY, USA; Cole, D.M., Newman, P.M., Using laser range data for 3D SLAM in outdoor environments (2006) Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006, pp. 1556-1563. , https://doi.org/10.1109/ROBOT.2006.1641929, ICRA 2006; Cuervo, E., Balasubramanian, A., Cho, D., Wolman, A., Saroiu, S., Chandra, R., Bahl, P., MAUI: Making smartphones last longer with code offload (2010) Proceedings of the 8th International Conference on Mobile Systems, Applications, and Services, pp. 49-62. , https://doi.org/10.1145/1814433.1814441, San Francisco, California, USA) (MobiSys '10) ACM, New York, NY, USA; (2020) Build New Augmented Reality Experiences That Seamlessly Blend the Digital and Physical Worlds, , https://developers.google.com/ar, Google Developers; Dissanayake, M.W.M.G., Newman, P., Clark, S., Durrant-Whyte, H.F., Csorba, M., A solution to the simultaneous localization and map building (SLAM) problem (2001) IEEE Transactions on Robotics and Automation, 17 (3), pp. 229-241. , https://doi.org/10.1109/70.938381, June 2001; Durrant-Whyte, H., Bailey, T., Simultaneous localization and mapping: Part i (2006) IEEE Robotics Automation Magazine, 13 (2), pp. 99-110. , https://doi.org/10.1109/MRA.2006.1638022, June 2006; Engel, J., Schops, T., Cremers, D., LSD-SLAM: Large-scale direct monocular slam (2014) Computer VisionECCV 2014, pp. 834-849. , David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars (Eds.) Springer International Publishing, Cham; Engelhard, N., Endres, F., Hess, J., Sturm, J., Burgard, W., Real-time 3D visual SLAM with a hand-held RGB-D camera (2011) Proc. Of the RGB-D Workshop on 3D Perception in Robotics at the European Robotics Forum, Vasteras, Sweden, 180, pp. 1-15; Engelhard, N., Endres, F., Hess, J., Sturm, J., Burgard, W., Real-time 3D visual SLAM with a hand-held RGB-D camera (2011) Proc. Of the RGB-D Workshop on 3D Perception in Robotics at the European Robotics Forum, Vasteras, Sweden, 180, pp. 1-15; Fallon, M.F., Folkesson, J., McClelland, H., Leonard, J.J., Relocating underwater features autonomously using sonar-based slam (2013) IEEE Journal of Oceanic Engineering, 38 (3), pp. 500-513. , https://doi.org/10.1109/JOE.2012.2235664, July 2013; Ferris, B., Fox, D., Lawrence, N., WiFi-slam using Gaussian process latent variable models (2007) Proceedings of the 20th International Joint Conference on Artifical Intelligence (Hyderabad, India) (IJCAI'07), pp. 2480-2485. , http://dl.acm.org/citation.cfmid=1625275.1625675, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA; Forster, C., Lynen, S., Kneip, L., Scaramuzza, D., Collaborative monocular SLAM with multiple Micro Aerial Vehicles (2013) 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3962-3970. , https://doi.org/10.1109/IROS.2013.6696923; Hashemifar, Z., Dantu, K., Practical persistence reasoning in visual slam (2020) Accepted to Appear in Proceedings of the International Conference on Robotics and Automation (ICRA '20), , IEEE, Paris, France; Hashemifar, Z., Lee, K., Napp, N., Dantu, K., Geometric mapping for sustained indoor autonomy (2018) Proceedings of the 1st International Workshop on Internet of People, Assistive Robots and Things, pp. 19-24; Hashemifar, Z.S., Adhivarahan, C., Balakrishnan, A., Dantu, K., Augmenting visual SLAM with Wi-Fi sensing for indoor applications (2019) Autonomous Robots, 43 (8), pp. 2245-2260. , 2019; Hashemifar, Z.S., Lee, K.W., Napp, N., Dantu, K., Consistent cuboid detection for semantic mapping (2017) 2017 IEEE 11th International Conference on Semantic Computing (ICSC), pp. 526-531; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2D LIDAR SLAM (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 1271-1278. , https://doi.org/10.1109/ICRA.2016.7487258; Huang, J., Millman, D., Quigley, M., Stavens, D., Thrun, S., Aggarwal, A., Efficient, generalized indoor WiFi GraphSLAM (2011) 2011 IEEE International Conference on Robotics and Automation, pp. 1038-1043. , https://doi.org/10.1109/ICRA.2011.5979643; (2020) Computer Vision Group-Dataset Download, , https://vision.in.tum.de/data/datasets/rgbd-dataset/download, Computer Vision Group in Department of Informatics at Technical University of Munich; (2020) Augmented Reality-Apple Developer, , https://developer.apple.com/augmented-reality/, Apple Inc; (2020) Magic Leap 1 | Magic Leap, , https://www.magicleap.com/enus/magic-leap-1, Magic Leap Inc; Ito, S., Endres, F., Kuderer, M., Diego Tipaldi, G., Stachniss, C., Burgard, W., W-RGB-D: Floor-plan-based indoor global localization using a depth camera and WiFi (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 417-422. , https://doi.org/10.1109/ICRA.2014.6906890; Jain, P., Manweiler, J., Choudhury, R.R., Low bandwidth offload for mobile ar (2016) Proceedings of the 12th International on Conference on Emerging Networking EXperiments and Technologies (Irvine, California, USA) (CoNEXT '16), , https://doi.org/10.1145/2999572.2999587, ACM, New York, NY, USA, 237-251; Klein, G., Murray, D., Parallel tracking and mapping for small ar workspaces (2007) 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 225-234. , https://doi.org/10.1109/ISMAR.2007.4538852; Ammerle, R.K., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) 2011 IEEE International Conference on Robotics and Automation, pp. 3607-3613. , https://doi.org/10.1109/ICRA.2011.5979949; Labbe, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745. , 2013; LabbAand, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745. , https://doi.org/10.1109/TRO.2013.2242375, June2013; Li, F., Yang, S., Yi, X., Yang, X., CORB-slam: A collaborative visual slam system for multiple robots (2018) Collaborative Computing: Networking, Applications and Worksharing, pp. 480-490. , Imed Romdhani, Lei Shu, Hara Takahiro, Zhangbing Zhou, Timothy Gordon, and Deze Zeng (Eds.) Springer International Publishing, Cham; Liu, L., Li, H., Gruteser, M., Edge assisted real-time object detection for mobile augmented reality (2019) the 25th Annual International Conference on Mobile Computing and Networking (Los Cabos, Mexico) (MobiCom '19), p. 16. , https://doi.org/10.1145/3300061.3300116, ACM, New York, NY, USA, Article 25; Mach, P., Becvar, Z., Mobile edge computing: A survey on architecture and computation offloading (2017) IEEE Communications Surveys Tutorials, 19 (3), pp. 1628-1656. , https://doi.org/10.1109/COMST.2017.2682318, thirdquarter 2017; (2020) HoloLens (1st Gen) Hardware | Microsoft Docs, , https://docs.microsoft.com/en-us/hololens/hololens1-hardware; Mirowski, P., Ho, T.K., Yi, S., MacDonald, M., SignalSLAM: Simultaneous localization and mapping with mixed WiFi, Bluetooth, LTE and magnetic signals (2013) International Conference on Indoor Positioning and Indoor Navigation, pp. 1-10. , https://doi.org/10.1109/IPIN.2013.6817853; Mur-Artal, R., Montiel, J.M.M., TardAs, J.D., Orb-slam: A versatile and accurate monocular slam system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163. , https://doi.org/10.1109/TRO.2015.2463671, Oct 2015; Mur-Artal, R., TardAs, J.D., ORB-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262. , https://doi.org/10.1109/TRO.2017.2705103, Oct 2017; Newcombe, R.A., Izadi, S., Hilliges, O., Molyneaux, D., Kim, D., Davison, A.J., Kohi, P., Fitzgibbon, A., Kinectfusion: Real-time dense surface mapping and tracking (2011) 2011 10th IEEE International Symposium on Mixed and Augmented Reality, pp. 127-136. , https://doi.org/10.1109/ISMAR.2011.6092378; Newcombe, R.A., Lovegrove, S.J., Davison, A.J., DTAM: Dense tracking and mapping in real-time (2011) 2011 International Conference on Computer Vision, pp. 2320-2327. , https://doi.org/10.1109/ICCV.2011.6126513; Quigley, M., Stavens, D., Coates, A., Thrun, S., Sub-meter indoor localization in unmodified environments with inexpensive sensors (2010) 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2039-2046. , https://doi.org/10.1109/IROS.2010.5651783; Riazuelo, L., Civera, J., Montiel, J.M.M., C2TAM: A Cloud framework for cooperative tracking and mapping (2014) Robotics and Autonomous Systems, 62 (4), pp. 401-413. , https://doi.org/10.1016/j.robot.2013.11.007, 2014; Satyanarayanan, M., The emergence of edge computing (2017) Computer, 50 (1), pp. 30-39. , https://doi.org/10.1109/MC.2017.9, Jan 2017; Satyanarayanan, M., Bahl, P., Caceres, R., Davies, N., The case for vmbased cloudlets in mobile computing (2009) IEEE Pervasive Computing, 8 (4), pp. 14-23. , https://doi.org/10.1109/MPRV.2009.82, Oct 2009; Schmuck, P., Chli, M., Multi-UAV collaborative monocular SLAM (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 3863-3870. , https://doi.org/10.1109/ICRA.2017.7989445; Shi, W., Cao, J., Zhang, Q., Li, Y., Xu, L., Edge computing: Vision and challenges (2016) IEEE Internet of Things Journal, 3 (5), pp. 637-646. , https://doi.org/10.1109/JIOT.2016.2579198, Oct 2016; Thrun, S., Robotic mapping: A survey (2002) Exploring Artificial Intelligence in the New Millennium, 1, pp. 1-35. , 2002 1; Whelan, T., Johannsson, H., Kaess, M., Leonard, J.J., McDonald, J., Robust real-time visual odometry for dense RGB-D mapping (2013) 2013 IEEE International Conference on Robotics and Automation, pp. 5724-5731. , https://doi.org/10.1109/ICRA.2013.6631400; Xu, J., Cao, H., Li, D., Huang, K., Qian, C., Shangguan, L., Yang, Z., (2020) Edge Assisted Mobile Semantic Visual SLAM, , July 2020},
  source = {Scopus},
  sponsors = {ACM SIGMOBILE},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088125321&doi=10.1145%2f3386901.3389033&partnerID=40&md5=9805a788a84734c5039d93ffd0d88b95},
}

@article{davison-murray:2002:1017615,
  author = {A. J. Davison and D. W. Murray},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title = {Simultaneous localization and map-building using active vision},
  volume = {24},
  number = {7},
  pages = {865--880},
  doi = {10.1109/TPAMI.2002.1017615},
  note = {cited By 404},
  year = {2002},
  abbrev_source_title = {IEEE Trans Pattern Anal Mach Intell},
  abstract = {An active approach to sensing can provide the focused measurement capability over a wide field of view which allows correctly formulated Simultaneous Localization and Map-Building (SLAM) to be implemented with vision, permitting repeatable long-term localization using only naturally occurring, automatically-detected features. In this paper, we present the first example of a general system for autonomous localization using active vision, enabled here by a high-performance stereo head, addressing such issues as uncertainty-based measurement selection, automatic map-maintenance, and goal-directed steering. We present varied real-time experiments in a complex environment.},
  affiliation = {IEEE, United Kingdom; Robotics Research Group, Department of Engineering Science, University of Oxford, Oxford, OX1 3PJ, United Kingdom},
  author_keywords = {Active vision;  Mobile robots;  Simultaneous localization and map-building},
  coden = {ITPID},
  correspondence_address1 = {Davison, A.J.; Robotics Research Group, , Oxford, OX1 3PJ, United Kingdom; email: ajd@robots.ox.ac.uk},
  document_type = {Article},
  issn = {01628828},
  keywords = {Active vision;  Active visual sensing;  Electromechanical stereo head;  High resolution omni-directional data;  Odometry;  Simultaneous Localization and Map-Building, Algorithms;  Cameras;  Closed loop control systems;  Degrees of freedom (mechanics);  Electromechanical devices;  Feature extraction;  Kalman filtering;  Kinematics;  Mathematical models;  Matrix algebra;  Mobile robots;  Probability density function, Computer vision},
  language = {English},
  references = {Smith, R., Self, M., Cheeseman, P., A stochastic map for uncertain spatial relationships Proc. Fourth Int'l Symp. Robotics Research, 1987; Harris, C.G., Pike, J.M., 3D positional integration from image sequences (1987) Proc. Third Alvey Vision Conf., pp. 233-236; Ayache, N., (1991) Artificial Vision for Mobile Robots: Stereo Vision and Multisensory Perception, , Cambridge, Mass: MIT Press; Durrant-Whyte, H.F., Where am I? A tutorial on mobile vehicle localization (1994) Industrial Robot, 21 (2), pp. 11-16; Harris, C.G., Geometry from visual motion (1992) Active Vision, , A. Blake and A. Yuille, eds; Beardsley, P.A., Reid, I.D., Zisserman, A., Murray, D.W., Active visual navigation using non-metric structure (1995) Proc. Fifth Int'l Conf. Computer Vision, pp. 58-65; Bouget, J.-Y., Perona, P., Visual navigation using a single camera (1995) ICCV5, pp. 645-652; Pollefeys, M., Koch, R., Van Gool, L., Self-calibration and metric reconstruction in spite of varying and unknown internal camera parameters (1998) Proc. Sixth Int'l Conf. Computer Vision, pp. 90-96; Torr, P.H.S., Fitzgibbon, A.W., Zisserman, A., Maintaining multiple motion model hypothesis over many views to recover matching and structure (1998) Proc. Sixth Int'l Conf. Computer Vision, pp. 485-491; Durrant-Whyte, H.F., Dissanayake, M.W.M.G., Gibbens, P.W., Toward deployments of large scale simultaneous localization and map building (SLAM) systems (1999) Proc. Ninth Int'l Symp. Robotics Research, pp. 121-127; Chong, K.S., Kleeman, L., Feature-based mapping in real, large scale environments using an ultrasonic array (1999) Int'l J. Robotics Research, 18 (2), pp. 3-19. , Jan; Thrun, S., Fox, D., Burgard, W., A probabilistic approach to concurrent mapping and localization for mobile robots (1998) Machine Learning, 31; Castellanos, J.A., Mobile robot localization and map building: A multisensor fusion approach (1998), PhD thesis, Universidad de Zaragoza, Spain; Leonard, J.J., Feder, H.J.S., A computationally efficient method for large-scale concurrent mapping and localization (2000) Robotics Research, , Springer Verlag; Davison, A.J., Murray, D.W., Mobile robot localization using active vision (1998) Proc. Fifth European Conf. Computer Vision, pp. 809-825; Nayar, S.K., Catadioptric omnidirectional camera Proc. IEEE Conf. Computer Vision and Pattern Recognition, 1997; Davison, A.J., Kita, N., Active visual localization for cooperating inspection robots Proc. IEEE/RSJ Conf. Intelligent Robots and Systems, 2000; Knight, J.G.H., Davison, A.J., Reid, I.D., Constant time SLAM using postponement Proc. IEEE/RSJ Conf. Intelligent Robots and Systems, 2001; Davison, A.J., Mobile robot navigation using active vision (1998), http://www.robots.ox.ac.uk/~ajd/, PhD thesis, Univ. of Oxford; Davison, A.J., Kita, N., Sequential localization and map-building for real-time computer vision and robotics (2001) Robotics and Autonomous Systems, 36 (4), pp. 171-183; MacCormick, J., Isard, M., Partitioned sampling, articulated objects and interface-quality hand tracking Proc. Sixth European Conf. Computer Vision, 2000; Thrun, S., Burgard, W., Fox, D., A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping Proc. IEEE Int'l Conf. Robotics and Automation, 2000; Harris, C.G., Stephens, M., A combined corner and edge detector (1988) Proc. Fourth Alvey Vision Conf., pp. 147-151; Shi, J., Tomasi, C., Good features to track (1994) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 593-600; Whaite, P., Ferrie, F.P., Autonomous exploration: Driven by uncertainty (1997) IEEE Trans. Pattern Analysis and Machine Intelligence, 19 (3), pp. 193-205; Murray, D.W., Reid, I.D., Davison, A.J., Steering without representation with the use of active fixation (1997) Perception, 26, pp. 1519-1528; Land, M.F., Lee, D.N., Where we look when we steer (1994) Nature, 369, pp. 742-744; Sandini, G., Tistarelli, M., Robust obstacle detection using optical flow Proc. IEEE Int'l Workshop Robust Computer Vision, 1990; Tistarelli, M., Sandini, G., Dynamic aspects in active vision (1992) Proc. CVGIP: Image Understanding, 56 (1), pp. 108-129; Grossi, E., Tistarelli, M., Active/dynamic stereo vision (1995) IEEE Trans. Pattern Analysis and Machine Intelligence, 17 (11), pp. 1117-1128; Chiuso, A., Favaro, P., Jin, H., Soatto, S., MFm': 3-D motion from 2-D motion causally integrated over time Proc. Sixth European Conf. Computer Vision, 2000},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036647318&doi=10.1109%2fTPAMI.2002.1017615&partnerID=40&md5=982a6c37043ef2f32ed09699824f95e3},
}

@conference{glover-et-al:2010:5509547,
  author = {A. J. Glover and W. P. Maddern and M. J. Milford and G. F. Wyeth},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {FAB-MAP + RatSLAM: Appearance-based SLAM for multiple times of day},
  pages = {3507--3512},
  doi = {10.1109/ROBOT.2010.5509547},
  note = {cited By 168; Conference of 2010 IEEE International Conference on Robotics and Automation, ICRA 2010 ; Conference Date: 3 May 2010 Through 7 May 2010;  Conference Code:81416},
  address = {Anchorage, AK},
  year = {2010},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Appearance-based mapping and localisation is especially challenging when separate processes of mapping and localisation occur at different times of day. The problem is exacerbated in the outdoors where continuous change in sun angle can drastically affect the appearance of a scene. We confront this challenge by fusing the probabilistic local feature based data association method of FAB-MAP with the pose cell filtering and experience mapping of RatSLAM. We evaluate the effectiveness of our amalgamation of methods using five datasets captured throughout the day from a single camera driven through a network of suburban streets. We show further results when the streets are re-visited three weeks later, and draw conclusions on the value of the system for lifelong mapping. ©2010 IEEE.},
  affiliation = {School of Information Technology and Electrical Engineering, University of Queensland, St Lucia, QLD 4072, Australia; Queensland Brain Institute, University of Queensland, St Lucia, QLD 4072, Australia},
  art_number = {5509547},
  coden = {PIIAE},
  correspondence_address1 = {Glover, A. J.; School of Information Technology and Electrical Engineering, , St Lucia, QLD 4072, Australia; email: arren@itee.uq.edu.au},
  document_type = {Conference Paper},
  isbn = {9781424450381},
  issn = {10504729},
  keywords = {Appearance based;  Data association;  Data sets;  Experience mappings;  Local feature;  Localisation;  Single cameras;  Suburban streets;  Sun angle, Data processing;  Mapping;  Metals;  Roads and streets, Robotics},
  language = {English},
  references = {Narasimhan, S., Wang, C., Nayar, S., All the Images of an Outdoor Scene (2002) Computer Vision - ECCV 2002, pp. 3-13; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded Up Robust Features (2006) Computer Vision - ECCV 2006, pp. 404-417; Lowe, D.G., Distinctive Image Features from Scale-Invariant Keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Konolige, K., Agrawal, M., FrameSLAM: From Bundle Adjustment to Real-Time Visual Mapping (2008) IEEE Transactions on Robotics, 24 (5), pp. 1066-1077; Clemente, L., Davison, A.J., Reid, I.D., Neira, J., Tardos, J.D., Mapping large loops with a single hand-held camera Robotics: Science and Systems, Atlanta, GA, USA, 2007; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Proc. of Robotics: Science and Systems (RSS), pp. 17-24. , Cambridge, MA, USA; Valgren, C., Lilienthal, A., Sift, surf, and seasons: Long-term outdoor localization using local features Proc. of 3rd European Conference on Mobile Robots, Freiburg, Germany, 2007; Cummins, M., Newman, P., Highly Scalable appearance-only SLAM - FAB-MAP 2.0 (2009) Robotics Science and Systems, , Seattle; Milford, M.J., Wyeth, G.F., Mapping a Suburb with a Single Camera Using a Biologically Inspired SLAM System (2008) IEEE Transactions on Robotics, 24 (5), pp. 1038-1053; Cummins, M., Newman, P., FAB-MAP: Probabilistic Localization and Mapping in the Space of Appearance (2008) International Journal of Robotics Research, 27 (6), pp. 647-665; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003) Proceedings of the Ninth IEEE International Conference on Computer Vision, 2003, 1472, pp. 1470-1477; Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Transactions on Information Theory, 14 (3), pp. 462-467; Jordan, M.I., Ghahramani, Z., Jaakkola, T.S., Saul, L.K., An Introduction to Variational Methods for Graphical Models (1999) Machine Learning, 37 (2), pp. 183-233; Milford, M.J., Wyeth, G.F., Prasser, D., RatSLAM: A hippocampal model for simultaneous localization and mapping (2004) Proceedings of the IEEE International Conference on Robotics and Automation, 2004 (ICRA '04), 401, pp. 403-408; Milford, M.J., Wyeth, G., Persistent navigation and Mapping using a Biologically Inspired SLAM System (2009) International Journal of Robotics Research; Teynor, A., Burkhardt, H., Fast Codebook Generation by Sequential Data Analysis for Object Classification (2007) Advances in Visual Computing, pp. 610-620; Baker, S., Scharstein, D., Lewis, J.P., Roth, S., Black, M.J., Szeliski, R., A Database and Evaluation Methodology for Optical Flow (2007) IEEE 11th International Conference on Computer Vision ( ICCV), pp. 1-8},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955801323&doi=10.1109%2fROBOT.2010.5509547&partnerID=40&md5=f77cf7db9cd04c0c21f52c4ac46f8d40},
}

@article{kawewong-et-al:2013:826410,
  author = {A. Kawewong and N. Tongprasit and O. Hasegawa},
  journal = {Advanced Robotics},
  title = {A speeded-up online incremental vision-based loop-closure detection for long-term SLAM},
  volume = {27},
  number = {17},
  pages = {1325--1336},
  doi = {10.1080/01691864.2013.826410},
  note = {cited By 4},
  year = {2013},
  abbrev_source_title = {Adv .Rob.},
  abstract = {An online incremental method of vision-only loop-closure detection for long-term robot navigation is proposed. The method is based on the scheme of direct feature matching which has recently become more efficient than the Bag-of-Words scheme in many challenging environments. The contributions of the paper are the application of hierarchical k-means to speed-up feature matching time and the improvement of the score calculation technique used to determine the loop-closing location. As a result, the presented method runs quickly in long term while retaining high accuracy. The searching cost has been markedly reduced. The proposed method requires no any off-line dictionary generation processes. It can start anywhere at any times. The evaluation has been done on standard well-known datasets being challenging in perceptual aliasing and dynamic changes. The results show that the proposed method offers high precision-recall in large-scale different environments with real-time computation comparing to other vision-only loop-closure detection methods. © 2013 Taylor & Francis and The Robotics Society of Japan.},
  affiliation = {Faculty of Engineering, Department of Computer Engineering, Chiang Mai University, 239 Huay Kaew Rd., Chiang Mai, 50200, Muang District, Thailand; Faculty of Science, Material Science Research Center, Chiang Mai University, 239 Huay Kaew Rd., Chiang Mai, 50200, Muang District, Thailand; Imaging Science and Engineering Laboratory, Department of Computational Intelligence and Systems Science, Tokyo Institute of Technology, 4259-J3 Nagatsuta, Midori-ku, Yokohama, 226-5803, Japan},
  author_keywords = {Place localization;  Robotics navigation;  Simultaneous localization and mapping;  Vision-based loop-closure detection},
  coden = {ADROE},
  correspondence_address1 = {Tongprasit, N.; Imaging Science and Engineering Laboratory, 4259-J3 Nagatsuta, Midori-ku, Yokohama, 226-5803, Japan; email: noppharit@gmail.com},
  document_type = {Article},
  funding_details = {Office of the Higher Education CommissionOffice of the Higher Education Commission},
  funding_text1 = {This study was supported by a JST CREST Project of Japan, by The Thailand Research Fund and Thai Network Information Center Foundation (Grant No. TRG5680062), and by the research grant from the National Research University Project under Thailand’s Office of Higher Education Commission.},
  issn = {01691864},
  keywords = {Calculation techniques;  Hierarchical k-means;  Loop closure;  Off-line dictionaries;  Perceptual aliasing;  Place localization;  Real-time computations;  Simultaneous localization and mapping, Mathematical techniques;  Robots, Robotics},
  language = {English},
  references = {Kawewong, A., Tongprasit, N., Tangruamsub, S., Hasegawa, O., Online and incremental appearance-based SLAM in highly dynamic environment (2011) Int. J. Rob. Res, 30, pp. 22-55; Kawewong, A., Tongprasit, N., Hasegawa, O., PIRF-Nav 2.0: Fast and online incremental appearance-based loop-closure detection in an indoor environment (2011) Rob. Auton. Syst, 59, pp. 727-739; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Rob. Res, 27, pp. 647-665; Cummins, M., Newman, P., Accelerating FAB-MAP with concentration inequalities (2010) IEEE Trans. Rob, 26, pp. 1042-1050; Cummins, M., Newman, P., Appearance-only SLAM at large-scale with FAB-MAP 2.0 (2011) Int. J. Rob. Res, 30, pp. 1100-1123; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.A., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Trans. Rob, 24, pp. 1027-1037; Filliat, D., Interactive learning of visual topological navigation (2008) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);, pp. 248-254; Paul, R., Newman, P., FAB-MAP 3D: Topological mapping with spatial and visual appearance (2010) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA);; Angeli, A., Doncieux, S., Filliat, D., Visual topological SLAM and global localization (2009) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA);; Krainin, M., Henry, P., Ren, X., Fox, D., Manipulator and object tracking for in-hand 3D object modeling (2011) Int. J. Rob. Res, 30, pp. 1311-1327; Sivic, J., Zisserman, A., Video google: A text retrieval approach to object matching in videos (2003) Proceedings of the IEEE International Conference on Computer Vision (ICCV);; Eade, E., Drummond, T., Unified loop closing recovery for real time monocular SLAM (2008) British Machine Vision Conference (BMVC);; Kawewong, A., Tangruamsub, S., Hasegawa, O., Positioninvariant robust features for long-term recognition of dynamic outdoor scenes (2010) IEICE Trans. Inf. Syst, E93-D, pp. 2587-2601; Lowe, D., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vision (IJCV), 60, pp. 91-110; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., SURF: Speeded up robust features (2009) Comput. Vision Image Understanding (CVIU), 110, pp. 346-359; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree (2006) Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR);; Knuth, D.E., Two notes on notation (1992) Am. Math. Mon, 99, pp. 403-422; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) Int. J. Rob. Res, 28, pp. 595-599; Morioka, H., Sangkyu, Y., Hasegawa, O., Vision-based mobile robot's SLAM and navigation in crowded environments (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS);},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885606487&doi=10.1080%2f01691864.2013.826410&partnerID=40&md5=135539eb8d56fc796786b85600adaaed},
}

@article{schaefer-et-al:2021:103709,
  author = {A. Schaefer and D. Büscher and J. Vertens and L. Luft and W. Burgard},
  journal = {Robotics and Autonomous Systems},
  title = {Long-term vehicle localization in urban environments based on pole landmarks extracted from 3-D lidar scans},
  volume = {136},
  pages = {103709},
  doi = {10.1016/j.robot.2020.103709},
  note = {cited By 5},
  publisher = {Elsevier B.V.},
  year = {2021},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation (Schaefer and Büscher, 0000). In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15 months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy. © 2020 Elsevier B.V.},
  affiliation = {Department of Computer Science, University of Freiburg, Germany},
  art_number = {103709},
  author_keywords = {Autonomous driving;  Feature extraction;  Landmark;  Lidar;  Localization;  Mapping;  Pole},
  coden = {RASOE},
  correspondence_address1 = {Büscher, D.; Department of Computer Science, Germany; email: buescher@cs.uni-freiburg.de},
  document_type = {Article},
  funding_text1 = {This work has been partially supported by Samsung Electronics Co. Ltd. under the GRO program.},
  issn = {09218890},
  keywords = {Agricultural robots;  Mapping;  Optical radar;  Poles, Complete mappings;  Construction sites;  Localization system;  Long term stability;  On-line localization;  Open source implementation;  Urban environments;  Vehicle localization, Urban growth},
  language = {English},
  references = {Modsching, M., Kramer, R., (2006), 2006, pp. 209-218. , K. ten Hagen, Field trial on GPS accuracy in a medium size city: the influence of built-up, in: 3rd Workshop on Positioning, Navigation and Communication; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan north campus long-term vision and lidar dataset (2015) Int. J. Robot. Res., 35 (9), pp. 1023-1035; Levinson, J., Thrun, S., Robust vehicle localization in urban environments using probabilistic maps (2010) 2010 IEEE International Conference on Robotics and Automation, pp. 4372-4378; Blanco-Claraco, J.L., Mañas-Alvarez, F., Torres-Moreno, J.L., Rodriguez, F., Gimenez-Fernandez, A., Benchmarking particle filter algorithms for efficient velodyne-based vehicle localization (2019) Sensors, 19 (14), p. 3155; Kümmerle, J., Sons, M., Poggenhans, F., Kuehner, T., Lauer, M., Stiller, C., Accurate and efficient self-localization on roads using basic geometric primitives (2019), 2019 IEEE International Conference on Robotics and Automation; Weng, L., Yang, M., Guo, L., Wang, B., Wang, C., Pole-based real-time localization for autonomous driving in congested urban scenarios (2018) 2018 IEEE International Conference on Real-Time Computing and Robotics, pp. 96-101; Fischler, M.A., Bolles, R.C., Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography (1981) Commun. ACM, 24 (6), pp. 381-395; Sefati, M., Daum, M., Sondermann, B., Kreisköther, K.D., Kampker, A., Improving vehicle localization using semantic and pole-like landmarks (2017) 2017 IEEE Intelligent Vehicles Symposium, pp. 13-19; Spangenberg, R., Goehring, D., Rojas, R., Pole-based localization for autonomous vehicles in urban scenarios (2016) 2016 IEEE International Conference on Intelligent Robots and Systems, pp. 2161-2166; Brenner, C., Global localization of vehicles using local pole patterns (2009) Pattern Recognition, pp. 61-70. , Denzler J. Notni G. Süße H. Springer Berlin Heidelberg; Cabo, C., Ordóñez, C., Garcia-Cortes, S., Martínez-Sánchez, J., An algorithm for automatic detection of pole-like street furniture objects from mobile laser scanner point clouds (2014) ISPRS J. Photogramm. Remote Sens., 87, pp. 47-56; Huang, J., You, S., Pole-like object detection and classification from urban point clouds (2015) 2015 IEEE International Conference on Robotics and Automation, pp. 3032-3038; Lehtomäki, M., Jaakkola, A., Hyyppä, J., Kukko, A., Kaartinen, H., Detection of vertical pole-like objects in a road environment using vehicle-based laser scanning data (2010) Remote Sens., 2, pp. 641-664; Rodríguez-Cuenca, B., García-Cortés, S., Ordóñez, C., Alonso, M.C., Automatic detection and classification of pole-like objects in urban point cloud data using an anomaly detection algorithm (2015) Remote Sens., 7 (10), pp. 12680-12703; Tombari, F., Fioraio, N., Cavallari, T., Salti, S., Petrelli, A., Stefano, L.D., Automatic detection of pole-like structures in 3D urban environments (2014) 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4922-4929; Wu, F., Wen, C., Guo, Y., Wang, J., Yu, Y., Wang, C., Li, J., Rapid localization and extraction of street light poles in mobile lidar point clouds: a supervoxel-based approach (2017) IEEE Trans. Intell. Transp. Syst., 18 (2), pp. 292-305; Yan, W.Y., Morsy, S., Shaker, A., Tulloch, M., Automatic extraction of highway light poles and towers from mobile lidar data (2016) Opt. Laser Technol., 77, pp. 162-168; Yu, Y., Li, J., Guan, H., Wang, C., Yu, J., Semiautomated extraction of street light poles from mobile LiDAR point-clouds (2015) IEEE Trans. Geosci. Remote Sens., 53 (3), pp. 1374-1386; Zheng, H., Tan, F., Wang, R., Pole-like object extraction from mobile lidar data (2016) Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci., 41; Yokoyama, H., Date, H., Kanai, S., Takeda, H., Detection and classification of pole-like objects from mobile laser scanning data of urban environments (2013) Int. J. CAD/CAM, 13 (2), pp. 31-40; Ordóñez, C., Cabo, C., Sanz-Ablanedo, E., Automatic detection and classification of pole-like objects for urban cartography using mobile laser scanning data (2017) Sensors, 17 (7), p. 1465; Li, F., Oude Elberink, S., Vosselman, G., Pole-like road furniture detection and decomposition in mobile laser scanning data based on spatial relations (2018) Remote Sens., 10 (4); Qin, B., Chong, Z., Bandyopadhyay, T., Ang, M.H., Frazzoli, E., Rus, D., Curb-intersection feature based Monte Carlo localization on urban roads (2012) 2012 IEEE International Conference on Robotics and Automation, pp. 2640-2646. , IEEE; Schindler, A., Vehicle self-localization with high-precision digital maps (2013) 2013 IEEE Intelligent Vehicles Symposium, pp. 141-146; Schreiber, M., Knöppel, C., Franke, U., LaneLoc: lane marking based localization using highly accurate maps (2013) 2013 IEEE Intelligent Vehicles Symposium, pp. 449-454; Hata, A.Y., Wolf, D.F., Feature detection for vehicle localization in urban environments using a multilayer lidar (2016) IEEE Trans. Intell. Transp. Syst., 17 (2), pp. 420-429; Deusch, H., Wiest, J., Reuter, S., Nuss, D., Fritzsche, M., Dietmayer, K., Multi-sensor self-localization based on maximally stable extremal regions (2014) 2014 IEEE Intelligent Vehicles Symposium Proceedings, pp. 555-560; Welzel, A., Reisdorf, P., Wanielik, G., Improving urban vehicle localization with traffic sign recognition (2015) 2015 IEEE International Conference on Intelligent Transportation Systems, pp. 2728-2732; Im, J.-H., Im, S.-H., Jee, G.-I., Vertical corner feature based precise vehicle localization using 3D lidar in urban area (2016) Sensors, 16 (8), p. 1268; Luft, L., Schaefer, A., Schubert, T., Burgard, W., Closed-form full map posteriors for robot localization with lidar sensors (2017) 2017 IEEE International Conference on Intelligent Robots and Systems, pp. 6678-6684; Fukunaga, K., Hostetler, L., The estimation of the gradient of a density function, with applications in pattern recognition (1975) IEEE Trans. Inform. Theory, 21 (1), pp. 32-40; Thrun, S., Burgard, W., Fox, D., Probabilistic Robotics (2005), The MIT Press; Schaefer, A., Büscher, D., https://github.com/acschaefer/polex, Long-term urban vehicle localization using pole landmarks extracted from 3-D lidar scans, URL; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: the KITTI dataset (2013) Int. J. Robot. Res.},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097641390&doi=10.1016%2fj.robot.2020.103709&partnerID=40&md5=5d5ddb6bedf322f6767044bee0046c6b},
}

@conference{walcott-bryant-et-al:2012:6385561,
  author = {A. Walcott-Bryant and M. Kaess and H. Johannsson and J. J. Leonard},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Dynamic pose graph SLAM: Long-term mapping in low dynamic environments},
  pages = {1871--1878},
  doi = {10.1109/IROS.2012.6385561},
  note = {cited By 93; Conference of 25th IEEE/RSJ International Conference on Robotics and Intelligent Systems, IROS 2012 ; Conference Date: 7 October 2012 Through 12 October 2012;  Conference Code:94955},
  address = {Vilamoura, Algarve},
  year = {2012},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Maintaining a map of an environment that changes over time is a critical challenge in the development of persistently autonomous mobile robots. Many previous approaches to mapping assume a static world. In this work we incorporate the time dimension into the mapping process to enable a robot to maintain an accurate map while operating in dynamical environments. This paper presents Dynamic Pose Graph SLAM (DPG-SLAM), an algorithm designed to enable a robot to remain localized in an environment that changes substantially over time. Using incremental smoothing and mapping (iSAM) as the underlying SLAM state estimation engine, the Dynamic Pose Graph evolves over time as the robot explores new places and revisits previously mapped areas. The approach has been implemented for planar indoor environments, using laser scan matching to derive constraints for SLAM state estimation. Laser scans for the same portion of the environment at different times are compared to perform change detection; when sufficient change has occurred in a location, the dynamic pose graph is edited to remove old poses and scans that no longer match the current state of the world. Experimental results are shown for two real-world dynamic indoor laser data sets, demonstrating the ability to maintain an up-to-date map despite long-term environmental changes. © 2012 IEEE.},
  affiliation = {Massachusetts Institute of Technology, Cambridge, MA 02139, United States},
  art_number = {6385561},
  coden = {85RBA},
  correspondence_address1 = {Walcott-Bryant, A.; Massachusetts Institute of Technology, Cambridge, MA 02139, United States; email: aisha.w.bryant@gmail.com},
  document_type = {Conference Paper},
  isbn = {9781467317375},
  issn = {21530858},
  keywords = {Autonomous Mobile Robot;  Change detection;  Critical challenges;  Dynamic environments;  Dynamical environment;  Environmental change;  Indoor environment;  Laser data;  Laser scans;  Mapping process;  Time dimension, Image matching;  Intelligent robots;  Intelligent systems;  Lasers;  Mapping;  State estimation, Robotics},
  language = {English},
  references = {Andrade-Cetto, J., Sanfeliu, A., Concurrent map building and localization on indoor dynamic environments (2002) International Journal of Pattern Recognition and Artificial Intelligence, 16 (3), pp. 361-374; Wolf, D.F., Sukhatme, G.S., Towards mapping dynamic environments (2003) Proceedings of the International Conference on Advanced Robotics (ICAR), pp. 594-600; Biswas, R., Limketkai, B., Sanner, S., Thrun, S., Towards object mapping in non-stationary environments with mobile robots (2002) Intelligent Robots and System, 2002. IEEE/RSJ International Conference on, 1, pp. 1014-1019. , vol.1; Mitsou, N.C., Tzafestas, C.S., Temporal occupancy grid for mobile robot dynamic environment mapping (2007) Control & Automation, 2007. MED '07. Mediterranean Conference on, pp. 1-8; Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based SLAM (2010) Intelligent Transportation Systems Magazine, IEEE, 2 (4), pp. 31-43; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Proc. of Robotics: Science and Systems (RSS); Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term SLAM (2009) The International Journal of Robotics Research, 28 (1), pp. 20-33; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) IROS, pp. 1156-1163; Meyer-Delius, D., (2011) Probabilistic Modeling of Dynamic Environments for Mobile Robots, , Ph.D. dissertation, University of Freiburg; Wyeth, G., Milford, M., Towards lifelong navigation and mapping in an office environment (2009) Proceedings of the 14th International Symposium of Robotics Research (ISRR); Fox, D., Burgard, W., Thrun, S., Cremers, A.B., Position estimation for mobile robots in dynamic environments (1998) Proc. of the National Conference on Artificial Intelligence (AAAI); Hahnel, D., Schulz, D., Burgard, W., Map building with mobile robots in populated environments (2002) Intelligent Robots and System, 2002. IEEE/RSJ International Conference on, 1, pp. 496-501. , vol.1; Wang, C.-C., Thorpe, C., Thrun, S., Online simultaneous localization and mapping with detection and tracking of moving objects: Theory and results from a ground vehicle in crowded urban areas (2003) Robotics and Automation, 2003. Proceedings. ICRA '03. IEEE International Conference on, 1, pp. 842-849. , vol.1; Olson, E., Real-time correlative scan matching (2009) ICRA'09: Proceedings of the 2009 IEEE Intl. Conf. on Robotics and Automation, pp. 1233-1239. , Piscataway, NJ, USA: IEEE Press; Gutmann, J.-S., Konolige, K., Incremental mapping of large cyclic environments (1999) International Symposium on Computational Intelligence in Robotics and Automation; Bosse, M., Newman, P., Leonard, J., Soika, M., Feiten, W., Teller, S., An Atlas framework for scalable mapping (2003) Robotics and Automation, 2003. Proceedings. ICRA '03. IEEE International Conference F on, 2, pp. 1899-1906. , vol.2; Ji, X., Zhang, H., Hai, D., Zheng, Z., A decision-theoretic active loop closing approach to autonomous robot exploration and mapping (2009) RoboCup 2008: Robot Soccer World Cup XII, 5399, pp. 507-518. , ser. Lecture Notes in Computer Science, L. Iocchi, H. Matsubara, A. Weitzenfeld, and C. Zhou, Eds. Springer; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) Robotics, IEEE Transactions on, 24 (6), pp. 1365-1378; Johannsson, H., Kaess, M., Fallon, M.F., Leonard, J.J., Temporally scalable visual SLAM using a reduced pose graph (2012) Computer Science and Artificial Intelligence Laboratory, MIT, Tech. Rep. MIT-CSAILTR-2012-013, , May},
  source = {Scopus},
  sponsors = {IEEE Robotics and Automation Society (RAS); IEEE Industrial Electronics Society (IES); Robotics Society of Japan (RSJ); Society of Instrument and Control Engineers (SICE); New Technology Foundation (NTF)},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872347968&doi=10.1109%2fIROS.2012.6385561&partnerID=40&md5=ecb49adc23454d108fe45bcb6e9f2888},
}

@article{bacca-et-al:2013:003,
  author = {B. Bacca and J. Salvi and X. Cufi},
  journal = {Robotics and Autonomous Systems},
  title = {Long-term mapping and localization using feature stability histograms},
  volume = {61},
  number = {12},
  pages = {1539--58},
  doi = {10.1016/j.robot.2013.07.003},
  note = {long-term mapping and localization;feature stability histograms;FSH model;feature management approach;voting schema;reobserved features;human memory model;short-term memory;STM;long-term memory;LTM;local feature stability values;FastSLAM framework;dynamic object filtering;map accuracy;data association effort reduction;mobile robotics;},
  address = {Netherlands},
  year = {2013},
  abstract = {This work proposes a system for long-term mapping and localization based on the Feature Stability Histogram (FSH) model which is an innovative feature management approach able to cope with changing environments. FSH is built using a voting schema, where re-observed features are promoted; otherwise the feature progressively decreases its corresponding FSH value. FSH is inspired by the human memory model. This model introduces concepts of Short-Term Memory (STM), which retains information long enough to use it, and Long-Term Memory (LTM), which retains information for longer periods of time. If the entries in STM are continuously rehearsed, they become part of LTM. However, this work proposes a change in the pipeline of this model, allowing any feature to be part of STM or LTM depending on the feature strength. FSH stores the stability values of local features, stable features are only used for localization and mapping. Experimental validation of the FSH model was conducted using the FastSLAM framework and a long-term dataset collected during a period of one year at different environmental conditions. The experiments carried out include qualitative and quantitative results such as: filtering out dynamic objects, increasing map accuracy, scalability, and reducing the data association effort in long-term runs. [All rights reserved Elsevier].},
  copyright = {Copyright 2014, The Institution of Engineering and Technology},
  issn = {0921-8890},
  keywords = {mobile robots;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1016/j.robot.2013.07.003},
}

@article{bescos-et-al:2018:2860039,
  author = {B. Bescos and J. M. Facil and J. Civera and J. Neira},
  journal = {IEEE Robotics and Automation Letters},
  title = {DynaSLAM: Tracking, Mapping, and Inpainting in Dynamic Scenes},
  volume = {3},
  number = {4},
  pages = {4076--4083},
  doi = {10.1109/LRA.2018.2860039},
  note = {cited By 243},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {The assumption of scene rigidity is typical in SLAM algorithms. Such a strong assumption limits the use of most visual SLAM systems in populated real-world environments, which are the target of several relevant applications like service robotics or autonomous vehicles. In this letter we present DynaSLAM, a visual SLAM system that, building on ORB-SLAM2, adds the capabilities of dynamic object detection and background inpainting. DynaSLAM is robust in dynamic scenarios for monocular, stereo, and RGB-D configurations. We are capable of detecting the moving objects either by multiview geometry, deep learning, or both. Having a static map of the scene allows inpainting the frame background that has been occluded by such dynamic objects. We evaluate our system in public monocular, stereo, and RGB-D datasets. We study the impact of several accuracy/speed trade-offs to assess the limits of the proposed methodology. DynaSLAM outperforms the accuracy of standard visual SLAM baselines in highly dynamic scenarios. And it also estimates a map of the static parts of the scene, which is a must for long-term applications in real-world environments. © 2016 IEEE.},
  affiliation = {Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza, Spain},
  art_number = {8421015},
  author_keywords = {localization;  SLAM;  visual-based navigation},
  correspondence_address1 = {Bescos, B.; Instituto de Investigación en Ingeniería de Aragón (I3A), Spain; email: bbescos@unizar.es},
  document_type = {Article},
  funding_details = {DGA T04-FSE},
  funding_text1 = {Manuscript received February 23, 2018; accepted July 11, 2018. Date of publication July 26, 2018; date of current version August 13, 2018. This letter was recommended for publication by Associate Editor T. Duckett and Editor D. Lee upon evaluation of the reviewers’ comments. This work was supported in part by NVIDIA through the donation of a Titan X GPU, in part by the Spanish Ministry of Economy and Competitiveness under Projects DPI2015-68905-P and DPI2015-67275-P, FPI Grant BES-2016-077836, and in part by the Aragón regional government (Grupo DGA T04-FSE). (Corresponding author: Berta Bescos.) The authors are with the Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza 50018, Spain (e-mail:, bbescos@ unizar.es; jmfacil@unizar.es; jcivera@unizar.es; jneira@unizar.es). Digital Object Identifier 10.1109/LRA.2018.2860039},
  funding_text2 = {This work was supported in part by NVIDIA through the donation of a Titan X GPU, in part by the Spanish Ministry of Economy and Competitiveness under Projects DPI2015-68905-P and DPI2015-67275-P, FPI Grant BES-2016-077836, and in part by the Arag?n regional government (Grupo DGA T04-FSE).},
  issn = {23773766},
  keywords = {Deep learning;  Economic and social effects;  Robotics;  Robots, Autonomous Vehicles;  Background inpainting;  Dynamic scenarios;  Localization;  Multi-view geometry;  Real world environments;  Service robotics;  SLAM, Object detection},
  language = {English},
  references = {Mur-Artal, R., Tardós, J.D., ORB-SLAM2: An open-source slam system for monocular, stereo, and RGB-D cameras (2017) IEEE Trans. Robot., 33 (5), pp. 1255-1262. , Oct; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) Proc. 6th IEEE ACMInt. Symp. Mixed Augmented Reality, pp. 225-234; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Trans. Robot., 31 (5), pp. 1147-1163. , Oct; Stühmer, J., Gumhold, S., Cremers, D., Real-time dense geometry from a handheld camera (2010) Proc. Joint Pattern Recognit. Symp., pp. 11-20; Newcombe, R.A., Lovegrove, S.J., Davison, A.J., DTAM: Dense tracking and mapping in real-time (2011) Proc. IEEE Int. Conf. Comput. Vision, pp. 2320-2327; Graber, G., Pock, T., Bischof, H., Online 3D reconstruction using convex optimization (2011) Proc. IEEE Int. Conf. Comput. Vision Workshops, pp. 708-711; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Large-scale direct monocular SLAM (2014) Proc. Eur. Conf. Comput. Vision, pp. 834-849; Engel, J., Koltun, V., Cremers, D., Direct sparse odometry (2017) IEEE Trans. Pattern Anal. Mach. Intell., 40 (3), pp. 611-625. , Mar; Tan, W., Liu, H., Dong, Z., Zhang, G., Bao, H., Robust monocularSLAM in dynamic environments (2013) Proc. IEEE Int. Symp. Mixed Augmented Reality, pp. 209-218; Wangsiripitak, S., Murray, D.W., Avoiding moving outliers in visual SLAM by tracking moving objects (2009) IEEE Int. Conf. Robot. Automat., pp. 375-380; Riazuelo, L., Montano, L., Montiel, J.M.M., Semantic visual SLAM in populated environments (2017) Proc. Eur. Conf. Mobile Robots, pp. 1-7; Li, S., Lee, D., RGB-D SLAM in dynamic environments using static point weighting (2017) IEEE Robot. Autom. Lett., 2 (4), pp. 2263-2270. , Oct; Alcantarilla, P.F., Yebes, J.J., Almazán, J., Bergasa, L.M., On combining visual SLAM and dense scene flow to increase the robustness of localization and mapping in dynamic environments (2012) Proc. Int. Conf. Robot. Automat., pp. 1290-1297; Wang, Y., Huang, S., Motion segmentation based robust RGB-D SLAM (2014) Proc. 11th World Congr. Intell. Control Automat., pp. 3122-3127; Kim, D.-H., Kim, J.-H., Effective background model-based RGB-D dense visual odometry in a dynamic environment (2016) IEEE Trans. Robot., 32 (6), pp. 1565-1573. , Dec; Sun, Y., Liu, M., Meng, M.Q.-H., Improving RGB-D SLAM in dynamic environments: A motion removal approach (2017) Robot. Auton. Syst., 89, pp. 110-122; Concha, A., Civera, J., DPPTAM: Dense piecewise planar tracking and mapping from a monocular sequence (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 5686-5693; Ambrus, R., Folkesson, J., Jensfelt, P., Unsupervised object segmentation through change detection in a long term autonomy scenario (2016) Proc. IEEE-RAS 16th Int. Conf. Humanoid Robots (Humanoids); He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask R-CNN (2017) Proc. IEEE Int. Conf. Comput. Vision, pp. 2980-2988; Lin, T.-Y., Microsoft coco: Common objects in context (2014) Proc. Eur. Conf. Comput. Vision, pp. 740-755; Gerlach, N.L., Meijer, G.J., Kroon, D.-J., Bronkhorst, E.M., Bergé, S.J., Maal, T.J.J., Evaluation of the potential of automatic segmentation of the mandibular canal (2014) Brit. J. Oral Maxillofacial Surgery, 52 (9), pp. 838-844; Sturm, J., Engelhard, N., Endres, F., Burgard, W., Cremers, D., A benchmark for the evaluation of RGB-D SLAM systems (2012) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 573-580; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The KITTI dataset (2013) Int. J. Robot. Res., 32 (11), pp. 1231-1237; Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T., Efros, A.A., Context encoders: Feature learning by inpainting (2016) Proc. Comput. Vision Pattern Recognit., pp. 2536-2544},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062528288&doi=10.1109%2fLRA.2018.2860039&partnerID=40&md5=a816f645991a250a0cbe53c7ef70d1d9},
}

@inproceedings{liu-et-al:2021:9561126,
  author = {B. Liu and F. Tang and Y. Fu and Y. Yang and Y. Wu},
  journal = {2021 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {A Flexible and Efficient Loop Closure Detection Based on Motion Knowledge},
  pages = {11241--7},
  doi = {10.1109/ICRA48506.2021.9561126},
  note = {novel LCD algorithm;motion knowledge;flexible detection strategy;efficient detection strategy;flexible combinations;efficient combinations;global binary feature;hand-crafted local binary feature;continuous motion model;motion states;visual-inertial odometry system;localization errors;state-of-the-art LCD algorithms;loop closure detection;essential module;long-term explorations;bag-of-words model;low time consumption;},
  address = {Piscataway, NJ, USA},
  year = {2021},
  abstract = {Loop closure detection (LCD) is an essential module for simultaneous localization and mapping (SLAM), which can correct accumulated errors after long-term explorations. The widely used bag-of-words (BoW) model can not satisfy well the requirements of both low time consumption and high accuracy for a mobile platform. In this paper, we propose a novel LCD algorithm based on motion knowledge. We give a flexible and efficient detection strategy and also give flexible and efficient combinations of a global binary feature extracted by convolutional neural network (CNN) and a hand-crafted local binary feature. We take a continuous motion model, grid-based motion statistics (GMS) and motion states as motion knowledge. Furthermore, we fuse the proposed LCD with a visual-inertial odometry (VIO) system to correct localization errors by a pose graph optimization. Comparative experiments with state-of-the-art LCD algorithms on typical datasets have been carried out, and the results demonstrate that our proposed method achieves quite high recall rates and quite high speed at 100% precision. Moreover, experimental results from VIO further validate the effectiveness of the proposed method.},
  copyright = {Copyright 2021, The Institution of Engineering and Technology},
  keywords = {distance measurement;feature extraction;graph theory;mobile robots;neural nets;object detection;pose estimation;robot vision;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/ICRA48506.2021.9561126},
}

@article{kim-et-al:2021:3047421,
  author = {C. Kim and S. Cho and M. Sunwoo and P. Resende and B. Bradai and K. Jo},
  journal = {IEEE Access},
  title = {A Geodetic Normal Distribution Map for Long-Term LiDAR Localization on Earth},
  volume = {9},
  pages = {470--484},
  doi = {10.1109/ACCESS.2020.3047421},
  note = {cited By 1},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Access},
  abstract = {Light detection and ranging (LiDAR) sensors enable a vehicle to estimate a pose by matching their measurements with a point cloud (PCD) map. However, the PCD map structure, widely used in robot fields, has some problems to be applied for mass production in automotive fields. First, the PCD map is too big to store all map data at in-vehicle units or download the map data from a wireless network according to the vehicle location. Second, the PCD map, represented by a single origin in the Cartesian coordinates, causes coordinate conversion errors due to an inaccurate plane-orb projection, when the vehicle estimate the geodetic pose on Earth. To solve two problems, this paper presents a geodetic normal distribution (GND) map structure. The GND map structure supports a geodetic quad-tree tiling system with multiple origins to minimize the coordinate conversion errors. The map data managed by the GND map structure are compressed by using Cartesian probabilistic distributions of points as map features. The truncation errors by heterogeneous coordinates between the geodetic tiling system and Cartesian distributions are compensated by the Cartesian voxelization rule. In order to match the LiDAR measurements with the GND map structure, the paper proposes map-matching approaches based on Monte-Carlo and optimization. The paper performed some experiments to evaluate the map size compression and the long-term localization on Earth: comparison with the PCD map structure, localization in various continents, and long-term localization. © 2013 IEEE.},
  affiliation = {Department of Automotive Engineering, Hanyang University, Seoul, South Korea; Valeo Driving Assistance Research Center, Bobigny Cedex, France; Department of Smart Vehicle Engineering, Konkuk University, Seoul, 05029, South Korea},
  art_number = {9308903},
  author_keywords = {map compression;  normal distribution map;  registration;  World-scale map management},
  correspondence_address1 = {Jo, K.; Department of Smart Vehicle Engineering, South Korea; email: kichun.jo@gmail.com},
  document_type = {Article},
  funding_details = {Ministry of EducationMinistry of Education, MOE, 10039673, 10060068, 10079961, 22A20130000045},
  funding_text1 = {This work was supported in part by the BK21 Plus Program through the Ministry of Education, South Korea, under Grant 22A20130000045; in part by the Industrial Strategy Technology Development Program under Grant 10039673, Grant 10060068, and Grant 10079961; in part by the International Collaborative Research and Development Program through the Ministry of Trade, Industry, and Energy (MOTIE Korea) under Grant N0001992; and in part by the National Research Foundation of Korea (NRF) Grant funded by the Korean Government (MEST) under Grant 2011-0017495.},
  issn = {21693536},
  keywords = {Errors;  Geodesy;  Normal distribution;  Vehicles, Cartesian coordinate;  Coordinate conversion;  Lidar measurements;  Light detection and ranging;  Mass production;  Probabilistic distribution;  Truncation errors;  Vehicle location, Optical radar},
  language = {English},
  references = {Thrun, S., Stanley: The robot that won the DARPA grand challenge (2006) J. Field Robot., 23 (9), pp. 661-692; Montemerlo, M., Junior: The stanford entry in the urban challenge (2008) J. Field Robot., 25 (9), pp. 569-597. , Sep; Urmson, C., Autonomous driving in urban environments: Boss and the urban challenge (2008) J. Field Robot., 25 (8), pp. 425-466; Kim, C., Jo, K., Cho, S., Sunwoo, M., Optimal smoothing based mapping process of road surface marking in urban canyon environment (2017) Proc. 14th Workshop Positioning, Navigat. Commun. (WPNC), pp. 1-6. , http://ieeexplore.ieee.org/document/8250072/, Oct; Kim, C., Cho, S., Sunwoo, M., Jo, K., Crowd-sourced mapping of new feature layer for high-definition map (2018) Sensors, 18 (12), p. 4172. , https://www.mdpi.com/1424-8220/18/12/4172, Nov; Jeong, J., Cho, Y., Kim, A., Road-SLAM: Road marking based SLAM with lane-level accuracy (2017) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 1736-1743. , Jun; Qu, X., Soheilian, B., Paparoditis, N., Vehicle localization using monocamera and geo-referenced traffic signs (2015) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 605-610. , Jun; Levinson, J., Montemerlo, M., Thrun, S., Map-based precision vehicle localization in urban environments (2007) Robotics: Science and Systems, 4. , Citeseer; Choi, J., Hybrid map-based SLAM using a velodyne laser scanner (2014) Proc. 17th Int. IEEE Conf. Intell. Transp. Syst. (ITSC), pp. 3082-3087. , Oct; Kuutti, S., Fallah, S., Katsaros, K., Dianati, M., Mccullough, F., Mouzakitis, A., A survey of the state-of-the-art localization techniques and their potentials for autonomous vehicle applications (2018) IEEE Internet Things J., 5 (2), pp. 829-846. , Apr; Wiggers, K., (2020) Bosch Debuts Long-Range Lidar Sensor for Autonomous Vehicles, , https://venturebeat.com/2020/01/02/bosch-debuts-new-lidar-sensor-for-autonomous-vehicles/; Mobileye. Road Experience Management (REM), , https://www.mobileye.com/our-technology/rem/, Accessed: Oct. 29 2019; Jo, K., Lee, M., Sunwoo, M., Fast GPS-DR sensor fusion framework: Removing the geodetic coordinate conversion process (2016) IEEE Trans. Intell. Transp. Syst., 17 (7), pp. 2008-2013. , Jul; Jo, K., Cho, S., Kim, C., Resende, P., Bradai, B., Nashashibi, F., Sunwoo, M., Cloud update of tiled evidential occupancy grid maps for the multi-vehicle mapping (2018) Sensors, 18 (12), p. 4119. , http://www.mdpi.com/1424-8220/18/12/4119, Nov; Liu, R., Wang, J., Zhang, B., High definition map for automated driving: Overview and analysis (2019) J. Navigat., 73 (2), pp. 324-341. , Mar; Schreiber, M., Knöppel, C., Franke, U., LaneLoc: Lane marking based localization using highly accurate maps (2013) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 449-454. , Jun; Ziegler, J., Lategahn, H., Schreiber, M., Keller, C.G., Knöppel, C., Hipp, J., Haueis, M., Stiller, C., Video based localization for bertha (2014) Proc. IEEE Intell. Vehicles Symp. Proc., pp. 1231-1238. , Jun; Al Hage, J., Xu, P., Bonnifait, P., High integrity localization with multilane camera measurements (2019) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 1232-1238. , Jun; Suhr, J.K., Jang, J., Min, D., Jung, H.G., Sensor fusion-based low-cost vehicle localization system for complex urban environments (2017) IEEE Trans. Intell. Transp. Syst., 18 (5), pp. 1078-1086. , May; Stewart, A.D., Newman, P., Laps-localisation using appearance of prior structure: 6-dof monocular camera localisation using prior pointclouds (2012) Proc. IEEE Int. Conf. Robot. Autom., pp. 2625-2632. , May; Maddern, W., Pascoe, G., Newman, P., Leveraging experience for largescale LIDAR localisation in changing cities (2015) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 1684-1691. , May; Liu, Z., Chen, H., Di, H., Tao, Y., Gong, J., Xiong, G., Qi, J., Real-time 6D lidar SLAM in large scale natural terrains for UGV (2018) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 662-667. , Jun; Xu, Y., John, V., Mita, S., Tehrani, H., Ishimaru, K., Nishino, S., 3D point cloud map based vehicle localization using stereo camera (2017) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 487-492. , Jun; Wang, Z., Fang, J., Dai, X., Zhang, H., Vlacic, L., Intelligent vehicle self-localization based on double-layer features and multilayer LIDAR (2020) IEEE Trans. Intell. Vehicles, 5 (4), pp. 616-625. , Dec; Yue, Y., Zhao, C., Wen, M., Wu, Z., Wang, D., Collaborative semantic perception and relative localization based on map matching (2020) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 6188-6193. , Oct; Akai, N., Hirayama, T., Murase, H., Semantic localization considering uncertainty of object recognition (2020) IEEE Robot. Autom. Lett., 5 (3), pp. 4384-4391. , Jul; Thrun, S., Burgard, W., Fox, D., A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping (2000) Proc. ICRA, 1, pp. 321-328; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Trans. Robot., 23 (1), pp. 34-36. , Feb; Fu, H., Xue, H., Ren, R., Fast implementation of 3D occupancy grid for autonomous driving (2020) Proc. 12th Int. Conf. Intell. Hum.-Mach. Syst. Cybern. (IHMSC), 2, pp. 217-220; Trehard, G., Alsayed, Z., Pollard, E., Bradai, B., Nashashibi, F., Credibilist simultaneous localization and mapping with a LIDAR (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 2699-2706. , Sep; Trehard, G., Pollard, E., Bradai, B., Nashashibi, F., On line mapping and global positioning for autonomous driving in urban environment based on evidential SLAM (2015) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 814-819. , Jun; Cho, S., Kim, C., Jo, K., Sunwoo, M., (2019) A GPU Accelerated Particle Filter Based Localization Using 3D Evidential Voxel Maps, , SAE Tech. Paper 2019-01-0491; Wurm, K.M., OctoMap: A probabilistic, flexible, and compact 3D map representation for robotic systems (2010) Proc. ICRA Workshop Best Pract. 3D Perception Modeling Mobile Manipulation, 2; Hornung, A., Wurm, K.M., Bennewitz, M., Stachniss, C., Burgard, W., OctoMap: An efficient probabilistic 3D mapping framework based on octrees (2013) Auto. Robots, 34 (3), pp. 189-206. , http://link.springer.com/10.1007/s10514-012-9321-0, Apr; Magnusson, M., Lilienthal, A., Duckett, T., Scan registration for autonomous mining vehicles using 3D-NDT (2007) J. Field Robot., 24 (10), pp. 803-827. , Oct; Stoyanov, T., Magnusson, M., Andreasson, H., Lilienthal, A.J., Fast and accurate scan registration through minimization of the distance between compact 3D NDT representations (2012) Int. J. Robot. Res., 31 (12), pp. 1377-1393. , Oct; Javanmardi, E., Javanmardi, M., Gu, Y., Kamijo, S., Adaptive resolution refinement of NDT map based on localization error modeled by map factors (2018) Proc. 21st Int. Conf. Intell. Transp. Syst. (ITSC), pp. 2237-2243. , https://ieeexplore.ieee.org/document/8569236/, Nov; Wolcott, R.W., Eustice, R.M., Fast LIDAR localization using multiresolution Gaussian mixture maps (2015) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 2814-2821. , May; Wolcott, R.W., Eustice, R.M., Robust LIDAR localization using multiresolution Gaussian mixture maps for autonomous driving (2017) Int. J. Robot. Res., 36 (3), pp. 292-319. , http://journals.sagepub.com/doi/10.1177/0278364917696568, Mar; Kim, K.-W., Jee, G.-I., Free-resolution probability distributions mapbased precise vehicle localization in urban areas (2020) Sensors, 20 (4), p. 1220. , Feb; Biber, P., Strasser, W., The normal distributions transform: A new approach to laser scan matching (2003) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), 3, pp. 2743-2748. , http://ieeexplore.ieee.org/document/1249285/, Nov; Li, L., Yang, M., Wang, C., Wang, B., Road DNA based localization for autonomous vehicles (2016) Proc. IEEE Intell. Vehicles Symp. (IV), pp. 883-888. , Aug; (2019) TomTom HD Map with RoadDNA, , https://www.tomtom.com/automotive/automotivesolutions/automated-driving/hd-map-roaddna/, Accessed: Oct. 29; Galvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Mousavian, A., Košecka, J., Semantically aware bag-of-words for localization (2015) Proc. CVPR Workshops; Morton, G.M., A computer oriented geodetic data base and a new technique in file sequencing (1966) IBM Res., , https://dominoweb.draco.res.ibm.com/0dabf9473b9c86d48525779800566a39.html, Tech. Rep; (2019) Google Protocol Buffers, , https://developers.google.com/protocol-buffers, Accessed: Oct. 29; Akai, N., Hirayama, T., Murase, H., 3D Monte Carlo localization with efficient distance field representation for automated driving in dynamic environments (2020) Proc. IEEE Intell. Vehicles Symp., pp. 1588-1595. , Jun; Jo, H., Kim, E., New Monte Carlo localization using deep initialization: A three-dimensional LiDAR and a camera fusion approach (2020) IEEE Access, 8, pp. 74485-74496; Kim, C., Cho, S., Jang, C., Sunwoo, M., Jo, K., Evidence filter of semantic segmented image from around view monitor in automated parking system (2019) IEEE Access, 7, pp. 92791-92804. , https://ieeexplore.ieee.org/document/8758815/; Cho, S., Kim, C., Sunwoo, M., Jo, K., Robust localization in map changing environments based on hierarchical approach of sliding window optimization and filtering (2020) IEEE Trans. Intell. Transp. Syst., , early access, Nov. 17; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The KITTI dataset (2013) Int. J. Robot. Res., 32 (11), pp. 1231-1237. , http://www.cvlibs.net/publications/Geiger2013IJRR.pdf, Sep; Reid, T.G.R., Houts, S.E., Cammarata, R., Mills, G., Agarwal, S., Vora, A., Pandey, G., (2019) Localization Requirements for Autonomous Vehicles, pp. 1-16. , http://arxiv.org/abs/1906.01061},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098756455&doi=10.1109%2fACCESS.2020.3047421&partnerID=40&md5=789605919db35cb0d2d39b4bb7661e8f},
}

@article{qin-et-al:2020:103561,
  author = {C. Qin and Y. Zhang and Y. Liu and S. Coleman and D. Kerr and G. Lv},
  journal = {Robotics and Autonomous Systems},
  title = {Appearance-invariant place recognition by adversarially learning disentangled representation},
  volume = {131},
  pages = {103561},
  doi = {10.1016/j.robot.2020.103561},
  note = {cited By 3},
  publisher = {Elsevier B.V.},
  year = {2020},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {Place recognition is an essential component to address the problem of visual navigation and SLAM. The long-term place recognition is challenging as the environment exhibits significant variations across different times of the days, months, and seasons. In this paper, we view appearance changes as multiple domains and propose a Feature Disentanglement Network (FDNet) based on a convolutional auto-encoder and adversarial learning to extract two independent deep features — content and appearance. In our network, the content feature is learned which only retains the content information of images through the competition with the discriminators and content encoder. Besides, we utilize the triplets loss to make the appearance feature encode the appearance information. The generated content features are directly used to measure the similarity of images without dimensionality reduction operations. We use datasets that contain extreme appearance changes to carry out experiments, which show how meaningful recall at 100% precision can be achieved by our proposed method where existing state-of-art approaches often get worse performance. © 2020 Elsevier B.V.},
  affiliation = {College of Information Science and Engineering, Northeastern University, Shenyang, China; Intelligent Systems Research Centre, University of Ulster, Derry, United Kingdom},
  art_number = {103561},
  author_keywords = {Adversarial learning;  Changing environment;  Representation disentanglement;  Visual place recognition},
  coden = {RASOE},
  correspondence_address1 = {Zhang, Y.; College of Information Science and Engineering, China; email: zhangyunzhou@mail.neu.edu.cn},
  document_type = {Article},
  funding_details = {61403120111},
  funding_text1 = {Yunzhou Zhang received B.S. and M.S. degree in Mechanical and Electronic engineering from National University of Defense Technology, Changsha, China in 1997 and 2000, respectively. He received Ph.D. degree in pattern recognition and intelligent system from Northeastern University, Shenyang, China, in 2009. He is currently a professor with the Faculty of Robot Science and Engineering, Northeastern University, China. Now he leads the Cloud Robotics and Visual Perception Research Group. His research has been supported by funding from various sources such as National Natural Science Foundation of China, Ministry of science and technology of China, Ministry of Education of China and some famous high-tech companies. He has published many journal papers and conference papers in intelligent robots, computer vision and wireless sensor networks. His research interests include intelligent robot, computer vision, and sensor networks.},
  funding_text2 = {Supported by National Natural Science Foundation of China (No. 61973066 , 61471110 ), Fundamental Research Funds for the Central Universities ( N172608005 , N182608004 ), Equipment Pre-research Foundation ( 61403120111 ), Foundation of Key Laboratory of Aerospace System Simulation ( 6142002301 ) and the Natural Science Foundation of Liaoning ( No.20180520040 ).},
  funding_text3 = {Sonya Coleman received the B.Sc. degree (Hons.) in mathematics, statistics, and computing, and the Ph.D. degree in mathematics from Ulster University, Londonderry, U.K., in 1999 and 2003, respectively. She is currently a Professor with the School of Computing and Intelligent System, Ulster University, and also a Cognitive Robotics Team Leader with the Intelligent Systems Research Centre. Her research has been supported by funding from various sources such as EPSRC, The Nuffield Foundation, The Leverhulme Trust, and the EU. She was involved in the EU FP7 funded projects RUBICON, VISUALISE, and SLANDAIL. She has authored or coauthored over 150 publications in robotics, image processing, and computational neuroscience. Dr. Coleman was awarded the Distinguished Research Fellowship by Ulster University in recognition of her contribution research in 2009.},
  issn = {09218890},
  keywords = {Agricultural robots;  Dimensionality reduction;  Signal encoding, Adversarial learning;  Auto encoders;  Content information;  Multiple domains;  Place recognition;  Visual Navigation, Arts computing},
  language = {English},
  references = {Oliva, A., Torralba, A., Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope (2001), pp. 145-175. , Kluwer Academic Publishers; Michael J. Swain Ballard, D.H., Color indexing (1991) Int. J. Comput. Vis., 7 (1), pp. 11-32; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Proc. Int. Conf. Comp. Vis. Patt. Recog., 1 (12), pp. 886-893; Lowe, D.G., (1999), p. 1150. , Lowe, D.: Object recognition from local scale-invariant features, in: Proc. ICCV, IEEE International Conference on Computer Vision; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., Speeded-up robust features (SURF) (2008) Comput. Vis. Image Underst., 110 (3), pp. 346-359; Csurka, G., Dance, C., Fan, L., Willamowski, J., Bray, C., Visual categorization with bags of keypoints (2004) Prague, 1, pp. 1-2. , Workshop on Statistical Learning in Computer Vision, ECCV; Radenović, F., Tolias, G., Chum, O., CNN image retrieval learns from BoW: Unsupervised fine-tuning with hard examples (2016), ECCV; Mur-Artal, R., Montiel, J.M.M., Tardós, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2017) IEEE Trans. Robot., 31 (5), pp. 1147-1163; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012), pp. 1097-1105. , International Conference on Neural Information Processing Systems; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) Intelligent Robots and Systems (IROS), 2015 IEEE/RSJ International Conference on, pp. 4297-4304. , IEEE; Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014), pp. 2672-2680. , International Conference on Neural Information Processing Systems; Liu, A.H., Liu, Y.-C., Yeh, Y.-Y., Wang, Y.-C.F., A unified feature disentangler for multi-domain image translation and manipulation (2018) Advances in Neural Information Processing Systems, pp. 2591-2600; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1798-1828; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Trans. Robot., 32 (1), pp. 1-19; Valgren, C., Lilienthal, A.J., SIFT, SURF & seasons: Appearance-based long-term localization in outdoor environments (2010) Robot. Auton. Syst., 58 (2), pp. 149-156; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., FAB-MAP+ RatSLAM: Appearance-based SLAM for multiple times of day (2010) Robotics and Automation (ICRA), 2010 IEEE International Conference on, pp. 3507-3512. , IEEE; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1643-1649. , IEEE; Naseer, T., Burgard, W., Stachniss, C., Robust visual localization across seasons (2018) IEEE Trans. Robot., 34 (2), pp. 289-302; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on, pp. 2769-2776. , IEEE; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., Fusion and binarization of CNN features for robust topological localization across seasons (2016) Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on, pp. 4656-4663. , IEEE; Naseer, T., Oliveira, G.L., Brox, T., Burgard, W., Semantics-aware visual localization under challenging perceptual conditions (2017) Robotics and Automation (ICRA), 2017 IEEE International Conference on, pp. 2614-2620. , IEEE; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014), pp. 2564-2570. , AAAI; Maddern, W., Stewart, A., McManus, C., Upcroft, B., Churchill, W., Newman, P., Illumination invariant imaging: Applications in robust vision-based localisation, mapping and classification for autonomous vehicles (2014), 2, p. 3. , Proceedings of the Visual Place Recognition in Changing Environments Workshop, IEEE International Conference on Robotics and Automation (ICRA), Hong Kong, China; McManus, C., Churchill, W., Maddern, W., Stewart, A.D., Newman, P., Shady dealings: Robust, long-term visual localisation using illumination invariance (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference on, pp. 901-906. , IEEE; Lowry, S.M., Milford, M.J., Wyeth, G.F., Transforming morning to afternoon using linear regression techniques (2014), pp. 3950-3955. , IEEE International Conference on Robotics and Automation; Neubert, P., Sünderhauf, N., Protzel, P., Superpixel-based appearance change prediction for long-term navigation across seasons (2015) Robot. Auton. Syst., 69, pp. 15-27; Sünderhauf, N., Protzel, P., Brief-gist-closing the loop by simple means (2011) Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on, pp. 1234-1241. , IEEE; Latif, Y., Garg, R., Milford, M., Reid, I., Addressing challenging place recognition tasks using generative adversarial networks (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 2349-2355. , IEEE; Taigman, Y., Polyak, A., Wolf, L., Unsupervised cross-domain image generation (2016), arXiv preprint; Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A.P., Wang, Z., (2017), 2, p. 4. , Photo-realistic single image super-resolution using a generative adversarial network, in: CVPR; Zhu, J.-Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017), IEEE International Conference on Computer Vision; Arjovsky, M., Chintala, S., Bottou, L., Wasserstein gan (2017), arXiv preprint; Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., Courville, A.C., Improved training of wasserstein gans (2017) Advances in Neural Information Processing Systems, pp. 5767-5777; Ganin, Y., Lempitsky, V., Unsupervised domain adaptation by backpropagation (2015), pp. 1180-1189. , International Conference on Machine Learning; Donahue, J., Krähenbühl, P., Darrell, T., Adversarial feature learning (2016), arXiv preprint; Liu, M.-Y., Tuzel, O., Coupled generative adversarial networks (2016) Advances in Neural Information Processing Systems, pp. 469-477; Wulfmeier, M., Bewley, A., Posner, I., Addressing appearance change in outdoor robotics with adversarial domain adaptation (2017) Intelligent Robots and Systems (IROS), 2017 IEEE/RSJ International Conference on, pp. 1551-1558. , IEEE; Wulfmeier, M., Bewley, A., Posner, I., Incremental adversarial domain adaptation for continually changing environments (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 1-9. , IEEE; Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., Frey, B., Adversarial autoencoders (2015), arXiv preprint; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier GANs (2017), pp. 2642-2651. , International Conference on Machine Learning; Huang, F.J., Boureau, Y.-L., LeCun, Y., Unsupervised learning of invariant feature hierarchies with applications to object recognition (2007) Computer Vision and Pattern Recognition, 2007. CVPR’07. IEEE Conference on, pp. 1-8. , IEEE; Kenshimov, C., Bampis, L., Amirgaliyev, B., Arslanov, M., Gasteratos, A., Deep learning features exception for cross-season visual place recognition (2017) Pattern Recognit. Lett., 100, pp. 124-130; Odena, A., Olah, C., Shlens, J., Conditional image synthesis with auxiliary classifier GANs (2017) Proceedings of the 34th International Conference on Machine Learning, vol. 70, pp. 2642-2651. , PMLR; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., Infogan: Interpretable representation learning by information maximizing generative adversarial nets (2016) Advances in Neural Information Processing Systems, pp. 2172-2180; Lample, G., Zeghidour, N., Usunier, N., Bordes, A., Denoyer, L., Fader networks: Manipulating images by sliding attributes (2017) Advances in Neural Information Processing Systems, pp. 5967-5976; Liu, Y.-C., Yeh, Y.-Y., Fu, T.-C., Wang, S.-D., Chiu, W.-C., Wang, Y.-C.F., Detach and adapt: Learning cross-domain disentangled deep representation (2018), Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Huang, X., Liu, M.-Y., Belongie, S., Kautz, J., Multimodal unsupervised image-to-image translation (2018), ECCV; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015), pp. 815-823. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: The Oxford RobotCar dataset (2017) Int. J. Robot. Res., 36 (1), pp. 3-15; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197; Bingham, E., Mannila, H., Random projection in dimensionality reduction: applications to image and text data (2001) Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 245-250. , ACM; Chen, Z., Maffra, F., Sa, I., Chli, M., Only look once, mining distinctive landmarks from ConvNet for visual place recognition (2017), IEEERSJ International Conference on Intelligent Robots & Systems; Chen, Z., Jacobson, A., Sünderhauf, N., Upcroft, B., Liu, L., Shen, C., Reid, I., Milford, M., Deep learning features at scale for visual place recognition (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 3223-3230. , IEEE; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2016), pp. 5297-5307. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Merrill, N., Huang, G., Lightweight unsupervised deep loop closure (2018), Proc. of Robotics: Science and Systems (RSS), Pittsburgh, PA; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., (2015), Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free, Proceedings of Robotics: Science and Systems XII},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085276237&doi=10.1016%2fj.robot.2020.103561&partnerID=40&md5=6bf815af2793164437e3aac295ae84a4},
}

@conference{yu-et-al:2019:8961714,
  author = {C. Yu and Z. Liu and X.-J. Liu and F. Qiao and Y. Wang and F. Xie and Q. Wei and Y. Yang},
  journal = {IEEE International Conference on Robotics and Biomimetics, ROBIO 2019},
  title = {A DenseNet feature-based loop closure method for visual SLAM system},
  pages = {258--265},
  doi = {10.1109/ROBIO49542.2019.8961714},
  note = {cited By 1; Conference of 2019 IEEE International Conference on Robotics and Biomimetics, ROBIO 2019 ; Conference Date: 6 December 2019 Through 8 December 2019;  Conference Code:156997},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {IEEE Int. Conf. Robot. Biomimetics, ROBIO},
  abstract = {Loop closure is a crucial part in SLAM, especially for large and long-term scenes. Utilizing off-the-shelf networks' features in loop closure becomes a hot spot. However, what kind of network is more suitable in loop closure and how to use their features have not been well-studied. In this paper, DenseNet is introduced in this field according to its own characters. The features of DenseNet preserve both semantic information and structure details and outweigh other popular networks' features significantly. Based on this, a DenseNet feature-based framework, named Dense-Loop, is proposed to address the loop closure problem. Weighted Vector of Locally Aggregated Descriptor (WVLAD) method is used to encode the local descriptors as the final global descriptor, which could resist geometry structure and viewpoint changes. Furthermore, 4 max-pooling by channel and locality-sensitive hashing (LSH) are adopted to accelerate the search process. Extensive experiments are conducted on public datasets and the results demonstrate Dense-Loop could achieve state-of-the-art performance. © 2019 IEEE.},
  affiliation = {Tsinghua University, Department of Electronic Engineering, Beijing, China; Beihang University, School of Opto-electronics Engineering, Beijing, China; Tsinghua University, Department of Mechanical Engineering, Beijing, China},
  art_number = {8961714},
  author_keywords = {Convolutional Neural Network;  DenseNet;  Loop closure;  SLAM},
  document_type = {Conference Paper},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 51425501, 91648116},
  funding_text1 = {∗This work is partially supported by the National Natural Science Foundation of China under Grant 91648116 and 51425501.},
  isbn = {9781728163215},
  keywords = {Biomimetics;  Neural networks;  Semantics, Convolutional neural network;  DenseNet;  Geometry structure;  Locality sensitive hashing;  Loop closure;  Semantic information;  SLAM;  State-of-the-art performance, Robotics},
  language = {English},
  references = {Yu, C., Liu, Z., Liu, X., Xie, F., Yang, Y., Wei, Q., Fei, Q., Dsslam: A semantic visual slam towards dynamic environments (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1168-1174. , Oct; Xiang, Y., Fox, D., (2017) DA-RNN: Semantic Mapping with Data Associated Recurrent Neural Networks, , http://arxiv.org/abs/1703.03098, CoRR abs/1703. 03098; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Labbe, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745. , June; Mur-Artal, R., Tardós, J.D., Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Cummins, M., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Upcroft, B., Mcmanus, C., Churchill, W., Maddern, W., Lighting invariant urban street classification (2014) IEEE International Conference on Robotics and Automation (ICRA), pp. 1712-1718. , Hong Kong, China: IEEE; Garg, S., Suenderhauf, N., Milford, M., Don't look back: Robustifying place categorization for viewpoint-and condition-invariant place recognition (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 3645-3652. , May; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the 25th International Conference on Neural Information Processing Systems (NIPS), Ser. NIPS'12, pp. 1097-1105. , USA: Curran Associates Inc; Chen, Z., Lam, O., Jacobson, A., Milford, M., (2014) Convolutional Neural Network-based Place Recognition, , CoRR abs/1411. 1509; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4297-4304. , Sept; Arandjelovi, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., Netvlad: Cnn architecture for weakly supervised place recognition (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40 (6), pp. 1437-1451. , June; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Robotics: Science and Systems (RSS), Auditorium Antonianum, , Rome, July; Bai, D., Wang, C., Zhang, B., Yi, X., Tang, Y., Matchingrange-constrained real-time loop closure detection with cnns features (2016) Robotics and Biomimetics, 3 (1), p. 15. , Sep; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., Speeded-up robust features (surf) (2008) Computer Vision and Image Understanding, 110 (3), pp. 346-359; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., Orb: An efficient alternative to sift or surf (2011) Proceedings of the 2011 International Conference on Computer Vision (ICCV), Ser. ICCV '11, pp. 2564-2571. , Washington, DC, USA: IEEE Computer Society; Lopez-Antequera, M., Gomez-Ojeda, R., Petkov, N., Gonzalez-Jimenez, J., Appearance-invariant place recognition by discriminatively training a convolutional neural network (2017) Pattern Recognition Letters, 92, pp. 89-95; Hou, Y., Zhang, H., Zhou, S., Convolutional neural network-based image representation for visual loop closure detection (2015) 2015 IEEE International Conference on Information and Automation (ICInfA), pp. 2238-2245. , Aug; Ravichandran, D., Pantel, P., Hovy, E., Randomized algorithms and nlp: Using locality sensitive hash function for high speed noun clustering (2005) Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, Ser. ACL '05, pp. 622-629. , Stroudsburg, PA, USA: Association for Computational Linguistics; Jégou, H., Douze, M., Schmid, C., Pérez, P., Aggregating local descriptors into a compact image representation (2010) 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3304-3311. , June; Kalantidis, Y., Mellina, C., Osindero, S., Cross-dimensional weighting for aggregated deep convolutional features (2016) Computer Vision-ECCV 2016 Workshops, pp. 685-701. , G. Hua and H. Jégou, Eds. Cham: Springer International Publishing; Huang, G., Liu, Z., Maaten L, V., Weinberger, K.Q., Densely connected convolutional networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2261-2269. , July; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778. , June; Simonyan, K., Zisserman, A., (2014) Very Deep Convolutional Networks for Large-scale Image Recognition, , CoRR abs/1409. 1556; Chen, Y., Li, J., Xiao, H., Jin, X., Yan, S., Feng, J., (2017) Dual Path Networks, , CoRR abs/1707. 01629; Hu, J., Shen, L., Sun, G., (2017) Squeeze-and-excitation Networks, , CoRR abs/1709. 01507; Xie, S., Girshick, R., Dollar, P., Tu, Z., He, K., Aggregated residual transformations for deep neural networks (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5987-5995. , July; Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V., (2017) Learning Transferable Architectures for Scalable Image Recognition, , CoRR abs/1707. 07012; Iandola, F.N., Moskewicz, M.W., Ashraf, K., Han, S., Dally, W.J., Keutzer, K., (2016) Squeezenet: Alexnet-level Accuracy with 50x Fewer Parameters and 1mb Model Size, , CoRR abs/1602. 07360; Chollet, F., Xception: Deep learning with depthwise separable convolutions (2017) 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1800-1807. , July; Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z., (2015) Rethinking the Inception Architecture for Computer Vision, , CoRR abs/1512. 00567; Szegedy, C., Ioffe, S., Vanhoucke, V., Multi-scale orderless pooling of deep convolutional activation features (2017) Proceeding of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI), pp. 4278-4284},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079054757&doi=10.1109%2fROBIO49542.2019.8961714&partnerID=40&md5=51a7e255a4e9359036f6ef2d66e35930},
}

@article{ball-et-al:2013:9,
  author = {D. Ball and S. Heath and J. Wiles and G. Wyeth and P. Corke and M. Milford},
  journal = {Autonomous Robots},
  title = {OpenRatSLAM: An open source brain-based SLAM system},
  volume = {34},
  number = {3},
  pages = {149--176},
  doi = {10.1007/s10514-012-9317-9},
  note = {cited By 84},
  year = {2013},
  abbrev_source_title = {Auton Robots},
  abstract = {RatSLAM is a navigation system based on the neural processes underlying navigation in the rodent brain, capable of operating with low resolution monocular image data. Seminal experiments using RatSLAM include mapping an entire suburb with a web camera and a long term robot delivery trial. This paper describes OpenRatSLAM, an open-source version of RatSLAM with bindings to the Robot Operating System framework to leverage advantages such as robot and sensor abstraction, networking, data playback, and visualization. OpenRatSLAM comprises connected ROS nodes to represent RatSLAM's pose cells, experience map, and local view cells, as well as a fourth node that provides visual odometry estimates. The nodes are described with reference to the RatSLAM model and salient details of the ROS implementation such as topics, messages, parameters, class diagrams, sequence diagrams, and parameter tuning strategies. The performance of the system is demonstrated on three publicly available open-source datasets. © 2013 Springer Science+Business Media New York.},
  affiliation = {School of Electrical Engineering and Computer Science, Queensland University of Technology, Brisbane, Australia; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, Australia},
  author_keywords = {Appearance-based;  Brain-based;  Hippocampus;  Mapping;  Navigation;  Open-source;  OpenRatSLAM;  RatSLAM;  ROS;  SLAM},
  coden = {AUROF},
  correspondence_address1 = {Ball, D.; School of Electrical Engineering and Computer Science, , Brisbane, Australia; email: david.ball@qut.edu.au},
  document_type = {Article},
  funding_details = {Australian Research CouncilAustralian Research Council, DP0987078, DP1212775, TS0669699},
  funding_text1 = {Acknowledgments This work was supported in part by the Australian Research Council under a Discovery Project Grant DP0987078 to GW and JW, a Special Research Initiative on Thinking Systems TS0669699 to GW and JW and a Discovery Project Grant DP1212775 to MM. We would like to thank Samuel Brian for coding an iRat ground truth tracking system.},
  issn = {09295593},
  keywords = {Appearance based;  Brain-based;  Hippocampus;  Open-source;  OpenRatSLAM;  RatSLAM;  ROS;  SLAM, Data visualization;  Mapping;  Navigation;  Navigation systems;  Open systems;  Robots, Brain mapping},
  language = {English},
  references = {Andreasson, H., Duckett, T., Lilienthal, A., A minimalistic approach to appearance-based visual SLAM (2008) IEEE Transactions on Robotics, 24, pp. 1-11. , 10.1109/TRO.2008.2004642; Ball, D., (2009) RatSLAM, 1.0 Ed. Ratslam.itee.uq.edu.au, , The University of Queensland, Brisbane; Ball, D., Heath, S., Wyeth, G., Wiles, J., IRat: Intelligent rat animal technology (2010) Australasian Conference on Robotics and Automation, , Brisbane, Australia; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) Computer Vision - ECCV 2006, pp. 404-417; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) International Journal of Robotics Research, 27, pp. 647-665. , 10.1177/0278364908090961; Cummins, M., Newman, P., Highly scalable appearance-only SLAM - FAB-MAP 2.0 (2009) Robotics: Science and Systems, , Seattle, United States; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2010) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29, pp. 1052-1067; Hafting, T., Fyhn, M., Molden, S., Moser, M.-B., Moser, E.I., Microstructure of a spatial map in the entorhinal cortex (2005) Nature, 11, pp. 801-806. , 10.1038/nature03721; Heath, S., Cummings, A., Wiles, J., Ball, D., A rat in the browser (2011) Australasian Conference on Robotics and Automation, , Melbourne, Australia; Jacobson, A., Milford, M., Towards brain-based sensor fusion for navigating robots (2012) Presented at the Australasian Conference on Robotics and Automation, , Wellington, New Zealand; Knuth, D., A generalization of Dijkstra's algorithm (1977) Information Processing Letters, 6; Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to real-time visual mapping (2008) IEEE Transactions on Robotics, 24, pp. 1066-1077. , 10.1109/TRO.2008.2004832; Konolige, K., Agrawal, M., Bolles, R., Cowan, C., Fischler, M., Gerkey, B., (2008) Outdoor Mapping and Navigation Using Stereo Vision, pp. 179-190; Kyprou, S., (2009) Simple but Effective Personal Localisation Using Computer Vision, , Department of Computing, Imperial College London London; Labbe, M., Michaud, F., Memory management for real-time appearance-based loop closure detection (2011) Presented at the IEEE/RSJ International Conference on Intelligent Robots and Systems, , San Francisco, United States; Lowe, D.G., Object recognition from local scale-invariant features (1999) Presented at the Proceedings of the International Conference on Computer Vision, 2; Maddern, W., Milford, M., Wyeth, G., CAT-SLAM: Probabilistic localisation and mapping using a continuous appearance-based trajectory (2012) The International Journal of Robotics Research, 31, pp. 429-451. , 10.1177/0278364912438273; Milford, M.J., (2008) Robot Navigation from Nature: Simultaneous Localisation, Mapping, and Path Planning Based on Hippocampal Models, , 41 Springer Berlin 1138.93008; Milford, M., Wyeth, G., Mapping a suburb with a single camera using a biologically inspired SLAM system (2008) IEEE Transactions on Robotics, 24, pp. 1038-1053. , 10.1109/TRO.2008.2004520; Milford, M., Wyeth, G., Single camera vision-only SLAM on a suburban road network (2008) International Conference on Robotics and Automation, , Pasadena, United States; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired SLAM system (2010) International Journal of Robotics Research, 29, pp. 1131-1153. , 10.1177/0278364909340592; Milford, M.J., Wiles, J., Wyeth, G.F., Solving navigational uncertainty using grid cells on robots (2010) PLoS Computational Biology, 6; Milford, M., Schill, F., Corke, P., Mahony, R., Wyeth, G., Aerial SLAM with a single camera using visual expectation (2011) International Conference on Robotics and Automation, , Shanghai, China; Newman, P., Sibley, G., Smith, M., Cummins, M., Harrison, A., Mei, C., Posner, I., Reid, I., Navigating, recognizing and describing urban spaces with vision and lasers (2009) The International Journal of Robotics Research, 28, pp. 1406-1433. , 10.1177/0278364909341483; Quigley, M., Gerkey, B., Conley, K., Fausty, J., Footey, T., Leibs, J., ROS: An open-source Robot Operating System (2009) Presented at the IEEE International Conference on Robotics and Automation, , Kobe, Japan; Radish: The Robotics Data Set Repository, , http://radish.sourceforge.net/, [Online]; Samsonovich, A., McNaughton, B.L., Path integration and cognitive mapping in a continuous attractor neural network model (1997) The Journal of Neuroscience, 17, pp. 5900-5920; Sibley, G., Mei, C., Reid, I., Newman, P., Vast-scale outdoor navigation using adaptive relative bundle adjustment (2010) International Journal of Robotics Research, 29, pp. 958-980. , 10.1177/0278364910369268; Smith, D., Dodds, Z., Visual navigation: Image profiles for odometry and control (2009) Journal of Computing Sciences in Colleges, 24, pp. 168-179; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) The International Journal of Robotics Research, 28, pp. 595-599. , 10.1177/0278364909103911; Strasdat, H., Montiel, J.M., Davison, A.J., Scale drift-aware large scale monocular SLAM (2010) Robotics Science and Systems, , Spain: Zaragoza; Sunderhauf, N., Towards a robust back-end for pose graph SLAM (2012) IEEE International Conference on Robotics and Automation, , St Paul, United States; Sunderhauf, N., Protzel, P., Beyond RatSLAM: Improvements to a biologically inspired SLAM system (2010) IEEE International Conference on Emerging Technologies and Factory Automation, pp. 1-8. , Bilbao, Spain; Zhang, A.M., Kleeman, L., Robust appearance based visual route following for navigation in large-scale outdoor environments (2009) The International Journal of Robotics Research, 28, pp. 331-356. , 10.1177/0278364908098412; Zoccolan, D., Oertelt, N., Dicarlo, J.J., Cox, D.D., A rodent model for the study of invariant visual object recognition (2009) Proceedings of the National Academy of Sciences of the United States of America, 106, pp. 8748-8753. , 10.1073/pnas.0811583106},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877875441&doi=10.1007%2fs10514-012-9317-9&partnerID=40&md5=27be1e46694136eaac6e79c3d3f4bfc3},
}

@article{martini-et-al:2020:s20216002,
  author = {D. D. Martini and M. Gadd and P. Newman},
  journal = {Sensors (Switzerland)},
  title = {kRadar++: Coarse-to-fine FMCW scanning radar localisation},
  volume = {20},
  number = {21},
  pages = {1--23},
  doi = {10.3390/s20216002},
  note = {cited By 6},
  publisher = {MDPI AG},
  year = {2020},
  abbrev_source_title = {Sensors},
  abstract = {This paper presents a novel two-stage system which integrates topological localisation candidates from a radar-only place recognition system with precise pose estimation using spectral landmark-based techniques. We prove that the-recently available-seminal radar place recognition (RPR) and scan matching sub-systems are complementary in a style reminiscent of the mapping and localisation systems underpinning visual teach-and-repeat (VTR) systems which have been exhibited robustly in the last decade. Offline experiments are conducted on the most extensive radar-focused urban autonomy dataset available to the community with performance comparing favourably with and even rivalling alternative state-of-the-art radar localisation systems. Specifically, we show the long-term durability of the approach and of the sensing technology itself to autonomous navigation. We suggest a range of sensible methods of tuning the system, all of which are suitable for online operation. For both tuning regimes, we achieve, over the course of a month of localisation trials against a single static map, high recalls at high precision, and much reduced variance in erroneous metric pose estimation. As such, this work is a necessary first step towards a radar teach-and-repeat (RTR) system and the enablement of autonomy across extreme changes in appearance or inclement conditions. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  affiliation = {Department of Engineering Science, Oxford Robotics Institute, University of Oxford, Oxford, OX1 3PJ, United Kingdom},
  art_number = {6002},
  author_keywords = {Autonomous vehicles;  Deep learning;  Localisation;  Mapping;  Place recognition;  Radar},
  correspondence_address1 = {De Martini, D.; Department of Engineering Science, United Kingdom; email: daniele@robots.ox.ac.uk},
  document_type = {Article},
  funding_details = {University of YorkUniversity of York},
  funding_text1 = {Funding: This project is supported by the Assuring Autonomy International Programme, a partnership between Lloyd’s Register Foundation and the University of York and UK EPSRC Programme Grant EP/M019918/1.},
  funding_text2 = {This project is supported by the Assuring Autonomy International Programme, a partnership between Lloyd?s Register Foundation and the University of York and UK EPSRC Programme Grant EP/M019918/1. The authors would like to thank their partners at Navtech Radar Ltd.},
  issn = {14248220},
  keywords = {Air navigation;  Frequency modulation, Alternative state;  Autonomous navigation;  Inclement conditions;  Localisation Systems;  Long term durability;  Online operations;  Place recognition;  Sensing technology, Radar, article;  deep learning;  male;  recall;  telecommunication},
  language = {English},
  pubmed_id = {33105910},
  references = {Sibley, G., Mei, C., Reid, I., Newman, P., Vast-scale outdoor navigation using adaptive relative bundle adjustment (2010) Int. J. Robot. Res, 29, pp. 958-980; Cen, S.H., Newman, P., Precise ego-motion estimation with millimeter-wave radar under diverse and challenging conditions (2018) Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 1-8. , Brisbane, QLD, Australia, 21-25 May; Cen, S.H., Newman, P., Radar-only ego-motion estimation in difficult settings via graph matching (2019) Proceedings of the 2019 International Conference on Robotics and Automation (ICRA), pp. 298-304. , Montreal, QC, Canada, 20-24 May; Aldera, R., De Martini, D., Gadd, M., Newman, P., Fast Radar Motion Estimation with a Learnt Focus of Attention using Weak Supervision (2019) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 1190-1196. , Montreal, QC, Canada, 20-24 May; Aldera, R., De Martini, D., Gadd, M., Newman, P., What Could Go Wrong? Introspective Radar Odometry in Challenging Environments (2019) Proceedings of the IEEE Intelligent Transportation Systems Conference (ITSC), , Auckland, New Zealand, 27-30 October; Barnes, D., Weston, R., Posner, I., Masking by Moving: Learning Distraction-Free Radar Odometry from Pose Information (2019) Proceedings of the Conference on Robot Learning (CoRL), , Osaka, Japan, 30 October-1 November; Barnes, D., Posner, I., Under the Radar: Learning to Predict Robust Keypoints for Odometry Estimation and Metric Localisation in Radar (2020) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), , Paris, France, 31 May-31 August; Săftescu, S., Gadd, M., De Martini, D., Barnes, D., Newman, P., Kidnapped Radar: Topological Radar Localisation using Rotationally-Invariant Metric Learning (2020) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), , Paris, France, 31 May-31 August; Gadd, M., De Martini, D., Newman, P., Look Around You: Sequence-based Radar Place Recognition with Learned Rotational Invariance (2020) Proceedings of the IEEE/ION Position, Location and Navigation Symposium (PLANS), , Portland, OR, USA, 20-23 April; Tang, T.Y., De Martini, D., Barnes, D., Newman, P., RSL-Net: Localising in Satellite Images From a Radar on the Ground (2020) IEEE Robot. Autom. Lett, 5, pp. 1087-1094; Kim, G., Park, Y.S., Cho, Y., Jeong, J., Kim, A., Mulran: Multimodal range dataset for urban place recognition (2020) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), , Paris, France, 31 May-31 August; Hong, Z., Petillot, Y., Wang, S., (2020) RadarSLAM: Radar based Large-Scale SLAM in All Weathers, , arXiv arXiv:2005.02198; Weston, R., Cen, S., Newman, P., Posner, I., Probably Unknown: Deep Inverse Sensor Modelling Radar (2019) Proceedings of the 2019 International Conference on Robotics and Automation (ICRA), pp. 5446-5452. , Montreal, QC, Canada, 20-24 May; Williams, D., De Martini, D., Gadd, M., Marchegiani, L., Newman, P., Keep off the Grass: Permissible Driving Routes from Radar with Weak Audio Supervision (2020) Proceedings of the IEEE Intelligent Transportation Systems Conference (ITSC), , Rhodes, Greece, 20-23 September; Kaul, P., De Martini, D., Gadd, M., Newman, P., RSS-Net: Weakly-Supervised Multi-Class Semantic Segmentation with FMCW Radar (2020) Proceedings of the IEEE Intelligent Vehicles Symposium (IV), , Las Vegas, NV, USA, 19 October-13 November; Sattler, T., Havlena, M., Radenovic, F., Schindler, K., Pollefeys, M., Hyperpoints and fine vocabularies for large-scale location recognition (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2102-2110. , Santiago, Chile, 7-13 December; Furgale, P., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) J. Field Robot, 27, pp. 534-560; Krajník, T., Majer, F., Halodová, L., Vintr, T., Navigation without localisation: Reliable teach and repeat based on the convergence theorem (2018) Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1657-1664. , Madrid, Spain, 1-5 October; Sprunk, C., Tipaldi, G.D., Cherubini, A., Burgard, W., Lidar-based teach-and-repeat of mobile robot trajectories (2013) Proceedings of the 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3144-3149. , Tokyo, Japan, 3-7 November; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int. J. Robot. Res, 32, pp. 1645-1661; Sibley, G., Mei, C., Reid, I., Newman, P., Planes, trains and automobiles-Autonomy for the modern robot (2010) Proceedings of the 2010 IEEE International Conference on Robotics and Automation, pp. 285-292. , Anchorage, AK, USA, 3-7 May; Strasdat, H., Davison, A.J., Montiel, J.M., Konolige, K., Double window optimisation for constant time visual SLAM (2011) Proceedings of the 2011 International Conference on Computer Vision, pp. 2352-2359. , Barcelona, Spain, 6-13 November; Maddern, W., Pascoe, G., Newman, P., Leveraging experience for large-scale LIDAR localisation in changing cities (2015) Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 1684-1691. , Seattle, WA, USA, 26-30 May; Reina, G., Johnson, D., Underwood, J., Radar sensing for intelligent vehicles in urban environments (2015) Sensors, 15, pp. 14661-14678; Mielle, M., Magnusson, M., Lilienthal, A.J., A comparative analysis of radar and lidar sensing for localization and mapping (2019) Proceedings of the European Conference on Mobile Robotics (ECMR), , Prague, Czech Republic, 4-6 September; Vivet, D., Checchin, P., Chapuis, R., Localization and mapping using only a rotating FMCW radar sensor (2013) Sensors, 13, pp. 4527-4552; Kim, T., Park, T.H., Extended Kalman Filter (EKF) Design for Vehicle Position Tracking Using Reliability Function of Radar and Lidar (2020) Sensors, 20, p. 4126; Tang, T.Y., De Martini, D., Wu, S., Newman, P., (2020) Self-Supervised Localisation between Range Sensors and Overhead Imagery, , arXiv arXiv:2006.02108; Fariña, B., Toledo, J., Estevez, J.I., Acosta, L., Improving Robot Localization Using Doppler-Based Variable Sensor Covariance Calculation (2020) Sensors, 20, p. 2287; Middelberg, S., Sattler, T., Untzelmann, O., Kobbelt, L., Scalable 6-dof localization on mobile devices (2014) Proceedings of the 13th European Conference on Computer Vision, pp. 268-283. , Zurich, Switzerland, 6-12 September; Garcia-Fidalgo, E., Ortiz, A., Hierarchical place recognition for topological mapping (2017) IEEE Trans. Robot, 33, pp. 1061-1074; Sarlin, P.E., Cadena, C., Siegwart, R., Dymczyk, M., From coarse to fine: Robust hierarchical localization at large scale (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 12716-12725. , Long Beach, CA, USA, 15-21 June; Sarlin, P.E., Debraine, F., Dymczyk, M., Siegwart, R., Cadena, C., Leveraging deep visual descriptors for hierarchical efficient localization (2018) Proceedings of the 2nd Annual Conference on Robot Learning, , Zürich, Switzerland, 29-31 October; Chen, X., Läbe, T., Milioto, A., Röhling, T., Vysotska, O., Haag, A., Behley, J., Fraunhofer, F., OverlapNet: Loop Closing for LiDAR-based SLAM (2020) Proceedings of the Robotics: Science and Systems (RSS), , Freiburg, Germany, 12-16 July; Kim, G., Kim, A., Scan context: Egocentric spatial descriptor for place recognition within 3d point cloud map (2018) Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4802-4809. , Madrid, Spain, 1-5 October; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5297-5307. , Las Vegas, NV, USA, 27-30 June; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the International Conference on Learning Representations (ICLR), , San Diego, CA, USA, 7-9 May; Wang, T.H., Huang, H.J., Lin, J.T., Hu, C.W., Zeng, K.H., Sun, M., Omnidirectional CNN for Visual Place Recognition and Navigation (2018) Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 2341-2348. , Brisbane, Australia, 21-25 May; Zhang, R., Making Convolutional Networks Shift-Invariant Again (2019) Proceedings of the International Conference on Machine Learning (ICML), pp. 7324-7334. , Long Beach, CA, USA, 9-15 June; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815-823. , Boston, MA, USA, 7-12 June; Cieslewski, T., Choudhary, S., Scaramuzza, D., Data-efficient decentralized visual SLAM (2018) Proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 2466-2473. , Brisbane, Australia, 21-25 May; Bengio, Y., Practical recommendations for gradient-based training of deep architectures (2012) Neural Networks: Tricks of the Trade, pp. 437-478. , Springer: Berlin/Heidelberg, Germany; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , MIT Press: Cambridge, MA, USA; Leordeanu, M., Hebert, M., A spectral technique for correspondence problems using pairwise constraints (2005) Proceedings of the Tenth IEEE International Conference on Computer Vision (ICCV’05), 2, pp. 1482-1489. , 1, Beijing, China, 17-21 October; Horn, R.A., Johnson, C.R., (1990) Matrix Analysis, , Cambridge University Press: Cambridge, MA, USA; Nguyen Mau, T., Inoguchi, Y., Locality-Sensitive Hashing for Information Retrieval System on Multiple GPGPU Devices (2020) Appl. Sci, 10, p. 2539; Churchill, W., Newman, P., Practice Makes Perfect? Managing and Leveraging Visual Experiences for Lifelong Navigation (2012) Proceedings of the 2012 IEEE International Conference on Robotics and Automation, pp. 4525-4532. , Saint Paul, MA, USA, 14-18 May; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 Year, 1000 km: The Oxford RobotCar Dataset (2017) Int. J. Robot. Res, 36, pp. 3-15; Barnes, D., Gadd, M., Murcutt, P., Newman, P., Posner, I., The Oxford Radar RobotCar Dataset: A Radar Extension to the Oxford RobotCar Dataset (2020) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), , Paris, France, 31 May-31 August; Kyberd, S., Attias, J., Get, P., Murcutt, P., Prahacs, C., Towlson, M., Venn, S., De Martini, D., The Hulk: Design and Development of a Weather-proof Vehicle for Long-term Autonomy in Outdoor Environments (2019) Proceedings of the International Conference on Field and Service Robotics (FSR), , Tokyo, Japan, 29-31 August; Gadd, M., De Martini, D., Marchegiani, L., Kunze, L., Newman, P., Sense-Assess-eXplain (SAX): Building Trust in Autonomous Vehicles in Challenging Real-World Driving Scenarios Proceedings of the IEEE Intelligent Vehicles Symposium (IV), Workshop on Ensuring and Validating Safety for Automated Vehicles (EVSAV), , Las Vegas, NV, USA, 20 October 2020; MacTavish, K., Paton, M., Barfoot, T.D., Visual triage: A bag-of-words experience selector for long-term visual route following (2017) Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 2065-2072. , Singapore, 29 May-3 June; Dequaire, J., Tong, C.H., Churchill, W., Posner, I., Off the Beaten Track: Predicting Localisation Performance in Visual Teach and Repeat (2016) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), , Stockholm, Sweden, 16-21 May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094161841&doi=10.3390%2fs20216002&partnerID=40&md5=f4c1d9437039b382f0f7c7990f5edcdf},
}

@conference{filliat:2007:364080,
  author = {D. Filliat},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {A visual bag of words method for interactive qualitative localization and mapping},
  pages = {3921--3926},
  doi = {10.1109/ROBOT.2007.364080},
  note = {cited By 181; Conference of 2007 IEEE International Conference on Robotics and Automation, ICRA'07 ; Conference Date: 10 April 2007 Through 14 April 2007;  Conference Code:70639},
  address = {Rome},
  year = {2007},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Localization for low cost humanoid or animal-like personal robots has to rely on cheap sensors and has to be robust to user manipulations of the robot. We present a visual localization and map-learning system that relies on vision only and that is able to incrementally learn to recognize the different rooms of an apartment from any robot position. This system is inspired by visual categorization algorithms called bag of words methods that we modified to make fully incremental and to allow a user-interactive training. Our system is able to reliably recognize the room in which the robot is after a short training time and is stable for long term use. Empirical validation on a real robot and on an image database acquired in real environments are presented. © 2007 IEEE.},
  affiliation = {ENSTA, 32 boulevard Victor, 75015 Paris, France},
  art_number = {4209698},
  coden = {PIIAE},
  correspondence_address1 = {Filliat, D.; ENSTA, 32 boulevard Victor, 75015 Paris, France; email: david.filliat@ensta.fr},
  document_type = {Conference Paper},
  isbn = {1424406021; 9781424406029},
  issn = {10504729},
  keywords = {Algorithms;  Database systems;  Image analysis;  Learning systems;  Manipulators;  User interfaces, Image databases;  Interactive qualitative localization;  Real robots;  Visual localization, Anthropomorphic robots},
  language = {English},
  references = {Smith, R., Self, M., Cheeseman, P., Estimating uncertain spatial relationships in robotics (1988) Uncertainty in Artificial Intelligence, pp. 435-461. , Elsevier; Filliat, D., Meyer, J.A., Map-based navigation in mobile robots - I. a review of localisation strategies (2003) Journal of Cognitive Systems Research, 4 (4), pp. 243-282; Kuipers, B.J., Byun, Y.T., A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations (1991) Robotics and Autonomous Systems, 8, pp. 47-63; Hähnel, D., Burgard, W., Fox, D., Thrun, S., A highly efficient FastSLAM. algorithm for generating cyclic maps of large-scale environments from raw laser range measurements (2003) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Davison, A., Cid, Y.G., Kita, N., Real-time 3D SLAM, with wideangle vision (2004) Proc. IFAC Symposium on Intelligent Autonomous Vehicles, Lisbon, , July; Tapus, A., Siegwart, R., Incremental robot mapping with fingerprints of places (2005) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS'2005); Mozos, O.M., Stachniss, C., Burgard, W., Supervised learning of places from, range data using adaboost (2005) Proceedings of the International Conference on Robotics and Automation ICRA'05; Ulrich, I., Nourbakhsh, I., Appearance-based place recognition for topological localization (2000) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA-2000), 2, pp. 1023-1029. , IEEE Press; Rybski, P.E., Zacharias, F., Lett, J.-F., Masoud, O., Gini, M., Papanikolopoulos, N., Using visual features to build topological maps of indoor environments (2003) Proceedings of the 2003 IEEE International Conference on Robotics & Automation, pp. 850-855; Fox, D., Burgard, W., Thrun, S., Markov localization for mobile robots in dynamic environments (1999) Journal of Artificial Intelligence Research, 11; Kosecka, J., Yang, X., Global localization and relative positioning based on scale-invariant features (2004) Proceedings of the International Conference on Pattern Recognition, pp. 319-322; Csurka, G., Dance, C., Fan, L., Williamowski, J., Bray, C., Visual, categorization with bags of keypoints (2004) ECCV04 workshop on Statistical Learning in. Computer Vision, pp. 59-74; June, F., Triggs, B., Creating efficient codebooks for visual, recognition (2005) International Conference on Computer Vision; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. Journal of Computer Vision, 60 (2), pp. 91-110; Tong, S., Koller, D., Support vector machine active learning with, applications to text classification Journal of Machine Learning Research, 2, pp. 45-66. , November 200.1; Blum, A., Langley, P., Selection, of relevant features and examples in machine learning (1997) Artificial Intelligence, 97 (1-2), pp. 245-271; Mikolajczyk, K., Schmid, C., A performance evaluation of local descriptors (2003) International Conference on Computer Vision & Pattern Recognition, 2, pp. 257-263. , June; Gonzalez-Barbosa, J.-J., Lacroix, S., Rover localization in natural environments by indexing panoramic images (2002) Proceedings of the 2002 IEEE International Conference on Robotics and Automation, ICRA 2002, pp. 1365-1370; Baillie, J., Urbi: A universal language for robotic control (2004) International journal of Humanoid Robotics; Jogan, M., Leonardis, A., Robust localization using an omnidirectional appearance-based subspace model of environment (2003) Robotics and Autonomous Systems, 45 (1), pp. 51-72; Wolf, J., Burgard, W., Burkhardt, H., (2002) Using an image retrieval system for vision-based mobile robot localization, , Proc. of the International Conference on Image and Video Retrieval CIVR; Fox, D., Burgard, W., Thrun, S., Active markov localization for mobile robots (1998) Robotics and Autonomous Systems, 25, pp. 195-207; Porta, J.M., Terwijn, B., Krse, B., Efficient entropy-based action selection for appearance-based robot localization (2003) Proceedings of the International Conference on Robotics and Automation ICRA '03, pp. 2842-2847; Beis, J.S., Lowe, D.G., Indexing without invariants in 3d object recognition (1999) IEEE Transactions on Pattern Analysis and Machine Intelligence, 21 (10), pp. 1000-1015; Cauwenberghs, G., Poggio, T., Incremental, and decremental support vector machine learning (2000) NIPS, pp. 409-415},
  source = {Scopus},
  sponsors = {University of Illinois/Urbana, USA},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-36348999309&doi=10.1109%2fROBOT.2007.364080&partnerID=40&md5=c563ec3e9406b19170de8d8d5ea13710},
}

@conference{opdenbosch-et-al:2018:00114,
  author = {D. V. Opdenbosch and T. Aykut and M. Oelsch and N. Alt and E. Steinbach},
  journal = {Proceedings - 2018 IEEE Winter Conference on Applications of Computer Vision, WACV 2018},
  title = {Efficient Map Compression for Collaborative Visual SLAM},
  volume = {2018-January},
  pages = {992--1000},
  doi = {10.1109/WACV.2018.00114},
  note = {cited By 10; Conference of 18th IEEE Winter Conference on Applications of Computer Vision, WACV 2018 ; Conference Date: 12 March 2018 Through 15 March 2018;  Conference Code:136280},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {Proc. - IEEE Winter Conf. Appl. Comput. Vis., WACV},
  abstract = {Swarm robotics is receiving increasing interest, because the collaborative completion of tasks, such as the exploration of unknown environments, leads to improved performance and reduced effort. The ability to exchange map information is an essential requirement for collaborative exploration. When moving to large-scale environments, where the communication data rate between the swarm participants is typically limited, efficient compression algorithms and an approach for discarding less informative parts of the map are key for a successful long-term operation. In this paper, we present a novel compression approach for environment maps obtained from a visual SLAM system. We apply feature coding to the visual information to compress the map efficiently. We make use of a minimum spanning tree to connect all features that serve as observations of a single map point. Thereby, we can exploit inter-feature dependencies and obtain an optimal coding order. Additionally, we add a map sparsification step to keep only useful map points by solving a linear integer programming problem, which preserves the map points that exhibit both good compression properties and high observability. We evaluate the proposed method on a standard dataset and show that our approach outperforms state-of-the-art techniques. © 2018 IEEE.},
  affiliation = {Department of Media Technology, Technical University of Munich, Germany},
  document_type = {Conference Paper},
  isbn = {9781538648865},
  keywords = {Integer programming;  Robotics;  Swarm intelligence, Compression algorithms;  Compression approach;  Compression properties;  Exploration of unknown environments;  Inter-feature dependencies;  Linear integer programming;  Minimum spanning trees;  State-of-the-art techniques, Computer vision},
  language = {English},
  references = {Baroffio, L., Canclini, A., Cesana, M., Redondi, A., Tagliasacchi, M., Tubaro, S., Coding local and global binary visual features extracted from video sequences (2015) IEEE Transactions on Image Processing, 24 (11), pp. 3546-3560; Baroffio, L., Cesana, M., Redondi, A., Tagliasacchi, M., Tubaro, S., Coding visual features extracted from video sequences (2014) IEEE Transactions on Image Processing, 23 (5), pp. 2262-2276; Burri, M., Nikolic, J., Gohl, P., Schneider, T., Rehder, J., Omari, S., Achtelik, M.W., Siegwart, R.Y., The EuRoC micro aerial vehicle datasets (2016) The International Journal of Robotics Research, 35 (10), pp. 1-7; Cheng, W., Lin, W., Zhang, X., Goesele, M., Sun, M.T., A data-driven point cloud simplification framework for cityscale image-based localization (2017) IEEE Transactions on Image Processing, 26 (1), pp. 262-275; Cieslewski, T., Lynen, S., Dymczyk, M., Magnenat, S., Siegwart, R., Map API-Scalable decentralized map building for robots (2015) IEEE International Conference on Robotics and Automation (ICRA), pp. 6241-6247; Contreras, L., Mayol-Cuevas, W., Trajectory-driven point cloud compression techniques for visual SLAM (2015) IEEE International Conference on Intelligent Robots and Systems (IROS), pp. 133-140; Contreras, L., Mayol-Cuevas, W., O-POCO: Online point cloud compression mapping for visual odometry and SLAM (2017) IEEE International Conference on Robotics and Automation (ICRA), pp. 4509-4514; Duan, L.-Y., Chandrasekhar, V., Chen, J., Lin, J., Wang, Z., Huang, T., Member, S., Gao, W., Overview of the MPEG-CDVS standard (2016) IEEE Transactions on Image Processing, 25 (1), pp. 179-194; Dymczyk, M., Lynen, S., Bosse, M., Siegwart, R., Keep it brief: Scalable creation of compressed localization maps (2015) IEEE International Conference on Intelligent Robots and Systems (IROS), pp. 2536-2542; Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The GIST of maps-Summarizing experience for lifelong localization (2015) IEEE International Conference on Network Infrastructure and Digital Content, 2015, pp. 2767-2773. , June; Dymczyk, M., Schneider, T., Gilitschenski, I., Siegwart, R., Stumm, E., Erasing bad memories: Agent-side summarization for long-term mapping (2016) IEEE International Conference on Intelligent Robots and Systems (IROS), 2016, pp. 4572-4579. , Novem; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Direct monocular SLAM (2014) European Conference on Computer Vision (ECCV), 8690, pp. 834-849; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Huiskes, M.J., Lew, M.S., The MIR flickr retrieval evaluation (2008) ACM International Conference on Multimedia Information Retrieval, 4, pp. 39-43; Inc, G.O., (2017) Gurobi Optimizer Reference Manual; Karp, R.M., Reducibility among combinatorial problems (1972) Complexity of Computer Computations, pp. 85-103. , Miller R.E., Thatcher J.W., Bohlinger J.D. (eds); Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR), pp. 225-234; Kruskal, J.B., On the shortest spanning subtree of a graph and the traveling salesman problem (1956) Proceedings of the American Mathematical Society, 7 (1), p. 48; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Lynen, S., Sattler, T., Bosse, M., Hesch, J., Pollefeys, M., Siegwart, R., Get out of my lab: Large-scale, real-time visual-inertial localization (2015) Robotics: Science and Systems XI; Merzić, H., Stumm, E., Dymczyk, M., Siegwart, R., Gilitschenski, I., Map quality evaluation for visual localization (2017) IEEE International Conference of Robotics and Automation (ICRA), pp. 3200-3206; Mur-Artal, R., Tardos, J.D., ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras (2017) IEEE Transactions on Robotics, PP (99), pp. 1-8; Newcombe, R.A., Lovegrove, S.J., Davison, A.J., DTAM: Dense tracking and mapping in real-time (2011) IEEE International Conference on Computer Vision (ICCV), pp. 2320-2327; Opdenbosch, D.V., Oelsch, M., Garcea, A., Steinbach, E., A joint compression scheme for local binary feature descriptors and their corresponding bag-of-words representation (2017) IEEE Conference on Visual Communications and Image Processing (VCIP); Park, H.S., Wang, Y., Nurvitadhi, E., Hoe, J.C., Sheikh, Y., Chen, M., 3D point cloud reduction using mixed-integer quadratic programming (2013) IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 229-236; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) IEEE International Conference on Computer Vision (ICCV), pp. 2564-2571; Strasdat, H., Davison, A.J., Montiel, J.M., Konolige, K., Double window optimisation for constant time visual SLAM (2011) IEEE International Conference on Computer Vision (ICCV), pp. 2352-2359; Williams, B., Cummins, M., Neira, J., Newman, P., Reid, I., Tardós, J., A comparison of loop closing techniques in monocular SLAM (2009) Robotics and Autonomous Systems, 57 (12), pp. 1188-1197},
  source = {Scopus},
  sponsors = {Cognex; et al.; Google; Honeywell; IEEE Biometrics Council; IEEE Computer Society},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050991898&doi=10.1109%2fWACV.2018.00114&partnerID=40&md5=2bc76d07f1cc70ca5b98cb894bbb7c9c},
}

@article{derner-et-al:2021:103676,
  author = {E. Derner and C. Gomez and A. C. Hernandez and R. Barber and R. Babuška},
  journal = {Robotics and Autonomous Systems},
  title = {Change detection using weighted features for image-based localization},
  volume = {135},
  pages = {103676},
  doi = {10.1016/j.robot.2020.103676},
  note = {cited By 2},
  publisher = {Elsevier B.V.},
  year = {2021},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {Autonomous mobile robots are becoming increasingly important in many industrial and domestic environments. Dealing with unforeseen situations is a difficult problem that must be tackled to achieve long-term robot autonomy. In vision-based localization and navigation methods, one of the major issues is the scene dynamics. The autonomous operation of the robot may become unreliable if the changes occurring in dynamic environments are not detected and managed. Moving chairs, opening and closing doors or windows, replacing objects and other changes make many conventional methods fail. To deal with these challenges, we present a novel method for change detection based on weighted local visual features. The core idea of the algorithm is to distinguish the valuable information in stable regions of the scene from the potentially misleading information in the regions that are changing. We evaluate the change detection algorithm in a visual localization framework based on feature matching by performing a series of long-term localization experiments in various real-world environments. The results show that the change detection method yields an improvement in the localization accuracy, compared to the baseline method without change detection. In addition, an experimental evaluation on a public long-term localization data set with more than 10000 images reveals that the proposed method outperforms two alternative localization methods on images recorded several months after the initial mapping. © 2020 Elsevier B.V.},
  affiliation = {Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University in Prague, Czech Republic; Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Czech Republic; Robotics Lab, Department of Systems Engineering and Automation, Carlos III University of Madrid, Spain; Cognitive Robotics, Delft University of Technology, Netherlands},
  art_number = {103676},
  author_keywords = {Change detection;  Image-based localization;  Long-term autonomy;  Mobile robotics},
  coden = {RASOE},
  correspondence_address1 = {Derner, E.; Czech Institute of Informatics, Czech Republic; email: erik.derner@cvut.cz},
  document_type = {Article},
  funding_details = {České Vysoké Učení Technické v PrazeČeské Vysoké Učení Technické v Praze, ČVUT, RTI2018-095599-B-C21, SGS19/174/OHK3/3T/13},
  funding_text1 = {This work was supported by the European Regional Development Fund under the project Robotics for Industry 4.0 (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000470 ) and by the Grant Agency of the Czech Technical University in Prague , grant no. SGS19/174/OHK3/3T/13 . This research has also received funding from HEROITEA: Heterogeneous Intelligent Multi-Robot Team for Assistance of Elderly People ( RTI2018-095599-B-C21 ), funded by Spanish Ministerio de Economia y Competitividad , and the RoboCity2030 – DIH-CM project ( S2018/NMT-4331 , RoboCity2030 – Madrid Robotics Digital Innovation Hub, Spain ).},
  funding_text2 = {This work was supported by the European Regional Development Fund under the project Robotics for Industry 4.0 (reg. no. CZ.02.1.01/0.0/0.0/15_003/0000470) and by the Grant Agency of the Czech Technical University in Prague, grant no.SGS19/174/OHK3/3T/13. This research has also received funding from HEROITEA: Heterogeneous Intelligent Multi-Robot Team for Assistance of Elderly People (RTI2018-095599-B-C21), funded by Spanish Ministerio de Economia y Competitividad, and the RoboCity2030?DIH-CM project (S2018/NMT-4331,RoboCity2030 ? Madrid Robotics Digital Innovation Hub, Spain ).},
  issn = {09218890},
  keywords = {Agricultural robots;  Industrial robots, Autonomous Mobile Robot;  Autonomous operations;  Change detection algorithms;  Experimental evaluation;  Image-based localizations;  Misleading informations;  Real world environments;  Vision based localization, Feature extraction},
  language = {English},
  references = {Alterovitz, R., Koenig, S., Likhachev, M., Robot planning in the real world: Research challenges and opportunities (2016) AI Mag., 37 (2), pp. 76-84; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2015) IEEE Trans. Robot., 32 (1), pp. 1-19; Garcia-Fidalgo, E., Ortiz, A., Vision-based topological mapping and localization methods: A survey (2015) Robot. Auton. Syst., 64, pp. 1-20; Bore, N., Jensfelt, P., Folkesson, J., Multiple object detection, tracking and long-term dynamics learning in large 3D maps (2018), arXiv preprint; Kunze, L., Karaoguz, H., Young, J., Jovan, F., Folkesson, J., Jensfelt, P., Hawes, N., SOMA: A Framework for Understanding Change in Everyday Environments Using Semantic Object Maps (2018), AAAI; Hawes, N., Burbridge, C., Jovan, F., Kunze, L., Lacerda, B., Mudrova, L., Young, J., Kortner, T., The STRANDS project: Long-term autonomy in everyday environments (2017) IEEE Robot. Autom. Mag., 24 (3), pp. 146-156; Biswas, J., Veloso, M., Episodic non-Markov localization: Reasoning about short-term and long-term features (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3969-3974. , IEEE; Finman, R., Whelan, T., Kaess, M., Leonard, J.J., Toward lifelong object segmentation from change detection in dense RGB-D maps (2013) 2013 European Conference on Mobile Robots, pp. 178-185. , IEEE; Bescós, B., Fácil, J.M., Civera, J., Neira, J., DynSLAM: Tracking, mapping and inpainting in dynamic scenes (2018), arXiv preprint; Fehr, M., Furrer, F., Dryanovski, I., Sturm, J., Gilitschenski, I., Siegwart, R., Cadena, C., TSDF-based change detection for consistent long-term dense reconstruction and dynamic object discovery (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 5237-5244. , IEEE; Drews, P., Manso, L.J., da Silva Filho, S., Núñez, P., Improving change detection using Vertical Surface Normal Histograms and Gaussian Mixture Models in structured environments (2013) 2013 16th International Conference on Advanced Robotics (ICAR), pp. 1-7. , IEEE; Wellhausen, L., Dubé, R., Gawel, A., Siegwart, R., Cadena, C., Reliable real-time change detection and mapping for 3D LiDARs (2017) 2017 IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR), pp. 81-87. , IEEE; Boniardi, F., Caselitz, T., Kümmerle, R., Burgard, W., A pose graph-based localization system for long-term navigation in CAD floor plans (2019) Robot. Auton. Syst., 112, pp. 84-97; Andrade-Cetto, J., Sanfeliu, A., Concurrent map building and localization on indoor dynamic environments (2002) Int. J. Pattern Recognit. Artif. Intell., 16 (3), pp. 361-374; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1156-1163. , IEEE; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., Towards life-long visual localization using an efficient matching of binary sequences from images (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 6328-6335. , IEEE; Alcantarilla, P.F., Stent, S., Ros, G., Arroyo, R., Gherardi, R., Street-view change detection with deconvolutional networks (2018) Auton. Robots, 42 (7), pp. 1301-1322; Nobre, F., Heckman, C., Ozog, P., Wolcott, R.W., Walls, J.M., Online probabilistic change detection in feature-based maps (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 1-9. , IEEE; Neuman, B., Sofman, B., Stentz, A., Bagnell, J.A., Segmentation-based online change detection for mobile robots (2011) 2011 IEEE International Conference on Robotics and Automation, pp. 5427-5434. , IEEE; Naseer, T., Burgard, W., Stachniss, C., Robust visual localization across seasons (2018) IEEE Trans. Robot., 34 (2), pp. 289-302; Valgren, C., Lilienthal, A.J., SIFT, SURF and seasons: Long-term outdoor localization using local features (2007) 3rd European Conference on Mobile Robots, ECMR’07, pp. 253-258; Sun, L., Yan, Z., Zaganidis, A., Zhao, C., Duckett, T., Recurrent-OctoMap: Learning state-based map refinement for long-term semantic mapping with 3-D-Lidar data (2018) IEEE Robot. Autom. Lett., 3 (4), pp. 3749-3756; Chen, Z., Liu, L., Sa, I., Ge, Z., Chli, M., Learning context flexible attention model for long-term visual place recognition (2018) IEEE Robot. Autom. Lett., 3 (4), pp. 4015-4022; Johns, E., Yang, G.-Z., Feature co-occurrence maps: Appearance-based localisation throughout the day (2013) 2013 IEEE International Conference on Robotics and Automation, pp. 3212-3218. , IEEE; Johns, E., Yang, G.-Z., Generative methods for long-term place recognition in dynamic scenes (2014) Int. J. Comput. Vis., 106 (3), pp. 297-314; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2769-2776. , IEEE; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int. J. Robot. Res., 32 (14), pp. 1645-1661; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots (2008) 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3364-3369. , IEEE; Bacca, B., Salvi, J., Cufí, X., Appearance-based mapping and localization for mobile robots using a feature stability histogram (2011) Robot. Auton. Syst., 59 (10), pp. 840-857; Atkinson, R.C., Shiffrin, R.M., (1968) Human Memory: A Proposed System and its Control Processes, Psychology of Learning and Motivation, 2, pp. 89-195. , Spence K.W. Spence J.T. Academic Press; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (SURF) (2008) Comput. Vis. Image Underst., 110 (3), pp. 346-359; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis., 60 (2), pp. 91-110; Fischler, M.A., Bolles, R.C., Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography (1981) Commun. ACM, 24 (6), pp. 381-395; (2003), 2, pp. 1470-1477. , Sivic,. Zisserman, Video Google: A text retrieval approach to object matching in videos, in: Proceedings Ninth IEEE International Conference on Computer Vision; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree (2006) 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’06), Vol. 2, pp. 2161-2168. , IEEE; Bezdek, J.C., Pattern Recognition with Fuzzy Objective Function Algorithms (2013), Springer Science & Business Media; Torr, P., Zisserman, A., MLESAC: A new robust estimator with application to estimating image geometry (2000) Comput. Vis. Image Underst., 78 (1), pp. 138-156; Krajník, T., Fentanes, J.P., Mozos, O.M., Duckett, T., Ekekrantz, J., Hanheide, M., Long-term topological localization for service robots in dynamic environments using spectral maps (2014) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Cummins, M., Newman, P., FAB-Map: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665; Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Trans. Inform. Theory, 14 (3), pp. 462-467; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) 2011 International Conference on Computer Vision, pp. 2564-2571. , IEEE; Leutenegger, S., Chli, M., Siegwart, R.Y., BRISK: Binary robust invariant scalable keypoints (2011) 2011 International Conference on Computer Vision, pp. 2548-2555. , IEEE},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095916049&doi=10.1016%2fj.robot.2020.103676&partnerID=40&md5=83df5997d76e7d54030c7b47d281605f},
}

@conference{einhorn-gross:2013:6698849,
  author = {E. Einhorn and H.-M. Gross},
  journal = {2013 European Conference on Mobile Robots, ECMR 2013 - Conference Proceedings},
  title = {Generic 2D/3D SLAM with NDT maps for lifelong application},
  pages = {240--247},
  doi = {10.1109/ECMR.2013.6698849},
  note = {cited By 24; Conference of 2013 6th European Conference on Mobile Robots, ECMR 2013 ; Conference Date: 25 September 2013 Through 27 September 2013;  Conference Code:102443},
  publisher = {IEEE Computer Society},
  address = {Barcelona},
  year = {2013},
  abbrev_source_title = {Eur. Conf. Mob. Rob., ECMR - Conf. Proc.},
  abstract = {In this paper, we present a new, generic approach for Simultaneous Localization and Mapping (SLAM). First of all, we propose an abstraction of the underlying sensor data using Normal Distribution Transform (NDT) maps that are suitable for making our approach independent from the used sensor and the dimension of the generated maps. We present some modifications for the original NDT mapping to handle free-space measurements explicitly and to enable its usage in dynamic environments with moving obstacles and persons. In the second part of this paper we describe our graph-based SLAM approach that is designed for lifelong usage. Therefore, the memory and computational complexity is limited by pruning the pose graph in an appropriate way. © 2013 IEEE.},
  affiliation = {Ilmenau University of Technology, Germany},
  art_number = {6698849},
  document_type = {Conference Paper},
  isbn = {9781479902637},
  keywords = {Mathematical techniques;  Mobile robots;  Normal distribution;  Sensors, Dynamic environments;  Free space measurements;  Generic approach;  Graph-based;  Moving obstacles;  Sensor data;  Simultaneous localization and mapping;  SLAM approach, Robotics},
  language = {English},
  references = {Biber, P., Straßer, W., The normal distributions transform: A new approach to laser scan matching (2003) Proceedings of the IEEE International Conference on Intelligent Robots and Systems (IROS), pp. 2743-2748; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (6), pp. 1052-1067. , DOI 10.1109/TPAMI.2007.1049; Einhorn, E., Schroter, C., Gross, H.-M., Finding the adequate resolution for grid mapping - Cell sizes locally adapting on-the-fly (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 1843-1848; Einhorn, E., Schroter, C., Gross, H., Can't take my eye off you: Attention-driven monocular obstacle detection and 3D mapping (2010) Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on, pp. 816-821; Fairfield, N., Kantor, G., Wettergreen, D., Real-time SLAM with octree evidence grids for exploration in underwater tunnels (2007) Journal of Field Robotics; Fox, D., KLD-sampling: Adaptive particle filters (2001) Advances in Neural Information Processing Systems 14, , MIT Press; Frese, U., Wagner, R., Röfer, T., A SLAM overview from a users perspective (2010) KI - Künstliche Intelligenz, 24, pp. 191-198; Frisken, S., Perry, R., Simple and efficient traversal methods for quadtrees and octrees (2003) Journal of Graphics Tools, 7; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46. , DOI 10.1109/TRO.2006.889486; Gross, H.-M., Böhme, H.-J., Schröter, C., Müller, S., König, A., Einhorn, E., Martin, C., Bley, A., Interactive shopping guide robots in everyday use - Final implementation and experiences from long-term field trials (2009) Proc. IEEE/RJS International Conference on Intelligent Robots and Systems (IROS), pp. 2005-2012; Gross, H.-M., Schröter, C., Müller, S., Volkhardt, M., Einhorn, E., Bley, A., Martin, C., Merten, M., Progress in developing a socially assistive mobile home robot companion for the elderly with mild cognitive impairment (2011) Proc. IEEE/RJS Int. Conf. on Intelligent Robots and Systems (IROS), pp. 2430-2437; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J., Dellaert, F., ISAM2: Incremental smoothing and mapping with fluid relinearization and incremental variable reordering (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 3281-3288; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) Robotics, IEEE Transactions on, 24 (6), pp. 1365-1378; Kennedy, J., Eberhart, R., Particle swarm optimization (1995) Neural Networks, 1995. Proceedings., IEEE International Conference on, 4, pp. 1942-1948; Kretzschmar, H., Grisetti, G., Stachniss, C., Lifelong map learning for graph-based SLAM in static environments (2010) KI - Knstliche Intelligenz, 24, pp. 199-206; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 3607-3613; Magnusson, M., (2009) The Three-dimensional Normal-Distributions Transform an Efficient Representation for Registration, , PhD thesis, Ö rebro University; Moravec, H., (1996) Robot Spatial Perception by Stereoscopic Vision and 3d Evidence Grids, , Technical report, Robotics Institute, Pittsburgh, PA; Payeur, P., Hebert, P., Laurendeau, D., Gosselin, C., Probabilistic octree modeling of a 3-d dynamic environment (1997) Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA); Rusinkiewicz, S., Levoy, M., Efficient variants of the icp algorithm (2001) Int. Conf. on 3-D Digital Imaging and Modeling; Saarinen, J., Andreasson, H., Stoyanov, T., Luhtala, J., Lilienthal, A., Normal distributions transform occupancy maps: Application to large-scale online 3D mapping (2013) Robotics and Automation (ICRA), 2013 IEEE International Conference on, pp. 2225-2230; Schröter, C., Gross, H.-M., A sensor-independent approach to RBPF SLAM - Map Match SLAM applied to visual mapping (2008) IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 2078-2083; Stoyanov, T., Magnusson, M., Almqvist, H., Lilienthal, A., On the accuracy of the 3d normal distributions transform as a tool for spatial representation (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 4080-4085. , IEEE; Stoyanov, T., Magnusson, M., Lilienthal, A.J., (2012) Point Set Registration Through Minimization of the L2 Distance Between 3d-ndt Models; Stricker, R., Muller, S., Einhorn, E., Schroter, C., Volkhardt, M., Debes, K., Gross, H., Interactive mobile robots guiding visitors in a university building (2012) ROMAN, 2012 IEEE, pp. 695-700; Sünderhauf, N., Protzel, P., Switchable constraints for robust pose graph SLAM (2012) IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 1879-1884; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics (Intelligent Robotics and Autonomous Agents), , The MIT Press; Wurm, K.M., Hornung, A., Bennewitz, M., Stachniss, C., Burgard, W., OctoMap: A probabilistic, flexible, and compact 3D map representation for robotic systems (2010) Proc. of the ICRA 2010},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893247078&doi=10.1109%2fECMR.2013.6698849&partnerID=40&md5=ebfcb5183c974f0abbc693fc7dea0282},
}

@article{einhorn-gross:2015:008,
  author = {E. Einhorn and H.-M. Gross},
  journal = {Robotics and Autonomous Systems},
  title = {Generic NDT mapping in dynamic environments and its application for lifelong SLAM},
  volume = {69},
  number = {1},
  pages = {28--39},
  doi = {10.1016/j.robot.2014.08.008},
  note = {cited By 31},
  publisher = {Elsevier B.V.},
  year = {2015},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {In this paper, we present a new, generic approach for Simultaneous Localization and Mapping (SLAM). First of all, we propose an abstraction of the underlying sensor data using Normal Distribution Transform (NDT) maps that are suitable for making our approach independent from the used sensor and the dimension of the generated maps. We present several modifications for the original NDT mapping to handle free-space measurements explicitly. We additionally describe a method to detect and handle dynamic objects such as moving persons. This enables the usage of the proposed approach in highly dynamic environments. In the second part of this paper we describe our graph-based SLAM approach that is designed for lifelong usage. Therefore, the memory and computational complexity is limited by pruning the pose graph in an appropriate way. © 2014 Elsevier B.V. All rights reserved.},
  affiliation = {Ilmenau University of Technology, Germany},
  author_keywords = {2D and 3D mapping;  Detection and tracking of moving objects;  Lifelong sLAM;  Map registration;  Mobile robots;  Normal Distribution Transform;  Occupancy mapping},
  coden = {RASOE},
  correspondence_address1 = {Einhorn, E.; Ilmenau University of TechnologyGermany; email: Erik.Einhorn@tu-ilmenau.de},
  document_type = {Article},
  funding_details = {Bundesministerium für Bildung und ForschungBundesministerium für Bildung und Forschung, BMBF, 16SV6133},
  funding_text1 = {This work has received funding from the German Federal Ministry of Education and Research as part of the ROREAS project under grant agreement no. 16SV6133 .},
  issn = {09218890},
  keywords = {Graphic methods;  Mobile robots;  Normal distribution;  Object detection;  Robotics, 3-D mapping;  Detection and tracking of moving objects;  Dynamic environments;  Free space measurements;  Generic approach;  ITS applications;  Lifelong SLAM;  Simultaneous localization and mapping, Mapping},
  language = {English},
  references = {Schröter, C., Gross, H.-M., A sensor-independent approach to RBPF SLAM-Map Match SLAM applied to visual mapping (2008) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, , IROS; Frese, U., Wagner, R., Röfer, T., A SLAM overview from a user's perspective (2010) Künstliche Intel., 24, pp. 191-198; Fox, D., KLD-sampling: Adaptive particle filters (2001) Advances in Neural Information Processing Systems, 14. , MIT Press; Gross, H.-M., Böhme, H.-J., Schröter, C., Müller, S., König, A., Einhorn, E., Martin, C., Bley, A., Interactive shopping guide robots in everyday use - Final implementation and experiences from long-term field trials (2009) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 2005-2012; Gross, H.-M., Schröter, C., Müller, S., Volkhardt, M., Einhorn, E., Bley, A., Martin, C., Merten, M., Progress in developing a socially assistive mobile home robot companion for the elderly with mild cognitive impairment (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 2430-2437; Einhorn, E., Schröter, C., Gross, H., Can't take my eye off you: Attention-driven monocular obstacle detection and 3D mapping (2010) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 816-821; Saarinen, J., Andreasson, H., Stoyanov, T., Luhtala, J., Lilienthal, A., Normal distributions transform occupancy maps: Application to large-scale online 3D mapping (2013) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA, pp. 2225-2230; Saarinen, J.P., Andreasson, H., Stoyanov, T., Lilienthal, A.J., 3D normal distributions transform occupancy maps: An efficient representation for mapping in dynamic environments (2013) Internat. J. Robot. Res., 32 (14), pp. 1627-1644; Stoyanov, T., Magnusson, M., Lilienthal, A., Point set registration through minimization of the L2 distance between 3D-NDT models (2012) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA, pp. 5196-5201; Sünderhauf, N., Protzel, P., Switchable constraints for robust pose graph SLAM (2012) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 1879-1884; Kretzschmar, H., Grisetti, G., Stachniss, C., Lifelong map learning for graph-based SLAM in static environments (2010) Künstliche Intel., 24, pp. 199-206; Wang, C.-C., Thorpe, C., Thrun, S., Online simultaneous localization and mapping with detection and tracking of moving objects: Theory and results from a ground vehicle in crowded urban areas (2003) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Trans. Pattern Anal. Mach. Intell., 29 (6), pp. 1052-1067; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Raoi-Blackwellized particle filters (2007) IEEE Trans. Robotics, 23 (1), pp. 34-46; Kaess, M., Ranganathan, A., Dellaert, F., iSAM: Incremental smoothing and mapping (2008) IEEE Trans. Robotics, 24 (6), pp. 1365-1378; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J., Dellaert, F., iSAM2: Incremental smoothing and mapping with fluid relinearization and incremental variable reordering (2011) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA, pp. 3281-3288; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA, pp. 3607-3613; Moravec, H., (1996) Robot Spatial Perception by Stereoscopic Vision and 3d Evidence Grids, , Technical Report, Robotics Institute, Pittsburgh, PA; Payeur, P., Hebert, P., Laurendeau, D., Gosselin, C., Probabilistic octree modeling of a 3-d dynamic environment (1997) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA; Fairfield, N., Kantor, G., Wettergreen, D., Real-time SLAM with octree evidence grids for exploration in underwater tunnels (2007) J. Field Robotics; Wurm, K.M., Hornung, A., Bennewitz, M., Stachniss, C., Burgard, W., OctoMap: A probabilistic, flexible, and compact 3D map representation for robotic systems (2010) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA; Einhorn, E., Schroter, C., Gross, H.-M., Finding the adequate resolution for grid mapping-cell sizes locally adapting on-the-fly (2011) International Conference on Robotics and Automation, ICRA, pp. 1843-1848; Biber, P., Straßer, W., The normal distributions transform: A new approach to laser scan matching (2003) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, pp. 2743-2748; Magnusson, M., (2009) The Three-dimensional Normal-distributions Transform - An Efficient Representation for Registration, , (Ph.D. thesis), Örebro University; Stoyanov, T., Magnusson, M., Almqvist, H., Lilienthal, A., On the accuracy of the 3d normal distributions transform as a tool for spatial representation (2011) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA, IEEE, pp. 4080-4085; Frisken, S., Perry, R., Simple and efficient traversal methods for quadtrees and octrees (2003) J. Graphics Tools, 7; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics (Intelligent Robotics and Autonomous Agents), , The MIT Press; Olesen, S.M., Lyder, S., Kraft, D., Krüger, N., Jessen, J., Real-time extraction of surface patches with associated uncertainties by means of kinect cameras (2012) J. Real-Time Image Process., pp. 1-14; Park, J.-H., Shin, Y.-D., Bae, J.-H., Baeg, M.-H., Spatial uncertainty model for visual features using a kinect sensor (2012) Sensors, 12 (7), pp. 8640-8662; Gindele, T., Brechtel, S., Schröder, J., Dillmann, R., Bayesian occupancy grid filter for dynamic environments using prior map knowledge (2009) IEEE Intelligent Vehicles Symposium, pp. 669-676; Brechtel, S., Gindele, T., Dillmann, R., Recursive importance sampling for efficient grid-based occupancy filtering in dynamic environments (2010) Proceedings of the IEEE International Conference on Robotics and Automation, ICRA, pp. 3932-3938; Kennedy, J., Eberhart, R., Particle swarm optimization (1995) Proc. IEEE Internat. Conf. Neural Netw., 4, pp. 1942-1948; Rusinkiewicz, S., Levoy, M., Efficient variants of the icp algorithm (2001) International Conference on 3-D Digital Imaging and Modeling; Stricker, R., Müller, S., Einhorn, E., Schröter, C., Volkhardt, M., Debes, K., Gross, H., Interactive mobile robots guiding visitors in a university building (2012) RO-MAN, IEEE, pp. 695-700},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933278205&doi=10.1016%2fj.robot.2014.08.008&partnerID=40&md5=ca03d93bc7621dee02a22f8ac3cab631},
}

@article{boniardi-et-al:2019:003,
  author = {F. Boniardi and T. Caselitz and R. Kümmerle and W. Burgard},
  journal = {Robotics and Autonomous Systems},
  title = {A pose graph-based localization system for long-term navigation in CAD floor plans},
  volume = {112},
  pages = {84--97},
  doi = {10.1016/j.robot.2018.11.003},
  note = {cited By 21},
  publisher = {Elsevier B.V.},
  year = {2019},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {Accurate localization is an essential technology for flexible automation. Industrial applications require mobile platforms to be precisely localized in complex environments, often subject to continuous changes and reconfiguration. Most of the approaches use precomputed maps both for localization and for interfacing robots with workers and operators. This results in increased deployment time and costs as mapping experts are required to setup the robotic systems in factory facilities. Moreover, such maps need to be updated whenever significant changes in the environment occur in order to be usable within commanding tools. To overcome those limitations, in this work we present a robust and highly accurate method for long-term LiDAR-based indoor localization that uses CAD-based architectural floor plans. The system leverages a combination of graph-based mapping techniques and Bayes filtering to maintain a sparse and up-to-date globally consistent map that represents the latest configuration of the environment. This map is aligned to the CAD drawing using prior constraints and is exploited for relative localization, thus allowing the robot to estimate its current pose with respect to the global reference frame of the floor plan. Furthermore, the map helps in limiting the disturbances caused by structures and clutter not represented in the drawing. Several long-term experiments in changing real-world environments show that our system outperforms common state-of-the-art localization methods in terms of accuracy and robustness while remaining memory and computationally efficient. © 2018 Elsevier B.V.},
  affiliation = {University of Freiburg, Georges-Köhler-Allee 80, Freiburg i. Br., 79110, Germany; KUKA, Zugspitzstraße 140, Augsburg, 86165, Germany},
  author_keywords = {Adaptive systems;  Localization;  Mapping;  Mobile robotics;  SLAM},
  coden = {RASOE},
  correspondence_address1 = {Boniardi, F.; University of Freiburg, Georges-Köhler-Allee 80, Germany; email: boniardi@informatik.uni-freiburg.de},
  document_type = {Article},
  funding_details = {European Research CouncilEuropean Research Council},
  funding_text1 = {The following is the Supplementary material related to this article. Video S1 . Federico Boniardi studied Mathematics at the University of Milan and Artificial Intelligence at the University of Edinburgh. Currently, he is a Ph.D. student at the Laboratory for Autonomous Intelligent Systems of the University of Freiburg headed by Wolfram Burgard. His research interests include robot localization, mapping and navigation. Tim Caselitz is a Ph.D. student at the Laboratory for Autonomous Intelligent Systems of the University of Freiburg, which is headed by professor Wolfram Burgard. He received his diploma degree in Electrical Engineering and Information Technology from Karlsruhe Institute of Technology in 2013. His research is focused on robotic perception using camera, RGB-D, and LiDAR sensors. Rainer Kümmerle is currently working as Product Owner at KUKA. He received his Ph.D. degree from the University of Freiburg in April 2013 where he was working in the Laboratory for Autonomous Intelligent Systems of the University of Freiburg headed by Wolfram Burgard. His research interests lie in the areas of navigation, mapping, and localization. Wolfram Burgard is a professor for computer science at the University of Freiburg, Germany where he heads the Laboratory for Autonomous Intelligent Systems. He received his Ph.D. degree in computer science from the University of Bonn in 1991. His areas of interest lie in artificial intelligence and mobile robots. In the past, Wolfram Burgard and his group developed several innovative probabilistic techniques for robot navigation and control. They cover different aspects such as localization, map building, path-planning, and exploration. For his work, Wolfram Burgard received several best paper awards from outstanding national and international conferences. In 2009, Wolfram Burgard received the Gottfried Wilhelm Leibniz Prize, the most prestigious German research award. In 2010 he received the Advanced Grant of the European Research Council. Wolfram Burgard is the spokesperson of the Cluster of Excellence BrainLinksBrainTools and President of the IEEE Robotics and Automation Society.},
  issn = {09218890},
  keywords = {Adaptive systems;  Computer aided design;  Floors;  Mapping;  Robotics;  Robots, Architectural floor plans;  Computationally efficient;  Localization;  Long-term experiments;  Mobile robotic;  Real world environments;  Relative localization;  SLAM, Indoor positioning systems},
  language = {English},
  references = {Elfes, A., Sonar-based real-world mapping and navigation (1987) IEEE J. Robot. Autom., 3 (3), pp. 249-265; (2015), pp. 1-54. , IEEE Standard for Robot Map Data Representation for Navigation, IEEE Standard 1873-2015; Bowen-Biggs, L., Dazo, S., Zhang, Y., Hubers, A., Rueben, M., Sowell, R., Smart, W.D., Grimm, C.M., A method for establishing correspondences between hand-drawn and sensor-generated maps (2016) Proc. of the International Conference on Social Robotics (ICSR); Boniardi, F., Caselitz, T., Kümmerle, R., Burgard, W., Robust LiDAR-based localization in architectural floor plans (2017) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Kümmerle, R., Steder, B., Dornhege, C., Kleiner, A., Grisetti, G., Burgard, W., Large scale graph-based SLAM using aerial images as prior information (2011) Auton. Robots, 30 (1), pp. 25-39; Smith, R., Self, M., Cheeseman, P., Estimating uncertain spatial relationships in robotics (1990) Autonomous Robot Vehicles, pp. 167-193. , Springer; Leonard, J.J., Durrant-Whyte, H.F., Mobile robot localization by tracking geometric beacons (1991) IEEE Trans. Robot. Autom., 7 (3), pp. 376-382; Burgard, W., Fox, D., Hennig, D., Schmidt, T., Estimating the absolute position of a mobile robot using position probability grids (1996) Proc.of the National Conference on Artificial Intelligence; Fox, D., Thrun, S., Burgard, W., Dellaert, F., Particle filters for mobile robot localization (2001) Sequential Monte Carlo Methods in Practice, pp. 401-428. , Springer; Fox, D., Burgard, W., Thrun, S., Markov localization for mobile robots in dynamic environments (1999) J. Artificial Intelligence Res., 11, pp. 391-427; Yilmaz, S., Kayir, H.E., Kaleci, B., Parlaktuna, O., Mobile robot localization via outlier rejection in sonar range sensor data (2011) Proc. of the International Conference on Electrical and Electronics Engineering (ELECO); Sprunk, C., Tipaldi, G.D., Cherubini, A., Burgard, W., Lidar-based teach-and-repeat of mobile robot trajectories (2013) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Mazuran, M., Boniardi, F., Burgard, W., Tipaldi, G.D., Relative topometric localization in globally inconsistent maps (2018) Robotics Research, pp. 435-451. , Springer; Schiotka, A., Suger, B., Burgard, W., Robot localization with sparse scan-based maps (2017) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Auton. Robots, 4 (4), pp. 333-349; Siddiqi, S., Sukhatme, G.S., Howard, A., Experiments in Monte-Carlo localization using wifi signal strength (2003) Proc. of the International Conference on Advanced Robotics (ICAR); Ito, S., Endres, F., Kuderer, M., Tipaldi, G.D., Stachniss, C., Burgard, W., W-RGBD-D: floor-plan-based indoor global localization using a depth camera and WiFi (2014) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Winterhalter, W., Fleckenstein, F., Steder, B., Spinello, L., Burgard, W., Accurate indoor localization for RGB-D smartphones and tablets given 2D floor plans (2015) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Hile, H., Borriello, G., Positioning and orientation in indoor environments using camera phones (2008) IEEE Comput. Graphics Appl. (CG&A), 28 (4); Luo, R.C., Lin, Y.-C., Kao, C.-C., Autonomous mobile robot navigation and localization based on floor plan map information and sensory fusion approach (2010) Proc. of the IEEE Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI); Mendez, O., Hadfield, S., Pugeault, N., Bowden, R., SeDAR-semantic detection and ranging: humans can localise without lidar, can robots? arXiv preprint ; Meyer-Delius, D., Hess, J., Grisetti, G., Burgard, W., Temporary maps for robust localization in semi-static environments (2010) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Meyer-Delius, D., Beinhofer, M., Burgard, W., Occupancy grid models for robot mapping in changing environments (2012) Proc. of the AAAI Conference on Artificial Intelligence; Tipaldi, G.D., Meyer-Delius, D., Burgard, W., Lifelong localization in changing environments (2013) Int. J. Robot. Res., 32 (14), pp. 1662-1678; Krajník, T., Fentanes, J.P., Santos, J.M., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) Trans. Robot., 33 (4), pp. 964-977; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Proc. of Robotics: Science and Systems; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments (2012) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong feature-based mapping in semi-static environments (2016) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Van De Ven, J., Ramos, F., Tipaldi, G.D., An integrated probabilistic model for scan-matching, moving object detection and motion estimation (2010) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Wang, D.Z., Posner, I., Newman, P., Model-free detection and tracking of dynamic objects with 2D lidar (2015) Int. J. Robot. Res., 34 (7), pp. 1039-1063; Röwekämper, J., Sprunk, C., Tipaldi, G.D., Stachniss, C., Pfaff, P., Burgard, W., On the position accuracy of mobile robot localization based on particle filters combined with scan matching (2012) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Walcott, A.N., Long-term Robot Mapping in Dynamic Environments (2011), (Ph.D. thesis) Massachusetts Institute of Technology Cambridge, MA, USA; Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based SLAM (2010) Intell. Transp. Syst. Mag., 2 (4), pp. 31-43; Segal, A., Haehnel, D., Thrun, S., Generalized-ICP (2009) Proc. of Robotics: Science and Systems; Vysotska, O., Stachniss, C., Exploiting building information from publicly available maps in graph-based SLAM (2016) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Thrun, S., Burgard, W., Fox, D., Probabilistic Robotics (2005), MIT Press; Hart, J.C., Sphere tracing: a geometric method for the antialiased ray tracing of implicit surfaces (1996) Vis. Comput., 12 (10), pp. 527-545; Donnelly, W., Per-pixel displacement mapping with distance functions (2005) GPU gems, 2 (22), p. 3; Kretzschmar, H., Stachniss, C., Information-Theoretic pose graph compression for Laser-based SLAM (2012) Int. J. Robot. Res., 31, pp. 1219-1230; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph slam (2013) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Huang, G., Kaess, M., Leonard, J.J., Consistent sparsification for graph optimization (2013) Proc. of the IEEE European Conference on Mobile Robots (ECMR); Mazuran, M., Burgard, W., Tipaldi, G.D., Nonlinear factor recovery for long-term SLAM (2016) Int. J. Robot. Res., 35 (1-3), pp. 50-72; Kümmerle, R., Ruhnke, M., Steder, B., Stachniss, C., Burgard, W., Autonomous robot navigation in highly populated pedestrian zones (2015) J. Field Robot., 32 (4), pp. 565-589; Olson, E.B., Robust and Efficient Robotic Mapping (2008), (Ph.D. thesis) Massachusetts Institute of Technology Cambridge, MA, USA; Lu, F., Milios, E., Robot pose estimation in unknown environments by matching 2d range scans (1997) J. Intell. Robot. Syst., 18 (3), pp. 249-275; Hopcroft, J., Tarjan, R., Algorithm 447: efficient algorithms for graph manipulation (1973) Commun. ACM, 16 (6), pp. 372-378; Agarwal, P., Tipaldi, G.D., Spinello, L., Stachniss, C., Burgard, W., Robust map optimization using dynamic covariance scaling (2013) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Sünderhauf, N., Protzel, P., Switchable constraints for robust pose graph SLAM (2012) Proc. of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., g2o: A general framework for graph optimization (2011) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Censi, A., An accurate closed-form estimate of icp's covariance (2007) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Censi, A., An ICP variant using a point-to-line metric (2008) Proc. of the IEEE International Conference on Robotics and Automation (ICRA); Scharr, H., Optimale Operatoren in der digitalen Bildverarbeitung (2000), (Ph.D. thesis) Universität Heidelberg},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057496266&doi=10.1016%2fj.robot.2018.11.003&partnerID=40&md5=4257f50d17c298217cd42b7eacaabf4a},
}

@article{cao-et-al:2021:2962416,
  author = {F. Cao and F. Yan and S. Wang and Y. Zhuang and W. Wang},
  journal = {IEEE Transactions on Industrial Electronics},
  title = {Season-Invariant and Viewpoint-Tolerant LiDAR Place Recognition in GPS-Denied Environments},
  volume = {68},
  number = {1},
  pages = {563--74},
  doi = {10.1109/TIE.2019.2962416},
  note = {LiDAR-based methods;sequence-based temporal consistency check;efficient place recognition;three-dimensional point clouds;compact cylindrical image model;severe seasonal changes;long-term robust localization;novel LiDAR-based place recognition system;structural changes;illumination changes;article studies light detection;existing place recognition methods;viewpoint shifts;GPS-denied environments;viewpoint-tolerant LiDAR place recognition;season-invariant;},
  address = {USA},
  year = {2021},
  abstract = {Place recognition remains a challenging problem under various perceptual conditions, e.g., all weather, times of day, seasons, and viewpoint shifts. Different from most of the existing place recognition methods using pure vision, this article studies light detection and ranging (LiDAR) based approaches. Point clouds have some benefits for place recognition since they do not suffer from illumination changes. On the other hand, they are dramatically affected by structural changes from different viewpoints or across seasons. In this article, a novel LiDAR-based place recognition system is proposed to achieve long-term robust localization, even under severe seasonal changes and viewpoint shifts. To improve the efficiency, a compact cylindrical image model is designed to convert three-dimensional point clouds to two-dimensional images representing the prominent geometric relationships of scenes. The contexts (buildings, trees, road structures, etc.) of scenes are utilized for efficient place recognition. A sequence-based temporal consistency check is also introduced for postverification. Extensive real experiments on three datasets (Oxford RobotCar [1], NCLT [2], and DUT-AS) show that the proposed system outperforms both state-of-the-art visual and LiDAR-based methods, verifying its robust performance in challenging scenarios.},
  copyright = {Copyright 2020, The Institution of Engineering and Technology},
  issn = {0278-0046},
  keywords = {feature extraction;image classification;image sensors;mobile robots;object recognition;optical radar;robot vision;SLAM (robots);visual databases;},
  language = {English},
  url = {http://dx.doi.org/10.1109/TIE.2019.2962416},
}

@article{cao-et-al:2018:2815956,
  author = {F. Cao and Y. Zhuang and H. Zhang and W. Wang},
  journal = {IEEE Sensors Journal},
  title = {Robust Place Recognition and Loop Closing in Laser-Based SLAM for UGVs in Urban Environments},
  volume = {18},
  number = {10},
  pages = {4242--4252},
  doi = {10.1109/JSEN.2018.2815956},
  note = {cited By 25},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Sensors J.},
  abstract = {Robust place recognition plays a key role for the long-term autonomy of unmanned ground vehicles (UGVs) working in indoor or outdoor environments. Although most of the state-of-the-art that approaches for place recognition are vision-based, visual sensors lack adaptability in environments with poor or dynamically changing illumination. In this paper, a 3-D-laser-based place recognition algorithm is proposed to accomplish loop closure detection for simultaneous localization and mapping. An image model named bearing angle (BA) is adopted to convert 3-D laser points to 2-D images, and then ORB features extracted from BA images are utilized to perform scene matching. Since the computational cost for matching a query BA image with all the BA images in a database is too high to meet the requirement of performing real-time place recognition, a visual bag of words approach is used to improve search efficiency. Furthermore, a speed normalization algorithm and a 3-D geometry-based verification algorithm are proposed to complete the proposed place recognition algorithm. Experiments were conducted on two self-developed UGV platforms to verify the performance of the proposed method. © 2001-2012 IEEE.},
  affiliation = {School of Control Science and Engineering, Dalian University of Technology, Dalian, 116024, China; Department of Computing Science, University of Alberta, Edmonton, AB  T6G 2R3, Canada; Research Center of Information and Control, Dalian University of Technology, Dalian, 116024, China},
  author_keywords = {Laser scanning;  place recognition;  simultaneous localization and mapping (SLAM);  unmanned ground vehicles (UGVs)},
  correspondence_address1 = {Zhuang, Y.; School of Control Science and Engineering, China; email: zhuang@dlut.edu.cn},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61375088, U1608253},
  funding_text1 = {Manuscript received February 7, 2018; accepted March 10, 2018. Date of publication March 15, 2018; date of current version April 23, 2018. This work was supported by the National Natural Science Foundation of China under Grant 61375088 and Grant U1608253. The associate editor coordinating the review of this paper and approving it for publication was Dr. Rosario Morello. (Corresponding author: Yan Zhuang.) F. Cao and Y. Zhuang are with the School of Control Science and Engineering, Dalian University of Technology, Dalian 116024, China (e-mail: cfkybfq@mail.dlut.edu.cn; zhuang@dlut.edu.cn).},
  issn = {1530437X},
  keywords = {Ground vehicles;  Image enhancement;  Indoor positioning systems;  Query processing;  Robotics, Computational costs;  Laser scanning;  Normalization algorithms;  Place recognition;  Simultaneous localization and mapping;  State-of-the-art approach;  Unmanned ground vehicles;  Verification algorithms, Intelligent vehicle highway systems},
  language = {English},
  references = {Silva, O.D., Mann, G.K.I., Gosine, R.G., An ultrasonic and vision-based relative positioning sensor for multirobot localization (2015) IEEE Sensors J., 15 (3), pp. 1716-1726. , Mar; Aliakbarpour, H., Ferreira, J.F., Palaniappan, K., Seetharaman, G., Dias, J., Prasath, V.B.S., A probabilistic fusion framework for 3-D reconstruction using heterogeneous sensors (2017) IEEE Sensors J., 17 (9), pp. 2640-2641. , May; Zhao, L., Gao, N., Huang, B., Wang, Q., Zhou, J., A novel terrainaided navigation algorithm combined with the TERCOM algorithm and particle filter (2015) IEEE J. Sensors, 15 (2), pp. 1124-1131. , Feb; Lowry, S., Visual place recognition: A survey (2016) IEEE Trans. Robot., 32 (1), pp. 1-19. , Feb; Cummins, M., Newman, P., Probabilistic appearance based navigation and loop closing (2007) Proc. IEEE Int. Conf. Robot. Autom., Roma, Italy, pp. 2042-2048. , Apr; Churchill, W., Newman, P., Experience-based navigation for longterm localisation (2013) Int. J. Robot. Res., 32 (14), pp. 1645-1661. , Dec; Sünderhauf, N., Shirazi, S., Upcroft, B., Milford, M., Dayoub, F., On the performance of ConvNet features for place recognition (2015) Proc. IEEE Int. Conf. Intell. Robots Syst. (IROS), pp. 4297-4304. , Hamburg, Germany, Sep./Oct; Arandjelović, R., Gronat, P., Pajdla, T., Sivic, J., Torii, A., NetVLAD: CNN architecture for weakly supervised place recognition (2017) Proc. IEEE Int. Conf. Comput. Vis. Pattern Recognit., Las Vegas, NV, USA, pp. 5297-5307. , Jun; Hou, Y., Zhang, H., Zhou, S., BoCNF: Efficient image matching with bag of ConvNet features for scalable and robust visual place recognition (2017) Auto. Robots, pp. 1-17. , Nov; Muhammad, N., Lacroix, S., Loop closure detection using smallsized signatures from 3D LIDAR data (2011) Proc. IEEE Int. Symp. Safety, Secur., Rescue Robot., Kyoto, Japan, pp. 333-338. , Nov; Magnusson, M., Andreasson, H., Lilienthal, A.J., Nuchter, A., Appearance-based loop detection from 3D laser data using the normal distributions transform (2009) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), Kobe, Japan, pp. 23-28. , May; He, L., Wang, X., Zhang, H., M2DP: A novel 3D point cloud descriptor and its application in loop closure detection (2016) Proc. IEEE Int. Conf. Intell. Robots Syst. (IROS), Daejeon, South Korea, pp. 231-237. , Oct; Steder, B., Grisetti, G., Burgard, W., Robust place recognition for 3D range data based on point features (2010) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), Anchorage, AK, USA, pp. 1400-1405. , May; Zhuang, Y., Jiang, N., Hu, H., Yan, F., 3-D-laser-based scene measurement and place recognition for mobile robots in dynamic indoor environments (2013) IEEE Trans. Instrum. Meas., 62 (2), pp. 438-450. , Feb; Scaramuzza, D., Harati, A., Siegwart, R., Extrinsic self calibration of a camera and a 3D laser range finder from natural scenes (2007) Proc. IEEE Int. Conf. Intell. Robots Syst. (IROS), pp. 4164-4169. , San Diego, CA, USA, Oct./Nov; Rublee, E., Rabaud, V., Bradski, G., Konolige, K., ORB: An efficient alternative to SIFT or SURF (2011) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Barcelona, Spain, pp. 2564-2571. , Nov; Newman, P., Ho, K., SLAM-Loop closing with visually salient features (2005) Proc. IEEE Int. Conf. Robot. Autom., Barcelona, Spain, pp. 635-642. , Apr; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) Int. J. Robot. Res., 30 (9), pp. 1100-1123. , Jun; Galvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Mur-Artal, R., Montiel, J.M.M., Tardós, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Trans. Robot., 31 (5), pp. 1147-1163. , Oct; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.A., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Trans. Robot., 24 (5), pp. 1027-1037. , Oct; Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) Int. J. Comput. Vis., 42 (3), pp. 145-175; Ho, K.L., Newman, P., Loop closure detection in SLAM by combining visual and spatial appearance (2006) Robot. Auto. Syst., 54 (9), pp. 740-749; Cadena, C., Galvez-López, D., Tardos, J.D., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Trans. Robot., 28 (4), pp. 871-885. , Aug; Korrapati, H., Mezouar, Y., Multi-resolution map building and loop closure with omnidirectional images (2016) Auto. Robots, 41 (4), pp. 967-987. , Mar; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Autom., Saint Paul, MN, USA, pp. 1643-1649. , May; Siam, S.M., Zhang, H., Fast-SeqSLAM: A fast appearance based place recognition algorithm (2017) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 5702-5708. , Singapore, May/Jun; Granström, K., Callmer, J., Nieto, J., Ramos, F., Learning to detect loop closure from range data (2009) Proc. IEEE Int. Conf. Robot. Autom., Kobe, Japan, pp. 15-22. , May; Rusu, R.B., Bradski, G., Thibaux, R., Hsu, J., Fast 3D recognition and pose using the viewpoint feature histogram (2010) Proc. IEEE Int. Conf. Intell. Robots Syst. (IROS), Taipei, Taiwan, pp. 2155-2162. , Oct; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003) Proc. IEEE Int. Conf. Comput. Vis., Nice, France, pp. 1470-1477. , Oct; Kümmerle, R., Grisetti, G., Konolige, K., Burgard, W., Strasdat, H., G2o: A general framework for graph optimization (2011) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), Shanghai, China, pp. 3607-3613. , May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043760869&doi=10.1109%2fJSEN.2018.2815956&partnerID=40&md5=8c1971c247d620b88401adc5e757a97f},
}

@article{dayoub-et-al:2011:013,
  author = {F. Dayoub and G. Cielniak and T. Duckett},
  journal = {Robotics and Autonomous Systems},
  title = {Long-term experiments with an adaptive spherical view representation for navigation in changing environments},
  volume = {59},
  number = {5},
  pages = {285--295},
  doi = {10.1016/j.robot.2011.02.013},
  note = {cited By 44},
  year = {2011},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {Real-world environments such as houses and offices change over time, meaning that a mobile robot's map will become out of date. In this work, we introduce a method to update the reference views in a hybrid metric-topological map so that a mobile robot can continue to localize itself in a changing environment. The updating mechanism, based on the multi-store model of human memory, incorporates a spherical metric representation of the observed visual features for each node in the map, which enables the robot to estimate its heading and navigate using multi-view geometry, as well as representing the local 3D geometry of the environment. A series of experiments demonstrate the persistence performance of the proposed system in real changing environments, including analysis of the long-term stability. © 2011 Elsevier B.V. All rights reserved.},
  affiliation = {School of Computer Science, University of Lincoln, LN6 7TS Lincoln, United Kingdom},
  author_keywords = {Mobile robot navigation;  Omnidirectional vision;  Persistent mapping},
  coden = {RASOE},
  correspondence_address1 = {Dayoub, F.; School of Computer Science, , LN6 7TS Lincoln, United Kingdom; email: fdayoub@lincoln.ac.uk},
  document_type = {Article},
  issn = {09218890},
  keywords = {3D geometry;  Changing environment;  Human memory;  Long term stability;  Long-term experiments;  Mobile Robot Navigation;  Multi-view geometry;  Omnidirectional vision;  Persistent mapping;  Real world environments;  Topological map;  Visual feature, Experiments;  Mobile robots;  Multi agent systems;  Navigation systems;  Three dimensional, Navigation},
  language = {English},
  references = {Elinas, P., Sim, R., Little, J.J., σ SLAM: Stereo vision SLAM using the rao-blackwellised particle filter and a novel mixture proposal distribution (2006) Proceedings - IEEE International Conference on Robotics and Automation, 2006, pp. 1564-1570. , DOI 10.1109/ROBOT.2006.1641930, 1641930, Proceedings 2006 IEEE International Conference on Robotics and Automation, ICRA 2006; Se, S., Lowe, D., Little, J., Mobile robot localization and mapping with uncertainty using scale-invariant visual landmarks (2002) The International Journal of Robotics Research, 21 (8), p. 735; Zivkovic, Z., Booij, O., Krose, B., From images to rooms (2007) Robotics and Autonomous Systems, 55 (5), pp. 411-418. , DOI 10.1016/j.robot.2006.12.005, PII S0921889006002053, From Sensors to Human Spatial Concepts; Valgren, C., Lilienthal, A., Duckett, T., Incremental topological mapping using omnidirectional vision (2006) Proc. IEEE International Conference on Intelligent Robots and Systems, , IROS; Kuipers, B., Byun, Y.T., A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations (1993) Toward Learning Robots, pp. 47-63. , MIT Press Cambridge, Massachusetts; Wang, C.-W., Thorpe, C., Thrun, S., Online SLAM with detection and tracking of moving objects: Theory and results from a ground vehicle in crowded urban areas (2003) Proc. IEEE International Conference on Robotics and Automation, pp. 842-849. , ICRA, Taipei, Taiwan; Bibby, C., Reid, I., Simultaneous localisation and mapping in dynamic environments (SLAMIDE) with reversible data association (2007) Proc. Robotics: Science and Systems, , RSS, Atlanta, GA, USA; Yamauchi, B., Beer, R., Spatial learning for navigation in dynamic environments (1996) IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 26 (3), pp. 496-505. , PII S1083441996032463; Andrade-Cetto, J., Sanfeliu, A., Concurrent map building and localization on indoor dynamic environments (2002) International Journal of Pattern Recognition and Artificial Intelligence, 16 (3), pp. 361-374. , DOI 10.1142/S0218001402001745; Ulrich, I., Nourbakhsh, I., Appearance-based place recognition for topological localization (2000) Proc. IEEE International Conference on Robotics and Automation, , ICRA; Gross, H., Koenig, A., Schroeter, C., Boehme, H., Omnivision-based probabilistic self-localization for a mobile shopping assistant continued (2003) Proc. IEEE International Conference on Intelligent Robots and Systems, , IROS; Vlassis, N., Terwijn, B., Krose, B., Auxiliary particle filter robot localization from high-dimensional sensor observations (2002) Proc. IEEE International Conference on Robotics and Automation, , ICRA; Menegatti, E., Zoccarato, M., Pagello, E., Ishiguro, H., Image-based Monte Carlo localisation with omnidirectional images (2004) Robotics and Autonomous Systems, 48 (1), pp. 17-30; Lowe, D., Object recognition from local scale-invariant features (1999) Proc. IEEE International Conference on Computer Vision, , ICCV; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) Proc. European Conference on Computer Vision, , ECCV; Matas, J., Chum, O., Urban, M., Pajdla, T., Robust wide-baseline stereo from maximally stable extremal regions (2004) Image and Vision Computing, 22 (10), pp. 761-767; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003) Proc. IEEE International Conference on Computer Vision, , ICCV; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree (2006) Proc. IEEE Conference on Computer Vision and Pattern Recognition, , CVPR; Fraundorfer, C., Engels, F., Nister, D., Topological mapping, localization and navigation using image collections (2007) Proc. IEEE International Conference on Intelligent Robots and Systems, , IROS; Goedeme, T., Nuttin, M., Tuytelaars, T., Van Gool, L., Omnidirectional vision based topological navigation (2007) International Journal of Computer Vision, 74 (3), pp. 219-236. , DOI 10.1007/s11263-006-0025-9, Vision and Robotics - Joint with The International Journal of Robotics Research; Guerrero, J.J., Murillo, A.C., Sagues, C., Localization and matching using the planar trifocal tensor with bearing-only data (2008) IEEE Transactions on Robotics, 24 (2), pp. 494-501. , DOI 10.1109/TRO.2008.918043; Booij, O., Terwijn, B., Zivkovic, Z., Krose, B., Navigation using an appearance based topological map Proc. of the IEEE International Conference on Robotics and Automation, , ICRA; Ila, V., Porta, J.M., Andrade-Cetto, J., Information-based compact pose SLAM IEEE Transactions on Robotics; Atkinson, R., Shiffrin, R., Human memory: A proposed system and its control processes (1968) The Psychology of Learning and Motivation, 2, pp. 89-195. , K.W. Spence and J.T. Spence (Eds.); Akihiko, T., Atsushi, I., Multiple view geometry for spherical cameras (2005) IEIC Technical Report (Institute of Electronics, Information and Communication Engineers), 105, pp. 29-34; Scaramuzza, D., Martinelli, A., Siegwart, R., A toolbox for easily calibrating omnidirectional cameras Proc. of the IEEE International Conference on Intelligent Systems, , IROS06, Beijing, China; Longuet-Higgins, H.C., A computer algorithm for reconstructing a scene from two projections (1981) Nature, 293, pp. 133-135; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Communications of the ACM, 24, pp. 381-395; Kosecka, J., Li, F., Yang, X., Global localization and relative positioning based on scale-invariant keypoints (2005) Robotics and Autonomous Systems, 52 (1), pp. 27-38. , DOI 10.1016/j.robot.2005.03.008, PII S092188900500062X, Advances in Robot Vision; Hartley, R., Zisserman, A., (2004) Multiple View Geometry in Computer Vision, , 2nd edition Cambridge University Press; Horn, B.K., Relative orientation (1990) International Journal of Computer Vision, 4 (1), pp. 59-78; Kang, S.B., Szeliski, R., 3-D scene data recovery using omnidirectional multibaseline stereo (1997) International Journal of Computer Vision, 25 (2), pp. 167-183; Bandari, E., Goldstein, N., Nesnas, I., Bajracharya, M., Riacs, N., Efficient calculation of absolute orientation with outlier rejection BMVA Syposium on Spatiotemporal Image Processing; Ess, A., Leibe, B., Schindler, K., Van Gool, L., A mobile vision system for robust multi-person tracking (2008) Proc. IEEE Conference on Computer Vision and Pattern Recognition, , CVPR, Anchorage, USA; Julier, S.J., Uhlmann, J.K., A new extension of the kalman filter to nonlinear systems (1997) Int. Symp. Aerospace/Defense Sensing, Simul. and Controls, 3, p. 26; Uhlmann, J.K., Simultaneous Map Building and Localization for Real Time Applications, , Transfer Thesis, Univ. Oxford, Oxford, UK; Howard, A., Laser-stabilized Odometry (Lododriver), , http://robotics.usc.edu/~ahoward; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots Proc. IEEE International Conference on Intelligent Robots and Systems (IROS), pp. 3364-3369. , Nice, France, 22-26 Sept 2008; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46. , DOI 10.1109/TRO.2006.889486},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955627458&doi=10.1016%2fj.robot.2011.02.013&partnerID=40&md5=bcc7120431a0b179391f91aa1f14307c},
}

@article{han-et-al:2018:3,
  author = {F. Han and H. Wang and G. Huang and H. Zhang},
  journal = {Autonomous Robots},
  title = {Sequence-based sparse optimization methods for long-term loop closure detection in visual SLAM},
  volume = {42},
  number = {7},
  pages = {1323--1335},
  doi = {10.1007/s10514-018-9736-3},
  note = {cited By 15},
  publisher = {Springer New York LLC},
  year = {2018},
  abbrev_source_title = {Auton. Robots},
  abstract = {Loop closure detection is one of the most important module in Simultaneously Localization and Mapping (SLAM) because it enables to find the global topology among different places. A loop closure is detected when the current place is recognized to match the previous visited places. When the SLAM is executed throughout a long-term period, there will be additional challenges for the loop closure detection. The illumination, weather, and vegetation conditions can often change significantly during the life-long SLAM, resulting in the critical strong perceptual aliasing and appearance variation problems in loop closure detection. In order to address this problem, we propose a new Robust Multimodal Sequence-based (ROMS) method for robust loop closure detection in long-term visual SLAM. A sequence of images is used as the representation of places in our ROMS method, where each image in the sequence is encoded by multiple feature modalites so that different places can be recognized discriminatively. We formulate the robust place recognition problem as a convex optimization problem with structured sparsity regularization due to the fact that only a small set of template places can match the query place. In addition, we also develop a new algorithm to solve the formulated optimization problem efficiently, which guarantees to converge to the global optima theoretically. Our ROMS method is evaluated through extensive experiments on three large-scale benchmark datasets, which record scenes ranging from different times of the day, months, and seasons. Experimental results demonstrate that our ROMS method outperforms the existing loop closure detection methods in long-term SLAM, and achieves the state-of-the-art performance. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
  affiliation = {Department of Computer Science, Colorado School of Mines, Golden, CO  80401, United States; Department of Mechanical Engineering, University of Delaware, Newark, DE  19716, United States},
  author_keywords = {Long-term autonomy;  Long-term place recognition;  Loop closure detection;  Visual SLAM},
  coden = {AUROF},
  correspondence_address1 = {Han, F.; Department of Computer Science, United States; email: fhan@mines.edu},
  document_type = {Article},
  funding_details = {National Science FoundationNational Science Foundation, NSF, 1423591, 1652943},
  funding_text1 = {Acknowledgements This work was partially supported by ARO W911NF-17-1-0447, NSF-IIS 1423591, and NSF-IIS 1652943.},
  issn = {09295593},
  keywords = {Artificial intelligence;  Robots, Convex optimization problems;  Localization and mappings;  Long-term autonomy;  Loop closure;  Place recognition;  State-of-the-art performance;  Structured sparsities;  Visual SLAM, Convex optimization},
  language = {English},
  references = {Angeli, A., Filliat, D., Doncieux, S., Meyer, J.A., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Transactions on Robotics, 24 (5), pp. 1027-1037; Arroyo, R., Alcantarilla, P., Bergasa, L., Romera, E., (2015) Towards Life-Long Visual Localization Using an Efficient Matching of Binary Sequences from Images, , In IEEE international conference on robotics and automation; Badino, H., Huber, D., Kanade, T., Real-time topometric localization (2012) IEEE International Conference on Robotics and Automation; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., Leonard, J.J., Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age (2016) IEEE Transactions on Robotics, 32 (6), pp. 1309-1332; Cadena, C., Gálvez-López, D., Tardós, J.D., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Transactions on Robotics, 28 (4), pp. 871-885; Chen, C., Wang, H., Appearance-based topological Bayesian inference for loop-closing detection in a cross-country environment (2006) The International Journal of Robotics Research, 25 (10), pp. 953-983; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Cummins, M., Newman, P., Highly scalable appearance-only SLAM-FAB-MAP 2.0 (2009) In Robotics: Science and Systems; Estrada, C., Neira, J., Tardós, J.D., Hierarchical SLAM: Real-time accurate mapping of large environments (2005) IEEE Transactions on Robotics, 21 (4), pp. 588-596; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., (2010) FAB-MAP + Ratslam: Appearance-Based SLAM for Multiple Times of Day, , In IEEE international conference on robotics and automation; Glover, A., Maddern, W., Warren, M., Reid, S., Milford, M., Wyeth, G., (2012) Openfabmap: An Open Source Toolbox for Appearance-Based Loop Closure Detection, , In IEEE international conference on robotics and automation; Goldberg, S.B., Maimone, M.W., Matthies, L., (2002) Stereo Vision and Rover Navigation Software for Planetary Exploration, , In IEEE aerospace conference proceedings; Gorodnitsky, I.F., Rao, B.D., Sparse signal reconstruction from limited data using FOCUSS: A re-weighted minimum norm algorithm (1997) IEEE Transactions on Signal Processing, 45 (3), pp. 600-616; Gutmann, J.S., Konolige, K., Incremental mapping of large cyclic environments (1999) In IEEE International Symposium on Computational Intelligence in Robotics and Automation; Han, F., Wang, H., Zhang, H., (2018) Learning of Integrated Holism-Landmark Representations for Long-Term Loop Closure Detection, , In AAAI conference on artificial intelligence; Han, F., Yang, X., Deng, Y., Rentschler, M., Yang, D., Zhang, H., SRAL: Shared representative appearance learning for long-term visual place recognition (2017) IEEE Robotics and Automation Letters, 2 (2), pp. 1172-1179; Hansen, P., Browning, B., Visual place recognition using HMM sequence matching (2014) IEEE/RSJ International Conference on Intelligent Robots and Systems; Henry, P., Krainin, M., Herbst, E., Ren, X., Fox, D., RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments (2012) The International Journal of Robotics Research, 31 (5), pp. 647-663; Ho, K.L., Newman, P., Detecting loop closure with scene sequences (2007) International Journal of Computer Vision, 74 (3), pp. 261-286; Johns, E., Yang, G.Z., (2013) Feature Co-Occurrence Maps: Appearance-Based Localisation throughout the Day, , In IEEE international conference on robotics and automation; Kleiner, A., Dornhege, C., Real-time localization and elevation mapping within urban search and rescue scenarios (2007) Journal of Field Robotics, 24 (8-9), pp. 723-745; Klopschitz, M., Zach, C., Irschara, A., Schmalstieg, D., Generalized detection and merging of loop closures for video sequences (2008) 3D Data Processing, Visualization, and Transmission; Labbe, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745; Labbe, M., Michaud, F., Online global loop closure detection for large-scale multi-session graph-based SLAM (2014) In IEEE/RSJ International Conference on Intelligent Robots and Systems; Latif, Y., Cadena, C., Neira, J., Robust loop closing over time for pose graph SLAM (2013) The International Journal of Robotics Research, 32, pp. 1611-1626; Latif, Y., Huang, G., Leonard, J., Neira, J., An online sparsity-cognizant loop-closure algorithm for visual navigation (2014) Robotics: Science and Systems Conference; Li, S., Huang, H., Zhang, Y., Liu, M., An efficient multi-scale convolutional neural network for image classification based on PCA (2015) International Conference on Real-Time Computing and Robotics; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32, p. 1; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) In IEEE International Conference on Robotics and Automation; Milford, M.J., Wyeth, G.F., Rasser, D., RatSLAM: A hippocampal model for simultaneous localization and mapping (2004) IEEE International Conference on Robotics and Automation; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163; Mur-Artal, R., Tardós, J.D., ). Fast relocalisation and loop closing in keyframe-based SLAM (2014) IEEE International Conference on Robotics and Automation; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual SLAM across seasons (2015) In IEEE/RSJ International Conference on Intelligent Robots and Systems; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) AAAI Conference on Artificial Intelligence; Nie, F., Huang, H., Cai, X., Ding, C.H., Efficient and robust feature selection via joint ℓ 2, 1 -norms minimization (2010) Advances in Neural Information Processing Systems; Pepperell, E., Corke, P., Milford, M.J., All-environment visual place recognition with SMART (2014) In IEEE International Conference on Robotics and Automation; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2015) Advances in Neural Information Processing Systems; Santos, J.M., Couceiro, M.S., Portugal, D., Rocha, R.P., A sensor fusion layer to cope with reduced visibility in SLAM (2015) Journal of Intelligent & Robotic Systems, 80 (3), pp. 401-422; Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet? Challenging SeqSLAM on a 3000 km journey across all four seasons (2013) In Workshop on IEEE International Conference on Robotics and Automation; Sünderhauf, N., Protzel, P., BRIEF-Gist—closing the loop by simple means (2011) IEEE/RSJ International Conference on Intelligent Robots and Systems; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., ConvNet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Robotics: Science and Systems; Thrun, S., Burgard, W., Fox, D., A real-time algorithm for mobile robot mapping with applications to multi-robot and 3D mapping (2000) In IEEE International Conference on Robotics and Automation; Thrun, S., Leonard, J.J., Simultaneous localization and mapping (2008) Springer handbook of robotics, pp. 871-889. , Siciliano B, Khatib O, (eds), Springer, Berlin; Tibshirani, R., Regression shrinkage and selection via the lasso (1996) Journal of the Royal Statistical Society Series B (Methodological), 58, pp. 267-288; Wang, H., Nie, F., Huang, H., Multi-view clustering and feature learning via structured sparsity (2013) International Conference on Machine Learning; Zhang, H., Han, F., Wang, H., Robust multimodal sequence-based loop closure detection via structured sparsity (2016) Robotics: Science and Systems},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045744764&doi=10.1007%2fs10514-018-9736-3&partnerID=40&md5=b781b775b2bd25ecfd433c09429b9718},
}

@article{han-et-al:2018:2856274,
  author = {F. Han and S. E. Beleidy and H. Wang and C. Ye and H. Zhang},
  journal = {IEEE Robotics and Automation Letters},
  title = {Learning of Holism-Landmark graph embedding for place recognition in Long-Term autonomy},
  volume = {3},
  number = {4},
  pages = {3669--3676},
  doi = {10.1109/LRA.2018.2856274},
  note = {cited By 5},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Place recognition plays an important role to perform loop closure detection of large-scale, long-term simultaneous localization and mapping in loopy environments. The long-term place recognition problem is challenging because the environment appearance exhibits significant long-term variations across various times of the day, months, and seasons. In this letter, we introduce a novel place representation approach that simultaneously integrates semantic landmarks and holistic information to achieve place recognition in long-term autonomy. First, a graph is constructed for each place. The graph nodes encode all landmarks and the holistic image of the place scene recorded in different scenarios. The edges connecting the nodes indicate that these nodes represent the same landmark or place, even though places and landmarks encoded by the nodes may exhibit different appearances in the long-term periods. Then, a graph embedding is learned to preserve the locality in the feature descriptor space, i.e., finding a projection such that the same landmark and place have the identical representation in the new projected descriptor space, no matter in what scenarios they are recorded. We formulate the embedding learning as an optimization problem and implement a new solver that provides a theoretical convergence guarantee. Extensive evaluations are conducted using large-scale benchmark datasets of place recognition in long-term autonomy, which has shown our approach's promising performance. © 2016 IEEE.},
  affiliation = {Department of Computer Science, Colorado School of Mines, Golden, CO  80401, United States; Department of Computer Science, Virginia Commonwealth University, Richmond, VA  23284, United States},
  art_number = {8411104},
  author_keywords = {localization;  recognition;  SLAM;  Visual learning},
  correspondence_address1 = {Zhang, H.; Department of Computer Science, United States; email: hzhang@mines.edu},
  document_type = {Article},
  funding_details = {National Science FoundationNational Science Foundation, NSF, 1423591, 1652943},
  issn = {23773766},
  keywords = {Benchmarking;  Edge detection;  Mapping;  Optimization;  Robustness (control systems);  Semantics, Convergence;  Image edge detection;  localization;  recognition;  Simultaneous localization and mapping;  SLAM;  Visual learning, Robotics},
  language = {English},
  references = {Zhang, H., Han, F., Wang, H., Robust multimodal sequence-based loop closure detection via structured sparsity (2016) Robotics: Science and Systems, , Cambridge, MA, USA: MIT Press; Han, F., Wang, H., Huang, G., Zhang, H., Sequence-based sparse optimization methods for long-term loop closure detection in visual slam (2018) Auton. Robots, pp. 1-13; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Trans. Robot., 32 (1), pp. 1-19. , Feb; Labbe, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Trans. Robot., 29 (3), pp. 734-745. , Jun; Grimmett, H., Integrating metric and semantic maps for visiononly automated parking (2015) Proc. IEEE Int. Conf. Robot. Autom., pp. 2159-2166; Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet? Challenging SeqSLAM on a 3000 km journey across all four seasons (2013) Proc. Workshop IEEE Int. Conf. Robot. Autom.; Han, F., Yang, X., Deng, Y., Rentschler, M., Yang, D., Zhang, H., SRAL: Shared representative appearance learning for long-term visual place recognition (2017) IEEE Robot. Autom. Lett., 2 (2), pp. 1172-1179. , Apr; Linegar, C., Churchill, W., Newman, P., Made to measure: Bespoke landmarks for 24-hour, all-weather localisation with a camera (2016) Proc. IEEE Int. Conf. Robot. Automat., pp. 787-794; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based SLAM (2014) Proc. IEEE Int. Conf. Robot. Automat., pp. 846-853; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Proc. AAAI Conf. Artif. Intell., pp. 2564-2570; Latif, Y., Huang, G., Leonard, J.J., Neira, J., An online sparsitycognizant loop-closure algorithm for visual navigation (2014) Proc. Robot. Sci. Syst.; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 4297-4304; Sunderhauf, N., Place recognition with ConvNet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proc. Robot. Sci. Syst.; Panphattarasap, P., Calway, A., Visual place recognition using landmark distribution descriptors (2016) Proc. Asian Conf. Comput. Vis., pp. 487-502; Wu, J., Rehg, J.M., CENTRIST: A visual descriptor for scene categorization (2011) IEEE Trans. Pattern Anal. Mach. Intell., 33 (8), pp. 1489-1501. , Aug; Pronobis, A., Mozos, O.M., Caputo, B., Jensfelt, P., Multi-modal semantic place classification (2010) Int. J. Robot. Res., 29 (2-3), pp. 298-320; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 2769-2776; Chen, Z., Lowry, S., Jacobson, A., Ge, Z., Milford, M., Distance metric learning for feature-agnostic place recognition (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 2556-2563; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Automat., pp. 1643-1649; Milford, M.J., Wyeth, G.F., Prasser, D., RatSLAM: A hippocampal model for simultaneous localization and mapping (2004) Proc. IEEE Int. Conf. Robot. Automat., pp. 403-408; Labbé, M., Michaud, F., Online global loop closure detection for largescale multi-session graph-based slam (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 2661-2666; Bentley, J.L., Multidimensional binary search trees used for associative searching (1975) Commun. ACM, 18 (9), pp. 509-517; Yang, X., Han, F., Wang, H., Zhang, H., Enforcing template representability and temporal consistency for adaptive sparse tracking (2016) Proc. Int. Joint Conf. Artif. Intell., pp. 3522-3529; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., Towards lifelong visual localization using an efficient matching of binary sequences from images (2015) Proc. IEEE Int. Conf. Robot. Automat., pp. 6328-6335; Johns, E., Yang, G.-Z., Feature co-occurrencemaps: Appearance-based localisation throughout the day (2013) Proc. IEEE Int. Conf. Robot. Automat., pp. 3212-3218; Hansen, P., Browning, B., Visual place recognition using HMM sequence matching (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 4549-4555; Cadena, C., Gálvez-López, D., Tardós, J.D., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Trans. Robot., 28 (4), pp. 871-885. , Aug; Ren, S., He, K., Girshick, R., Sun, J., Faster R-CNN: Towards real-time object detection with region proposal networks (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39 (6), pp. 1137-1149. , Jun; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual SLAM across seasons (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 2529-2535; Badino, H., Huber, D., Kanade, T., Real-time topometric localization (2012) Proc. IEEE Int. Conf. Robot. Automat., pp. 1635-1642},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063309114&doi=10.1109%2fLRA.2018.2856274&partnerID=40&md5=2308c44339df12a6013c88ec92d15094},
}

@article{han-et-al:2017:2662061,
  author = {F. Han and X. Yang and Y. Deng and M. Rentschler and D. Yang and H. Zhang},
  journal = {IEEE Robotics and Automation Letters},
  title = {SRAL: Shared Representative Appearance Learning for Long-Term Visual Place Recognition},
  volume = {2},
  number = {2},
  pages = {1172--1179},
  doi = {10.1109/LRA.2017.2662061},
  note = {cited By 34},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2017},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Place recognition, or loop closure detection, is an essential component to address the problem of visual simultaneous localization and mapping (SLAM). Long-term navigation of robots in outdoor environments introduces new challenges to enable life-long SLAM, including the strong appearance change resulting from vegetation, weather, and illumination variations across various times of the day, different days, months, or even seasons. In this paper, we propose a new shared representative appearance learning (SRAL) approach to address long-term visual place recognition. Different from previous methods using a single feature modality or a concatenation of multiple features, our SRAL method autonomously learns representative features that are shared in all scene scenarios, and then fuses the features together to represent the long-term appearance of environments observed by a robot during life-long navigation. By formulating SRAL as a regularized optimization problem, we use structured sparsity-inducing norms to model interrelationships of feature modalities. In addition, an optimization algorithm is developed to efficiently solve the formulated optimization problem, which holds a theoretical convergence guarantee. Extensive empirical study was performed to evaluate the SRAL method using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have shown that our SRAL method obtains superior performance for life-long place recognition using individual images, outperforms previous single image-based methods, and is capable of estimating the importance of feature modalities. © 2016 IEEE.},
  affiliation = {Division of Computer Science, Colorado School of Mines, GoldenCO  80401, United States; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI  48824, United States; Department of Mechanical Engineering, University of Colorado BoulderCO  80309, United States},
  art_number = {7839213},
  author_keywords = {long-term place recognition;  Loop closure detection;  simultaneous localization and mapping (SLAM);  visual learning},
  document_type = {Article},
  issn = {23773766},
  keywords = {Mapping;  Optimization;  Robotics;  Robots, Illumination variation;  Loop closure;  Optimization algorithms;  Place recognition;  Regularized optimization problems;  Simultaneous localization and mapping;  Visual learning;  Visual simultaneous localization and mappings, Optical character recognition},
  language = {English},
  references = {Lowry, S., Visual place recognition: A survey (2016) IEEE Trans. Robot, 32 (1), pp. 1-19. , Feb; Sünderhauf, N., Protzel, P., BRIEF-Gist - Closing the loop by simple means (2011) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 1234-1241; Cummins, M., Newman, P., Highly scalable appearance-only SLAMFAB- MAP 2.0 (2009) Proc. Robot.: Sci. Syst; Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet challenging SeqSLAM on a 3000 km journey across all four seasons (2013) Proc. Workshop IEEE Int. Conf. Robot. Autom, p. 2013; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int. J Robot. Res, 32 (14), pp. 1645-1661; Linegar, C., Churchill, W., Newman, P., Made to measure: Bespoke landmarks for 24-hour, all-weather localisation with a camera (2016) Proc. IEEE Int. Conf. Robot. Autom, pp. 787-794; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res, 27 (6), pp. 647-665; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Autom, pp. 1643-1649; Arroyo, R., Alcantarilla, P., Bergasa, L., Romera, E., Towards life-long visual localization using an efficient matching of binary sequences from images (2015) Proc. IEEE Int. Conf. Robot. Autom, pp. 6328-6335; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual SLAM across seasons (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 2529-2535; Hansen, P., Browning, B., Visual place recognition using HMM sequence matching (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 4549-4555; Zhang, H., Han, F., Wang, H., Robust multimodal sequence-based loop closure detection via structured sparsity (2016) Proc. Robot.: Sci. Syst; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J.J., Dellaert, F., ISAM2: Incremental smoothing and mapping using the Bayes tree (2012) Int. J. Robot. Res, 31 (2), pp. 216-235; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Large-scale direct monocular SLAM (2014) Proc. Eur. Conf. Comput. Vis, pp. 834-849; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Trans. Robot, 31 (5), pp. 1147-1163. , Oct; Labbe, M., Michaud, F., Online global loop closure detection for largescale multi-session graph-based slam (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 2661-2666; Henry, P., Krainin, M., Herbst, E., Ren, X., Fox, D., RGB-D mapping: Using kinect-style depth cameras for dense 3D modeling of indoor environments (2012) Int. J. Robot. Res, 31 (5), pp. 647-663; Stumm, E., Mei, C., Lacroix, S., Nieto, J., Hutter, M., Siegwart, R., Robust visual place recognition with graph kernels (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4535-4544; Sunderhauf, N., Place recognition with ConvNet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proc. Robot.: Sci. Syst; Chen, C., Wang, H., Appearance-based topological Bayesian inference for loop-closing detection in a cross-country environment (2006) Int. J. Robot. Res, 25 (10), pp. 953-983; Gutmann, J.-S., Konolige, K., Incremental mapping of large cyclic environments (1999) Proc. IEEE Int. Symp. Comput. Intell. Robot. Autom, pp. 318-325; Song, D., Tao, D., Biologically inspired feature manifold for scene classification (2010) IEEE Trans. Image Process, 19 (1), pp. 174-184. , Jan; Klopschitz, M., Zach, C., Irschara, A., Schmalstieg, D., Generalized detection and merging of loop closures for video sequences (2008) Proc. 3D Data Process., Visual. Transm; Cadena, C., Gálvez-López, D., Tardós, J.D., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Trans. Robot, 28 (4), pp. 871-885. , Aug; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Proc. AAAI Conf. Artif. Intell, pp. 2564-2570; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Trans. Robot, 24 (5), pp. 1027-1037. , Oct; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot, 28 (5), pp. 1188-1197; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based SLAM (2014) Proc. IEEE Int. Conf. Robot. Autom, pp. 846-853; Latif, Y., Huang, G., Leonard, J., Neira, J., An online sparsity-cognizant loop-closure algorithm for visual navigation (2014) Proc. Robot.: Sci. Syst; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of ConvNet features for place recognition (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 4297-4304; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Int. Conf. Multimedia, pp. 675-678; Chen, Z., Lam, O., Jacobson, A., Milford, M., Convolutional neural network-based place recognition (2014) Proc. Australiaian Conf. Robot. Autom; Pepperell, E., Corke, P., Milford, M.J., All-environment visual place recognition with SMART (2014) Proc. IEEE Int. Conf. Robot. Autom, pp. 1612-1618; Feldman, D., Volkov, M., Rus, D., Dimensionality reduction of massive sparse datasets using coresets (2016) Proc. Annu. Conf. Neural Inform. Process. Syst, pp. 2766-2774; Lee, D., Kim, H., Myung, H., 2D image feature-based real-time RGBD 3D SLAM (2013) Proc. Robot Intell. Technol. Appl, pp. 485-492; Qiao, Y., Cappelle, C., Ruichek, Y., Place recognition based visual localization using LBP feature and SVM (2015) Proc. Adv. Artif. Intell. Appl, pp. 393-404; Badino, H., Huber, D., Kanade, T., Real-time topometric localization (2012) Proc. IEEE Int. Conf. Robot. Autom, pp. 1635-1642; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., FAB-MAP + RatSLAM: Appearance-based SLAM for multiple times of day (2010) Proc. IEEE Int. Conf. Robot. Autom, pp. 3507-3512},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050632561&doi=10.1109%2fLRA.2017.2662061&partnerID=40&md5=988aa6c2178d0ccd73bdcd235fd8505f},
}

@conference{nobre-et-al:2018:8461111,
  author = {F. Nobre and C. Heckman and P. Ozog and R. W. Wolcott and J. M. Walls},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Online probabilistic change detection in feature-based maps},
  pages = {3661--3668},
  doi = {10.1109/ICRA.2018.8461111},
  note = {cited By 6; Conference of 2018 IEEE International Conference on Robotics and Automation, ICRA 2018 ; Conference Date: 21 May 2018 Through 25 May 2018;  Conference Code:139796},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Sparse feature-based maps provide a compact representation of the environment that admit efficient algorithms, for example simultaneous localization and mapping. These representations typically assume a static world and therefore contain static map features. However, since the world contains dynamic elements, determining when map features no longer correspond to the environment is essential for long-term utility. This work develops a feature-based model of the environment which evolves over time through feature persistence. Moreover, we augment the state-of-the-art sparse mapping model with a correlative structure that captures spatio-temporal properties, e.g. that nearby features frequently have similar persistence. We show that such relationships, typically addressed through an ad hoc formalism focusing only on feature repeatability, are crucial to evaluate through a probabilistically principled approach. The joint posterior over feature persistence can be computed efficiently and used to improve online data association decisions for localization. The proposed algorithms are validated in numerical simulation and using publicly available data sets. © 2018 IEEE.},
  affiliation = {Boulder Autonomous Robotics and Perception Group, University of Colorado, United States; Toyota Research Institute, Japan},
  art_number = {8461111},
  coden = {PIIAE},
  document_type = {Conference Paper},
  funding_details = {Defense Advanced Research Projects AgencyDefense Advanced Research Projects Agency, DARPA},
  funding_text1 = {This work was supported by the Toyota Research Institute. CH was supported by DARPA award no. N65236-16-1-1000.},
  isbn = {9781538630815},
  issn = {10504729},
  keywords = {Mapping, Change detection;  Compact representation;  Dynamic elements;  Feature based modeling;  Simultaneous localization and mapping;  Sparse features;  Spatio-temporal properties;  State of the art, Robotics},
  language = {English},
  references = {Neira, J., Tardós, J.D., Data association in stochastic mapping using the joint compatibility test (2001) IEEE Transactions on Robotics and Automation, 17 (6), pp. 890-897; Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong featurebased mapping in semi-static environments (2016) Robotics and Automation (ICRA), 2016 IEEE International Conference On. IEEE, pp. 1063-1070; Dellaert, F., (2012) Factor Graphs and GTSAM: A Hands-on Introduction, , Georgia Institute of Technology, Tech. Rep; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J.J., Dellaert, F., Isam2: Incremental smoothing and mapping using the Bayes tree (2012) The International Journal of Robotics Research, 31 (2), pp. 216-235; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Robotics: Science and Systems, pp. 17-24; Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term slam (2009) The International Journal of Robotics Research, 28 (1), pp. 20-33; Morris, T., Dayoub, F., Corke, P., Wyeth, G., Upcroft, B., Multiple map hypotheses for planning and navigating in non-stationary environments (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference On. IEEE, pp. 2765-2770; Churchill, W., Newman, P., Practice makes perfect? managing and leveraging visual experiences for lifelong navigation (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference On. IEEE, pp. 4525-4532; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments (2012) Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference On. IEEE, pp. 1871-1878; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International Conference On. IEEE, pp. 1156-1163; Konolige, K., Bowman, J., Chen, J., Mihelich, P., Calonder, M., Lepetit, V., Fua, P., View-based maps (2010) The International Journal of Robotics Research, 29 (8), pp. 941-957; Meyer-Delius, D., Beinhofer, M., Burgard, W., Occupancy grid models for robot mapping in changing environments (2012) AAAI; Moravec, H., Elfes, A., High resolution maps from wide angle sonar (1985) Robotics and Automation. Proceedings. 1985 IEEE International Conference on, 2, pp. 116-121. , IEEE; Saarinen, J., Andreasson, H., Lilienthal, A.J., Independent markov chain occupancy grid maps for representation of dynamic environment (2012) Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference On. IEEE, pp. 3489-3495; Tipaldi, G.D., Meyer-Delius, D., Burgard, W., Lifelong localization in changing environments (2013) The International Journal of Robotics Research, 32 (14), pp. 1662-1678; Krajnik, T., Fentanes, J.P., Cielniak, G., Dondrup, C., Duckett, T., Spectral analysis for long-term robotic mapping (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference On. IEEE, pp. 3706-3711; Dellaert, F., (2001) Monte-Carlo em for Data-association and Its Applications in Computer Vision, , Ph.D. dissertation, Carnegie Mellon University Pittsburgh, PA; Sibley, G., Matthies, L., Sukhatme, G., Sliding window filter with application to planetary landing (2010) Journal of Field Robotics, 27 (5), pp. 587-608; Agarwal, S., Mierle, K., (2012) Ceres Solver; Kaess, M., Dellaert, F., Covariance recovery from a square root information matrix for data association (2009) Robotics and Autonomous Systems, 57 (12), pp. 1198-1210; Leung, K.Y., Halpern, Y., Barfoot, T.D., Liu, H.H., The utias multi-robot cooperative localization and mapping dataset (2011) The International Journal of Robotics Research, 30 (8), pp. 969-974},
  source = {Scopus},
  sponsors = {Csiro; Department of Defence; DJI; et al.; Queensland University of Technology (QUT); Woodside},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063135084&doi=10.1109%2fICRA.2018.8461111&partnerID=40&md5=ab5d2b6619fbe3e96c1f67afb0b970de},
}

@conference{pomerleau-et-al:2014:6907397,
  author = {F. Pomerleau and P. Krüsi and F. Colas and P. Furgale and R. Siegwart},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Long-term 3D map maintenance in dynamic environments},
  pages = {3712--3719},
  doi = {10.1109/ICRA.2014.6907397},
  note = {cited By 79; Conference of 2014 IEEE International Conference on Robotics and Automation, ICRA 2014 ; Conference Date: 31 May 2014 Through 7 June 2014;  Conference Code:107395},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2014},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {New applications of mobile robotics in dynamic urban areas require more than the single-session geometric maps that have dominated simultaneous localization and mapping (SLAM) research to date; maps must be updated as the environment changes and include a semantic layer (such as road network information) to aid motion planning in dynamic environments. We present an algorithm for long-term localization and mapping in real time using a three-dimensional (3D) laser scanner. The system infers the static or dynamic state of each 3D point in the environment based on repeated observations. The velocity of each dynamic point is estimated without requiring object models or explicit clustering of the points. At any time, the system is able to produce a most-likely representation of underlying static scene geometry. By storing the time history of velocities, we can infer the dominant motion patterns within the map. The result is an online mapping and localization system specifically designed to enable long-term autonomy within highly dynamic environments. We validate the approach using data collected around the campus of ETH Zurich over seven months and several kilometers of navigation. To the best of our knowledge, this is the first work to unify long-term map update with tracking of dynamic objects. © 2014 IEEE.},
  affiliation = {Autonomous Systems Lab, ETH Zurich, Zurich, 8092, Switzerland},
  art_number = {6907397},
  author_keywords = {dynamic obstacles;  ICP;  kd-tree;  Long-term mapping;  registration;  robot;  scan matching;  SLAM},
  coden = {PIIAE},
  document_type = {Conference Paper},
  funding_details = {Seventh Framework ProgrammeSeventh Framework Programme, FP7, 247870, 269916, 609763},
  isbn = {9781479936854; 9781479936854},
  issn = {10504729},
  keywords = {Air navigation;  Collision avoidance;  Mapping;  Motion planning;  Robotics;  Robots;  Semantics;  Urban planning, Dynamic obstacles;  K-d tree;  registration;  Scan matching;  SLAM, Robot programming},
  language = {English},
  references = {Kümmerle, R., Ruhnke, M., Steder, B., Stachniss, C., Burgard, W., A navigation system for robots operating in crowded urban environments (2013) Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA); Furgale, P., Schwesinger, U., Rufli, M., Derendarz, W., Grimmett, H., Mühlfellner, P., Wonneberger, S., Siegwart, R., Toward automated driving in cities using closeto-market sensors, an overview of the v-charge project (2013) IEEE Intelligent Vehicles Symposium (IV), pp. 809-816. , Gold Coast, Australia, 23-26 June; Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term slam (2009) The International Journal of Robotics Research, 28 (1), pp. 20-33; Burgard, W., Stachniss, C., Hhnel, D., Mobile robot map learning from range data in dynamic environments (2007) Autonomous Navigation in Dynamic Environments, Ser. Springer Tracts in Advanced Robotics, 35, pp. 3-28. , C. Laugier and R. Chatila, Eds. Springer Berlin Heidelberg; Wurm, K.M., Hornung, A., Bennewitz, M., Stachniss, C., Burgard, W., OctoMap: A probabilistic, flexible, and compact 3D map representation for robotic systems (2010) Workshop on Best Practice in 3D Perception and Modeling for Mobile Manipulation 2010 (ICRA); Aijazi, A., Checchin, P., Trassoudaine, L., Automatic removal of imperfections and change detection for accurate 3D urban cartography by classification and incremental updating (2013) Remote Sensing, 5 (8), pp. 3701-3728. , Aug; Ryde, J., Hillier, N., Alignment and 3D scene change detection for segmentation in autonomous earth moving (2011) Robotics and Automation 2011. Proceedings of the IEEE International Conference on, pp. 1484-1490; Kaestner, R., Maye, J., Pilat, Y., Siegwart, R., Generative object detection and tracking in 3D range data (2012) Robotics and Automation (ICRA) 2012 IEEE International Conference on, pp. 3075-3081; Shackleton, J., Vanvoorst, B., Hesch, J., Tracking people with a 360-degree lidar (2010) Advanced Video and Signal Based Surveillance (AVSS), 2010 Seventh IEEE International Conference on, pp. 420-426; Anderson-Sprecher, P., Simmons, R., Huber, D., Background subtraction and accessibility analysis in evidence grids (2011) Robotics and Automation 2011. Proceedings of the IEEE International Conference on, pp. 3104-3110; Wang, C.C., Thorpe, C., Thrun, S., Hebert, M., Durrant-Whyte, H., Simultaneous localization, mapping and moving object tracking (2007) The International Journal of Robotics Research, 26 (9), pp. 889-916. , Sept; Moosmann, F., Fraichard, T., Motion estimation from range images in dynamic outdoor scenes (2010) Robotics and Automation (ICRA) 2010 IEEE International Conference on, pp. 142-147; Elseberg, J., Magnenat, S., Siegwart, R., Nüchter, A., Comparison of nearest-neighbor-search strategies and implementations for efficient shape registration (2012) Journal of Software Engineering for Robotics, 3 (1), pp. 2-12. , Mar; Rufli, M., Alonso-Mora, J., Siegwart, R., Reciprocal collision avoidance with motion continuity constraints (2013) Robotics IEEE Transactions on, 29 (4), pp. 899-912; Feldmar, J., Ayache, N., Locally affine registration of free-form surfaces (1994) Computer Vision and Pattern Recognition 1994. Proceedings of the IEEE Computer Society Conference on, pp. 496-501; Pomerleau, F., Colas, F., Siegwart, R., Magnenat, S., Comparing ICP variants on real-world data sets (2013) Autonomous Robots, 34 (3), pp. 133-148. , Feb; Alonso-Mora, J., Breitenmoser, A., Rufli, M., Siegwart, R., Beardsley, P., Image and animation display with multiple mobile robots (2012) The International Journal of Robotics Research, 31 (6), pp. 753-773. , May; Kim, K., Lee, D., Essa, I., Gaussian process regression flow for analysis of motion trajectories (2011) Proceedings of IEEE International Conference on Computer Vision (ICCV), , IEEE Computer Society, November},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929207776&doi=10.1109%2fICRA.2014.6907397&partnerID=40&md5=a1da6d69b80262e555a2c0cb57af3c43},
}

@article{tipaldi-et-al:2013:0278364913502830,
  author = {G. D. Tipaldi and D. Meyer-Delius and W. Burgard},
  journal = {International Journal of Robotics Research},
  title = {Lifelong localization in changing environments},
  volume = {32},
  number = {14},
  pages = {1662--1678},
  doi = {10.1177/0278364913502830},
  note = {cited By 66},
  year = {2013},
  abbrev_source_title = {Int J Rob Res},
  abstract = {Robot localization systems typically assume that the environment is static, ignoring the dynamics inherent in most real-world settings. Corresponding scenarios include households, offices, warehouses and parking lots, where the location of certain objects such as goods, furniture or cars can change over time. These changes typically lead to inconsistent observations with respect to previously learned maps and thus decrease the localization accuracy or even prevent the robot from globally localizing itself. In this paper we present a sound probabilistic approach to lifelong localization in changing environments using a combination of a Rao-Blackwellized particle filter with a hidden Markov model. By exploiting several properties of this model, we obtain a highly efficient map management approach for dynamic environments, which makes it feasible to run our algorithm online. Extensive experiments with a real robot in a dynamically changing environment demonstrate that our algorithm reliably adapts to changes in the environment and also outperforms the popular Monte-Carlo localization approach. © The Author(s) 2013.},
  affiliation = {Department of Computer Science, University of Freiburg, Freiburg, Germany; KUKA Laboratories GmbH, Augsburg, Germany},
  author_keywords = {cognitive robotics;  learning and adaptive systems;  localization;  mapping;  Mobile and distributed robotics SLAM},
  coden = {IJRRE},
  correspondence_address1 = {Tipaldi, G.D.; Department of Computer Science, , Freiburg, Germany; email: tipaldi@informatik.uni-freiburg.de},
  document_type = {Article},
  funding_details = {Seventh Framework ProgrammeSeventh Framework Programme, FP7, 248258, 260026, 267686},
  issn = {02783649},
  keywords = {Cognitive robotics;  Learning and adaptive system;  localization;  Localization accuracy;  Mobile and distributed robotics SLAM;  Monte Carlo localization;  Probabilistic approaches;  Rao-blackwellized particle filter, Algorithms;  Hidden Markov models;  Mapping;  Robot applications, Robotics},
  language = {English},
  references = {Anguelov, D., Biswas, R., Koller, D., Limketkai, B., Sanner, S., Thrun, S., Learning hierarchical object maps of non-stationary environments with mobile robots Proceedings of the Conference on Uncertainty in AI (UAI); Avots, D., Lim, E., Thibaux, R., Thrun, S., A probabilistic technique for simultaneous localization and door state estimation with mobile robots in dynamic environments Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots Proceedings of Robotics: Science and Systems (RSS); Blake, A., Zisserman, A., (1987) Visual Reconstruction, , Cambridge, MA: MIT Press;; Brechtel, S., Gindele, T., Dillmann, R., Recursive importance sampling for efficient grid-based occupancy filtering in dynamic environments Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Chen, C., Tay, C., Laugier, C., Mekhnacha, K., Dynamic environment modeling with gridmap: A multiple-object tracking application Proceedings of the IEEE International Conference on Control, Automation, Robotics and Vision (ICARCV); Churchill, W., Newman, P., Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Doucet, A., De Freitas, J., Murphy, K., Russel, S., Rao-Blackwellized partcile filtering for dynamic Bayesian networks Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI); Eliazar, A.I., Parr, R., DP-SLAM 2.0 Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Fox, D., Adapting the sample size in particle filters through KLD-sampling (2003) International Journal of Robotics Research, 22, pp. 985-1003; Fox, D., Burgard, W., Thrun, S., Markov localization for mobile robots in dynamic environments (1999) Journal of Artificial Intelligence Research, 11, pp. 391-427; Gallagher, G., Srinivasa, S.S., Bagnell, J.A., Ferguson, D., GATMO: A generalized approach to tracking movable objects Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based SLAM (2010) IEEE Transactions on Intelligent Transportation Systems Magazine, 2, pp. 31-43; Grisetti, G., Kümmerle, R., Stachniss, C., Frese, U., Hertzberg, C., Hierarchical optimization on manifolds for online 2D and 3D mapping Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Hähnel, D., Triebel, R., Burgard, W., Thrun, S., Map building with mobile robots in dynamic environments Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Konolige, K., Bowman, J., Towards lifelong visual maps Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based slam (2012) International Journal of Robotics Research, 31, pp. 1219-1230; Levin, D.A., Peres, Y., Wilmer, E.L., (2008) Markov Chains and Mixing Times, , American Mathematical Society;; Meyer-Delius, D., Beinhofer, M., Burgard, W., Occupancy grid models for robot mapping in changing environments Proceedings of the AAAI Conference on Artificial Intelligence (AAAI); Meyer-Delius, D., Hess, J., Grisetti, G., Burgard, W., Temporary maps for robust localization in semi-static environments Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Montemerlo, M., Thrun, S., Whittaker, W., Conditional particle filters for simultaneous mobile robot localization and people-tracking Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Montesano, L., Minguez, J., Montano, L., Modeling the static and the dynamic parts of the environment to improve sensor-based navigation Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Moravec, H., Elfes, A., High resolution maps from wide angle sonar Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Murphy, K., Bayesian map learning in dynamic environments Proceedings of the Conference on Neural Information Processing Systems (NIPS); Olson, E., (2008) Robust and Efficient Robotic Mapping, , PhD Thesis, Massachusetts Institute of Technology, Cambridge, MA; Olson, E., Walter, M., Leonard, J., Teller, S., Single cluster graph partitioning for robotics applications (2005) Proceedings of Robotics Science and Systems; Petrovskaya, A., Ng, A.Y., Probabilistic mobile manipulation in dynamic environments, with application to opening doors Proceedings of the International Conference on Artificial Intelligence (IJCAI); Rabiner, L., A tutorial on hidden Markov models and selected applications in speech recognition (1989) Proceedings of the IEEE, 77 (2), pp. 257-286; Röwekämper, J., Sprunk, C., Tipaldi, G.D., Cyrill, S., Pfaff, P., Burgard, W., On the position accuracy of mobile robot localization based on particle filters combined with scan matching Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Saarinen, J., Andreasson, H., Lilienthal, A.J., Independent Markov chain occupancy grid maps for representation of dynamic environments Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Schulz, D., Fox, D., Hightower, J., People tracking with anonymous and id-sensors using Rao-Blackwellised particle filters (2003) Proceedings of the International Conference on Artificial Intelligence (IJCAI), , http://dl.acm.org/citation.cfm?id=1630659.1630792, Available at; Stachniss, C., Burgard, W., Mobile robot mapping and localization in non-static environments Proceedings of the National Conference on Artificial Intelligence (AAAI); Thrun, S., A probabilistic online mapping algorithm for teams of mobile robots (2001) International Journal of Robotics Research, 20 (5), pp. 335-363; Walcott, A., (2011) Long-term Mobile Robot Mapping in Dynamic Environments, , PhD Thesis, Massachusetts Institute of Technology, Cambridge, MA; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Wang, C.C., Thorpe, C., Thrun, S., Hebert, M., Durrant-Whyte, H., Simultaneous localization, mapping and moving object tracking (2007) International Journal of Robotics Research, 26, pp. 889-916; Wolf, D.F., Sukhatme, G.S., Mobile robot simultaneous localization and mapping in dynamic environments (2005) Autonomous Robots, 19 (1), pp. 53-65; Yang, S.W., Wang, C.C., Feasibility grids for localization and mapping in crowded urban scenes IEEE International Conference on Robotics and Automation (ICRA)},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892620468&doi=10.1177%2f0278364913502830&partnerID=40&md5=32b07f9c5be711731c83f908f4ca52fa},
}

@conference{huang-et-al:2013:6698835,
  author = {G. Huang and M. Kaess and J. J. Leonard},
  journal = {2013 European Conference on Mobile Robots, ECMR 2013 - Conference Proceedings},
  title = {Consistent sparsification for graph optimization},
  pages = {150--157},
  doi = {10.1109/ECMR.2013.6698835},
  note = {cited By 51; Conference of 2013 6th European Conference on Mobile Robots, ECMR 2013 ; Conference Date: 25 September 2013 Through 27 September 2013;  Conference Code:102443},
  publisher = {IEEE Computer Society},
  address = {Barcelona},
  year = {2013},
  abbrev_source_title = {Eur. Conf. Mob. Rob., ECMR - Conf. Proc.},
  abstract = {In a standard pose-graph formulation of simultaneous localization and mapping (SLAM), due to the continuously increasing numbers of nodes (states) and edges (measurements), the graph may grow prohibitively too large for long-term navigation. This motivates us to systematically reduce the pose graph amenable to available processing and memory resources. In particular, in this paper we introduce a consistent graph sparsification scheme: i) sparsifying nodes via marginalization of old nodes, while retaining all the information (consistent relative constraints) - which is conveyed in the discarded measurements - about the remaining nodes after marginalization; and ii) sparsifying edges by formulating and solving a consistent ℓ1-regularized minimization problem, which automatically promotes the sparsity of the graph. The proposed approach is validated on both synthetic and real data. © 2013 IEEE.},
  affiliation = {Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA 02139, United States},
  art_number = {6698835},
  document_type = {Conference Paper},
  funding_details = {N00014-10-1-0936, N00014-11-1-0688, N00014-12-1-0093, N00014-12-10020},
  isbn = {9781479902637},
  keywords = {Mathematical techniques;  Mobile robots;  Robotics, Graph optimization;  Graph sparsification;  Marginalization;  Memory resources;  Minimization problems;  Simultaneous localization and mapping;  Sparsification;  Synthetic and real data, Graph theory},
  language = {English},
  references = {Dellaert, F., Kaess, M., Square root SAM: Simultaneous localization and mapping via square root information smoothing (2006) International Journal of Robotics Research, 25 (12), pp. 1181-1203. , DOI 10.1177/0278364906072768; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) IEEE Transactions on Robotics, 24 (6), pp. 1365-1378. , Dec; Grisetti, G., Kummerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based SLAM (2010) IEEE Intelligent Transportation Systems Magazine, 2 (4), pp. 31-43; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proc. of the IEEE Intl. Conf. on Robotics and Automation, pp. 3607-3613. , Shanghai, China, May 9-13; Eade, E., Fong, P., Munich, M., Monocular graph SLAM with complexity reduction (2010) Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems, pp. 3017-3024. , Taipei, Taiwan, Oct. 18-22; Ila, V., Porta, J., Andrade-Cetto, J., Information-based compact pose SLAM (2010) IEEE Transactions on Robotics, 26 (1), pp. 78-93. , Feb; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based SLAM (2012) International Journal of Robotics Research, 31 (11), pp. 1219-1230. , Sep; Johannsson, H., Kaess, M., Fallon, M., Leonard, J., Temporally scalable visual SLAM using a reduced pose graph (2013) Proc. of the IEEE Intl. Conf. on Robotics and Automation, pp. 54-61. , Karlsruhe, Germany, May 6-10; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph SLAM (2013) Proc. of the IEEE Intl. Conf. on Robotics and Automation, pp. 5728-5735. , Karlsruhe, Germany, May 6-10; Bar-Shalom, Y., Li, X.R., Kirubarajan, T., (2001) Estimation with Applications to Tracking and Navigation, , New York: Wiley; Triggs, B., McLauchlan, P.F., Hartley, R.I., Fitzgibbon, A.W., Bundle adjustment - A modern synthesis (2000) Lecture Notes in Computer Science, 1883, pp. 298-375. , Jan; Donoho, D., Compressed sensing (2006) IEEE Transactions on Signal Processing, 52 (4), pp. 1289-1306. , Apr; Thrun, S., Robotic mapping: A survey (2003) Exploring Artificial Intelligence in the New Millennium, pp. 1-35. , G. Lakemeyer and B. Nebel, Eds. San Francisco, CA: Morgan Kaufmann Inc; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , Cambridge, MA: The MIT Press; Durrant-Whyte, H., Bailey, T., Simultaneous localization and mapping: Part I (2006) IEEE Robotics Automation Magazine, 13 (2), pp. 99-110. , Jun; Bailey, T., Durrant-Whyte, H., Simultaneous localization and mapping (SLAM): Part II (2006) IEEE Robotics and Automation Magazine, 13 (3), pp. 108-117. , DOI 10.1109/MRA.2006.1678144; Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Autonomous Robots, 4 (4), pp. 333-349; Folkesson, J., Christensen, H., Graphical SLAM - A self-correcting map (2004) Proc. of the IEEE Intl. Conf. on Robotics and Automation, 1, pp. 383-390. , Apr. 26-May 1; Olson, E., Leonard, J., Teller, S., Fast iterative alignment of pose graphs with poor initial estimates (2006) Proceedings - IEEE International Conference on Robotics and Automation, 2006, pp. 2262-2269. , DOI 10.1109/ROBOT.2006.1642040, 1642040, Proceedings 2006 IEEE International Conference on Robotics and Automation, ICRA 2006; Konolige, K., Grisetti, G., Kummerle, R., Burgard, W., Limketkai, B., Vincent, R., Efficient sparse pose adjustment for 2D mapping (2010) Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems, pp. 22-29. , Taipei, Taiwan, Oct. 18-22; Grisetti, G., Stachniss, C., Burgard, W., Nonlinear constraint network optimization for efficient map learning (2009) IEEE Transactions on Intelligent Transportation Systems, 10 (3), pp. 428-439. , Sep; Grisetti, G., Kummerle, R., Stachniss, C., Frese, U., Hertzberg, C., Hierarchical optimization on manifolds for online 2D and 3D mapping (2010) Proc. of the IEEE Intl. Conf. on Robotics and Automation, pp. 273-278. , Anchorage, AK, May3-8; Strasdat, H., Montiel, J.M.M., Davison, A.J., Visual SLAM: Why filter? (2012) Image and Vision Computing, 30 (2), pp. 65-77. , Feb; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J., Dellaert, F., ISAM2: Incremental smoothing and mapping using the Bayes tree (2012) International Journal of Robotics Research, 31, pp. 217-236. , Feb; Sibley, G., Matthies, L., Sukhatme, G., Sliding window filter with application to planetary landing (2010) Journal of Field Robotics, 27 (5), pp. 587-608; Huang, G.P., Mourikis, A.I., Roumeliotis, S.I., An observability constrained sliding window filter for SLAM (2011) Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems, pp. 65-72. , San Francisco, CA, Sep. 25-30; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) Proc. of the IEEE and ACM International Symposium on Mixed and Augmented Reality, , Nara, Japan, Nov. 13-16; Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to real-time visual mapping (2008) IEEE Transactions on Robotics, 24 (5), pp. 1066-1077. , Oct; Konolige, K., Bowman, J., Chen, J.D., Mihelich, P., Calonder, M., Lepetit, V., Fua, P., View-based maps (2010) International Journal of Robotics Research, 29 (8), pp. 941-957. , Jul; Eustice, R.M., Singh, H., Leonard, J.J., Exactly sparse delayed-state filters for view-based SLAM (2006) IEEE Transactions on Robotics, 22 (6), pp. 1100-1114. , DOI 10.1109/TRO.2006.886264; Vial, J., Durrant-Whyte, H., Bailey, T., Conservative sparsification for efficient and consistent approximate estimation (2011) Proc. of the IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems, pp. 886-893. , San Francisco, CA, Sep. 25-30; Thrun, S., Liu, Y., Koller, D., Ng, A., Ghahramani, Z., Durrant-Whyte, H., Simultaneous localization and mapping with sparse extended information filters (2004) International Journal of Robotics Research, 23 (7-8), pp. 693-716. , Aug; Walter, M.R., Eustice, R.M., Leonard, J.J., Exactly sparse extended information filters for feature-based SLAM (2007) International Journal of Robotics Research, 26 (4), pp. 335-359. , DOI 10.1177/0278364906075026; Olson, E., (2008) Robust and Efficient Robotic Mapping, , Ph. D. dissertation, MIT, Cambridge, MA, USA; Golub, G.H., Loan, C.F.V., (1996) Matrix Computations, , The Johns Hopkins University Press; Boyd, S., Vandenberghe, L., (2004) Convex Optimization, , Cambridge University Press; Banerjee, O., Ghaoui, L.E., D'Aspremont, A., Natsoulis, G., Convex optimization techniques for fitting sparse Gaussian graphical models (2006) Proc. of the International Conference on Machine Learning, pp. 89-96. , New York, NY, Jun. 25-29; Horn, R.A., Johnson, C.R., (1990) Matrix Analysis, , Cambridge University Press; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., Distributed optimization and statistical learning via the alternating direction method of multipliers (2011) Foundations and Trends in Machine Learning, 3 (1), pp. 1-122; Tibshirani, R., Regression shrinkage and selection via the lasso (1996) Journal of the Royal Statistical Society (Series B), 58 (1), pp. 267-288},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893301601&doi=10.1109%2fECMR.2013.6698835&partnerID=40&md5=d3ed7f443662be6219eb636619411593},
}

@article{kim-et-al:2019:2897340,
  author = {G. Kim and B. Park and A. Kim},
  journal = {IEEE Robotics and Automation Letters},
  title = {1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image},
  volume = {4},
  number = {2},
  pages = {1948--1955},
  doi = {10.1109/LRA.2019.2897340},
  note = {cited By 47},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {In this letter, we present a long-term localization method that effectively exploits the structural information of an environment via an image format. The proposed method presents a robust year-round localization performance even when learned in just a single day. The proposed localizer learns a point cloud descriptor, named Scan Context Image (SCI), and performs robot localization on a grid map by formulating the place recognition problem as place classification using a convolutional neural network. Our method is faster than existing methods proposed for place recognition because it avoids a pairwise comparison between a query and scans in a database. In addition, we provide thorough validations using publicly available long-term datasets, the NCLT dataset and the Oxford RobotCar dataset, and show that the Scan Context Image (SCI) localization attains consistent performance over a year and outperforms existing methods. © 2016 IEEE.},
  affiliation = {Department of Civil and Environmental Engineering, KAIST, Daejeon, 34141, South Korea; Intelligent Robot System Research Group, ETRI, Daejeon, 34129, South Korea},
  art_number = {8633942},
  author_keywords = {Localization;  range sensing;  SLAM},
  correspondence_address1 = {Kim, A.; Department of Civil and Environmental Engineering, South Korea; email: ayoungk@kaist.ac.kr},
  document_type = {Article},
  funding_details = {Ministry of Land, Infrastructure and TransportMinistry of Land, Infrastructure and Transport, MOLIT, 19CTAP-C142170-02},
  funding_text1 = {Manuscript received September 6, 2018; accepted January 21, 2019. Date of publication February 4, 2019; date of current version February 28, 2019. This letter was recommended for publication by Associate Editor N. Sunderhauf and Editor C. Stachniss upon evaluation of the reviewers’ comments. This work was supported in part by the Korea Agency for Infrastructure Technology Advancement (KAIA) through the Ministry of Land, Infrastructure and Transport of Korea under Grant 19CTAP-C142170-02, and in part by the [High-Definition Map Based Precise Vehicle Localization Using Cameras and LIDARs] project funded by Naver Labs Corporation. (Corresponding author: Ayoung Kim.) G. Kim and A. Kim are with the Department of Civil and Environmental Engineering, KAIST, Daejeon 34141, South Korea (e-mail:,paulgkim@kaist.ac.kr; ayoungk@kaist.ac.kr).},
  issn = {23773766},
  keywords = {Neural networks;  Robot applications, Consistent performance;  Convolutional neural network;  Localization;  Localization performance;  Pair-wise comparison;  Range sensing;  SLAM;  Structural information, Query processing},
  language = {English},
  references = {He, L., Wang, X., Zhang, H., M2DP: A novel 3D point cloud descriptor and its application in loop closure detection (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 231-237; Uy, M.A., Lee, G.H., PointNetVLAD: Deep point cloud based retrieval for large-scale place recognition (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4470-4479; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan north campus long-term vision and lidar dataset (2016) Int. J. Robot. Res., 35 (9), pp. 1023-1035; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: The oxford robotcar dataset (2017) Int. J. Robot. Res., 36 (1), pp. 3-15; Galvez-Lpez, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Kendall, A., Grimes, M., Cipolla, R., PoseNet: A convolutional net-work for real-time 6-DOF camera relocalization (2015) Proc. IEEE Int. Conf. Comput. Vis., pp. 2938-2946; Schönberger, J.L., Pollefeys, M., Geiger, A., Sattler, T., Semantic visual localization (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 6896-6906; Porav, H., Maddern, W., Newman, P., Adversarial training for adverse conditions: Robust metric localisation using appearance transfer (2018) Proc. IEEE Int. Conf. Robot. Automat., pp. 1011-1018; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int. J. Robot. Res., 32 (14), pp. 1645-1661; Ye, Y., Cieslewski, T., Loquercio, A., Scaramuzza, D., Place recognition in semi-dense maps: Geometric and learning-based approaches (2017) Proc. Brit. Mach. Vis. Conf., pp. 721-7213; Kim, G., Kim, A., Scan context: Egocentric spatial descriptor for place recognition within 3D point cloud map (2018) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Oct., pp. 4802-4809; Dubé, R., Cramariuc, A., Dugas, D., Nieto, J., Siegwart, R., Cadena, C., SegMap: 3D segment mapping using data-driven descriptors (2018) Proc. Robot., Sci. Syst. Conf.; Wohlkinger, W., Vincze, M., Ensemble of shape functions for 3D object classification (2011) Proc. IEEE Int. Conf. Robot. Biomimetics, pp. 2987-2992; Benedikt, M.L., To take hold of space: Isovists and isovist fields (1979) Env. Planning B: Planning and Des., 6 (1), pp. 47-65; Cop, K., Borges, P.V.K., Dubé, R., DELIGHT: An efficient descriptor for global localisation using LiDAR intensities (2018) Proc. IEEE Int. Conf. Robot. Automat., pp. 3653-3660; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3D classification and segmentation (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 77-85; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5297-5307; Maddern, W., Pascoe, G., Newman, P., Leveraging experience for large-scale LIDAR localisation in changing cities (2015) Proc. IEEE Int. Conf. Robot. Automat., pp. 1684-1691; Withers, D., Newman, P., Modelling scene change for large-scale long term laser localisation (2017) Proc. IEEE Int. Conf. Robot. Automat., pp. 6233-6239; Weyand, T., Kostrikov, I., Philbin, J., PlaNet-photo geolocation with convolutional neural networks (2016) Proc. Eur. Conf. Comput. Vis., pp. 37-55; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Miller, D., Nicholson, L., Dayoub, F., Sünderhauf, N., Dropout Sampling for robust object detection in open-set conditions (2018) Proc. IEEE Int. Conf. Robot. Automat., pp. 3243-3249; Kendall, A., Gal, Y., What uncertainties do we need in Bayesian deep learning for computer vision? (2017) Proc. Adv. Neural Inf. Process. Syst. Conf., pp. 5574-5584},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062621439&doi=10.1109%2fLRA.2019.2897340&partnerID=40&md5=f984d40ba54e543247d76c41300d14fd},
}

@conference{kurz-et-al:2021:9636530,
  author = {G. Kurz and M. Holoch and P. Biber},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Geometry-based Graph Pruning for Lifelong SLAM},
  pages = {3313--3320},
  doi = {10.1109/IROS51168.2021.9636530},
  note = {cited By 0; Conference of 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2021 ; Conference Date: 27 September 2021 Through 1 October 2021;  Conference Code:175617},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case). © 2021 IEEE.},
  affiliation = {Corporate Research, Robert Bosch GmbH, Germany},
  coden = {85RBA},
  document_type = {Conference Paper},
  isbn = {9781665417143},
  issn = {21530858},
  keywords = {Graph theory;  Robotics, Changing environment;  Graph sizes;  Graph-based;  Loop closure;  Marginalization;  Novel methods;  Pruning algorithms;  Real-world;  Robot trajectory;  SLAM approach, Graphic methods},
  language = {English},
  references = {Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based slam (2010) IEEE Intelligent Transportation Systems Magazine, 2 (4), pp. 31-43; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., Leonard, J.J., Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age (2016) IEEE Transactions on Robotics, 32 (6), pp. 1309-1332. , dec; Krajnik, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), , oct; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proc. IEEE Int. Conf. Robotics and Automation, pp. 3607-3613. , May; Dellaert, F., Factor graphs and gtsam: A hands-on introduction (2012) Georgia Institute of Technology, Tech. Rep. GT-RIM-CP&R-2012-002, , Sept; Kretzschmar, H., Grisetti, G., Stachniss, C., Lifelong map learning for graph-based slam in static environments (2010) KI-Künstliche Intelligenz, 24 (3), pp. 199-206; Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Transactions on Information Theory, 14 (3), pp. 462-467. , may; Kretzschmar, H., Stachniss, C., Grisetti, G., Efficient informationtheoretic graph pruning for graph-based slam with laser range finders (2011) IEEE/RSJ Int. Conf. Intelligent Robots and Systems, pp. 865-871; Eade, E., Fong, P., Munich, M.E., Monocular graph slam with complexity reduction (2010) Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems, pp. 3017-3024; Lázaro, M.T., Capobianco, R., Grisetti, G., Efficient long-term mapping in dynamic environments (2018) Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems (IROS), pp. 153-160; Grisetti, G., Kummerle, R., Ni, K., Robust optimization of factor graphs by using condensed measurements (2012) 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, , oct; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph slam (2013) 2013 IEEE International Conference on Robotics and Automation, , may; Carlevaris-Bianco, N., Kaess, M., Eustice, R.M., Generic node removal for factor-graph slam (2014) IEEE Transactions on Robotics, 30 (6), pp. 1371-1385. , dec; Mazuran, M., Burgard, W., Tipaldi, G.D., Nonlinear factor recovery for long-term slam (2015) The International Journal of Robotics Research, 35 (1-3), pp. 50-72. , jun; Ta, D.-N., Banerjee, N., Eick, S., Lenser, S., Munich, M.E., Fast nonlinear approximation of pose graph node marginalization (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 2494-2501; Wang, Y., Xiong, R., Huang, S., A pose pruning driven solution to pose feature graphslam (2015) Advanced Robotics, 29 (10), pp. 683-698. , jan; Underwood, J.P., Gillsjö, D., Bailey, T., Vlaskine, V., Explicit 3d change detection using ray-tracing in spherical coordinates (2013) Proc. IEEE Int. Conf. Robotics and Automation, pp. 4735-4741; Lee, G.H., Fraundorfer, F., Pollefeys, M., Robust pose-graph loop-closures with expectation-maximization (2013) 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems, , nov; Hart, P., Nilsson, N., Raphael, B., A formal basis for the heuristic determination of minimum cost paths (1968) IEEE Transactions on Systems Science and Cybernetics, 4 (2), pp. 100-107; Biber, P., Strasser, W., The normal distributions transform: A new approach to laser scan matching (2003) 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003); Burgard, W., Stachniss, C., Grisetti, G., Steder, B., Kümmerle, R., Dornhege, C., Ruhnke, M., Tardös, J.D., A comparison of slam algorithms based on a graph of relations (2009) 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2089-2095},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124373627&doi=10.1109%2fIROS51168.2021.9636530&partnerID=40&md5=102902e7b40ce9738cb94735d6e987a0},
}

@conference{singh-et-al:2021:9564866,
  author = {G. Singh and M. Wu and S.-K. Lam and D. V. Minh},
  journal = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
  title = {Hierarchical Loop Closure Detection for Long-term Visual SLAM with Semantic-Geometric Descriptors},
  volume = {2021-September},
  pages = {2909--2916},
  doi = {10.1109/ITSC48978.2021.9564866},
  note = {cited By 0; Conference of 2021 IEEE International Intelligent Transportation Systems Conference, ITSC 2021 ; Conference Date: 19 September 2021 Through 22 September 2021;  Conference Code:173112},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Conf Intell Transport Syst Proc ITSC},
  abstract = {Modern visual Simultaneous Localization and Mapping (SLAM) systems rely on loop closure detection methods for correcting drifts in maps and poses. Existing loop closure detection methods mainly employ conventional feature descriptors to create vocabulary for describing places using bag-of-words (BOW). Such methods do not perform well in long-term SLAM applications as the scene content may change over time due to the presence of dynamic objects, even though the locations are revisited with the same viewpoint. This work enhances the loop closure detection capability of long-term visual SLAM by reducing the number of false matches through the use of location semantics. We extend a semantic visual SLAM framework to build compact global semantic-geometric location descriptors and local semantic vocabulary trees, by leveraging on the already available features and semantics. The local semantic vocabulary trees support incremental vocabulary learning, which is well-suited for long-term SLAM scenarios where the scenes encountered are not known beforehand. A novel hierarchical place recognition method that leverages the global and local location semantics is proposed to enable fast and accurate loop closure detection. The proposed method outperforms recent state-of-the-art methods (i.e., FABMAP2, SeqSLAM, iBOW-LCD, and HTMap) on all datasets considered (i.e., KITTI, Synthia, and CBD), with highest loop closure detection accuracy and lowest query time. © 2021 IEEE.},
  document_type = {Conference Paper},
  funding_details = {Agency for Science, Technology and ResearchAgency for Science, Technology and Research, A*STAR, I1701E0013},
  funding_text1 = {ACKNOWLEDGMENT This research was conducted in part at Singtel Cognitive and Artificial Intelligence Lab for Enterprises (SCALE@NTU), which is a collaboration between Singapore Telecommunications Limited (Singtel) and Nanyang Technological University (NTU) that is supported by A*STAR under its Industry Alignment Fund (LOA Award number: I1701E0013).},
  isbn = {9781728191423},
  keywords = {Forestry;  Location;  Robotics, Detection methods;  Feature descriptors;  Geometric descriptor;  Local semantics;  Localisation Systems;  Loop closure;  Mapping systems;  Simultaneous localization and mapping;  Visual simultaneous localization and mappings;  Vocabulary tree, Semantics},
  language = {English},
  references = {Bowman, S.L., Probabilistic data association for semantic slam (2017) 2017 Ieee International Conference on Robotics and Automation (ICRA)., pp. 1722-1729; Cummins, M., Newman, P., Appearance-only slam at large scale with fab-map 2.0 (2011) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Fuentes-Pacheco, J., Ruiz-Ascencio, J., Manuel Rendón-Mancha, J., Visual simultaneous localization and mapping: A survey (2015) Artificial Intelligence Review, 43 (1), pp. 55-81; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) Ieee Transactions on Robotics, 28 (5), pp. 1188-1197. , Oct., ISSN: 1552-3098; Garcia-Fidalgo, E., Ortiz, A., Ibow-lcd: An appearance-based loop-closure detection approach using incremental bags of binary words (2018) Ieee Robotics and Automation Letters, 3 (4), pp. 3051-3057; Garcia-Fidalgo, E., Ortiz, A., Hierarchical place recognition for topological mapping (2017) Ieee Transactions on Robotics, 33 (5), pp. 1061-1074. , Oct; Garcia-Fidalgo, E., Ortiz, A., On the use of binary feature descriptors for loop closure detection (2014) Emerging Technology and Factory Automation (ETFA), pp. 1-8. , IEEE. Sept. 2014; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The kitti vision benchmark suite (2012) Conference on Computer Vision and Pattern Recognition (CVPR).; Gidaris, S., Komodakis, N., Locnet: Improving localization accuracy for object detection (2016) Computer Vision and Pattern Recognition (CVPR), 2016 Ieee Conference On.; Glover, A.J., Fab-map + ratslam: Appearance-based slam for multiple times of day (2010) 2010 Ieee International Conference on Robotics and Automation., pp. 3507-3512; Lowry, S., Visual place recognition: A survey (2016) Ieee Transactions on Robotics, 32 (1), pp. 1-19; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) 2012 Ieee International Conference on Robotics and Automation., pp. 1643-1649; Ros, G., The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes (2016) 2016 Ieee Conference on Computer Vision and Pattern Recognition (CVPR)., pp. 3234-3243; Singh, G., Wu, M., Lam, S., Fusing semantics and motion state detection for robust visual slam (2020) Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)., , Mar; Uy, M.A., Hee Lee, G., Pointnetvlad: Deep point cloud based retrieval for large-scale place recognition (2018) The Ieee Conference on Computer Vision and Pattern Recognition (CVPR).; Zhang, G., Yan, X., Ye, Y., Loop closure detection via maximization of mutual information (2019) Ieee Access, 7, pp. 124217-124232},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118448425&doi=10.1109%2fITSC48978.2021.9564866&partnerID=40&md5=b3c9ea9859b2444fbc603add6249ccb1},
}

@article{hu-et-al:2022:1003907,
  author = {H. Hu and H. Wang and Z. Liu and W. Chen},
  journal = {IEEE/CAA Journal of Automatica Sinica},
  title = {Domain-Invariant Similarity Activation Map Contrastive Learning for Retrieval-Based Long-Term Visual Localization},
  volume = {9},
  number = {2},
  pages = {313--328},
  doi = {10.1109/JAS.2021.1003907},
  note = {cited By 1},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2022},
  abbrev_source_title = {IEEE CAA J. Autom. Sin.},
  abstract = {Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the contrastive learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization. © 2014 Chinese Association of Automation.},
  affiliation = {Shanghai Jiao Tong University, Department of Automation, Shanghai, 200240, China; Institute of Medical Robotics, Key Laboratory of System Control and Information Processing, Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Jiao Tong University, Department of Automation, Shanghai, 200240, China; University of Cambridge, Department of Computer Science and Technology, Cambridge, CB3 0FD, United Kingdom},
  author_keywords = {Deep representation learning;  place recognition;  visual localization},
  correspondence_address1 = {Wang, H.; Institute of Medical Robotics, China; email: wanghesheng@sjtu.edu.cn},
  document_type = {Article},
  issn = {23299266},
  keywords = {Chemical activation, Coarse-to-fine strategy;  Environmental conditions;  General architectures;  Generalization ability;  Illumination changes;  Image-based localizations;  Sequential combination;  Visual localization, Image retrieval},
  language = {English},
  references = {Bescos, B., Fácil, J.M., Civera, J., Neira, J., DynaSLAM: Tracking, mapping, and inpainting in dynamic scenes (2018) IEEE Robot. Autom. Lett., 3 (4), pp. 4076-4083. , Oct; Wang, L.P., Wei, H., Avoiding non-Manhattan obstacles based on projection of spatial corners in indoor environment (2020) IEEE/CAA J. Autom. Sinica, 7 (4), pp. 1190-1200. , Jul; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2018) IEEE Trans. Pattern Anal. Mach. Intell., 40 (6), pp. 1437-1451. , Jun; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Trans. Robot., 32 (1), pp. 1-19. , Feb; Torii, A., Arandjelovic, R., Sivic, J., Okutomi, M., Pajdla, T., 4/7 place recognition by view synthesis (2018) IEEE Trans. Pattern Anal. Mach. Intell., 40 (2), pp. 257-271. , Feb; Sattler, T., Zhou, Q.J., Pollefeys, M., Leal-Taixé, L., Understanding the limitations of CNN-based absolute camera pose regression (2019) Proc. IEEE/CVF Conf. Computer Vision and Pattern Recognition, pp. 3297-3307. , Long Beach, CA, USA; Sarlin, P.E., Cadena, C., Siegwart, R., Dymczyk, M., From coarse to fine: Robust hierarchical localization at large scale (2019) Proc. IEEE/CVF Conf. Computer Vision and Pattern Recognition, pp. 12708-12717. , Long Beach, CA, USA; Sattler, T., Maddern, W., Toft, C., Benchmarking 6DOF outdoor visual localization in changing conditions (2018) Proc. IEEE/CVF Conf. Computer Vision and Pattern Recognition, pp. 8601-8610. , Salt Lake City, UT, USA; Ma, Y.F., Wang, Z.Y., Yang, H., Yang, L., Artificial intelligence applications in the development of autonomous vehicles: A survey (2020) IEEE/CAA J. Autom. Sinica, 7 (2), pp. 315-329. , Mar; Doan, D., Latif, Y., Chin, T.J., Liu, Y., Do, T.T., Reid, I., Scalable place recognition under appearance change for autonomous driving (2019) Proc. IEEE/CVF Int. Conf. Computer Vision, pp. 9318-9327. , Seoul, Korea (South); Yin, P., Xu, L.Y., Li, X.Q., Yin, C., Li, Y.L., Srivatsan, R.A., Li, L., He, Y.Q., A multi-domain feature learning method for visual place recognition (2019) Proc. IEEE Int. Conf. Robotics and Automation, pp. 319-324. , Montreal, QC, Canada; Chen, Z.T., Jacobson, A., Sünderhauf, N., Upcroft, B., Liu, L.Q., Shen, C.H., Reid, I., Milford, M., Deep learning features at scale for visual place recognition (2017) Proc. IEEE Int. Conf. Robotics and Automation, pp. 3223-3230. , Singapore; Wang, J., Song, Y., Leung, T., Rosenberg, C., Wang, J.B., Philbin, J., Chen, B., Wu, Y., Learning fine-grained image similarity with deep ranking (2014) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 1386-1393. , Columbus, OH, USA; Wohlhart, P., Lepetit, V., Learning descriptors for object recognition and 3D pose estimation (2015) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 3109-3118. , Boston, MA, USA; Lu, J.W., Hu, J.L., Tan, Y.P., Discriminative deep metric learning for face and kinship verification (2017) IEEE Trans. Image Process., 26 (9), pp. 4269-4282. , Sept; Lowry, S., Milford, M.J., Supervised and unsupervised linear learning techniques for visual place recognition in changing environments (2016) IEEE Trans. Robot., 32 (3), pp. 600-613. , Jun; Gordo, A., Almazán, J., Revaud, J., Larlus, D., End-to-end learning of deep visual representations for image retrieval (2017) Int. J. Comput. Vis., 124 (2), pp. 237-254. , Sept; Radenovi, F., Tolias, G., Chum, O., Fine-tuning CNN image retrieval with no human annotation (2019) IEEE Trans. Pattern Anal. Mach. Intell., 41 (7), pp. 1655-1668. , Jul; Zhou, B.L., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A., Learning deep features for discriminative localization (2016) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 2921-2929. , Las Vegas, NV, USA; Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra, D., Grad-CAM: Visual explanations from deep networks via gradient-based localization (2017) Proc. IEEE Int. Conf. Computer Vision, pp. 618-626. , Venice, Italy; Chattopadhay, A., Sarkar, A., Howlader, P., Balasubramanian, V.N., Grad-CAM++: Generalized gradient-based visual explanations for deep convolutional networks (2018) Proc. IEEE Winter Conf. Applications of Computer Vision, pp. 839-847. , Lake Tahoe, NV, USA; Kim, H.J., Dunn, E., Frahm, J.M., Learned contextual feature reweighting for image geo-localization (2017) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 3251-3260. , Honolulu, HI, USA; Chen, Z.T., Liu, L.Q., Sa, I., Ge, Z.Y., Chli, M., Learning context flexible attention model for long-term visual place recognition (2018) IEEE Robot. Autom. Lett., 3 (4), pp. 4015-4022. , Oct; Gu, H.Y., Wang, H.S., Xu, F., Liu, Z., Chen, W.D., Active fault detection of soft manipulator in visual servoing (2020) IEEE Trans. Ind. Electron.; Han, L.J., Wang, H.S., Liu, Z., Chen, W.D., Zhang, X.F., Visionbased cutting control of deformable objects with surface tracking (2020) IEEE/ASME Trans. Mechatron.; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Shi, W., Liu, P.X., Zheng, M.H., A mixed-depth visual rendering method for bleeding simulation (2019) IEEE/CAA J. Autom. Sinica, 6 (4), pp. 917-925. , Jul; Liu, Z.Y., Qiao, H., GNCCP-graduated NonConvexity and concavity procedure (2014) IEEE Trans. Pattern Anal. Mach. Intell., 36 (6), pp. 1258-1267. , Jun; Qiao, H., Li, Y.L., Tang, T., Wang, P., Introducing memory and association mechanism into a biologically inspired visual model (2014) IEEE Trans. Cybernet., 44 (9), pp. 1485-1496. , Sept; Mur-Artal, R., Tardós, J.D., ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras (2017) IEEE Trans. Robot., 33 (5), pp. 1255-1262. , Oct; Jégou, H., Douze, M., Schmid, C., Pérez, P., Aggregating local descriptors into a compact image representation (2010) Proc. IEEE Computer Society Conf. Computer Vision & Pattern Recognition, pp. 3304-3311. , San Francisco, CA, USA; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robotics and Automation, pp. 1643-1649. , Saint Paul, MN, USA; Siam, S.M., Zhang, H., Fast-SeqSLAM: A fast appearance based place recognition algorithm (2017) Proc. IEEE Int. Conf. Robotics and Automation, pp. 5702-5708. , Singapore; Xing, Y., Lv, C., Chen, L., Wang, H.J., Wang, H., Cao, D.P., Velenis, E., Wang, F.Y., Advances in vision-based lane detection: Algorithms, integration, assessment, and perspectives on ACP-based parallel vision (2018) IEEE/CAA J. Autom. Sinica, 5 (3), pp. 645-661. , May; Jenicek, T., Chum, O., No fear of the dark: Image retrieval under varying illumination conditions (2019) Proc. IEEE/CVF Int. Conf. Computer Vision, pp. 9696-9703. , Seoul, Korea (South); Isola, P., Zhu, J.Y., Zhou, T.H., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 5967-5976. , Honolulu, HI, USA; Anoosheh, A., Agustsson, E., Timofte, R., Van Gool, L., ComboGAN: Unrestrained scalability for image domain translation (2018) Proc. IEEE/CVF Conf. Computer Vision and Pattern Recognition Workshops, pp. 896-903. , Salt Lake City, UT, USA; Liu, M.Y., Breuel, T., Kautz, J., Unsupervised image-to-image translation networks (2017) Proc. 31st Int. Conf. Neural Information Processing Systems, pp. 700-708. , Red Hook, NY, United States; Huang, X., Liu, M.Y., Belongie, S., Kautz, J., Multimodal unsupervised image-to-image translation (2018) Proc. European Conf. Computer Vision, pp. 179-196. , Munich, Germany; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., Generative adversarial nets (2014) Proc. 27th Int. Conf. Neural Information Processing Systems, pp. 2672-2680. , Cambridge, MA, United States; Radford, A., Metz, L., Chintala, S., (2015) Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks; Porav, H., Maddern, W., Newman, P., Adversarial training for adverse conditions: Robust metric localisation using appearance transfer (2018) Proc. IEEE Int. Conf. Robotics and Automation, pp. 1011-1018. , Brisbane, QLD, Australia; Zhu, J.Y., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) Proc. IEEE Int. Conf. Computer Vision, pp. 2242-2251. , Venice, Italy; Anoosheh, A., Sattler, T., Timofte, R., Pollefeys, M., Van Gool, L., Night-to-day image translation for retrieval-based localization (2019) Proc. IEEE Int. Conf. Robotics and Automation, pp. 5958-5964. , Montreal, QC, Canada; Naseer, T., Oliveira, G.L., Brox, T., Burgard, W., Semantics-aware visual localization under challenging perceptual conditions (2017) Proc. IEEE Int. Conf. Robotics and Automation, pp. 2614-2620. , Singapore; Stenborg, E., Toft, C., Hammarstrand, L., Long-term visual localization using semantically segmented images (2018) Proc. IEEE Int. Conf. Robotics and Automation, pp. 6484-6490. , Brisbane, QLD, Australia; Piasco, N., Sidibé, D., Gouet-Brunet, V., Demonceaux, C., Learning scene geometry for visual localization in challenging conditions (2019) Proc. IEEE Int. Conf. Robotics and Automation, pp. 9094-9100. , Montreal, QC, Canada; Piasco, N., Sidibé, D., Gouet-Brunet, V., Demonceaux, C., Improving image description with auxiliary modality for visual localization in challenging conditions (2021) Int. J. Comput. Vis.; Wang, X.H., Duan, H.B., Hierarchical visual attention model for saliency detection inspired by avian visual pathways (2019) IEEE/CAA J. Autom. Sinica, 6 (2), pp. 540-552. , Mar; Xin, Z., Cai, Y.H., Lu, T., Xing, X.X., Cai, S.J., Zhang, J.P., Yang, Y.P., Wang, Y.Q., Localizing discriminative visual landmarks for place recognition (2019) Proc. IEEE Int. Conf. Robotics and Automation, pp. 5979-5985. , Montreal, QC, Canada; Luo, X., Wang, D.X., Zhou, M.C., Yuan, H.Q., Latent factor-based recommenders relying on extended stochastic gradient descent algorithms (2019) IEEE Trans. Syst. Man Cybernet.: Syst., 51 (2), pp. 916-926; Wu, D., He, Q., Luo, X., Shang, M.S., He, Y., Wang, G.Y., A posterior-neighborhood-regularized latent factor model for highly accurate web service QoS prediction (2019) IEEE Trans. Serv. Comput.; Wu, D., Luo, X., Shang, M.S., He, Y., Wang, G.Y., Zhou, M.C., A deep latent factor model for high-dimensional and sparse matrices in recommender systems (2019) IEEE Trans. Syst. Man Cybernet.: Syst.; Gong, R., Li, W., Chen, Y.H., Van Gool, L., DLOW: Domain flow for adaptation and generalization (2019) Proc. IEEE/CVF Conf. Computer Vision and Pattern Recognition, pp. 2472-2481. , Long Beach, CA; Achille, A., Soatto, S., Emergence of invariance and disentanglement in deep representations (2018) Proc. Information Theory and Applications Workshop, pp. 1-9. , San Diego, CA, USA; Kim, H., Mnih, A., Disentangling by factorising (2018) Proc. 35th Int. Conf. Machine Learning, pp. 2649-2658. , Stockholm, Sweden; Makhzani, A., Shlens, J., Jaitly, N., Goodfellow, I., Frey, B., (2015) Adversarial Autoencoders; Mathieu, M., Zhao, J.B., Sprechmann, P., Ramesh, A., LeCun, Y., Disentangling factors of variation in deep representations using adversarial training (2016) Proc. 30th Int. Conf. Neural Information Processing Systems, pp. 5047-5055. , Red Hook, NY, United States; Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I., Abbeel, P., InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets (2016) Proc. 30th Int. Conf. Neural Information Processing Systems, pp. 2180-2188. , Red Hook, NY, United States; Donahue, C., Lipton, Z.C., Balsubramani, A., McAuley, J., (2018) Semantically Decomposing the Latent Spaces of Generative Adversarial Networks; Lopez-Antequera, M., Gomez-Ojeda, R., Petkov, N., Gonzalez-Jimenez, J., Appearance-invariant place recognition by discriminatively training a convolutional neural network (2017) Pattern Recogn. Lett., 92, pp. 89-95. , Jun; Hu, H.J., Wang, H.S., Liu, Z., Yang, C.G., Chen, W.D., Xie, L., Retrieval-based localization based on domain-invariant feature learning under changing environments (2019) Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems, pp. 3684-3689. , Macau, China; Tang, L., Wang, Y., Luo, Q.H., Ding, X.Q., Xiong, R., Adversarial feature disentanglement for place recognition across changing appearance (2020) Proc. IEEE Int. Conf. Robotics and Automation, pp. 1301-1307. , Paris, France; Hausler, S., Jacobson, A., Milford, M., Filter early, match late: Improving network-based visual place recognition (2019) Proc. IEEE/RSJ Int. Conf. Intelligent Robots and Systems, pp. 3268-3275. , Macau, China; Garg, S., Suenderhauf, N., Milford, M., Don' t look back: Robustifying place categorization for viewpoint-and conditioninvariant place recognition (2018) Proc. IEEE Int. Conf. Robotics and Automation, pp. 3645-3652. , Brisbane, QLD, Australia; Oh Song, H., Xiang, Y., Jegelka, S., Savarese, S., Deep metric learning via lifted structured feature embedding (2016) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 4004-4012. , Las Vegas, NV, USA; Xing, E.P., Ng, A.Y., Jordan, M.I., Russell, S., Distance metric learning, with application to clustering with side-information (2002) Proc. 15th Int. Conf. Neural Information Processing Systems, pp. 521-528. , Cambridge, MA, United States; Weinberger, K.Q., Saul, L.K., Fast solvers and efficient implementations for distance metric learning (2008) Proc. 25th Int. Conf. Machine Learning, pp. 1160-1167. , Helsinki, Finland; Varior, R.R., Haloi, M., Wang, G., Gated siamese convolutional neural network architecture for human re-identification (2016) Proc. European Conf. Computer Vision, pp. 791-808. , Amsterdam, The Netherlands; Balntas, V., Li, S.D., Prisacariu, V., RelocNet: Continuous metric learning relocalisation using neural nets (2018) Proc. European Conf. Computer Vision, pp. 782-799. , Munich, Germany; Hoffer, E., Ailon, N., Deep metric learning using triplet network (2015) Proc. Int. Workshop on Similarity-Based Pattern Recognition, pp. 84-92. , Copenhagen, Denmark; Kumar, B.G.V., Carneiro, G., Reid, I., Learning local image descriptors with deep siamese and triplet convolutional networks by minimizing global loss functions (2016) Proc. IEEE Conf. Computer Vision and Pattern Recognition, pp. 5385-5394. , Las Vegas, NV, USA; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665. , Jun; Badino, H., Huber, D., Kanade, T., Visual topometric localization (2011) Proc. IEEE Intelligent Vehicles Symp.; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: The Oxford RobotCar dataset (2017) Int. J. Robot. Res., 36 (1), pp. 3-15. , Jan},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101742423&doi=10.1109%2fJAS.2021.1003907&partnerID=40&md5=aa955cfc805ad33f1d0b31589541d169},
}

@conference{johannsson-et-al:2013:6630556,
  author = {H. Johannsson and M. Kaess and M. Fallon and J. J. Leonard},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Temporally scalable visual SLAM using a reduced pose graph},
  pages = {54--61},
  doi = {10.1109/ICRA.2013.6630556},
  note = {cited By 75; Conference of 2013 IEEE International Conference on Robotics and Automation, ICRA 2013 ; Conference Date: 6 May 2013 Through 10 May 2013;  Conference Code:100673},
  address = {Karlsruhe},
  year = {2013},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {In this paper, we demonstrate a system for temporally scalable visual SLAM using a reduced pose graph representation. Unlike previous visual SLAM approaches that maintain static keyframes, our approach uses new measurements to continually improve the map, yet achieves efficiency by avoiding adding redundant frames and not using marginalization to reduce the graph. To evaluate our approach, we present results using an online binocular visual SLAM system that uses place recognition for both robustness and multi-session operation. Additionally, to enable large-scale indoor mapping, our system automatically detects elevator rides based on accelerometer data. We demonstrate long-term mapping in a large multi-floor building, using approximately nine hours of data collected over the course of six months. Our results illustrate the capability of our visual SLAM system to map a large are over extended period of time. © 2013 IEEE.},
  affiliation = {Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, United States},
  art_number = {6630556},
  coden = {PIIAE},
  correspondence_address1 = {Computer Science and Artificial Intelligence Laboratory, , Cambridge, United States},
  document_type = {Conference Paper},
  isbn = {9781467356411},
  issn = {10504729},
  keywords = {Accelerometer data;  Graph representation;  Key-frames;  Marginalization;  Place recognition;  Visual SLAM, Robotics},
  language = {English},
  references = {Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term SLAM (2009) Intl.J.Of Robotics Research, 28 (1), pp. 20-33; Castle, R., Klein, G., Murray, D., Wide-area augmented reality using camera tracking and mapping in multiple regions (2011) Computer Vision and Image Understanding, 115 (6), pp. 854-867. , http://www.sciencedirect.com/science/article/pii/S1077314211000701; Dellaert, F., Square Root SAM: Simultaneous location and mapping via square root information smoothing (2005) Robotics: Science and Systems (RSS), , Cambridge, MA; Eade, E., Fong, P., Munich, M., Monocular graph SLAM with complexity reduction (2010) IEEE/RSJ Intl.Conf.On Intelligent Robots and Systems (IROS), pp. 3017-3024. , Oct; Estrada, C., Neira, J., Tardos, J., Hierarchical SLAM: Realtime accurate mapping of large environments (2005) IEEE Trans.Robotics, 21 (4), pp. 588-596; Folkesson, J., Christensen, H., Graphical SLAM-A self-correcting map (2004) IEEE Intl.Conf.On Robotics and Automation (ICRA), 1, pp. 383-390; Grisetti, G., Stachniss, C., Grzonka, S., Burgard, W., A tree parameterization for efficiently computing maximum likelihood maps using gradient descent (2007) Robotics: Science and Systems (RSS), Jun.; Grisetti, G., Kummerle, R., Stachniss, C., Frese, U., Hertzberg, C., Hierarchical optimization on manifolds for online 2D and 3D mapping (2010) IEEE Intl.Conf.On Robotics and Automation (ICRA), , Anchorage, Alaska, May; Gutmann, J., Konolige, K., Incremental mapping of large cyclic environments (1999) Proc.Of the 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation, 1, pp. 318-325; Huang, A., Bachrach, A., Henry, P., Krainin, M., Maturana, D., Fox, D., Roy, N., Visual odometry and mapping for autonomous flight using an RGB-D camera (2011) Proc.Of the Intl.Symp.Of Robotics Research (ISRR), , Flagstaff, USA, Aug; Ila, V., Porta, J., Andrade-Cetto, J., Information-based compact pose SLAM (2010) Robotics, IEEE Transactions on, 26 (1), pp. 78-93. , Feb; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) IEEE Trans.Robotics, 24 (6), pp. 1365-1378. , Dec; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) IEEE and ACM Intl.Sym.On Mixed and Augmented Reality (ISMAR), pp. 225-234. , Nara, Japan, Nov; Klein, G., Murray, D., Improving the agility of keyframe-based SLAM (2008) ECCV '08: Proceedings of the 10th European Conference on Computer Vision.Berlin, pp. 802-815. , Heidelberg: Springer-Verlag; Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to real-time visual mapping (2008) IEEE Trans.Robotics, 24 (5), pp. 1066-1077. , Oct; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) IEEE/RSJ Intl.Conf.On Intelligent Robots and Systems (IROS), pp. 1156-1163. , Oct; Kretzschmar, H., Stachniss, C., Grisetti, G., Efficient informationtheoretic graph pruning for graph-based SLAM with laser range finders (2011) IEEE/RSJ Intl.Conf.On Intelligent Robots and Systems (IROS), , Sep; Lu, F., Milios, E., Globally consistent range scan alignment for environmental mapping (1997) Autonomous Robots, 4, pp. 333-349. , Apr; Olson, E., Leonard, J., Teller, S., Fast iterative alignment of pose graphs with poor initial estimates (2006) IEEE Intl.Conf.On Robotics and Automation (ICRA), pp. 2262-2269. , May; Pinies, P., Paz, L., Galvez-Lopez, D., Tardos, J., CI-Graph SLAM for 3D reconstruction of large and complex environments using a multicamera system (2010) J.Of Field Robotics, 27 (5), pp. 561-586. , Sep; Pirker, K., Ruether, M., Bischof, H., CD SLAM-continuous localization and mapping in a dynamic world (2011) IEEE/RSJ Intl.Conf.On Intelligent Robots and Systems (IROS), , Sep; Rosen, D., Kaess, M., Leonard, J., An incremental trust-region method for robust online sparse least-squares estimation (2012) IEEE Intl.Conf.On Robotics and Automation (ICRA), pp. 1262-1269. , St.Paul, MN, May; Sibley, G., Mei, C., Reid, I., Newman, P., Planes, trains and automobiles-autonomy for the modern robot (2010) IEEE Intl.Conf.On Robotics and Automation (ICRA).IEEE, pp. 285-292; Smith, R., Self, M., Cheeseman, P., Estimating uncertain spatial relationships in robotics (1990) Autonomous Robot Vehicles, pp. 167-193. , Springer Verlag; Walter, M., Eustice, R., Leonard, J., Exactly sparse extended information filters for feature-based SLAM (2007) Intl.J.Of Robotics Research, 26 (4), pp. 335-359; Wang, Z., Huang, S., Dissanayake, G., D-SLAM: A decoupled solution to simultaneous localization and mapping (2007) Intl.J.Of Robotics Research, 26 (2), pp. 187-204},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887298986&doi=10.1109%2fICRA.2013.6630556&partnerID=40&md5=a677df3b28e54abbd5e76f1624d20411},
}

@article{karaoguz-bozma:2016:4,
  author = {H. Karaoguz and H. I. Bozma},
  journal = {AUTONOMOUS ROBOTS},
  title = {An integrated model of autonomous topological spatial cognition},
  volume = {40},
  number = {8},
  pages = {1379--1402},
  doi = {10.1007/s10514-015-9514-4},
  publisher = {SPRINGER},
  address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
  year = {2016},
  month = {12},
  abstract = {This paper is focused on endowing a mobile robot with topological
spatial cognition. We propose an integrated model-where the concept of a
`place' is defined as a collection of appearances or locations sharing
common perceptual signatures or physical boundaries. In this model, as
the robot navigates, places are detected in a systematic manner via
monitoring coherency in the incoming visual data while pruning out
uninformative or scanty data. Detected places are then either recognized
or learned along with mapping as necessary. The novelties of the model
are twofold: First, it explicitly incorporates a long-term spatial
memory where the knowledge of learned places and their spatial relations
are retained in place and map memories respectively. Second, the
processing modules operate together so that the robot is able to build
its spatial memory in an organized, incremental and unsupervised manner.
Thus, the robot's long-term spatial memory evolves completely on its own
while learned knowledge is organized based on appearance-related
similarities in a manner that is amenable for higher-level semantic
reasoning, As such, the proposed model constitutes a step forward
towards having robots that are capable of interacting with their
environments in an autonomous manner.},
  affiliation = {Karaoguz, H (Corresponding Author), Bogazici Univ, Intelligent Syst Lab, Elect \& Elect Engn, Istanbul, Turkey.
Karaoguz, Hakan; Bozma, H. Isil, Bogazici Univ, Intelligent Syst Lab, Elect \& Elect Engn, Istanbul, Turkey.},
  affiliations = {Bogazici University},
  author-email = {hakan.karaoguz@boun.edu.tr},
  cited-references = {Beeson P, 2010, INT J ROBOT RES, V29, P428, DOI 10.1177/0278364909100586.
Casati R., 2002, TOPOLOGY COGNITION.
Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
Chella Antonio, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P741, DOI 10.1109/IROS.2007.4399614.
Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
Denis M, 2007, PSYCHOL RES-PSYCH FO, V71, P235, DOI 10.1007/s00426-006-0079-x.
Dolins F. L., 2010, LINKING SPATIAL PERC.
Erkent O, 2015, IEEE INT CONF ROBOT, P5462, DOI 10.1109/ICRA.2015.7139962.
Erkent O, 2012, IEEE INT CONF ROBOT, P3497, DOI 10.1109/ICRA.2012.6225367.
Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511.
Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
Karaoguz H, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P218, DOI 10.1109/ICAR.2015.7251459.
Karaoguz H, 2014, IEEE INT CONF ROBOT, P697, DOI 10.1109/ICRA.2014.6906930.
Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5.
Lim J, 2012, INT J ROBOT RES, V31, P1394, DOI 10.1177/0278364912461455.
Liu M, 2012, IEEE INT CONF ROBOT, P3503, DOI 10.1109/ICRA.2012.6225040.
Mozos OM, 2007, ROBOT AUTON SYST, V55, P391, DOI 10.1016/j.robot.2006.12.003.
Martinez-Gomez J, 2011, IEEE INT CONF ROBOT, P1936, DOI 10.1109/ICRA.2011.5980102.
Mozos O. M., 2007, P IEEE RSJ IROS WORK.
Murphy L, 2014, IEEE INT CONF ROBOT, P1312, DOI 10.1109/ICRA.2014.6907022.
Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
Posner I, 2008, SPRINGER TRAC ADV RO, V39, P85.
Pronobis A, 2009, INT J ROBOT RES, V28, P588, DOI 10.1177/0278364909103912.
Pronobis A, 2010, 11 INT C INT AUT SYS.
Pronobis A, 2012, IEEE INT CONF ROBOT, P3515, DOI 10.1109/ICRA.2012.6224637.
Ranganathan A., 2010, P ROB SCI SYST.
Ranganathan A, 2012, AUTON ROBOT, V32, P351, DOI 10.1007/s10514-012-9273-4.
Remolina E, 2004, ARTIF INTELL, V152, P47, DOI 10.1016/S0004-3702(03)00114-0.
Robert L., 1997, SPATIAL COGNITION GE.
Shi L, 2012, IEEE INT C INT ROBOT, P2991, DOI 10.1109/IROS.2012.6385549.
SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30.
Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
Tapus A., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2429.
TVERSKY B, 1983, COGNITIVE PSYCHOL, V15, P121, DOI 10.1016/0010-0285(83)90006-3.
Tversky B., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT `93 Proceedings, P14.
Tversky B., 2005, CAMBRIDGE HDB VISUOS, P1, DOI DOI 10.1017/CBO9780511610448.002.
Ursic P, 2012, IEEE INT C INT ROBOT, P1371, DOI 10.1109/IROS.2012.6385546.
Vasudevan S, 2008, ROBOT AUTON SYST, V56, P522, DOI 10.1016/j.robot.2008.03.005.
Vasudevan S, 2007, ROBOT AUTON SYST, V55, P359, DOI 10.1016/j.robot.2006.12.008.
Walter MR, 2014, INT J ROBOT RES, V33, P1167, DOI 10.1177/0278364914537359.
Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
Yeh T, 2008, PROC CVPR IEEE, P61.
Zivkovic Z., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2480.
Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.},
  da = {2022-05-17},
  doc-delivery-number = {EA6AB},
  eissn = {1573-7527},
  funding-acknowledgement = {Bogazici University BAP {[}9164]; Tubitak {[}EEAG 111E285]; Turkish
State Planning Organization (DPT) under the TAM {[}2007K120610]},
  funding-text = {This work has been supported in part by Bogazici University BAP Project
9164 and Tubitak Project EEAG 111E285. The first author is supported by
Turkish State Planning Organization (DPT) under the TAM Project number
2007K120610.},
  issn = {0929-5593},
  journal-iso = {Auton. Robot.},
  keywords = {Spatial cognition; Long-term spatial memory; Place recognition},
  keywords-plus = {SEMANTIC MAPS; LOOP CLOSURE; LARGE-SCALE; FAB-MAP; LOCALIZATION; VISION;
SPACE},
  language = {English},
  number-of-cited-references = {47},
  research-areas = {Computer Science; Robotics},
  researcherid-numbers = {Bozma, Huriye Isil/A-2348-2017},
  times-cited = {5},
  type = {Article},
  unique-id = {WOS:000386705700002},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {15},
  web-of-science-categories = {Computer Science, Artificial Intelligence; Robotics},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
}

@article{karaoguz-bozma:2020:2,
  author = {H. Karaoguz and H. I. Bozma},
  journal = {AUTONOMOUS ROBOTS},
  title = {Merging of appearance-based place knowledge among multiple robots},
  volume = {44},
  number = {6},
  pages = {1009--1027},
  doi = {10.1007/s10514-020-09911-2},
  publisher = {SPRINGER},
  address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
  year = {2020},
  month = {7},
  abstract = {If robots can merge the appearance-based place knowledge of other robots
with their own, they can relate to these places even if they have not
previously visited them. We have investigated this problem using robots
with compatible visual sensing capabilities and with each robot having
its individual long-term place memory. Here, each place refers to a
spatial region as defined by a collection of appearances and in the
place memory, the knowledge is organized in a tree hierarchy. In the
proposed merging approach, the hierarchical organization plays a key
role-as it corresponds to a nested sequence of hyperspheres in the
appearance space. The merging proceeds by considering the extent of
overlap of the respective nested hyperspheres-starting with the largest
covering hypersphere. Thus, differing from related work, knowledge is
merged in as large chunks as possible while the hierarchical structure
is preserved accordingly. As such, the merging scales better as the
extent of knowledge to be merged increases. This is demonstrated in an
extensive set of multirobot experiments where robots share their
knowledge and then use their merged knowledge when visiting these
places.},
  affiliation = {Karaoguz, H (Corresponding Author), Kungliga Tekn Hgsk Stockholm, Stockholm, Sweden.
Karaoguz, Hakan, Kungliga Tekn Hgsk Stockholm, Stockholm, Sweden.
Bozma, H. Isil, Bogazici Univ, Fac Elect \& Elect Engn, Istanbul, Turkey.},
  affiliations = {Royal Institute of Technology; Bogazici University},
  author-email = {hkarao@kth.se},
  cited-references = {Adluru N, 2008, INT C PATT RECOG, P382.
Amigoni F, 2006, P IEEE, V94, P1340, DOI 10.1109/JPROC.2006.876925.
Aragues R, 2012, IEEE T ROBOT, V28, P840, DOI 10.1109/TRO.2012.2192012.
Beeson P, 2010, INT J ROBOT RES, V29, P428, DOI 10.1177/0278364909100586.
Birk A, 2006, P IEEE, V94, P1384, DOI 10.1109/JPROC.2006.876965.
Carpin S, 2005, ROBOT AUTON SYST, V53, P1, DOI 10.1016/j.robot.2005.07.001.
Carpin S, 2008, AUTON ROBOT, V25, P305, DOI 10.1007/s10514-008-9097-4.
Chella A, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P747.
Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
Erinc G, 2014, AUTON ROBOT, V36, P241, DOI 10.1007/s10514-013-9352-1.
Erkent O, 2017, ADV ROBOTICS, V31, P865, DOI 10.1080/01691864.2017.1356746.
Erkent O, 2013, INT J ROBOT RES, V32, P672, DOI 10.1177/0278364913481393.
Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
Ferreira F., 2008, ICLAWAR, P1.
Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511.
Garcia-Fidalgo E, 2017, IEEE T ROBOT, V33, P1061, DOI 10.1109/TRO.2017.2704598.
Gil A, 2010, ROBOT AUTON SYST, V58, P68, DOI 10.1016/j.robot.2009.07.026.
Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
Ho K., 2005, IEEE RSJ INT C INT R.
Howard A, 2004, IEEE INT CONF ROBOT, P4198, DOI 10.1109/ROBOT.2004.1308933.
Huang WH, 2005, INT J ROBOT RES, V24, P601, DOI 10.1177/0278364905056348.
Karaoguz H, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5107, DOI 10.1109/IROS.2016.7759749.
Karaoguz H, 2016, AUTON ROBOT, V40, P1379, DOI 10.1007/s10514-015-9514-4.
Karaoguz H, 2014, IEEE INT CONF ROBOT, P697, DOI 10.1109/ICRA.2014.6906930.
Ko J., 2003, IEEE RSJ INT C INT R, V4.
Konolige K, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P212.
Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006.
Lee HC, 2011, ADV ROBOTICS, V25, P1675, DOI 10.1163/016918611X584631.
Leung KYK, 2011, IEEE INT CONF ROBOT.
Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
Ma X., 2008, WORLD C INT CONTR AU, P5704.
Marjovi A, 2012, ROBOT AUTON SYST, V60, P1191, DOI 10.1016/j.robot.2012.05.007.
Matlin M.W, 2005, COGNITION.
Nieto-Granda C, 2014, INT J ROBOT RES, V33, P519, DOI 10.1177/0278364913515309.
Ozkucur NE, 2009, LECT NOTES COMPUT SC, V5399, P189, DOI 10.1007/978-3-642-02921-9\_17.
Park S, 2016, IEEE T ROBOT, V32, P528, DOI 10.1109/TRO.2016.2544301.
Parker L. E, 2008, J PHYS AGENTS, V2, P5, DOI {[}DOI 10.14198/JOPHA.2008.2.1.02, 10.14198/jopha.2008.2.1.02].
Pronobis A, 2009, INT J ROBOT RES, V28, P588, DOI 10.1177/0278364909103912.
Ranganathan A., 2010, P ROB SCI SYST.
Saeedi S, 2014, ROBOT AUTON SYST, V62, P1408, DOI 10.1016/j.robot.2014.06.002.
Samatova NF, 2002, DISTRIB PARALLEL DAT, V11, P157.
Thrun S., 2000, IEEE INT C ROB AUT, V1.
Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
Tomono M, 2013, IEEE INT C INT ROBOT, P5172, DOI 10.1109/IROS.2013.6697104.
Tungadi F, 2010, IEEE INT C INT ROBOT, P7, DOI 10.1109/IROS.2010.5654446.
Williams SB, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2743, DOI 10.1109/ROBOT.2002.1013647.
Zhou XS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1785, DOI 10.1109/IROS.2006.282219.},
  da = {2022-05-17},
  doc-delivery-number = {MI1DC},
  earlyaccessdate = {MAR 2020},
  eissn = {1573-7527},
  funding-acknowledgement = {Royal Institute of Technology; TUBITAK {[}EEEAG-111E285]; Turkish State
Planning Organization (DPT) {[}TAM 2007K120610]; BAP {[}9164]},
  funding-text = {Open access funding provided by Royal Institute of Technology. This work
has been supported in part by TUBITAK EEEAG-111E285, BAP 9164 and by the
Turkish State Planning Organization (DPT) under the TAM 2007K120610.},
  issn = {0929-5593},
  journal-iso = {Auton. Robot.},
  keywords = {Place recognition; Multi-robot; Unsupervised learning},
  keywords-plus = {LARGE-SCALE; SLAM; MAPS},
  language = {English},
  number-of-cited-references = {47},
  oa = {hybrid},
  research-areas = {Computer Science; Robotics},
  times-cited = {0},
  type = {Article},
  unique-id = {WOS:000521864000001},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {2},
  web-of-science-categories = {Computer Science, Artificial Intelligence; Robotics},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
}

@article{kretzschmar-stachniss:2012:0278364912455072,
  author = {H. Kretzschmar and C. Stachniss},
  journal = {International Journal of Robotics Research},
  title = {Information-theoretic compression of pose graphs for laser-based SLAM},
  volume = {31},
  number = {11},
  pages = {1219--1230},
  doi = {10.1177/0278364912455072},
  note = {cited By 76},
  year = {2012},
  abbrev_source_title = {Int J Rob Res},
  abstract = {In graph-based simultaneous localization and mapping (SLAM), the pose graph grows over time as the robot gathers information about the environment. An ever growing pose graph, however, prevents long-term mapping with mobile robots. In this paper, we address the problem of efficient information-theoretic compression of pose graphs. Our approach estimates the mutual information between the laser measurements and the map to discard the measurements that are expected to provide only a small amount of information. Our method subsequently marginalizes out the nodes from the pose graph that correspond to the discarded laser measurements. To maintain a sparse pose graph that allows for efficient map optimization, our approach applies an approximate marginalization technique that is based on Chow-Liu trees. Our contributions allow the robot to effectively restrict the size of the pose graph. Alternatively, the robot is able to maintain a pose graph that does not grow unless the robot explores previously unobserved parts of the environment. Real-world experiments demonstrate that our approach to pose graph compression is well suited for long-term mobile robot mapping. © 2012 The Author(s).},
  affiliation = {Department of Computer Science, University of Freiburg, Geroges Köhler-Allee 79, Freiburg 79110, Germany},
  author_keywords = {compression;  long-term;  mutual information;  pose graph;  SLAM},
  coden = {IJRRE},
  correspondence_address1 = {Stachniss, C.; Department of Computer Science, Geroges Köhler-Allee 79, Freiburg 79110, Germany; email: stachnis@informatik.uni-freiburg.de},
  document_type = {Conference Paper},
  funding_details = {Seventh Framework ProgrammeSeventh Framework Programme, FP7, 260026},
  issn = {02783649},
  keywords = {Amount of information;  Graph-based;  Laser measurements;  long-term;  Marginalization;  Mutual informations;  pose graph;  Real world experiment;  Robot mapping;  Simultaneous localization and mapping;  SLAM, Compaction;  Information theory;  Mathematical techniques;  Mobile robots;  Robotics, Trees (mathematics)},
  language = {English},
  references = {Bachrach, A., Prentice, S., He, R., Roy, N., RANGE - Robust autonomous navigation in GPS-denied environments (2011) Journal of Field Robotics, 28, pp. 644-666; Bosse, M., Newman, P.M., Leonard, J.J., Teller, A., An ATLAS framework for scalable mapping Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Cheeseman, P., Smith, P., On the representation and estimation of spatial uncertainty (1986) The International Journal of Robotics Research, 5, pp. 56-68; Chli, M., Davison, A.J., Automatically and efficiently inferring the hierarchical structure of visual maps Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Transactions on Information Theory, 14, pp. 462-467; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27, pp. 647-665; Davison, A., Active search for real-time vision Proceedings of the International Conference on Computer Vision (ICCV); Eade, E., Fong, P., Munich, M., Monocular graph SLAM with complexity reduction Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Estrada, C., Neira, J., Tardós, J., Hierachical SLAM: Real-time accurate mapping of large environments (2005) IEEE Transactions on Robotics, 21, pp. 588-596; Eustice, R., Singh, H., Leonard, J., Exactly sparse delayed-state filters for view-based SLAM (2006) IEEE Transactions on Robotics, 22, pp. 1100-1114; Folkesson, J., Jensfelt, P., Christensen, H., Vision SLAM in the measurement subspace (2005) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 325-330. , Barcelona, Spain; Grisetti, G., Kümmerle, R., Stachniss, C., Frese, U., Hertzberg, C., Hierarchical optimization on manifolds for online 2D and 3D mapping (2010) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 273-278. , Anchorage, AK ; 2010; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Transactions on Robotics, 23, pp. 34-46; He, R., Prentice, S., Roy, N., Planning in information space for a quadrotor helicopter in a gps-denied environments (2008) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 1814-1820. , Los Angeles, CA ; 2008; Howard, A.R., Oy, N., (2003) The Robotics Data Set Repository (Radish), , http://radish.sourceforge.net/; Ila, V., Porta, J., Andrade-Cetto, J., Information-based compact pose SLAM (2010) IEEE Transactions on Robotics, 26, pp. 78-93; Kaess, M., Dellaert, F., Covariance recovery from a square root information matrix for data association (2009) Journal of Robotics and Autonomous Systems, 57, pp. 1198-1210; Kim, A., Eustice, R., Combined visually and geometrically informative link hypothesis for pose-graph visual SLAM using bag-of-words (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1647-1654. , San Francisco, CA; Kollar, T., Roy, N., Efficient optimization of information-theoretic exploration in slam (2008) Proceedings of the National Conference on Artificial Intelligence (AAAI), pp. 1369-1375. , Chicago, IL; Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to realtime visual mappping (2008) IEEE Transactions on Robotics, 24, pp. 1066-1077; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1156-1163. , St. Louis, MO, USA; Krause, A., Guestrin, C., Near-optimal nonmyopic value of information in graphical models (2005) Proceedings of Uncertainty in Artificial Intelligence (UAI); Kretzschmar, H., Stachniss, C., Grisetti, G., Efficient information-theoretic graph pruning for graph-based SLAM with laser range finders (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 865-871. , San Francisco, CA, USA; Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Autonomous Robots, 4, pp. 333-349; MacKay, D., (2003) Information Theory, Inference, and Learning Algorithms, , Cambridge: Cambridge University Press; Ni, K., Steedly, D., Dellaert, F., Tectonic SAM: Exact, out-of-core, submap-based SLAM (2007) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 1678-1685. , Rome, Italy; Olson, E., (2008) Robust and Efficient Robotic Mapping, , Ph.D. thesis, MIT, Cambridge, MA, USA; Olson, E., Real-time correlative scan matching (2009) Proceedings of the IEEE International Conference on Robotics & Automation (ICRA), pp. 4387-4393. , Kobe, Japan; Snavely, N., Seitz, S., Szeliski, R., Skeletal graphs for efficient structure from motion (2008) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1-8. , Anchorage, AK; Stachniss, C., Grisetti, G., Burgard, W., (2005) Proceedings of Robotics: Science and Systems (RSS), pp. 65-72. , Cambridge, MA, USA; Stachniss, C., Kretzschmar, H., Pose graph compression for laser-based SLAM (2011) Proceedings of the International Symposium of Robotics Research (ISRR), , Flagstaff, AZ, USA},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866286835&doi=10.1177%2f0278364912455072&partnerID=40&md5=435ef5d0fe3199d837c8d6347c9717d9},
}

@article{kretzschmar-et-al:2010:2,
  author = {H. Kretzschmar and G. Grisetti and C. Stachniss},
  journal = {KI - Kunstliche Intelligenz},
  title = {Lifelong Map Learning for Graph-based SLAM in Static Environments},
  volume = {24},
  number = {3},
  pages = {199--206},
  doi = {10.1007/s13218-010-0034-2},
  note = {cited By 14},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  year = {2010},
  abbrev_source_title = {KI - Kunstl. Intell.},
  abstract = {In this paper, we address the problem of lifelong map learning in static environments with mobile robots using the graph-based formulation of the simultaneous localization and mapping problem. The pose graph, which stores the poses of the robot and spatial constraints between them, is the central data structure in graph-based SLAM. The size of the pose graph has a direct influence on the runtime and the memory complexity of the SLAM system and typically grows over time. A robot that performs lifelong mapping in a bounded environment has to limit the memory and computational complexity of its mapping system. We present a novel approach to prune the pose graph so that it only grows when the robot acquires relevant new information about the environment in terms of expected information gain. As a result, our approach scales with the size of the environment and not with the length of the trajectory, which is an important prerequisite for lifelong map learning. The experiments presented in this paper illustrate the properties of our method using real robots. © 2010, Springer-Verlag.},
  affiliation = {Department of Computer Science, University of Freiburg, Georges-Koehler-Allee 79, Freiburg, 79110, Germany},
  author_keywords = {Expected information gain;  Mapping;  SLAM},
  correspondence_address1 = {Kretzschmar, H.; Department of Computer Science, Georges-Koehler-Allee 79, Germany; email: kretzsch@informatik.uni-freiburg.de},
  document_type = {Article},
  funding_details = {European CommissionEuropean Commission, EC, FP7-ICT-231888-EUROPA},
  funding_text1 = {We would like to thank Dirk Hähnel for providing the Intel Research Lab dataset. This work has partly been supported by the German Research Foundation (DFG) under contract number SFB/TR-8 and by the European Commission under contract number FP7-ICT-231888-EUROPA.},
  issn = {09331875},
  keywords = {Robotics;  Robots, Expected information gain;  Expected informations;  Graph-based;  Information gain;  Map learning;  Runtimes;  Simultaneous localization and mapping problems;  SLAM;  Spatial constraints;  Static environment, Mapping},
  language = {English},
  references = {Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Proc of Robotics: Science and Systems (RSS), pp. 17-24; Duckett, T., Marsland, S., Shapiro, J., Fast, on-line learning of globally consistent maps (2002) Auton Robots, 12 (3), pp. 287-300; Eustice, R., Singh, H., Leonard, J., Exactly sparse delayed-state filters (2005) Proc of the IEEE Int Conf on Robotics & Automation (ICRA, pp. 2428-2435. , In,); Eustice, R., Singh, H., Leonard, J., Exactly sparse delayed-state filters for view-based SLAM (2006) IEEE Trans Robot, 22 (6), pp. 1100-1114; Folkesson, J., Christensen, H., Graphical slam—a self-correcting map (2004) Proc of the IEEE Int Conf on Robotics & Automation (ICRA), , In; Frese, U., Larsson, P., Duckett, T., A multilevel relaxation algorithm for simultaneous localisation and mapping (2005) IEEE Trans Robot, 21 (2), pp. 1-12; Garrison, W.L., Marble, D.F., (1965) A Prolegomenon to the Forecasting of Transportation Development. United States Army Aviation Material Labs Technical Report, , Office of Technical Services, United States Department of Commerce; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-blackwellized particle filters (2007) IEEE Trans Robot, 23 (1), pp. 34-46; Grisetti, G., Stachniss, C., Grzonka, S., Burgard, W., (2007) A tree parameterization for efficiently computing maximum likelihood maps using gradient descent, , Proc of robotics: science and systems (RSS); Grisetti, G., Rizzini, D.L., Stachniss, C., Olson, E., Burgard, W., (2008) Online Constraint Network Optimization for Efficient Maximum Likelihood Map Learning, , In, Proc of the IEEE int conf on robotics & automation (ICRA; Julier, S., Uhlmann, J., Durrant-Whyte, H., A new approach for filtering nonlinear systems (1995) Proc of the American Control Conference, pp. 1628-1632; Konolige, K., Agrawal, M., Frameslam: from bundle adjustment to real-time visual mapping (2008) IEEE Trans Robot, 24 (5), pp. 1066-1077; Leonard, J., Durrant-Whyte, H., Mobile robot localization by tracking geometric beacons (1991) IEEE Trans Robot Automat, 7 (4), pp. 376-382; Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Auton Robots, 4, pp. 333-349; Montemerlo, M., Thrun, S., Simultaneous localization and mapping with unknown data association using FastSLAM (2003) Proc of the IEEE Int Conf on Robotics & Automation (ICRA), pp. 1985-1991; Moravec, H., Elfes, A., High resolution maps from wide angle sonar (1985) Proc of the IEEE Int Conf on Robotics & Automation (ICRA, pp. 116-121. , St Louis, MO, USA; Olson, E., (2008) Robust and efficient robotic mapping. PhD thesis, , MIT, Cambridge: MA, USA; Olson, E., Walter, M., Leonard, J., Teller, S., Single cluster graph partitioning for robotics applications (2005) Proceedings of Robotics Science and Systems, pp. 265-272; Olson, E., Leonard, J., Teller, S., Fast iterative optimization of pose graphs with poor initial estimates (2006) Proc of the IEEE Int Conf on Robotics & Automation (ICRA), pp. 2262-2269; Stachniss, C., Burgard, W., Mobile robot mapping and localization in non-static environments (2005) Proc of the National Conference on Artificial Intelligence (AAAI), pp. 1324-1329; Stachniss, C., Grisetti, G., Burgard, W., Information gain-based exploration using Rao-blackwellized particle filters (2005) Proc of Robotics: Science and Systems (RSS), pp. 65-72. , Cambridge, MA, USA; Thrun, S., Montemerlo, M., The graph SLAM algorithm with applications to large-scale mapping of urban structures (2006) Int J Robot Res, 25 (5-6), p. 403; Thrun, S., Liu, Y., Koller, D., Ng, A., Ghahramani, Z., Durrant-Whyte, H., Simultaneous localization and mapping with sparse extended information filters (2004) Int J Robot Res, 23 (78), pp. 693-716; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic robotics, , MIT Press, Cambridge; Tipaldi, G.D., Grisetti, G., Burgard, W., Approximated covariance estimation in graphical approaches to slam (2007) Proc of the IEEE/RSJ Int Conf on Intelligent Robots and Systems (IROS)},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651515765&doi=10.1007%2fs13218-010-0034-2&partnerID=40&md5=6949e57ee281b8072eb6ad7690e3eaf6},
}

@conference{thomas-et-al:2021:9561701,
  author = {H. Thomas and B. Agro and M. Gridseth and J. Zhang and T. D. Barfoot},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation},
  volume = {2021-May},
  pages = {14047--14053},
  doi = {10.1109/ICRA48506.2021.9561701},
  note = {cited By 0; Conference of 2021 IEEE International Conference on Robotics and Automation, ICRA 2021 ; Conference Date: 30 May 2021 Through 5 June 2021;  Conference Code:177050},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {We present a self-supervised learning approach for the semantic segmentation of lidar frames. Our method is used to train a deep point cloud segmentation architecture without any human annotation. The annotation process is automated with the combination of simultaneous localization and mapping (SLAM) and ray-tracing algorithms. By performing multiple navigation sessions in the same environment, we are able to identify permanent structures, such as walls, and disentangle short-term and long-term movable objects, such as people and tables, respectively. New sessions can then be performed using a network trained to predict these semantic labels. We demonstrate the ability of our approach to improve itself over time, from one session to the next. With semantically filtered point clouds, our robot can navigate through more complex scenarios, which, when added to the training pool, help to improve our network predictions. We provide insights into our network predictions and show that our approach can also improve the performances of common localization techniques. © 2021 IEEE},
  affiliation = {University of Toronto Institute for Aerospace Studies (UTIAS), 4925 Dufferin StON, Canada; Apple Inc.},
  coden = {PIIAE},
  document_type = {Conference Paper},
  isbn = {9781728190778},
  issn = {10504729},
  language = {English},
  references = {Thomas, H., Qi, C.R., Deschaud, J.-E., Marcotegui, B., Goulette, F., Guibas, L.J., KPConv: Flexible and deformable convolution for point clouds (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 6411-6420; Sofman, B., Lin, E., Bagnell, J.A., Cole, J., Vandapel, N., Stentz, A., Improving robot navigation through self-supervised online learning (2006) Journal of Field Robotics, 23 (11-12), pp. 1059-1075; Lookingbill, A., Rogers, J., Lieb, D., Curry, J., Thrun, S., Reverse optical flow for self-supervised adaptive autonomous robot navigation (2007) International Journal of Computer Vision, 74 (3), pp. 287-302; Hadsell, R., Sermanet, P., Ben, J., Erkan, A., Scoffier, M., Kavukcuoglu, K., Muller, U., LeCun, Y., Learning long-range vision for autonomous off-road driving (2009) Journal of Field Robotics, 26 (2), pp. 120-144; Brooks, C.A., Iagnemma, K., Self-supervised terrain classification for planetary surface exploration rovers (2012) Journal of Field Robotics, 29 (3), pp. 445-468; Ridge, B., Leonardis, A., Ude, A., Deniša, M., Skočaj, D., Self-supervised online learning of basic object push affordances (2015) International Journal of Advanced Robotic Systems, 12 (3), p. 24; Nava, M., Guzzi, J., Chavez-Garcia, R.O., Gambardella, L.M., Giusti, A., Learning long-range perception using self-supervision from short-range sensors and odometry (2019) IEEE Robotics and Automation Letters, 4 (2), pp. 1279-1286; Zhang, L., Wei, L., Shen, P., Wei, W., Zhu, G., Song, J., Semantic slam based on object detection and improved octomap (2018) IEEE Access, 6, pp. 75545-75559; Wang, K., Lin, Y., Wang, L., Han, L., Hua, M., Wang, X., Lian, S., Huang, B., A unified framework for mutual improvement of slam and semantic segmentation (2019) 2019 International Conference on Robotics and Automation (ICRA), pp. 5224-5230; Chen, X., Milioto, A., Palazzolo, E., Giguère, P., Behley, J., Stachniss, C., SUMA++: Efficient lidar-based semantic slam (2019) 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4530-4537; Sun, L., Yan, Z., Zaganidis, A., Zhao, C., Duckett, T., Recurrent-octomap: Learning state-based map refinement for long-term semantic mapping with 3-d-lidar data (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 3749-3756; Dewan, A., Oliveira, G.L., Burgard, W., Deep semantic classification for 3d lidar data (2017) 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3544-3549; Biswas, J., Veloso, M., Episodic non-markov localization: Reasoning about short-term and long-term features (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3969-3974; Pomerleau, F., Colas, F., Siegwart, R., Magnenat, S., Comparing icp variants on real-world data sets (2013) Autonomous Robots, 34 (3), pp. 133-148; Zhang, J., Singh, S., LoaM: Lidar odometry and mapping in real-time (2014) Robotics: Science and Systems, 2 (9); Mendes, E., Koch, P., Lacroix, S., Icp-based pose-graph slam (2016) 2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR), pp. 195-200; Deschaud, J.-E., Imls-slam: Scan-to-model matching based on 3d data (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 2480-2485; Moravec, H., Elfes, A., High resolution maps from wide angle sonar (1985) Proceedings. 1985 IEEE International Conference on Robotics and Automation, 2, pp. 116-121; Izadi, S., Kim, D., Hilliges, O., Molyneaux, D., Newcombe, R., Kohli, P., Shotton, J., Davison, A., KinectFusion: Real-time 3d reconstruction and interaction using a moving depth camera (2011) Proceedings of the 24th Annual ACM Symposium on User Interface Software and Technology, pp. 559-568; Hornung, A., Wurm, K.M., Bennewitz, M., Stachniss, C., Burgard, W., OctoMap: An efficient probabilistic 3d mapping framework based on octrees (2013) Autonomous Robots, 34 (3), pp. 189-206; Pomerleau, F., Krüsi, P., Colas, F., Furgale, P., Siegwart, R., Long-term 3d map maintenance in dynamic environments (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3712-3719; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Communications of the ACM, 24 (6), pp. 381-395; Fox, D., Adapting the sample size in particle filters through kldsampling (2003) The International Journal of Robotics Research, 22 (12), pp. 985-1003; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46},
  source = {Scopus},
  sponsors = {Baidu; Biomimetic Intelligence and Robotics; dji; et al.; Mech Mind Robotics Technologies; Toyota Research Institute},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114148382&doi=10.1109%2fICRA48506.2021.9561701&partnerID=40&md5=319ae684d1faab8fe3c8c5e2f0af2aa9},
}

@article{yin-et-al:2021:661199,
  author = {H. Yin and X. Xu and Y. Wang and R. Xiong},
  journal = {Frontiers in Robotics and AI},
  title = {Radar-to-Lidar: Heterogeneous Place Recognition via Joint Learning},
  volume = {8},
  pages = {661199},
  doi = {10.3389/frobt.2021.661199},
  note = {cited By 2},
  publisher = {Frontiers Media S.A.},
  year = {2021},
  abbrev_source_title = {Front. Robot. AI},
  abstract = {Place recognition is critical for both offline mapping and online localization. However, current single-sensor based place recognition still remains challenging in adverse conditions. In this paper, a heterogeneous measurement based framework is proposed for long-term place recognition, which retrieves the query radar scans from the existing lidar (Light Detection and Ranging) maps. To achieve this, a deep neural network is built with joint training in the learning stage, and then in the testing stage, shared embeddings of radar and lidar are extracted for heterogeneous place recognition. To validate the effectiveness of the proposed method, we conducted tests and generalization experiments on the multi-session public datasets and compared them to other competitive methods. The experimental results indicate that our model is able to perform multiple place recognitions: lidar-to-lidar (L2L), radar-to-radar (R2R), and radar-to-lidar (R2L), while the learned model is trained only once. We also release the source code publicly: https://github.com/ZJUYH/radar-to-lidar-place-recognition. © Copyright © 2021 Yin, Xu, Wang and Xiong.},
  affiliation = {Institute of Cyber-Systems and Control, College of Control Science and Engineering, Zhejiang University, Hangzhou, China},
  art_number = {661199},
  author_keywords = {deep neural network;  heterogeneous measurements;  lidar;  mobile robot;  place recognition;  radar},
  correspondence_address1 = {Wang, Y.; Institute of Cyber-Systems and Control, China; email: ywang24@zju.edu.cn},
  document_type = {Article},
  funding_details = {National Key Research and Development Program of ChinaNational Key Research and Development Program of China, NKRDPC, 2020YFB1313300},
  funding_text1 = {This work was supported by the National Key R&D Program of China under grant 2020YFB1313300.},
  issn = {22969144},
  language = {English},
  references = {Adolfsson, D., Lowry, S., Magnusson, M., Lilienthal, A., Andreasson, H., submap per perspective-selecting subsets for super mapping that afford superior localization quality (2019) 2019 European Conference on Mobile Robots (ECMR), pp. 1-7. , Prague, IEEE; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., Netvlad: Cnn architecture for weakly supervised place recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5297-5307. , Las Vegas, NV, 28622667; Barnes, D., Gadd, M., Murcutt, P., Newman, P., Posner, I., The oxford radar robotcar dataset: a radar extension to the oxford robotcar dataset (2020) 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 6433-6438. , a, Paris, IEEE; Barnes, D., Weston, R., Posner, I., Masking by moving: learning distraction-free radar odometry from pose information (2020) Conference on Robot Learning, pp. 303-316. , b, Osaka, PMLR; Bay, H., Tuytelaars, T., Van Gool, L., Surf: speeded up robust features (2006) European Conference on Computer Vision, pp. 404-417. , Graz, Springer; Bosse, M., Zlot, R., Place recognition using keypoint voting in large 3d lidar datasets (2013) 2013 IEEE International Conference on Robotics and Automation, pp. 2677-2684. , Karlsruhe, IEEE; Carballo, A., Lambert, J., Monrroy, A., Wong, D., Narksri, P., Kitsukawa, Y., Libre: the multiple 3d lidar dataset (2020) 2020 IEEE Intelligent Vehicles Symposium (IV), , Las Vegas, NV, IEEE; Cattaneo, D., Vaghi, M., Fontana, S., Ballardini, A.L., Sorrenti, D.G., Global visual localization in lidar-maps through shared 2d-3d embedding space (2020) 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 4365-4371. , Paris, IEEE; Cen, S.H., Newman, P., Precise ego-motion estimation with millimeter-wave radar under diverse and challenging conditions (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 6045-6052. , Brisbane, QLD, IEEE; Chen, X., Läbe, T., Milioto, A., Röhling, T., Vysotska, O., Haag, A., Overlapnet: loop closing for lidar-based slam (2020) Proc. of Robotics: Science and Systems (RSS), , Corvallis, OR, in; Cummins, M., Newman, P., Fab-map: probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res, 27, pp. 647-665; Ding, X., Wang, Y., Xiong, R., Li, D., Tang, L., Yin, H., Persistent stereo visual localization on cross-modal invariant map (2019) IEEE Trans. Intell. Transport. Syst, 21, pp. 4646-4658; Dubé, R., Cramariuc, A., Dugas, D., Sommer, H., Dymczyk, M., Nieto, J., Segmap: segment-based mapping and localization using data-driven descriptors (2020) Int. J. Robot. Res, 39, pp. 339-355; Elhousni, M., Huang, X., A survey on 3d lidar localization for autonomous vehicles (2020) 2020 IEEE Intelligent Vehicles Symposium (IV), pp. 1879-1884. , Las Vegas, NV, IEEE; Feng, M., Hu, S., Ang, M.H., Lee, G.H., 2d3d-matchnet: learning to match keypoints across 2d image and 3d point cloud (2019) 2019 International Conference on Robotics and Automation (ICRA), pp. 4790-4796. , Montreal, QC, IEEE; Filliat, D., A visual bag of words method for interactive qualitative localization and mapping (2007) Proceedings 2007 IEEE International Conference on Robotics and Automation, pp. 3921-3926. , Roma, IEEE; Gadd, M., De Martini, D., Newman, P., Look around you: sequence-based radar place recognition with learned rotational invariance (2020) 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), pp. 270-276. , Portland, OR; Granström, K., Schön, T.B., Nieto, J.I., Ramos, F.T., Learning to close loops from range data (2011) Int. J. Robot. Res, 30, pp. 1728-1754; He, L., Wang, X., Zhang, H., M2dp: a novel 3d point cloud descriptor and its application in loop closure detection (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 231-237. , Daejeon, IEEE; Hong, Z., Petillot, Y., Wang, S., Radarslam: radar based large-scale slam in all weathers (2020) 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), , Las Vegas, NV, in; Jégou, H., Douze, M., Schmid, C., Pérez, P., Aggregating local descriptors into a compact image representation (2010) 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 3304-3311. , San Francisco, CA, IEEE; Kim, G., Kim, A., Scan context: egocentric spatial descriptor for place recognition within 3d point cloud map (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4802-4809. , Madrid, IEEE; Kim, G., Park, Y.S., Cho, Y., Jeong, J., Kim, A., Mulran: multimodal range dataset for urban place recognition (2020) IEEE International Conference on Robotics and Automation (ICRA), , Las Vegas, NV, in; Kingma, D.P., Ba, J., Adam: a method for stochastic optimization (2015) Proceedings of the 3rd International Conference on Learning Representations (ICLR), , San Diego, CA, in; Krstanovic, C., Keller, S., Groft, E., (2012) Radar Vehicle Detection System, , US Patent 8,279,107; Latif, Y., Garg, R., Milford, M., Reid, I., Addressing challenging place recognition tasks using generative adversarial networks (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 2349-2355. , Brisbane, QLD, IEEE; Le Gentil, C., Vayugundla, M., Giubilato, R., Vidal-Calleja, T., Triebel, R., Gaussian process gradient maps for loop-closure detection in unstructured planetary environments (2020) 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), , Las Vegas, NV, in; Li, L., Yang, M., Wang, B., Wang, C., An overview on sensor map based localization for automated driving (2017) 2017 Joint Urban Remote Sensing Event (JURSE), pp. 1-4. , Dubai, IEEE; Liu, Z., Zhou, S., Suo, C., Yin, P., Chen, W., Wang, H., Lpd-net: 3d point cloud learning for large-scale place recognition and environment analysis (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 2831-2840. , Seoul; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Visual place recognition: a survey (2015) IEEE Trans. Robot, 32, pp. 1-19; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: the oxford robotcar dataset (2017) Int. J. Robot. Res, 36, pp. 3-15; Milford, M.J., Wyeth, G.F., Seqslam: visual route-based navigation for sunny summer days and stormy winter nights (2012) 2012 IEEE International Conference on Robotics and Automation, pp. 1643-1649. , St Paul, MN, IEEE; Pan, Y., Xu, X., Li, W., Wang, Y., Xiong, R., Coral: colored structural representation for bi-modal place recognition (2020) arXiv [Preprint].arXiv:2011.10934; Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Pytorch: an imperative style, high-performance deep learning library (2019) Advances in Neural Information Processing Systems, pp. 8026-8037. , Vancouver, BC; Ronneberger, O., Fischer, P., Brox, T., U-net: convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-Assisted Intervention, pp. 234-241. , Munich, Springer; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., Orb: an efficient alternative to sift or surf (2011) 2011 International Conference on Computer Vision, pp. 2564-2571. , Barcelona, IEEE; Săftescu, Ş., Gadd, M., De Martini, D., Barnes, D., Newman, P., Kidnapped radar: topological radar localisation using rotationally-invariant metric learning (2020) 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 4358-4364. , Paris, IEEE; Sun, L., Adolfsson, D., Magnusson, M., Andreasson, H., Posner, I., Duckett, T., Localising faster: efficient and precise lidar-based robot localisation in large-scale environments (2020) 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 4386-4392. , Paris, IEEE; Tang, T.Y., De Martini, D., Barnes, D., Newman, P., Rsl-net: localising in satellite images from a radar on the ground (2020) IEEE Robot. Autom. Lett, 5, pp. 1087-1094; Uy, M.A., Lee, G.H., Pointnetvlad: deep point cloud based retrieval for large-scale place recognition (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4470-4479. , Salt Lake City, UT; Wang, Y., Sun, Z., Xu, C.-Z., Sarma, S., Yang, J., Kong, H., Lidar iris for loop-closure detection (2019) arXiv [Preprint].arXiv:1912.03825; Xie, S., Pan, C., Peng, Y., Liu, K., Ying, S., Large-scale place recognition based on camera-lidar fused descriptor (2020) Sensors, 20, p. 2870. , 32438550; Xu, X., Yin, H., Chen, Z., Li, Y., Wang, Y., Xiong, R., DiSCO: differentiable scan context with orientation (2021) IEEE Robot. Autom. Lett, 6, pp. 2791-2798; Yin, H., Chen, R., Wang, Y., Xiong, R., Rall: end-to-end radar localization on lidar map using differentiable measurement model (2021) IEEE Trans. Intell. Transport. Syst, , [Epub ahead of print]; Yin, H., Ding, X., Tang, L., Wang, Y., Xiong, R., Efficient 3d lidar based loop closing using deep neural network (2017) 2017 IEEE International Conference on Robotics and Biomimetics (ROBIO), pp. 481-486. , Macau, IEEE; Yin, H., Wang, Y., Ding, X., Tang, L., Huang, S., Xiong, R., 3d lidar-based global localization using siamese neural network (2019) IEEE Trans. Intell. Transport. Syst, 21, pp. 1380-1392; Yin, H., Wang, Y., Tang, L., Xiong, R., Radar-on-lidar: metric radar localization on prior lidar maps (2020) 2020 IEEE International Conference on Real-time Computing and Robotics (RCAR), , Asahikawa, IEEE; Zhang, X., Wang, L., Su, Y., Visual place recognition: A survey from deep learning perspective (2020) Pattern Recognit, 113, p. 107760},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107035661&doi=10.3389%2ffrobt.2021.661199&partnerID=40&md5=c02d4e877a05b938257508b780e718e8},
}

@article{yin-et-al:2020:2905046,
  author = {H. Yin and Y. Wang and X. Ding and L. Tang and S. Huang and R. Xiong},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  title = {3D LiDAR-Based Global Localization Using Siamese Neural Network},
  volume = {21},
  number = {4},
  pages = {1380--1392},
  doi = {10.1109/TITS.2019.2905046},
  note = {cited By 18},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {IEEE Trans. Intell. Transp. Syst.},
  abstract = {Global localization in 3D point clouds is a challenging task for mobile vehicles in outdoor scenarios, which requires the vehicle to localize itself correctly in a given map without prior knowledge of its pose. This is a critical component of autonomous vehicles or robots on the road for handling localization failures. In this paper, based on reduced dimension scan representations learned from neural networks, a solution to global localization is proposed by achieving place recognition first and then metric pose estimation in the global prior map. Specifically, we present a semi-handcrafted feature learning method for 3D Light detection and ranging (LiDAR) point clouds using artificial statistics and siamese network, which transforms the place recognition problem into a similarity modeling problem. Additionally, the sensor data using dimension reduced representations require less storage space and make the searching easier. With the learned representations by networks and the global poses, a prior map is built and used in the localization framework. In the localization step, position only observations obtained by place recognition are used in a particle filter algorithm to achieve precise pose estimation. To demonstrate the effectiveness of our place recognition and localization approach, KITTI benchmark and our multi-session datasets are employed for comparison with other geometric-based algorithms. The results show that our system can achieve both high accuracy and efficiency for long-term autonomy. © 2000-2011 IEEE.},
  affiliation = {State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, 310058, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, 310058, China; Joint Centre for Robotics Research between, Zhejiang University, Hangzhou, 310058, China; University of Technology Sydney, Sydney, NSW  2007, Australia; Center for Autonomous Systems (CAS), University of Technology Sydney, Sydney, NSW  2007, Australia},
  art_number = {8734150},
  author_keywords = {global localization;  Mobile vehicles;  place recognition;  siamese network},
  correspondence_address1 = {Wang, Y.; State Key Laboratory of Industrial Control and Technology, China; email: wangyue@iipc.zju.edu.cn},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, U1609210},
  funding_text1 = {This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFB1300400 and in part by the National Nature Science Foundation of China Grant U1609210.},
  funding_text2 = {Manuscript received July 24, 2018; revised January 5, 2019 and February 28, 2019; accepted March 11, 2019. Date of publication June 10, 2019; date of current version March 27, 2020. This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFB1300400 and in part by the National Nature Science Foundation of China Grant U1609210. The Associate Editor for this paper was L. M. Bergasa. (Corresponding author: Yue Wang.) H. Yin, Y. Wang, X. Ding, L. Tang, and R. Xiong are with the State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou 310058, China, and with the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou 310058, China, and also with the Joint Centre for Robotics Research between Zhejiang University, Hangzhou 310058, China, and the University of Technology Sydney, Sydney, NSW 2007, Australia (e-mail: wangyue@iipc.zju.edu.cn).},
  issn = {15249050},
  keywords = {Digital storage;  Learning systems;  Road vehicles, Critical component;  Feature learning;  Global localization;  Light detection and ranging;  Mobile vehicle;  Place recognition;  Reduced representation;  Similarity models, Optical radar},
  language = {English},
  references = {Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2D LIDAR SLAM (2016) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 1271-1278. , May; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665. , Jun; Li, B., 3D fully convolutional network for vehicle detection in point cloud (2017) Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst. (IROS), pp. 1513-1518. , Sep; Rozsa, Z., Sziranyi, T., Obstacle prediction for automated guided vehicles based on point clouds measured by a tilted lidar sensor (2018) IEEE Trans. Intell. Transp. Syst., 19 (8), pp. 2708-2720. , Aug; Steder, B., Ruhnke, M., Grzonka, S., Burgard, W., Place recognition in 3D scans using a combination of bag of words and point feature based relative pose estimation (2011) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 1249-1255. , Sep; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 4297-4304. , Sep. /Oct; Röhling, T., Mack, J., Schulz, D., A fast histogram-based similarity measure for detecting loop closures in 3-D LIDAR data (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 736-741. , Sep. /Oct; Dubé, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., Segmatch: Segment based place recognition in 3D point clouds (2017) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 5266-5272. , May/Jun; Bosse, M., Zlot, R., Place recognition using keypoint voting in large 3D lidar datasets (2013) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 2677-2684. , May; Rusu, R.B., Blodow, N., Beetz, M., Fast point feature histograms (FPFH) for 3D registration (2009) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 3212-3217. , May; Tombari, F., Salti, S., Stefano, L.D., A combined texture-shape descriptor for enhanced 3D feature matching (2011) Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 809-812. , Sep; Pomerleau, F., Colas, F., Siegwart, R., A review of point cloud registration algorithms for mobile robotics (2015) Found. Trends Robot., 4 (1), pp. 1-104. , May; Yang, J., Li, H., Campbell, D., Jia, Y., Go-ICP: A globally optimal solution to 3D ICP point-set registration (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (11), pp. 2241-2254. , Nov; Yin, H., Tang, L., Ding, X., Wang, Y., Xiong, R., LocNet: Global localization in 3D point clouds for mobile vehicles (2018) Proc. IEEE Intell. Veh. Symp. (IV), pp. 728-733. , Jun; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 1643-1649. , May; Naseer, T., Burgard, W., Stachniss, C., Robust visual localization across seasons (2018) IEEE Trans. Robot., 34 (2), pp. 289-302. , Apr; Filliat, D., A visual bag of words method for interactive qualitative localization and mapping (2007) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 3921-3926. , Apr; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Proc. AAAI Conf. Artif. Intell. (AAAI), pp. 2564-2570. , Jun; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 90-97. , May; Fernández-Moral, E., Mayol-Cuevas, W., Arévalo, V., González-Jiménez, J., Fast place recognition with plane-based maps (2013) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 2719-2724. , May; Johnson, A.E., Hebert, M., Using spin images for efficient object recognition in cluttered 3D scenes (1999) IEEE Trans. Pattern Anal. Mach. Intell., 21 (5), pp. 433-449. , May; Wohlkinger, W., Vincze, M., Ensemble of shape functions for 3D object classification (2011) Proc. IEEE Int. Conf. Robot. Biomimetics (ROBIO), pp. 2987-2992. , Dec; Belongie, S., Malik, J., Puzicha, J., Shape matching and object recognition using shape contexts (2002) IEEE Trans. Pattern Anal. Mach. Intell., 24 (4), pp. 509-522; Frome, A., Huber, D., Kolluri, R., Bülow, T., Malik, J., Recognizing objects in range data using regional point descriptors (2004) Proc. Eur. Conf. Comput. Vis. (ECCV), pp. 224-237; Magnusson, M., Andreasson, H., Nuchter, A., Lilienthal, A.J., Appearance-based loop detection from 3D laser data using the normal distributions transform (2009) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 23-28. , May; He, L., Wang, X., Zhang, H., M2DP: A novel 3D point cloud descriptor and its application in loop closure detection (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 231-237. , Oct; Granström, K., Schön, T.B., Nieto, J.I., Ramos, F.T., Learning to close loops from range data (2011) Int. J. Robot. Res., 30 (14), pp. 1728-1754. , Dec; Dellaert, F., Fox, D., Burgard, W., Thrun, S., Monte carlo localization for mobile robots (1999) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 1322-1328. , May; Hata, A.Y., Ramos, F.T., Wolf, D.F., Monte Carlo localization on Gaussian process occupancy maps for urban environments (2017) IEEE Trans. Intell. Transp. Syst., 19 (9), pp. 2839-2902. , Sep; Pomerleau, F., Colas, F., Siegwart, R., Magnenat, S., Comparing ICP variants on real-world data sets (2013) Auton. Robot., 34 (3), pp. 133-148. , Apr; Bromley, J., Guyon, I., LeCun, Y., Säckinger, Y., Shah, R., Signature verification using a 'siamese' time delay neural network (1994) Proc. Adv. Neural Inf. Process. Syst. (NIPS), pp. 737-744; Hadsell, R., Chopra, S., LeCun, Y., Dimensionality reduction by learning an invariant mapping (2006) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 1735-1742. , Jun; Anguelova, M., (2004) Nonlinear Observability and Identifiability: General Theory and A Case Study of A Kinetic Model for S. Cerevisiae, , Ph. D. dissertation, Dept. Math., School Math. Sci., Chalmers Univ. Technol., Gothenburg, Sweden; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3354-3361. , Jun; Tang, L., Wang, Y., Ding, X., Yin, H., Xiong, R., Huang, S., Topological local-metric framework for mobile robots navigation: A long term perspective (2018) Auton. Robot., 43 (1), pp. 197-211. , Jan; Jia, Y., Caffe: Convolutional architecture for fast feature embedding (2014) Proc. ACM Int. Conf. Multimedia (ACMMM), pp. 675-678. , Nov; Kim, G., Kim, A., Scan context: Egocentric spatial descriptor for place recognition within 3D point cloud map (2018) Proc. IEEE/RSJ Int. Conf. Intell. Robot Syst., pp. 4802-4809. , Oct; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2: A general framework for graph optimization (2011) Proc. IEEE Int. Conf. Robot. Autom. (ICRA), pp. 3607-3613. , May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082761003&doi=10.1109%2fTITS.2019.2905046&partnerID=40&md5=e5e8a88c8f1bc504ae85a5c44ab35115},
}

@article{zhang-et-al:2018:1729881418780178,
  author = {H. Zhang and X. Chen and H. Lu and J. Xiao},
  journal = {International Journal of Advanced Robotic Systems},
  title = {Distributed and collaborative monocular simultaneous localization and mapping for multi-robot systems in large-scale environments},
  volume = {15},
  number = {3},
  doi = {10.1177/1729881418780178},
  note = {cited By 10},
  publisher = {SAGE Publications Inc.},
  year = {2018},
  abbrev_source_title = {Int. J. Adv. Rob. Syst.},
  abstract = {In this article, we propose a distributed and collaborative monocular simultaneous localization and mapping system for the multi-robot system in large-scale environments, where monocular vision is the only exteroceptive sensor. Each robot estimates its pose and reconstructs the environment simultaneously using the same monocular simultaneous localization and mapping algorithm. Meanwhile, they share the results of their incremental maps by streaming keyframes through the robot operating system messages and the wireless network. Subsequently, each robot in the group can obtain the global map with high efficiency. To build the collaborative simultaneous localization and mapping architecture, two novel approaches are proposed. One is a robust relocalization method based on active loop closure, and the other is a vision-based multi-robot relative pose estimating and map merging method. The former is used to solve the problem of tracking failures when robots carry out long-term monocular simultaneous localization and mapping in large-scale environments, while the latter uses the appearance-based place recognition method to determine multi-robot relative poses and build the large-scale global map by merging each robot’s local map. Both KITTI data set and our own data set acquired by a handheld camera are used to evaluate the proposed system. Experimental results show that the proposed distributed multi-robot collaborative monocular simultaneous localization and mapping system can be used in both indoor small-scale and outdoor large-scale environments. © 2018, The Author(s) 2018.},
  affiliation = {Department of Automation, National University of Defense Technology, Changsha, China},
  author_keywords = {large-scale SLAM;  monocular SLAM;  Multi-robot collaborative SLAM;  relocalization},
  correspondence_address1 = {Chen, X.; Department of Automation, 137 Yanwachi Street, China; email: chenxieyuanli@hotmail.com},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61503401, 61773393},
  funding_text1 = {The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by National Science Foundation of China (nos 61503401 and 61773393).},
  issn = {17298806},
  keywords = {Conformal mapping;  Industrial robots;  Merging;  Multipurpose robots;  Robot learning;  Robotics;  Vision, Exteroceptive sensor;  large-scale SLAM;  Monocular SLAM;  Multirobots;  Re-localization;  Robot operating system;  Simultaneous localization and mapping;  Simultaneous localization and mapping algorithms, Indoor positioning systems},
  language = {English},
  references = {Williams, B., Klein, G., Reid, I., Automatic relocalization and loop closing for real-time monocular SLAM (2011) IEEE Trans Pattern Anal Mach Intell, 33 (9), pp. 1699-1712; Feng, Y., Wu, Y., Fan, L., Online learning of binary feature indexing for real-time SLAM relocalization Asian conference on computer vision, pp. 206-217. , Springer, In; Straub, J., Hilsenbeck, S., Schroth, G., Fast relocalization for visual odometry using binary features, pp. 2548-2552. , 2013 20th IEEE international conference on image processing (ICIP), Melbourne, VIC, Australia, IEEE, In; Strasdat, H., Davison, A.J., Montiel, J.M., Double window optimisation for constant time visual SLAM, pp. 2352-2359. , 2011 IEEE international conference on computer vision (ICCV), Barcelona, Spain, IEEE, In; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: a versatile and accurate monocular SLAM system (2015) IEEE Trans Robot, 31 (5), pp. 1147-1163; Saeedi, S., Trentini, M., Seto, M., Multiple-robot simultaneous localization and mapping: a review (2016) J Field Rob, 33 (1), pp. 3-46; Davison, A.J., Real-time simultaneous localisation and mapping with a single camera, 2, p. 1403. , http://dl.acm.org/citation.cfm?id=946247.946734, Proceedings of the ninth IEEE international conference on computer vision, ICCV ’03, Washington, DC, USA, IEEE Computer Society,, In:,., p; Eade, E., Drummond, T., Monocular SLAM as a graph of coalesced observations, pp. 1-8. , ICCV 2007. IEEE 11th international conference on computer vision, Rio de Janeiro, Brazil, IEEE, In; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: large-scale direct monocular SLAM European conference on computer vision, pp. 834-849. , Springer, In; Newcombe, R.A., Lovegrove, S.J., Davison, A.J., DTAM: dense tracking and mapping in real-time, pp. 2320-2327. , 2011 IEEE international conference on computer vision (ICCV), Barcelona, Spain, IEEE, In; Engel, J., Koltun, V., Cremers, D., Direct sparse odometry (2018) IEEE Trans Pattern Anal Mach Intell, 40 (3), pp. 611-625; Dellaert, F., Fox, D., Burgard, W., Monte carlo localization for mobile robots. In: 1999 Proceedings, 2, pp. 1322-1328. , IEEE international conference on robotics and automation, Detroit, MI, USA, IEEE, of; Williams, B., Cummins, M., Neira, J., A comparison of loop closing techniques in monocular SLAM (2009) Robot Auto Syst, 57 (12), pp. 1188-1197. , http://www.sciencedirect.com/science/article/pii/S0921889009000876; Clemente, L.A., Davison, A.J., Reid, I.D., Mapping large loops with a single hand-held camera (2007) Robot Sci Syst, p. 2; Reitmayr, G., Drummond, T., Going out: robust model-based tracking for outdoor augmented reality, pp. 109-118. , Proceedings of the 5th IEEE and ACM international symposium on mixed and augmented reality, IEEE Computer Society, In; Klein, G., Murray, D., Improving the agility of keyframe-based SLAM, pp. 802-815. , European conference on computer vision, In; Sivic, J., Zisserman, A., Video Google: a text retrieval approach to object matching in videos null, pp. 1470-1477. , IEEE, In; Eade, E., Drummond, T., Unified loop closing and recovery for real time monocular SLAM (2008) BMVC, 136, p. 13; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int J Comput Vision, 60 (2), pp. 91-110. , https://doi.org/10.1023/B:VISI.0000029664.99615.94; Cummins, M., Newman, P., Appearance-only SLAM at large scale with fab-map 2.0 (2011) Int J Rob Res, 30 (9), pp. 1100-1123. , https://doi.org/10.1177/0278364910385483; Bay, H., Tuytelaars, T., Van Gool, L., speeded up robust features (2006) Comput Vision ECCV, 2006, pp. 404-417. , SURF; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based SLAM, pp. 846-853. , 2014 IEEE international conference on robotics and automation (ICRA), Hong Kong, China, IEEE, In; Rublee, E., Rabaud, V., Konolige, K., ORB: an efficient alternative to SIFT or SURF, pp. 2564-2571. , 2011 IEEE international conference on computer vision (ICCV), Barcelona, Spain, IEEE, In; Pupilli, M., Calway, A., Real-time camera tracking using a particle filter BMVC, , https://doi.org/10.5244/C.19.50; Se, S., Lowe, D.G., Little, J.J., Vision-based global localization and mapping for mobile robots (2005) IEEE Trans Robot, 21 (3), pp. 364-375; Gionis, A., Indyk, P., Motwani, R., Similarity search in high dimensions via hashing (1999) VLDB, 99, pp. 518-529. , http://dl.acm.org/citation.cfm?id=645925.671516; Feder, H.J.S., Leonard, J.J., Smith, C.M., Adaptive mobile robot navigation and mapping (1999) Int J Robot Res, 18 (7), pp. 650-668. , https://doi.org/10.1177/02783649922066484; Rone, W., Ben-Tzvi, P., Mapping, localization and motion planning in mobile multi-robotic systems (2013) Robotica, 31 (1), pp. 1-23; Zhou, X.S., Roumeliotis, S.I., Multi-robot SLAM with unknown initial correspondence: the robot rendezvous case, pp. 1785-1792. , 2006 IEEE/RSJ international conference on intelligent robots and systems, Beijing, China, IEEE, In; Ko, J., Stewart, B., Fox, D., A practical, decision-theoretic approach to multi-robot mapping and exploration, 4, pp. 3232-3238. , 2003.(IROS 2003). Proceedings of 2003 IEEE/RSJ international conference on intelligent robots and systems, Las Vegas, NV, USA, IEEE, In; Fox, D., Ko, J., Konolige, K., Distributed multirobot exploration and mapping (2006) Proc IEEE, 94 (7), pp. 1325-1339; Birk, A., Carpin, S., Merging occupancy grid maps from multiple robots (2006) Proc IEEE, 94 (7), pp. 1384-1397; Indelman, V., Nelson, E., Michael, N., Multi-robot pose graph localization and data association from unknown initial relative poses via expectation maximization, pp. 593-600. , 2014 IEEEinternational conference on robotics and automation (ICRA), Hong Kong, China, IEEE, In; Kim, B., Kaess, M., Fletcher, L., Multiple relative pose graphs for robust cooperative mapping, pp. 3185-3192. , 2010 IEEE international conference on robotics and automation (ICRA), Anchorage, AK, USA, IEEE, In; Dong, J., Nelson, E., Indelman, V., Distributed real-time cooperative localization and mapping using an uncertainty-aware expectation maximization approach, pp. 5807-5814. , 2015 IEEE international conference on robotics and automation (ICRA), Seattle, WA, USA, IEEE, In; Saeedi, S., Paull, L., Trentini, M., Map merging for multiple robots using hough peak matching (2014) Robot Auto Syst, 62 (10), pp. 1408-1424. , http://www.sciencedirect.com/science/article/pii/S0921889014001134; Fox, D., Burgard, W., Kruppa, H., A probabilistic approach to collaborative multi-robot localization (2000) Auton Robot, 8 (3), pp. 325-344. , https://doi.org/10.1023/A:1008937911390; Martinelli, A., Pont, F., Siegwart, R., Multi-robot localization using relative observations, pp. 2797-2802. , ICRA 2005. Proceedings of the 2005 IEEE international conference on robotics and automation, Barcelona, Spain, IEEE, In; Vidal-Calleja, T.A., Berger, C., Solà, J., Large scale multiple robot visual mapping with heterogeneous landmarks in semi-structured terrain (2011) Robot Auto Syst, 59 (9), pp. 654-674. , http://www.sciencedirect.com/science/article/pii/S0921889011000923; Kaess, M., Dellaert, F., Probabilistic structure matching for visual SLAM with a multi-camera rig (2010) Comput Vis Image Underst, 114 (2), pp. 286-296. , http://www.sciencedirect.com/science/article/pii/S1077314209001283; Sola, J., Monin, A., Devy, M., BiCamSLAM: two times mono is more than stereo, pp. 4795-4800. , 2007 IEEE international conference on robotics and automation, Roma, Italy, IEEE, In; Doitsidis, L., Renzaglia, A., Weiss, S., 3D surveillance coverage using maps extracted by a monocular SLAM algorithm, pp. 1661-1667. , 2011 IEEE/RSJ international conference on intelligent robots ansystems (IROS), San Francisco, CA, USA, IEEE, In; Forster, C., Lynen, S., Kneip, L., Collaborative monocular SLAM with multiple micro aerial vehicles, pp. 3962-3970. , 2013 IEEE/RSJ international conference on intelligent robots and systems (IROS), Tokyo, Japan, IEEE, In; Chebrolu, N., Marquez-Gamez, D., Martinet, P., Collaborative visual SLAM framework for a multi-robot system; Schmuck, P., Multi-uav collaborative monocular SLAM, pp. 3863-3870. , 2017 IEEE international conference on robotics and automation (ICRA), Singapore, IEEE, In; Chen, X., Lu, H., Xiao, J., Robust relocalization based on active loop closure for real-time monocular SLAM, pp. 131-143. , 2017 Springer international conference on computer vision systems (ICVS), Springer, In; Chen, X., Zhang, H., Lu, H., Robust SLAM system based on monocular vision and lidar for robotic urban search and rescue, pp. 41-47. , 2017 IEEE international symposium on safety, security and rescue robotics (SSRR), Shanghai, China, IEEE, In; Stachniss, C., Hahnel, D., Burgard, W., Exploration with active loop-closing for fastSLAM, 2, pp. 1505-1510. , 2004.(IROS 2004). Proceedings. 2004 IEEE/RSJ international conference on intelligent robots and systems, Sendai, Japan, IEEE, In; Rahimi, A., Morency, L.P., Darrell, T., Reducing drift in parametric motion tracking, 1, pp. 315-322. , ICCV 2001. Proceedings. Eighth IEEE international conference on computer vision, 2001, Vancouver, BC, Canada, IEEE, In:, ume; Muja, M., Lowe, D.G., Fast approximate nearest neighbors with automatic algorithm configuration (2009) VISAPP (1), 2 (331-340), p. 2; Lepetit, V., Moreno-Noguer, F., Fua, P., an accurate o(n) solution to the pnp problem (2009) Int J Comput Vision, 81 (2), pp. 155-166. , https://doi.org/10.1007/s11263-008-0152-6, Epnp:;; Kümmerle, R., Grisetti, G., Strasdat, H., g2o: a general framework for graph optimization, pp. 3607-3613. , 2011 IEEE international conference on robotics and automation (ICRA), Shanghai, China, IEEE, In; Chen, X., Lu, H., Xiao, J., Distributed monocular multi-robot SLAM, , The 8th Annual IEEE international conference on CYBER technology automation, control, and intelligent systems (IEEE-CYBER), IEEE, In; Galvez-Lpez, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans Robot, 28 (5), pp. 1188-1197; Strasdat, H., Montiel, J., Davison, A.J., Scale drift-aware large scale monocular SLAM (2010) Robot Sci Syst VI, p. 2. , http://www.roboticsproceedings.org/rss06/p10.html; Strasdat, H., Local accuracy and global consistency for efficient SLAM 2012, , https://books.google.com/books?id=4cR4mwEACAAJ; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite, pp. 3354-3361. , 2012 IEEE conference on computer vision and pattern recognition (CVPR), Providence, RI, USA, IEEE, In; Leung, K.Y., Barfoot, T.D., Liu, H.H., Decentralized cooperative SLAM for sparsely-communicating robot networks: a centralized-equivalent approach (2012) J Int Rob Syst, 66 (3), pp. 321-342. , https://doi.org/10.1007/s10846-011-9620-2; Howard, A., Multi-robot simultaneous localization and mapping using particle filters (2005) Proc IEEE, 94 (7), pp. 1360-1369. , https://doi.org/10.1177/0278364906072250},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049965041&doi=10.1177%2f1729881418780178&partnerID=40&md5=6faa9727a648f164c51e1d9cf2506a6d},
}

@article{biswas-veloso:2013:0278364913503892,
  author = {J. Biswas and M. M. Veloso},
  journal = {International Journal of Robotics Research},
  title = {Localization and navigation of the CoBots over long-term deployments},
  volume = {32},
  number = {14},
  pages = {1679--1694},
  doi = {10.1177/0278364913503892},
  note = {cited By 52},
  year = {2013},
  abbrev_source_title = {Int J Rob Res},
  abstract = {For the last three years, we have developed and researched multiple collaborative robots, CoBots, which have been autonomously traversing our multi-floor buildings. We pursue the goal of long-term autonomy for indoor service mobile robots as the ability for them to be deployed indefinitely while they perform tasks in an evolving environment. The CoBots include several levels of autonomy, and in this paper we focus on their localization and navigation algorithms. We present the Corrective Gradient Refinement (CGR) algorithm, which refines the proposal distribution of the particle filter used for localization with sensor observations using analytically computed state space derivatives on a vector map. We also present the Fast Sampling Plane Filtering algorithm that extracts planar regions from depth images in real time. These planar regions are then projected onto the 2D vector map of the building, and along with the laser rangefinder observations, used with CGR for localization. For navigation, we present a hierarchical planner, which computes a topological policy using a graph representation of the environment, computes motion commands based on the topological policy, and then modifies the motion commands to side-step perceived obstacles. We started logging the deployments of the CoBots one and a half years ago, and have since collected logs of the CoBots traversing more than 130 km over 1082 deployments and a total run time of 182 h, which we publish as a dataset consisting of more than 10 million laser scans. The logs show that although there have been continuous changes in the environment, the robots are robust to most of them, and there exist only a few locations where changes in the environment cause increased uncertainty in localization. © The Author(s) 2013.},
  affiliation = {Robotics Institute, School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213-3890, United States; Computer Science Department, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States},
  author_keywords = {autonomous robots;  indoor mobile robots;  Localization;  long-term autonomy;  navigation},
  coden = {IJRRE},
  correspondence_address1 = {Biswas, J.; Robotics Institute, 5000 Forbes Avenue, Pittsburgh, PA 15213-3890, United States; email: joydeepb@cs.cmu.edu},
  document_type = {Article},
  issn = {02783649},
  keywords = {Graph representation;  Hierarchical planners;  Indoor mobile robots;  Localization;  Localization and navigation;  long-term autonomy;  Proposal distribution;  Service mobile robots, Algorithms;  Distributed computer systems;  Motion planning;  Navigation;  Robots;  Target tracking;  Topology;  Vector spaces, Mobile robots},
  language = {English},
  references = {Bailey, T., Durrant-Whyte, H., Simultaneous localization and mapping (slam): Part II (2006) IEEE Robotics & Automation Magazine, 13 (3), pp. 108-117; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots Proceedings of Robotics: Science and Systems (RSS); Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term slam (2009) The International Journal of Robotics Research, 28 (1), pp. 20-33; Biswas, J., Coltin, B., Veloso, M., Corrective gradient refinement for mobile robot localization 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Biswas, J., Veloso, M., Wifi localization and navigation for autonomous indoor mobile robots 2010 IEEE International Conference on Robotics and Automation (ICRA); Biswas, J., Veloso, M., Depth camera based indoor mobile robot localization and navigation 2012 IEEE International Conference on Robotics and Automation (ICRA); Biswas, J., Veloso, M., Multi-sensor mobile robot localization for diverse environments RoboCup 2013: Robot Soccer World Cup XVII; Bruce, J., Zickler, S., Licitra, M., Veloso, M., Cmdragons 2007 team description Proceedings of the 11th International RoboCup Symposium; Buhmann, J., Burgard, W., Cremers, A., Fox, D., Hofmann, T., Schneider, F., Strikos, J., Thrun, S., The mobile robot rhino (1995) AI Magazine, 16 (2), p. 31; Churchill, W., Newman, P., Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation 2012 IEEE International Conference on Robotics and Automation (ICRA); Dayoub, F., Cielniak, G., Duckett, T., Long-term experiments with an adaptive spherical view representation for navigation in changing environments (2011) Robotics and Autonomous Systems, 59 (5), pp. 285-295; Dellaert, F., Fox, D., Burgard, W., Thrun, S., Monte Carlo localization for mobile robots Proceedings of 1999 IEEE International Conference on Robotics and Automation; Doucet, A., De Freitas, N., Murphy, K., Russell, S., Rao-Blackwellised particle filtering for dynamic Bayesian networks Proceedings of the Sixteenth Conference on Uncertainty in Artificial Intelligence; Durrant-Whyte, H., Bailey, T., Simultaneous localization and mapping: Part i (2006) IEEE Robotics & Automation Magazine, 13 (2), pp. 99-110; Elfes, A., Using occupancy grids for mobile robot perception and navigation (1989) Computer, 22 (6), pp. 46-57; Fox, D., KLD-sampling: Adaptive particle filters and mobile robot localization (2001) Advances in Neural Information Processing Systems (NIPS), pp. 713-720; Gordon, N.J., Salmond, D.J., Smith, A.F., Novel approach to nonlinear/non-gaussian bayesian state estimation (1993) IEE Proceedings F (Radar and Signal Processing), 140 (2), pp. 107-113; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Jetto, L., Longhi, S., Venturini, G., Development and experimental validation of an adaptive extended kalman filter for the localization of mobile robots (1999) IEEE Transactions on Robotics and Automation, 15 (2), pp. 219-229; Kalman, R.E., A new approach to linear filtering and prediction problems (1960) Transactions of the ASME - Journal of Basic Engineering, 82, pp. 35-45. , Series D; Koenig, S., Simmons, R., (1998) Artificial Intelligence Based Mobile Robotics: Case Studies of Successful Robot Systems, pp. 91-122. , Kortenkamp RB Murphy R, ed. Cambridge, MA: MIT Press;; Lefebvre, T., Bruyninckx, H., De Schutter, J., Kalman filters for non-linear systems: A comparison of performance (2004) International Journal of Control, 77 (7), pp. 639-653; Lenser, S., Veloso, M., Sensor resetting localization for poorly modelled mobile robots Proceedings of International Conference on Robotics and Automation; Leonard, J., Durrant-Whyte, H., Mobile robot localization by tracking geometric beacons (1991) IEEE Transactions on Robotics and Automation, 7 (3), pp. 376-382; Mendoza, J.P., Veloso, M., Simmons, R., Motion interference detection in mobile robots Proceedings the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '12); Nilsson, N., (1984) Shakey the Robot. Technical Report No. 323, , http://handle.dtic.mil/100.2/ADA458918, DTIC Document; Nourbakhsh, I., Kunz, C., Willeke, T., The Mobot museum robot installations: A five year experiment Proceedings of the 2003 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003); Oyama, A., Konolige, K., Cousins, S., Chitta, S., Conley, K., Bradski, G., Come on in, our community is wide open for robotics research! The 27th Annual Conference of the Robotics Society of Japan; Rosenthal, S., Biswas, J., Veloso, M., An effective personal mobile robot agent through symbiotic human-robot interaction Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems; Rosenthal, S., Veloso, M., Mobile robot planning to seek help with spatially-situated tasks Proceedings of the Twenty-sixth Conference on Artificial Intelligence (AAAI-12); Roumeliotis, S., Bekey, G., Segments: A layered, dual-Kalman filter algorithm for indoor feature extraction Proceedings of 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000); Saarinen, J., Andreasson, H., Lilienthal, A.J., Independent Markov chain occupancy grid maps for representation of dynamic environment Proceedings of 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012); Samadi, M., Kollar, T., Veloso, M., Using the web to interactively learn to find objects Proceedings of the Twenty-sixth Conference on Artificial Intelligence (AAAI-12); Thrun, S., Bennewitz, M., Burgard, W., Cremers, A., Dellaert, F., Fox, D., Hahnel, D., Schulz, D., Minerva: A second-generation museum tour-guide robot Proceedings of 1999 IEEE International Conference on Robotics and Automation; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , Cambridge, MA: MIT Press;; Thrun, S., Montemerlo, M., The graph slam algorithm with applications to large-scale mapping of urban structures (2006) The International Journal of Robotics Research, 25 (56), pp. 403-429; Thrun, S., (2002) Exploring Artificial Intelligence in the New Millennium, pp. 1-35. , Lakemeyer G Nebel B, ed. San Francisco, CA: Morgan Kauffman Publishers;; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph slam: Long-term mapping in low dynamic environments Proceedings of 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2012); Zhang, L., Ghosh, B., Line segment based map building and localization using 2D laser rangefinder Proceedings of International Conference on Robotics and Automation},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892596433&doi=10.1177%2f0278364913503892&partnerID=40&md5=b4ec65b2b0b206ce6f3d978fe1a1d270},
}

@article{biswas-veloso:2017:005,
  author = {J. Biswas and M. M. Veloso},
  journal = {Robotics and Autonomous Systems},
  title = {Episodic non-Markov localization},
  volume = {87},
  pages = {162--176},
  doi = {10.1016/j.robot.2016.09.005},
  note = {cited By 9},
  publisher = {Elsevier B.V.},
  year = {2017},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {Markov localization and its variants are widely used for mobile robot localization. These methods assume Markov independence of observations, implying that the observations can be entirely explained by a map. However, in real human environments, robots frequently make unexpected observations due to unmapped static objects like chairs and tables, and dynamic objects like humans. We therefore introduce Episodic non-Markov Localization (EnML), which reasons about the world as consisting of three classes of objects: long-term features corresponding to permanent mapped objects, short-term features corresponding to unmapped static objects, and dynamic features corresponding to unmapped moving objects. Long-term features are represented by a static map, while short-term features are detected and tracked in real-time. To reason about unexpected observations and their correlations across poses, we augment the Dynamic Bayesian Network for Markov localization to include varying edges and nodes, resulting in a novel Varying Graphical Network representation. The maximum likelihood estimate of the belief is incrementally computed by non-linear functional optimization. By detecting timesteps along the robot's trajectory where unmapped observations prior to such time steps are unrelated to those afterwards, EnML limits the history of observations and pose estimates to “episodes” over which the belief is computed. We demonstrate EnML using different types of sensors including laser rangefinders and depth cameras, and over multiple datasets, comparing it with alternative approaches. We further include results of a team of indoor autonomous service mobile robots traversing hundreds of kilometers using EnML. © 2016 Elsevier B.V.},
  affiliation = {Computer Science Department, Carnegie Mellon UniversityPA, United States; College of Information and Computer Sciences, University of Massachusetts, Amherst, United States},
  author_keywords = {Localization;  Long-term autonomy;  Mapping},
  coden = {RASOE},
  correspondence_address1 = {Biswas, J.; Computer Science Department, United States; email: joydeepb@cs.cmu.edu},
  document_type = {Article},
  funding_details = {National Science FoundationNational Science Foundation, IIS-1012733},
  funding_text1 = {This research was supported by NSF award IIS-1012733 and ONR grant number N00014-09-1-1031 . The views and conclusions contained in this document are those of the authors only. We thank the members of the CORAL group, in particular Brian Coltin, Stephanie Rosenthal, and Richard Wang, for the underlying robot task scheduling, human-robot interaction planning, and data-collection deployments. We also thank Mike Licitra for the design and construction of the CoBot robots. Joydeep Biswas is an Assistant Professor in the College of Information and Computer Sciences at University of Massachusetts Amherst. Prior to joining UMass Amherst, Joydeep was a post-doctoral fellow in the Computer Science Department at Carnegie Mellon University, and before that he earned his Ph.D. in Robotics from the Robotics Institute at Carnegie Mellon University. As a Ph.D. student he was the recipient of the 2015 Siebel Scholarship. See www.cs.umass.edu/ joydeepb/ for further details related to his research on autonomous service mobile robots. Manuela M. Veloso is the Herbert A. Simon University Professor in the Computer Science Department at Carnegie Mellon University. She is the Incoming Head of the Machine Learning Department, and she has courtesy appointments in the Robotics Institute and Electrical and Computer Engineering Department. She researches in Artificial Intelligence, Robotics, and Machine Learning. She founded and directs the CORAL research laboratory, for the study of autonomous agents that Collaborate, Observe, Reason, Act, and Learn, www.cs.cmu.edu/ coral . Professor Veloso is IEEE Fellow, AAAS Fellow, AAAI Fellow, and the past President of AAAI and RoboCup. Professor Veloso and her students research with a variety of autonomous robots, including mobile service robots and soccer robots. See www.cs.cmu.edu/ mmv for further information, including publications.},
  issn = {09218890},
  keywords = {Bayesian networks;  Functions;  Mapping;  Maximum likelihood;  Maximum likelihood estimation;  Mobile robots;  Range finders;  Robot applications, Dynamic Bayesian networks;  Laser range finders;  Localization;  Long-term autonomy;  Markov localizations;  Maximum likelihood estimate;  Mobile robot localization;  Service mobile robots, Robots},
  language = {English},
  references = {Dellaert, F., Fox, D., Burgard, W., Thrun, S., Monte carlo localization for mobile robots (1999) ICRA, 2, pp. 1322-1328; Julier, S.J., Uhlmann, J.K., Unscented filtering and nonlinear estimation (2004) Proc. IEEE, 92 (3), pp. 401-422; Koenig, S., Simmons, R., Xavier: A robot navigation architecture based on partially observable markov decision process models (1998) Artificial Intelligence Based Mobile Robotics: Case Studies of Successful Robot Systems, pp. 91-122; Rosenthal, S., Biswas, J., Veloso, M., An effective personal mobile robot agent through symbiotic human-robot interaction (2010) AAMAS 2010, pp. 915-922; Biswas, J., Coltin, B., Veloso, M., Corrective Gradient Refinement for mobile robot localization (2011) Intelligent Robots and Systems, IROS, 2011 IEEE/RSJ International Conference on, vol. 1, pp. 73-78; Fox, D., (1998) Markov Localization: A Probabilistic Framework for Mobile Robot Localization and Navigation, , Dept. of Computer Science, University of Bonn Germany; Fox, D., Thrun, S., Burgard, W., Dellaert, F., Particle filters for mobile robot localization (2001) Sequential Monte Carlo methods in practice, pp. 499-516; Pearl, J., (1988) Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, , Morgan Kaufmann; Leonard, J.J., Durrant-Whyte, H.F., Cox, I.J., Dynamic map building for an autonomous mobile robot (1992) Int. J. Robot. Res., 11 (4), pp. 286-298; Fox, D., KLD-sampling: Adaptive particle filters and mobile robot localization (2001) Adv. Neural Inf. Process. Syst.; Lenser, S., Veloso, M., Sensor resetting localization for poorly modelled mobile robots (2000) Int. Conf. on Robotics and Automation; Bailey, T., Durrant-Whyte, H., Simultaneous localization and mapping (SLAM): Part II (2006) IEEE Robot. Autom. Mag., 13 (3), pp. 108-117; Durrant-Whyte, H., Bailey, T., Simultaneous localization and mapping: part I (2006) IEEE Robot. Autom. Mag., 13 (2), pp. 99-110; Thrun, S., Montemerlo, M., The graph SLAM algorithm with applications to large-scale mapping of urban structures (2006) Int. J. Robot. Res., 25 (5-6), pp. 403-429; Dellaert, F., Kaess, M., Square root sam: Simultaneous localization and mapping via square root information smoothing (2006) Int. J. Robot. Res., 25 (12), pp. 1181-1203; Olson, E.B., Real-time correlative scan matching (2009) ICRA, pp. 4387-4393; Lu, F., Milios, E., Robot pose estimation in unknown environments by matching 2d range scans (1997) J. Intell. Robot. Syst., 18 (3), pp. 249-275; Olson, E., Leonard, J., Teller, S., Fast iterative alignment of pose graphs with poor initial estimates (2006) ICRA, pp. 2262-2269; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments (2012) IROS, pp. 1871-1878; Stachniss, C., Burgard, W., Mobile robot mapping and localization in non-static environments (2005) AAAI, pp. 1324-1329; Meyer-Delius, D., Hess, J., Grisetti, G., Burgard, W., Temporary maps for robust localization in semi-static environments (2010) IROS, pp. 5750-5755; Morris, T., Dayoub, F., Corke, P., Wyeth, G., Upcroft, B., Multiple map hypotheses for planning and navigating in non-stationary environments (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference on, pp. 2765-2770. , IEEE; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Robotics: Science and Systems, pp. 17-24; Saarinen, J., Andreasson, H., Lilienthal, A.J., Independent Markov chain occupancy grid maps for representation of dynamic environment (2012) IROS, pp. 3489-3495; Tipaldi, G.D., Meyer-Delius, D., Beinhofer, M., Burgard, W., Lifelong localization and dynamic map estimation in changing environments (2012) RSS Workshop on Robots in Clutter; Biswas, J., Veloso, M., Localization and navigation of the CoBots over long-term deployments (2013) Int. J. Robot. Res., 32 (14), pp. 1679-1694; Biswas, J., Veloso, M., Depth camera based indoor mobile robot localization and navigation (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1697-1702. , IEEE; Bentley, J.L., Multidimensional binary search trees used for associative searching (1975) Commun. ACM, 18 (9), pp. 509-517; Barton, J.J., Nackman, L.R., (1994) Scientific and Engineering C++: an introduction with advanced techniques and examples, , Addison-Wesley Longman Publishing Co; Agarwal, S., Mierle, K., (2012) Ceres Solver: Tutorial & Reference; Griewank, A., Walther, A., (2008) Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation, , Society for Industrial and Applied Mathematics (SIAM); Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Auton. Robots, 4 (4), pp. 333-349; Marquardt, D.W., A method for the solution of certain nonlinear problems in least squares (1944) Quart. Appl. Math, 2 (2), pp. 164-168; Marquardt, D.W., An algorithm for least-squares estimation of nonlinear parameters (1963) J. Soc. Ind. Appl. Math., 11 (2), pp. 431-441; Chen, Y., Davis, T.A., Hager, W.W., Rajamanickam, S., Algorithm 887: CHOLMOD, supernodal sparse Cholesky factorization and update/downdate (2008) ACM Trans. Math. Softw., 35 (3), p. 22; Du Croz, J., Mayes, P., Radicati, G., (1990) Factorizations of Band Matrices Using Level 3 BLAS, , Springer; Biswas, J., (2014) Vector Map-Based, Non-Markov Localization for Long-Term Deployment of Autonomous Mobile Robots, , The Robotics Institute, Carnegie Mellon University USA},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997124583&doi=10.1016%2fj.robot.2016.09.005&partnerID=40&md5=fc49a61c300fea3a8e182df6c1e8c3b3},
}

@article{coulin-et-al:2022:3136241,
  author = {J. Coulin and R. Guillemard and V. Gay-Bellile and C. Joly and A. D. L. Fortelle},
  journal = {IEEE Robotics and Automation Letters},
  title = {Tightly-Coupled Magneto-Visual-Inertial Fusion for Long Term Localization in Indoor Environment},
  volume = {7},
  number = {2},
  pages = {952--959},
  doi = {10.1109/LRA.2021.3136241},
  note = {cited By 0},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2022},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {We propose in this letter a tightly-coupled fusion of visual, inertial and magnetic data for long-term localization in indoor environment. Unlike state-of-the-art Visual-Inertial SLAM (VISLAM) solutions that reuse visual map to prevent drift, we present in this letter an extension of the Multi-State Constraint Kalman Filter (MSCKF) that takes advantage of a magnetic map. It makes our solution more robust to variations of the environment appearance. The experimental results demonstrate that the localization accuracy of the proposed approach is almost the same over time periods longer than a year. © 2016 IEEE.},
  affiliation = {Université Paris-Saclay, CEA-List, Palaiseau, 91120, France; MINES ParisTech, PSL University, Center for Robotics, Paris, 75006, France},
  author_keywords = {indoor magnetic field;  Localization;  MSCKF;  sensor fusion;  visual-inertial SLAM},
  correspondence_address1 = {Coulin, J.; Université Paris-Saclay, France; email: jade.coulin@cea.fr},
  document_type = {Article},
  issn = {23773766},
  keywords = {Bibliographies;  Robotics, BIBT E X;  Code;  Documentation;  IEEE;  Indoor environment;  L A T E X;  Localisation;  Style;  Template;  Tightly-coupled, Indoor positioning systems},
  language = {English},
  references = {Campos, C., Elvira, R., Rodriguez, J.J.G., Montiel, J.M.M., Tardos, J.D., Orb-slam3: An accurate open-source library for visual, visual-inertial, and multimap slam (2021) IEEE Trans. Robot., 37 (6), pp. 1874-1890. , Dec; Forster, C., Carlone, L., Dellaert, F., Scaramuzza, D., Imu prein-tegration on manifold for efficient visual-inertial maximum-a-posteriori estimation (2015) Proc. Robot.: Sci. Syst, pp. 1-20. , Jul; Galvez-Lopez, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Kokand, M., Solin, A., Scalable magnetic field slam in 3Dusing Gaussian process maps (2018) Proc. 21st Int. Conf. Inf. Fusion, pp. 1353-1360. , Jul; Germain, H., Bourmaud, G., Lepetit, V., S2Dnet: Learning image features for accurate sparse-to-dense matching (2020) Proc. Eur. Conf. Comput. ViS, pp. 626-643. , Dec; Labbé, M., Michaud, F., Multi-session visual SLAM for illumination invariant localization in indoor environments (2021) Proc. IEEE Int. Conf. Robot. Automat. (Submitted), , Mar; Zuo, X., Multimodal localization: Stereo over LiDAR map (2020) J. Field Robot., 37 (6), pp. 1003-1026. , Jan; Hashemifar, Z., Adhivarahan, C., Balakrishnan, A., Dantu, K., Augmenting visual SLAM with Wi-Fi sensing for indoor applications (2019) Auton. Robots, 43, pp. 2245-2260. , Jul; Nguyen, T., Yuan, S., Cao, M., Nguyen, T., Xie, L., (2021) VIRAL SLAM: Tightly Coupled Camera-IMU-UWB-LIDAR SLAM, , May; Li, B., Gallagher, T., Dempster, A.G., Rizos, C., How feasible is the use of magnetic field alone for indoor positioning? (2012) Proc. Int. Conf. Indoor Positioning Indoor Navigation, pp. 1-9. , Nov; Robertson, P., Simultaneous localization and mapping for pedestrians using distortions of the local magnetic field intensity in large indoor environments (2013) Proc. Int. Conf. Indoor Positioning Indoor Navigation, pp. 1-10. , Oct; Wu, Z., Wen, M., Peng, G., Tang, X., Wang, D., Magnetic-assisted initialization for infrastructure-free mobile robot localization (2019) Proc. IEEE Int. Conf. Cybern. Intell. Syst. and IEEE Conf. Robot., Automat. Mechatronics, pp. 518-523. , Nov; Vallivaara, I., Haverinen, J., Kemppainen, A., Roning, J., Magnetic field-based slam method for solving the localization problem in mobile robot floor-cleaning task (2011) Proc. 15th Int. Conf. Adv. Robot, pp. 198-203. , Jun; Solin, A., Kok, M., Wahlström, N., Schön, T., Särkkä, S., Modeling and interpolation of the ambient magnetic field by Gaussian processes (2018) IEEE Trans. Robot., 34 (4), pp. 1112-1127. , Aug; Liu, Z., Zhang, L., Liu, Q., Yin, Y., Cheng, L., Zimmermann, R., Fusion of magnetic and visual sensors for indoor localization: Infrastructure-free and more effective (2017) IEEE Trans. Multimedia, 19, pp. 874-888; Vasconcelos, J.F., Elkaim, G., Silvestre, C., Oliveira, P., Cardeira, B., Geometric approach to strapdown magnetometer calibration in sensor frame (2011) IEEE Trans. Aerosp. Electron. Syst., 47 (2), pp. 1293-1306. , Apr; Vitiello, F., Causa, F., Opromolla, R., Fasano, G., Onboard and external magnetic bias estimation for UAS through CDGNSS/Visual cooperative navigation (2021) Sensors, 21 (11). , May; Mohamadabadi, K., Hillion, M., An automated indoor scalar calibration method for three-axis vector magnetometers (2014) IEEE Sensors J., 14 (9), pp. 3076-3083. , Sep; Kok, M., Schön, T., Magnetometer calibration using inertial sensors (2016) IEEE Sensors J., 16 (14), pp. 5679-5689. , Jul; Caruso, D., Eudes, A., Sanfourche, M., Vissière, D., Le Besnerais, G., Robust indoor/outdoor navigation through magneto-visual-inertial optimization-based estimation (2017) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 4402-4409. , Sep; Mourikis, A.I., Roumeliotis, S.I., A multi-state constraint Kalman filter for vision-aided inertial navigation (2007) Proc. IEEE Int. Conf. Robot. Automat, pp. 3565-3572. , Apr; Troni, G., Whitcomb, L., Adaptive estimation of measurement bias in three-dimensional field sensors with angular rate sensors: Theory and comparative experimental evaluation (2013) Robot.: Sci. Syst, pp. 50-57. , Jun; Rehder, J., Nikolic, J., Schneider, T., Hinzmann, T., Siegwart, R., Extending Kalibr: Calibrating the extrinsics of multiple IMUs and of individual axes (2016) Int. Conf. Robot. Automat, pp. 4304-4311. , May; Lee, N., Ahn, S., Han, D., AMID: Accurate magnetic indoor localization using deep learning (2018) Sensors, 18 (5). , May; Montoliu, R., Torres-Sospedra, J., Belmonte, O., Magnetic field based Indoor positioning using the Bag of Words paradigm (2016) Proc. Int. Conf. Indoor Positioning Indoor Navigation, pp. 1-7. , Oct; (2021) IEEE Standard for Specifying and Testing Single-Axis Interferometric Fiber Optic Gyros, pp. 1-93. , IEEE Std 952-2020 (Revision of IEEE Std 952-1997), Feb},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121789491&doi=10.1109%2fLRA.2021.3136241&partnerID=40&md5=0d1f2802e3001409ccf19523ed40252f},
}

@inproceedings{li-et-al:2015:7139706,
  author = {J. Li and R. M. Eustice and M. Johnson-Roberson},
  booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
  title = {High-Level Visual Features for Underwater Place Recognition},
  pages = {3652--3659},
  doi = {10.1109/ICRA.2015.7139706},
  note = {IEEE International Conference on Robotics and Automation (ICRA),
Seattle, WA, MAY 26-30, 2015},
  publisher = {IEEE COMPUTER SOC},
  address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
  year = {2015},
  abstract = {This paper reports on a method to perform robust visual relocalization
between temporally separated sets of underwater images gathered by a
robot. The place recognition and relocalization problem is more
challenging in the underwater environment mainly due to three factors:
1) changes in illumination; 2) long-term changes in the visual
appearance of features because of phenomena like biofouling on man-made
structures and growth or movement in natural features; and 3) low
density of visually salient features for image matching. To address
these challenges, a patch-based feature matching approach is proposed,
which uses image segmentation and local intensity contrast to locate
salient patches and HOG description to make correspondences between
patches. Compared to traditional point-based features that are sensitive
to dramatic appearance changes underwater, patch-based features are able
to encode higher level information such as shape or structure which
tends to persist across years in underwater environments. The algorithm
is evaluated on real data, from multiple years, collected by a Hovering
Autonomous Underwater Vehicle for ship hull inspection. Results in
relocalization performance across missions from different years are
compared to other traditional methods.},
  affiliation = {Li, J (Corresponding Author), Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
Li, Jie, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
Eustice, Ryan M.; Johnson-Roberson, Matthew, Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
  affiliations = {University of Michigan System; University of Michigan; University of
Michigan System; University of Michigan},
  author-email = {ljlijie@umich.edu
eustice@umich.edu
mattjr@umich.Gdu},
  book-group-author = {IEEE},
  cited-references = {Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66.
Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226.
Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
Carlevaris-Bianco Nicholas, 2011, IEEE International Conference on Robotics and Automation, P423.
Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
Dalal N., 2005, 2005 IEEE COMPUTER S, P886, DOI {[}10.1109/CVPR.2005.177, DOI 10.1109/CVPR.2005.177].
Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
Eustice RM, 2008, IEEE J OCEANIC ENG, V33, P103, DOI 10.1109/JOE.2008.923547.
Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77.
Harel J., 2007, NIPS C ADV NEUR INF, P545, DOI {[}10.7551/mitpress/7503.0 01.0 0 01, DOI 10.7551/MITPRESS/7503.003.0073].
Hartley R., 2003, MULTIPLE VIEW GEOMET.
Jiang H., 2011, BMVC, V6, P7, DOI DOI 10.5244/C.25.110.(4).
Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
McManus C., 2014, P ROB SCI SYST C BER.
Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
Ozog P, 2014, IEEE INT CONF ROBOT, P3832, DOI 10.1109/ICRA.2014.6907415.
Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743.},
  da = {2022-05-17},
  doc-delivery-number = {BE3MR},
  eissn = {2577-087X},
  isbn = {978-1-4799-6923-4},
  issn = {1050-4729},
  keywords-plus = {SIMULTANEOUS LOCALIZATION; NAVIGATION; SLAM},
  language = {English},
  number-of-cited-references = {20},
  oa = {Green Submitted},
  research-areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
  series = {IEEE International Conference on Robotics and Automation ICRA},
  times-cited = {13},
  type = {Proceedings Paper},
  unique-id = {WOS:000370974903096},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Automation \& Control Systems; Computer Science, Artificial
Intelligence; Engineering, Electrical \& Electronic; Robotics},
  web-of-science-index = {Conference Proceedings Citation Index - Science (CPCI-S)},
}

@article{santos-et-al:2016:2516594,
  author = {J. M. Santos and T. Krajnik and T. J. P. A. D. Fentanes},
  journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
  title = {Lifelong Information- Driven Exploration to Complete and Refine 4-D
Spatio-Temporal Maps},
  volume = {1},
  number = {2},
  pages = {684--691},
  doi = {10.1109/LRA.2016.2516594},
  publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
  address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
  year = {2016},
  month = {7},
  abstract = {This letter presents an exploration method that allows mobile robots to
build and maintain spatio-temporal models of changing environments. The
assumption of a perpetually changing world adds a temporal dimension to
the exploration problem, making spatio-temporal exploration a
never-ending, lifelong learning process. We address the problem by
application of information-theoretic exploration methods to
spatio-temporal models that represent the uncertainty of environment
states as probabilistic functions of time. This allows to predict the
potential information gain to be obtained by observing a particular area
at a given time, and consequently, to decide which locations to visit
and the best times to go there. To validate the approach, a mobile robot
was deployed continuously over 5 consecutive business days in a busy
office environment. The results indicate that the robot's ability to
spot environmental changes improved as it refined its knowledge of the
world dynamics.},
  affiliation = {Santos, JM (Corresponding Author), Univ Lincoln, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.
Santos, Joao Machado; Krajnik, Tomas; Fentanes, Jaime Pulido; Duckett, Tom, Univ Lincoln, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.},
  affiliations = {University of Lincoln},
  author-email = {jsantos@lincoln.ac.uk},
  cited-references = {Amigoni F, 2010, ROBOT AUTON SYST, V58, P684, DOI 10.1016/j.robot.2009.11.005.
Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
Caglioti V, 2001, IEEE T SYST MAN CY B, V31, P187, DOI 10.1109/3477.915342.
Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
CROES GA, 1958, OPER RES, V6, P791, DOI 10.1287/opre.6.6.791.
Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
Fentanes JP, 2015, IEEE INT CONF ROBOT, P1112, DOI 10.1109/ICRA.2015.7139315.
Hawes N., 2014, STRANDS SOFTWARE SYS.
Holz D., 2010, ISR 2010 41 INT S RO, P1.
Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
Koenig S, 2001, IEEE INT CONF ROBOT, P3594, DOI 10.1109/ROBOT.2001.933175.
Krajnik T., 2015, MOB ROB ECMR 2015 EU, P1.
Krajnik T., 2014, J INTELL ROBOT SYST.
Krajnik T., 2014, ADV AUTONOMOUS ROBOT, P281.
Krajnik T, 2015, IEEE INT CONF ROBOT, P2140, DOI 10.1109/ICRA.2015.7139481.
Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965.
Marchant R, 2014, IEEE INT CONF ROBOT, P6136, DOI 10.1109/ICRA.2014.6907763.
Marchant R, 2012, IEEE INT C INT ROBOT, P2242, DOI 10.1109/IROS.2012.6385653.
Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
MORAVEC HP, 1988, AI MAG, V9, P61.
Muhlfellner P., 2015, J FIELD ROBOT.
Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
Fentanes JAP, 2011, J FIELD ROBOT, V28, P832, DOI 10.1002/rob.20402.
Rahman M, 2011, APPLICATIONS OF FOURIER TRANSFORMS TO GENERALIZED FUNCTIONS, P1.
Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
Singh Amarjeet, 2010, 2010 IEEE International Conference on Robotics and Automation (ICRA 2010), P5490, DOI 10.1109/ROBOT.2010.5509934.
Stachniss C., 2005, P ROB SCI SYST RSS C.
Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
  da = {2022-05-17},
  doc-delivery-number = {FK7ZO},
  funding-acknowledgement = {EU ICT project Grant {[}600623]},
  funding-text = {This work was supported by the EU ICT project Grant 600623 `STRANDS.'},
  issn = {2377-3766},
  journal-iso = {IEEE Robot. Autom. Lett.},
  keywords = {Mapping; service robots},
  keywords-plus = {MOBILE ROBOTS; ENVIRONMENTS; LOCALIZATION; NAVIGATION},
  language = {English},
  number-of-cited-references = {31},
  oa = {Green Accepted},
  orcid-numbers = {Krajník, Tomáš/0000-0002-4408-7916
Santos, Joao/0000-0002-4797-3542},
  research-areas = {Robotics},
  researcherid-numbers = {Krajník, Tomáš/O-2339-2013},
  times-cited = {17},
  type = {Article},
  unique-id = {WOS:000413726900012},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {2},
  web-of-science-categories = {Robotics},
  web-of-science-index = {Emerging Sources Citation Index (ESCI)},
}

@conference{oberländer-et-al:2013:6766479,
  author = {J. Oberländer and A. Roennau and R. Dillmann},
  journal = {2013 16th International Conference on Advanced Robotics, ICAR 2013},
  title = {Hierarchical SLAM using spectral submap matching with opportunities for long-term operation},
  pages = {1--7},
  doi = {10.1109/ICAR.2013.6766479},
  note = {cited By 11; Conference of 2013 16th International Conference on Advanced Robotics, ICAR 2013 ; Conference Date: 25 November 2013 Through 29 November 2013;  Conference Code:104529},
  publisher = {IEEE Computer Society},
  address = {Montevideo},
  year = {2013},
  abbrev_source_title = {Int. Conf. Adv. Rob., ICAR},
  abstract = {We present a hierarchical SLAM approach which uses spectral registration of local submaps to close loops and to perform global localization after a restart. Using the Fourier-Mellin Transform (FMT), we robustly register occupancy grid representations of local submaps and present methods which improve matching performance. We further show how good match candidates can be reliably detected even from scaled-down versions of the submaps, which significantly reduces the computation time. The spectral registration approach proves useful even in the presence of significant environmental changes due to the fact that it calculates a dense match, incorporating all observed information rather than a sparse set of features. © 2013 IEEE.},
  affiliation = {Department of Interactive Diagnosis and Service Systems (IDS), FZI Research Center for Information Technology, 76131 Karlsruhe, Germany; Humanoids and Intelligence Systems Lab, Institute for Anthropomatics, Karlsruhe Institute of Technology, 76128 Karlsruhe, Germany},
  art_number = {6766479},
  document_type = {Conference Paper},
  keywords = {Human computer interaction, Computation time;  Environmental change;  Fourier-mellin transforms;  Global localization;  Matching performance;  Occupancy grids;  Scaled-down versions;  SLAM approach, Robotics},
  language = {English},
  references = {Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , The MIT Press; Blanco, J.L., Gonzalez, Fernandez-Madrigal, J.-A., Subjective local maps for hybrid metric-topological SLAM (2009) Robotics and Autonomous Systems, 57, pp. 64-74; Blanco, J.L., Fernandez-Madrigal, J.-A., Gonzalez, J., Toward a unified bayesian approach to hybrid metric-topological SLAM (2008) IEEE Transactions on Robotics, 24 (2), pp. 259-270. , April; Bosse, M., Newman, P., Leonard, J., Soika, M., Feiten, W., Teller, S., An atlas framework for scalable mapping (2003) Proceedings of the2003 IEEE International Conference on Robotics and Automation, pp. 1899-1906; Yamauchi, B., Langley, P., Place recognition in dynamic environments (1997) Journal of Robotic Systems, 14 (2), pp. 107-120. , February; Birk, A., Carpin, S., Merging occupancy grid maps from multiple robots (2006) Proceedings of the IEEE, 94 (7), pp. 1384-1397. , July; Censi, A., Iocchi, L., Grisetti, G., Scan matching in the hough domain (2005) Proceedings of the 2005 IEEE International Conference on Robotics and Automation, pp. 2739-2744; Reddy, B.S., Chatterji, B.N., An fft-based technique for translation, rotation, and scale-invariant image registration (1996) IEEE Transactions on Image Processing, 5 (8), pp. 1266-1271. , August; Kazik, T., Goktogan, A.H., Visual odometry based on the fourier-mellin transform for a rover using a monocular ground-facing camera (2011) IEEE International Conference on Mechatronics, pp. 469-474. , April; Checchin, P., Gerossier, F., Blanc, C., Chapuis, R., Trassoudaine, L., Radar scan matching SLAM using the fourier-mellin transform (2010) Field and Service Robotics, Ser. Springer Tracts in Advanced Robotics, 62, pp. 151-161. , A. Howard, K. lagnemma, and A. Kelly, Eds. Springer Berlin/Heidelberg; Billow, H., Birk, A., Fast and robust photomapping with an unmanned aerial vehicle (UAV) (2009) Proceedings of the 2009 IEEEIRSJ International Conference on Intelligent Robots and Systems, pp. 3368-3373; Pfingsthorn, M., Birk, A., Schwerdtfeger, S., Billow, H., Pathak, K., Maximum likelihood mapping with spectral image registration (2010) Proceedings of the 2010 IEEE International Conference on Robotics and Automation, pp. 4282-4287; Birk, A., Using recursive spectral registrations to determine bro-kenness as measure of structural map errors (2010) Proceedings of the 2010 IEEE International Conference on Robotics and Automation, pp. 3472-3477. , May; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Tipaldi, G.D., Arras, K.O., FLIRT-interest regions for 2D range data (2010) Proceedings of the 2010 IEEE International Conference on Robotics and Automation, pp. 3616-3622. , May; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (SURF) (2008) Computer Vision and Image Understanding, 110, pp. 346-359; Billow, H., Birk, A., Unnithan, V., Online generation of an underwater photo map with improved fourier mellin based registration (2009) OCEANS 2009, pp. 1-6. , May; Bradski, G., (2000) The OpenCV Library, , Dr. Dobb's Journal of Software Tools; Padfield, D., Masked object registration in the fourier domain (2012) IEEE Transactions on Image Processing, 21 (5), pp. 2706-2718; Fisher, R.B., Naidu, D.K., A comparison of algorithms for subpixel peak detection (1996) Image Technology: Advances in Image Processing, Multimedia and Machine Vision, pp. 385-404. , J. L. C. Sanz, Ed. Springer Berlin/Heidelberg; Howard, A., Roy, N., (2003) The Robotics Data Set Repository (Radish), , http://radish.sourceforge.net/; Dellaert, F., (2012) Factor Graphs and GTSAM: A Hands-on Introduction, , Georgia Institute of Technology, Tech. Rep. GT-RIM-CP&R-2012-002, September; Tipaldi, G.D., Spinello, L., Burgard, W., Geometrical FLIRT phrases for large scale place recognition in 2d range data (2013) Proceedings of the 2013 IEEE International Conference on Robotics and Automation, , May},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899407505&doi=10.1109%2fICAR.2013.6766479&partnerID=40&md5=cf224e6cd8a1b3f7d54704b29766ce26},
}

@article{oh-eoh:2021:app11198976,
  author = {J. Oh and G. Eoh},
  journal = {Applied Sciences (Switzerland)},
  title = {Variational Bayesian approach to condition-invariant feature extraction for visual place recognition},
  volume = {11},
  number = {19},
  pages = {8976},
  doi = {10.3390/app11198976},
  note = {cited By 0},
  publisher = {MDPI},
  year = {2021},
  abbrev_source_title = {Appl. Sci.},
  abstract = {As mobile robots perform long-term operations in large-scale environments, coping with perceptual changes becomes an important issue recently. This paper introduces a stochastic variational inference and learning architecture that can extract condition-invariant features for visual place recognition in a changing environment. Under the assumption that a latent representation of the variational autoencoder can be divided into condition-invariant and condition-sensitive features, a new structure of the variation autoencoder is proposed and a variational lower bound is derived to train the model. After training the model, condition-invariant features are extracted from test images to calculate the similarity matrix, and the places can be recognized even in severe environmental changes. Experiments were conducted to verify the proposed method, and the experimental results showed that our assumption was reasonable and effective in recognizing places in changing environments. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
  affiliation = {Department of Robotics, Kwangwoon University, Seoul, 01897, South Korea; Industrial AI Research Center, Chungbuk National University, Cheongju, 28116, South Korea},
  art_number = {8976},
  author_keywords = {Auto-encoder;  Deep learning;  Localization;  Mobile robots;  Place recognition;  SLAM},
  correspondence_address1 = {Eoh, G.; Industrial AI Research Center, South Korea; email: gyuho.eoh@cbnu.ac.kr},
  document_type = {Article},
  funding_details = {Ministry of Trade, Industry and EnergyMinistry of Trade, Industry and Energy, MOTIE, 20174010201620},
  funding_text1 = {Funding: This work has supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government(MSIT) (No. 2020R1F1A1076667), Korea Institute of Energy Technology Evaluation and Planning (KETEP) and the Ministry of Trade, Industry & Energy (MOTIE) of the Republic of Korea (No. 20174010201620). This work was also supported by Research Resettlement Fund for the new faculty of Kwangwoon University in 2019.},
  issn = {20763417},
  language = {English},
  references = {Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Trans. Robot, 32, pp. 1-19. , [CrossRef]; Sattler, T., Maddern, W., Toft, C., Torii, A., Hammarstrand, L., Stenborg, E., Safari, D., Sivic, J., Benchmarking 6dof outdoor visual localization in changing conditions Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 8601-8610. , Salt Lake City, UT, USA, 18–22 June 2018; Sünderhauf, N., Protzel, P., BRIEF-Gist—Closing the loop by simple means Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1234-1241. , Brisbane, Australia, 25–30 September 2011; [CrossRef]; Liu, Y., Zhang, H., Visual loop closure detection with a compact image descriptor Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1051-1056. , Vilamoura-Algarve, Portugal, 7–12 October 2012; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis, 60, pp. 91-110. , [CrossRef]; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (SURF) (2008) Comput. Vis. Image. Und, 110, pp. 346-359. , [CrossRef]; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 1, pp. 886-893. , San Diego, CA, USA, 20–25 June; Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) Int. J. Comput. Vis, 42, pp. 145-175. , [CrossRef]; Torralba, A., Fergus, R., Weiss, Y., Small codes and large image databases for recognition Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-8. , Anchorage, AK, USA, 23–28 June 2008; Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) Proceedings of the International Conference on Advances in Neural Information Processing Systems, pp. 1097-1105. , Lake Tahoe, NV, USA, 3–6 December; Arandjelovi´c, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN Architecture for Weakly Supervised Place Recognition (2018) IEEE Trans. Pattern Anal. Mach. Intell, 40, pp. 1437-1451. , [CrossRef]; Chancán, M., Hernandez-Nunez, L., Narendra, A., Barron, A.B., Milford, M., A hybrid compact neural architecture for visual place recognition (2020) IEEE Robot. Autom. Lett, 5, pp. 993-1000. , [CrossRef]; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free Proceedings of the International Conference on Robotics: Science and Systems. Robotics: Science and Systems Conference, pp. 1-10. , Rome, Italy, 13–17 July 2015; Garg, S., Sünderhauf, N., Milford, M., Don’t look back: Robustifying place categorization for viewpoint-and condition-invariant place recognition Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 3645-3652. , Brisbane, Australia, 21–26 May 2018; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual SLAM across seasons Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 2529-2535. , Hamburg, Germany, 28 September–2 October 2015; Oh, J.H., Lee, B.H., Dynamic programming approach to visual place recognition in changing environments (2017) Electron. Lett, 53, pp. 391-393. , [CrossRef]; Park, C., Chae, H.W., Song, J.B., Robust Place Recognition Using Illumination-compensated Image-based Deep Convolutional Autoencoder Features (2020) Int. J. Control Autom. Syst, 18, pp. 2699-2707. , [CrossRef]; Kingma, D., Welling, M., Auto-encoding variational Bayes (2014) Proceedings of the International Conference on Learning Representations (ICLR), , Banff, AB, Canada, 14–16 April; Pu, Y., Gan, Z., Henao, R., Yuan, X., Li, C., Stevens, A., Carin, L., Variational autoencoder for deep learning of images, labels and captions (2016) Proceedings of the International Conferene on Advances in neural information processing systems (NIPS), 29, pp. 2352-2360. , Barcelona, Spain, 5–10 December; Oh, J., Han, C., Lee, S., Condition-invariant robot localization using global sequence alignment of deep features (2021) Sensors, 21, p. 4103. , [CrossRef] [PubMed]; Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet? Challenging SeqSLAM on a 3000 km journey across all four seasons (2013) Proceedings of theWorkshop on Long-Term Autonomy, IEEE International Conference on Robotics and Automation (ICRA), , Karlsruhe, Germany, 6–10 May; Olid, D., Fácil, J.M., Civera, J., Single-view place recognition under seasonal changes (2018) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)Workshops, , Madrid, Spain, 1–5 October; Choi, Y., Kim, N., Park, K., Hwang, S., Yoon, J., Kweon, I.S., All-day visual place recognition: Benchmark dataset and baseline (2015) Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)Workshops, , Boston, MA, USA, 7–12 June; Milford, M., Wyeth, G., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 1643-1649. , St Paul, MN, USA, 14–19 May 2012; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) Int. J. Robot. Res, 30, pp. 1100-1123. , [CrossRef]; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Proceedings of the International Conference on Learning Representations (ICLR), , Vancouver, BC, Canada, 30 April–3 May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116389822&doi=10.3390%2fapp11198976&partnerID=40&md5=000d76d9f79bb71dfb08f8c5394e1fce},
}

@article{saarinen-et-al:2013:0278364913499415,
  author = {J. P. Saarinen and H. Andreasson and T. Stoyanov and A. J. Lilienthal},
  journal = {International Journal of Robotics Research},
  title = {3D normal distributions transform occupancy maps: An efficient representation for mapping in dynamic environments},
  volume = {32},
  number = {14},
  pages = {1627--44},
  doi = {10.1177/0278364913499415},
  note = {3D normal distributions transform occupancy maps;dynamic environments;autonomous vehicles;industrial environments;3D world models;3D spatial representation;online real-world mapping;normal distributions transform maps;occupancy grid maps;NDT-OM;NDT maps;exact recursive update equations;multiresolution maps;occupancy update equations;probabilistic sensor model;milkfactory;preprogrammed manipulators;},
  address = {USA},
  year = {2013},
  abstract = {In order to enable long-term operation of autonomous vehicles in industrial environments numerous challenges need to be addressed. A basic requirement for many applications is the creation and maintenance of consistent 3D world models. This article proposes a novel 3D spatial representation for online real-world mapping, building upon two known representations: normal distributions transform (NDT) maps and occupancy grid maps. The proposed normal distributions transform occupancy map (NDT-OM) combines the advantages of both representations; compactness of NDT maps and robustness of occupancy maps. One key contribution in this article is that we formulate an exact recursive updates for NDT-OMs. We show that the recursive update equations provide natural support for multi-resolution maps. Next, we describe a modification of the recursive update equations that allows adaptation in dynamic environments. As a second key contribution we introduce NDT-OMs and formulate the occupancy update equations that allow to build consistent maps in dynamic environments. The update of the occupancy values are based on an efficient probabilistic sensor model that is specially formulated for NDT-OMs. In several experiments with a total of 17 hours of data from a milkfactory we demonstrate that NDT-OMs enable real-time performance in large-scale, long-term industrial setups.},
  copyright = {Copyright 2014, The Institution of Engineering and Technology},
  issn = {0278-3649},
  keywords = {control engineering computing;dairy products;industrial robots;mobile robots;normal distribution;production engineering computing;production facilities;robot dynamics;robot vision;SLAM (robots);solid modelling;transforms;},
  language = {English},
  url = {http://dx.doi.org/10.1177/0278364913499415},
}

@article{pérez-et-al:2015:y,
  author = {J. Pérez and F. Caballero and L. Merino},
  journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
  title = {Enhanced Monte Carlo Localization with Visual Place Recognition for Robust Robot Localization},
  volume = {80},
  number = {3-4},
  pages = {641--656},
  doi = {10.1007/s10846-015-0198-y},
  note = {cited By 15},
  publisher = {Kluwer Academic Publishers},
  year = {2015},
  abbrev_source_title = {J Intell Rob Syst Theor Appl},
  abstract = {This paper proposes extending Monte Carlo Localization methods with visual place recognition information in order to build a robust robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position within the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based on datasets gathered with a real robot in challenging scenarios. © 2015, Springer Science+Business Media Dordrecht.},
  affiliation = {University Pablo de Olavide, Seville, Spain; University of Seville, Seville, Spain},
  author_keywords = {Crowded environment;  Long-term localization;  Monte Carlo localization;  Robust localization},
  coden = {JIRSE},
  correspondence_address1 = {Pérez, J.; University Pablo de OlavideSpain},
  document_type = {Article},
  funding_details = {288235},
  funding_text1 = {This paper is an extension of work presented at ICARSC 2014 [] and is partially supported by the FP7 FROG Project (Contract 288235) funded by the European Commission and the PAIS-MultiRobot Project (TIC-7390) funded by Regional Government of Andalucía},
  issn = {09210296},
  keywords = {Range finders;  Robot applications;  Robots, Crowded environment;  Long-term localization;  Monte Carlo localization;  Place recognition;  Real robot;  Robot positions;  Robust localization;  Robust robots, Monte Carlo methods},
  language = {English},
  references = {Alcantarilla, P.F., Stasse, O., Druon, S., Bergasa, L.M., Dellaert, F., How to localize humanoids with a single camera? (2013) Auton. Robots, 34 (1-2), pp. 47-71; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Trans. Robot., 24 (5), pp. 1027-1037; Carlone, L., Bona, B., A comparative study on robust localization: Fault tolerance and robustness test on probabilistic filters for range-based positioning (2009) International Conference on Advanced Robotics, 2009. ICAR 2009, pp. 1-8; Corke, P., Paul, R., Churchill, W., Newman, P., Dealing with shadows: Capturing intrinsic scene appearance for image-based outdoor localisation (2013) IROS, pp. 2085–2092. IEEE; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots (2008) IEEE/RSJ International Conference onIntelligent Robots and Systems, 2008. IROS 2008, pp. 3364-3369; Doucet, A., Freitas, N.D., Murphy, K.P., Russell, S.J., Rao-blackwellised particle filtering for dynamic bayesian networks (2000) Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, UAI ’00, pp. 176-183. , http://dl.acm.org/citation.cfm?id=647234.720075, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA; Galvez-Lopez, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197; Glover, A.J., Maddern, W.P., Warren, M., Reid, S., Milford, M., Wyeth, G., Openfabmap: An open source toolbox for appearance-based loop closure detection (2012) ICRA, pp. 4730–4735. IEEE; Hentschel, M., Wagner, B., An adaptive memory model for long-term navigation of autonomous mobile robots (2011) Journal of Robotics; Himstedt, M., Keil, S., Hellbach, S., Böhme, H.J., A robust graph-based framework for building precise maps from laser range scans (2013) ICRA, Workshop on Robust and Multimodal Inference in Factor Graphs; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W.: g2o: A general framework for graph optimization (2011) Proc. International Conference on Robotics and Automation, ICRA, pp. 3607–3613. IEEE, , http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5979949; Kümmerle, R., Ruhnke, M., Steder, B., Stachniss, C., Burgard, W., A navigation system for robots operating in crowded urban environments (2013) Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), pp. 3225-3232; Pérez-Lara, J., Caballero, F., Merino, L., Long-term ground robot localization architecture for mixed indoor-outdoor scenarios (2014) Proceedings of the International Symposium on Robotics, ISR; Pérez-Lara, J., Caballero, F., Merino, L., Integration of Monte Carlo localization and place recognition for reliable long term robot localization (2014) IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC, p. 2014. , Espinho, Portugal; Ruhnke, M., Kümmerle, R., Grisetti, G., Burgard, W., Highly accurate maximum likelihood laser mapping by jointly optimizing laser points and robot poses (2011) Proceedings International Conference on Robotics and Automation, ICRA; Thrun, S., Beetz, M., Bennewitz, M., Burgard, W., Cremers, A.B., Dellaert, F., Fox, D., Hahnel, C., Probabilistic algorithms and the interactive museum tour-guide robot minerva (2000) Int. J. Robot. Res., 19, pp. 972-999; Thrun, S., Burgard, W., Fox, D., Probabilistic Robotics (Intelligent Robotics and Autonomous Agents) (2005) The MIT Press; Thrun, S., Fox, D., Burgard, W., Dellaert, F., Robust monte carlo localization for mobile robots (2000) Artif. Intell., 128 (1-2), pp. 99-141; Wallach, H.M., Topic modeling: Beyond bag-of-words (2006) Proceedings of the 23rd International Conference on Machine Learning, ICML ’06, pp. 977-984. , ACM, New York, NY, USA},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945480250&doi=10.1007%2fs10846-015-0198-y&partnerID=40&md5=28fa10437be093bb3ca9e4b093a1233b},
}

@conference{berrio-et-al:2019:8814289,
  author = {J. S. Berrio and J. Ward and S. Worrall and E. Nebot},
  journal = {IEEE Intelligent Vehicles Symposium, Proceedings},
  title = {Identifying robust landmarks in feature-based maps},
  volume = {2019-June},
  pages = {1166--1172},
  doi = {10.1109/IVS.2019.8814289},
  note = {cited By 4; Conference of 30th IEEE Intelligent Vehicles Symposium, IV 2019 ; Conference Date: 9 June 2019 Through 12 June 2019;  Conference Code:151325},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {IEEE Intell Veh Symp Proc},
  abstract = {To operate in an urban environment, an automated vehicle must be capable of accurately estimating its position within a global map reference frame. This is necessary for optimal path planning and safe navigation. To accomplish this over an extended period of time, the global map requires long term maintenance. This includes the addition of newly observable features and the removal of transient features belonging to dynamic objects. The latter is especially important for the long-term use of the map as matching against a map with features that no longer exist can result in incorrect data associations, and consequently erroneous localisation. This paper addresses the problem of removing features from the map that correspond to objects that are no longer observable/present in the environment. This is achieved by assigning a single score which depends on the geometric distribution and characteristics when the features are re-detected (or not) on different occasions. Our approach not only eliminates ephemeral features, but can also be used as a reduction algorithm for highly dense maps. We tested our approach using half a year of weekly drives over the same 500 metre section of road in an urban environment. The results presented demonstrate the validity of the long term approach to map maintenance. © 2019 IEEE.},
  affiliation = {Australian Centre for Field Robotics (ACFR), University of SydneyNSW, Australia},
  art_number = {8814289},
  document_type = {Conference Paper},
  funding_details = {University of MichiganUniversity of Michigan, U-M},
  funding_text1 = {This work has been funded by the ACFR, the University of Sydney through the Dean of Engineering and Information Technologies PhD Scholarship (South America) and the Australian Research Council Discovery Grant DP160104081 and University of Michigan / Ford Motors Company Contract “Next generation Vehicles”.},
  isbn = {9781728105604},
  keywords = {Digital storage;  Intelligent vehicle highway systems;  Motion planning;  Probability distributions;  Urban planning, Automated vehicles;  Geometric distribution;  Long-term maintenances;  Optimal path planning;  Reduction algorithms;  Safe navigations;  Transient features;  Urban environments, Vehicles},
  language = {English},
  references = {Levinson, J., Askeland, J., Becker, J., Dolson, J., Held, D., Kammel, S., Kolter, J.Z., Thrun, S., Towards fully autonomous driving: Systems and algorithms (2011) 2011 IEEE Intelligent Vehicles Symposium (IV), pp. 163-168. , June; Kuutti, S., Fallah, S., Katsaros, K., Dianati, M., McCullough, F., Mouzakitis, A., A survey of the state-of-the-art localization techniques and their potentials for autonomous vehicle applications (2018) IEEE Internet of Things Journal, 5 (2), pp. 829-846. , April; Pomerleau, F., Krsi, P., Colas, F., Furgale, P., Siegwart, R., Longterm 3D map maintenance in dynamic environments (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3712-3719. , May; Guo, R., Sun, F., Yuan, J., ICP based on polar point matching with application to graph-slam (2009) 2009 International Conference on Mechatronics and Automation, pp. 1122-1127. , Aug; Kim, D.-I., Chae, H., Song, J.B., Min, J., Point feature-based outdoor slam for rural environments with geometric analysis (2015) 2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI), pp. 218-223. , Oct; Siritanawan, P., Prasanjith, M.D., Wang, D., 3D feature points detection on sparse and non-uniform pointcloud for slam (2017) 2017 18th International Conference on Advanced Robotics (ICAR), pp. 112-117. , July; Dymczyk, M., Schneider, T., Gilitschenski, I., Siegwart, R., Stumm, E., Erasing bad memories: Agent-side summarization for long-term mapping (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4572-4579. , Oct; Dissanayake, M.W.M.G., Newman, P., Clark, S., Durrant-Whyte, H.F., Csorba, M., A solution to the simultaneous localization and map building (slam) problem (2001) IEEE Transactions on Robotics and Automation, 17 (3), pp. 229-241. , June; Yi, S., Worrall, S., Nebot, E., (2019) Metrics for the Evaluation of Localisation Robustness; Lynen, S., Sattler, T., Bosse, M., Hesch, J.A., Pollefeys, M., Siegwart, R., Get out of my lab: Large-scale, real-time visual-inertial localization (2015) Robotics: Science and Systems; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) Journal of Field Robotics, 33 (5), pp. 561-590. , this work is supported in part by the European Communitys Seventh Framework Programme (FP7/2007-2013) under Grants 269916 (V-Charge) and 610603 (EUROPA2); Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The GIST of maps-summarizing experience for lifelong localization (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 2767-2773. , May; Carneiro, G., Jepson, A.D., The quantitative characterization of the distinctiveness and robustness of local image descriptors (2009) Image and Vision Computing, 27 (8), pp. 1143-1156; Verdie, Y., Yi, K.M., Fua, P., Lepetit, V., Tilde: A temporally invariant learned detector (2015) IEEE Computer Society, pp. 5279-5288; Meyer-Delius, D., Beinhofer, M., Burgard, W., Occupancy grid models for robot mapping in changing environments (2012) Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, Ser. AAAI'12, pp. 2024-2030. , http://dl.acm.org/citation.cfm?id=2900929.2901014, AAAI Press; Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong featurebased mapping in semi-static environments (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 1063-1070. , May; Nobre, F., Heckman, C., Ozog, P., Wolcott, R., Walls, J., Online probabilistic change detection in feature-based maps (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 3661-3668. , May; Krajnk, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4558-4563. , Oct; Krajnk, T., Fentanes, J.P., Santos, J.M., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) IEEE Transactions on Robotics, 33 (4), pp. 964-977. , Aug; Kaeli, J.W., Leonard, J.J., Singh, H., Visual summaries for lowbandwidth semantic mapping with autonomous underwater vehicles (2014) 2014 IEEE/OES Autonomous Underwater Vehicles (AUV), pp. 1-7. , Oct; Vani, M., Urbaniec, K., Employing Bayesian networks and conditional probability functions for determining dependences in road traffic accidents data (2017) 2017 Smart City Symposium Prague (SCSP), pp. 1-5. , May; Zou, H., Hastie, T., Regularization and variable selection via the elastic net (2005) Journal of the Royal Statistical Society, Series B, 67, pp. 301-320},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072290600&doi=10.1109%2fIVS.2019.8814289&partnerID=40&md5=b9240fab7189359c3acbe8cff456cdb3},
}

@article{berrio-et-al:2021:3094485,
  author = {J. S. Berrio and S. Worrall and M. Shan and E. Nebot},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  title = {Long-Term Map Maintenance Pipeline for Autonomous Vehicles},
  doi = {10.1109/TITS.2021.3094485},
  note = {cited By 0},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Trans. Intell. Transp. Syst.},
  abstract = {For autonomous vehicles to operate persistently in a typical urban environment, it is essential to have high accuracy position information. This requires a mapping and localisation system that can adapt to changes over time. A localisation approach based on a single-survey map will not be suitable for long-term operation as it does not incorporate variations in the environment. In this paper, we present new algorithms to maintain a featured-based map. A map maintenance pipeline is proposed that can continuously update a map with the most relevant features taking advantage of the changes in the surroundings. Our pipeline detects and removes transient features based on their geometrical relationships with the vehicle's pose. Newly identified features became part of a new feature map and are assessed by the pipeline as candidates for the localisation map. By purging out-of-date features and adding newly detected features, we continually update the prior map to more accurately represent the most recent environment. We have validated our approach using the USyd Campus Dataset, which includes more than 18 months of data. The results presented demonstrate that our maintenance pipeline produces a resilient map which can provide sustained localisation performance over time. IEEE},
  affiliation = {Australian Centre for Field Robotics (ACFR), The University of Sydney, Sydney, NSW 2006, Australia (e-mail: j.berrio@acfr.usyd.edu.au); Australian Centre for Field Robotics (ACFR), The University of Sydney, Sydney, NSW 2006, Australia.},
  author_keywords = {Autonomous vehicles;  Feature extraction;  feature-based map;  Long-term localisation;  Maintenance engineering;  map update.;  Pipelines;  Task analysis;  Transient analysis;  Visualization},
  document_type = {Article},
  issn = {15249050},
  keywords = {Feature extraction;  Maintenance;  Pipelines, Geometrical relationship;  High-accuracy;  Localisation;  Localisation Systems;  Position information;  Relevant features;  Transient features;  Typical urban, Autonomous vehicles},
  language = {English},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110835631&doi=10.1109%2fTITS.2021.3094485&partnerID=40&md5=31d95a0a9abb9d0a523480e40ef5f5f9},
}

@inproceedings{zhu-et-al:2018:8500686,
  author = {J. Zhu and Y. Ai and B. Tian and D. Cao and S. Scherer},
  journal = {2018 IEEE Intelligent Vehicles Symposium (IV)},
  title = {Visual Place Recognition in Long-term and Large-scale Environment based on CNN Feature},
  pages = {1679--85},
  doi = {10.1109/IVS.2018.8500686},
  note = {visual place recognition;large-scale environment;CNN feature;intelligent vehicles;intelligent vehicle localization;visual description;place images;hand-crafted feature;description method;convolutional neural network;pre-trained network model;place sequence;image descriptors;Hamming distance;place matching;},
  address = {Piscataway, NJ, USA},
  year = {2018},
  abstract = {With the universal application of camera in intelligent vehicles, visual place recognition has become a major problem in intelligent vehicle localization. The traditional solution is to make visual description of place images using hand-crafted feature for matching places, but this description method is not very good for extreme variability, especially for seasonal transformation. In this paper, we propose a new method based on convolutional neural network (CNN), by putting images into the pre-trained network model to get automatically learned image descriptors, and through some operations of pooling, fusion and binarization to optimize them, then the similarity result of place recognition is presented with the Hamming distance of the place sequence. In the experimental part, we compare our method with some state-of-the-art algorithms, FABMAP, ABLE-M and SeqSLAM, to illustrate its advantages. The experimental results show that our method based on CNN achieves better performance than other methods on the representative public datasets.},
  copyright = {Copyright 2018, The Institution of Engineering and Technology},
  keywords = {convolution;feedforward neural nets;image matching;image recognition;intelligent transportation systems;learning (artificial intelligence);SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/IVS.2018.8500686},
}

@article{tsintotas-et-al:2021:103782,
  author = {K. A. Tsintotas and L. Bampis and A. Gasteratos},
  journal = {Robotics and Autonomous Systems},
  title = {Modest-vocabulary loop-closure detection with incremental bag of tracked words},
  volume = {141},
  pages = {103782},
  doi = {10.1016/j.robot.2021.103782},
  note = {cited By 8},
  publisher = {Elsevier B.V.},
  year = {2021},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {A key feature in the context of simultaneous localization and mapping is loop-closure detection, a process determining whether the current robot's environment perception coincides with previous observation. However, in long-term operations, both computational efficiency and memory requirements involved in an autonomous robot operation in uncontrolled environments, are of particular importance. The majority of approaches scale linearly with the environment's size in terms of storage and query time. The article at hand presents an efficient appearance-based loop-closure detection pipeline, which encodes the traversed trajectory by a low amount of unique visual words generated on-line through feature tracking. The incrementally constructed visual vocabulary is referred to as the “Bag of Tracked Words.” A nearest-neighbor voting scheme is utilized to query the database and assign probabilistic scores to all visited locations. Exploiting the inherent temporal coherency in the loop-closure task, the produced scores are processed through a Bayesian filter to estimate the belief state about the robot's location on the map. Also, a geometrical verification step ensures consistency between image matches. Management is also applied to the resulting vocabulary to reduce its growth rate and constraint the system's computational complexity while improving its voting distinctiveness. The proposed approach's performance is experimentally evaluated on several publicly available and challenging datasets, including hand-held, car-mounted, aerial, and ground trajectories. Results demonstrate the method's adaptability, which retains high operational frequency in environments of up to 13 km and high recall rates for perfect precision, outperforming other state-of-the-art techniques. The system's effectiveness is owed to the reduced vocabulary size, which is at least one order of magnitude smaller than other contemporary approaches. An open research-oriented source code has been made publicly available, which is dubbed as “BoTW-LCD.” © 2021 Elsevier B.V.},
  affiliation = {Laboratory of Robotics and Automation, Department of Production and Management Engineering, School of Engineering, Democritus University of Thrace, Xanthi, GR-67132, Greece},
  art_number = {103782},
  author_keywords = {Loop-closure detection;  Mapping;  Recognition;  SLAM;  Visual-based navigation},
  coden = {RASOE},
  correspondence_address1 = {Tsintotas, K.A.; Laboratory of Robotics and Automation, Greece; email: ktsintot@pme.duth.gr},
  document_type = {Article},
  funding_details = {European CommissionEuropean Commission, EC},
  funding_text1 = {Loukas Bampis received the diploma in electrical and computer engineering and PhD degree in machine vision and embedded systems from the Democritus University of Thrace (DUTh), Greece, in 2013 and 2019, respectively. He is currently a postdoctoral fellow in the laboratory of robotics and automation (LRA), department of production and management engineering, DUTh. His work has been supported through several research projects funded by the European Space Agency, the European commission and the Greek government. His research interests include real-time localization and place recognition techniques using hardware accelerators and parallel processing.},
  issn = {09218890},
  keywords = {Agricultural robots;  Antennas;  Computational efficiency;  Feature extraction;  Robots, Environment perceptions;  Memory requirements;  Operational frequency;  Probabilistic scores;  Simultaneous localization and mapping;  State-of-the-art techniques;  Temporal coherency;  Visual vocabularies, Query processing},
  language = {English},
  references = {Garcia-Fidalgo, E., Ortiz, A., Vision-based topological mapping and localization methods: A survey (2015) Robot. Auton. Syst., 64, pp. 1-20; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Trans. Robot. Autom., 32, pp. 1-19; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., Leonard, J.J., Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age (2016) IEEE Trans. Robot. Autom., 32, pp. 1309-1332; Kostavelis, I., Gasteratos, A., Semantic mapping for mobile robotics tasks: A survey (2015) Robot. Auton. Syst., 66, pp. 86-103; Balaska, V., Bampis, L., Kansizoglou, I., Gasteratos, A., Enhancing satellite semantic maps with ground-level imagery (2021) Robot. Auton. Syst.; Ho, K.L., Newman, P., Loop closure detection in SLAM by combining visual and spatial appearance (2006) Robot. Auton. Syst., 54, pp. 740-749; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis., 60, pp. 91-110; Rosten, E., Drummond, T., Fusing points and lines for high performance tracking (2005) Procceding of the IEEE International Conference on Computer Vision, pp. 1508-1515; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., Speeded-Up Robust Features (SURF) (2008) Comput. Vis. Image Underst., 110, pp. 346-359; Calonder, M., Lepetit, V., Strecha, C., Fua, P., BRIEF: Binary Robust Independent Elementary Features (2010) Proceedings of the European Conference on Computer Vision, pp. 778-792; Leutenegger, S., Chli, M., Siegwart, R.Y., BRISK: Binary robust invariant scalable keypoints (2011), pp. 2548-2555. , Proceedings of the IEEE International Conference on Computer Vision, Barcelona, Spain; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011), pp. 2564-2571. , Proceedings of the IEEE International Conference on Computer Vision, Barcelona, Spain; Alcantarilla, P.F., Bartoli, A., Davison, A.J., KAZE features (2012) Proceedings of the European Conference on Computer Vision, pp. 214-227; Zhang, H., BoRF: Loop-closure detection with scale invariant visual features (2011), pp. 3125-3130. , Proceedings of the IEEE International Conference on Robotics and Automation, Shanghai, China; Baeza-Yates, R., Ribeiro-Neto, B., Modern Information Retrieval, Vol. 463 (1999); Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27, pp. 647-665; Mei, C., Sibley, G., Newman, P., Closing loops without places (2010), pp. 3738-3744. , Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, Taipei, Taiwan; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) Int. J. Robot. Res., 30, pp. 1100-1123; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot. Autom., 28, pp. 1188-1197; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based SLAM (2014), pp. 846-853. , Proceedings of the IEEE International Conference on Robotics and Automation, Hong Kong, China; Stumm, E.S., Mei, C., Lacroix, S., Building location models for visual place recognition (2016) Int. J. Robot. Res., 35, pp. 334-356; Bampis, L., Amanatiadis, A., Gasteratos, A., Encoding the description of image sequences: A two-layered pipeline for loop closure detection (2016) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4530-4536; Bampis, L., Amanatiadis, A., Gasteratos, A., Fast loop-closure detection using visual-word-vectors from image sequences (2018) Int. J. Robot. Res., 37, pp. 62-82; Balaska, V., Bampis, L., Boudourides, M., Gasteratos, A., Unsupervised semantic clustering and localization for mobile robotics tasks (2020) Robot. Auton. Syst.; Papapetros, I.T., Balaska, V., Gasteratos, A., Multi-layer map: Augmenting semantic visual memory (2020), pp. 1206-1212. , Proceedings of the International Conference on Unmanned Aircraft Systems, Athens, Greece; MacQueen, J., (1967), pp. 281-297. , Some methods for classification and analysis of multivariate observations, in: Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003), pp. 1470-1477. , Proceedings of the IEEE International Conferyence on Computer Vision, Nice, France; Filliat, D., A visual bag of words method for interactive qualitative localization and mapping (2007) Procedings of the IEEE International Conference on Robotics and Automation, pp. 3921-3926; Angeli, A., Filliat, D., Doncieux, S., Meyer, J., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Trans. Robot. Autom., 24, pp. 1027-1037; Kawewong, A., Tongprasit, N., Tangruamsub, S., Hasegawa, O., Online and incremental appearance-based SLAM in highly dynamic environments (2011) Int. J. Robot. Res., 30, pp. 33-55; Nicosevici, T., Garcia, R., Automatic visual bag-of-words for online robot navigation and mapping (2012) IEEE Trans. Robot. Autom., 28, pp. 886-898; Labbé, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Trans. Robot. Autom., 29, pp. 734-745; Khan, S., Wollherr, D., IBuILD: Incremental bag of binary words for appearance based loop closure detection (2015), pp. 5441-5447. , Proceedings of the IEEE International Conference on Robotics and Automation, Seattle, WA, USA; Zhang, G., Lilly, M.J., Vela, P.A., Learning binary features online from motion dynamics for incremental loop-closure detection and place recognition (2016), pp. 765-772. , Procedings of the International Conference on Robotics and Automation, Stockholm, Sweden; Tsintotas, K.A., Bampis, L., Gasteratos, A., Assigning visual words to places for loop closure detection (2018), pp. 5979-5985. , Proceedings of the IEEE International Conference on Robotics and Automation, Brisbane, QLD, Australia; Garcia-Fidalgo, E., Ortiz, A., iBoW-LCD: An appearance-based loop-closure detection approach using incremental bags of binary words (2018) IEEE Robot. Autom. Lett., 3, pp. 3051-3057; Company-Corcoles, J.P., Garcia-Fidalgo, E., Ortiz, A., Towards robust loop closure detection in weakly textured environments using points and lines (2020) Proceedings of the IEEE International Conference on Emerging Technologies and Factory Automation, pp. 1313-1316; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4297-4304; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2016) Proceeding of the IEEE Conference Computer Vision and Pattern Recognition, pp. 5297-5307; Radenović, F., Tolias, G., Chum, O., CNN image retrieval learns from BoW: Unsupervised fine-tuning with hard examples (2016) Proceedings of the European Conference on Computer Vision, pp. 3-20; Kansizoglou, I., Bampis, L., Gasteratos, A., Deep feature space: A geometrical perspective (2020), arXiv preprint; Maffra, F., Chen, Z., Chli, M., Tolerant place recognition combining 2D and 3D information for UAV navigation (2018) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 2542-2549; Maffra, F., Teixeira, L., Chen, Z., Chli, M., Real-time wide-baseline place recognition using depth completion (2019) IEEE Robot. Autom. Lett., 4, pp. 1525-1532; Lucas, B.D., Kanade, T., An iterative image registration technique with an application to stereo vision (1981), pp. 674-679. , Proceedings of the International Joint Conference on Artificial Intelligence, San Francisco, CA, USA; Tsintotas, K.A., Giannis, P., Bampis, L., Gasteratos, A., Appearance-based loop closure detection with scale-restrictive visual features (2019) Proceedings of the International Conference on Computer Vision Systems, pp. 75-87; Zobel, J., Moffat, A., Inverted files for text search engines (2006) ACM Comput. Surv., 38, p. 6; Cummins, M., Newman, P., Probabilistic appearance based navigation and loop closing (2007) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 2042-2048. , IEEE; Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Trans. Inform. Theory, 14, pp. 462-467; Maddern, W., Milford, M., Wyeth, G., Cat-slam: probabilistic localisation and mapping using a continuous appearance-based trajectory (2012) Int. J. Robot. Res., 31, pp. 429-451; Hiemstra, D., A probabilistic justification for using tf×idf term weighting in information retrieval (2000) Int. J. Digit. Libr., 3, pp. 131-139; Arthur, D., Vassilvitskii, S., (2007), pp. 1027-1035. , k-means++: The advantages of careful seeding, in: Proceedings of the ACM-SIAM Symposium on Discrete Algorithms; Hansen, P., Browning, B., Visual place recognition using HMM sequence matching (2014) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4549-4555. , IEEE; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., Towards life-long visual localization using an efficient matching of binary sequences from images (2015), pp. 6328-6335. , Proceedings of the IEEE International Conference on Robotics and Automation; Tsintotas, K.A., Bampis, L., Gasteratos, A., DOSeqSLAM: dynamic on-line sequence based loop closure detection algorithm for SLAM (2018) Proceedings of the IEEE International Conference on Imaging Systems and Techniques, pp. 1-6. , IEEE; Neubert, P., Schubert, S., Protzel, P., A neurologically inspired sequence processing model for mobile robot place recognition (2019) IEEE Robot. Autom. Lett., 4, pp. 3200-3207; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 1643-1649; Tsintotas, K.A., Bampis, L., Rallis, S., Gasteratos, A., SeqSLAM with bag of visual words for appearance based loop closure detection (2018), pp. 580-587. , Proceedings of the International Conference on Robotics in Alpe-Adria Danube Region, Patras, Greece; Garcia-Fidalgo, E., Ortiz, A., Hierarchical place recognition for topological mapping (2017) IEEE Trans. Robot. Autom., 33, pp. 1061-1074; Fritzke, B., A growing neural gas network learns topologies (1994), pp. 625-632. , Proceedings of the International Conference on Neural Information Processing Systems; Gehrig, M., Stumm, E., Hinzmann, T., Siegwart, R., Visual place recognition with probabilistic voting (2017), pp. 3192-3199. , Proceedings of the IEEE International Conference on Robotics and Automation, Singapore, Singapore; Kazmi, S.M.A.M., Mertsching, B., Detecting the expectancy of a place using nearby context for appearance-based mapping (2019) IEEE Trans. Robot. Autom., 35, pp. 1352-1366; Alahakoon, D., Halgamuge, S.K., Srinivasan, B., Dynamic self-organizing maps with controlled growth for knowledge discovery (2000) IEEE Trans. Neural Netw., 11, pp. 601-614; An, S., Che, G., Zhou, F., Liu, X., Ma, X., Chen, Y., Fast and incremental loop closure detection using proximity graphs (2019), pp. 378-385. , Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems; Senst, T., Eiselein, V., Sikora, T., Robust local optical flow for feature tracking (2012) IEEE Trans. Circuits Syst. Video Technol., 22, pp. 1377-1387; Lan, X., Ma, A.J., Yuen, P.C., Multi-cue visual tracking using robust feature-level fusion based on joint sparse representation (2014), pp. 1194-1201. , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition; Zhang, G., Liu, H., Dong, Z., Jia, J., Wong, T.-T., Bao, H., Efficient non-consecutive feature tracking for robust structure-from-motion (2016) IEEE Trans. Image Process., 25, pp. 5957-5970; Mur-Artal, R., Tardós, J.D., Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras (2017) IEEE Trans. Robot. Autom., 33, pp. 1255-1262; Tsintotas, K.A., Bampis, L., Gasteratos, A., Probabilistic appearance-based place recognition through bag of tracked words (2019) IEEE Robot. Autom. Lett., 4, pp. 1737-1744; Bentley, J.L., Multidimensional binary search trees used for associative searching (1975) Commun. ACM, 18, pp. 509-517; Lynen, S., Bosse, M., Furgale, P., Siegwart, R., (2014), 1, pp. 303-310. , Placeless place-recognition, in: Proceedings of the International Conference on 3D Vision; Liu, Y., Zhang, H., Indexing visual features: Real-time loop closure detection using a tree structure (2012), pp. 3613-3618. , Proceedings of the IEEE International Conference on Robotics and Automation; Babenko, A., Lempitsky, V., The inverted multi-index (2014) IEEE Trans. Pattern Anal. Mach. Intell., 37, pp. 1247-1260; Schlegel, D., Grisetti, G., HBST: A hamming distance embedding binary search tree for feature-based visual place recognition (2018) IEEE Robot. Autom. Lett., 3, pp. 3741-3748; Murillo, A.C., Singh, G., Kosecká, J., Guerrero, J.J., Localization in urban environments using a panoramic gist descriptor (2012) IEEE Trans. Robot. Autom., 29, pp. 146-160; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI Vis. benchmark suite (2012) Proceedings of the IEEE Conference on Computer Vision and Rattern Recognition, pp. 3354-3361; Burri, M., Nikolic, J., Gohl, P., Schneider, T., Rehder, J., Omari, S., Achtelik, M.W., Siegwart, R., The EuRoC micro aerial vehicle datasets (2016) Int. J. Robot. Res., 35, pp. 1157-1163; Blanco, J.-L., Moreno, F.-A., Gonzalez, J., A collection of outdoor robotic datasets with centimeter-accuracy ground truth (2009) Auton. Robots, 27, p. 327; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college visual and laser data set (2009) Int. J. Robot. Res., 28, pp. 595-599; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Yebes, J.J., Bronte, S., Fast and effective visual place recognition using binary codes and disparity information (2014) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3089-3094; Durbin, R., Eddy, S.R., Krogh, A., Mitchison, G., Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids (1998); Tsintotas, K.A., Bampis, L., Gasteratos, A., Tracking-DOSeqSLAM: A dynamic sequence-based visual place recognition paradigm (2021) IET Comput. Vis.; Talbot, B., Garg, S., Milford, M., OpenSeqSLAM2.0: An open source toolbox for visual place recognition under changing conditions (2018) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 7758-7765; Milford, M., Vision-based place recognition: how low can you go? (2013) Int. J. Robot. Res., 32, pp. 766-789; An, S., Zhu, H., Wei, D., Tsintotas, K.A., Fast and incremental loop closure detection with deep features and proximity graphs (2020), arXiv preprint; Yue, H., Miao, J., Yu, Y., Chen, W., Wen, C., Robust loop closure detection based on bag of superpoints and graph verification (2019), pp. 3787-3793. , Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, Macau, China},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104623871&doi=10.1016%2fj.robot.2021.103782&partnerID=40&md5=23ceef64ccee234a9474a6f306c0aef9},
}

@conference{ikeda-tanaka:2010:5509579,
  author = {K. Ikeda and K. Tanaka},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Visual robot localization using compact binary landmarks},
  pages = {4397--4403},
  doi = {10.1109/ROBOT.2010.5509579},
  note = {cited By 14; Conference of 2010 IEEE International Conference on Robotics and Automation, ICRA 2010 ; Conference Date: 3 May 2010 Through 7 May 2010;  Conference Code:81416},
  address = {Anchorage, AK},
  year = {2010},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {This paper is concerned with the problem of mobile robot localization using a novel compact representation of visual landmarks. With recent progress in lifelong map-learning as well as in information sharing networks, compact representation of a large-size landmark database has become crucial. In this paper, we propose a compact binary code (e.g. 32bit code) landmark representation by employing the semantic hashing technique from web-scale image retrieval. We show how well such a binary representation achieves compactness of a landmark database while maintaining efficiency of the localization system. In our contribution, we investigate the cost-performance, the semantic gap, the saliency evaluation using the presented techniques as well as challenge to further reduce the resources (#bits) per landmark. Experiments using a high-speed car-like robot show promising results. ©2010 IEEE.},
  affiliation = {Faculty of Engineering, University of Fukui, Japan},
  art_number = {5509579},
  coden = {PIIAE},
  correspondence_address1 = {Ikeda, K.; Faculty of Engineering, Japan},
  document_type = {Conference Paper},
  isbn = {9781424450381},
  issn = {10504729},
  keywords = {Binary representations;  Bit codes;  Car-like robot;  Compact representation;  Cost performance;  Hashing techniques;  High-speed;  Information sharing network;  Landmark database;  Large sizes;  Localization system;  Mobile robot localization;  Recent progress;  Robot localization;  Semantic gap;  Visual landmarks, Automobiles;  Information retrieval;  Robot applications;  Robots;  Semantic Web;  Semantics, Robotics},
  language = {English},
  references = {Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots Proc. Robotics: Science and Systems I, 2005; Sukhatme, G.S., Burgard, W., Robotic sensor networks: Principles and practice RSS07 Workshop, 2007; Schindler, G., Brown, M., Szeliski, R., City-scale location recognition (2007) Proc. IEEE Int. Conf. Computer Vision and Pattern Recognition, pp. 1-7; Vlassis, N.A., Terwijn, B., Ja Kroese, B., Auxiliary particle filter robot localization from high-dimensional sensor observations (2002) Proc. IEEE Int. Conf. Robotics and Automation, pp. 7-12; Hays, J., Efros, A.A., Im2gps: Estimating geographic information from a single image (2008) IEEE Computer Vision and Pattern Recognition; Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) Int. J. Computer Vision, 42 (3), pp. 145-175; Williams, B., Klein, G., Reid, I., Real-time slam relocalisation (2007) Proc. IEEE 11th Int. Conf. Computer Vision, pp. 1-8; Tanaka, K., Kondo, E., A scalable algorithm for monte carlo localization using an incremental e2lsh-database of high dimensional features (2008) Proc. IEEE Int. Conf. Robotics and Automation, pp. 2784-2791; Saeki, K., Tanaka, K., Ueda, T., Lsh-ransac: An incremental scheme for scalable localization (2009) Proc. IEEE Int. Conf. Robotics and Automation, pp. 3523-3530; Newman, P., Posner, I., Cummins, M., Fast probabilistic labeling of city maps Proc. Robotics: Science and Systems IV, 2008; Salakhutdinov, R., Hinton, G., Semantic hashing (2008) Int. J. Approximate Reasoning; Torralba, A., Fergus, R., Weiss, Y., Small codes and large image databases for recognition (2008) Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-6; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313, pp. 504-507; Dellaert, F., Fox, D., Burgard, W., Thrun, S., Monte carlo localization for mobile robots (1999) Proc. IEEE Int. Conf. Robotics and Automation, pp. 1322-1328; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree (2006) Proc. IEEE Int. Conf. Computer Vision and Pattern Recognition, pp. 2161-2168; Nister, D., Naroditsky, O., Bergen, J., Visual odometry for ground vehicle applications (2006) J. Field Robotics, 23 (1), pp. 3-20; Rosencrantz, M., Gordon, G., Thrun, S., Decentralized sensor fusion with distributed particle filters Proc. UAI, 2003; Gionis, A., Indyk, P., Motwani, R., Similarity search in high dimensions via hashing Proc. Very Large Database Conference, 1999; Csurka, G., Fan, C.R.D.L., Willamowski, J., Bray, C., Visual categorization with bags of keypoints ECCV2004 Workshops on Statistical Learning in Computer Vison, 2004; Salton, Developments in automatic text retrieval (1991) Science, p. 253; Jensfelt, P., Kristensen, S., Active global localisation for a mobile robot using multiple hypothesis tracking (1999) Trans. IEEE Robotics and Automation, pp. 13-22; Douze, M., Jégou, H., Singh, H., Amsaleg, L., Schmid, C., Evaluation of gist descriptors for web-scale image search Proc. Int. Conf. Image and Video Retrieval, 2009; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Proc. IEEE Int. Conf. Conputer Vision and Pattern Recognition, pp. 886-893; Montemerlo, M., (2003) FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem with Unknown Data Association, , PhD thesis, Carnegie Mellon University; Horn, B.K.P., Schunck, B.G., Determining optical flow (1981) Artificial Intelligence, 17, pp. 185-203; Lowe, D.G., Object recognition from local scale-invariant features (1999) Proc. Int. Conf. Computer Vision, pp. 1150-1157; Doucet, A., Freitas, N., Gordon, N., Sequential monte carlo methods in practice (2001) Statistics for Engineering and Information Science; Lenser, S., Velose, M., Sensor resetting localization for poorly modeled mobile robots (2002) Proc. IEEE Int. Conf. Robotics and Automation, pp. 1225-1232; Russell, B., Torralba, A., Freeman, W.T., Labelme: The Open Annotation Tool, , http://labelme.csail.mit.edu/; Angeli, A., Doncieux, S., Meyer, J.A., Filliat, D., Real-time visual loop-closure detection (2008) Proc. IEEE Int. Conf. Robotics and Automation, pp. 1842-1847; Sala, P., Sim, R., Shokoufandeh, A., Dickinson, S., Landmark selection for vision-based navigation (2006) Trans. IEEE Robotics, 22, pp. 334-349},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955794780&doi=10.1109%2fROBOT.2010.5509579&partnerID=40&md5=5cfdb097472df1942b1b542961349728},
}

@conference{konolige-bowman:2009:5354121,
  author = {K. Konolige and J. Bowman},
  journal = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009},
  title = {Towards lifelong visual maps},
  pages = {1156--1163},
  doi = {10.1109/IROS.2009.5354121},
  note = {cited By 109; Conference of 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009 ; Conference Date: 11 October 2009 Through 15 October 2009;  Conference Code:79280},
  address = {St. Louis, MO},
  year = {2009},
  abbrev_source_title = {IEEE/RSJ Int. Conf. Intelligent Rob. Syst., IROS},
  abstract = {The typical SLAM mapping system assumes a static environment and constructs a map that is then used without regard for ongoing changes. Most SLAM systems, such as FastSLAM, also require a single connected run to create a map. In this paper we present a system of visual mapping, using only input from a stereo camera, that continually updates an optimized metric map in large indoor spaces with movable objects: people, furniture, partitions, etc. The system can be stopped and restarted at arbitrary disconnected points, is robust to occlusion and localization failures, and efficiently maintains alternative views of a dynamic environment. It operates completely online at a 30 Hz frame rate. © 2009 IEEE.},
  affiliation = {Willow Garage, Menlo Park, CA, United States},
  art_number = {5354121},
  correspondence_address1 = {Konolige, K.; Willow Garage, Menlo Park, CA, United States; email: konolige@willowgarage.com},
  document_type = {Conference Paper},
  isbn = {9781424438044},
  keywords = {Dynamic environments;  Fast-SLAM;  Frame rate;  Indoor space;  Mapping systems;  Ongoing changes;  Static environment;  Stereo cameras;  Visual map;  Visual mapping, Intelligent robots},
  language = {English},
  references = {Agrawal, M., Konolige, K., Rough terrain visual odometry (2007) Proc. International Conference on Advanced Robotics (ICAR), , August; Agrawal, M., Konolige, K., FrameSLAM: From bundle adjustment to real-time visual mapping (2008) IEEE Transactions on Robotics, 24 (5). , October; Andreasson, H., Treptow, A., Duckett, T., Self-localization in non-stationary environments using omni-directional vision (2007) Robotics and Autonomous Systems, 55 (7), pp. 541-551. , July; P. Biber and T. Duckett. Dynamic maps for long-term operation of mobile service robots. In RSS, 2005; Burgard, W., Stachniss, C., Haehnel, D., Mobile robot map learning from range data in dynamic environments (2007) Springer Tracts in Advanced Robotics, 35. , Autonomous Navigation in Dynamic Environments, of, Springer Verlag; Callmer, J., Granström, K., Nieto, J., Ramos, F., Tree of words for visual loop closure detection in urban slam (2008) Proceedings of the 2008 Australasian Conference on Robotics and Automation, p. 8; Calonder, M., Lepetit, V., Fua, P., Keypoint signatures for fast learning and recognition (2008) ECCV; Cummins, M., Newman, P.M., Probabilistic appearance based navigation and loop closing (2007) ICRA; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots (2008) IROS; Eade, E., Drummond, T., Unified loop closing and recovery for real time monocular slam (2008) BMVC; Fox, D., Burgard, W., Markov localization for mobile robots in dynamic environments (1999) Journal of Artificial Intelligence Research, 11, pp. 391-427; Fraundorfer, F., Engels, C., Nistér, D., Topological mapping, localization and navigation using image collections (2007) IROS, pp. 3872-3877; Grisetti, G., Stachniss, C., Grzonka, S., Burgard, W., A tree parameterization for efficiently computing maximum likelihood maps using gradient descent (2007) In RSS; Gutmann, J., Konolige, K., Incremental mapping of large cyclic environments (1999) Proc. IEEE International Symposium on Computational Intelligence in Robotics and Automation (CIRA), pp. 318-325. , Monterey, California, November; Haehnel, D., Triebel, R., Burgard, W., Thrun, S., Map building with mobile robots in dynamic environments (2003) ICRA, pp. 1557-1563; Jegou, H., Douze, M., Schmid, C., Hamming embedding and weak geometric consistency for large scale image search (2008) ECCV; Jegou, H., Harzallah, H., Schmid, C., A contextual dissimilarity measure for accurate and efficient image search (2007) Computer Vision and Pattern Recognition, IEEE Computer Society Conference on, 0, pp. 1-8; Konolige, K., Agrawal, M., Frame-frame matching for realtime consistent visual mapping (2007) Proc. International Conference on Robotics and Automation (ICRA); Konolige, K., Bowman, J., Chen, J., Mihelich, P., Colander, M., Lepetit, V., Fua, P., View-based maps (2009) Submitted; Montemerlo, M., Thrun, S., Conditional particle filters for simultaneous mobile robot localization and people-tracking (2002) ICRA, pp. 695-701; Nistér, D., Stewénius, H., Scalable recognition with a vocabulary tree (2006) CVPR; Rosten, E., Drummond, T., Machine learning for high-speed corner detection (2006) European Conference on Computer Vision, 1; Sivic, J., Zisserman, A., Video google: A text retrieval approach to object matching in videos (2003) Computer Vision, IEEE International Conference on, 2, p. 1470; Smith, R.C., Cheeseman, P., On the representation and estimation of spatial uncertainty (1986) International Journal of Robotics Research, 5 (4); Snavely, N., Seitz, S.M., Szeliski, R., Skeletal sets for efficient structure from motion (2008) Proc. Computer Vision and Pattern Recognition; Ulrich, I., Nourbakhsh, I., Appearance-based place recognition for topological mapping (2000) ICRA; Valgren, C., Lilienthal, A., Duckett, T., Incremental topological mapping using omnidirectional vision (2006) IROS; Williams, B., Klein, G., Reid, I., Real-time slam relocalisation (2007) ICCV; Wolf, D., Sukhatme, G., Online simultaneous localization and mapping in dynamic environments (2004) ICRA},
  source = {Scopus},
  sponsors = {IEEE Robotics and Automation Society, IEEE; Robotics Society of Japan, RSJ; Society of Instrument and Control Engineers, SICE; IEEE Industrial Electronics Society, IES; Institute of Control, Robotics and Systems in Korea, ICROS},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249093571&doi=10.1109%2fIROS.2009.5354121&partnerID=40&md5=1c84f8beebd53935fa55e577ea93daaa},
}

@article{mactavish-et-al:2018:21838,
  author = {K. MacTavish and M. Paton and T. D. Barfoot},
  journal = {Journal of Field Robotics},
  title = {Selective memory: Recalling relevant experience for long-term visual localization},
  volume = {35},
  number = {8},
  pages = {1265--1292},
  doi = {10.1002/rob.21838},
  note = {cited By 7},
  publisher = {John Wiley and Sons Inc.},
  year = {2018},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {Visual navigation is a key enabling technology for autonomous mobile vehicles. The ability to provide large-scale, long-term navigation using low-cost, low-power vision sensors is appealing for industrial applications. A crucial requirement for long-term navigation systems is the ability to localize in environments whose appearance is constantly changing over time—due to lighting, weather, seasons, and physical changes. This paper presents a multiexperience localization (MEL) system that uses a powerful map representation—storing every visual experience in layers—that does not make assumptions about underlying appearance modalities and generators. Our localization system provides real-time performance by selecting online, a subset of experiences against which to localize. We achieve this task through a novel experience-triage algorithm based on collaborative filtering, which selects experiences relevant to the live view, outperforming competing techniques. Based on classical memory-based recommender systems, this technique also enables landmark-level recommendations, is entirely online, and requires no training data. We demonstrate the capabilities of the MEL system in the context of long-term autonomous path following in unstructured outdoor environments with a challenging 100-day field experiment through day, night, snow, spring, and summer. We furthermore provide offline analysis comparing our system to several state-of-the-art alternatives. We show that the combination of the novel methods presented in this paper enable full use of incredibly rich multiexperience maps, opening the door to robust long-term visual localization. © 2018 Wiley Periodicals, Inc.},
  affiliation = {Institute for Aerospace Studies, Faculty of Applied Science & Engineering, University of Toronto, Toronto, ON, Canada},
  author_keywords = {mapping;  position estimation;  terrestrial robotics},
  correspondence_address1 = {MacTavish, K.; Institute for Aerospace Studies, Canada; email: kirk.mactavish@mail.utoronto.ca},
  document_type = {Article},
  funding_details = {Natural Sciences and Engineering Research Council of CanadaNatural Sciences and Engineering Research Council of Canada, NSERC},
  funding_text1 = {This workstudy was supported financially and in-kind by Clearpath Robotics and the Natural Sciences and Engineering Research Council (NSERC) through the NSERC Canadian Field Robotics Network (NCFRN).},
  issn = {15564959},
  keywords = {Collaborative filtering;  Costs;  Mapping;  Navigation systems;  Robots, Autonomous mobile vehicles;  Enabling technologies;  Localization system;  Map representations;  Outdoor environment;  Position estimation;  Real time performance;  Visual localization, Online systems},
  language = {English},
  references = {Agarwal, P., Tipaldi, G.D., Spinello, L., Stachniss, C., Burgard, W., Robust map optimization using dynamic covariance scaling (2013) 2013 IEEE International Conference on Robotics and Automation (ICRA), pp. 62-69. , May).,). IEEE; Anderson, S., Barfoot, T.D., Full STEAM ahead: Exactly sparse gaussian process regression for batch continuous-time trajectory estimation on SE (3) (2015) In 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 157-164. , September).,). IEEE; Barfoot, T.D., (2017) State estimation for robotics, , Cambridge, Cambridge University Press; Barfoot, T.D., Furgale, P.T., Associating uncertainty with three-dimensional poses for use in estimation problems (2014) IEEE Transactions on Robotics, 30 (3), pp. 679-693; Barfoot, T.D., McManus, C., Anderson, S., Dong, H., Beerepoot, E., Tong, C.H., Enright, J., (2016) Into darkness: Visual navigation based on a lidar-intensity-image pipeline, pp. 487-504. , In Robotics Research (). Cham Springer; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (surf) (2008) Computer vision and image understanding, 110 (3), pp. 346-359; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 2769-2776. , September)., (). IEEE; Chum, O., Matas, J., Kittler, J., Locally optimized RANSAC (2003) Joint Pattern Recognition Symposium, pp. 236-243. , September)., (). Berlin, Heidelberg Springer; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Clement, L., Kelly, J., How to train a CAT: Learning canonical appearance transformations for direct visual localization under illumination change (2018) IEEE Robotics and Automation Letters, 3 (3), pp. 2447-2454; Costante, G., Mancini, M., Valigi, P., Ciarfuglia, T.A., Exploring representation learning with cnns for frame-to-frame ego-motion estimation (2016) IEEE Robotics and Automation Letters, 1 (1), pp. 18-25; Csurka, G., Dance, C., Fan, L., Willamowski, J., Bray, C., Visual categorization with bags of keypoints (2004) In Workshop on statistical learning in computer vision, ECCV, 1, pp. 1-2; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Dymczyk, M., Schneider, T., Gilitschenski, I., Siegwart, R., Stumm, E., Erasing bad memories: Agent-side summarization for long-term mapping (2016) In 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4572-4579. , October).,). IEEE; Furgale, P., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) Journal of Field Robotics, 27 (5), pp. 534-560; Galler, B.A., Fisher, M.J., An improved equivalence algorithm (1964) Communications of the ACM, 7 (5), pp. 301-303; Girdhar, Y., Dudek, G., Online visual vocabularies (2011) In 2011 Canadian Conference on Computer and Robot Vision (CRV), pp. 191-196. , May)., (). IEEE; Glover, A., Maddern, W., Warren, M., Reid, S., Milford, M., Wyeth, G., (2012) OpenFABMAP: An open source toolbox for appearance-based loop closure detection. In 2012 IEEE international conference on Robotics and automation (ICRA), pp. 4730-4735. , May).,). IEEE; Johannsson, H., Kaess, M., Fallon, M., Leonard, J.J., (2013) Temporally scalable visual SLAM using a reduced pose graph. In 2013 IEEE International Conference on Robotics and Automation (ICRA), pp. 54-61. , May)., (). IEEE; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J.J., Dellaert, F., isam2: Incremental smoothing and mapping using the bayes tree (2012) The International Journal of Robotics Research, 31 (2), pp. 216-235; Kendall, A., Grimes, M., Cipolla, R., Posenet: A convolutional network for real-time 6-dof camera relocalization (2015) Proceedings of the IEEE international conference on computer vision, pp. 2938-2946; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) ISMAR, pp. 225-234; Linegar, C., Churchill, W., Newman, P., (2015) Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation. In 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 90-97. , May)., (). IEEE; Liu, N.N., Zhao, M., Xiang, E., Yang, Q., Online evolutionary collaborative filtering (2010) In Proceedings of the fourth ACM conference on Recommender systems, pp. 95-102. , September)., (). ACM; Lowry, S.M., Milford, M.J., Wyeth, G.F., Transforming morning to afternoon using linear regression techniques (2014) In Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA 2014), pp. 3950-3955. , (). IEEE; MacTavish, K., Barfoot, T.D., Towards hierarchical place recognition for long-term autonomy (2014) ICRA Workshop on Visual Place Recognition in Changing Environments, pp. 1-6. , May); MacTavish, K., Barfoot, T.D., At all costs: A comparison of robust cost functions for camera correspondence outliers (2015) In 2015 12th Conference on Computer and Robot Vision (CRV), pp. 62-69. , June)., (). IEEE; MacTavish, K., Paton, M., Barfoot, T.D., Beyond a shadow of a doubt: Place recognition with colour-constant images (2016) In Field and Service Robotics, pp. 187-199. , (). Cham Springer; MacTavish, K., Paton, M., Barfoot, T.D., Visual triage: A bag-of-words experience selector for long-term visual route following (2017) In 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 2065-2072. , May)., (). IEEE; Maddern, W., Pascoe, G., Newman, P., Leveraging experience for large-scale LIDAR localisation in changing cities (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 1684-1691. , May)., (). IEEE; McManus, C., Furgale, P., Stenning, B., Barfoot, T.D., Lighting-invariant visual teach and repeat using appearance-based lidar (2013) Journal of Field Robotics, 30 (2), pp. 254-287; McManus, C., Upcroft, B., Newmann, P., (2014) Scene signatures: Localised and point-less features for localisation, , Robotics Science and Systems; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) JFR, 33 (5). , 561–590; Neubert, P., Sünderhauf, N., Protzel, P., Superpixel-based appearance change prediction for long-term navigation across seasons (2015) Robotics and Autonomous Systems, 69, pp. 15-27; Ostafew, C.J., Schoellig, A.P., Barfoot, T.D., Collier, J., Learning-based nonlinear model predictive control to improve vision-based mobile robot path tracking (2016) Journal of Field Robotics, 33 (1), pp. 133-152; Pascoe, G., Maddern, W., Stewart, A.D., Newman, P., Farlap: Fast robust localisation using appearance priors (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 6366-6373. , May)., (). IEEE; Paton, M., MacTavish, K., Warren, M., Barfoot, T.D., Bridging the appearance gap: Multi-experience localization for long-term visual teach and repeat (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1918-1925. , October)., (). IEEE; Paton, M., MacTavish, K., Berczi, L.-P., van Es, S.K., Barfoot, T.D., I can see for miles and miles: An extended field test of visual teach and repeat 2.0 (2018) Field and Service Robotics, pp. 415-431. , (). Cham Springer; Paton, M., Pomerleau, F., MacTavish, K., Ostafew, C.J., Barfoot, T.D., Expanding the limits of vision-based localization for long-term route-following autonomy (2017) Journal of Field Robotics, 34 (1), pp. 98-122; Powell, M.J., An efficient method for finding the minimum of a function of several variables without calculating derivatives (1964) The Computer Journal, 7 (2), pp. 155-162; Sünderhauf, N., Protzel, P., Switchable constraints for robust pose graph SLAM (2012) 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1879-1884. , October)., (). IEEE; Sunderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proceedings of Robotics: Science and Systems XII; Teynor, A., Burkhardt, H., Fast codebook generation by sequential data analysis for object classification (2007) International Symposium on Visual Computing, pp. 610-620. , November).,). Berlin, Heidelberg Springer; Trahanias, P., Skordalakis, E., An efficient sequential clustering method (1989) Pattern Recognition, 22 (4), pp. 449-453; Wolcott, R.W., Eustice, R.M., Visual localization within lidar maps for automated urban driving (2014) Intelligent Robots and Systems (IROS 2014,, pp. 176-183},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055930460&doi=10.1002%2frob.21838&partnerID=40&md5=2beb6b5d9c8eb7fb7d832bcbebbd288d},
}

@conference{pirker-et-al:2011:6048253,
  author = {K. Pirker and M. Rüther and H. Bischof},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {CD SLAM - Continuous localization and mapping in a dynamic world},
  pages = {3990--3997},
  doi = {10.1109/IROS.2011.6048253},
  note = {cited By 30; Conference of 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems: Celebrating 50 Years of Robotics, IROS'11 ; Conference Date: 25 September 2011 Through 30 September 2011;  Conference Code:87712},
  address = {San Francisco, CA},
  year = {2011},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {When performing large-scale perpetual localization and mapping one faces problems like memory consumption or repetitive and dynamic scene elements requiring robust data association. We propose a visual SLAM method which handles short- and long-term scene dynamics in large environments using a single camera only. Through visibility-dependent map filtering and efficient keyframe organization we reach a considerable performance gain only through incorporation of a slightly more complex map representation. Experiments on a large, mixed indoor/outdoor dataset over a time period of two weeks demonstrate the scalability and robustness of our approach. © 2011 IEEE.},
  affiliation = {Institute for Computer Graphics and Vision, University of Technology, Graz, Austria},
  art_number = {6048253},
  coden = {85RBA},
  correspondence_address1 = {Pirker, K.; Institute for Computer Graphics and Vision, , Graz, Austria; email: kpirker@icg.tugraz.at},
  document_type = {Conference Paper},
  isbn = {9781612844541},
  keywords = {Data sets;  Dynamic scenes;  Dynamic world;  Indoor/outdoor;  Key frames;  Memory consumption;  Performance Gain;  Robust datum;  Single cameras;  Time-periods;  Visual SLAM, Intelligent robots, Robotics},
  language = {English},
  references = {Pirker, K., Rüther, M., Bischof, H., Histogram of oriented cameras - A new descriptor for visual slam in dynamic environments Proceedings of British Machine Vision Conference, 2010; Alcantarilla, G.L.M., Oh, S., Learning visibility of landmarks for vision-based localization International Conference on Robotics and Automation, 2010; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (6), pp. 1052-1067. , DOI 10.1109/TPAMI.2007.1049; Eade, E., Drummond, T., Scalable monocular SLAM International Conference on Computer Vision and Pattern Recognition, 2006, pp. 469-476; Paz, L., Pinies, P., Tardos, J., Neira, J., Large-scale 6-DOF SLAM with stereo-in-hand (2008) Transactions on Robotics, 24 (5), pp. 946-957; Clemente, L., Davison, A., Reid, I., Neira, J., Tardós, J.D., Mapping large loops with a single hand-held camera (2007) Robotics: Science and Systems; Eade, E., Drummond, T., Monocular SLAM as a graph of coalesced observations International Conference on Computer Vision, 2007; Joan, S., (2007) Towards Visual Localization, Mapping and Moving Objects Tracking by A Mobile Robot: A Geometric and Probabilistic Approach, , Ph.D. dissertation, Institut National Politechnique de Toulouse; Migliore, D., Rigamonti, R., Marzorati, D., Matteucci, M., Sorrenti, D.G., Use a single camera for simultaneous localization and mapping with mobile object tracking in dynamic environments ICRA Workshop on Safe Navigation in Open and Dynamic Environments Application to Autonomous Vehicles, 2009, pp. 27-32; Hochdorfer, S., Schlegel, C., Towards a robust visual SLAM approach: Addressing the challenge of life-long operation International Conference on Advanced Robotics, 2009, pp. 1-6; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces IEEE and ACM International Symposium on Mixed and Augmented Reality, 2007, pp. 225-234; Mouragnon, E., Lhuillier, M., Dhome, M., Dekeyser, F., Sayd, P., 3D reconstruction of complex structures with bundle adjustment: An incremental approach International Conference on Robotics and Automation, 2006; Newcombe, R.A., Davison, A.J., Live dense reconstruction with a single moving camera International Conference on Computer Vision and Pattern Recognition, 2010; Strasdat, H., Montiel, J.M.M., Davison, A., Scale drift-aware large scale monocular SLAM (2010) Robotics: Science and Systems; Mei, C., Sibley, G., Cummins, M., Newman, P., Reid, I., A constant time efficient stereo SLAM system British Machine Vision Conference, 2009; Mei, C., Sibley, G., Cummins, M., Newman, P., Reid, I., RSLAM: A system for large-scale mapping in constant-time using stereo (2010) International Journal of Computer Vision, pp. 1-17; Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to real-time visual mapping (2008) Transactions on Robotics, 24, pp. 1066-1077; Sibley, G., Mei, C., Reid, I., Newman, P., Adaptive relative bundle adjustment (2009) Robotics: Science and Systems; Giorgio Grisetti, C.S., Burgard, W., Non-linear constraint network optimization for efficient map learning (2009) Transactions on Intelligent Transportation Systems, 10, pp. 428-439; Konolige, K., Bowman, J., Towards lifelong visual maps International Conference on Intelligent Robots and Systems, 2009, pp. 1156-1163; Glover, A., Maddern, W., Milford, M., Wyeth, G., FAB-MAP + RatSLAM: Appearance-based slam for multiple times of day International Conference on Robotics and Automation, 2010; Milford, M., Wyeth, G., Mapping a suburb with a single camera using a biologically inspired SLAM system (2008) Transactions on Robotics, 24, pp. 1038-1053; Cummins, M., Newman, P., Highly scalable appearance-only SLAM - FAB-MAP 2.0 (2009) Robotics: Science and Systems; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Clipp, B., Lim, J., Frahm, J.-M., Pollefeys, M., Parallel, real-time visual SLAM International Conference on Intelligent Robots and Systems, 2010; Cummins, M., Newman, P., Accelerated appearance-only SLAM International Conference on Robotics and Automation, 2008, pp. 1828-1833; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Commun. ACM, 24, pp. 381-395},
  source = {Scopus},
  sponsors = {IEEE Robotics and Automation Society (RAS); IEEE Industrial Electronics Society (IES); Robotics Society of Japan (RSJ); Society of Instrument and Control Engineers (SICE); New Technology Foundation (NTF)},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84455179037&doi=10.1109%2fIROS.2011.6048253&partnerID=40&md5=60745ea0c111857b93343287fc874a6e},
}

@conference{wang-et-al:2019:8793499,
  author = {K. Wang and Y. Lin and L. Wang and L. Han and M. Hua and X. Wang and S. Lian and B. Huang},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {A unified framework for mutual improvement of SLAM and semantic segmentation},
  volume = {2019-May},
  pages = {5224--5230},
  doi = {10.1109/ICRA.2019.8793499},
  note = {cited By 11; Conference of 2019 International Conference on Robotics and Automation, ICRA 2019 ; Conference Date: 20 May 2019 Through 24 May 2019;  Conference Code:150804},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {This paper presents a novel framework for simultaneously implementing localization and segmentation, which are two of the most important vision-based tasks for robotics. While the goals and techniques used for them were considered to be different previously, we show that by making use of the intermediate results of the two modules, their performance can be enhanced at the same time. Our framework is able to handle both the instantaneous motion and long-term changes of instances in localization with the help of the segmentation result, which also benefits from the refined 3D pose information. We conduct experiments on various datasets, and prove that our framework works effectively on improving the precision and robustness of the two tasks and outperforms existing localization and segmentation algorithms. © 2019 IEEE.},
  affiliation = {CloudMinds Technologies Inc, Beijing, 100102, China},
  art_number = {8793499},
  coden = {PIIAE},
  document_type = {Conference Paper},
  isbn = {9781538660263},
  issn = {10504729},
  language = {English},
  references = {Bescos, B., Fcil, J.M., Civera, J., Neira, J., Dynaslam: Tracking, mapping, and inpainting in dynamic scenes (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 4076-4083; Guo, Y., Liu, Y., Georgiou, T., Lew, M.S., A review of semantic segmentation using deep neural networks (2018) International Journal of Multimedia Information Retrieval, 7 (2), pp. 87-93; Taketomi, T., Uchiyama, H., Ikeda, S., Visual slam algorithms: A survey from 2010 to 2016 (2017) IPSJ Transactions on Computer Vision and Applications, 9 (1), p. 16; Klein, G., Murray, D., Parallel tracking and mapping for small ar workspaces (2007) 6th IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR), pp. 225-234; Mur-Artal, R., Tardós, J.D., Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Saputra, M.R.U., Markham, A., Trigoni, N., Visual slam and structure from motion in dynamic environments: A survey (2018) ACM Computing Surveys (CSUR), 51 (2), p. 37; Klappstein, J., Vaudrey, T., Rabe, C., Wedel, A., Klette, R., Moving object segmentation using optical flow and depth information (2009) Pacific-Rim Symposium on Image and Video Technology, pp. 611-623; Reddy, N.D., Singhal, P., Chari, V., Krishna, K.M., Dynamic body vslam with semantic constraints (2015) Proceedings of the International Conference on Intelligent Robot Systems (IROS), pp. 1897-1904; Kaneko, M., Iwami, K., Ogawa, T., Yamasaki, T., Aizawa, K., Mask-slam: Robust feature-based monocular slam by masking using semantic segmentation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 258-266; Chen, L.-C., Papandreou, G., Kokkinos, I., Murphy, K., Yuille, A.L., Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs (2018) IEEE Transactions on Pattern Analysis & Machine Intelligence (TPAMI), 40 (4), pp. 834-848; Bârsan, I.A., Liu, P., Pollefeys, M., Geiger, A., Robust dense mapping for large-scale dynamic environments (2018) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Zhong, F., Wang, S., Ziqi, Z., Chen, C., Wang, Y., Detect-slam: Making object detection and slam mutually beneficial (2018) 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 1001-1010; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3431-3440; Badrinarayanan, V., Kendall, A., Cipolla, R., (2015) Segnet: A Deep Convolutional Encoder-decoder Architecture for Image Segmentation, , arXiv preprint arXiv:1511.00561; Chen, L.-C., Papandreou, G., Schroff, F., Adam, H., (2017) Rethinking Atrous Convolution for Semantic Image Segmentation, , arXiv preprint arXiv:1706.05587; Wu, T., Bajwa, W.U., A low tensor-rank representation approach for clustering of imaging data (2018) IEEE Signal Processing Letters, 25 (8), pp. 1196-1200; Chen, L.-C., Zhu, Y., Papandreou, G., Schroff, F., Adam, H., (2018) Encoder-decoder with Atrous Separable Convolution for Semantic Image Segmentation, , arXiv preprint arXiv: 1802.02611; Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J., Pyramid scene parsing network (2017) IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), pp. 2881-2890; Hariharan, B., Arbeláez, P., Girshick, R., Malik, J., Simultaneous detection and segmentation (2014) European Conference on Computer Vision (ECCV), pp. 297-312; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 580-587; Dai, J., He, K., Sun, J., Instance-aware semantic segmentation via multi-task network cascades (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3150-3158; Li, Y., Qi, H., Dai, J., Ji, X., Wei, Y., (2016) Fully Convolutional Instanceaware Semantic Segmentation, , arXiv preprint arXiv:1611.07709; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask r-cnn (2018) IEEE Transactions on Pattern Analysis & Machine Intelligence (TPAMI); Ren, S., He, K., Girshick, R., Sun, J., Faster r-cnn: Towards real-time object detection with region proposal networks (2017) IEEE Transactions on Pattern Analysis & Machine Intelligence (TPAMI), (6), pp. 1137-1149; Qiu, Z., Yao, T., Mei, T., Learning deep spatio-temporal dependence for semantic video segmentation (2018) IEEE Transactions on Multimedia, 20 (4), pp. 939-949; Tran, D., Bourdev, L., Fergus, R., Torresani, L., Paluri, M., Learning spatiotemporal features with 3d convolutional networks (2015) Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp. 4489-4497; Shi, X., Chen, Z., Wang, H., Yeung, D.-Y., Wong, W.-K., Woo, W.-C., Convolutional lstm network: A machine learning approach for precipitation nowcasting (2015) Advances in Neural Information Processing Systems, pp. 802-810; Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L., Microsoft coco: Common objects in context (2014) European Conference on Computer Vision (ECCV), pp. 740-755; Sturm, J., A benchmark for the evaluation of rgb-d slam eystems (2012) Proceedings of the International Conference on Intelligent Robot Systems (IROS), pp. 573-580; Dai, A., Chang, A.X., Savva, M., Halber, M., Funkhouser, T., Nießner, M., Scannet: Richly-annotated 3d reconstructions of indoor scenes (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2432-2443; Shah, S., Dey, D., Lovett, C., Kapoor, A., Airsim: High-fidelity visual and physical simulation for autonomous vehicles (2017) Field and Service Robotics},
  source = {Scopus},
  sponsors = {Bosch; DJI; et al.; Kinova; Mercedes-Benz; Samsung},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071467185&doi=10.1109%2fICRA.2019.8793499&partnerID=40&md5=05fc4d5a3dc8587bf249a1eed15b955a},
}

@article{zhang-et-al:2022:3086822,
  author = {K. Zhang and X. Jiang and J. Ma},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  title = {Appearance-Based Loop Closure Detection via Locality-Driven Accurate Motion Field Learning},
  volume = {23},
  number = {3},
  pages = {2350--2365},
  doi = {10.1109/TITS.2021.3086822},
  note = {cited By 1},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2022},
  abbrev_source_title = {IEEE Trans. Intell. Transp. Syst.},
  abstract = {Loop closure detection (LCD) is of significant importance in simultaneous localization and mapping. It represents the robot's ability to recognize whether the current surrounding corresponds to a previously observed one. In this paper, we conduct this task in a two-step strategy: candidate frame selection and loop closure verification. The first step aims to search semantically similar images for the query one using features obtained by Key.Net with HardNet. Instead of adopting the traditional Bag-of-Words strategy, we utilize the aggregated selective match kernel to calculate the similarity between images. Subsequently, based on the potential property of motion field in the LCD scene, we propose a novel feature matching method, i.e., exploiting the smoothness prior and learning the motion field for an image pair in a reproducing kernel Hilbert space (RKHS), to implement loop closure verification. Concretely, we formulate the learning problem into a Bayesian framework with latent variables indicating the true/false correspondences and a mixture model accounting for the distribution of data. Furthermore, we propose a locality-driven mechanism to enhance the local relevance of motion vectors and term the algorithm as locality-driven accurate motion field learning (LAL). To satisfy the requirement of efficiency in the LCD task, we use a sparse approximation and search a suboptimal solution for the motion field in the RKHS, termed as LAL∗. Extensive experiments are conducted on public datasets for feature matching and LCD tasks. The quantitative results demonstrate the effectiveness of our method over the current state-of-the-art, meanwhile showing its potential for long-term visual localization. The codes of LAL and LAL∗ are publicly available at https://github.com/KN-Zhang/LAL. © 2000-2011 IEEE.},
  affiliation = {Electronic Information School, Wuhan University, Wuhan, 430072, China},
  author_keywords = {autonomous vehicle;  feature matching;  loop closure detection;  place recognition;  SLAM},
  correspondence_address1 = {Ma, J.; Electronic Information School, China; email: jyma2010@gmail.com},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61773295},
  funding_text1 = {This work was supported in part by the National Natural Science Foundation of China under Grant 61773295, in part by the Key Research and Development Program of Hubei Province under Grant 2020BAB113, and in part by the Natural Science Foundation of Hubei Province under Grant 2019CFA037.},
  issn = {15249050},
  keywords = {Computer applications;  Intelligent systems, Bayesian frameworks;  Feature matching methods;  Quantitative result;  Reproducing Kernel Hilbert spaces;  Simultaneous localization and mapping;  Sparse approximations;  Suboptimal solution;  Visual localization, Learning systems},
  language = {English},
  references = {Nguyen, D.-D., Elouardi, A., Florez, S.A.R., Bouaziz, S., HOOFR SLAM system: An embedded vision SLAM algorithm and its hardwaresoftware mapping-based intelligent vehicles applications (2019) IEEE Trans. Intell. Transp. Syst., 20 (11), pp. 4103-4118. , Nov; Han, J., Kim, J., Shim, D.H., Precise localization and mapping in indoor parking structures via parameterized SLAM (2019) IEEE Trans. Intell. Transp. Syst., 20 (12), pp. 4415-4426. , Dec; Cadena, C., Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age (2016) IEEE Trans. Robot., 32 (6), pp. 1309-1332. , Dec; Williams, B., Cummins, M., Neira, J., Newman, P., Reid, I., Tardós, J., A comparison of loop closing techniques in monocular SLAM (2009) Robot. Auto. Syst., 57 (12), pp. 1188-1197. , Dec; Lowry, S., Visual place recognition: A survey (2016) IEEE Trans. Robot., 32 (1), pp. 1-19. , Feb; Kazmi, S.M.A.M., Mertsching, B., Detecting the expectancy of a place using nearby context for appearance-based mapping (2019) IEEE Trans. Robot., 35 (6), pp. 1352-1366. , Dec; Sarlin, P.-E., Cadena, C., Siegwart, R., Dymczyk, M., From coarse to fine: Robust hierarchical localization at large scale (2019) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 12716-12725. , Jun; Cao, B., Araujo, A., Sim, J., Unifying deep local and global features for image search (2020) Proc. Eur. Conf. Comput. Vis., pp. 726-743; Macqueen, J., Some methods for classification and analysis of multivariate observations (1967) Proc. 5th Berkeley Symp. Math. Statist. Probab., pp. 281-297. , Jun; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003) Proc. 9th IEEE Int. Conf. Comput. Vis., p. 1470. , Oct; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) Int. J. Robot. Res., 30 (9), pp. 1100-1123. , Aug; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665. , Jun; Bampis, L., Amanatiadis, A., Gasteratos, A., Fast loop-closure detection using visual-word-vectors from image sequences (2018) Int. J. Robot. Res., 37 (1), pp. 62-82. , Jan; Galvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Mur-Artal, R., Tardos, J.D., Fast relocalisation and loop closing in keyframe-based SLAM (2014) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 846-853. , May; Khan, S., Wollherr, D., IBuILD: Incremental bag of binary words for appearance based loop closure detection (2015) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 5441-5447. , May; Garcia-Fidalgo, E., Ortiz, A., IBoW-LCD: An appearance-based loop-closure detection approach using incremental bags of binary words (2018) IEEE Robot. Autom. Lett., 3 (4), pp. 3051-3057. , Oct; Tsintotas, K.A., Bampis, L., Gasteratos, A., Assigning visual words to places for loop closure detection (2018) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 1-7. , May; Tsintotas, K.A., Bampis, L., Gasteratos, A., Probabilistic appearance-based place recognition through bag of tracked words (2019) IEEE Robot. Autom. Lett., 4 (2), pp. 1737-1744. , Apr; Perronnin, F., Dance, C., Fisher kernels on visual vocabularies for image categorization (2007) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 1-8. , Jun; Jégou, H., Douze, M., Schmid, C., Improving bag-of-features for large scale image search (2010) Int. J. Comput. Vis., 87 (3), pp. 316-336. , May; Ji, R., Location discriminative vocabulary coding for mobile landmark search (2012) Int. J. Comput. Vis., 96 (3), pp. 290-314. , Feb; Tolias, G., Avrithis, Y., Jégou, H., Image search with selective match kernels: Aggregation across single and multiple images (2016) Int. J. Comput. Vis., 116 (3), pp. 247-261. , Feb; Andrew, A.M., Multiple view geometry in computer vision (2001) Kybernetes, 30 (9-10), pp. 1333-1341. , Dec; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Commun. ACM, 24 (6), pp. 381-395. , Jun; Laguna, A.B., Riba, E., Ponsa, D., Mikolajczyk, K., Key.Net: Keypoint detection by handcrafted and learned CNN filters (2019) Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 5836-5844. , Oct; Mishchuk, A., Mishkin, D., Radenovic, F., Matas, J., (2017) Working Hard to Know Your Neighbor's Margins: Local Descriptor Learning Loss, , https://arxiv.org/abs/1705.10872; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis., 60 (2), pp. 91-110. , Nov; Bay, H., Tuytelaars, T., Van Gool, L., Surf: Speeded up robust features (2006) Proc. Eur. Conf. Comput. Vis., pp. 404-417; Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Trans. Inf. Theory, IT-14 (3), pp. 462-467. , May; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) Proc. Int. Conf. Comput. Vis., pp. 2564-2571. , Nov; Leutenegger, S., Chli, M., Siegwart, R.Y., BRISK: Binary robust invariant scalable keypoints (2011) Proc. Int. Conf. Comput. Vis., pp. 2548-2555. , Nov; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst., pp. 1097-1105; Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., Oliva, A., Learning deep features for scene recognition using places database (2014) Proc. Adv. Neural Inf. Process. Syst., pp. 1-10; Yi, K.M., Trulls, E., Lepetit, V., Fua, P., Lift: Learned invariant feature transform (2016) Proc. Eur. Conf. Comput. Vis., pp. 467-483; Choy, C.B., Gwak, J., Savarese, S., Chandraker, M., Universal correspondence network (2016) Proc. Adv. Neural Inf. Process. Syst., pp. 2414-2422; Simo-Serra, E., Trulls, E., Ferraz, L., Kokkinos, I., Fua, P., Moreno-Noguer, F., Discriminative learning of deep convolutional feature point descriptors (2015) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 118-126. , Dec; Noh, H., Araujo, A., Sim, J., Weyand, T., Han, B., Large-scale image retrieval with attentive deep local features (2017) Proc. IEEE Int. Conf. Comput. Vis. (ICCV), pp. 3456-3465. , Oct; Detone, D., Malisiewicz, T., Rabinovich, A., SuperPoint: Selfsupervised interest point detection and description (2018) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 224-236. , Jun; Luo, Z., ASLFeat: Learning local features of accurate shape and localization (2020) Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 6589-6598. , Jun; Ma, J., Jiang, X., Fan, A., Jiang, J., Yan, J., Image matching from handcrafted to deep features: A survey (2021) Int. J. Comput. Vis., 129 (1), pp. 23-79. , Jan; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 5297-5307. , Jun; Yu, J., Zhu, C., Zhang, J., Huang, Q., Tao, D., Spatial pyramidenhanced NetVLAD with weighted triplet loss for place recognition (2020) IEEE Trans. Neural Netw. Learn. Syst., 31 (2), pp. 661-674. , Feb; Xia, Y., Li, J., Qi, L., Fan, H., Loop closure detection for visual SLAM using PCANet features (2016) Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 2274-2281. , Jul; Chen, Z., Deep learning features at scale for visual place recognition (2017) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 3223-3230. , May; Wang, T.-H., Huang, H.-J., Lin, J.-T., Hu, C.-W., Zeng, K.-H., Sun, M., Omnidirectional CNN for visual place recognition and navigation (2018) Proc. IEEE Int. Conf. Robot. Automat. (ICRA), pp. 2341-2348. , May; An, S., Che, G., Zhou, F., Liu, X., Ma, X., Chen, Y., (2019) Fast and Incremental Loop Closure Detection Using Proximity Graphs, , https://arxiv.org/abs/1911.10752; An, S., Zhu, H., Wei, D., Tsintotas, K.A., (2020) Fast and Incremental Loop Closure Detection with Deep Features and Proximity Graphs, , https://arxiv.org/abs/2010.11703; Torr, P.H.S., Zisserman, A., MLESAC: A new robust estimator with application to estimating image geometry (2000) Comput. Vis. Image Understand., 78 (1), pp. 138-156. , Apr; Ma, J., Wu, J., Zhao, J., Jiang, J., Zhou, H., Sheng, Q.Z., Nonrigid point set registration with robust transformation learning under manifold regularization (2019) IEEE Trans. Neural Netw. Learn. Syst., 30 (12), pp. 3584-3597. , Dec; Li, X., Hu, Z., Rejecting mismatches by correspondence function (2010) Int. J. Comput. Vis., 89 (1), pp. 1-17. , Aug; Ma, J., Zhao, J., Tian, J., Yuille, A.L., Tu, Z., Robust point matching via vector field consensus (2014) IEEE Trans. Image Process., 23 (4), pp. 1706-1721. , Apr; Liu, H., Yan, S., Common visual pattern discovery via spatially coherent correspondences (2010) Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit., pp. 1609-1616. , Jun; Yan, J., Cho, M., Zha, H., Yang, X., Chu, S.M., Multi-graph matching via affinity optimization with graduated consistency regularization (2016) IEEE Trans. Pattern Anal. Mach. Intell., 38 (6), pp. 1228-1242. , Jun; Ma, J., Zhao, J., Jiang, J., Zhou, H., Guo, X., Locality preserving matching (2019) Int. J. Comput. Vis., 127 (5), pp. 512-531. , May; Bian, J., Lin, W.-Y., Matsushita, Y., Yeung, S.-K., Nguyen, T.-D., Cheng, M.-M., GMS: Grid-based motion statistics for fast, ultra-robust feature correspondence (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 4181-4190. , Jul; Jiang, X., Ma, J., Jiang, J., Guo, X., Robust feature matching using spatial clustering with heavy outliers (2020) IEEE Trans. Image Process., 29, pp. 736-746; Tian, Y., Fan, B., Wu, F., L2-Net: Deep learning of discriminative patch descriptor in Euclidean space (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 661-669. , Jul; Zheng, Y., Doermann, D., Robust point matching for nonrigid shapes by preserving local neighborhood structures (2006) IEEE Trans. Pattern Anal. Mach. Intell., 28 (4), pp. 643-649. , Apr; Rodriguez, A., Laio, A., Clustering by fast search and find of density peaks (2014) Science, 344 (6191), pp. 1492-1496. , Jun; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The KITTI dataset (2013) Int. J. Robot. Res., 32 (11), pp. 1231-1237. , Sep; Blanco, J.-L., Moreno, F.-A., Gonzalez, J., A collection of outdoor robotic datasets with centimeter-accuracy ground truth (2009) Auton. Robots, 27 (4), p. 327. , Nov; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., FABMAP+ RatSLAM: Appearance-based slam for multiple times of day (2010) Proc. IEEE Int. Conf. Robot. Automat., pp. 3507-3512. , May; Tola, E., Lepetit, V., Fua, P., DAISY: An efficient dense descriptor applied to wide-baseline stereo (2010) IEEE Trans. Pattern Anal. Mach. Intell., 32 (5), pp. 815-830. , May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112137846&doi=10.1109%2fTITS.2021.3086822&partnerID=40&md5=f812b052eeeebb7e670b6067e3d100a8},
}

@article{clement-et-al:2020:2967659,
  author = {L. Clement and M. Gridseth and J. Tomasi and J. Kelly},
  journal = {IEEE Robotics and Automation Letters},
  title = {Learning Matchable Image Transformations for Long-Term Metric Visual Localization},
  volume = {5},
  number = {2},
  pages = {1492--1499},
  doi = {10.1109/LRA.2020.2967659},
  note = {cited By 6},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Long-term metric self-localization is an essential capability of autonomous mobile robots, but remains challenging for vision-based systems due to appearance changes caused by lighting, weather, or seasonal variations. While experience-based mapping has proven to be an effective technique for bridging the 'appearance gap,' the number of experiences required for reliable metric localization over days or months can be very large, and methods for reducing the necessary number of experiences are needed for this approach to scale. Taking inspiration from color constancy theory, we learn a nonlinear RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature matches for images captured under different lighting and weather conditions, and use it as a pre-processing step in a conventional single-experience localization pipeline to improve its robustness to appearance change. We train this mapping by approximating the target non-differentiable localization pipeline with a deep neural network, and find that incorporating a learned low-dimensional context feature can further improve cross-appearance feature matching. Using synthetic and real-world datasets, we demonstrate substantial improvements in localization performance across day-night cycles, enabling continuous metric localization over a 30-hour period using a single mapping experience, and allowing experience-based localization to scale to long deployments with dramatically reduced data requirements. © 2016 IEEE.},
  affiliation = {Space and Terrestrial Autonomous Robotic Systems (STARS) Lab, University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, ON  M3H 5T6, Canada; Autonomous Space Robotics Lab (ASRL), UTIAS, North York, ON  M3H 5T6, Canada},
  art_number = {8963763},
  author_keywords = {Deep learning in robotics and automation;  localization;  visual learning;  visual-based navigation},
  correspondence_address1 = {Clement, L.; Space and Terrestrial Autonomous Robotic Systems (STARS) Lab, Canada; email: lee.clement@mail.utoronto.ca},
  document_type = {Article},
  issn = {23773766},
  keywords = {Deep neural networks;  Image enhancement;  Lighting;  Mapping;  Pipelines;  Robots;  User experience, Autonomous Mobile Robot;  Image transformations;  localization;  Localization performance;  Pre-processing step;  Vision based system;  Visual learning;  Visual localization, Deep learning},
  language = {English},
  references = {Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int. J. Robot. Res., 32, pp. 1645-1661. , Dec; Linegar, C., Churchill, W., Newman, P., Work smart, not hard:Recalling relevant experiences for vast-scale but time-constrained localisation (2015) Proc. IEEE Int. Conf. Robot. Autom., pp. 90-97. , May; Paton, M., MacTavish, K., Warren, M., Barfoot, T.D., Bridging the appearance gap: Multi-experience localization for long-term visual teach and repeat (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst., pp. 1918-1925. , Oct; Paton, M., MacTavish, K., Berczi, L.-P., Van Es, S.K., Barfoot, T.D., I can see for miles and miles: An extended field test of visual teach and repeat 2. 0 (2018) Proc. Field Service Robot., pp. 415-431; Clement, L., Kelly, J., How to train a CAT: Learning canonical appearance transformations for direct visual localization under illumination change (2018) IEEE Robot. Autom. Lett., 3 (3), pp. 2447-2454. , Jul; Porav, H., Maddern, W., Newman, P., Adversarial training for adverse conditions: Robustmetric localisation using appearance transfer (2018) Proc. IEEE Int. Conf. Robot. Autom., pp. 1011-1018. , May; Isola, P., Zhu, J.Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 5967-5976. , Jul; Zhu, J., Park, T., Isola, P., Efros, A.A., Unpaired image-to-image translation using cycle-consistent adversarial networks (2017) Proc. IEEE Int. Conf. Comput. Vision, pp. 2242-2251. , Oct; Ratnasingam, S., Collins, S., Study of the photodetector characteristics of a camera for color constancy in natural scenes (2010) J. Opt. Soc. America A, 27 (2), pp. 286-294; Paszke, A., PyTorch: An imperative style, high-performance deep learning library (2019) Proc. Conf. Neural Inf. Processing Syst., pp. 8024-8035. , Dec; Clement, L., Kelly, J., Barfoot, T.D., Robust monocular visual teach and repeat aided by local ground planarity and color-constant imagery (2017) J. Field Robot., 34 (1), pp. 74-97; Corke, P., Paul, R., Churchill, W., Newman, P., Dealing with shadows: Capturing intrinsic scene appearance for image-based outdoor localisation (2013) Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst., pp. 2085-2092; McManus, C., Churchill, W., Maddern, W., Stewart, A.D., Newman, P., Shady dealings: Robust, long-term visual localisation using illumination invariance (2014) Proc. IEEE Int. Conf. Robot. Automat., pp. 901-906. , May; Paton, M., Pomerleau, F., MacTavish, K., Ostafew, C.J., Barfoot, T.D., Expanding the limits of vision-based localization for long-term route-following autonomy (2017) J. Field Robot., 34 (1), pp. 98-122; Engel, J., Stuckler, J., Cremers, D., Large-scale direct SLAM with stereo cameras (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst., pp. 1935-1942; Park, S., Schöps, T., Pollefeys, M., Illumination change robustness in direct visual SLAM (2017) Proc. IEEE Int. Conf. Robot. Autom., pp. 4523-4530. , May; McManus, C., Upcroft, B., Newman, P., Learning place-dependant features for long-term vision-based localisation (2015) Auton. Robots, 39 (3), pp. 363-387; Linegar, C., Churchill, W., Newman, P., Made to measure: Bespoke landmarks for 24-hour, all-weather localisation with a camera (2016) Proc. IEEE Int. Conf. Robot. Autom., pp. 787-794. , May; Krajník, T., Cristóforis, P., Kusumam, K., Neubert, P., Duckett, T., Image features for visual teach-and-repeat navigation in changing environments (2017) Robot. Auton. Syst., 88, pp. 127-141; Zhang, N., Warren, M., Barfoot, T.D., Learning place-and-timedependent binary descriptors for long-term visual localization (2018) Proc. IEEE Int. Conf. Robot. Autom., pp. 828-835. , May; Gomez-Ojeda, R., Zhang, Z., Gonzalez-Jimenez, J., Scaramuzza, D., Learning-based image enhancement for visual odometry in challenging HDR environments (2018) Proc. IEEE Int. Conf. Robot. Autom., pp. 805-811. , May; Latif, Y., Garg, R., Milford, M., Reid, I., Addressing challenging place recognition tasks using generative adversarial networks (2018) Proc. IEEE Int. Conf. Robot. Autom., pp. 2349-2355. , May; Anoosheh, A., Sattler, T., Timofte, R., Pollefeys, M., Gool, L.V., Nightto-day image translation for retrieval-based localization (2019) Proc. IEEE Int. Conf. Robot. Autom., pp. 5958-5964. , May; Koziel, S., Ciaurri, D.E., Leifsson, L., (2011) Surrogate-BasedMethods, pp. 33-59. , Berlin, Germany: Springer; Grzeszczuk, R., Terzopoulos, D., Hinton, G., Fast neural network emulation of dynamical systems for computer animation (1998) Proc. Conf. Neural Inf. Process. Syst., pp. 882-888; Merwe Der Van, R., Leen, T.K., Lu, Z., Frolov, S., Baptista, A.M., Fast neural network surrogates for very high dimensional physics-based models in computational oceanography (2007) Neural Netw., 20 (4), pp. 462-478; Goodfellow, I., Generative adversarial nets (2014) Proc. Conf. Neural Inf. Process. Syst., pp. 2672-2680. , Dec; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) Proc. Eur. Conf. Comput. Vision, Lecture Notes in Comput. Science, pp. 694-711. , Oct; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automatated cartography (1981) Commun. ACM, 24 (6), pp. 381-395; Geiger, A., Ziegler, J., Stiller, C., StereoScan: Dense 3D reconstruction in real-time (2011) Proc. IEEE Intell. Vehicles Symp., pp. 963-968. , Jun; Peretroukhin, V., Kelly, J., DPC-Net: Deep pose correction for visual localization (2018) IEEE Robot. Autom. Lett., 3 (3), pp. 2424-2431. , Jul; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (SURF) (2008) Comput. Vision Image Understanding, 110 (3), pp. 346-359; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) Proc. IEEE Int. Conf. Comput. Vision, pp. 2564-2571. , Nov; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 770-778. , Jun; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) Proc. Int. Conf. Mach. Learn., pp. 448-456. , Jul; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification (2015) Proc. IEEE Int. Conf. Comput. Vision, pp. 1026-1034. , Dec; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) Proc. Int. Conf. Learn. Representations; Gaidon, A., Wang, Q., Cabon, Y., Vig, E., Virtual worlds as proxy for multi-object tracking analysis (2016) Proc. IEEE Conf. Comput. Vision Pattern Recognit., pp. 4340-4349. , June; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The KITTI dataset (2013) Int. J. Robot. Res., 32, pp. 1231-1237. , Sep; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: The Oxford RobotCar dataset (2017) Int. J. Robot. Res., 36 (1), pp. 3-15},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079679538&doi=10.1109%2fLRA.2020.2967659&partnerID=40&md5=86c18ca6085961f1d756911157a03dcb},
}

@conference{camara-et-al:2020:9196967,
  author = {L. G. Camara and C. Gabert and L. Preucil},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Highly Robust Visual Place Recognition Through Spatial Matching of CNN Features},
  pages = {3748--3755},
  doi = {10.1109/ICRA40945.2020.9196967},
  note = {cited By 10; Conference of 2020 IEEE International Conference on Robotics and Automation, ICRA 2020 ; Conference Date: 31 May 2020 Through 31 August 2020;  Conference Code:163172},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {We revise, improve and extend the system previously introduced by us and named SSM-VPR (Semantic and Spatial Matching Visual Place Recognition), largely boosting its performance above the current state of the art. The system encodes images of places by employing the activations of different layers of a pre-trained, off-the-shelf, VGG16 Convolutional Neural Network (CNN) architecture. It consists of two stages: given a query image of a place, (1) a list of candidates is selected from a database of places and (2) the candidates are geometrically compared with the query. The comparison is made by matching CNN features and, equally important, their spatial locations, selecting the best candidate as the recognized place. The performance of the system is maximized by finding optimal image resolutions during the second stage and by exploiting temporal correlation between consecutive frames in the employed datasets. © 2020 IEEE.},
  affiliation = {Czech Technical University in Prague, Czech Institute of Informatics, Prague, 160 00, Czech Republic},
  art_number = {9196967},
  author_keywords = {Convolutional Neural Networks;  Life-long Navigation;  Loop Closure;  SLAM;  Visual Place Recognition},
  coden = {PIIAE},
  document_type = {Conference Paper},
  funding_details = {Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme, H2020, 688117},
  funding_text1 = {ACKNOWLEDGMENT This work has been supported by the European Union’s Horizon 2020 research and innovation programme under grant agreement No 688117 (Safelog) and by the European Regional Development Fund under the project Robotics for Industry 4.0 (reg. no. CZ.02.1.01/0.0/0.0/15 003/0000470).},
  isbn = {9781728173955},
  issn = {10504729},
  keywords = {Agricultural robots;  Image resolution;  Multilayer neural networks;  Query processing;  Robotics;  Semantics, Different layers;  Place recognition;  Query images;  Spatial location;  Spatial matching;  State of the art;  Temporal correlations, Convolutional neural networks},
  language = {English},
  references = {Krajník, T., (2018) Long-term Autonomy of Mobile Robots in Changing Environments, , Habilitation. Czech Technical University in Prague; Kunze, L., Artificial intelligence for long-term robot autonomy: A survey (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 4023-4030; Cadena, C., Past, present, and future of simultaneous localization and mapping: Toward the robustperception age (2016) IEEE Transactions on Robotics, 32 (6), pp. 1309-1332; Davison, A.J., Real-time simultaneous localisation and mapping with a single camera (2003) Iccv., 3, pp. 1403-1410; Labbe, M., Michaud, F., Online global loop closure detection for large-scale multi-session graph-based slam (2014) 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE., pp. 2661-2666; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Hou, Y., Zhang, H., Zhou, S., Convolutional neural network-based image representation for visual loop closure detection (2015) 2015 IEEE International Conference on Information and Automation. IEEE., pp. 2238-2245; Lowry, S., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Arandjelovic, R., NetVLAD: Cnn architecture for weakly supervised place recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 5297-5307; Torii, A., Visual place recognition with repetitive structures (2013) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 883-890; Chen, Z., (2014) Convolutional Neural Network-based Place Recognition; Sünderhauf, N., (2015) On the Performance of Convnet Features for Place Recognition; Sünderhauf, N., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proceedings of Robotics: Science and Systems XII; Arroyo, R., Fusion and binarization of cnn features for robust topological localization across seasons (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE., pp. 4656-4663; Chen, Z., Deep learning features at scale for visual place recognition (2017) Robotics and Automation (ICRA), 2017 IEEE International Conference On. IEEE., pp. 3223-3230; Chen, Z., Only look once, mining distinctive landmarks from convnet for visual place recognition (2017) 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE., pp. 9-16; Khaliq, A., (2018) A Holistic Visual Place Recognition Approach Using Lightweight CNNs for Severe View-Point and Appearance Changes; Cascianelli, S., Robust visual semi-semantic loop closure detection by a covisibility graph and cnn features (2017) Robotics and Autonomous Systems, 92, pp. 53-65; Camara, L.G., Preucil, L., Spatio-semantic convnet-based visual place recognition (2019) 2019 European Conference on Mobile Robots. IEEE., pp. 1-8; Zaffar, M., (2019) Levelling the Playing Field: A Comprehensive Comparison of Visual Place Recognition Approaches under Changing Conditions; Karami, E., Prasad, S., Shehata, M., (2017) Image Matching Using SIFT, SURF, BRIEF and ORB: Performance Comparison for Distorted Images; Sharif Razavian, A., CNN features off-the-shelf: An astounding baseline for recognition (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops., pp. 806-813; Philbin, J., Object retrieval with large vocabularies and fast spatial matching (2007) 2007 IEEE Conference on Computer Vision and Pattern Recognition. IEEE., pp. 1-8; Cummins, M., Newman, P., Appearance-only slam at large scale with fab-map 2. 0 (2011) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Cadena, C., Robust place recognition with stereo sequences (2012) IEEE Transactions on Robotics, 28 (4), pp. 871-885; Rocco, I., Arandjelovic, R., Sivic, J., Convolutional neural network architecture for geometric matching (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 6148-6157; Taira, H., InLoc: Indoor visual localization with dense matching and view synthesis (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition., pp. 7199-7209; Zhou, B., Places: A 10 million image database for scene recognition (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40 (6), pp. 1452-1464; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) 2012 IEEE International Conference on Robotics and Automation. IEEE., pp. 1643-1649; Hansen, P., Browning, B., Visual place recognition using hmm sequence matching (2014) 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE., pp. 4549-4555; Ho, K.L., Newman, P., Detecting loop closure with scene sequences (2007) International Journal of Computer Vision, 74 (3), pp. 261-286; Olid, D., Fácil, J.M., Civera, J., Single-view place recognition under seasonal changes (2018) PPNIV Workshop at IROS 2018; Cieslewski, T., Choudhary, S., Scaramuzza, D., Data-efficient decentralized visual slam (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE., pp. 2466-2473; Wang, M., Intensity filtering and group fusion for accurate mobile place recognition (2018) IEEE Access, 6, pp. 31088-31098},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092722679&doi=10.1109%2fICRA40945.2020.9196967&partnerID=40&md5=21e5a38bec75fc8b093d83d3c6acc0f1},
}

@conference{murphy-sibley:2014:6907022,
  author = {L. Murphy and G. Sibley},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Incremental unsupervised topological place discovery},
  pages = {1312--1318},
  doi = {10.1109/ICRA.2014.6907022},
  note = {cited By 22; Conference of 2014 IEEE International Conference on Robotics and Automation, ICRA 2014 ; Conference Date: 31 May 2014 Through 7 June 2014;  Conference Code:107395},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2014},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {This paper describes an online place discovery and recognition engine that fuses information over time to create topologically distinct places. A key motivation is the recognition that a single image may be a poor exemplar of what constitutes a place. Images are not 'places' nor are they 'documents'. Instead, by treating image-sequences as a multimodal distribution over topics - and by discovering topics incrementally and online - it is possible to both reduce the memory footprint of place recognition systems, and to improve precision and recall. Distinctive key-places are represented by a cluster topics found from the covisibility graph of a relative simultaneous localization and mapping engine - key-places inherently span many images. A dynamic vocabulary of visual words and density based clustering is used to continually estimate a set of visual topics, changes in which drive the place-recognition process. The system is evaluated using an indoor robot sequence, a standard outdoor robot sequence and a long-term sequence from a static camera. Experiments demonstrate qualitatively distinct themes associated with discovered places - from common place types such as 'hallway', or 'desk-area', to temporal concepts such as 'dusk', 'dawn' or 'mid-day'. Compared to traditional image-based place-recognition, this reduces the information that must be stored without reducing place-recognition performance. © 2014 IEEE.},
  affiliation = {Department of Computer Science, George Washington University, Washington, DC  20052, United States},
  art_number = {6907022},
  coden = {PIIAE},
  document_type = {Conference Paper},
  isbn = {9781479936854; 9781479936854},
  issn = {10504729},
  keywords = {Engines;  Online systems;  Optical character recognition;  Robotics;  Topology, Density-based Clustering;  Memory footprint;  Multimodal distributions;  Place recognition;  Precision and recall;  Recognition engines;  Simultaneous localization and mapping;  Temporal concepts, Image enhancement},
  language = {English},
  references = {Nicosevici, T., Garcia, R., Automatic visual bag-of-words for online robot navigation and mapping (2012) Robotics, IEEE Transactions on, 28 (4), pp. 886-898. , aug; Mei, C., Sibley, G., Cummins, M., Newman, P., Reid, I., Rslam: A system for large-scale mapping in constant-time using stereo (2011) International Journal of Computer Vision, 94 (2), pp. 198-214; Chou, T.-C., Chen, M., Using incremental PLSI for threshold-resilient online event analysis (2008) Knowledge and Data Engineering, IEEE Transactions on, 20 (3), pp. 289-299. , march; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based SLAM (2012) The International Journal of Robotics Research, 31 (11), pp. 1219-1230; Ila, V., Porta, J., Andrade-Cetto, J., Information-based compact pose SLAM (2010) Robotics, IEEE Transactions on, 26 (1), pp. 78-93. , feb; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International Conference on, pp. 1156-1163. , oct; Ranganathan, A., Dellaert, F., Bayesian surprise and landmark detection (2009) Robotics and Automation, 2009. ICRA '09. IEEE International Conference on, pp. 2017-2023. , may; Chapoulie, A., Rives, P., Filliat, D., Topological segmentation of indoors/outdoors sequences of spherical views (2012) Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference on, pp. 4288-4295. , oct; Korrapati, H., Courbon, J., Mezouar, Y., Martinet, P., Image sequence partitioning for outdoor mapping (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1650-1655. , may; Paul, R., Rus, D., Newman, P., How was your day? Online visual workspace summaries using incremental clustering in topic space (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4058-4065. , may; Paul, R., Newman, P., Self help: Seeking out perplexing images for ever improving navigation (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 445-451. , may; Girdhar, Y., Giguere, P., Dudek, G., Autonomous adaptive underwater exploration using online topic modelling (2012) 13th International Symposium on Experimental Robotics (ISER 2012); Hofmann, T., Probabilistic latent semantic indexing (1999) Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Ser. SIGIR '99, pp. 50-57. , New York, NY, USA: ACM; Blei, D., Ng, A., Jordan, M., Latent dirichlet allocation (2003) J. Mach. Learn. Res., 3, pp. 993-1022. , Mar; Ester, M., Kriegel, H., Sander, J., Xu, X., A density-based algorithm for discovering clusters in large spatial databases with noise (1996) Second International Conference on Knowledge Discovery and Data Mining, pp. 226-231. , E. Simoudis, J. Han, and U. Fayyad, Eds. Portland, Oregon: AAAI Press; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) The International Journal of Robotics Research, 28 (5), pp. 595-599. , May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926205234&doi=10.1109%2fICRA.2014.6907022&partnerID=40&md5=6426e21c070c0eb17d5ac8f29a27d4eb},
}

@conference{sun-et-al:2021:9635886,
  author = {L. Sun and M. Taher and C. Wild and C. Zhao and Y. Zhang and F. Majer and Z. Yan and T. Krajnik and T. Prescott and T. Duckett},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Robust and Long-term Monocular Teach and Repeat Navigation using a Single-experience Map},
  pages = {2635--2642},
  doi = {10.1109/IROS51168.2021.9635886},
  note = {cited By 1; Conference of 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2021 ; Conference Date: 27 September 2021 Through 1 October 2021;  Conference Code:175617},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {This paper presents a robust monocular visual teach-and-repeat (VTR) navigation system for long-term operation in outdoor environments. The approach leverages deep-learned descriptors to deal with the high illumination variance of the real world. In particular, a tailored self-supervised descriptor, DarkPoint, is proposed for autonomous navigation in outdoor environments. We seamlessly integrate the localisation with control, in which proportional-integral control is used to eliminate the visual error with the pitfall of the unknown depth. Consequently, our approach achieves day-to-night navigation using a single-experience map and is able to repeat complex and fast manoeuvres. To verify our approach, we performed a vast array of navigation experiments in various outdoor environments, where both navigation accuracy and robustness of the proposed system are investigated. The experimental results show that our approach is superior to the baseline method with regards to accuracy and robustness. © 2021 IEEE.},
  affiliation = {University of Sheffield, Sheffield Robotics, United Kingdom; Department of Engineering Science, University of Oxford, United Kingdom; Harbin Institute of Technology, China; Czech Technical University in Prague, Czech Republic; CIAD UMR7533, Univ. Bourgogne Franche-Comte, UTBM, France; L-CAS, University of Lincoln, United Kingdom},
  coden = {85RBA},
  correspondence_address1 = {Sun, L.; University of Sheffield, United Kingdom; email: li.sun@sheffield.ac.uk},
  document_type = {Conference Paper},
  funding_details = {732737},
  funding_text1 = {∗ Corresponding Author: li.sun@sheffield.ac.uk This project is funded by EPSRC FAIR-SPACE Hub (EP/R026092/1), EU Horizon 2020 ILIAD (No 732737), The Royal Society (R/165063-11-1), and CSF/NRF project ToLTATempo 20-27034J. 1 Sheffield Robotics, University of Sheffield, UK 2 Department of Engineering Science, University of Oxford, UK 3 Harbin Institute of Technology, China 4 Czech Technical University in Prague, Czech Republic 5 CIAD UMR7533, Univ. Bourgogne Franche-Comté, UTBM, France 6 L-CAS, University of Lincoln, UK},
  isbn = {9781665417143},
  issn = {21530858},
  keywords = {Air navigation;  Computer vision;  Intelligent robots;  Robustness (control systems);  Two term control systems, Autonomous navigation;  Baseline methods;  Descriptors;  Experience maps;  Localisation;  Navigation accuracy;  Outdoor environment;  Proportional-integral control;  Real-world, Navigation systems},
  language = {English},
  references = {Furgale, P., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) Journal of Field Robotics, 27 (5), pp. 534-560; Krajnk, T., Faigl, J., Vonásek, V., Kosnar, K., Kulich, M., Preucil, L., Simple yet stable bearing-only navigation (2010) Journal of Field Robotics, 27 (5), pp. 511-533; Paton, M., MacTavish, K., Berczi, L.-P., Van Es, S.K., Barfoot, T.D., I can see for miles and miles: An extended field test of visual teach and repeat 2. 0 (2018) Field and Service Robotics., pp. 415-431. , Springer; Churchill, W., Newman, P., Experience-based navigation for longterm localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Paton, M., MacTavish, K., Warren, M., Barfoot, T.D., Bridging the appearance gap: Multi-experience localization for long-term visual teach and repeat (2016) IROS. IEEE, pp. 1918-1925; MacTavish, K., Paton, M., Barfoot, T.D., Visual triage: A bagof-words experience selector for long-term visual route following (2017) ICRA. IEEE, pp. 2065-2072; Neubert, P., Sünderhauf, N., Protzel, P., Appearance change prediction for long-term navigation across seasons (2013) 2013 European Conference on Mobile Robots. IEEE, pp. 198-203; Lowry, S., Milford, M.J., Supervised and unsupervised linear learning techniques for visual place recognition in changing environments (2016) IEEE Transactions on Robotics, 32 (3), pp. 600-613; Krajnk, T., Cristóforis, P., Kusumam, K., Neubert, P., Duckett, T., Image features for visual teach-and-repeat navigation in changing environments (2017) Robotics and Autonomous Systems, 88, pp. 127-141; Zhang, N., Warren, M., Barfoot, T.D., Learning place-and-timedependent binary descriptors for long-term visual localization (2018) ICRA. IEEE, pp. 828-835; Halodová, L., Dvorráková, E., Majer, F., Vintr, T., Mozos, O.M., Dayoub, F., Krajnk, T., Predictive and adaptive maps for longterm visual navigation in changing environments (2019) IROS. IEEE, pp. 7033-7039; Kunze, L., Hawes, N., Duckett, T., Hanheide, M., Krajnk, T., Artificial intelligence for long-term robot autonomy: A survey (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 4023-4030; Kidono, K., Miura, J., Shirai, Y., Autonomous visual navigation of a mobile robot using a human-guided experience (2002) Robotics and Autonomous Systems, 40 (2-3), pp. 121-130; Royer, E., Lhuillier, M., Dhome, M., Lavest, J.-M., Monocular vision for mobile robot localization and autonomous navigation (2007) International Journal of Computer Vision, 74 (3), pp. 237-260; Krajnk, T., Majer, F., Halodová, L., Vintr, T., Navigation without localisation: Reliable teach and repeat based on the convergence theorem (2018) IROS. IEEE, pp. 1657-1664; Segvic, S., Remazeilles, A., Diosi, A., Chaumette, F., Large scale vision based navigation without an accurate global reconstruction (2007) IEEE International Conference on Computer Vision and Pattern Recognition, CVPR'07, pp. 1-8. , Minneapolis, Minnesota; Blanc, G., Mezouar, Y., Martinet, P., Indoor navigation of a wheeled mobile robot along visual routes (2005) ICRA; Matsumoto, Y., Inaba, M., Inoue, H., Visual navigation using viewsequenced route representation (1996) ICRA; Royer, E., Lhuillier, M., Dhome, M., Lavest, J.-M., Monocular vision for mobile robot localization and autonomous navigation (2007) International Journal of Computer Vision, 74 (3), pp. 237-260. , Sep; Zhao, C., Sun, L., Krajnk, T., Monocular teach-and-repeat navigation using a deep steering network with scale estimation (2021) IROS. IEEE; Chen, Z., Birchfield, S.T., Qualitative vision-based path following (2009) IEEE Transactions on Robotics and Automation, 25 (3), pp. 749-754; Krajnk, T., Fentanes, J.P., Santos, J.M., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) IEEE Trans. Robotics, 33 (4), pp. 964-977; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots (2008) 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, pp. 3364-3369; Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong featurebased mapping in semi-static environments (2016) ICRA. IEEE, pp. 1063-1070; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, pp. 2769-2776; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Calonder, M., Lepetit, V., Ozuysal, M., Trzcinski, T., Strecha, C., Fua, P., Brief: Computing a local binary descriptor very fast (2011) IEEE Transactions on Pattern Analysis and Machine Intelligence, 34 (7), pp. 1281-1298; Dusmanu, M., Rocco, I., Pajdla, T., Pollefeys, M., Sivic, J., Torii, A., Sattler, T., D2-net: A trainable cnn for joint detection and description of local features (2019) CVPR 2019; Ono, Y., Trulls, E., Fua, P., Yi, K.M., Lf-net: Learning local features from images (2018) Advances in Neural Information Processing Systems, pp. 6234-6244; DeTone, D., Malisiewicz, T., Rabinovich, A., Superpoint: Selfsupervised interest point detection and description (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 224-236; Barroso-Laguna, A., Riba, E., Ponsa, D., Mikolajczyk, K., Key. net: Keypoint detection by handcrafted and learned cnn filters (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 5836-5844; Sarlin, P.-E., DeTone, D., Malisiewicz, T., Rabinovich, A., Superglue: Learning feature matching with graph neural networks (2020) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4938-4947; Schroff, F., Kalenichenko, D., Philbin, J., Facenet: A unified embedding for face recognition and clustering (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 815-823; Sturm, J., Engelhard, N., Endres, F., Burgard, W., Cremers, D., A benchmark for the evaluation of rgb-d slam systems (2012) IROS, , Oct; Mair, E., Hager, G.D., Burschka, D., Suppa, M., Hirzinger, G., Adaptive and generic corner detection based on the accelerated segment test (2010) European Conference on Computer Vision, pp. 183-196. , Springer},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124182975&doi=10.1109%2fIROS51168.2021.9635886&partnerID=40&md5=de01da53c446e01abaa8fbcac9e76fa3},
}

@article{sun-et-al:2018:2856268,
  author = {L. Sun and Z. Yan and A. Zaganidis and C. Zhao and T. Duckett},
  journal = {IEEE Robotics and Automation Letters},
  title = {Recurrent-OctoMap: Learning State-Based Map Refinement for Long-Term Semantic Mapping with 3-D-Lidar Data},
  volume = {3},
  number = {4},
  pages = {3749--3756},
  doi = {10.1109/LRA.2018.2856268},
  note = {cited By 33},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {This letter presents a novel semantic mapping approach, Recurrent-OctoMap, learned from long-term three-dimensional (3-D) Lidar data. Most existing semantic mapping approaches focus on improving semantic understanding of single frames, rather than 3-D refinement of semantic maps (i.e. fusing semantic observations). The most widely used approach for the 3-D semantic map refinement is 'Bayes update,' which fuses the consecutive predictive probabilities following a Markov-chain model. Instead, we propose a learning approach to fuse the semantic features, rather than simply fusing predictions from a classifier. In our approach, we represent and maintain our 3-D map as an OctoMap, and model each cell as a recurrent neural network, to obtain a Recurrent-OctoMap. In this case, the semantic mapping process can be formulated as a sequence-to-sequence encoding-decoding problem. Moreover, in order to extend the duration of observations in our Recurrent-OctoMap, we developed a robust 3-D localization and mapping system for successively mapping a dynamic environment using more than two weeks of data, and the system can be trained and deployed with arbitrary memory length. We validate our approach on the ETH long-term 3-D Lidar dataset. The experimental results show that our proposed approach outperforms the conventional 'Bayes update' approach. © 2016 IEEE.},
  affiliation = {Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Laboratoire Electronique, Informatique et Image, CNRS, University of Technology of Belfort-Montbéliard (UTBM), Belfort, 90010, France},
  art_number = {8411109},
  author_keywords = {deep learning in robotics and automation;  Mapping;  object detection;  segmentation and categorization;  simultaneous localization and mapping (SLAM)},
  correspondence_address1 = {Sun, L.; Lincoln Centre for Autonomous Systems (L-CAS), United Kingdom; email: lsun@lincoln.ac.uk},
  document_type = {Article},
  funding_details = {Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme, H2020, 645376, 732737},
  funding_text1 = {Manuscript received February 24, 2018; accepted June 19, 2018. Date of publication July 16, 2018; date of current version August 8, 2018. This letter was recommended for publication by Associate Editor Nick Hawes and Editor Dongheui Lee upon evaluation of the reviewers’ comments. This work was supported by the European Union’s Horizon 2020 research and innovation programme under Grant 732737 (ILIAD) and 645376 (FLOBOT). (Corresponding author: Li Sun.) L. Sun, C. Cheng, A. Zaganidis, and T. Duckett are with the Lincoln Centre for Autonomous Systems (L-CAS), University of Lincoln, Lincoln LN6 7TS, U.K. (e-mail:, lsun@lincoln.ac.uk; azaganidis@lincoln.ac.uk; czhao@lincoln.ac.uk; tduckett@lincoln.ac.uk).},
  funding_text2 = {This work was supported by the European Union's Horizon 2020 research and innovation programme under Grant 732737 (ILIAD) and 645376 (FLOBOT).},
  issn = {23773766},
  keywords = {Deep learning;  Feature extraction;  Mapping;  Markov processes;  Object detection;  Object recognition;  Optical radar;  Recurrent neural networks;  Robotics;  Semantics, Dynamic environments;  Markov chain models;  Recurrent neural network (RNN);  Semantic understanding;  Short term memory;  Simultaneous localization and mapping;  SLAM;  Two-dimensional displays, Three dimensional displays},
  language = {English},
  references = {Pomerleau, F., Krusi, P., Colas, F., Furgale, P., Siegwart, R., Long-term 3D mapmaintenance in dynamic environments Proc. Int. Conf. Robot. Autom., 2014, pp. 3712-3719; Sebastian, T., Wolfram, B., Dieter, F., (2005) Probabilistic Robotics (Intelligent Robotics and Autonomous Agents), , Cambridge, MA, USA: MIT Press; Hermans, A., Floros, G., Leibe, B., Dense 3d semantic mapping of indoor scenes from RGB-D images (2014) Proc. Int. Conf. Robot. Autom., pp. 2631-2638; Sengupta, S., Greveson, E., Shahrokni, A., Torr, P.H., Urban 3D semantic modelling using stereo vision (2013) Proc. Int. Conf. Robot. Autom., pp. 580-585; McCormac, J., Handa, A., Davison, A., Leutenegger, S., SemanticFusion: Dense 3D semantic mapping with convolutional neural networks (2017) Proc. Int. Conf. Robot. Autom., pp. 4628-4635; Zhao, C., Sun, L., Stolkin, R., A fully end-to-end deep learning approach for real-time simultaneous 3D reconstruction and material recognition (2017) Proc. Int. Conf. Adv. Robot., pp. 75-82; Xiang, Y., Fox, D., DA-RNN: Semantic mapping with data associated recurrent neural networks (2017) Proc. Robot.: Sci. Syst. (RSS); Ma, L., Sẗuc, J., Kerl, C., Cremers, D., Multi-view deep learning for consistent semantic mapping with RGB-D cameras (2017) Proc. Int. Conf. Intell. Robots Syst., pp. 598-605; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3D classification and segmentation (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recog., 1 (2), pp. 77-85; Tateno, K., Tombari, F., Navab, N., When 2.5D is not enough: Simultaneous reconstruction, segmentation and recognition on dense SLAM (2016) Proc. Int. Conf. Robot. Autom., pp. 2295-2302; Sengupta, S., Automatic dense visual semantic mapping from streetlevel imagery (2012) Proc. Int. Conf. Intell. Robots Syst., pp. 857-862; Maturana, D., Chou, P.-W., Uenoyama, M., Scherer, S., Real-time semantic mapping for autonomous off-road navigation (2018) Proc. Conf. Field Service Robot., pp. 335-350; Bogoslavskyi, I., Stachniss, C., Fast range image-based segmentation of sparse 3D laser scans for online operation (2016) Proc. Int. Conf. Intell. Robots Syst., pp. 163-169; Yan, Z., Duckett, T., Bellotto, N., Online learning for human classification in 3D LIDAR-based tracking (2017) Proc. Int. Conf. Intell. Robots Syst., pp. 864-871; Dewan, A., Caselitz, T., Tipaldi, G.D., Burgard, W., Motion-based detection and tracking in 3D LIDAR scans (2016) Proc. Int. Conf. Robot. Autom., pp. 4508-4513; Navarro-Serment, L.E., Mertz, C., Hebert, M., Pedestrian detection and tracking using three-dimensional LADAR data (2009) Proc. Conf. Field Service Robot., pp. 1516-1528; Kidono, K., Miyasaka, T., Watanabe, A., Naito, T., Miura, J., Pedestrian recognition using high-definition LIDAR (2011) Proc. IEEE Intell. Veh. Symp., pp. 405-410; Spinello, L., Luber, M., Arras, K.O., Tracking people in 3D using a bottom-up top-down detector (2011) Proc. Int. Conf. Robot. Autom., pp. 1304-1310; Deuge, M.D., Quadros, A., Hung, C., Douillard, B., Unsupervised feature learning for classification of outdoor 3D scans (2013) Proc. Australasian Conf. Robot. Autom., 2, pp. 1-9; Chen, X., Ma, H., Wan, J., Li, B., Xia, T., Multi-view 3d object detection network for autonomous driving (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 1 (2), pp. 6526-6534; Wu, B., Wan, A., Yue, X., Keutzer, K., SqueezeSeg: Convolutional neural nets with recurrent CRF for real-time road-object segmentation from 3D LIDAR point cloud (2018) Proc. Int. Conf. Robot. Autom., pp. 1887-1893; Li, B., 3D fully convolutional network for vehicle detection in point cloud (2017) Proc. Int. Conf. Intell. Robots Syst., pp. 1513-1518; Engelmann, F., Kontogianni, T., Hermans, A., Leibe, B., Exploring spatial context for 3D semantic segmentation of point clouds (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recog., pp. 716-724; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Trans. Robot., 23 (1), pp. 34-46. , Feb; Mur-Artal, R., Tardos, J.D., ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras (2017) IEEE Trans. Robot., 33 (5), pp. 1255-1262. , Oct; Zhang, J., Singh, S., LOAM: Lidar odometry and mapping in realtime (2014) Proc. Robot., Sci. Syst., 2, pp. 9-17; Einhorn, E., Gross, H.-M., Generic NDT mapping in dynamic environments and its application for lifelong SLAM (2015) Robot. Auton. Syst., 69, pp. 28-39; Krajnik, T., Fentanes, J.P., Santos, J.M., Duckett, T., FreMEn: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) IEEE Trans. Robot., 33 (4), pp. 964-977. , Aug; Hornung, A., Wurm, K.M., Bennewitz, M., Stachniss, C., Burgard, W., Octomap: An efficient probabilistic 3d mapping framework based on octrees (2013) Auton. Robots, 34 (3), pp. 189-206; Elman, J.L., Finding structure in time (1990) Cognitive Sci., 14 (2), pp. 179-211; Cho, K., (2014) Learning Phrase Representations Using RNN Encoderdecoder for Statistical Machine Translation; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Sun, L., Gerardo, A.-C., Simon, R., Siebert, J.P., Accurate garment surface analysis using an active stereo robot head with application to dualarm flattening (2015) Proc. Int. Conf. Robot. Autom., pp. 185-192; Sun, L., Simon, R., Gerardo, A.-C., Siebert, J.P., Recognising the clothing categories from free-configuration using Gaussian-processbased interactive perception (2016) Proc. Int. Conf. Robot. Autom., pp. 2464-2470; Zaganidis, A., Sun, L., Duckett, T., Cielniak, G., Integrating deep semantic segmentation into 3d point cloud registration (2018) IEEE Robot. Autom. Lett., 3 (4), pp. 2942-2949. , Oct; Zhao, C., Sun, L., Shuai, B., Purkait, P., Stolkin, R., (2017) Dense RGB-D Semantic Mapping with Pixel-voxel Neural Network; Sun, L., Yan, Z., Mellado, S.M., Hanheide, M., Duckett, T., 3DOF pedestrian trajectory prediction learned from long-term autonomous mobile robot deployment data (2018) Proc. Int. Conf. Robot. Autom., pp. 5942-5948},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053706009&doi=10.1109%2fLRA.2018.2856268&partnerID=40&md5=594f4eb4a1b1a7839a2c5df96628102e},
}

@article{tang-et-al:2021:17298814211037497,
  author = {L. Tang and Y. Wang and Q. Tan and R. Xiong},
  journal = {International Journal of Advanced Robotic Systems},
  title = {Explicit feature disentanglement for visual place recognition across appearance changes},
  volume = {18},
  number = {6},
  doi = {10.1177/17298814211037497},
  note = {cited By 0},
  publisher = {SAGE Publications Inc.},
  year = {2021},
  abbrev_source_title = {Int. J. Adv. Rob. Syst.},
  abstract = {In the long-term deployment of mobile robots, changing appearance brings challenges for localization. When a robot travels to the same place or restarts from an existing map, global localization is needed, where place recognition provides coarse position information. For visual sensors, changing appearances such as the transition from day to night and seasonal variation can reduce the performance of a visual place recognition system. To address this problem, we propose to learn domain-unrelated features across extreme changing appearance, where a domain denotes a specific appearance condition, such as a season or a kind of weather. We use an adversarial network with two discriminators to disentangle domain-related features and domain-unrelated features from images, and the domain-unrelated features are used as descriptors in place recognition. Provided images from different domains, our network is trained in a self-supervised manner which does not require correspondences between these domains. Besides, our feature extractors are shared among all domains, making it possible to contain more appearance without increasing model complexity. Qualitative and quantitative results on two toy cases are presented to show that our network can disentangle domain-related and domain-unrelated features from given data. Experiments on three public datasets and one proposed dataset for visual place recognition are conducted to illustrate the performance of our method compared with several typical algorithms. Besides, an ablation study is designed to validate the effectiveness of the introduced discriminators in our network. Additionally, we use a four-domain dataset to verify that the network can extend to multiple domains with one model while achieving similar performance. © The Author(s) 2021.},
  affiliation = {Department of Control Science and Engineering, Zhejiang University, Hangzhou, China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, China},
  author_keywords = {adversarial;  changing appearance;  feature disentanglement;  Place recognition;  self-supervised},
  correspondence_address1 = {Wang, Y.; Department of Control Science and Engineering, China; email: ywang24@zju.edu.cn},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61903332},
  funding_text1 = {The author(s) disclosed the receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported in part by the National Nature Science Foundation of China under Grant 61903332, and in part by the Natural Science Foundation of Zhejiang Province under grant number LGG21F030012.},
  issn = {17298806},
  keywords = {Discriminators;  Toys, Adversarial;  Changing appearance;  Feature disentanglement;  Global localization;  Localisation;  Performance;  Place recognition;  Position information;  Self-supervised;  Visual sensor, Machine learning},
  language = {English},
  references = {Bresson, G., Alsayed, Z., Yu, L., Simultaneous localization and mapping: a survey of current trends in autonomous driving (2017) IEEE Trans Intell Veh, 2 (3), pp. 194-220; Cadena, C., Carlone, L., Carrillo, H., Past, present, and future of simultaneous localization and mapping: toward the robust-perception age (2016) IEEE Trans Robot, 32 (6), pp. 1309-1332; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int J Comput Vis, 60 (2), pp. 91-110; Rublee, E., Rabaud, V., Konolige, K., ORB: An efficient alternative to SIFT or SURF International conference on computer vision, 2011, pp. 2564-2571. , In; Schindler, G., Brown, M., Szeliski, R., City-scale location recognition 2007 IEEE conference on computer vision and pattern recognition, pp. 1-7. , Minneapolis, MN, 17 June 2007 to 22 June 2007, IEEE, In; Cummins, M., Newman, P., FAB-MAP: probabilistic localization and mapping in the space of appearance (2008) Int J Robot Res, 27 (6), pp. 647-665; Milford, M.J., Wyeth, G.F., SeqSLAM: visual route-based navigation for sunny summer days and stormy winter nights 2012 IEEE international conference on robotics and automation, pp. 1643-1649. , St Paul, MN, USA, 14 May 2012–19 May 2012, IEEE, In; Doan, A.D., Latif, Y., Chin, T.J., Scalable place recognition under appearance change for autonomous driving Proceedings of the IEEE international conference on computer vision, pp. 9319-9328. , Long Beach, CA, 16–20 June 2019, In; Chen, Z., Jacobson, A., Sünderhauf, N., Deep learning features at scale for visual place recognition 2017 IEEE international conference on robotics and automation (ICRA), pp. 3223-3230. , Marina Bay Sands, Singapore, From 29 May 2017 until 3 June 2017, IEEE, In; Arandjelovic, R., Gronat, P., Torii, A., NetVLAD: CNN architecture for weakly supervised place recognition Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 5297-5307. , Las Vegas, 27–30 June 2016, In; Merrill, N., Huang, G., Lightweight unsupervised deep loop closure (2018) Proceedings of robotics: science and systems (RSS), , Pittsburgh, PA, (accepted), In; Anoosheh, A., Sattler, T., Timofte, R., Night-to-day image translation for retrieval-based localization 2019 International conference on robotics and automation (ICRA), pp. 5958-5964. , Montreal, Canada, 20–24 May 2019, IEEE, In; Lee, H.Y., Tseng, H.Y., Mao, Q., DRIT++: diverse image-to-image translation via disentangled representations (2020) Int J Comp Vis, 128, pp. 2402-2417; Higgins, I., Amos, D., Pfau, D., Towards a definition of disentangled representations (2018) arXiv preprint arXiv:181202230; Tang, L., Wang, Y., Luo, Q., Adversarial feature disentanglement for place recognition across changing appearance International conference on robotics and automation (ICRA), pp. 1301-1307. , p. accepted, Paris, France, 31 May–15 June 2020, IEEE, In; Li, F., Kosecka, J., Probabilistic location recognition using reduced feature set Proceedings 2006 IEEE international conference on robotics and automation, 2006. ICRA 2006, pp. 3405-3410. , Orlando, FL, USA, 5–19 May 2006, IEEE, In; Nowicki, M.R., Wietrzykowski, J., Skrzypczyński, P., Real-time visual place recognition for personal localization on a mobile device (2017) Wirel Pers Commun, 97 (1), pp. 213-244; Zaffar, M., Ehsan, S., Milford, M., Memorable maps: a framework for re-defining places in visual place recognition (2020) IEEE Trans Intell Transp Syst, pp. 1-15; Schlegel, D., Grisetti, G., HBST: a hamming distance embedding binary search tree for feature-based visual place recognition (2018) IEEE Robot Auto Lett, 3 (4), pp. 3741-3748; Kanji, T., (2019) Mining minimal map-segments for visual place classifiers; Yin, P., Srivatsan, R.A., Chen, Y., MRS-VPR: a multi-resolution sampling based global visual place recognition method 2019 International conference on robotics and automation (ICRA), pp. 7137-7142. , Montreal, Canada, May 20–24 2019, IEEE, In; Hausler, S., Milford, M., Hierarchical multi-process fusion for visual place recognition 2020 IEEE International conference on robotics and automation, ICRA 2020, pp. 3327-3333. , https://doi.org/10.1109/ICRA40945.2020.9197360, Paris, France, May 31–August 31 2020, IEEE,, In; Schubert, S., Neubert, P., Protzel, P., Unsupervised learning methods for visual place recognition in discretely and continuously changing environments 2020 IEEE international conference on robotics and automation (ICRA), pp. 4372-4378. , Paris, France, 31 May 2020–31 August 2020, In; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection 2005 IEEE computer society conference on computer vision and pattern recognition (CVPR’05), 1, pp. 886-893. , San Diego, CA, USA, 20–25 June 2005, IEEE, ume; Murillo, A.C., Singh, G., Kosecká, J., Localization in urban environments using a panoramic GIST descriptor (2013) IEEE Trans Robot, 29 (1), pp. 146-160; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: a versatile and accurate monocular slam system (2015) IEEE Trans Robot, 31 (5), pp. 1147-1163; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans Robot, 28 (5), pp. 1188-1197; Jégou, H., Douze, M., Schmid, C., Aggregating local descriptors into a compact image representation CVPR 2010-23 rd IEEE conference on computer vision & pattern recognition, pp. 3304-3311. , San Francisco, CA, USA, 13–18 June 2010, IEEE Computer Society, In; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, pp. 1097-1105. , In; Sünderhauf, N., Shirazi, S., Dayoub, F., On the performance of convnet features for place recognition 2015 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp. 4297-4304. , Hamburg, Germany, 28 September–3 October 2015, IEEE, In; Deng, J., Dong, W., Socher, R., ImageNet: a large-scale hierarchical image database 2009 IEEE conference on computer vision and pattern recognition, pp. 248-255. , Miami, FL, June 20 2009 to June 25 2009, IEEE, In; Facil, J.M., Olid, D., Montesano, L., Condition-invariant multi-view place recognition (2019) arXiv preprint arXiv:190209516; Hausler, S., Jacobson, A., Milford, M., Filter early, match late: improving network-based visual place recognition 2019 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp. 3268-3275. , Macao, China, 03 November 2019–08 November 2019, In; Pillai, S., Leonard, J., Self-supervised visual place recognition learning in mobile robots Learning for localization and mapping workshop at IROS 2017 IROS: IEEE/RSJ international conference on intelligent robots and systems, , Vancouver, BC, Canada, 24–28 September 2019, In; Yu, J., Zhu, C., Zhang, J., Spatial pyramid-enhanced NetVLAD with weighted triplet loss for place recognition (2019) IEEE Tran Neur Netw Learn Syst, 31, pp. 661-674; Sünderhauf, N., Shirazi, S., Jacobson, A., Place recognition with convnet landmarks: viewpoint-robust, condition-robust, training-free (2015) Proceedings of robotics: science and systems XII, , In; Hong, Z., Petillot, Y., Lane, D., Textplace: visual place recognition and topological localization through reading scene texts Proceedings of the IEEE international conference on computer vision, pp. 2861-2870. , Seoul, Korea, 27 October–2 November, In; Khaliq, A., Ehsan, S., Chen, Z., A holistic visual place recognition approach using lightweight cnns for significant viewpoint and appearance changes (2019) IEEE Trans Robot, 36 (2), pp. 1-9; Chen, Z., Liu, L., Sa, I., Learning context flexible attention model for long-term visual place recognition (2018) IEEE Robot Auto Lett, 3 (4), pp. 4015-4022; Xin, Z., Cai, Y., Lu, T., Localizing discriminative visual landmarks for place recognition 2019 International conference on robotics and automation (ICRA), pp. 5979-5985. , Montreal, Canada, 20–24 May 2019, IEEE, In; Khaliq, A., Ehsan, S., Milford, M., Camal: context-aware multi-scale attention framework for lightweight visual place recognition (2019) arXiv preprint arXiv:190908153; Lowry, S., Milford, M.J., Supervised and unsupervised linear learning techniques for visual place recognition in changing environments (2016) IEEE Trans Robot, 32 (3), pp. 600-613; Garg, S., Milford, M., Fast, compact and highly scalable visual place recognition through sequence-based matching of overloaded representations 2020 IEEE international conference on robotics and automation (ICRA), pp. 3341-3348. , Paris, France, 31 May 2020–31 Aug 2020, In; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Sci, 313 (5786), pp. 504-507; Shantia, A., Timmers, R., Schomaker, L., Indoor localization by denoising autoencoders and semi-supervised learning in 3d simulated environment 2015 international joint conference on neural networks (IJCNN), pp. 1-7. , Killarney, Ireland, 11 July 2015–16 July 2015, IEEE, In; Mukherjee, A., Chakraborty, S., Saha, S.K., Learning deep representation for place recognition in slam (2017) International conference on pattern recognition and machine intelligence, pp. 557-564. , Pattern Recognition and Machine Intelligence, Springer, In; Gao, X., Zhang, T., Unsupervised learning to detect loops using deep neural networks for visual slam system (2017) Auto Robot, 41 (1), pp. 1-18; Liu, M.Y., Breuel, T., Kautz, J., Unsupervised image-to-image translation networks Advances in neural information processing systems, pp. 700-708. , In, 2017; Isola, P., Zhu, J.Y., Zhou, T., Image-to-image translation with conditional adversarial networks Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1125-1134. , Honolulu, Hawaii, 21–26 July 2017, In; Goodfellow, I., Pouget-Abadie, J., Mirza, M., Generative adversarial nets Advances in neural information processing systems, pp. 2672-2680. , In, 2014; Porav, H., Maddern, W., Newman, P., Adversarial training for adverse conditions: robust metric localisation using appearance transfer 2018 IEEE international conference on robotics and automation (ICRA), pp. 1011-1018. , Brisbane, Australia, 21 May 2018–25 May 2018, IEEE, In; Latif, Y., Garg, R., Milford, M., Addressing challenging place recognition tasks using generative adversarial networks 2018 IEEE international conference on robotics and automation (ICRA), pp. 2349-2355. , Brisbane, Australia, 21 May 2018–25 May 2018, IEEE, In; Clement, L., Kelly, J., How to train a cat: learning canonical appearance transformations for direct visual localization under illumination change (2018) IEEE Robot Auto Lett, 3 (3), pp. 2447-2454; Yin, P., Xu, L., Li, X., A multi-domain feature learning method for visual place recognition 2019 International conference on robotics and automation (ICRA), pp. 319-324. , Montreal, Canada, 20 May 2019–24 May 2019, IEEE, In; Torii, A., Arandjelovic, R., Sivic, J., 24/7 place recognition by view synthesis Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1808-1817. , Boston, Massachusetts, 8–10 June 2015, In; Garg, S., Suenderhauf, N., Milford, M., Semantic–geometric visual place recognition: a new perspective for reconciling opposing views Int J Robot Res, , Epub ahead of print 8 April 2019; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution European conference on computer vision, , Amsterdam, Netherlands, 8–16 October 2016, In; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition 3 rd International conference on learning representations, ICLR 2015, , http://arxiv.org/abs/1409.1556, Bengio Y., LeCun Y., (eds), San Diego, CA, USA, 7–9 May 2015, Conference Track Proceedings,, In:, (eds; Mao, X., Li, Q., Xie, H., Least squares generative adversarial networks Proceedings of the IEEE international conference on computer vision, pp. 2794-2802. , Venice, Italy, 22–29 October 2017, In; Kingma, D.P., Ba, J., ADAM: a method for stochastic optimization 3 rd International conference on learning representations, ICLR 2015, , http://arxiv.org/abs/1412.6980, Bengio Y., LeCun Y., (eds), San Diego, CA, USA, 7–9 May 2015, Conference Track Proceedings,, In:, (eds; Schroff, F., Kalenichenko, D., Philbin, J., FaceNet: a unified embedding for face recognition and clustering Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 815-823. , Boston, 7–12 June 2015, In; Tang, L., Wang, Y., Ding, X., Topological local-metric framework for mobile robots navigation: a long term perspective (2019) Auto Robot, 43 (1), pp. 197-211; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int J Robot Res, 32 (14), pp. 1645-1661; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models Proceedings of the ICML, , Atlanta, Georgia, 16–23 June 2013, USA; LeCun, Y., Bottou, L., Bengio, Y., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86 (11), pp. 2278-2324; Hinton, G., Visualizing data using t-SNE (2008) J Mach Learn Res, 9 (Nov), pp. 2579-2605. , and; Huang, X., Liu, M.Y., Belongie, S., Multimodal unsupervised image-to-image translation Proceedings of the European conference on computer vision (ECCV), pp. 172-189. , Munich, Germany, 8–14 September 2018, In; Sattler, T., Maddern, W., Toft, C., Benchmarking 6DOF outdoor visual localization in changing conditions Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 8601-8610. , Salt Lake City, Utah, 19–21 June 2018, In; Gomez-Ojeda, R., Lopez-Antequera, M., Petkov, N., Training a convolutional neural network for appearance-invariant place recognition (2015) arXiv preprint arXiv:150507428; Maddern, W., Pascoe, G., Linegar, C., 1 Year, 1000 km: the oxford robotcar dataset (2017) Int J Robot Res, 36 (1), pp. 3-15; Hu, H., Wang, H., Liu, Z., Retrieval-based localization based on domain-invariant feature learning under changing environments 2019 IEEE/RSJ international conference on intelligent robots and systems (IROS), pp. 3684-3689. , Macau, China, 3 November 2019 until 8 November 2019, In; Ulyanov, D., Vedaldi, A., Lempitsky, V., Improved texture networks: maximizing quality and diversity in feed-forward stylization and texture synthesis Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 6924-6932. , Honolulu, Hawaii, 21–26 July 2017, In; Lei Ba, J., Kiros, J.R., Hinton, G.E., Layer normalization (2016) arXiv preprint arXiv:160706450},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120968635&doi=10.1177%2f17298814211037497&partnerID=40&md5=2631bf76da69fa4a7cff8a70dea9878f},
}

@article{tang-et-al:2019:7,
  author = {L. Tang and Y. Wang and X. Ding and H. Yin and R. Xiong and S. Huang},
  journal = {Autonomous Robots},
  title = {Topological local-metric framework for mobile robots navigation: a long term perspective},
  volume = {43},
  number = {1},
  pages = {197--211},
  doi = {10.1007/s10514-018-9724-7},
  note = {cited By 20},
  publisher = {Springer New York LLC},
  year = {2019},
  abbrev_source_title = {Auton. Robots},
  abstract = {Long term mapping and localization are the primary components for mobile robots in real world application deployment, of which the crucial challenge is the robustness and stability. In this paper, we introduce a topological local-metric framework (TLF), aiming at dealing with environmental changes, erroneous measurements and achieving constant complexity. TLF organizes the sensor data collected by the robot in a topological graph, of which the geometry is only encoded in the edge, i.e. the relative poses between adjacent nodes, relaxing the global consistency to local consistency. Therefore the TLF is more robust to unavoidable erroneous measurements from sensor information matching since the error is constrained in the local. Based on TLF, as there is no global coordinate, we further propose the localization and navigation algorithms by switching across multiple local metric coordinates. Besides, a lifelong memorizing mechanism is presented to memorize the environmental changes in the TLF with constant complexity, as no global optimization is required. In experiments, the framework and algorithms are evaluated on 21-session data collected by stereo cameras, which are sensitive to illumination, and compared with the state-of-art global consistent framework. The results demonstrate that TLF can achieve similar localization accuracy with that from global consistent framework, but brings higher robustness with lower cost. The localization performance can also be improved from sessions because of the memorizing mechanism. Finally, equipped with TLF, the robot navigates itself in a 1 km session autonomously. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
  affiliation = {State Key Laboratory of Industrial Control and Technology, and Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; iPlusBot, Hangzhou, China; Center for Autonomous Systems (CAS), University of Technology Sydney, Sydney, Australia},
  author_keywords = {Lifelong learning;  Localization;  Mobile robot;  Navigation},
  coden = {AUROF},
  correspondence_address1 = {Wang, Y.; iPlusBotChina; email: wangyue@iipc.zju.edu.cn},
  document_type = {Article},
  funding_details = {61473258, 61621002, U1609210},
  funding_text1 = {Acknowledgements This work was supported by the National Nature Science Foundation of China (Grant Nos. U1609210, 61473258 and 61621002), National Key Research and Development Program (Grant No. 2017YFB1300400), and in part by the Joint Centre for Robotics Research between Zhejiang University and the University of Technology, Sydney.},
  issn = {09295593},
  keywords = {Global optimization;  Large scale systems;  Navigation;  Stereo image processing;  Topology, Application deployment;  Framework and algorithms;  Life long learning;  Localization;  Localization and navigation;  Localization performance;  Long-term perspective;  Mapping and localization, Mobile robots},
  language = {English},
  references = {Angeli, A., Doncieux, S., Meyer, J.A., Filliat, D., Visual topological slam and global localization (2009) IEEE International Conference on Robotics and Automation, pp. 4300-4305. , &, (,).,. In; Besl, P.J., Mckay, N.D., Method for registration of 3-d shapes. In: Robotics—DL tentative, pp (1992) 239–256; Blaer, P., Allen, P., Topological mobile robot localization using fast vision techniques (2002) In: IEEE International Conference on Robotics and Automation, 2002. Proceedings. ICRA, vol. 1, pp. 1031-1036. , &; Cadena, C., Galvez-l, P.D., Tardos, J.D., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Transactions on Robotics, 28 (4), pp. 871-885; Carlevaris-Bianco, N., Kaess, M., Eustice, R.M., Generic node removal for factor-graph slam (2014) IEEE Transactions on Robotics, 30 (6), pp. 1371-1385; Choi, J., Maurer, M., Local volumetric hybrid-map-based simultaneous localization and mapping with moving object tracking (2016) IEEE Transactions on Intelligent Transportation Systems, 17 (9), pp. 2440-2455; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) International Journal of Robotics Research, 32 (14), pp. 1645-1661; Corcoran, P., Winstanley, A., Mooney, P., Middleton, R., Background foreground segmentation for slam (2011) IEEE Transactions on Intelligent Transportation Systems, 12 (4), pp. 1177-1183; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) International Journal of Robotics Research, 27 (6), pp. 647-665; Dellaert, F., Kaess, M., Square root sam: Simultaneous localization and mapping via square root information smoothing (2006) International Journal of Robotics Research, 25 (12), pp. 1181-1203; Dissanayake, G., Durrant-Whyte, H., Bailey, T., A computationally efficient solution to the simultaneous localisation and map building (slam) problem (2000) IEEE International Conference on Robotics and Automation, 2000. Proceedings. ICRA, 2, pp. 1009-1014. , &, (,),.,. In; Eustice, R.M., Singh, H., Leonard, J.J., Exactly sparse delayed-state filters for view-based slam (2006) IEEE Transactions on Robotics, 22 (6), pp. 1100-1114; Fox, D., Burgard, W., Dellaert, F., Thrun, S., Monte carlo localization: efficient position estimation for mobile robots. In Sixteenth National Conference on Artificial Intelligence and Eleventh Conference on Innovative Applications of Artificial Intelligence, July 18–22, 1999, Orlando, Florida (1999) USA, pp. 343-349; Furgale, P., Barfoot, T.D., Visual teach and repeat for long range rover autonomy (2010) Journal of Field Robotics, 27 (5), pp. 534-560; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Geiger, A., Ziegler, J., Stiller, C., Stereoscan: Dense 3d reconstruction in real-time (2011) Intelligent Vehicles Symposium (IV), 2011 IEEE, pp. 963-968. , &, (,).,. In; Huang, G.P., Mourikis, A.I., Roumeliotis, S.I., A first-estimates jacobian ekf for improving slam consistency (2009) Springer Tracts in Advanced Robotics, 54, pp. 373-382; Huang, G.P., Mourikis, A.I., Roumeliotis, S.I., Observability-based rules for designing consistent ekf slam estimators (2010) International Journal of Robotics Research, 29 (5), pp. 502-528; Huang, S., Dissanayake, G., Convergence and consistency analysis for extended kalman filter based slam (2007) IEEE Transactions on Robotics, 23 (5), pp. 1036-1049; Kaess, M., Ranganathan, A., Dellaert, F., Isam: Incremental smoothing and mapping (2008) IEEE Transactions on Robotics, 24 (6), pp. 1365-1378; Konolige, K., Bowman, J., Chen, J.D., Mihelich, P., Calonder, M., Lepetit, V., Fua, P., View-based maps (2010) International Journal of Robotics Research, 29 (8), pp. 941-957; Konolige, K., Marder-Eppstein, E., Marthi, B., Navigation in hybrid metric-topological maps (2011) IEEE International Conference on Robotics and Automation, pp. 3041-3047. , &, (,).,. In; Krüsi, P., Bücheler, B., Pomerleau, F., Schwesinger, U., Siegwart, R., Furgale, P., Lighting invariant adaptive route following using iterative closest point matching (2015) Journal of Field Robotics, 32 (4), pp. 534-564; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., G 2 o: A general framework for graph optimization (2011) In: IEEE International Conference on Robotics and Automation, pp. 3607-3613. , &; Kurt Konolige, M.A., Frameslam: From bundle adjustment to real-time visual mapping (2008) IEEE Transanctions on Robotics, pp. 1066-1077. , (,).,. In; Latif, Y., Cadena, C., Neira, J., Robust loop closing over time for pose graph slam (2013) International Journal of Robotics Research, 32 (32), pp. 1611-1626; Lauer, M., Stein, D., A train localization algorithm for train protection systems of the future (2015) IEEE Transactions on Intelligent Transportation Systems, 16 (2), pp. 970-979; Lee, G.H., Fraundorfer, F., Pollefeys, M., Robust pose-graph loop-closures with expectation-maximization (2013) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 556-563. , &, (,).,. In; Liao, Y., Wang, Y., Liu, Y., (2016) Graph regularized auto-encoders for image representation. IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society p., p. 99. , &; Liu, M., Pradalier, C., Pomerleau, F., Siegwart, R., The role of homing in visual topological navigation (2012) Ieee/rsj International Conference on Intelligent Robots and Systems, pp. 567-572. , &, (,).,. In; Lowry, S., Snderhauf, N., Newman, P., Leonard, J.J., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Mcdonald, J., Kaess, M., Cadena, C., Neira, J., Leonard, J.J., Real-time 6-dof multi-session visual slam over large-scale environments (2013) Robotics & Autonomous Systems, 61 (10), pp. 1144-1158; Mcmanus, C., Furgale, P., Stenning, B., Barfoot, T.D., Lighting-invariant visual teach and repeat using appearance-based lidar (2013) Journal of Field Robotics, 30 (2), p. 254C287; Mcmanus, C., Churchill, W., Maddern, W., Stewart, A.D., Shady dealings: Robust, long-term visual localisation using illumination invariance (2014) IEEE International Conference on Robotics and Automation, pp. 901-906. , &, (,).,. In; McManus, C., Upcroft, B., Newman, P., Learning place-dependant features for long-term vision-based localisation (2015) Autonomous Robots, 39 (3), pp. 363-387; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation, pp. 1643-1649. , &, (,).,. In; Montemerlo, M., Thrun, S., Koller, D., Wegbreit, B., (2002) Fastslam:a factored solution to the simultaneous localization and mapping problem, pp. 593-598. , &, (,).,.,:, Eighteenth National Conference on Artificial Intelligence; Mur-Artal, R., Montiel, J.M.M., Tards, J.D., Orb-slam: A versatile and accurate monocular slam system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163; Newman, P., Sibley, G., Smith, M., Cummins, M., Harrison, A., Mei, C., Posner, I., Murphy, L., Navigating, recognizing and describing urban spaces with vision and lasers (2009) International Journal of Robotics Research, 28 (1112), pp. 1406-1433; Pascoe, G., Maddern, W., Stewart, A.D., Newman, P., (2015) Farlap: Fast robust localisation using appearance priors, , &; Paton, M., Mactavish, K., Warren, M., Barfoot, T.D., Bridging the appearance gap: Multi-experience localization for long-term visual teach and repeat (2016) Ieee/rsj International Conference on Intelligent Robots and Systems, pp. 1918-1925. , &, (,).,. In; Paton, M., Pomerleau, F., Mactavish, K., Ostafew, C.J., Barfoot, T.D., Expanding the limits of visionbased localization for longterm routefollowing autonomy (2017) Journal of Field Robotics, 34, pp. 98-122; Rybski, P.E., Roumeliotis, S., Gini, M., Papanikopoulos, N., Appearance-based mapping using minimalistic sensor models (2008) Autonomous Robots, 24 (3), pp. 229-246; Simhon, S., Dudek, G., A global topological map formed by local metric maps (1998) In: 1998 IEEE/RSJ International Conference on Intelligent Robots and Systems, 1998. Proceedings, IEEE, vol. 3, pp. 1708-1714; Thrun, S., Montemerlo, M., The graph slam algorithm with applications to large-scale mapping of urban structures (2006) International Journal of Robotics Research, 25 (5), pp. 403-429; Tully, S., Kantor, G., Choset, H., A unified bayesian framework for global localization and slam in hybrid metric/topological maps (2012) International Journal of Robotics Research, 31 (3), pp. 271-288; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph slam: Long-term mapping in low dynamic environments (2012) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1871-1878. , &, (,).,. In; Wang, Y., Xiong, R., Li, Q., Huang, S., Kullback-leibler divergence based graph pruning in robotic feature mapping (2013) European Conference on Mobile Robots, pp. 32-37. , (,).,. In; Wang, Y., Xiong, R., Huang, S., A pose pruning driven solution to pose feature graphslam (2015) Advanced Robotics, 29 (10), pp. 1-16; Wang, Y., Huang, S., Xiong, R., Wu, J., A framework for multi-session rgbd slam in low dynamic workspace environment (2016) Caai Transactions on Intelligence Technology, 1 (1), pp. 90-103; Wolf, D.F., Sukhatme, G.S., Mobile robot simultaneous localization and mapping in dynamic environments (2005) Autonomous Robots, 19 (1), pp. 53-65},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044547008&doi=10.1007%2fs10514-018-9724-7&partnerID=40&md5=03f451b4d5483027fc8f6194bda4949a},
}

@conference{wang-et-al:2020:9468884,
  author = {L. Wang and W. Chen and J. Wang},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Long-term localization with time series map prediction for mobile robots in dynamic environments},
  volume = {2020-January},
  pages = {8587--8593},
  doi = {10.1109/IROS45743.2020.9468884},
  note = {cited By 0; Conference of 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2020 ; Conference Date: 24 October 2020 Through 24 January 2021;  Conference Code:167055},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments. © 2020 IEEE.},
  affiliation = {Institute of Medical Robotics, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing, Ministry of Education, Department of Automation, Shanghai, 200240, China},
  art_number = {9468884},
  coden = {85RBA},
  correspondence_address1 = {Chen, W.; Institute of Medical Robotics, China; email: wdchen@sjtu.edu.cn},
  document_type = {Conference Paper},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61773261, U1813206},
  funding_text1 = {ACKNOWLEDGMENT This work is supported by the National Natural Science Foundation of China (Grant U1813206 and 61773261).},
  issn = {21530858},
  keywords = {Agricultural robots;  Autoregressive moving average model;  Forecasting;  Mobile robots;  Time series, Auto-regressive moving average model (ARMA);  Dynamic environments;  Environmental change;  High-precision localization;  Historical information;  Localization performance;  Modeling and predictions;  Predictive mechanisms, Intelligent robots},
  language = {English},
  references = {Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , MIT press; Potter, M.C., Wyble, B., Hagmann, C.E., McCourt, E.S., Detecting meaning in rsvp at 13 ms per picture (2014) Attention, Perception, & Psychophysics, 76 (2), pp. 270-279; Song, B., Chen, W., Wang, J., Wang, H., Long-term visual inertial slam based on time series map prediction (2019) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Macao, Macau, China, pp. 5364-5369; Wang, Y., Chen, W., Wang, J., Map-based localization for mobile robots in high-occluded and dynamic environments (2014) Industrial Robot: An International Journal, 41 (3), pp. 241-252; Hassler, U., Autoregressive moving average processes (arma) (2016) Stochastic Processes and Calculus, pp. 45-75. , Springer; Saarinen, J.P., Andreasson, H., Stoyanov, T., Lilienthal, A.J., 3d normal distributions transform occupancy maps: An efficient representation for mapping in dynamic environments (2013) The International Journal of Robotics Research, 32 (14), pp. 1627-1644; Tipaldi, G.D., Meyer-Delius, D., Burgard, W., Lifelong localization in changing environments (2013) The International Journal of Robotics Research, 32 (14), pp. 1662-1678; Sun, D., Geißer, F., Nebel, B., Towards effective localization in dynamic environments (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 4517-4523. , Daejeon, Korea; Olson, E., M3rsm: Many-to-many multi-resolution scan matching (2015) Proc. IEEE Int. Conf. Robot. Autom., pp. 5815-5821. , Seattle, Washington; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Robotics: Science and Systems, pp. 17-24; Dayoub, F., Cielniak, G., Duckett, T., Long-term experiments with an adaptive spherical view representation for navigation in changing environments (2011) Robotics and Autonomous Systems, 59 (5), pp. 285-295; Morris, T., Dayoub, F., Corke, P., Wyeth, G., Upcroft, B., Multiple map hypotheses for planning and navigating in non-stationary environments (2014) Proc. IEEE Int. Conf. Robot. Autom., pp. 2765-2770. , Chicago, Illinois, USA; Krajnik, T., Fentanes, J.P., Cielniak, G., Dondrup, C., Duckett, T., Spectral analysis for long-term robotic mapping (2014) Proc. IEEE Int. Conf. Robot. Autom., pp. 3706-3711. , Chicago, Illinois, USA; Krajník, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 4558-4563. , Daejeon, Korea; Krajník, T., Fentanes, J.P., Santos, J.M., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) IEEE Transactions on Robotics, 33 (4), pp. 964-977; Schreiber, M., Hoermann, S., Dietmayer, K., Long-term occupancy grid prediction using recurrent neural networks (2019) Proc. IEEE Int. Conf. Robot. Autom., pp. 9299-9305. , Montreal, QC, Canada; Chen, Z., Jacobson, A., Sünderhauf, N., Upcroft, B., Liu, L., Shen, C., Reid, I., Milford, M., Deep learning features at scale for visual place recognition (2017) Proc. IEEE Int. Conf. Robot. Autom., pp. 3223-3230. , Vancouver, Canada; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Akaike, H., A new look at the statistical model identification (1974) Selected Papers of Hirotugu Akaike, pp. 215-222. , Springer; Akaike, H., Fitting autoregressive models for prediction (1969) Annals of the Institute of Statistical Mathematics, 21 (1), pp. 243-247; Dodge, Y., (2008) The Concise Encyclopedia of Statistics, , Springer Science & Business Media; Hu, X., Wang, J., Chen, W., Long-term localization of mobile robots in dynamic changing environments (2018) Chinese Automation Congress (CAC), pp. 384-389. , Xi'an, China; Meyer-Delius, D., Hess, J., Grisetti, G., Burgard, W., Temporary maps for robust localization in semi-static environments (2010) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 5750-5755. , Taipei, Taiwan; Rabiner, L.R., A tutorial on hidden markov models and selected applications in speech recognition (1989) Proceedings of the IEEE, 77 (2), pp. 257-286},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112463942&doi=10.1109%2fIROS45743.2020.9468884&partnerID=40&md5=b0389a34803e04922792176550055984},
}

@conference{wu-wu:2019:8968599,
  author = {L. Wu and Y. Wu},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Deep Supervised Hashing with Similar Hierarchy for Place Recognition},
  pages = {3781--3786},
  doi = {10.1109/IROS40897.2019.8968599},
  note = {cited By 2; Conference of 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2019 ; Conference Date: 3 November 2019 Through 8 November 2019;  Conference Code:157163},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Place recognition as one of the most significant requirements for long-term simultaneous localization and mapping (SLAM) has been developed rapidly in recent years. Also, deep learning is proved to be more capable than traditional methods to extract features under some complex environments. However, in real-world environments, there are many challenging problems such as viewpoint changes and illumination changes. The existing deep learning-based place recognition in extracting feature phases and matching process is both time-consuming. Moreover, features extracted from convolution neural network (CNN) are floating-point type with high dimension. In this paper, we propose deep supervised hashing for place recognition, where we design a similar hierarchy loss function to learn a model. The model can distinguish the similar images more accurately which is well suitable to place recognition. Besides the model can learn high quality hash codes by maximizing the likelihood of triplet labels. Experiments on several benchmark datasets for place recognition show that our approach is robust to viewpoints, illuminations and season changes with high accuracy. Furthermore, the trained model can extract features and match in real time on CPU with less memory consumption. © 2019 IEEE.},
  affiliation = {School of Software Microelectronics of Peking University, Institute of Automation, Chinese Academy of Sciences, National Laboratory of Pattern Recognition, China; Institute of Automation, Chinese Academy of Sciences; University of Chinese Academy of Sciences, National Laboratory of Pattern Recognition, China},
  art_number = {8968599},
  coden = {85RBA},
  correspondence_address1 = {Wu, Y.; Institute of Automation, China; email: yhwu@nlpr.ia.ac.cn},
  document_type = {Conference Paper},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 61421004, 61572499, 61836015},
  funding_text1 = {This work was supported by the National Natural Science Foundation of China under Grant Nos. 61836015, 61572499, 61421004.},
  isbn = {9781728140049},
  issn = {21530858},
  keywords = {Digital arithmetic;  Hash functions;  Intelligent robots;  Robotics, Benchmark datasets;  Complex environments;  Convolution neural network;  Extracting features;  Illumination changes;  Memory consumption;  Real world environments;  Simultaneous localization and mapping, Deep learning},
  language = {English},
  references = {Tang, F., Li, H., Wu, Y., Fmd stereo slam: Fusing mvg and direct formulation towards accurate and fast stereo slam (2019) IEEE International Conference on Robotics and Automation (ICRA; Wu, Y., Tang, F., Li, H., Image-based camera localization: An overview (2018) Visual Computing for Industry, Biomedicine, and Art, 1 (1), p. 8; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based slam (2014) IEEE International Conference on Robotics and Automation (ICRA, pp. 846-853; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., A fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Transactions on Robotics, pp. 1027-1037; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS, pp. 1097-1105; Gidaris, S., Komodakis, N., Object detection via a multi-region and semantic segmentation-Aware cnn model (2015) IEEE International Conference on Computer Vision (ICCV, pp. 1134-1142; Olid, D., Fácil, J.M., Civera, J., (2018) Single-View Place Recognition under Seasonal Changes; Cummins, M., Newman, P.M., Appearance-only slam at large scale with fab-map 2.0 (2011) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet? Challenging seqslam on a 3000 km journey across all four seasons (2013) Proc.of Workshop on Long-Term Autonomy, in IEEE International Conference on Robotics and Automation (ICRA; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) International Conference on Robotics and Automation (ICRA, pp. 1643-1649; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training free (2015) Proceedings of Robotics: Science and Systems, 12; Sünderhauf, N., Dayoub, F., Shirazi, S., Upcroft, B., Milford, M., (2015) On the Performance of Convnet Features for Place Recognition; McManus, C., Upcroft, B., Newmann, P., Scene signatures: Localised and pointless features for localisation (2014) Robotics: Science and Systems, 10. , University of California, Berkeley, CA, July; Gomez-Ojeda, R., Lopez-Antequera, M., Petkov, N., Gonzalez Jimenez, J., (2015) Training a Convolutional Neural Network for Appearance Invariant Place Recognition; Chen, Z., Lam, O., Jacobson, A., Milford, M., (2014) Convolutional Neural Network-Based Place Recognition; Gionis, A., Indyk, P., Motwani, R., Similarity search in high dimensions via hashing (2000) Proceedings of the 25th International Conference on Very Large Data Bases, 99, pp. 518-529; Xia, R., Pan, Y., Lai, H., Liu, C., Yan, S., Supervised hashing for image retrieval via image rrepresentation learning (2014) Twenty-Eighth AAAI Conference on Artificial Intelligence; Lai, H., Pan, Y., Liu, Y., Yan, S., Simultaneous feature learning and hash coding with deep neural networks (2015) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 3270-3278; Zhao, F., Huang, Y., Wang, L., Tan, T., Deep semantic ranking based hashing for multi-label image retrieval (2015) Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR, pp. 1556-1564; Yang, H.-F., Lin, K., Chen, C.-S., Supervised learning of semantics peserving hash via deep convolutional neural networks (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence, 40 (2), pp. 437-451; Li, W.J., Wang, S., Kang, W.C., (2015) Feature Llearning Based Deep Supervised Hashing with Pairwise Labels; Wang, X., Shi, Y., Kitani, K.M., Deep supervised hashing with triplet labels (2016) Asian Conference on Computer Vision (ACCV, pp. 70-84; Howard, A.G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H., (2017) Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081154808&doi=10.1109%2fIROS40897.2019.8968599&partnerID=40&md5=6ed7066fbafaf54d127df7d764ba456d},
}

@article{bosse-zlot:2009:009,
  author = {M. Bosse and R. Zlot},
  journal = {Robotics and Autonomous Systems},
  title = {Keypoint design and evaluation for place recognition in 2D lidar maps},
  volume = {57},
  number = {12},
  pages = {1211--1224},
  doi = {10.1016/j.robot.2009.07.009},
  note = {cited By 81},
  year = {2009},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {We address the place recognition problem, which we define as the problem of establishing whether an observed location has been previously seen, and if so, determining the transformation aligning the current observations to an existing map. In the contexts of robot navigation and mapping, place recognition amounts to globally localizing a robot or map segment without being given any prior estimate. An efficient method of solving this problem involves first selecting a set of keypoints in the scene which store an encoding of their local region, and then utilizing a sublinear-time search into a database of keypoints previously generated from the global map to identify places with common features. We present an algorithm to embed arbitrary keypoint descriptors in a reduced-dimension metric space, in order to frame the problem as an efficient nearest neighbor search. Given that there are a multitude of possibilities for keypoint design, we propose a general methodology for comparing keypoint location selection heuristics and descriptor models that describe the region around the keypoint. With respect to selecting keypoint locations, we introduce a metric that encodes how likely it is that the keypoint will be found in the presence of noise and occlusions during mapping passes. Metrics for keypoint descriptors are used to assess the distinguishability between the distributions of matches and non-matches and the probability the correct match will be found in an approximate k-nearest neighbors search. Verification of the test outcomes is done by comparing the various keypoint designs on a kilometers-scale place recognition problem. We apply our design evaluation methodology to three keypoint selection heuristics and six keypoint descriptor models. A full place recognition system is presented, including a series of match verification algorithms which effectively filter out false positives. Results from city-scale and long-term mapping problems illustrate our approach for both offline and online SLAM, map merging, and global localization and demonstrate that our algorithm is able to produce accurate maps over trajectories of hundreds of kilometers. Crown Copyright © 2009.},
  affiliation = {Autonomous Systems Laboratory, CSIRO ICT Centre, Australia},
  author_keywords = {Data association;  Dimension reduction;  Localization;  Mapping;  Place recognition;  Regional point descriptor;  SLAM},
  coden = {RASOE},
  correspondence_address1 = {Bosse, M.; Autonomous Systems Laboratory, Australia; email: mike.bosse@csiro.au},
  document_type = {Article},
  issn = {09218890},
  keywords = {Data association;  Dimension reduction;  Localization;  Place recognition;  Regional point descriptor;  SLAM, Design;  Heuristic methods;  Location;  Mapping;  Optical radar;  Probability distributions;  Set theory;  Topology, Problem solving},
  language = {English},
  references = {Bailey, T., (2002) Mobile robot localisation and mapping in extensive outdoor environments, , Ph.D. thesis, The University of Sydney, Sydney, Australia August; Bosse, M., Newman, P., Leonard, J., Teller, S., Simultaneous localization and map building in large-scale cyclic environments using the Atlas Framework (2004) International Journal of Robotics Research, 23 (12), pp. 1113-1139; Estrada, C., Neira, J., Tardós, J., Hierarchical SLAM: Real-time accurate mapping of large environments (2005) IEEE Transactions on Robotics, 21 (4), pp. 588-596; Tomono, M., A scan matching method using Euclidean invariant signature for global localization and map building (2004) IEEE International Conference on Robotics and Automation; Walthelm, A., Enhancing global pose estimation with laser range scans using local techniques (2004) International Conference on Intelligent Autonomous Systems; Ho, K., Newman, P., Combining visual and spatial appearance for loop closure detection in SLAM (2005) European Conference on Mobile Robotics; Ho, K.L., Newman, P., Detecting loop closure with scene sequences (2007) International Journal of Computer Vision, 74 (3), pp. 261-286; Schindler, G., Brown, M., Szeliski, R., City-scale location recognition (2007) IEEE Computer Society Conference on Computer Vision and Pattern Recognition; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) International Journal of Robotics Research, 27 (6), pp. 647-665; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Bay, H., Tuytelaars, T., Gool, L.V., Speeded up robust features (2006) European Conference on Computer Vision, , SURF; Bosse, M., Zlot, R., Map matching and data association for large-scale two-dimensional laser scan-based SLAM (2008) International Journal of Robotics Research, 27 (6), pp. 667-691; Howard, A., Roy, N., (2003) The robotics data set repository, , http://radish.sourceforge.net, Radish; Lu, F., Milios, E., Robot pose estimation in unknown environments by matching 2D range scans (1994) IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 935-938. , Seattle, USA; Fukunaga, K., Hostetler, L.D., The estimation of the gradient of a density function, with applications in pattern recognition (1975) IEEE Transactions on Information Theory, 21 (1), pp. 32-40; Weiss, G., Wetzler, C., von Puttkamer, E., Keeping track of position and orientation of moving indoor systems by correlation of range-finder scans (1994) IEEE/RSJ International Conference on Intelligent Robots and Systems; Belongie, S., Malik, J., Puzicha, J., Shape matching and object recognition using shape contexts (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (4), pp. 509-522; Neyman, J., Pearson, E.S., On the problem of the most efficient tests of statistical hypotheses (1933) Philosophical Transactions of the Royal Society of London: Series A, Containing Papers of a Mathematical or Physical Character, 231, pp. 289-337; Matthews, B.W., Comparison of the predicted and observed secondary structure of T4 phage lysozyme (1975) Biochimica et Biophysica Acta, 405, pp. 442-451; Lin, K.-I., Nolen, M., Kommeneni, K., Utilizing indexes for approximate and on-line nearest neighbor queries (2005) International Database Eng. and Application Symposium; Zlot, R., Bosse, M., Place recognition using keypoint similarities in 2D lidar maps (2008) International Symposium on Experimental Robotics; Arya, S., Mount, D.M., Netanyahu, N.S., Silverman, R., Wu, A.Y., An optimal algorithm for approximate nearest neighbor searching in fixed dimensions (1998) Journal of the ACM, 45, pp. 891-923; Liu, T., Moore, A.W., Gray, A., Yang, K., An investigation of practical approximate nearest neighbor algorithms (2004) Neural Information Processing Systems Conference; Andoni, A., Indyk, P., Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions (2008) Communications of the ACM, 51 (1), pp. 117-122; Procopiuc, O., Agarwal, P., Arge, L., Vitter, J.S., tree, B., A dynamic scalable kd-tree (2003) International Symposium on Spatial and Temporal Databases; Bosse, M., Zlot, R., Place recognition using regional point descriptors for 3D mapping (2009) International Conference on Field and Service Robotics},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350728823&doi=10.1016%2fj.robot.2009.07.009&partnerID=40&md5=e83c3997ee99c0ccf0722acb23a94718},
}

@article{bürki-et-al:2019:21870,
  author = {M. Bürki and C. Cadena and I. Gilitschenski and R. Siegwart and J. Nieto},
  journal = {Journal of Field Robotics},
  title = {Appearance-based landmark selection for visual localization},
  volume = {36},
  number = {6},
  pages = {1041--1073},
  doi = {10.1002/rob.21870},
  note = {cited By 8},
  publisher = {John Wiley and Sons Inc},
  year = {2019},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {Visual localization in outdoor environments is subject to varying appearance conditions rendering it difficult to match current camera images against a previously recorded map. Although it is possible to extend the respective maps to allow precise localization across a wide range of differing appearance conditions, these maps quickly grow in size and become impractical to handle on a mobile robotic platform. To address this problem, we present a landmark selection algorithm that exploits appearance co-observability for efficient visual localization in outdoor environments. Based on the appearance condition inferred from recently observed landmarks, a small fraction of landmarks useful under the current appearance condition is selected and used for localization. This allows to greatly reduce the bandwidth consumption between the mobile platform and a map backend in a shared-map scenario, and significantly lowers the demands on the computational resources on said mobile platform. We derive a landmark ranking function that exhibits high performance under vastly changing appearance conditions and is agnostic to the distribution of landmarks across the different map sessions. Furthermore, we relate and compare our proposed appearance-based landmark ranking function to popular ranking schemes from information retrieval, and validate our results on the challenging University of Michigan North Campus long-term vision and LIDAR data sets (NCLT), including an evaluation of the localization accuracy using ground-truth poses. In addition to that, we investigate the computational and bandwidth resource demands. Our results show that by selecting 20–30% of landmarks using our proposed approach, a similar localization performance as the baseline strategy using all landmarks is achieved. © 2019 Wiley Periodicals, Inc.},
  affiliation = {Autonomous Systems Lab, ETH Zürich, Zürich, Switzerland; Computer Science and Artificial Intelligence Lab, MIT, Cambridge, MA, United States},
  author_keywords = {landmark selection;  long-term localization;  multisession mapping;  visual localization;  wheeled robots},
  correspondence_address1 = {Bürki, M.; Autonomous Systems Lab, Switzerland; email: mathias.buerki@mavt.ethz.ch},
  document_type = {Article},
  funding_details = {Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme, H2020, 688652},
  funding_text1 = {This project has received funding from the EU H2020 research project ?UP-Drive? under grant no. 688652 and from the Swiss State Secretariat for Education, Research and Innovation (SERI) under contract number 15.0284.},
  issn = {15564959},
  keywords = {Agricultural robots;  Drilling platforms;  Information retrieval, Bandwidth consumption;  Computational resources;  Landmark selection;  Localization performance;  long-term localization;  University of Michigan;  Visual localization;  Wheeled robot, Bandwidth},
  language = {English},
  references = {Aizawa, A., An information-theoretic perspective of tf-idf measures (2003) Information Processing and Management, 39 (1), pp. 45-65; (2012), pp. 510-517. , Alahi, A., Ortiz, R.Vandergheynst, P. (,). Freak Fast retina keypoint., 2012 IEEE Conference on Computer Vision and Pattern Recognition,  Rhode Island, RI; (2006), pp. 404-417. , Bay, H., Tuytelaars, T.Van Gool, L. (,). Surf Speeded up robust features., European Conference on Computer Vision, Graz, Austria; (2009), pp. 2089-2095. , Burgard, W., Stachniss, C., Grisetti, G., Steder, B., Kümmerle, R., Dornhege, C., … Tardós, J. (,). A comparison of SLAM algorithms based on a graph of relations. 2009, IEEE/RSJ International Conference on Intelligent Robots and Systems, St. Louis, MO; (2018), pp. 682-688. , Bürki, M., Dymczyk, M., Gilitschenski, I., Cadena, C., Siegwart, R.Nieto, J. (,). Map management for efficient long-term visual localization in outdoor environments. 2018 IEEE Intelligent Vehicles Symposium, Daejeon, South Korea; (2016), pp. 4137-4143. , Bürki, M., Gilitschenski, I., Stumm, E., Siegwart, R.Nieto, J. (,). Appearance-based landmark selection for efficient long-term visual localization. 2016, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), IEEE,  Daejeon, South Korea; Calonder, M., Lepetit, V., Özuysal, M., Trzcinski, T., Strecha, C., Fua, P., BRIEF: Computing a local binary descriptor very fast (2012) Transactions on Pattern Analysis and Machine Intelligence, 34 (7), pp. 1281-1298; Carlevaris-Bianco, N., Ushani, A., Eustice, R., University of Michigan North Campus long-term vision and lidar datase (2016) The International Journal of Robotics Research, 35 (9), pp. 1023-1035; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Clement, L., Kelly, J., Barfoot, T., Robust monocular visual teach and repeat aided by local ground planarity and color-constant imagery (2017) Journal of Field Robotics, 34 (1), pp. 74-97; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Dayoub, F., Cielniak, G., Duckett, T., Long-term experiments with an adaptive spherical view representation for navigation in changing environments (2011) Robotics and Autonomous Systems, 59 (5), pp. 285-295; (2015), pp. 2536-2542. , Dymczyk, M., Lynen, S., Bosse, M.Siegwart, R. (,). Keep it brief Scalable creation of compressed localization maps. 2015, IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS,), Hamburg, Germany; (2006), 2006, pp. 3405-3410. , Fayin, L.Košecká, J. (,). Probabilistic location recognition using reduced feature set., Proceedings of, 2006, IEEE International Conference on Robotics and Automation, Orlando, FL; (2009), pp. 1-6. , Hochdorfer, S.Schlegel, C. (,). Towards a robust visual SLAM approach Addressing the challenge of life-long operation. 2009, International Conference on Advanced Robotics,  Munich, Germany; (2013), pp. 3212-3218. , Johns, E.Yang, G. (,). Feature co-occurrence maps Appearance-based localisation throughout the day. 2013, IEEE International Conference on Robotics and Automation, St. Louis, MO; Johns, E., Yang, G., Generative methods for long-term place recognition in dynamic scenes (2014) International Journal of Computer Vision, 106 (3), pp. 297-314; Konolige, K., Bowman, J., (2009), pp. 115-1163. , . Towards lifelong visual maps., 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems; (2014), pp. 756-761. , Lategahn, H., Beck, J.Stiller, C. (,). DIRD is an illumination robust descriptor. 2014, IEEE Intelligent Vehicles Symposium Proceedings, Ypsilanti, MI; (2010), pp. 791-804. , Li, Y., Snavely, N.Huttenlocher, D. P. (,). Location recognition using prioritized feature matching., ECCV’10 Proceedings of the 11th ECCV, Hersonissos, Greece; (2015), pp. 90-97. , Linegar, C., Churchill, W.Newman, P. (,). Work smart, not hard Recalling relevant experiences for vast-scale but time-constrained localisation. 2015, IEEE International Conference on Robotics and Automation, ICRA,), Seattle, WA; (1999), pp. 1150-1157. , Lowe, D. (,). Object recognition from local scale-invariant features., Proceedings of the Seventh IEEE International Conference on Computer Vision, Corfu, Greece, vol 2; (2017), pp. 2065-2072. , Mactavish, K., Paton, M.Barfoot, T. (,). Visual triage A bag-of-words experience selector for long-term visual route following. 2017, IEEE International Conference on Robotics and Automation, ICRA,), Singapore; (2014), Maddern, W., Stewart, A., McManus, C., Upcroft, B., Churchill, W.Newman, P. (,). Illumination invariant imaging Applications in robust vision-based localisation, mapping and classification for autonomous vehicles., IEEE International Conference on Robotics and Automation, Hong Kong, China, p. 5; (2014), pp. 901-906. , McManus, C., Churchill, W., Maddern, W., Stewart, A.Newman, P. (,). Shady dealings Robust, long-term visual localisation using illumination invariance. 2014, IEEE International Conference on Robotics and Automation, Hong Kong, China; McManus, C., Upcroft, B., Newman, P., (2014) Scene Signatures: Localised and Point-Less Features for Localisation, , RSS. Rome, Italy; Milford, M., Prasser, D., Wyeth, G., (2005), pp. 1-10. , . Experience mapping Producing spatially continuous environment representations using RatSLAM., Proceedings of Australasian Conference on Robotics and Automation 2005; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired slam system (2010) The International Journal of Robotics Research, 29 (9), pp. 1131-1153; (2004), pp. 403-408. , Milford, M., Wyeth, G.Prasser, D. (,). RatSLAM A hippocampal model for simultaneous localization and mapping., IEEE International Conference on Robotics and Automation,  New Orleans, LA, vol 1, IEEE; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) Journal of Field Robotics, 33 (5), pp. 561-590; (2015), http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A811166&dswid=-565, Mühlfellner, P., Furgale, P., Derendarz, W.Philippsen, R. (, Designing a relational database for long-term visual mapping; (2015), pp. 1519-1526. , Paton, M., MacTavish, K., Ostafew, C.Barfoot, T. (,). Itas not easy seeing green Lighting-resistant stereo Visual Teach & Repeat using color-constant images. 2015, IEEE International Conference on Robotics and Automation, ICRA,), Seattle, WA; (2016), pp. 1918-1925. , Paton, M., Mactavish, K., Warren, M.Barfoot, T. D. (,). Bridging the appearance gap Multi-experience localization for long-term visual teach and repeat. 2016, IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS,), Daejeon, South Korea; Prasser, D., Milford, M., Wyeth, G., Outdoor simultaneous localisation and mapping using RatSLAM (2006) Field and Service Robotics, 25, pp. 143-154; Salton, G., Buckley, C., Term-weighting approaches in automatic text retrieval (1988) Information Processing and Management, 24 (5), pp. 513-523; (2011), pp. 667-674. , Sattler, T., Leibe, B.Kobbelt, L. (,). Fast image-based localization using direct 2D-to-3D matching. 2011, International Conference on Computer Vision, Barcelona, Spain; (2007), pp. 1-7. , Schindler, G., Brown, M.Szeliski, R. (,). City-scale location recognition. 2007, IEEE Conference on Computer Vision and Pattern Recognition, Minneapolis, MN; (2015), pp. 5475-5480. , Stumm, E., Mei, C., Lacroix, S.Chli, M. (,). Location graphs for visual place recognition. 2015 IEEE International Conference on Robotics and Automation (ICRA), Seattle, WA},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067640191&doi=10.1002%2frob.21870&partnerID=40&md5=852a36bfcbca474822776f4dc134d84c},
}

@conference{dymczyk-et-al:2016:66,
  author = {M. Dymczyk and E. Stumm and J. Nieto and R. Siegwart and I. Gilitschenski},
  journal = {Proceedings - 2016 4th International Conference on 3D Vision, 3DV 2016},
  title = {Will it last? Learning stable features for long-term visual localization},
  pages = {572--581},
  doi = {10.1109/3DV.2016.66},
  note = {cited By 11; Conference of 4th International Conference on 3D Vision, 3DV 2016 ; Conference Date: 25 October 2016 Through 28 October 2016;  Conference Code:125615},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2016},
  abbrev_source_title = {Proc. - Int. Conf. 3D Vis., 3DV},
  abstract = {An increasing number of simultaneous localization and mapping (SLAM) systems are using appearance-based localization to improve the quality of pose estimates. However, with the growing time-spans and size of the areas we want to cover, appearance-based maps are often becoming too large to handle and are consisting of features that are not always reliable for localization purposes. This paper presents a method for selecting map features that are persistent over time and thus suited for long-term localization. Our methodology relies on a CNN classifier based on image patches and depth maps for recognizing which features are suitable for life-long matchability. Thus, the classifier not only considers the appearance of a feature but also takes into account its expected lifetime. As a result, our feature selection approach produces more compact maps with a high fraction of temporally-stable features compared to the current state-of-the-art, while rejecting unstable features that typically harm localization. Our approach is validated on indoor and outdoor datasets, that span over a period of several months. © 2016 IEEE.},
  affiliation = {Autonomous Systems Lab, ETH Zurich, Switzerland},
  art_number = {7785133},
  author_keywords = {CNN;  feature selection;  localization;  machine learning;  mapping;  place recognition;  SLAM},
  correspondence_address1 = {Dymczyk, M.; Autonomous Systems Lab, Switzerland},
  document_type = {Conference Paper},
  isbn = {9781509054077},
  keywords = {Indoor positioning systems;  Learning systems;  Mapping;  Robotics, Appearance based;  Expected lifetime;  localization;  Place recognition;  Simultaneous localization and mapping;  SLAM;  State of the art;  Visual localization, Feature extraction},
  language = {English},
  references = {Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., Rftxt University of Michigan north campus long-Term vision and lidar dataset (2015) The International Journal of Robotics Research, , 0278364915614638; Churchill, W., Newman, P., Experience-based navigation for long-Term localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661. , sep; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-Time single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (6), pp. 1052-1067. , jun; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T., Decaf: A deep convolutional acti- vation feature for generic visual recognition (2014) ICML, pp. 647-655; Dymczyk, M., Lynen, S., Bosse, M., Siegwart, R., (2015) Keep It Brief: Scalable Creation of Compressed Localization Maps; Fusiello, A., Trucco, E., Verri, A., A compact algorithm for rectification of stereo pairs (2000) Machine Vision and Applications, 12 (1), pp. 16-22; Gao, X.-S., Hou, X.-R., Tang, J., Cheng, H.-F., Complete solution classification for the perspective-Three-point problem (2003) IEEE Transactions on Pattern Analysis and Machine Intelligence, 25 (8), pp. 930-943; Harris, C., Stephens, M., A combined corner and edge detector (1988) Proc. of Fourth Alvey Vision Conference, pp. 147-151; Hartmann, W., Havlena, M., Schindler, K., Predicting Matchability (2014) 2014 IEEE Conference on Computer Vision and Pattern Recognition, pp. 9-16. , IEEE, jun; Ibrahim, J.G., Chen, M.-H., Sinha, D., (2001) Bayesian Survival Analysis, , Springer; Jegou, H., Douze, M., Schmid, C., Hamming embedding and weak geometric consistency for large scale image search (2008) European Conference on Computer Vision, pp. 304-317. , Springer; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional Architecture for Fast Feature Embedding, , arXiv preprint arXiv 1408.5093; Johns, E., Yang, G.-Z., Generative methods for long-Term place recognition in dynamic scenes (2014) International Journal of Computer Vision, 106 (3), pp. 297-314; Karayev, S., Hertzmann, A., Winnemoeller, H., Agarwala, A., Darrell, T., Recognizing image style (2013) CoRR, abs/1311.3715; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) CVPR; Kim, H.J., Dunn, E., Frahm, J.-M., Predicting Good Features for Image Geo-Localization Using Per-Bundle VLAD (2015) ICCV; Knopp, J., Sivic, J., Pajdla, T., Avoiding Confusing Features in Place Recognition (2010) ECCV; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1156-1163. , IEEE, oct 2009; Konolige, K., Bowman, J., Chen, J.D., Mihelich, P., Calonder, M., Lepetit, V., Fua, P., View-based Maps (2010) The International Journal of Robotics Research, 29 (8), pp. 941-957. , jul; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks Advances in Neural Information Processing Systems, 25, pp. 1097-1105. , F. Pereira C. Burges, L. Bottou, and K. Weinberger, editors Curran Associates, Inc., 2012; Leutenegger, S., Chli, M., Siegwart, R.Y., BRISK: Binary Robust invariant scalable keypoints (2011) 2011 International Conference on Computer Vision, pp. 2548-2555. , IEEE, nov; Linegar, C., Churchill, W., Newman, P., Work Smart, Not Hard: Recalling Relevant Experiences for Vast-Scale but Time-Constrained Localisation (2015) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), Seattle, USA; Linegar, C., Churchill, W., Newman, P., Made to measure: Bespoke landmarks for 24-hour, all-weather localisation with a camera (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 787-794. , IEEE, may; Lowe, D., Object recognition from local scale-invariant features (1999) Proceedings of the Seventh IEEE International Conference on Computer Vision, 2, pp. 1150-1157. , IEEE 2; Lynen, S., Bosse, M., Furgale, P., Siegwart, R., Placeless Place-Recognition (2014) 2nd International Conference on 3D Vision, 1, pp. 303-310. , IEEE, dec; Lynen, S., Sattler, T., Bosse, M., Hesch, J., Pollefeys, M., Siegwart, R., Get out of my lab: Large-scale, real-Time visualinertial localization (2015) Proceedings of Robotics: Science and Systems, , Rome, Italy, July; McManus, C., Upcroft, B., Newman, P., Learning placedependant features for long-Term vision-based localisation (2015) Autonomous Robots, 39 (3), pp. 363-387. , jul; Middelberg, S., Sattler, T., Untzelmann, O., Kobbelt, L., Scalable 6-dof localization on mobile devices (2014) ECCV; Mourikis, A.I., Roumeliotis, S.I., A multi-state constraint kalman filter for vision-Aided inertial navigation (2007) Proceedings 2007 IEEE International Conference on Robotics and Automation, pp. 3565-3572. , IEEE; Ortiz Freak, R., Fast retina keypoint Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), CVPR ?12, pp. 510-517. , Washington, DC, USA, 2012; Park, H.S., Wang, Y., Nurvitadhi, E., Hoe, J.C., Sheikh, Y., Chen, M., 3d point cloud reduction using mixed-integer quadratic programming (2013) Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 229-236. , IEEE Conference on IEEE, 2013; Pollefeys, M., Koch, R., Van Gool, L., A simple and efficient rectification method for general motion (1999) Computer Vision 1999 IEEE International Conference on, 1, pp. 496-501. , IEEE; Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong feature-based mapping in semi-static environments (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 1063-1070. , may; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Image net large scale visual recognition challenge (2015) International Journal of Computer Vision (IJCV), pp. 1-42. , April; Sattler, T., Leibe, B., Kobbelt, L., Fast image-based localization using direct 2d-To-3d matching (2011) 2011 International Conference on Computer Vision, pp. 667-674. , IEEE; Tomasi, C., Manduchi, R., Bilateral filtering for gray and color images (1998) Computer Vision, pp. 839-846. , IEEE 1998; Turcot, P., Lowe, D.G., Better matching with fewer features: The selection of useful features in large database recognition problems (2009) IEEE 12th International Conference on Computer Vision Workshops, , IEEE 2009; Valgren, C., Lilienthal, A.J., SIFT SURF & Seasons: Appearance-based Long-Term Localization in Outdoor Environments (2010) Robotics and Autonomous Systems, 58 (2), pp. 149-156},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011318002&doi=10.1109%2f3DV.2016.66&partnerID=40&md5=6e17d2ff56ae3b9f45f149fc69900f26},
}

@conference{dymczyk-et-al:2015:7139575,
  author = {M. Dymczyk and S. Lynen and T. Cieslewski and M. Bosse and R. Siegwart and P. Furgale},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {The gist of maps - Summarizing experience for lifelong localization},
  volume = {2015-June},
  number = {June},
  pages = {2767--2773},
  doi = {10.1109/ICRA.2015.7139575},
  note = {cited By 46; Conference of 2015 IEEE International Conference on Robotics and Automation, ICRA 2015 ; Conference Date: 26 May 2015 Through 30 May 2015;  Conference Code:113196},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2015},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Robust, scalable place recognition is a core competency for many robotic applications. However, when revisiting places over and over, many state-of-the-art approaches exhibit reduced performance in terms of computation and memory complexity and in terms of accuracy. For successful deployment of robots over long time scales, we must develop algorithms that get better with repeated visits to the same environment, while still working within a fixed computational budget. This paper presents and evaluates an algorithm that alternates between online place recognition and offline map maintenance with the goal of producing the best performance with a fixed map size. At the core of the algorithm is the concept of a Summary Map, a reduced map representation that includes only the landmarks that are deemed most useful for place recognition. To assign landmarks to the map, we use a scoring function that ranks the utility of each landmark and a sampling policy that selects the landmarks for each place. The Summary Map can then be used by any descriptor-based inference method for constant-complexity online place recognition. We evaluate a number of scoring functions and sampling policies and show that it is possible to build and maintain maps of a constant size and that place-recognition performance improves over multiple visits. © 2015 IEEE.},
  affiliation = {Autonomous Systems Lab, ETH Zurich, Switzerland},
  art_number = {7139575},
  coden = {PIIAE},
  document_type = {Conference Paper},
  isbn = {9781479969234},
  issn = {10504729},
  keywords = {Agricultural robots;  Budget control, Computational budget;  Core competencies;  Inference methods;  Map representations;  Place recognition;  Robotic applications;  Scoring functions;  State-of-the-art approach, Robotics},
  language = {English},
  references = {Furgale, P.T., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) Journal of Field Robotics; Muehlfellner, P., Furgale, P.T., Derendarz, W., Philippsen, R., Evaluation of fisheye-camera based visual multi-session localization in a real-world scenario (2013) IEEE Intelligent Vehicles Symposium, 4; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) The International Journal of Robotics Research (IJRR); Lynen, S., Bosse, M., Furgale, P., Siegwart, R., Placeless place-recognition (2014) 3DV; Jegou, H., Douze, M., Schmid, C., Hamming embedding and weak geometric consistency for large scale image search Computer Vision (ECCV), 2008 IEEE European Conference on; Sivic, J., Zisserman, A., Video google: A text retrieval approach to object matching in videos Computer Vision (ICCV), 2003 IEEE International Conference on; Beinhofer, M., Müller, J., Burgard, W., Effective landmark placement for accurate and reliable mobile robot navigation (2013) Robotics and Autonomous Systems; Vitus, M.P., Tomlin, C.J., Sensor placement for improved robotic navigation (2010) Robotics: Science and Systems; Allen, R., Macmillan, N., Marinakis, D., Nishat, R.I., Rahman, R., Whitesides, S., The range beacon placement problem for robot navigation (2014) Computer and Robot Vision (CRV), Canadian Conference on, , IEEE; Konolige, K., Bowman, J., Chen, J., Mihelich, P., Calonder, M., Lepetit, V., Fua, P., View-based maps (2010) The Int. Journal of Robotics Research; Agrawal, M., Konolige, K., Frameslam: From bundle adjustment to real-time visual mapping (2008) IEEE Transactions on Robotics; Johannsson, H., Kaess, M., Fallon, M., Leonard, J.J., Temporally scalable visual slam using a reduced pose graph (2013) Robotics and Automation (ICRA), IEEE International Conference on, , IEEE; Kretzschmar, H., Stachniss, C., Informationtheoretic compression of pose graphs for laser-based slam (2012) The Int. Journal of Robotics Research; Carlevaris-Bianco, N., Kaess, M., Eustice, R.M., Generic node removal for factor-graph SLAM (2014) IEEE Transactions on Robotics; Huang, G., Kaess, M., Leonard, J.J., Consistent sparsification for graph optimization (2013) Mobile Robots (ECMR), European Conference on, , IEEE; Milford, M., Wyeth, G., Seqslam: Visual routebased navigation for sunny summer days and stormy winter nights (2012) Robotics and Automation (ICRA), IEEE International Conference on; Pepperell, E., Corke, P.I., Milford, M.J., Allenvironment visual place recognition with smart (2014) Robotics and Automation (ICRA), IEEE International Conference on; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) AAAI; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research; Maddern, W.P., Milford, M., Wyeth, G., Towards persistent localization and mapping with a continuous appearance-based topology (2012) Robotics: Science and Systems; Paul, R., Newman, P., Self help: Seeking out perplexing images for ever improving navigation (2011) Robotics and Automation (ICRA), IEEE International Conference on, , IEEE; Maddern, W., Milford, M., Wyeth, G., Towards persistent indoor appearance-based localization, mapping and navigation using cat-graph (2012) Intelligent Robots and Systems (IROS), IEEE/RSJ International Conference on, , IEEE; Johns, E., Yang, G.-Z., Feature co-occurrence maps: Appearance-based localisation throughout the day (2013) Robotics and Automation (ICRA), IEEE International Conference on; Sattler, T., Leibe, B., Kobbelt, L., Fast image-based localization using direct 2d-to-3d matching (2011) Computer Vision (ICCV), IEEE International Conference on, , IEEE; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., (2014) Summary Maps for Lifelong Visual Localization, , manuscript submitted for publication; Lee, J.C., Dugan, R., Google Project Tango, , https//www.google.com/atap/projecttango/#project; Cieslewski, T., Lynen, S., Dymczyk, M., Magnenat, S., Siegwart, R., Map api-scalable decentralized map building for robots (2015) Robotics and Automation (ICRA), 2015 IEEE International Conference on},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938252809&doi=10.1109%2fICRA.2015.7139575&partnerID=40&md5=ae0e3d100d94b16754f0e9449013429f},
}

@conference{dymczyk-et-al:2016:7759673,
  author = {M. Dymczyk and T. Schneider and I. Gilitschenski and R. Siegwart and E. Stumm},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Erasing bad memories: Agent-side summarization for long-term mapping},
  volume = {2016-November},
  pages = {4572--4579},
  doi = {10.1109/IROS.2016.7759673},
  note = {cited By 12; Conference of 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2016 ; Conference Date: 9 October 2016 Through 14 October 2016;  Conference Code:125056},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2016},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Precisely estimating the pose of an agent in a global reference frame is a crucial goal that unlocks a multitude of robotic applications, including autonomous navigation and collaboration. In order to achieve this, current state-oftheart localization approaches collect data provided by one or more agents and create a single, consistent localization map, maintained over time. However, with the introduction of lengthier sorties and the growing size of the environments, data transfers between the backend server where the global map is stored and the agents are becoming prohibitively large. While some existing methods partially address this issue by building compact summary maps, the data transfer from the agents to the backend can still easily become unmanageable. In this paper, we propose a method that is designed to reduce the amount of data that needs to be transferred from the agent to the backend, functioning in large-scale, multisession mapping scenarios. Our approach is based upon a landmark selection method that exploits information coming from multiple, possibly weak and correlated, landmark utility predictors; fused using learned feature coefficients. Such a selection yields a drastic reduction in data transfer while maintaining localization performance and the ability to efficiently summarize environments over time. We evaluate our approach on a data set that was autonomously collected in a dynamic indoor environment over a period of several months. © 2016 IEEE.},
  affiliation = {Autonomous Systems Lab, ETH Zurich, Switzerland},
  art_number = {7759673},
  coden = {85RBA},
  document_type = {Conference Paper},
  isbn = {9781509037629},
  issn = {21530858},
  keywords = {Data transfer;  Intelligent robots;  Mapping;  Robots, Autonomous navigation;  Back-end servers;  Indoor environment;  Landmark selection;  Localization performance;  Mapping scenarios;  Reference frame;  Robotic applications, Autonomous agents},
  language = {English},
  references = {Middelberg, S., Sattler, T., Untzelmann, O., Kobbelt, L., Scalable 6-dof localization on mobile devices (2014) European Conf. on Computer Vision; Cieslewski, T., Lynen, S., Dymczyk, M., Magnenat, S., Siegwart, R., Map API - Scalable decentralized map building for robots (2015) IEEE Int. Conf. on Robotics and Automation; Lynen, S., Sattler, T., Bosse, M., Hesch, J., Pollefeys, M., Siegwart, R., Get out of my lab: Large-scale, realtime visual-inertial localization (2015) Robotics: Science and Systems; Riazuelo, L., Civera, J., Montiel, J., C2tam: A cloud framework for cooperative tracking and mapping (2013) Robotics and Autonomous Systems; Forster, C., Lynen, S., Kneip, L., Scaramuzza, D., Collaborative monocular slam with multiple micro aerial vehicles (2013) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems; Arth, C., Klopschitz, M., Reitmayr, G., Schmalstieg, D., Real-time self-localization from panoramic images on mobile devices (2011) IEEE Int. Symp. on Mixed and Augmented Reality; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2015) Journal of Field Robotics; Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The GIST of mapssummarizing experience for lifelong localization (2015) IEEE Int. Conf. on Robotics and Automation; Dymczyk, M., Lynen, S., Bosse, M., Siegwart, R., Keep it brief: Scalable creation of compressed localization maps (2015) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems; Hartmann, W., Havlena, M., Schindler, K., Predicting matchability (2014) IEEE Conf. on Computer Vision and Pattern Recognition; Buoncompagni, S., Maio, D., Maltoni, D., Papi, S., Saliency-based keypoint selection for fast object detection and matching (2015) Pattern Recognition Letters, 62, pp. 32-40; Milford, M.J., Wyeth, G.F., Seqslam: Visual routebased navigation for sunny summer days and stormy winter nights (2012) IEEE Int. Conf. on Robotics and Automation; Sünderhauf, N., Shirazi, S., Jacobson, A., Pepperell, E., Dayoub, F., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Robotics: Science and Systems; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5); Sattler, T., Leibe, B., Kobbelt, L., Fast image-based localization using direct 2d-to-3d matching (2011) Int. Conf. on Computer Vision; Lynen, S., Bosse, M., Furgale, P., Siegwart, R., Placeless place-recognition (2014) 3DV; Carneiro, G., Jepson, A.D., The quantitative characterization of the distinctiveness and robustness of local image descriptors (2009) Image and Vision Computing, 27 (8), pp. 1143-1156; Verdie, Y., Yi, K.M., Fua, P., Lepetit, V., TILDE: A temporally invariant learned detector (2015) IEEE Conf. on Computer Vision and Pattern Recognition; Zhang, W., Košecká, J., Hierarchical building recognition (2007) Image and Vision Computing, 25 (5), pp. 704-716; Knopp, J., Sivic, J., Pajdla, T., Avoiding confusing features in place recognition (2010) European Conf. on Computer Vision, , Springer; Leutenegger, S., Chli, M., Siegwart, R.Y., BRISK: Binary robust invariant scalable keypoints (2011) Int. Conf. on Computer Vision; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph slam: Long-term mapping in low dynamic environments (2012) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems; Churchill, W., Newman, P., Experience-based Navigation for Long-term Localisation (2013) The International Journal of Robotics Research (IJRR); Park, H.S., Wang, Y., Nurvitadhi, E., Hoe, J.C., Sheikh, Y., Chen, M., 3d point cloud reduction using mixed-integer quadratic programming (2013) IEEE Conf. on Computer Vision and Pattern Recognition Workshops; Marder-Eppstein, E., Berger, E., Foote, T., Gerkey, B., Konolige, K., The office marathon: Robust navigation in an indoor office environment (2010) IEEE Int. Conf. on Robotics and Automation; Nikolic, J., Rehder, J., Burri, M., Gohl, P., Leutenegger, S., Furgale, P.T., Siegwart, R., A synchronized visualinertial sensor system with FPGA pre-processing for accurate real-time slam (2014) IEEE Int. Conf. on Robotics and Automation},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006470261&doi=10.1109%2fIROS.2016.7759673&partnerID=40&md5=3d025ca7098dfd25d280867572eee4e5},
}

@conference{gadd-newman:2016:7759843,
  author = {M. Gadd and P. Newman},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Checkout my map: Version control for fleetwide visual localisation},
  volume = {2016-November},
  pages = {5729--5736},
  doi = {10.1109/IROS.2016.7759843},
  note = {cited By 13; Conference of 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2016 ; Conference Date: 9 October 2016 Through 14 October 2016;  Conference Code:125056},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2016},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {This paper is about underpinning long-term operations of fleets of vehicles using visual localisation. In particular it examines ways in which vehicles, considered as independent agents, can share, update and leverage each others' visual experiences in a mutually beneficial way. We draw on our previous work in Experience-based Navigation (EBN) [1], in which a visual map supporting multiple representations of the same place is built, yielding real-time localisation capability for a solitary vehicle. We now consider how any number of such agents might operate in concert via data sharing policies that are germane to the shared task of lifelong localisation. We rapidly construct considerable maps by the conjoining of work distributed to asynchronous processes, and share expertise amongst the team by the selective dispensing of mission-specific map contents. We demonstrate and evaluate our system against 100km of data collected in North Oxford over a period of a month featuring diverse deviation in appearance due to atmospheric, lighting, and structural dynamics. We show that our framework is capable of creating maps in a fraction of the time required by single-agent EBN, with no significant loss in localisation robustness, and is able to furnish robots on realworld forays with maps which require much less storage. © 2016 IEEE.},
  affiliation = {Mobile Robotics Group, University of Oxford, Oxford, United Kingdom},
  art_number = {7759843},
  coden = {85RBA},
  document_type = {Conference Paper},
  funding_details = {Engineering and Physical Sciences Research CouncilEngineering and Physical Sciences Research Council, EPSRC, EP/I005021/1, EP/M019918/1},
  isbn = {9781509037629},
  issn = {21530858},
  keywords = {Digital storage;  Intelligent robots;  Robots;  Structural dynamics;  Vehicles, Data Sharing;  Independent agents;  Localisation;  Multiple representation;  Real-world;  Single-agent;  Version control;  Visual experiences, Visual servoing},
  language = {English},
  references = {Churchill, W., Newman, P., Experience-based navigation for longterm localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International Conference on, pp. 1156-1163. , IEEE; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1643-1649. , IEEE; Pepperell, E., Corke, P., Milford, M., (2015) Automatic Image Scaling for Place Recognition in Changing Environments; Churchill, W., Newman, P., Continually improving large scale long term visual navigation of a vehicle in dynamic urban environments (2012) Intelligent Transportation Systems (ITSC), 2012 15th International IEEE Conference on, pp. 1371-1376. , IEEE; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) Proc. IEEE International Conference on Robotics and Automation (ICRA2015); Wingerd, L., (2005) Practical Perforce, , O'Reilly Media, Inc; Cieslewski, T., Lynen, S., Dymczyk, M., Magnenat, S., Siegwart, R., Map api-scalable decentralized map building for robots (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 6241-6247. , IEEE; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired slam system (2010) The International Journal of Robotics Research, 29 (9), pp. 1131-1153; Paul, R., Rus, D., Newman, P., How was your day? Online visual workspace summaries using incremental clustering in topic space (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4058-4065. , IEEE; Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The GIST of maps - Summarising experiences for life-long localisation (2015) Proc. IEEE International Conference on Robotics and Automation (ICRA2015); Bahr, A., Walter, M.R., Leonard, J.J., Consistent cooperative localization (2009) Robotics and Automation, 2009. ICRA'09. IEEE International Conference on, pp. 3415-3422. , IEEE; Bailey, T., Bryson, M., Mu, H., Vial, J., McCalman, L., Durrant-Whyte, H., Decentralised cooperative localisation for heterogeneous teams of mobile robots (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 2859-2865. , IEEE; Cunningham, A., Wurm, K.M., Burgard, W., Dellaert, F., Fully distributed scalable smoothing and mapping with robust multi-robot data association (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1093-1100. , IEEE; Maddern, W., Pascoe, G., Newman, P., Leveraging experience for large-scale LIDAR localisation in changing cities (2015) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), , Seattle, WA, USA, May; Nistér, D., Naroditsky, O., Bergen, J., Visual odometry (2004) Computer Vision and Pattern Recognition, 2004. CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on, 1, pp. I-652. , IEEE; Glover, A., Maddern, W., Warren, M., Reid, S., Milford, M., Wyeth, G., Openfabmap: An open source toolbox for appearancebased loop closure detection (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4730-4735. , IEEE; Leach, P.J., Mealling, M., Salz, R., (2005) A Universally Unique Identifier (uuid) Urn Namespace; Nagel, W., (2005) Subversion Version Control: Using the Subversion Version Control System in Development Projects, , Prentice Hall PTR; Stormo, G.D., Schneider, T.D., Gold, L., Ehrenfeucht, A., Use of the perceptronalgorithm to distinguish translational initiation sites in e. Coli (1982) Nucleic Acids Research, 10 (9), pp. 2997-3011; McManus, C., Churchill, W., Maddern, W., Stewart, A.D., Newman, P., Shady dealings: Robust, long-term visual localisation using illumination invariance (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference on, pp. 901-906. , IEEE; Aragues, R., Cortes, J., Sagues, C., Distributed consensus on robot networks for dynamically merging feature-based maps (2012) IEEE Transactions on Robotics, 28 (4), pp. 840-854},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006365185&doi=10.1109%2fIROS.2016.7759843&partnerID=40&md5=cba5c4d812c08ce91767c008220cf366},
}

@article{labbé-michaud:2019:21831,
  author = {M. Labbé and F. Michaud},
  journal = {Journal of Field Robotics},
  title = {RTAB-Map as an open-source lidar and visual simultaneous localization and mapping library for large-scale and long-term online operation},
  volume = {36},
  number = {2},
  pages = {416--446},
  doi = {10.1002/rob.21831},
  note = {cited By 228},
  publisher = {John Wiley and Sons Inc.},
  year = {2019},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {Distributed as an open-source library since 2013, real-time appearance-based mapping (RTAB-Map) started as an appearance-based loop closure detection approach with memory management to deal with large-scale and long-term online operation. It then grew to implement simultaneous localization and mapping (SLAM) on various robots and mobile platforms. As each application brings its own set of constraints on sensors, processing capabilities, and locomotion, it raises the question of which SLAM approach is the most appropriate to use in terms of cost, accuracy, computation power, and ease of integration. Since most of SLAM approaches are either visual- or lidar-based, comparison is difficult. Therefore, we decided to extend RTAB-Map to support both visual and lidar SLAM, providing in one package a tool allowing users to implement and compare a variety of 3D and 2D solutions for a wide range of applications with different robots and sensors. This paper presents this extended version of RTAB-Map and its use in comparing, both quantitatively and qualitatively, a large selection of popular real-world datasets (e.g., KITTI, EuRoC, TUM RGB-D, MIT Stata Center on PR2 robot), outlining strengths, and limitations of visual and lidar SLAM configurations from a practical perspective for autonomous navigation applications. © 2018 Wiley Periodicals, Inc.},
  affiliation = {Department of Electrical Engineering and Computer Engineering, Interdisciplinary Institute of Technological Innovation (3IT), Université de Sherbrooke, Sherbrooke, QC, Canada},
  author_keywords = {perception;  position estimation;  SLAM},
  correspondence_address1 = {Labbé, M.; Department of Electrical Engineering and Computer Engineering, Canada; email: Mathieu.M.Labbe@USherbrooke.ca},
  document_type = {Article},
  funding_details = {Natural Sciences and Engineering Research Council of CanadaNatural Sciences and Engineering Research Council of Canada, NSERC},
  funding_text1 = {This study was supported by the Natural Sciences and Engineering},
  funding_text2 = {This study was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC).},
  issn = {15564959},
  keywords = {Mapping;  Optical radar;  Robots;  Sensory perception, Autonomous navigation;  Open-source libraries;  Position estimation;  Processing capability;  Real-world datasets;  Simultaneous localization and mapping;  SLAM;  Visual simultaneous localization and mappings, Robotics},
  language = {English},
  references = {Barsan, I.A., Liu, P., Pollefeys, M., Geiger, A., (2018) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), Brisbane, Australia, , May)., Robust dense mapping for large-scale dynamic environments; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., Speeded up robust features (SURF) (2008) Computer Vision and Image Understanding, 110 (3), pp. 346-359; Besl, P.J., McKay, N.D., Method for registration of 3-D shapes (1992) Robotics-DL Tentative, 1611, pp. 586-606; Bosse, M., Zlot, R., Map matching and data association for large-scale two-dimensional laser scan-based SLAM (2008) International Journal of Robotics Research, 27 (6), pp. 667-691; Bradski, G., Kaehler, A., (2008) Learning OpenCV: Computer vision with the OpenCV library, , Sebastopol, CA O’Reilly Media, Inc; Burhanpurkar, M., Labbé, M., Guan, C., Michaud, F., Kelly, J., Cheap or robust? The practical realization of self-driving wheelchair technology (2017) Proceedings of International Conference on Rehabilitation Robotics, pp. 1079-1086. , July)., London, UK; Burri, M., Nikolic, J., Gohl, P., Schneider, T., Rehder, J., Omari, S., Siegwart, R., The EuRoC micro aerial vehicle datasets (2016) The International Journal of Robotics Research, 35 (10), pp. 1157-1163; Calonder, M., Lepetit, V., Strecha, C., Fua, P., Brief: Binary robust independent elementary features (2010) Proceedings of the European Conference on Computer Vision (ECCV), Heraklion, Crete, Greece, , Sept); Carlone, L., Aragues, R., Castellanos, J.A., Bona, B., A linear approximation for graph-based simultaneous localization and mapping (2012) Robotics: Science and Systems VII, pp. 41-48; Chen, Y., Wu, F., Wang, N., Tang, K., Cheng, M., Chen, X., KeJia-LC: A low-cost mobile robot platform—Champion of demo challenge on benchmarking service robots at RoboCup 2015. In L. Almeida, J. Ji, G. Steinbauer, & S. Luke (Eds.) (2015) Robot World Cup XIX. RoboCup 2015. Lecture Notes in Computer Science, pp. 60-71. , (Vol 9513,). Cham Springer; Cvišić, I., Ćesić, J., Marković, I., Petrović, I., Soft-slam: Computationally efficient stereo visual simultaneous localization and mapping for autonomous unmanned aerial vehicles (2018) Journal of Field Robotics, 35 (4), pp. 578-595; Dai, A., Nießner, M., Zollöfer, M., Izadi, S., Theobalt, C., Bundlefusion: Real-time globally consistent 3D reconstruction using on-the-fly surface re-integration (2017) ACM Transactions on Graphics, 36 (3), pp. 1-18; Della Corte, B., Bogoslavskyi, I., Stachniss, C., Grisetti, G., (2017) A general framework for flexible multi-cue photometric point cloud registration, , https://arxiv.org/abs/1709.05945, Retrieved from; (2012), Dellaert F. (, Factor graphs and GTSAM A hands-on introduction, (Technical Report GT-RIM-CP&R-2012-002). Georgia Institute of Technology; Dubé, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., (2016) Segmatch: Segment based loop-closure for 3D point clouds, , https://arxiv.org/abs/1609.07720, Retrieved from; Dubé, R., Gawel, A., Sommer, H., Nieto, J., Siegwart, R., Cadena, C., An online multi-robot slam system for 3D lidars (2017) Proceedings IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1004-1011. , Vancouver, BC, Canada; Endres, F., Hess, J., Sturm, J., Cremers, D., Burgard, W., 3-D mapping with an RGB-D camera (2014) IEEE Transactions on Robotics, 30 (1), pp. 177-187; (2014), Engel, J. Schöps, T. Cremers D. (, Sept)., LSD-SLAM Large-scale direct monocular SLAM, Proceedings of the European Conference on Computer Vision, Zurich, Switzerland, 834–849; Engel, J., Stückler, J., Cremers, D., Large-scale direct SLAM with stereo cameras (2015) Proceedings IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1935-1942. , Sept)., Hamburg, Germany; Fallon, M., Johannsson, H., Kaess, M., Leonard, J.J., The MIT stata center dataset (2013) The International Journal of Robotics Research, 32 (14), pp. 1695-1699; Foote, T., (2013) Proceedings IEEE International Conference on Technologies for Practical Robot Applications, Open-Source Software workshop, pp. 1-6. , April)., tf The transform library, Woburn, MA; Foresti, H., Finch, G., Cavalcanti, L., Alves, F., Lacerda, D., Brito, R., Teixeira, J.M., (2016) Emotive robotics with I-Zak, , http://www.robocup2016.org/media/symposium/Team-Description-Papers/AtHome/RoboCup_2016_AtHome_TDP_CESAR_VOXAR_LABS.pdf, Retrieved from; Forster, C., Pizzoli, M., Scaramuzza, D., (2014) Proceedings IEEE International Conference on Robotics and Automation, Hong Kong, China, , May)., SVO Fast semi-direct monocular visual odometry; Fox, D., Burgard, W., Dellaert, F., Thrun, S., (1999) Proceedings National Conference on Artificial Intelligence and Innovative Applications of Artificial Intelligence, pp. 343-349. , July)., Monte Carlo localization Efficient position estimation for mobile robots, Orlando, FL; Fuentes-Pacheco, J., Ruiz-Ascencio, J., Rendón-Mancha, J.M., Visual simultaneous localization and mapping: A survey (2015) Artificial Intelligence Review, 43 (1), pp. 55-81; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Geiger, A., Lenz, P., Urtasun, R., (2012), pp. 3354-3361. , June)., Are we ready for autonomous driving? The KITTI vision benchmark suite, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, Providence, RI; Geiger, A., Ziegler, J., Stiller, C., (2011) Proceedings Intelligent Vehicles Symposium, Baden-Baden, Germany, , June)., StereoScan Dense 3D reconstruction in real-time; Goebel, P., (2014), https://www.meetup.com/SV-ROS-users/pages/17825242/Winning_the_IROS2014_Microsoft_Connect_Challenge/, Winning the IROS 2014 Microsoft Kinect Challenge, Retrieved from; Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based SLAM (2010) IEEE Intelligent Transportation Systems Magazine, 2 (4), pp. 31-43; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with Rao-Blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Gutierrez-Gomez, D., Mayol-Cuevas, W., Guerrero, J.J., Dense RGB-D visual odometry using inverse depth (2016) Robotics and Autonomous Systems, 75, pp. 571-583; Harmat, A., Trentini, M., Sharf, I., Multi-camera tracking and mapping for unmanned aerial vehicles in unstructured environments (2015) Journal of Intelligent and Robotic Systems, 78 (2), pp. 291-317; Herrera, C.D., Kim, K., Kannala, J., Pulli, K., Heikkilä, J., DT-SLAM: Deferred triangulation for robust SLAM (2014) Proceedings IEEE International Conference on 3D Vision, 1, pp. 609-616. , Dec)., Tokyo, Japan; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2D LIDAR SLAM (2016) Proceedingz IEEE International Conference on Robotics and Automation, pp. 1271-1278. , May)., Stockholm, Sweden; Hornung, A., Wurm, K.M., Bennewitz, M., Stachniss, C., Burgard, W., Octomap: An efficient probabilistic 3D mapping framework based on octrees (2013) Autonomous Robots, 34 (3), pp. 189-206; Huang, A.S., Bachrach, A., Henry, P., Krainin, M., Maturana, D., Fox, D., Roy, N., (2011) Proceedings International Symposium on Robotics Research, Flagstaff, AZ, , Dec)., Visual odometry and mapping for autonomous flight using an RGB-D camera; Kähler, O., Prisacariu, V.A., Murray, D.W., (2016) Proceedings of European Conference on Computer Vision, pp. 500-516. , Oct)., Real-time large-scale dense 3D reconstruction with loop closure, Amsterdam, The Netherlands; Kerl, C., Sturm, J., Cremers, D., (2013) Proceedings IEEE/RSJ International Conference on Intelligent Robots and Systems, Tokyo, Japan, pp. 2100-2106. , Nov)., Dense visual SLAM for RGB-D cameras; (2000), Klein, G., Murray, D. (, Parallel tracking and mapping for small AR workspaces, Proceedings of IEEE and ACM International Symposium on Mixed and Augmented Reality, Nara, Japan; Kohlbrecher, S., Meyer, J., vonStryk, O., Klingauf, U., (2011), A flexible and scalable SLAM system with full 3D motion estimation, Proceedings IEEE International Symposium on Safety, Security and Rescue Robotics, Kyoto, Japan; Kohlbrecher, S., Rose, C., Koert, D., Manns, P., Kunz, F., Wartusch, B., vonStryk, O., RoboCup Rescue 2016 team description paper Hector Darmstadt (2016) (Technical Report). Technische Universitaet Darmstadt; Konolige, K., Small vision systems: Hardware and implementation (1998) Robotics Research, pp. 203-212. , In Y. Shirai, S. Hirose (Eds.),,). London, UK, Springer; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., (2011) Proceedings of IEEE International Conference on Robotics and Automation, pp. 3607-3613. , May)., g2o A general framework for graph optimization, Shanghai, China; Labbé, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745; Labbé, M., Michaud, F., (2014) Proceedings IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2661-2666. , &, Sept)., Online global loop closure detection for large-scale multi-session graph-gased SLAM, Chicago, IL; Labbé, M., Michaud, F., (2017) Autonomous Robots., , &, Long-term online multi-session graph-based splam with memory management; Laniel, S., Létourneau, D., Labbé, M., Grondin, F., Polgar, J., Michaud, F., (2017) Proceedings International Conference on Rehabilitation Robotics, pp. 809-811. , July)., Adding navigation, artificial audition and vital sign monitoring capabilities to a telepresence mobile robot for remote home care applications, London, UK; Leutenegger, S., Lynen, S., Bosse, M., Siegwart, R., Furgale, P., Keyframe-based visual-inertial odometry using nonlinear optimization (2015) The International Journal of Robotics Research, 34 (3), pp. 314-334; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Lucas, B.D., Kanade, T., An iterative image registration technique with an application to stereo vision (1981) Proceedings International Joint Conference on Artificial Intelligence, pp. 674-679. , Canada, Vancouver, BC; Marder-Eppstein, E., Berger, E., Foote, T., Gerkey, B., Konolige, K., (2010) Proceedings IEEE International Conference on Robotics and Automation, pp. 300-307. , May)., The Office Marathon Robust navigation in an indoor office environment, Anchorage, AK; (2014), Moore, T. Stouch, D. (, July), A generalized extended Kalman filter implementation for the robot operating system, Proceedings International Conference on Intelligent Autonomous Systems. Shanghai, China; Muja, M., Lowe, D.G., (2009) Proceedings International Conference on Computer Vision Theory and Application, pp. 331-340. , &, Feb)., Fast approximate nearest neighbors with automatic algorithm configuration, Lisboa, Portugal; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163; Mur-Artal, R., Tardós, J.D., ORB-SLAM2: An open-source SLAM system for monocular, stereo and RGB-D cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Pire, T., Fischer, T., Castro, G., DeCristóforis, P., Civera, J., JacoboBerlles, J., S-PTAM: Stereo parallel tracking and mapping (2017) Robotics and Autonomous Systems, 93, pp. 27-42; Pizzoli, M., Forster, C., Scaramuzza, D., (2014) Proceedings IEEE International Conference on Robotics and Automation, Hong Kong, China, , June)., REMODE Probabilistic, monocular dense reconstruction in real time; Pomerleau, F., Colas, F., Siegwart, R., Magnenat, S., Comparing ICP variants on real-world data sets (2013) Autonomous Robots, 34 (3), pp. 133-148; Quigley, M., Gerkey, B., Conley, K., Faust, J., Foote, T., Leibs, J., Ng, A., (2009) Proceedings of the IEEE International Conference on Robotics and Automation, Kobe, Japan, , May)., ROS An open-source robot operating system; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., (2011) Proceedings IEEE International Conference on Computer Vision, pp. 2564-2571. , Nov)., ORB An efficient alternative to SIFT or SURF, Barcelona, Spain; Rusu, R.B., Cousins, S., (2011) Proceedings IEEE International Conference on Robotics and Automation, pp. 1-4. , &, May)., 3D is here Point Cloud Library (PCL), Shanghai, China; Scaramuzza, D., Fraundorfer, F., Visual odometry [tutorial] (2011) IEEE Robotics and Automation Magazine, 18 (4), pp. 80-92; Schlegel, D., Colosi, M., Grisetti, G., (2017) ProSLAM: Graph SLAM from a programmer’s perspective, , https://arxiv.org/abs/1709.04377, Retrieved from; Schneider, T., Dymczyk, M., Fehr, M., Egger, K., Lynen, S., Gilitschenski, I., Siegwart, R., maplab: An open framework for research in visual-inertial mapping and localization (2018) IEEE Robotics and Automation Letters, 3 (3), pp. 1418-1425; Shi, J., (1994) Proceedings IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 593-600. , June)., Good features to track, Seattle, WA; (2003), Sivic, J. Zisserman, A., Video Google A text retrieval approach to object matching in videos, Proceedings International Conference on Computer Vision, 1470–1478. Nice, France; Stachniss, C., Leonard, J.J., Thrun, S., Simultaneous localization and mapping (2016) Springer Handbook of Robotics, pp. 1153-1176. , In B. SicilianoO. Khatib (Eds.),,). Cham Springer; Steux, B., El Hamzaoui, O., (2010) Proceedings IEEE International Conference on Control Automation Robotics & Vision, pp. 1975-1979. , &, Dec)., tinySLAM A SLAM algorithm in less than 200 lines C-language program, Singapore; Sturm, J., Engelhard, N., Endres, F., Burgard, W., Cremers, D., (2012) Proceedings IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 573-580. , Oct)., A benchmark for the evaluation of RGB-D SLAM systems, Vilamoura, Portugal; Sun, K., Mohta, K., Pfrommer, B., Watterson, M., Liu, S., Mulgaonkar, Y., Kumar, V., Robust stereo visual inertial odometry for fast autonomous flight (2018) IEEE Robotics and Automation Letters, 3 (2), pp. 965-972; Thrun, S., Robotic mapping: A survey (2002) Exploring artificial intelligence in the new millennium, 1, pp. 1-35. , In G. Lakemeyer & B. Nebel (Eds.),,). San Francisco, CA, Morgan Kaufmann Publishers Inc; Vincent, R., Limketkai, B., Eriksen, M., Comparison of indoor robot localization techniques in the absence of GPS (2010) Detection and Sensing of Mines, Explosive Objects, and Obscured Targets XV, 7664, p. 1Z; Whelan, T., Kaess, M., Johannsson, H., Fallon, M., Leonard, J.J., McDonald, J., Real-time large-scale dense RGB-D SLAM with volumetric fusion (2015) The International Journal of Robotics Research, 34 (4-5), pp. 598-626; Whelan, T., Salas-Moreno, R.F., Glocker, B., Davison, A.J., Leutenegger, S., ElasticFusion: Real-time dense SLAM and light source estimation (2016) The International Journal of Robotics Research, 35 (14), pp. 1697-1716; Xu, W., Mulligan, J., Performance evaluation of color correction approaches for automatic multi-view image and video stitching (2010) Proceedings IEEE Conference on Computer Vision and Pattern Recognition, pp. 263-270. , &, June)., San Francisco, CA; Yi, L., Fei, G., Tong, Q., Wenliang, G., Tianbo, L., William, W., Shaojie, S., Autonomous aerial navigation using monocular visual-inertial fusion (2017) Journal of Field Robotics, 35 (1), pp. 23-51; Zhang, J., Singh, S., Low-drift and real-time lidar odometry and mapping (2017) Autonomous Robots, 41 (2), pp. 401-416; Zollhöfer, M., Stotko, P., Görlitz, A., Theobalt, C., Nießner, M., Klein, R., Kolb, A., State of the art on 3D reconstruction with RGB-D cameras (2018) Computer Graphics Forum, 37 (2), pp. 625-652},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055707168&doi=10.1002%2frob.21831&partnerID=40&md5=7375b4295b7a885075c4b065b7997993},
}

@article{mazuran-et-al:2016:0278364915581629,
  author = {M. Mazuran and W. Burgard and G. D. Tipaldi},
  journal = {International Journal of Robotics Research},
  title = {Nonlinear factor recovery for long-term SLAM},
  volume = {35},
  number = {1-3},
  pages = {50--72},
  doi = {10.1177/0278364915581629},
  note = {cited By 35},
  publisher = {SAGE Publications Inc.},
  year = {2016},
  abbrev_source_title = {Int J Rob Res},
  abstract = {For long-term operations, graph-based simultaneous localization and mapping (SLAM) approaches require nodes to be marginalized in order to control the computational cost. In this paper, we present a method to recover a set of nonlinear factors that best represents the marginal distribution in terms of Kullback-Leibler divergence. The proposed method, which we call nonlinear factor recovery (NFR), estimates both the mean and the information matrix of the set of nonlinear factors, where the recovery of the latter is equivalent to solving a convex optimization problem. NFR is able to provide either the dense distribution or a sparse approximation of it. In contrast to previous algorithms, our method does not necessarily require a global linearization point and can be used with any nonlinear measurement function. Moreover, we are not restricted to only using tree-based sparse approximations and binary factors, but we can include any topology and correlations between measurements. Experiments performed on several publicly available datasets demonstrate that our method outperforms the state of the art with respect to the Kullback-Leibler divergence and the sparsity of the solution. © The Author(s) 2015.},
  affiliation = {Department of Computer Science, University of Freiburg, Georges-Koehler-Allee 79, Freiburg, 79110, Germany},
  author_keywords = {graphical models;  localization;  mapping;  Mobile robotics;  nonlinear optimization;  SLAM},
  coden = {IJRRE},
  correspondence_address1 = {Mazuran, M.; Department of Computer Science, Georges-Koehler-Allee 79, Germany; email: mazuran@informatik.uni-freiburg.de},
  document_type = {Article},
  funding_details = {European CommissionEuropean Commission, EC, ERC-AG-PE7-267686-LIFENAV, FP7-610603-EUROPA2},
  funding_text1 = {This work has been partially been supported by the European Commission (grant numbers ERC-AG-PE7-267686-LIFENAV and FP7-610603-EUROPA2).},
  issn = {02783649},
  keywords = {Binary trees;  Convex optimization;  Graphic methods;  Mapping;  Nonlinear programming;  Optimization;  Recovery, GraphicaL model;  localization;  Mobile robotic;  Non-linear optimization;  SLAM, Robotics},
  language = {English},
  references = {Banerjee, O., Ghaoui, L.E., D'Aspremont, A., Natsoulis, G., Convex optimization techniques for fitting sparse Gaussian graphical models (2006) Proceedings of the International Conference on Machine Learning; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., Distributed optimization and statistical learning via the alternating direction method of multipliers (2011) Foundations and Trends in Machine Learning, 3 (1), pp. 1-122; Boyd, S., Vandenberghe, L., (2009) Convex Optimization, , Cambridge: Cambridge University Press; Carlevaris-Bianco, N., Eustice, R., Long-term simultaneous localization and mapping with generic linear constraint node removal (2013) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph SLAM (2013) Proceedings of the IEEE International Conference on Robotics and Automation; Carlevaris-Bianco, N., Eustice, R.M., Conservative edge sparsification for graph SLAM node removal (2014) Proceedings of the IEEE International Conference on Robotics and Automation; Carlevaris-Bianco, N., Kaess, M., Eustice, R.M., Generic node removal for factor-graph SLAM (2014) IEEE Transactions on Robotics; Chow, C.I., Liu, C.N., Approximating discrete probability distributions with dependence trees (1968) IEEE Transactions on Information Theory, 14, pp. 462-467; Dellaert, F., Kaess, M., Square Root SAM: Simultaneous localization and mapping via square root information smoothing (2006) The International Journal of Robotics Research, 25 (12), pp. 1181-1204; Duchi, J.C., Gould, S., Koller, D., Projected subgradient methods for learning sparse gaussians (2008) Proceedings of the Conference in Uncertainty in Artificial Intelligence; Eade, E., Fong, P., Munich, M.E., Monocular graph SLAM with complexity reduction (2010) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems; Eustice, R., Walter, M., Leonard, J., Sparse extended information filters: Insights into sparsification (2005) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems; Folkesson, J., Christensen, H., Graphical SLAM - A self-correcting map (2004) Proceedings of the IEEE International Conference on Robotics and Automation, Volume, 1; Frese, U., Treemap: An O(log n) algorithm for indoor simultaneous localization and mapping (2006) Autonomous Robots, 21 (2), pp. 103-122; Frese, U., Efficient 6-dof SLAM with treemap as a generic backend (2007) Proceedings of the IEEE International Conference on Robotics and Automation; Friedman, J., Hastie, T., Tibshirani, R., Sparse inverse covariance estimation with the graphical lasso (2008) Biostatistics, 9 (3), pp. 432-441; Golub, G.H., Van Loan, C.F., (1996) Matrix Computations, , 3rd edition. Baltimore, MD: Johns Hopkins University Press; Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based SLAM (2010) IEEE Transactions on Intelligent Transportation Systems Magazine, 2, pp. 31-43; Grisetti, G., Stachniss, C., Grzonka, S., Burgard, W., A tree parameterization for efficiently computing maximum likelihood maps using gradient descent (2007) Proceedings of Robotics: Science and Systems; Higham, N.J., Computing a nearest symmetric positive semidefinite matrix (1988) Linear Algebra and Its Applications, 103, pp. 103-118; Huang, G., Kaess, M., Leonard, J.J., Consistent sparsification for graph optimization (2013) Proceedings of the European Conference on Mobile Robots; Huang, S., Wang, Z., Dissanayake, G., Frese, U., Iterated D-SLAM map joining: Evaluating its performance in terms of consistency, accuracy and efficiency (2009) Autonomous Robots, 27 (4), pp. 409-429; Ila, V., Porta, J.M., Andrade-Cetto, J., Information-based compact pose SLAM (2010) IEEE Transactions on Robotics, 26 (1), pp. 78-93; Johannsson, H., Kaess, M., Fallon, M., Leonard, J., Temporally scalable visual SLAM using a reduced pose graph (2013) Proceedings of the IEEE International Conference on Robotics and Automation; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Fast incremental smoothing and mapping with efficient data association (2007) Proceedings of the IEEE International Conference on Robotics and Automation; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based SLAM (2012) The International Journal of Robotics Research, 31 (11), pp. 1219-1230; Kretzschmar, H., Stachniss, C., Grisetti, G., Efficient information-theoretic graph pruning for graph-based SLAM with laser range finders (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proceedings of the IEEE International Conference on Robotics and Automation; Mazuran, M., Tipaldi, G.D., Spinello, L., Burgard, W., Nonlinear graph sparsification for SLAM (2014) Proceedings of Robotics: Science and Systems; Nocedal, J., Updating quasi-Newton matrices with limited storage (1980) Mathematics of Computation, 35 (151), pp. 773-782; Olson, E., Leonard, J., Teller, S., Fast iterative alignment of pose graphs with poor initial estimates (2006) Proceedings of the IEEE International Conference on Robotics and Automation; Paskin, M.A., Thin junction tree filters for simultaneous localization and mapping (2003) Proceedings of the International Joint Conference on Artificial Intelligence; Schmidt, M., Van Den Berg, E., Friedlander, M.P., Murphy, K., Optimizing costly functions with simple constraints: A limited-memory projected quasi-Newton algorithm (2009) Proceedings of the International Conference on Artificial Intelligence and Statistics; Thrun, S., Liu, Y., Koller, D., Ng, A.Y., Ghahramani, Z., Durrant-Whyte, H., Simultaneous localization and mapping with sparse extended information filters (2004) The International Journal of Robotics Research, 23 (7), pp. 693-716. , (- 8); Vandenberghe, L., Boyd, S., Wu, S.P., Determinant maximization with linear matrix inequality constraints (1998) SIAM Journal on Matrix Analysis and Applications, 19 (2), pp. 499-533; Vial, J., Durrant-Whyte, H., Bailey, T., Conservative sparsification for efficient and consistent approximate estimation (2011) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953331595&doi=10.1177%2f0278364915581629&partnerID=40&md5=fe8ccca02738b5c5b3603d3096498578},
}

@conference{mohan-et-al:2015:7139966,
  author = {M. Mohan and D. Galvez-Lopez and C. Monteleoni and G. Sibley},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Environment selection and hierarchical place recognition},
  volume = {2015-June},
  number = {June},
  pages = {5487--5494},
  doi = {10.1109/ICRA.2015.7139966},
  note = {cited By 15; Conference of 2015 IEEE International Conference on Robotics and Automation, ICRA 2015 ; Conference Date: 26 May 2015 Through 30 May 2015;  Conference Code:113196},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2015},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {As robots continue to create long-term maps, the amount of information that they need to handle increases over time. In terms of place recognition, this implies that the number of images being considered may increase until exceeding the computational resources of the robot. In this paper we consider a scenario where, given multiple independent large maps, possibly from different cities or locations, a robot must effectively and in real time decide whether it can localize itself in one of those known maps. Since the number of images to be handled by such a system is likely to be extremely large, we find that it is beneficial to decompose the set of images into independent groups or environments. This raises a new question: Given a query image, how do we select the best environment? This paper proposes a similarity criterion that can be used to solve this problem. It is based on the observation that, if each environment is described in terms of its co-occurrent features, similarity between environments can be established by comparing their co-occurrence matrices. We show that this leads to a novel place recognition algorithm that divides the collection of images into environments and arranges them in a hierarchy of inverted indices. By selecting first the relevant environment for the operating robot, we can reduce the number of images to perform the actual loop detection, reducing the execution time while preserving the accuracy. The practicality of this approach is shown through experimental results on several large datasets covering a combined distance of more than 750Km. © 2015 IEEE.},
  affiliation = {Department of Computer Science, George Washington University, United States; Department of Computer Science, University of Colorado Boulder, United States},
  art_number = {7139966},
  coden = {PIIAE},
  document_type = {Conference Paper},
  isbn = {9781479969234},
  issn = {10504729},
  keywords = {Agricultural robots;  Robotics;  Robots, Amount of information;  Co-occurrence-matrix;  Computational resources;  Environment selection;  Inverted indices;  Loop detection;  Place recognition;  Similarity criteria, Large dataset},
  language = {English},
  references = {Nordlandsbanen: minute by minute, season by season, January 2013; Blanco, J., Moreno, F., González, J., A collection of outdoor robotic datasets with centimeter-accuracy ground truth (2009) Autonomous Robots, 27 (4), pp. 327-351. , November; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Cummins, M., Newman, P., Appearance-only slam at large scale with fab-map 2. 0 (2010) The International Journal of Robotics Research, , November; Doersch, C., Singh, S., Gupta, A., Sivic, J., Efros, A.A., What makes Paris look like Paris (2012) ACM Transactions on Graphics (SIGGRAPH), 31 (4); Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197. , October; Gärtner, T., Flach, P., Wrobel, S., On graph kernels: Hardness results and efficient alternatives (2003) Learning Theory and Kernel Machines, pp. 129-143. , Springer; Glover, A., Maddern, W., Milford, M., Wyeth, G., FAB-MAP + RatSLAM: Appearance-based SLAM for Multiple Times of Day (2010) IEEE International Conference on Robotics and Automation, , Anchorage, USA; Kashima, H., Tsuda, K., Inokuchi, A., Marginalized kernels between labeled graphs (2003) Proceedings of the Twentieth International Conference on Machine Learning, 3, pp. 321-328; Labbe, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745. , June; Lazebnik, S., Schmid, C., Ponce, J., Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories (2006) IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, pp. 2169-2178. , IEEE; MacTavish, K., Barfoot, T.D., Towards hierarchical place recognition for long-term autonomy (2014) IEEE International Conference on Robotics and Automation (ICRA) Workshop on Visual Place Recognition in Changing Environments, , May; Maohai, L., Lining, S., Qingcheng, H., Zesu, C., Songhao, P., Robust omnidirectional vision based mobile robot hierarchical localization and autonomous navigation (2011) Information Technology Journal, 10 (1), pp. 29-39. , January; Mei, C., Sibley, G., Newman, P., Closing loops without places (2010) International Conference on Intelligent Robots and Systems, , Taipei, Taiwan, October; Milford, M., Fraser Wyeth, G., SeqSLAM: Visual routebased navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation (ICRA), pp. 1643-1649. , IEEE; Morrison, J., Gálvez-López, D., Sibley, G., MOARSLAM: Multiple operator augmented rslam (2014) International Symposium on Distributed Autonomous Robotic Systems, , November. Accepted for publication; Murphy, L., Sibley, G., Incremental unsupervised topological place discovery (2014) IEEE International Conference on Robotics and Automation, , May; Nicosevici, T., Garcia, R., Automatic visual bag-of-words for online robot navigation and mapping (2012) IEEE Transactions on Robotics, 28 (4), pp. 886-898. , Aug; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree (2006) IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, pp. 2161-2168; Pandey, G., McBride, J.R., Eustice, R.M., Ford campus vision and lidar data set (2011) The International Journal of Robotics Research, 30 (13), pp. 1543-1552. , November; Rawseeds. Robotics Advancement through Web-publishing of Sensorial and Elaborated Extensive Data Sets (Project FP6-IST-045144)., 2007-2009; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003) IEEE International Conference on Computer Vision, pp. 1470-1477; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) The International Journal of Robotics Research, 28 (5), pp. 595-599. , May; Vishwanathan, S.V.N., Schraudolph, N.N., Kondor, R., Borgwardt, K.M., Graph kernels (2010) The Journal of Machine Learning Research, 11, pp. 1201-1242; Xiao, J., Ehinger, K.A., Hays, J., Torralba, A., Oliva, A., SUN Database: Exploring a large collection of scene categories (2014) International Journal of Computer Vision, pp. 1-20},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938263668&doi=10.1109%2fICRA.2015.7139966&partnerID=40&md5=59b92fe86c41ff1a95eff3fee8a498ff},
}

@inproceedings{rapp-et-al:2015:77,
  author = {M. Rapp and M. Hahn and M. Thom and K. J. A. D. Dickmann},
  booktitle = {2015 IEEE 18TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION
SYSTEMS},
  title = {Semi-Markov Process Based Localization using Radar in Dynamic
Environments},
  pages = {423--429},
  doi = {10.1109/ITSC.2015.77},
  note = {18th IEEE International Conference on Intelligent Transportation
Systems, SPAIN, SEP 15-18, 2015},
  publisher = {IEEE},
  address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
  year = {2015},
  abstract = {Automotive localization in urban environment faces natural long-term
changes of the surroundings. In this work, a robust Monte-Carlo based
localization is presented. Robustness is achieved through a stochastic
analysis of previous observations of the area of interest. The model
uses a grid-based Markov chain to instantly model changes. An extension
of this model by a Levy process allows statements about reliability and
prediction for each cell of the grid. Experiments with a vehicle
equipped with four short range radars show the localization accuracy
performance improvement in a dynamic environment.},
  affiliation = {Rapp, M (Corresponding Author), Univ Ulm, Inst Measurement Control \& Microtechnol, D-89069 Ulm, Germany.
Rapp, Matthias; Thom, Markus; Dietmayer, Klaus, Univ Ulm, Inst Measurement Control \& Microtechnol, D-89069 Ulm, Germany.
Hahn, Markus; Dickmann, Juergen, Daimler AG, Ulm, Germany.},
  affiliations = {Ulm University; Daimler AG},
  author-email = {matthias.rapp@uni-ulm.de
markus.hahn@daimler.de
markus.thom@uni-ulm.de
jurgen.dickmann@daimler.de
klaus.dietmayer@uni-ulm.de},
  book-group-author = {IEEE},
  cited-references = {Adams M, 2012, ROBOTIC NAVIGATION AND MAPPING WITH RADAR, P1.
Anguelov D., 2002, P 18 C UNC ART INT, P10.
Birk A, 2006, P IEEE, V94, P1384, DOI 10.1109/JPROC.2006.876965.
Bouzouraa ME, 2010, IEEE INT VEH SYM, P294, DOI 10.1109/IVS.2010.5548106.
Coue C, 2006, INT J ROBOT RES, V25, P19, DOI 10.1177/0278364906061158.
Fink D., 1997, COMPENDIUM CONJUGATE.
Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
Luber Matthias, 2011, INT J ROBOTICS RES.
MEDHI J, 1983, STOCHASTIC PROCESSES.
Meyer-Delius D., 2012, AAAI.
Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
Montemerlo M, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2436.
Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
Morris Timothy, 2014, IEEE INT C ROB AUT 2.
Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
Rapp Matthias, 2015, INT VEH S.
Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
Schreier M, 2014, IEEE INT CONF ROBOT, P3995, DOI 10.1109/ICRA.2014.6907439.
Shephard N, 2012, BASICS LEVY PROCESSE.
Thrun S., 2005, PROBABILISTIC ROBOTI.
Werber Klaudius, 2015, 2015 IEEE MTTS INT C.
Wolf DF, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P594.
Ziegler J, 2014, IEEE INTEL TRANSP SY, V6, P8, DOI 10.1109/MITS.2014.2306552.},
  da = {2022-05-17},
  doc-delivery-number = {BE8OT},
  isbn = {978-1-4673-6596-3},
  issn = {2153-0009},
  keywords-plus = {MAPS},
  language = {English},
  number-of-cited-references = {25},
  research-areas = {Transportation},
  series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
  times-cited = {11},
  type = {Proceedings Paper},
  unique-id = {WOS:000376668800070},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {1},
  web-of-science-categories = {Transportation Science \& Technology},
  web-of-science-index = {Conference Proceedings Citation Index - Science (CPCI-S)},
}

@conference{lázaro-et-al:2018:8594310,
  author = {M. T. Lázaro and R. Capobianco and G. Grisetti},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Efficient Long-term Mapping in Dynamic Environments},
  pages = {153--160},
  doi = {10.1109/IROS.2018.8594310},
  note = {cited By 16; Conference of 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018 ; Conference Date: 1 October 2018 Through 5 October 2018;  Conference Code:144267},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation. © 2018 IEEE.},
  affiliation = {Dipartimento di Ingegneria Informatica Automatica e Gestionale 'An-tonio Ruberti', Sapienza University of Rome, Italy},
  art_number = {8594310},
  coden = {85RBA},
  document_type = {Conference Paper},
  isbn = {9781538680940},
  issn = {21530858},
  keywords = {Intelligent robots;  Mapping;  Robotics, Dynamic environments;  Graph complexity;  Mapping problem;  Merging procedure;  Point cloud data;  Real world environments;  Robot operations;  Robotics research, Information management},
  language = {English},
  references = {Iocchi, L., Lázaro, M., Jeanpierre, L., Mouaddib, A.-I., Erdem, E., Sahli, H., Coaches: Cooperative autonomous robots in complex and human populated environments (2015) Congress of the Italian Association for Artificial Intelligence, pp. 465-477; Triebel, R., Arras, K., Alami, R., Beyer, L., Breuers, S., Chatila, R., Chetouani, M., Fiore, M., Spencer: A socially aware service robot for passenger guidance and help in busy airports (2016) Field and Service Robotics, pp. 607-622; Hanheide, M., Hebesberger, D., Krajnik, T., The when, where, and how: An adaptive robotic info-terminal for care home residents - A long-term study (2017) ACM/IEEE Int. Conf. on Human-Robot Interaction (HRI), , Vienna; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Kohlbrecher, S., Meyer, J., Von Stryk, O., Klingauf, U., A flexible and scalable slam system with full 3d motion estimation (2011) Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR), , Nov; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2d lidar slam (2016) IEEE Int. Conf. on Robotics and Automation, pp. 1271-1278; Grisetti, G., Kmmerle, R., Ni, K., Robust optimization of factor graphs by using condensed measurements (2012) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, Oct, pp. 581-588; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) IEEE Int. Conf. on Robotics and Automation, Shangai, China, May, pp. 3607-3613; Kaess, M., Ranganathan, A., Dellaert, F., Isam: Incremental smoothing and mapping (2008) IEEE Transactions on Robotics, 24 (6), pp. 1365-1378. , Dec; Latif, Y., Neira, J., Go straight, turn right: Pose graph reduction through trajectory segmentation using line segments (2013) European Conference on Mobile Robots, , Barcelona, Spain, Sept; Vallvé, J., Sol, J., Andrade-Cetto, J., Graph slam sparsification with populated topologies using factor descent optimization (2018) IEEE Robotics and Automation Letters, 3 (2), pp. 1322-1329; McDonald, J., Kaess, M., Lerma, C.D.C., Neira, J.L., Leonard, J.J., 6-dof multi-session visual slam using anchor nodes (2011) ECMR; Johannsson, H., Kaess, M., Fallon, M., Leonard, J.J., Temporally scalable visual slam using a reduced pose graph (2013) IEEE Int. Conf. on Robotics and Automation, pp. 54-61; Biswas, R., Limketkai, B., Sanner, S., Thrun, S., Towards object mapping in non-stationary environments with mobile robots (2002) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems; Wolf, D., Sukhatme, G.S., Online simultaneous localization and mapping in dynamic environments (2004) IEEE Int. Conf. on Robotics and Automation, 2, pp. 1301-1307; Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term slam, " the int (2009) Journal of Robotics Research, 28 (1), pp. 20-33; Krajník, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems; Labbé, M., Michaud, F., Online global loop closure detection for large-scale multi-session graph-based slam (2014) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, Sep, pp. 2661-2666; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph slam: Long-term mapping in low dynamic environments (2012) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, Oct, pp. 1871-1878; Serafin, J., Grisetti, G., Using extended measurements and scene merging for efficient and robust point cloud registration (2017) Robotics and Autonomous Systems, 92, pp. 91-106; Grisetti, G., Kummerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based slam (2010) IEEE Intelligent Transportation Systems Magazine, 2 (4), pp. 31-43; Lázaro, M., Paz, L., Piníes, P., Castellanos, J., Grisetti, G., Multirobot slam using condensed measurements (2013) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, Tokyo Big Sight, Japan, Nov; Fallon, M., Johannsson, H., Kaess, M., Leonard, J.J., The mit stata center dataset (2013) The Int. Journal of Robotics Research, 32 (14), pp. 1695-1699. , Dec; Burgard, W., Stachniss, C., Grisetti, G., Steder, B., Kmmerle, R., Dornhege, C., Ruhnke, M., Tards, J.D., A comparison of slam algorithms based on a graph of relations (2009) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, pp. 2089-2095. , Oct},
  source = {Scopus},
  sponsors = {Bosch; et al.; JD.Com; Kuka; PAL Robotics; Santander},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063005233&doi=10.1109%2fIROS.2018.8594310&partnerID=40&md5=84f88619fbe474b6f45e06effa5e5f36},
}

@conference{zhang-et-al:2019:8814347,
  author = {M. Zhang and Y. Chen and M. Li},
  journal = {Proceedings of the American Control Conference},
  title = {SDF-Loc: Signed distance Field based 2D relocalization and map update in dynamic environments},
  volume = {2019-July},
  pages = {1997--2004},
  doi = {10.23919/acc.2019.8814347},
  note = {cited By 6; Conference of 2019 American Control Conference, ACC 2019 ; Conference Date: 10 July 2019 Through 12 July 2019;  Conference Code:151322},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {Proc Am Control Conf},
  abstract = {To empower an autonomous robot to perform long-term navigation in a given area, a concurrent localization and map update algorithm is required. In this paper, we tackle this problem by providing both theoretical analysis and algorithm design for robotic systems equipped with 2D laser range finders. The first key contribution of this paper is that we propose a hybrid signed distance field (SDF) framework for laser based localization. The proposed hybrid SDF integrates two methods with complementary characteristics, namely Euclidean SDF (ESDF) and Truncated SDF (TSDF). With our framework, accurate pose estimation and fast map update can be performed simultaneously. Moreover, we introduce a novel sliding window estimator which attains better accuracy by consistently utilizing sensor and map information with both scan-to-scan and scan-to-map data association. Real-world experimental results demonstrate that the proposed algorithm can be used for commercial robots in various environments with long-term usage. Experiments also show that our approach outperforms competing approaches by a wide margin. © 2019 American Automatic Control Council.},
  affiliation = {Alibaba DAMO Academy AI Labs, Hangzhou, China},
  art_number = {8814347},
  coden = {PRACE},
  document_type = {Conference Paper},
  isbn = {9781538679265},
  issn = {07431619},
  language = {English},
  references = {Dellaert, F., Fox, D., Burgard, W., Thrun, S., Monte carlo localization for mobile robots (1999) IEEE International Conference on Robotics and Automation, Volume 2, 2, pp. 1322-1328; Hess, W., Kohler, D., Rapp, H., Andor, D., Realtime loop closure in 2d lidar SLAM (2016) IEEE International Conference on Robotics and Automation, pp. 1271-1278; Kohlbrecher, S., Von Stryk, O., Meyer, J., Klingauf, U., A flexible and scalable SLAM system with full 3d motion estimation (2011) IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR), pp. 155-160. , IEEE; Ruchti, P., Steder, B., Ruhnke, M., Burgard, W., Localization on Openstreet map data using a 3d laser scanner (2015) IEEE International Conference on Robotics and Automation, pp. 5260-5265; Schiotka, A., Suger, B., Burgard, W., Robot localization with sparse scan-based maps (2017) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 642-647; Meyer-Delius, D., Hess, J., Grisetti, G., Burgard, W., Temporary maps for robust localization in semi-static environments (2010) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 5750-5755; Fox, D., Burgard, W., Dellaert, F., Thrun, S., Monte carlo localization: Efficient position estimation for mobile robots (1999) AAAI/IAAI 1999, 343-349, p. 2; Hesch, J.A., Mirzaei, F.M., Mariottini, G.L., Roumeliotis, S.I., (2010) A Laser-aided Inertial Navigation System (L-ins) for Human Localization in Unknown Indoor Environments, pp. 5376-5382; Kallasi, F., Rizzini, D.L., Efficient loop closure based on FALKO lidar features for online robot localization and mapping (2016) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1206-1213. , Oct; Li, Y., Olson, E.B., Extracting general-purpose features from LIDAR data (2010) IEEE International Conference on Robotics and Automation, pp. 1388-1393. , May; Milstein, A., Occupancy grid maps for localization and mapping (2008) Motion Planning, , InTech; Fossel, J.-D., Tuyls, K., Sturm, J., 2d-sdf-slam: A signed distance function based slam frontend for laser scanners (2015) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1949-1955. , IEEE; Nicolai, A., Skeele, R., Eriksen, C., Hollinger, G.A., Deep learning for laser based odometry estimation (2016) RSS Workshop Limits and Potentials of Deep Learning in Robotics; Li, J., Zhan, H., Chen, B.M., Reid, I., Lee, G.H., Deep learning for 2d scan matching and loop closure (2017) IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 763-768. , Sept; Oleynikova, H., Millane, A., Taylor, Z., Galceran, E., Nieto, J., Siegwart, R., Signed distance fields: A natural representation for both mapping and planning (2016) RSS 2016 Workshop: Geometry and Beyond-Representations, Physics, and Scene Understanding for Robotics, , University of Michigan; Oleynikova, H., Taylor, Z., Fehr, M., Siegwart, R., Nieto, J., Voxblox: Incremental 3d Euclidean signed distance fields for on-board MAV planning (2017) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Zucker, M., Ratliff, N., Dragan, A.D., Pivtoraiko, M., Klingensmith, M., Dellin, C.M., Bagnell, J.A., Srinivasa, S.S., Chomp: Covariant hamiltonian optimization for motion planning (2013) The International Journal of Robotics Research, 32 (9-10), pp. 1164-1193; Lau, B., Sprunk, C., Burgard, W., Improved updating of euclidean distance maps and voronoi diagrams (2010) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 281-286; Jaimez, M., Monroy, J.G., Gonzalez-Jimenez, J., Planar odometry from a radial laser scanner. A range flow-based approach (2016) IEEE International Conference on Robotics and Automation (ICRA), pp. 4479-4485; Jaimez, M., Monroy, J., Lopez-Antequera, M., Gonzalez-Jimenez, J., Robust planar odometry based on symmetric range flow and multi-scan alignment (2018) IEEE Transactions on Robotics; Behl, A., Paschalidou, D., Donné, S., Geiger, A., (2018) Pointflownet: Learning Representations for 3d Scene Flow Estimation from Point Clouds, , arXiv preprint arXiv: 1806.02170; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Robotics: Science and Systems, pp. 17-24; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments (2012) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1871-1878; Krajník, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4558-4563; Krajník, T., Fentanes, J.P., Santos, J.M., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) IEEE Transactions on Robotics, 33 (4), pp. 964-977; Felzenszwalb, P.F., Huttenlocher, D.P., Distance transforms of sampled functions (2012) Theory of Computing, 8 (1), pp. 415-428; Dong-Si, T., Mourikis, A.I., Motion tracking with fixed-lag smoothing: Algorithm and consistency analysis (2011) IEEE International Conference on Robotics and Automation, pp. 5655-5662. , May; Li, M., Mourikis, A.I., High-precision, consistent Ekf-based visual-inertial odometry (2013) The International Journal of Robotics Research, 32 (6), pp. 690-711; Li, M., Yu, H., Zheng, X., Mourikis, A.I., High-fidelity sensor modeling and self-calibration in vision-aided inertial navigation (2014) IEEE International Conference on Robotics and Automation, pp. 409-416. , May; Bresenham, J.E., Algorithm for computer control of a digital plotter (1965) IBM Systems Journal, 4 (1), pp. 25-30; Klingensmith, M., Dryanovski, I., Srinivasa, S., Xiao, J., Chisel: Real time large scale 3d reconstruction onboard a mobile device using spatially hashed signed distance fields (2015) Robotics: Science and Systems, 4; Agarwal, S., Mierle, K., Ceres Solver, , http://ceres-solver.org, and Others; Fox, D., Kld-sampling: Adaptive particle filters (2002) Advances in Neural Information Processing Systems, pp. 713-720; Ros Implementation of Amcl, , http://wiki.ros.org/amcl; Kümmerle, R., Steder, B., Dornhege, C., Ruhnke, M., Grisetti, G., Stachniss, C., Kleiner, A., On measuring the accuracy of slam algorithms (2009) Autonomous Robots, 27 (4), p. 387},
  source = {Scopus},
  sponsors = {Boeing; et al.; GE Research; General Motors Co.; Mitsubishi Electric Research Laboratory (MERL); United Technologies Research Center (UTRC)},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072285847&doi=10.23919%2facc.2019.8814347&partnerID=40&md5=691a0c6bddc2e2f24a7b491b68e5bb87},
}

@article{carlevaris-bianco-et-al:2014:2347571,
  author = {N. Carlevaris-Bianco and M. Kaess and R. M. Eustice},
  journal = {IEEE Transactions on Robotics},
  title = {Generic node removal for factor-graph SLAM},
  volume = {30},
  number = {6},
  pages = {1371--1385},
  doi = {10.1109/TRO.2014.2347571},
  note = {cited By 59},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2014},
  abbrev_source_title = {IEEE Trans. Rob.},
  abstract = {This paper reports on a generic factor-based method for node removal in factor-graph simultaneous localization and mapping (SLAM),whichwe call generic linear constraints (GLCs). The need for a generic node removal tool is motivated by long-term SLAMapplications,whereby nodes are removed in order to control the computational cost of graph optimization. GLC is able to produce a new set of linearized factors over the elimination clique that can represent either the true marginalization (i.e., dense GLC) or a sparse approximation of the true marginalization using a Chow-Liu tree (i.e., parse GLC). The proposed algorithm improves upon commonly used methods in two key ways: First, it is not limited to graphs with strictly full-state relative-pose factors and works equally well with other low-rank factors, such as those produced by monocular vision. Second, the new factors are produced in such a way that accounts for measurement correlation, which is a problem encountered in other methods that rely strictly upon pairwise measurement composition. We evaluate the proposed method over multiple real-world SLAM graphs and show that it outperforms other recently proposed methods in terms of Kullback-Leibler divergence. Additionally, we experimentally demonstrate that the proposed GLC method provides a principled and flexible tool to control the computational complexity of long-term graph SLAM, with results shown for 34.9 h of real-world indoor-outdoor data covering 147.4 km collected over 27 mapping sessions spanning a period of 15 months. © 2014 IEEE. Personal.},
  affiliation = {Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI  48109-2145, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA  15213, United States; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI  48109-2145, United States},
  art_number = {6898876},
  author_keywords = {Factor-graphs;  Long-term autonomy;  Marginalization;  Mobile robotics;  Simultaneous localization and mapping (SLAM)},
  correspondence_address1 = {Carlevaris-Bianco, N.; Department of Electrical Engineering and Computer Science, University of MichiganUnited States},
  document_type = {Article},
  issn = {15523098},
  keywords = {Computational complexity;  Mapping;  Robotics, Factor-graphs;  Long-term autonomy;  Marginalization;  Mobile robotic;  Simultaneous localization and mapping, Trees (mathematics)},
  language = {English},
  references = {Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph SLAM Proc. IEEE Int. Conf. Robot. Autom., Karlsruhe, Germany, May 2013, pp. 5728-5735; Carlevaris-Bianco, N., Eustice, R.M., Long-term simultaneous localization and mapping with generic linear constraint node removal Proc. IEEE/RSJ Int. Conf. Intell. Robot. Syst., Tokyo, Japan, Nov. 2013, pp. 1034-1041; Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Auton. Robots, 4, pp. 333-349; Thrun, S., Montemerlo, M., The graph SLAM algorithm with applications to large-scale mapping of urban structures (2006) Int. J. Robot. Res., 25 (5-6), pp. 403-429; Dellaert, F., Kaess, M., Square root SAM: Simultaneous localization and mapping via square root information smoothing (2006) Int. J. Robot. Res., 25 (12), pp. 1181-1203; Olson, E., Leonard, J., Teller, S., Fast iterative alignment of pose graphs with poor initial estimates Proc. IEEE Int. Conf. Robot. Autom., Orlando, FL, USA, May 2006, pp. 2262-2269; Eustice, R.M., Singh, H., Leonard, J.J., Exactly sparse delayed-state filters for view-based SLAM (2006) IEEE Trans. Robot., 22 (6), pp. 1100-1114. , Dec; Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to real-time visual mapping (2008) IEEE Trans. Robot., 24 (5), pp. 1066-1077. , Oct; Kaess, M., Ranganathan, A., Dellaert, F., iSAM: Incremental smoothing and mapping (2008) IEEE Trans. Robot., 24 (6), pp. 1365-1378. , Dec; Ila, V., Porta, J.M., Andrade-Cetto, J., Information-based compact pose SLAM (2010) IEEE Trans. Robot., 26 (1), pp. 78-93. , Feb; Johannsson, H., Kaess, M., Fallon, M., Leonard, J.J., Temporally scalable visual SLAM using a reduced pose graph Proc. IEEE Int. Conf. Robot. Autom., Karlsruhe, Germany, May 2013, pp. 54-61; Thrun, S., Liu, Y., Koller, D., Ng, A., Ghahramani, Z., Durrant-Whyte, H., Simultaneous localization and mapping with sparse extended information filters (2004) Int. J. Robot. Res., 23 (7-8), pp. 693-716; Walter, M.R., Eustice, R.M., Leonard, J.J., Exactly sparse extended information filters for feature-based SLAM (2007) Int. J. Robot. Res., 26 (4), pp. 335-359; Vial, J., Durrant-Whyte, H., Bailey, T., Conservative sparsification for efficient and consistent approximate estimation Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., San Francisco, CA, USA, Sep. 2011, pp. 886-893; Eustice, R., Walter, M., Leonard, J., Sparse extended information filters: Insights into sparsification Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Edmonton, AB, Canada, Aug. 2005, pp. 3281-3288; Konolige, K., Bowman, J., Towards lifelong visual maps Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., St. Louis, MO, USA, Oct. 2009, pp. 1156-1163; Eade, E., Fong, P., Munich, M.E., Monocular graph SLAM with complexity reduction Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Taipei, Taiwan, Oct. 2010, pp. 3017-3024; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based SLAM (2012) Int. J. Robot. Res., 31, pp. 1219-1230; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Vilamoura, Portugal, Oct. 2012, pp. 1871-1878; Wang, Y., Xiong, R., Li, Q., Huang, S., Kullback-leibler divergence based graph pruning in robotic feature mapping Proc. Eur. Conf. Mobile Robot., Barcelona, Spain, Sep. 2013, pp. 32-37; Smith, R., Self, M., Cheeseman, P., Estimating uncertain spatial relationships in robotics (1990) Autonomous Robot Vehicles, pp. 167-193. , I. Cox and G. Wilfong, Eds. New York, NY USA: Springer-Verlag; Folkesson, J., Christensen, H., Graphical SLAM - A self-correcting map Proc. IEEE Int. Conf. Robot. Automat., New Orleans, LA, USA, Apr. 2004, pp. 383-390; Frese, U., Efficient 6-DOF SLAM with treemap as a generic backend Proc. IEEE Int. Conf. Robot. Autom., Rome, Italy, Apr. 2007, pp. 4814-4819; Huang, G., Kaess, M., Leonard, J.J., Consistent sparsification for graph optimization Proc. Eur. Conf. Mobile Robot., Barcelona, Spain, Sep. 2013, pp. 150-157; Frese, U., Treemap: An O(Log N) algorithm for simultaneous localization and mapping (2004) Spatial Cognition IV, , C. Freksa Ed., New York, NY, USA: Springer-Verlag; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., g2o: A general framework for graph optimization Proc. IEEE Int. Conf. Robot. Autom., Shanghai, China, May 2011, pp. 3607-3613; Mazuran, M., Diego, T.G., Luciano, S., Burgard, W., Nonlinear graph sparsification for SLAM Proc. Robot.: Sci. Syst. Conf., Berkeley, CA, USA, Jul. 2014, pp. 1-8; Cunningham, A., Indelman, V., Dellaert, F., DDF-SAM 2.0: Consistent distributed smoothing and mapping Proc. IEEE Int. Conf. Robot. Autom., Karlsruhe, Germany, May 2013, pp. 5200-5207; Rao, C.R., Mitra, S.K., (1971) Generalized Inverse of Matrices and Its Applications, , New York, NY, USA: Wiley; Kaess, M., Johannsson, H., Rosen, D., Carlevaris-Bianco, N., Leonard, J., (2010) Open Source Implementation of ISAM, , http://people.csail.mit.edu/kaess/isam, Online. Available; Ozog, P., Eustice, R.M., Toward long-term, automated ship hull inspection with visual SLAM, explicit surface optimization, and generic graph-sparsication Proc. IEEE Int. Conf. Robot. Autom., Hong Kong, Jun. 2014, pp. 3832-3839; Chow, C., Liu, C.N., Approximating discrete probability distributions with dependence trees (1968) IEEE Trans. Inf. Theory, IT-14 (3), pp. 462-467. , May; Davison, A., Active search for real-time vision Proc. IEEE Int. Conf. Comput. Vis., Beijing, China, Oct. 2005, pp. 66-73; Minka, T.P., Inferring a Gaussian distribution (2001) Mass. Inst. Technol. Media Lab., , Cambridge, MA, USA, Tech. Rep; Hover, F.S., Eustice, R.M., Kim, A., Englot, B., Johannsson, H., Kaess, M., Leonard, J.J., Advanced perception, navigation and planning for autonomous in-water ship hull inspection (2012) Int. J. Robot. Res., 31 (12), pp. 1445-1464; Kaess, M., Dellaert, F., Covariance recovery from a square root information matrix for data association (2009) Robot. Auton. Syst., 57, pp. 1198-1210; Neira, J., Tardos, J., Data association in stochastic mapping using the joint compatibility test (2001) IEEE Trans. Robot. Autom., 17 (6), pp. 890-897. , Dec; Carlevaris-Bianco, N., Eustice, R.M., Conservative edge sparsification for graph SLAM node removal Proc. IEEE Int. Conf. Robot. Autom., Hong Kong, China, Jun. 2014, pp. 854-860; Magnusson, M., The three-dimensional normal-distributions transform -An efficient representation for registration, surface analysis, and loop detection (2009) Örebro Studies in Technol., , Ph.D. dissertation, Örebro Univ., Örebro, Sweden; Koller, D., Friedman, N., (2009) Probabilistic Graphical Models: Principles and Techniques, , Cambridge, MA, USA: MIT Press},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916882069&doi=10.1109%2fTRO.2014.2347571&partnerID=40&md5=c0b614f7ca2c8a707375141c52c952ae},
}

@article{chebrolu-et-al:2018:2849603,
  author = {N. Chebrolu and T. Labe and C. Stachniss},
  journal = {IEEE Robotics and Automation Letters},
  title = {Robust long-term registration of UAV images of crop fields for precision agriculture},
  volume = {3},
  number = {4},
  pages = {3097--3104},
  doi = {10.1109/LRA.2018.2849603},
  note = {cited By 32},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Continuous crop monitoring is an important aspect of precision agriculture and requires the registration of sensor data over longer periods of time. Often, fields are monitored using cameras mounted on unmanned aerial vehicles (UAVs) but strong changes in the visual appearance of the growing crops and the field itself poses serious challenges to conventional image registration methods. In this letter, we present a method for registering images of agricultural fields taken by an UAV over the crop season and present a complete pipeline for computing temporally aligned three-dimensional (3-D) point clouds of the field. Our approach exploits the inherent geometry of the crop arrangement in the field, which remains mostly static over time. This allows us to register the images even in the presence of strong visual changes. To this end, we propose a scale invariant, geometric feature descriptor that encodes the local plant arrangement geometry. The experiments suggest that we are able to register images taken over the crop season, including situations where matching with an off-the-shelf visual descriptor fails. We evaluate the accuracy of our matching system with respect to manually labeled ground truth. We furthermore illustrate that the reconstructed 3-D models are qualitatively correct and the registration results allow for monitoring growth parameters at a per plant level. © 2016 IEEE.},
  affiliation = {Institute of Geodesy and Geoinformation, University of Bonn, Bonn, 53113, Germany},
  author_keywords = {Robotics in agriculture and forestry;  SLAM},
  correspondence_address1 = {Chebrolu, N.; Institute of Geodesy and Geoinformation, Germany; email: nived.chebrolu@igg.uni-bonn.de},
  document_type = {Article},
  funding_details = {Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme, H2020, 644227},
  issn = {23773766},
  keywords = {Antennas;  Forestry;  Geometry;  Precision agriculture;  Robotics;  Three dimensional computer graphics;  Unmanned aerial vehicles (UAV), Agricultural fields;  Crop monitoring;  Geometric feature;  Growth parameters;  Matching system;  Registration methods;  SLAM;  Visual appearance, Crops},
  language = {English},
  references = {Agarwal, S., Building Rome in a day (2011) Commun. ACM, 54 (10), pp. 105-112; Bryson, M., Reid, A., Ramos, F.T., Sukkarieh, S., Airborne visionbased mapping and classification of large farmland environments (2010) J. Field Robot, 27 (5), pp. 632-655; Carcassoni, M., Hancock, E.R., Spectral correspondence for point pattern matching (2003) Pattern Recognit, 36 (1), pp. 193-204; Das, J., Devices, systems, and methods for automated monitoring enabling precision agriculture (2015) Proc. IEEE Automat. Sci. Eng, pp. 462-469; Dong, J., Burnham, J.G., Boots, B., Rains, G., Dellaert, F., 4D Crop Monitoring: Spatio-temporal reconstruction for agriculture (2017) Proc. IEEE Int. Conf. Robot. Automat, pp. 3878-3885; Furukawa, Y., Ponce, J., Accurate, dense, and robustmultiviewstereopsis (2010) IEEE Trans. Pattern Anal.Mach. Intell, 32 (8), pp. 1362-1376. , Aug; Gold, S., Rangarajan, A., Lu, C.P., Pappu, S., Mjolsness, E., New algorithms for 2d and 3d point matching: Pose estimation and correspondence (1998) Pattern Recognit, 31 (8), pp. 1019-1031; Kusumam, K., Krajnk, T., Pearson, S., Cielniak, G., Duckett, T., Can you pick a broccoli? 3d-vision based detection and localisation of broccoli heads in the field (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 646-651; Labe, T., Forstner, W., Automatic relative orientation of images (2006) Proc. Turkish-German Joint Geodetic Days, 6p; Li, Y., Fan, X., Mitra, N.J., Chamovitz, D., Cohen-Or, D., Chen, B., Analyzing growing plants from 4d point cloud data (2013) ACMTrans.Graph, 32 (6); Lottes, P., Khanna, R., Pfeifer, J., Siegwart, R., Stachniss, C., UAVBased crop and weed classification for smart farming (2017) Proc. IEEE Int. Conf. Robot. Automat, pp. 3024-3031; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis, 60 (2), pp. 91-110; Lowry, S., Visual place recognition: A survey (2016) IEEE Trans. Robot, 32 (1), pp. 1-19. , Feb; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Automat, pp. 1643-1649; Munkres, J., Algorithms for the assignment and transportation problems (1957) J. Soc. Ind. Appl. Math, 5 (1), pp. 32-38; Otsu, N., Athreshold selectionmethod from gray-level histograms (1979) IEEE Trans. Syst., Man, Cybern, 9 (1), pp. 62-66. , Jan; Pfeifer, J., Towards automatic UAV data interpretation for precision farming (2016) Proc. Int. Conf. Agricultural Eng, 8p; Vysotska, O., Stachniss, C., Lazy data association for image sequences matching under substantial appearance changes (2016) IEEE Robot. Automat. Lett, 1 (1), pp. 213-220. , Jan; Wolfson, H.J., Rigoutsos, I., Geometric hashing: An overview (1997) IEEE Comput. Sci. Eng, 4 (4), pp. 10-21. , Oct; Yang, L., Normand, J.-M., Moreau, G., Local geometric consensus: A general purpose point pattern-based tracking algorithm (2015) IEEE Trans. Vis. Comput. Graph, 21 (11), pp. 1299-1308. , Nov},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063304907&doi=10.1109%2fLRA.2018.2849603&partnerID=40&md5=4d18064900d98631d26ee6b4e4f6f539},
}

@article{piasco-et-al:2021:6,
  author = {N. Piasco and D. Sidibé and V. Gouet-Brunet and C. Demonceaux},
  journal = {International Journal of Computer Vision},
  title = {Improving Image Description with Auxiliary Modality for Visual Localization in Challenging Conditions},
  volume = {129},
  number = {1},
  pages = {185--202},
  doi = {10.1007/s11263-020-01363-6},
  note = {cited By 4},
  publisher = {Springer},
  year = {2021},
  abbrev_source_title = {Int J Comput Vision},
  abstract = {Image indexing for lifelong localization is a key component for a large panel of applications, including robot navigation, autonomous driving or cultural heritage valorization. The principal difficulty in long-term localization arises from the dynamic changes that affect outdoor environments. In this work, we propose a new approach for outdoor large scale image-based localization that can deal with challenging scenarios like cross-season, cross-weather and day/night localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We show through extensive evaluation that our method can improve localization performances, especially in challenging scenarios when the visual appearance of the scene has changed. Our method is able to leverage both visual and geometric clues from monocular images to create discriminative descriptors for cross-season localization and effective matching of images acquired at different time periods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images. Finally we extended our method to reflectance modality and we compare multi-modal descriptors respectively based on geometry, material reflectance and a combination of both. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
  affiliation = {ImViA, VIBOT ERL CNRS 6000, Université Bourgogne Franche-Comté, Dijon, France; LaSTIG, IGN, ENSG, Université Paris-Est, Saint-Mandé, 94160, France; IBISC, Université Paris-Saclay - Univ Evry, Evry, 91020, France},
  author_keywords = {Depth from monocular;  Global image descriptor;  Image retrieval;  Localization;  Side modality learning},
  coden = {IJCVE},
  correspondence_address1 = {Piasco, N.; ImViA, France; email: nathan.piasco@gmail.com},
  document_type = {Article},
  funding_details = {NvidiaNvidia},
  funding_text1 = {We would like to acknowledge the French ANR project pLaTINUM (ANR-15-CE23-0010) for its financial support and Marco Bevilacqua for kindly sharing the code of his inpainting algorithm used in this research. We also gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research.},
  issn = {09205691},
  keywords = {Geometry;  Reflection;  Robots;  Search engines, Geometry information;  Image descriptions;  Image-based localizations;  Localization accuracy;  Localization performance;  Outdoor environment;  Visual localization;  Weakly annotated data, Image enhancement},
  language = {English},
  references = {Anoosheh, A., Agustsson, E., Timofte, R., van Gool, L., Combogan: Unrestrained scalability for image domain translation (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 783-790; Anoosheh, A., Sattler, T., Timofte, R., Pollefeys, M., van Gool, L., Night-to-day image translation for retrieval-based localization (2019) International Conference on Robotics and Automation (ICRA), pp. 5958-5964. , IEEE; Arandjelović, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), pp. 5297-5307; Arandjelović, R., Zisserman, A., DisLocation: Scalable descriptor (2014) In Asian Conference on Computer Vision (ACCV); Ardeshir, S., Zamir, A.R., Torroella, A., Shah, M., GIS-assisted object detection and geospatial localization (2014) European Conference on Computer Vision (ECCV), LNCS, 8694, pp. 602-617; Aubry, M., Russell, B.C., Sivic, J., Painting-to-3D model alignment via discriminative visual elements (2014) ACM Transactions on Graphics (ToG), 33 (2), pp. 1-14; Azzi, C., Asmar, D., Fakih, A., Zelek, J., Filtering 3D keypoints using GIST for accurate image-based localization (2016) British Machine Vision Conference (BMVC), 2, pp. 1-12; Balntas, V., Riba, E., Ponsa, D., Mikolajczyk, K., Learning local feature descriptors with triplets and shallow convolutional neural networks (2016) BMVC, 1, p. 3; Bansal, A., Badino, H., Huber, D., Understanding how camera configuration and environmental conditions affect appearance-based localization (2014) IEEE Intelligent Vehicles Symposium (IV), pp. 800-807; Bevilacqua, M., Aujol, J.F., Biasutti, P., Brédif, M., Bugeau, A., Joint inpainting of depth and reflectance with visibility estimation (2017) ISPRS Journal of Photogrammetry and Remote Sensing, 125, pp. 16-32; Bhowmik, N., Weng, L., Gouet-Brunet, V., Soheilian, B., Cross-domain image localization by adaptive feature fusion (2017) In Joint Urban Remote Sensing Event (JURSE); Brachmann, E., Rother, C., Learning less is more—6D camera localization via 3D surface regression (2018) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Cao, Y., Long, M., Wang, J., Zhu, H., Wen, Q., Deep quantization network for efficient image retrieval (2016) AAAI Conference on Artificial Intelligence., , In; Cao, Z., Long, M., Wang, J., Yu, P.S., Hashnet: Deep learning to hash by continuation (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 5608-5617; Chevalier, M., Thome, N., Hénaff, G., Cord, M., Classifying low-resolution images by integrating privileged information in deep CNNs (2018) Pattern Recognition Letters, 116, pp. 29-35; Christie, G., Warnell, G., Kochersberger, K., (2016) Semantics for UGV registration in GPS-denied environments; Chum, O., Mikul, A., Perdoch, M., Matas, J., Total recall II: Query expansion revisited (2011) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Chum, O., Philbin, J., Sivic, J., Isard, M., Zisserman, A., Total recall: Automatic query expansion with a generative feature model for object retrieval (2007) IEEE International Conference on Computer Vision (ICCV).; Deng, C., Chen, Z., Liu, X., Gao, X., Tao, D., Triplet-based deep hashing network for cross-modal retrieval (2018) IEEE Transactions on Image Processing, 27 (8), pp. 3893-3903; Eigen, D., Puhrsch, C., Fergus, R., Depth map prediction from a single image using a multi-scale deep network (2014) Annual Conference on Neural Information Processing Systems (NIPS), pp. 1-9; Eitel, A., Springenberg, J.T., Spinello, L., Riedmiller, M., Burgard, W., Multimodal deep learning for robust RGB-D object recognition (2015) In IEEE International Conference on Intelligent Robots and Systems (IROS), 2015, pp. 681-687; Garg, S., Suenderhauf, N., Milford, M., Don’t look back: Robustifying place categorization for viewpoint- and condition-invariant place recognition (2018) IEEE International Conference on Robotics and Automation (ICRA); Garg, S., Suenderhauf, N., Milford, M., LoST? Appearance-invariant place recognition for opposite viewpoints using visual semantics (2018) In Robotics Science and Systems (RSS); Germain, H., Bourmaud, G., Lepetit, V., (2018) Improving Nighttime Retrieval-Based Localization, , pdf; Germain, H., Bourmaud, G., Lepetit, V., Sparse-to-dense hypercolumn matching for long-term visual localization (2019) 2019 International Conference on 3D Vision (3DV), pp. 513-523. , September, (pp,). IEEE; Godard, C., Mac Aodha, O., Brostow, G.J., Unsupervised monocular depth estimation with left-right consistency (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR).; Gordo, A., Almazán, J., Revaud, J., Larlus, D., Deep image retrieval: Learning global representations for image search (2016) European Conference on Computer Vision (ECCV), 9905, pp. 241-257; Gordo, A., Almazán, J., Revaud, J., Larlus, D., End-to-end learning of deep visual representations for image retrieval (2017) International Journal of Computer Vision (IJCV), 124 (2), pp. 237-254; Gupta, S., Girshick, R., Arbeláez, P., Malik, J., Learning rich features from RGB-D images for object detection and segmentation (2014) In European Conference on Computer Vision (ECCV), LNCS (, 8695, pp. 345-360; Hays, J., Efros, A.A., IM2GPS: Estimating geographic information from a single image (2008) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 5; Hinton, G., Vinyals, O., Dean, J., (2015) Distilling the Knowledge in a Neural Network; Hoffman, J., Gupta, S., Darrell, T., Learning with side information through modality hallucination (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 826-834; Iscen, A., Tolias, G., Avrithis, Y., Chum, O., (2018) Mining on manifolds: Metric learning without labels; Isola, P., Zhu, J.-Y.Y., Zhou, T., Efros, A.A., Image-to-image translation with conditional adversarial networks (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1125-1134; Jégou, H., Douze, M., Schmid, C., On the burstiness of visual elements (2009) In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) (Pp, pp. 1169-1176; Jiang, Q.-Y., Li, W.-J., Deep cross-modal hashing (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3232-3240; Johnson, J., Alahi, A., Fei-Fei, L., Perceptual losses for real-time style transfer and super-resolution (2016) European Conference on Computer Vision, pp. 694-711. , . In, (pp,). Springer; Johnson, J., Douze, M., Jégou, H., (2017) Billion-Scale Similarity Search with Gpus, , https://ieeexplore.ieee.org/abstract/document/8733051; Kim, H.J., Dunn, E., Frahm, J.-M., Learned contextual feature reweighting for image geo-localization (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Lai, H., Pan, Y., Liu, Y., Yan, S., Simultaneous feature learning and hash coding with deep neural networks (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3270-3278; Li, W., Chen, L., Xu, D., Van Gool, L., Visual recognition in RGB images and videos by learning from RGB-D data (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 40 (8), pp. 2030-2036; Liu, L., Li, H., Dai, Y., Stochastic attraction-repulsion embedding for large scale image localization (2019) Proceedings of the IEEE International Conference on Computer Vision, pp. 2570-2579; Long, M., Cao, Y., Cao, Z., Wang, J., Jordan, M.I., Transferable representation learning with deep adaptation networks (2018) IEEE Transactions on Pattern Analysis and Machine Intelligence, 41 (12), pp. 3071-3085; Loo, S.Y., Amiri, A.J., Mashohor, S., Tang, S.H., Zhang, H., CNN-SVO: Improving the mapping in semi-direct visual odometry using single-image depth prediction (2019) IEEE International Conference on Robotics and Automation (ICRA), 1; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Transactions on Robotics (TRO), 32 (1), pp. 1-19; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: The Oxford RobotCar dataset (2016) The International Journal of Robotics Research (IJRR), 36, pp. 3-15; Mahjourian, R., Wicke, M., Angelova, A., Unsupervised learning of depth and ego-motion from monocular video using 3D geometric constraints (2018) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation (ICRA) (Pp, pp. 1643-1649; Morago, B., Bui, G., Duan, Y., 2D matching using repetitive and salient features in architectural images (2016) IEEE Transactions on Image Processing (ToIP), 7149 (c), pp. 1-12; Mordan, T., Thome, N., Henaff, G., Cord, M., Revisiting multi-task learning with rock: A deep residual auxiliary block for visual detection (2018) Advances in Neural Information Processing Systems, pp. 1310-1322; Muja, M., Lowe, D.G., Fast approximate nearest neighbors with automatic algorithm configuration (2009) International Conference on Computer Vision Theory and Applications (VISAPP), pp. 1-10; Naseer, T., Burgard, W., Stachniss, C., Robust visual localization across seasons (2018) IEEE Transactions on Robotics (TRO), 34 (2), pp. 289-302; Naseer, T., Oliveira, G.L., Brox, T., Burgard, W., Semantics-aware visual localization under challenging perceptual conditions (2017) In IEEE International Conference on Robotics and Automation (ICRA), pp. 2614-2620; Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) International Journal of Computer Vision (IJCV), 42 (3), pp. 145-175; Paulin, M., Mairal, J., Douze, M., Harchaoui, Z., Perronnin, F., Schmid, C., Convolutional patch representations for image retrieval: An unsupervised approach (2017) International Journal of Computer Vision (IJCV), 121 (1), pp. 149-168; Philbin, J., Chum, O., Isard, M., Sivic, J., Zisserman, A., Object retrieval with large vocabularies and fast spatial matching (2007) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Piasco, N., Sidibé, D., Demonceaux, C., Gouet-Brunet, V., A survey on visual-based localization: On the benefit of heterogeneous data (2018) Pattern Recognition, 74, pp. 90-109; Piasco, N., Sidibé, D., Demonceaux, C., Gouet-Brunet, V., Geometric camera pose refinement with learned depth maps (2019) In IEEE International Conference on Image Processing (ICIP); Piasco, N., Sidibé, D., Demonceaux, C., Gouet-Brunet, V., Perspective-n-learned-point: Pose estimation from relative depth (2019) British Machine Vision Conference (BMVC); Piasco, N., Sidibé, D., Gouet-Brunet, V., Demonceaux, C., Learning scene geometry for visual localization in challenging conditions (2019) IEEE International Conference on Robotics and Automation (ICRA), , (c); Porav, H., Bruls, T., Newman, P., I can see clearly now: Image restoration via de-raining (2019) IEEE International Conference on Robotics and Automation (ICRA).; Porav, H., Maddern, W., Newman, P., Adversarial training for adverse conditions: Robust metric localisation using appearance transfer (2018) IEEE International Conference on Robotics and Automation (ICRA); Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3D classification and segmentation (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Radenović, F., Tolias, G., Chum, O., CNN image retrieval learns from BoW: Unsupervised fine-tuning with hard examples (2016) In European Conference on Computer Vision (ECCV) (, 9905, pp. 3-20; Radenović, F., Tolias, G., Chum, O., Fine-tuning CNN image retrieval with no human annotation (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 41, pp. 1655-1668; Russell, B.C., Sivic, J., Ponce, J., Dessales, H., Automatic alignment of paintings and photographs depicting a 3D scene (2011) IEEE International Conference on Computer Vision Workshops (ICCVW).; Sarlin, P.-E., Cadena, C., Siegwart, R., Dymczyk, M., From coarse to fine: Robust hierarchical localization at large scale (2019) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Sarlin, P.-E., Debraine, F., Dymczyk, M., Siegwart, R., Cadena, C., Leveraging deep visual descriptors for hierarchical efficient localization (2018) Conference on Robot Learning (Corl), pp. 1-10; Sattler, T., Havlena, M., Schindler, K., Pollefeys, M., Large-scale location recognition and the geometric burstiness problem (2016) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Sattler, T., Maddern, W., Toft, C., Torii, A., Hammarstrand, L., Stenborg, E., Benchmarking 6DOF outdoor visual localization in changing conditions (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 8601-8610; Sattler, T., Maddern, W., Torii, A., Sivic, J., Pajdla, T., Pollefeys, M., Okutomi, M., Benchmarking 6DOF urban visual localization in changing conditions (2018) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Schönberger, J.L., Pollefeys, M., Geiger, A., Sattler, T., Semantic visual localization (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).; Seymour, Z., Sikka, K., Chiu, H.-P., Samarasekera, S., Kumar, R., (2019) In British Machine Vision Conference (BMVC); Sharmanska, V., Quadrianto, N., Lampert, C.H., Learning to rank using privileged information (2013) Proceedings of the IEEE International Conference on Computer Vision, pp. 825-832; Shotton, J., Glocker, B., Zach, C., Izadi, S., Criminisi, A., Fitzgibbon, A., Scene coordinate regression forests for camera relocalization in RGB-D images (2013) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2930-2937; Sizikova, E., Singh, V.K., Georgescu, B., Halber, M., Ma, K., Chen, T., Enhancing place recognition using joint intensity—depth analysis and synthetic data (2016) European Conference on Computer Vision Workshops (ECCVW), pp. 1-8; Stenborg, E., Toft, C., Hammarstrand, L., Long-term visual localization using semantically segmented images (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 6484-6490. , IEEE; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Place recognition with ConvNet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Robotics Science and Systems (RSS).; Tateno, K., Tombari, F., Laina, I., Navab, N., CNN-SLAM: Real-time dense monocular SLAM with learned depth prediction (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Toft, C., Stenborg, E., Hammarstrand, L., Brynte, L., Pollefeys, M., Sattler, T., Kahl, F., Semantic match consistency for long-term visual localization (2018) In European Conference on Computer Vision (ECCV); Torii, A., Arandjelović, R., Sivic, J., Okutomi, M., Pajdla, T., 24/7 place recognition by view synthesis (2015) In IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Torii, A., Sivic, J., Okutomi, M., Pajdla, T., Visual place recognition with repetitive structures (2013) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 37, pp. 2346-2359; Tzeng, E., Hoffman, J., Saenko, K., Darrell, T., Adversarial discriminative domain adaptation (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7167-7176; Uy, M.A., Lee, G.H., PointNetVLAD: Deep point cloud based retrieval for large-scale place recognition (2018) IEEE Conference on Computer Vision and Pattern Recognition (CVPR).; Vapnik, V., Vashist, A., A new learning paradigm: Learning using privileged information (2009) Neural Networks, 22 (5-6), pp. 544-557; Xu, D., Ouyang, W., Ricci, E., Wang, X., Sebe, N., Detection, learning cross-modal deep representations for robust pedestrian (2017) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5363-5371; Zamir, A.R., Shah, M., Accurate image localization based on google maps street view (2010) European Conference on Computer Vision (ECCV), LNCS, 6314, pp. 255-268; Zamir, A.R., Shah, M., Image geo-localization based on multiplenearest neighbor feature matching using generalized graphs (2014) IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 36 (8), pp. 1546-1558; Zwald, L., Lambert-Lacroix, S., (2012) The berhu penalty and the grouped effect., , arXiv preprint arXiv},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089885445&doi=10.1007%2fs11263-020-01363-6&partnerID=40&md5=dfe9bac192f78822b583fc9cf5506a51},
}

@conference{zhang-et-al:2018:8460674,
  author = {N. Zhang and M. Warren and T. D. Barfoot},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Learning Place-and-Time-Dependent Binary Descriptors for Long-Term Visual Localization},
  pages = {828--835},
  doi = {10.1109/ICRA.2018.8460674},
  note = {cited By 5; Conference of 2018 IEEE International Conference on Robotics and Automation, ICRA 2018 ; Conference Date: 21 May 2018 Through 25 May 2018;  Conference Code:139796},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Vision-based navigation is extremely susceptible to natural scene changes. This can result in localization failures in less than a few hours after map creation. To combat short-term illumination changes as well as long-term seasonal variations, we propose using a place-and-time-dependent binary descriptor that adapts to different scenarios in an online fashion. This is achieved by extending the GRIEF [6] evolution algorithm in two ways: correspondence generation using a known pose change and the inclusion of LATCH triplets in addition to BRIEF comparisons for descriptor generation. We show the adaptive descriptor outperforms a single descriptor scheme for localization within a single-experience Visual Teach and Repeat (VTR) system while maintaining the efficiency of binary descriptors. By adapting the description function to different environmental conditions, it allows the system to operate for a longer period before a new experience is required. In the presence of extreme illumination changes from day to night, we obtain 40% more inlier matches compared to SURF. In the case of seasonal variations, a 70% increase is demonstrated. The increased correspondences result in more localizable sections along the paths, amounting to a 25% and 150% increase in the lighting and seasonal cases, respectively. © 2018 IEEE.},
  affiliation = {University of Toronto, University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, ON  4925, Canada},
  art_number = {8460674},
  coden = {PIIAE},
  document_type = {Conference Paper},
  isbn = {9781538630815},
  issn = {10504729},
  keywords = {Evolutionary algorithms;  Robotics, Environmental conditions;  Evolution algorithms;  Extreme illuminations;  Illumination changes;  On-line fashion;  Seasonal variation;  Vision based navigation;  Visual localization, Robots},
  language = {English},
  references = {Calonder, M., Lepetit, V., Strecha, C., Fua, P., Brief: Binary robust independent elementary features (2010) Computer Vision-ECCV 2010, pp. 778-792; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) Intelligent Robots and Systems (IROS 2014), 2014 IEEE/RSJ International Conference on, pp. 2769-2776. , IEEE; Churchill, W., Newman, P., Practice makes perfect? managing and leveraging visual experiences for lifelong navigation (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 4525-4532. , IEEE; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots (2008) Intelligent Robots and Systems, 2008. IROS 2008. IEEE/RSJ International Conference on, pp. 3364-3369. , IEEE; Furgale, P., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) Journal of Field Robotics, 27 (5), pp. 534-560; Krajník, T., Cristóforis, P., Kusumam, K., Neubert, P., Duckett, T., Image features for visual teach-and-repeat navigation in changing environments (2017) Robotics and Autonomous Systems, 88, pp. 127-141; Leutenegger, S., Chli, M., Siegwart, R.Y., Brisk: Binary robust invariant scalable keypoints (2011) Computer Vision (ICCV), 2011 IEEE International Conference on, pp. 2548-2555. , IEEE; Linegar, C., Churchill, W., Newman, P., Made to measure: Bespoke landmarks for 24-hour, all-weather localisation with a camera (2016) Robotics and Automation (ICRA), 2016 IEEE International Conference on, pp. 787-794. , IEEE; MacTavish, K., Paton, M., Barfoot, T.D., Beyond a shadow of a doubt: Place recognition with colour-constant images (2016) Field and Service Robotics, pp. 187-199. , Springer; McManus, C., Churchill, W., Maddern, W., Stewart, A.D., Newman, P., Shady dealings: Robust, long-term visual localisation using illumination invariance (2014) Robotics and Automation (ICRA), 2014 IEEE International Conference on, pp. 901-906. , IEEE; McManus, C., Upcroft, B., Newman, P., Learning placedependant features for long-term vision-based localisation (2015) Autonomous Robots, 39 (3), pp. 363-387; McManus, C., Upcroft, B., Newmann, P., (2014) Scene Signatures: Localised and Point-less Features for Localisation.; Milford, M.J., Wyeth, G.F., Seqslam: visual routebased navigation for sunny summer days and stormy winter nights (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1643-1649. , IEEE; Neubert, P., Sunderhauf, N., Protzel, P., Appearance change prediction for long-term navigation across seasons (2013) Mobile Robots (ECMR), 2013 European Conference on, pp. 198-203. , IEEE; Paton, M., MacTavish, K., Warren, M., Barfoot, T.D., Bridging the appearance gap: Multi-experience localization for long-term visual teach and repeat (2016) Intelligent Robots and Systems (IROS), 2016 IEEE/RSJ International Conference on, pp. 1918-1925. , IEEE; Paton, M., Pomerleau, F., Barfoot, T.D., (2016) The Dead of Winter: Challenging Vision-Based Path Following in Extreme Conditions, pp. 563-576. , Springer International Publishing, Cham; Perdices, E., López, L.M., Canas, J.M., Lineslam: Visual real time localization using lines and ukf (2014) ROBOT2013: First Iberian Robotics Conference, pp. 663-678. , Springer; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., Orb: An efficient alternative to sift or surf (2011) Computer Vision (ICCV), 2011 IEEE International Conference on, pp. 2564-2571. , IEEE; Salas-Moreno, R.F., Newcombe, R.A., Strasdat, H., Kelly, P.H.J., Davison, A.J., Slam++: Simultaneous localisation and mapping at the level of objects (2013) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1352-1359; Simo-Serra, E., Trulls, E., Ferraz, L., Kokkinos, I., Fua, P., Moreno-Noguer, F., Discriminative learning of deep convolutional feature point descriptors (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 118-126; Simonyan, K., Vedaldi, A., Zisserman, A., Learning local feature descriptors using convex optimisation (2014) IEEE Transactions on Pattern Analysis and Machine Intelligence, 36 (8), pp. 1573-1585; Valgren, C., Lilienthal, A.J., Sift, surf and seasons: Long-term outdoor localization using local features (2007) EMCR; Williams, S., Howard, A.M., Developing monocular visual pose estimation for arctic environments (2010) Journal of Field Robotics, 27 (2), pp. 145-157},
  source = {Scopus},
  sponsors = {Csiro; Department of Defence; DJI; et al.; Queensland University of Technology (QUT); Woodside},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063134571&doi=10.1109%2fICRA.2018.8460674&partnerID=40&md5=40c1dce45bcbd2c341fd66c6fcf6d880},
}

@inproceedings{vysotska-et-al:2015:7139576,
  author = {O. Vysotska and T. Naseer and L. Spinello and W. Burgard and C. Stachniss},
  journal = {2015 IEEE International Conference on Robotics and Automation (ICRA). Proceedings},
  title = {Efficient and effective matching of image sequences under substantial appearance changes exploiting GPS priors},
  pages = {2774--9},
  doi = {10.1109/ICRA.2015.7139576},
  note = {image sequences matching;GPS priors;image data;visual image matching;sequence information;seasonal changes;},
  address = {Piscataway, NJ, USA},
  year = {2015},
  abstract = {The ability to localize a robot is an important capability and matching of observations under substantial changes is a prerequisite for robust long-term operation. This paper investigates the problem of efficiently coping with seasonal changes in image data. We present an extension of a recent approach [15] to visual image matching using sequence information. Our extension allows for exploiting GPS priors in the matching process to overcome the main computational bottleneck of the previous method and to handle loops within the image sequences. We present an experimental evaluation using real world data containing substantial seasonal changes and show that our approach outperforms the previous method in case a noisy GPS pose prior is available.},
  copyright = {Copyright 2015, The Institution of Engineering and Technology},
  keywords = {Global Positioning System;image matching;image sequences;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/ICRA.2015.7139576},
}

@article{biber-duckett:2009:0278364908096286,
  author = {P. Biber and T. Duckett},
  journal = {International Journal of Robotics Research},
  title = {Experimental analysis of sample-based maps for long-term SLAM},
  volume = {28},
  number = {1},
  pages = {20--33},
  doi = {10.1177/0278364908096286},
  note = {cited By 53},
  year = {2009},
  abbrev_source_title = {Int J Rob Res},
  abstract = {This paper presents a system for long-term SLAM (simultaneous localization and mapping) by mobile service robots and its experimental evaluation in a real dynamic environment. To deal with the stability-plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns), the environment is represented by multiple timescales simultaneously (five in our experiments). A sample-based representation is proposed, where older memories fade at different rates depending on the timescale and robust statistics are used to interpret the samples. The dynamics of this representation are analyzed in a five-week experiment, measuring the relative influence of short- and long-term memories over time and further demonstrating the robustness of the approach. © 2009 SAGE Publications.},
  affiliation = {Deptartment of Computer Science, WSI-GRIS, University of Tübingen, Tübingen, Germany; Deptartment of Computing and Informatics, University of Lincoln, Lincoln LN6 7TS, United Kingdom},
  author_keywords = {Dynamic environments;  Lifelong learning;  Mobile robot navigation;  Multi-timescale representations;  Simultaneous localization and mapping},
  coden = {IJRRE},
  correspondence_address1 = {Biber, P.; Deptartment of Computer Science, , Tübingen, Germany; email: dr.peter.biber@googleemail.com},
  document_type = {Article},
  issn = {02783649},
  keywords = {Conformal mapping;  Experiments;  Mobile robots;  Navigation;  Navigation systems;  Robotics, Dynamic environments;  Lifelong learning;  Mobile robot navigation;  Multi-timescale representations;  Simultaneous localization and mapping, Robots},
  language = {English},
  references = {Andrade-Cetto, J., Sanfeliu, A., Concurrent map building and localization in indoor dynamic environments (2002) International Journal of Pattern Recognition and Artificial Intelligence, 16 (3), pp. 361-374; Anguelov, D., Biswas, R., Koller, D., Limketkai, B., Sanner, S., Thrun, S., Learning hierachical objects maps of non-stationary environments with mobile robots Proceedings of the 17th Annual Conference on Uncertainty in AI (UAI); Biber, P., (2007) Map Building and Localization for Long-Term Operation of Mobile Robots in Dynamic Environments. Ph. D. Thesis, Wilhelm-Schickard-Institut, , University of Tübingen, Germany; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots Proceedings of Robotics: Science and Systems i; Biber, P., Straßer, W., The normal distributions transform: A new approach to laser scan matching International Conference on Intelligent Robots and Systems (IROS); Burgard, W., Cremers, A., Fox, D., Hähnel, D., Lakemeyer, G., Steiner, W., Thrun, S., Experiences with an interactive museum tour-guide robot (1999) Artificial Intelligence, 114 (1-2), pp. 3-55; Dennis, J., Schnabel, R.B., (1996) Numerical Methods for Unconstrained Optimization and Nonlinear Equations, , SIAM Classics in Applied Mathematics; Duda, R.O., Hart, P.E., Stork, D.G., (2001) Pattern Classification (Second Ed.), , Wiley; Grossberg, S., (1988) The Adaptive Brain, , North Holland; Hähnel, D., Triebbel, R., Burgard, W., Thrun, S., Map building with mobile robots in dynamic environments (2003) ICRA; Huber, P.J., (1981) Robust Statistics, , New York : Wiley; Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Autonomous Robots, 4, pp. 333-349; Stachniss, C., Burgard, W., Mobile robot mapping and localization in non-static environments Proceedings of the National Conference on Artificial Intelligence (AAAI); Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , MIT Press, Cambridge, MA; Thrun, S., Bennewitz, M., Burgard, W., Cremers, A., Dellaert, F., Fox, D., Hähnel, D., Schulz, D., MINERVA: A Second Generation Mobile Tour-guide Robot (1999) ICRA; Wang, C.-W., Thorpe, C., Thrun, S., Online Simultaneous Localization and Mapping with Detection and Tracking of Moving Objects: Theory and Results from a Ground Vehicle in Crowded Urban Areas (2003) ICRA; Yamauchi, B., Beer, R., Spatial learning for navigation in dynamic environments. IEEE Transactions on Systems (1996) Man and Cybernetics, Special Issue of Learning Autonomous Robots, 26 (3), pp. 496-505; Zimmer, U., (1995) Adaptive Approaches to Basic Mobile Robot Tasks. Ph. D. Thesis, , University of Kaiserslautern},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58149352781&doi=10.1177%2f0278364908096286&partnerID=40&md5=78d5804d47c15f3159e4dadb9c5c1bf0},
}

@conference{egger-et-al:2018:8593854,
  author = {P. Egger and P. V. K. Borges and G. Catt and A. Pfrunder and R. Siegwart and R. Dube},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization},
  pages = {3430--3437},
  doi = {10.1109/IROS.2018.8593854},
  note = {cited By 24; Conference of 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018 ; Conference Date: 1 October 2018 Through 5 October 2018;  Conference Code:144267},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure. © 2018 IEEE.},
  affiliation = {Data61, Robotics and Autonomous Systems Group, CSIRO, Australia; ETH Zurich, Autonomous Systems Lab, Switzerland},
  art_number = {8593854},
  coden = {85RBA},
  document_type = {Conference Paper},
  funding_details = {CVPath InstituteCVPath Institute},
  funding_text1 = {This work was supported by CVPath Institute, Inc., a not-for-profit research organization dedicated to the study of cardiovascular disease.},
  isbn = {9781538680940},
  issn = {21530858},
  keywords = {Autonomous vehicles;  Off road vehicles;  Optical radar, Computational costs;  Dynamic environments;  Map representations;  Moving vehicles;  Multi-environments;  Range measurements;  Road environment;  Visibility analysis, Intelligent robots},
  language = {English},
  references = {McManus, C., Upcroft, B., Newman, P., Learning place-dependant features for long-term vision-based localisation (2015) Autonomous Robots, 39 (3), pp. 363-387; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) Journal of Field Robotics, 33 (5), pp. 561-590; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Transactions on Robotics, 23 (1), pp. 34-46; Kohlbrecher, S., Von Stryk, O., Meyer, J., Klingauf, U., A flexible and scalable slam system with full 3d motion estimation (2011) Safety, Security, and Rescue Robotics (SSRR), 2011 IEEE International Symposium On. IEEE, pp. 155-160; Bosse, M., Zlot, R., Map matching and data association for large-scale two-dimensional laser scan-based slam (2008) The International Journal of Robotics Research, 27 (6), pp. 667-691; Bosse, M., Zlot, R., Continuous 3d scan-matching with a spinning 2d laser (2009) Robotics and Automation, 2009. ICRA'09. IEEE International Conference On. IEEE, pp. 4312-4319; Bosse, M., Zlot, R., Flick, P., Zebedee: Design of a springmounted 3-d range sensor with application to mobile mapping (2012) IEEE Transactions on Robotics, 28 (5), pp. 1104-1119; Zhang, J., Singh, S., Loam: Lidar odometry and mapping in realtime (2014) Robotics: Science and Systems, 2; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2d lidar slam (2016) Robotics and Automation (ICRA), 2016 IEEE International Conference On. IEEE, pp. 1271-1278; Dubé, R., Gawel, A., Sommer, H., Nieto, J., Siegwart, R., Cadena, C., An online multi-robot slam system for 3d lidars (2017) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Elfes, A., Using occupancy grids for mobile robot perception and navigation (1989) Computer, 22 (6), pp. 46-57; Meyer-Delius, D., Beinhofer, M., Burgard, W., Occupancy grid models for robot mapping in changing environments (2012) AAAI; Saarinen, J., Andreasson, H., Lilienthal, A.J., Independent markov chain occupancy grid maps for representation of dynamic environment (2012) Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference On. IEEE, pp. 3489-3495; Hornung, A., Wurm, K.M., Bennewitz, M., Stachniss, C., Burgard, W., Octomap: An efficient probabilistic 3d mapping framework based on octrees (2013) Autonomous Robots, 34 (3), pp. 189-206; Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-term slam (2009) The International Journal of Robotics Research, 28 (1), pp. 20-33; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph slam: Long-term mapping in low dynamic environments (2012) Intelligent Robots and Systems (IROS), 2012 IEEE/RSJ International Conference On. IEEE, pp. 1871-1878; Maddern, W., Pascoe, G., Newman, P., Leveraging experience for large-scale lidar localisation in changing cities (2015) Robotics and Automation (ICRA), 2015 IEEE International Conference On. IEEE, pp. 1684-1691; Pfrunder, A., Borges, P.V.K., Romero, A.R., Catt, G., Elfes, A., Real-time autonomous ground vehicle navigation in heterogeneous environments using a 3d lidar (2017) 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 2601-2608. , Sept; Bosse, M., Zlot, R., Place recognition using keypoint voting in large 3d lidar datasets (2013) IEEE International Conference on Robotics and Automation (ICRA); Dubé, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., Segmatch: Segment based place recognition in 3d point clouds (2017) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 5266-5272; Dubé, R., Cramariuc, A., Dugas, D., Nieto, J., Siegwart, R., Cadena, C., Segmap: 3d segment mapping using data-driven descriptors (2018) Robotics: Science and Systems (RSS)},
  source = {Scopus},
  sponsors = {Bosch; et al.; JD.Com; Kuka; PAL Robotics; Santander},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062964443&doi=10.1109%2fIROS.2018.8593854&partnerID=40&md5=a4ffa03c55cdcd426ae0323d4f43dd8a},
}

@conference{ganti-waslander:2019:00024,
  author = {P. Ganti and S. Waslander},
  journal = {Proceedings - 2019 16th Conference on Computer and Robot Vision, CRV 2019},
  title = {Network uncertainty informed semantic feature selection for visual SLAM},
  pages = {121--128},
  doi = {10.1109/CRV.2019.00024},
  note = {cited By 6; Conference of 16th Conference on Computer and Robot Vision, CRV 2019 ; Conference Date: 29 May 2019 Through 31 May 2019;  Conference Code:150294},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {Proc. - Conf. Comput. Robot Vis., CRV},
  abstract = {In order to facilitate long-term localization using a visual simultaneous localization and mapping (SLAM) algorithm, careful feature selection can help ensure that reference points persist over long durations and the runtime and storage complexity of the algorithm remain consistent. We present SIVO (Semantically Informed Visual Odometry and Mapping), a novel information-theoretic feature selection method for visual SLAM which incorporates semantic segmentation and neural network uncertainty into the feature selection pipeline. Our algorithm selects points which provide the highest reduction in Shannon entropy between the entropy of the current state and the joint entropy of the state, given the addition of the new feature with the classification entropy of the feature from a Bayesian neural network. Each selected feature significantly reduces the uncertainty of the vehicle state and has been detected to be a static object (building, traffic sign, etc.) repeatedly with a high confidence. This selection strategy generates a sparse map which can facilitate long-term localization. The KITTI odometry dataset is used to evaluate our method, and we also compare our results against ORB-SLAM2. Overall, SIVO performs comparably to the baseline method while reducing the map size by almost 70%. © 2019 IEEE.},
  affiliation = {Department of Mechanical and Mechatronics Engineering, University of Waterloo, Waterloo, Canada; Institute for Aerospace Studies, University of Toronto, Toronto, Canada},
  art_number = {8781616},
  author_keywords = {Deep Learning;  Information Theory;  Localization;  Mapping;  Semantic Segmentation;  SLAM},
  document_type = {Conference Paper},
  isbn = {9781728118383},
  keywords = {Agricultural robots;  Classification (of information);  Computational complexity;  Computer vision;  Deep learning;  Information theory;  Mapping;  Neural networks;  Robots;  Semantic Web;  Semantics, Bayesian neural networks;  Feature selection methods;  Localization;  Network uncertainties;  Semantic segmentation;  SLAM;  Storage complexity;  Visual simultaneous localization and mappings, Feature extraction},
  language = {English},
  references = {Nistér, D., Naroditsky, O., Bergen, J., Visual odometry (2004) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1, p. I. , IEEE; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision (IJCV), 60 (2), pp. 91-110; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) European Conference on Computer Vision (ECCV), pp. 404-417. , Springer; Rosten, E., Drummond, T., Machine learning for highspeed corner detection (2006) European Conference on Computer Vision (ECCV), pp. 430-443. , Springer; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to sift or surf (2011) IEEE International Conference on Computer Vision (ICCV). IEEE, pp. 2564-2571; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research (IJRR), 27 (6), pp. 647-665; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual routebased navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 1643-1649; Fischler, M.A., Bolles, R.C., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Communications of the ACM, 24 (6), pp. 381-395; Mur-Artal, R., Tardós, J.D., ORB-SLAM2: An opensource SLAM system for monocular, stereo, and RGB-D cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? the KITTI vision benchmark suite (2012) IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, pp. 3354-3361; Dissanayake, G., Durrant-Whyte, H., Bailey, T., A computationally efficient solution to the simultaneous localisation and map building (SLAM) problem (2000) IEEE International Conference on Robotics and Automation (ICRA), 2, pp. 1009-1014. , IEEE; Hochdorfer, S., Schlegel, C., Landmark rating and selection according to localization coverage: Addressing the challenge of lifelong operation of SLAM in service robots (2009) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 382-387; Davison, A.J., Active search for real-time vision (2005) IEEE International Conference on Computer Vision (ICCV), 1, pp. 66-73. , IEEE; Kaess, M., Dellaert, F., Covariance recovery from a square root information matrix for data association (2009) Robotics and Autonomous Systems, 57 (12), pp. 1198-1210; Zhang, S., Xie, L., Adams, M.D., Entropy based feature selection scheme for real time simultaneous localization and map building (2005) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 1175-1180; Choudhary, S., Indelman, V., Christensen, H.I., Dellaert, F., Information-based reduced landmark SLAM (2015) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 4620-4627; Strasdat, H., Stachniss, C., Burgard, W., Which landmark is useful? Learning selection policies for navigation in unknown environments (2009) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 1410-1415; Salas-Moreno, R.F., Newcombe, R.A., Strasdat, H., Kelly, P.H., Davison, A.J., SLAM++: Simultaneous localisation and mapping at the level of objects (2013) IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, pp. 1352-1359; Murali, V., Chiu, H.-P., Samarasekera, S., Kumar, R.T., Utilizing semantic visual landmarks for precise vehicle navigation (2017) International Conference on Intelligent Transportation Systems (ITSC). IEEE, pp. 1-8; Badrinarayanan, V., Kendall, A., Cipolla, R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 39 (12), pp. 2481-2495; Li, X., Belaroussi, R., (2016) Semi-dense 3D Semantic Mapping from Monocular SLAM, , arXiv preprint arXiv:1611.04144; An, L., Zhang, X., Gao, H., Liu, Y., Semantic segmentation-aided visual odometry for urban autonomous driving (2017) International Journal of Advanced Robotic Systems (IJARS), 14 (5), pp. 1729881417735667; Stenborg, E., Toft, C., Hammarstrand, L., Long-term visual localization using semantically segmented images (2018) International Conference on Robotics and Automation (ICRA). IEEE, pp. 6484-6490; Mu, B., Liu, S.-Y., Paull, L., Leonard, J., How, J.P., Slam with objects using a nonparametric pose graph (2016) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 4602-4609; Bowman, S.L., Atanasov, N., Daniilidis, K., Pappas, G.J., Probabilistic data association for semantic SLAM (2017) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 1722-1729; Gal, Y., (2016) Uncertainty in Deep Learning, , Ph.D. dissertation, University of Cambridge; Gal, Y., Ghahramani, Z., (2015) Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference, , arXiv preprint arXiv:1506.02158; Gal, Y., Ghahramani, Z., Dropout as a Bayesian approximation: Representing model uncertainty in deep learning (2016) International Conference on Machine Learning (ICML), pp. 1050-1059; Gal, Y., Ghahramani, Z., (2015) Dropout As A Bayesian Approximation: Appendix, , arXiv preprint arXiv:1506.02157; Kendall, A., Gal, Y., What uncertainties do we need in Bayesian deep learning for computer vision (2017) Advances in Neural Information Processing Systems (NIPS), pp. 5580-5590; Kendall, A., Badrinarayanan, V., Cipolla, R., (2015) Bayesian Segnet: Model Uncertainty in Deep Convolutional Encoderdecoder Architectures for Scene Understanding, , arXiv preprint arXiv:1511.02680; Kendall, A., Cipolla, R., Modelling uncertainty in deep learning for camera relocalization (2016) IEEE International Conference on Robotics and Automation (ICRA). IEEE, pp. 4762-4769; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research (JMLR), 15 (1), pp. 1929-1958; Neal, R.M., (1995) Bayesian Learning for Neural Networks, , Ph.D. dissertation, University of Toronto; Cover, T.M., Thomas, J.A., (2012) Elements of Information Theory, , John Wiley &Sons; Chli, M., (2010) Applying Information Theory to Efficient SLAM, , Ph.D. dissertation, Department of Computing, Imperial College London; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) 22nd ACM International Conference on Multimedia. ACM, pp. 675-678; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3213-3223},
  source = {Scopus},
  sponsors = {Canadian Image Processing and Pattern Recognition Society / Association Canadienne de Traitement d�Images et de Reconnaissance des Formes (CIPPRS/ACTIRF)},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071049485&doi=10.1109%2fCRV.2019.00024&partnerID=40&md5=d432634030828d03acd9dfa6a43c0970},
}

@conference{gao-zhang:2020:9196906,
  author = {P. Gao and H. Zhang},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships},
  pages = {1070--1076},
  doi = {10.1109/ICRA40945.2020.9196906},
  note = {cited By 3; Conference of 2020 IEEE International Conference on Robotics and Automation, ICRA 2020 ; Conference Date: 31 May 2020 Through 31 August 2020;  Conference Code:163172},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks. © 2020 IEEE.},
  affiliation = {Colorado School of Mines, Human-Centered Robotics Lab, Golden, CO  80401, United States},
  art_number = {9196906},
  coden = {PIIAE},
  document_type = {Conference Paper},
  funding_details = {National Science FoundationNational Science Foundation, NSF, 1849348, 1849359, 1942056},
  funding_text1 = {This work was partially supported by IIS-1942056, IIS-1849348, IIS-1849359, DOT PHMSA 693JK31850005CAAP, and DOE DE-FE0031650.},
  isbn = {9781728173955},
  issn = {10504729},
  keywords = {Agricultural robots;  Graph structures;  Knowledge representation, Appearance similarities;  Environment change;  Graph matching problems;  Graph representation;  Localization and mappings;  Robotics applications;  Spatial relationships;  Worst case scenario, Robotics},
  language = {English},
  references = {Mur-Artal, R., Tardós, J.D., ORB-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-slam: A versatile and accurate monocular slam system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163; Engel, J., Schöps, T., Cremers, D., LSD-slam: Large-scale direct monocular slam (2014) European Conference on Computer Vision; Ulrich, I., Nourbakhsh, I., Appearance-based place recognition for topological localization (2000) IEEE International Conference on Robotics and Automation; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Lowry, S., Milford, M.J., Supervised and unsupervised linear learning techniques for visual place recognition in changing environments (2016) IEEE Transactions on Robotics, 32 (3), pp. 600-613; Mur-Artal, R., Tardós, J.D., Visual-inertial monocular slam with map reuse (2017) IEEE Robotics and Automation Letters, 2 (2), pp. 796-803; Kerl, C., Sturm, J., Cremers, D., Dense visual slam for rgb-d cameras (2013) IEEE International Conference on Intelligent Robots and Systems; Zhou, H., Zou, D., Pei, L., Ying, R., Liu, P., Yu, W., StructSLAM: Visual slam with building structure lines (2015) IEEE Transactions on Vehicular Technology, 64 (4), pp. 1364-1375; Gao, X., Zhang, T., Unsupervised learning to detect loops using deep neural networks for visual slam system (2017) Autonomous Robots, 41 (1), pp. 1-18; Strasdat, H., Montiel, J.M., Davison, A.J., Visual slam: Why filter? (2012) Image and Vision Computing, 30 (2), pp. 65-77; Kitt, B.M., Rehder, J., Chambers, A.D., Schonbein, M., Lategahn, H., Singh, S., (2011) Monocular Visual Odometry Using A Planar Road Model to Solve Scale Ambiguity; Neubert, P., Sünderhauf, N., Protzel, P., Superpixel-based appearance change prediction for long-term navigation across seasons (2015) Robotics and Autonomous Systems, 69, pp. 15-27; Yang, S., Scherer, S.A., Yi, X., Zell, A., Multi-camera visual slam for autonomous navigation of micro aerial vehicles (2017) Robotics and Autonomous Systems, 93, pp. 116-134; Lategahn, H., Geiger, A., Kitt, B., Visual slam for autonomous ground vehicles (2011) IEEE International Conference on Robotics and Automation; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: Cnn architecture for weakly supervised place recognition (2016) IEEE Conference on Computer Vision and Pattern Recognition; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2015) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) IEEE International Conference on Intelligent Robots and Systems; Endres, F., Hess, J., Engelhard, N., Sturm, J., Cremers, D., Burgard, W., An evaluation of the rgb-d slam system (2012) IEEE International Conference on Robotics and Automation; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) AAAI Conference on Artificial Intelligence; Latif, Y., Huang, G., Leonard, J.J., Neira, J., An online sparsitycognizant loop-closure algorithm for visual navigation (2014) Robotics: Science and Systems; Han, F., Yang, X., Deng, Y., Rentschler, M., Yang, D., Zhang, H., SRAL: Shared representative appearance learning for long-term visual place recognition (2017) IEEE Robotics and Automation Letters, 2 (2), pp. 1172-1179; Han, F., El Beleidy, S., Wang, H., Ye, C., Zhang, H., Learning of holism-landmark graph embedding for place recognition in long-term autonomy (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 3669-3676; Siva, S., Zhang, H., Omnidirectional multisensory perception fusion for long-term place recognition (2018) IEEE International Conference on Robotics and Automation; Panphattarasap, P., Calway, A., Visual place recognition using landmark distribution descriptors (2016) Asian Conference on Computer Vision; Chen, Z., Maffra, F., Sa, I., Chli, M., Only look once, mining distinctive landmarks from convnet for visual place recognition (2017) IEEE International Conference on Intelligent Robots and Systems; Pronobis, A., Martinez Mozos, O., Caputo, B., Jensfelt, P., Multimodal semantic place classification (2010) The International Journal of Robotics Research, 29 (2-3), pp. 298-320; Babenko, A., Lempitsky, V., Aggregating local deep features for image retrieval (2015) IEEE International Conference on Computer Vision; Zitnick, C.L., Dollár, P., Edge boxes: Locating object proposals from edges (2014) European Conference on Computer Vision; Hou, Y., Zhang, H., Zhou, S., Evaluation of object proposals and convnet features for landmark-based visual place recognition (2018) Journal of Intelligent and Robotic Systems, 92 (3-4), pp. 505-520; Liu, K., Wang, H., Han, F., Zhang, H., Visual place recognition via robust l2-norm distance based holism and landmark integration (2019) AAAI Conference on Artificial Intelligence; Han, F., Wang, H., Huang, G., Zhang, H., Sequence-based sparse optimization methods for long-term loop closure detection in visual slam (2018) Autonomous Robots, 42 (7), pp. 1323-1335; Ho, K.L., Newman, P., Loop closure detection in slam by combining visual and spatial appearance (2006) Robotics and Autonomous Systems, 54 (9), pp. 740-749; Newman, P., Cole, D., Ho, K., Outdoor slam using visual appearance and laser ranging (2006) IEEE International Conference on Robotics and Automation; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual slam across seasons (2015) IEEE International Conference on Intelligent Robots and Systems; Milford, M.J., Wyeth, G.F., Prasser, D., RatSLAM: A hippocampal model for simultaneous localization and mapping (2004) IEEE International Conference on Robotics and Automation; Cummins, M., Newman, P., FAB-map: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Zhang, H., Han, F., Wang, H., Robust multimodal sequence-based loop closure detection via structured sparsity (2016) Robotics: Science and Systems; Johns, E., Yang, G.-Z., Feature co-occurrence maps: Appearancebased localisation throughout the day (2013) IEEE International Conference on Robotics and Automation; Siam, S.M., Zhang, H., Fast-seqslam: A fast appearance based place recognition algorithm (2017) IEEE International Conference on Robotics and Automation; Hansen, P., Browning, B., Visual place recognition using hmm sequence matching (2014) IEEE International Conference on Intelligent Robots and Systems; Cadena, C., Gálvez-López, D., Tardós, J.D., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Transactions on Robotics, 28 (4), pp. 871-885; Rabanser, S., Shchur, O., Günnemann, S., Introduction to tensor decompositions and their applications in machine learning (2015) Machine Learning, 98 (1-2), pp. 1-5; Romeijn, H.E., Morales, D.R., A class of greedy algorithms for the generalized assignment problem (2000) Discrete Applied Mathematics, 103 (1-3), pp. 209-235; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., FABMAP+ ratslam: Appearance-based slam for multiple times of day (2010) IEEE International Conference on Robotics and Automation; Badino, H., Huber, D., Kanade, T., Real-time topometric localization (2012) IEEE International Conference on Robotics and Automation; Lee, D., Kim, H., Myung, H., 2D image feature-based realtime rgb-d 3d slam (2013) Robot Intelligence Technology and Applications; Sünderhauf, N., Protzel, P., Brief-GIST-closing the loop by simple means (2011) IEEE International Conference on Intelligent Robots and Systems},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092746607&doi=10.1109%2fICRA40945.2020.9196906&partnerID=40&md5=4837eae23583d73b511e84dbba4bf3c9},
}

@article{mühlfellner-et-al:2016:21595,
  author = {P. Mühlfellner and M. Bürki and M. Bosse and W. Derendarz and R. Philippsen and P. Furgale},
  journal = {Journal of Field Robotics},
  title = {Summary Maps for Lifelong Visual Localization},
  volume = {33},
  number = {5},
  pages = {561--590},
  doi = {10.1002/rob.21595},
  note = {cited By 52},
  publisher = {John Wiley and Sons Inc.},
  year = {2016},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {Robots that use vision for localization need to handle environments that are subject to seasonal and structural change, and operate under changing lighting and weather conditions. We present a framework for lifelong localization and mapping designed to provide robust and metrically accurate online localization in these kinds of changing environments. Our system iterates between offline map building, map summary, and online localization. The offline mapping fuses data from multiple visually varied datasets, thus dealing with changing environments by incorporating new information. Before passing these data to the online localization system, the map is summarized, selecting only the landmarks that are deemed useful for localization. This Summary Map enables online localization that is accurate and robust to the variation of visual information in natural environments while still being computationally efficient. We present a number of summary policies for selecting useful features for localization from the multisession map, and we explore the tradeoff between localization performance and computational complexity. The system is evaluated on 77 recordings, with a total length of 30 kilometers, collected outdoors over 16 months. These datasets cover all seasons, various times of day, and changing weather such as sunshine, rain, fog, and snow. We show that it is possible to build consistent maps that span data collected over an entire year, and cover day-to-night transitions. Simple statistics computed on landmark observations are enough to produce a Summary Map that enables robust and accurate localization over a wide range of seasonal, lighting, and weather conditions. © 2015 Wiley Periodicals, Inc.},
  affiliation = {Department for Driver Assistance and Integrated Safety, Volkswagen AG, Halmstad University, Letter Box 011/1777, Wolfsburg, Germany; Autonomous Systems Lab, ETH Zürich, Leonhardstrasse 21, Zürich, Switzerland; Department for Driver Assistance and Integrated Safety, Volkswagen AG, Letter Box 011/1777, Wolfsburg, Germany; Intelligent Systems Lab, Halmstad University, Kristian IV's väg 3, Halmstad, Sweden},
  correspondence_address1 = {Mühlfellner, P.; Department for Driver Assistance and Integrated Safety, Letter Box 011/1777, Germany; email: peter.muehlfellner@volkswagen.de},
  document_type = {Article},
  funding_details = {269916, 610603, EUROPA2},
  funding_text1 = {This work is supported in part by the European Community's Seventh Framework Programme (FP7/2007-2013) under Grants No. 269916 (V-Charge) and No. 610603 (EUROPA2).},
  issn = {15564959},
  keywords = {Computer vision;  Data visualization;  Lighting;  Mapping;  Meteorology, Changing environment;  Computationally efficient;  Localization and mappings;  Localization performance;  Natural environments;  On-line localization;  Visual information;  Visual localization, Social networking (online)},
  language = {English},
  references = {Agarwal, S., Snavely, N., Seitz, S.M., Szeliski, R., Bundle adjustment in the large (2010) Computer Vision–ECCV 2010 (pp. 29–42), , In, Springer; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Robotics: Science and Systems (pp. 17–24), , In, MIT Press, Cambridge, Massachusetts; Bosse, M., Zlot, R., Place recognition using keypoint voting in large 3D lidar datasets (2013) 2013 IEEE International Conference on Robotics and Automation (ICRA), pp. 2677-2684. , May)., In; Bosse, M., Newman, P., Leonard, J., Soika, M., Feiten, W., Teller, S., An atlas framework for scalable mapping (2003) ICRA'03 Proceedings of the IEEE International Conference on Robotics and Automation, 2003 (Vol. 2, pp. 1899–1906). IEEE; Brubaker, M.A., Geiger, A., Urtasun, R., Lost! Leveraging the crowd for probabilistic visual self-localization (2013) 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 3057–3064). IEEE; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE; Carlevaris-Bianco, N., Eustice, R.M., Long-term simultaneous localization and mapping with generic linear constraint node removal (2013) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1034-1041. , In, Tokyo; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Corke, P., Paul, R., Churchill, W., Newman, P., Dealing with shadows: Capturing intrinsic scene appearance for image-based outdoor localisation (2013) 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (pp. 2085–2092). IEEE; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Dayoub, F., Cielniak, G., Duckett, T., Long-term experiments with an adaptive spherical view representation for navigation in changing environments (2011) Robotics and Autonomous Systems, 59 (5), pp. 285-295; Furgale, P., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) Journal of Field Robotics, 27 (5), pp. 534-560; Furgale, P., Schwesinger, U., Rufli, M., Derendarz, W., Grimmett, H., Muhlfellner, P., Wonneberger, S., Li, B., Toward automated driving in cities using close-to-market sensors: An overview of the v-charge project (2013) 2013 IEEE Conference on Intelligent Vehicles Symposium (IV) (pp. 809–816). IEEE; Heng, L., Furgale, P., Pollefeys, M., Leveraging image-based localization for infrastructure-based calibration of a multi-camera rig (2014) Journal of Field Robotics, , http://www.youtube.com/watch?v=ppWppzDIYPk, video;, http://people.inf.ethz.ch/hengli/camodocal/ code; Johannsson, H., Kaess, M., Fallon, M.F., Leonard, J.J., Temporally scalable visual SLAM using a reduced pose graph (2012) In RSS Workshop on Long-term Operation of Autonomous Robotic Systems in Changing Environments. Sydney, Australia, , July); Johns, E., Yang, G.-Z., Feature co-occurrence maps: Appearance-based localisation throughout the day (2013) In 2013 IEEE International Conference on Robotics and Automation (ICRA), pp. 3212–3218. IEEE; Johns, E., Yang, G.-Z., Generative methods for long-term place recognition in dynamic scenes (2014) International Journal of Computer Vision, 106 (3), pp. 297-314; Kneip, L., Furgale, P.T., OpenGV: A unified and generalized approach to real-time calibrated geometric vision (2014) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA) (pp. 1–8). Hong Kong, , bib/kneip_icra14.pdf, May–June)., In, (code); Kneip, L., Lynen, S., Direct optimization of frame-to-frame rotation (2013) 2013 IEEE International Conference on Computer Vision (ICCV) (pp. 2352–2359). IEEE; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) IEEE/RSJ International Conference on Intelligent Robots and Systems (pp. 1156–1163). IEEE; Krajník, T., Faigl, J., Vonásek, V., Košnar, K., Kulich, M., Přeučil, L., Simple yet stable bearing-only navigation (2010) Journal of Field Robotics, 27 (5), pp. 511-533; Krajnik, T., Pedre, S., Preucil, L., Monocular navigation for long-term autonomy (2013) 2013 16th International Conference on Advanced Robotics (ICAR) (pp. 1–6). IEEE; Krajnik, T., Fentanes, J.P., Mozos, O.M., Duckett, T., Ekekrantz, J., Hanheide, M., Long-term topological localisation for service robots in dynamic environments using spectral maps (2014) In 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2014) (pp. 4537–4542). IEEE; Lategahn, H., Stiller, C., (2012) City GPS using stereo vision. In 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES) (pp. 1 –6), , July); Lategahn, H., Stiller, C., Vision-only localization (2014) IEEE Transactions on Intelligent Transportation Systems, 15 (3), pp. 1246-1257. , June); Henning, L., Johannes, B., Bernd, K., Christoph, S., How to learn an illumination robust image feature for place recognition (2013) In 2013 Conference on IEEE Intelligent Vehicles Symposium (IV) (pp. 285–291). IEEE; Lee, G.H., Visual mapping and pose estimation for self-driving cars. Ph.D. thesis (2014) Eidgenössische Technische Hochschule ETH Zürich, Nr. 21858; Lee, G.H., Fraundorfer, F., Pollefeys, M., Structureless pose-graph loop-closure with a multi-camera system on a self-driving car (2013) 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (pp. 564–571). IEEE; Leutenegger, S., Chli, M., Siegwart, R.Y., BRISK: Binary robust invariant scalable keypoints (2011) 2011 IEEE International Conference on Computer Vision (ICCV) (pp. 2548–2555). IEEE; Li, Y., Snavely, N., Huttenlocher, D.P., Location recognition using prioritized feature matching (2010) Computer Vision–ECCV 2010 (pp. 791–804), , In, Springer; Lovegrove, S., Davison, A.J., Ibanez-Guzmán, J., Accurate visual odometry from a rear parking camera (2011) 2011 IEEE Conference on Intelligent Vehicles Symposium (IV) (pp. 788–793). IEEE; Maddern, W., Milford, M., Wyeth, G., Towards persistent localization and mapping with a continuous appearance-based topology (2012) Proceedings of Robotics Science and Systems Conference 2012, , In, University of Sydney., MIT Press, Cambridge, Massachusetts; Maddern, W., Stewart, A.D., Newman, P., LAPS-II: 6-DOF day and night visual localisation with prior 3D structure for autonomous road vehicles (2014) In 2014 IEEE Intelligent Vehicles Symposium; Mazuran, M., Diego, T.G., Luciano, S., Burgard, W., Nonlinear graph sparsification for SLAM (2014) Proceedings of Robotics: Science and Systems, Berkeley, CA, , July), In; McManus, C., Furgale, P.T., Stenning, B.E., Barfoot, T.D., Lighting-invariant visual teach and repeat using appearance-based lidar (2013) Journal of Field Robotics, 30 (2), pp. 254-287; McManus, C., Churchill, W., Maddern, W., Stewart, A.D., Newman, P., Shady dealings: Robust, long-term visual localisation using illumination invariance (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA); McManus, C., Upcroft, B., Newman, P., Scene signatures: Localised and point-less features for localisation (2014) Proceedings of Robotics Science and Systems (RSS). Berkeley, CA, , July)., In; Milford, M., Vig, E., Scheirer, W., Cox, D., Vision-based simultaneous localization and mapping in changing outdoor environments (2014) Journal of Field Robotics, 31 (5), pp. 814-836; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) 2012 IEEE International Conference on Robotics and Automation (ICRA) (pp. 1643–1649). IEEE; Muehlfellner, P., Furgale, P., Derendarz, W., Philippsen, R., Evaluation of fisheye-camera based visual multi-session localization in a real-world scenario (2013) 2013 IEEE Conference on Intelligent Vehicles Symposium (IV) (pp. 57–62). IEEE; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Proceedings of the National Conference on Artificial Intelligence (AAAI); Neubert, P., Sunderhauf, N., Protzel, P., Appearance change prediction for long-term navigation across seasons (2013) 2013 European Conference on Mobile Robots (ECMR) (pp. 198–203). IEEE; Ni, K., Steedly, D., Dellaert, F., Out-of-core bundle adjustment for large-scale 3D reconstruction (2007) IEEE 11th International Conference on Computer Vision (pp. 1–8). IEEE; Pepperell, E., Corke, P.I., Milford, M.J., All-environment visual place recognition with SMART (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA) (pp. 1612–1618). IEEE; Sibley, G., Mei, C., Reid, I., Newman, P., Vast-scale outdoor navigation using adaptive relative bundle adjustment (2010) The International Journal of Robotics Research, 29 (8), pp. 958-980; Sibley, G., Mei, C., Reid, I., Newman, P., Adaptive relative bundle adjustment. In Robotics Science and Systems (RSS) (2009) Seattle, , June)., MIT Press, Cambridge, Massachusetts; Snavely, N., Seitz, S.M., Szeliski, R., Skeletal graphs for efficient structure from motion (2008) Conference on Computer Vision and Pattern Recognition, 1, p. 2. , In, IEEE (, p; Stewart, A.D., Newman, P., Laps-localisation using appearance of prior structure: 6-DOF monocular camera localisation using prior pointclouds (2012) 2012 IEEE International Conference on Robotics and Automation (ICRA) (pp. 2625–2632). IEEE; Valgren, C., Lilienthal, A.J., Sift, surf & seasons: Appearance-based long-term localization in outdoor environments (2010) Robotics and Autonomous Systems, 58 (2), pp. 149-156; Zhang, Z., Parameter estimation techniques: A tutorial with application to conic fitting (1997) Image and Vision Computing, 15 (1), pp. 59-76; Ziegler, J., Lategahn, H., Schreiber, M., Keller, C.G., Knoppel, C., Hipp, J., Haueis, M., Stiller, C., Video based localization for Bertha (2014) Proceedings of the 2014 IEEE Conference on Intelligent Vehicles Symposium (pp. 1231–1238), , June), In; Ziegler, J., Bender, P., Schreiber, M., Lategahn, H., Strauss, T., Stiller, C., Dang, T., Keller, C., Making Bertha drive? An autonomous journey on a historic route (2014) IEEE Intelligent Transportation Systems Magazine, 6 (2), pp. 8-20},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931069651&doi=10.1002%2frob.21595&partnerID=40&md5=42e1dd551bdb31f08dbc661d2e3a7100},
}

@article{neubert-et-al:2015:005,
  author = {P. Neubert and N. Sunderhauf and P. Protzel},
  journal = {Robotics and Autonomous Systems},
  title = {Superpixel-based appearance change prediction for long-term navigation across seasons},
  volume = {69},
  pages = {15--27},
  doi = {10.1016/j.robot.2014.08.005},
  note = {superpixel-based appearance change prediction;long-term navigation;robotic systems;weather conditions;place recognition;visual appearance;learned knowledge;SP-ACP;SeqSLAM;BRIEF-Gist;Nordland dataset;},
  address = {Netherlands},
  year = {2015},
  abstract = {Changing environments pose a serious problem to current robotic systems aiming at long term operation under varying seasons or local weather conditions. This paper is built on our previous work where we propose to learn to <i>predict</i> the changes in an environment. Our key insight is that the occurring scene changes are in part systematic, repeatable and therefore predictable. The goal of our work is to support existing approaches to place recognition by learning how the visual appearance of an environment changes over time and by using this learned knowledge to predict its appearance under different environmental conditions. We describe the general idea of appearance change prediction (ACP) and investigate properties of our novel implementation based on vocabularies of superpixels (SP-ACP). Our previous work showed that the proposed approach significantly improves the performance of SeqSLAM and BRIEF-Gist for place recognition on a subset of the Nordland dataset under extremely different environmental conditions in summer and winter. This paper deepens the understanding of the proposed SP-ACP system and evaluates the influence of its parameters. We present the results of a large-scale experiment on the complete 10 h Nordland dataset and appearance change predictions between different combinations of seasons. [All rights reserved Elsevier].},
  copyright = {Copyright 2015, The Institution of Engineering and Technology},
  issn = {0921-8890},
  keywords = {image recognition;knowledge based systems;mobile robots;navigation;robot vision;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1016/j.robot.2014.08.005},
}

@article{ozog-et-al:2016:21582,
  author = {P. Ozog and N. Carlevaris-Bianco and A. Kim and R. M. Eustice},
  journal = {Journal of Field Robotics},
  title = {Long-term Mapping Techniques for Ship Hull Inspection and Surveillance using an Autonomous Underwater Vehicle},
  volume = {33},
  number = {3},
  pages = {265--289},
  doi = {10.1002/rob.21582},
  note = {cited By 41},
  publisher = {John Wiley and Sons Inc.},
  year = {2016},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {This paper reports on a system for an autonomous underwater vehicle to perform in situ, multiple session hull inspection using long-term simultaneous localization and mapping (SLAM). Our method assumes very little a priori knowledge, and it does not require the aid of acoustic beacons for navigation, which is a typical mode of navigation in this type of application. Our system combines recent techniques in underwater saliency-informed visual SLAM and a method for representing the ship hull surface as a collection of many locally planar surface features. This methodology produces accurate maps that can be constructed in real-time on consumer-grade computing hardware. A single-session SLAM result is initially used as a prior map for later sessions, where the robot automatically merges the multiple surveys into a common hull-relative reference frame. To perform the relocalization step, we use a particle filter that leverages the locally planar representation of the ship hull surface, and a fast visual descriptor matching algorithm. Finally, we apply the recently developed graph sparsification tool, generic linear constraints, as a way to manage the computational complexity of the SLAM system as the robot accumulates information across multiple sessions. We show results for 20 SLAM sessions for two large vessels over the course of days, months, and even up to three years, with a total path length of approximately 10.2 km. © 2015 Wiley Periodicals, Inc.},
  affiliation = {Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, United States; Department of Civil and Environmental Engineering, Korea Advanced Institute of Science and Technology, Daejeon, S., South Korea; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, United States},
  correspondence_address1 = {Eustice, R.M.; Department of Naval Architecture and Marine Engineering, United States; email: eustice@umich.edu},
  document_type = {Article},
  funding_details = {Office of Naval ResearchOffice of Naval Research, ONR, N00014-12-1-0092},
  funding_text1 = {This work was supported by the Office of Naval Research under award N00014-12-1-0092.},
  issn = {15564959},
  keywords = {Algorithms;  Autonomous underwater vehicles;  Distributed computer systems;  Image matching;  Information management;  Mapping;  Robotics;  Robots;  Ships, Computing hardware;  Descriptor matching;  Graph sparsification;  Linear constraints;  Mapping techniques;  Ship-hull inspections;  Simultaneous localization and mapping;  Total path length, Hulls (ship)},
  language = {English},
  references = {Agarwal, P., Tipaldi, G.D., Spinello, L., Stachniss, C., Burgard, W., Robust map optimization using dynamic covariance scaling (2013) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 62-69. , Karlsruhe, Germany; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) Proceedings of the European Conference on Computer Vision (Pp. 404-417), , Graz, Austria: Springer; Belcher, E., Matsuyama, B., Trimble, G., Object identification with acoustic lenses (2001) Proceedings of the IEEE/MTS OCEANS Conference and Exhibition, 1, pp. 6-11. , Kona, HI; Bonnín-Pascual, F., Ortiz, A., Detection of cracks and corrosion for automated vessels visual inspection (2010) Proceedings of the International Conference of the Catalan Association for Artificial Intelligence, pp. 111-120. , Tarragona, Spain; Boon, B., Brennan, F., Garbatov, Y., Ji, C., Parunov, J., Rahman, T., Rizzo, C., Yamamoto, N., Condition assessment of aged ships and offshore structures (2009) International Ship and Offshore Structures Congress, 2, pp. 313-365. , Seoul, Korea; Bosse, M., Newman, P., Leonard, J., Teller, S., Simultaneous localization and map building in large-scale cyclic environments using the Atlas framework (2004) International Journal of Robotics Research, 23 (12), pp. 1113-1139; Bosse, M., Zlot, R., Map matching and data association for large-scale two-dimensional laser scan-based SLAM (2008) International Journal of Robotics Research, 27 (6), pp. 667-691; Bowen, A.D., Yoerger, D.R., Taylor, C., McCabe, R., Howland, J., Gomez-Ibanez, D., Kinsey, J.C., Hulme, S., Field trials of the Nereus hybrid underwater robotic vehicle in the challenger deep of the Mariana Trench (2009) Proceedings of the IEEE/MTS OCEANS Conference and Exhibition, pp. 1-10. , Biloxi, MS; Carlevaris-Bianco, N., Eustice, R.M., Multi-view registration for feature-poor underwater imagery (2011) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 423-430. , Shanghai, China; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph SLAM (2013) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 5728-5735. , Karlsruhe, Germany; Carlevaris-Bianco, N., Eustice, R.M., Long-term simultaneous localization and mapping with generic linear constraint node removal (2013) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1034-1041. , Tokyo, Japan; Carlevaris-Bianco, N., Eustice, R.M., Conservative edge sparsification for graph SLAM node removal (2014) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 854-860. , Hong Kong, China; Carvalho, A., Sagrilo, L., Silva, I., Rebello, J., Carneval, R., On the reliability of an automated ultrasonic system for hull inspection in ship-based oil production units (2003) Applied Ocean Research, 25 (5), pp. 235-241; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) International Journal of Robotics Research, 27 (6), pp. 647-665; Dellaert, F., Kaess, M., Square root SAM: Simultaneous localization and mapping via square root information smoothing (2006) International Journal of Robotics Research, 25 (12), pp. 1181-1203; Eade, E., Fong, P., Munich, M., Monocular graph SLAM with complexity reduction (2010) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3017-3024. , Taipei, Taiwan; Eustice, R.M., Pizarro, O., Singh, H., Visually augmented navigation for autonomous underwater vehicles (2008) IEEE Journal of Ocean Engineering, 33 (2), pp. 103-122; Glover, A., Maddern, W., Warren, M., Reid, S., Milford, M., Wyeth, G., OpenFABMAP: An open source toolbox for appearance-based loop closure detection (2012) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 4730-4735. , St. Paul, MN; Grisetti, G., Stachniss, C., Grzonka, S., Burgard, W., A tree parameterization for efficiently computing maximum likelihood maps using gradient descent (2007) Proceedings of the Robotics: Science & Systems Conference, pp. 65-72. , Atlanta, GA; Gustafson, E., Jalving, B., Engelhardtsen, Ø., Burchill, N., HUGIN 1000 Arctic class AUV (2011) The Polar Petroleum Potential Conference & Exhibition, pp. 714-721. , Halifax, Nova Scotia; Harris, S., Slate, E., Lamp ray: Ship hull assessment for value, safety and readiness (1999) Proceedings of the IEEE/MTS OCEANS Conference and Exhibition, 1, pp. 493-500. , Seattle, WA; Hover, F., Vaganay, J., Elkins, M., Willcox, S., Polidoro, V., Morash, J., Damus, R., Desset, S., A vehicle system for autonomous relative survey of in-water ships (2007) Marine Technology Society Journal, 41 (2), pp. 44-55; Hover, F.S., Eustice, R.M., Kim, A., Englot, B., Johannsson, H., Kaess, M., Leonard, J.J., Advanced perception, navigation and planning for autonomous in-water ship hull inspection (2012) International Journal of Robotics Research, 31 (12), pp. 1445-1464; Ishizu, K., Sakagami, N., Ishimaru, K., Shibata, M., Onishi, H., Murakami, S., Kawamura, S., Ship hull inspection using a small underwater robot with a mechanical contact mechanism (2012) Proceedings of the IEEE/MTS OCEANS Conference and Exhibition, pp. 1-6. , Hampton Roads, VA; Johannsson, H., Kaess, M., Englot, B., Hover, F., Leonard, J.J., Imaging sonar-aided navigation for autonomous underwater harbor surveillance (2010) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 4396-4403. , Taipei, Taiwan; Julier, S., The scaled unscented transformation (2002) Proceedings of the American Control Conference, 6, pp. 4555-4559. , Anchorage, AK; Kaess, M., Dellaert, F., Covariance recovery from a square root information matrix for data association (2009) Robotics and Autonomous Systems, 57 (12), pp. 1198-1210; Kaess, M., Johannsson, H., Rosen, D., Carlevaris-Bianco, N., Leonard, J., (2010) Open Source Implementation of ISAM, , http://people.csail.mit.edu/kaess/isam; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) IEEE Transactions on Robotics, 24 (6), pp. 1365-1378; Kim, A., Eustice, R.M., Pose-graph visual SLAM with geometric model selection for autonomous underwater ship hull inspection (2009) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1559-1565. , St. Louis, MO; Kim, A., Eustice, R.M., Real-time visual SLAM for autonomous underwater hull inspection using visual saliency (2013) IEEE Transactions on Robotics, 29 (3), pp. 719-733; Kim, B., Kaess, M., Fletcher, L., Leonard, J., Bachrach, A., Roy, N., Teller, S., Multiple relative pose graphs for robust cooperative mapping (2010) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 3185-3192. , Anchorage, AK; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1156-1163. , St. Louis, MO; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based SLAM (2012) International Journal of Robotics Research, 31 (11), pp. 1219-1230; Kullback, S., Leibler, R.A., On information and sufficiency (1951) The Annals of Mathematical Statistics, 22 (1), pp. 79-86; Kummerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 3607-3613. , Shanghai, China; Kunz, C., Murphy, C., Singh, H., Pontbriand, C., Sohn, R.A., Singh, S., Sato, T., Bailey, J., Toward extraplanetary under-ice exploration: Robotic steps in the arctic (2009) Journal of Field Robotics, 26 (4), pp. 411-429; Leonard, J., Feder, H., A computationally efficient method for large-scale concurrent mapping and localization (1999) Proceedings of the International Symposium on Robotics Research, , J. Hollerbach & D. Koditschek (eds.), Salt Lake City, UT; Lowe, D., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Menegaldo, L.L., Ferreira, G., Santos, M.F., Guerato, R.S., Development and navigation of a mobile robot for floating production storage and offloading ship hull inspection (2009) IEEE Transactions on Industrial Electronics, 56 (9), pp. 3717-3722; Menegaldo, L.L., Santos, M., Ferreira, G.A.N., Siqueira, R.G., Moscato, L., SIRUS: A mobile robot for floating production storage and offloading (FPSO) ship hull inspection (2008) Proceedings of the IEEE International Workshop on Advanced Motion Control, pp. 27-32. , Trento, Italy; Milne, P., (1983) Underwater Acoustic Positioning Systems, , Houston: Gulf Publishing Company; Muja, M., Lowe, D.G., Fast approximate nearest neighbors with automatic algorithm configuration (2009) International Conference on Computer Vision Theory and Application, pp. 331-340. , Lisboa, Portugal; Negahdaripour, S., Firoozfam, P., An ROV stereovision system for ship-hull inspection (2006) IEEE Journal of Oceanic Engineering, 31 (3), pp. 551-564; Neira, J., Tardos, J., Data association in stochastic mapping using the joint compatibility test (2001) IEEE Transactions on Robotics and Automation, 17 (6), pp. 890-897; Ni, K., Steedly, D., Dellaert, F., Tectonic SAM: Exact, out-of-core, submap-based SLAM (2007) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 1678-1685. , Rome, Italy; Nistér, D., Stewénius, H., Scalable recognition with a vocabulary tree (2006) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2, pp. 2161-2168; Ozog, P., Eustice, R.M., On the importance of modeling camera calibration uncertainty in visual SLAM (2013) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 3762-3769. , Karlsruhe, Germany; Ozog, P., Eustice, R.M., Real-time SLAM with piecewise-planar surface models and sparse 3D point clouds (2013) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1042-1049. , Tokyo, Japan; Ozog, P., Eustice, R.M., Toward long-term, automated ship hull inspection with visual SLAM, explicit surface optimization, and generic graph-sparsification (2014) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 3832-3839. , Hong Kong, China; Pizarro, O., Eustice, R.M., Singh, H., Large area 3-D reconstructions from underwater optical surveys (2009) IEEE Journal of Oceanic Engineering, 34 (2), pp. 150-169; Ridao, P., Carreras, M., Ribas, D., Garcia, R., Visual inspection of hydroelectric dams using an autonomous underwater vehicle (2010) Journal of Field Robotics, 27 (6), pp. 759-778; Roman, C., Singh, H., Improved vehicle based multibeam bathymetry using sub-maps and SLAM (2005) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2422-2429. , Edmonton, Alberta, Canada; Segal, A., Haehnel, D., Thrun, S., Generalized-ICP (2009) Proceedings of the Robotics: Science & Systems Conference, , Seattle, WA; Singh, H., Armstrong, R., Gilbes, F., Eustice, R., Roman, C., Pizarro, O., Torres, J., Imaging coral I: Imaging coral habitats with the SeaBED AUV (2004) The Journal for Subsurface Sensing Technologies and Applications, 5 (1), pp. 25-42; Smith, R., Self, M., Cheeseman, P., Estimating uncertain spatial relationships in robotics (1986) Proceedings of Uncertainty in AI (Pp. 267-288), , Philadelphia, PA: Elsevier; Sunderhauf, N., Protzel, P., Switchable constraints for robust pose graph SLAM (2012) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1879-1884. , Algarve, Portugal; Thrun, S., Montemerlo, M., The graph SLAM algorithm with applications to large-scale mapping of urban structures (2006) International Journal of Robotics Research, 25 (56), pp. 403-429; Trevor, A.J.B., Rogers, J.G., Christensen, H.I., Planar surface SLAM with 3D and 2D sensors (2012) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 3041-3048. , St. Paul, MN; Trimble, G., Belcher, E., Ship berthing and hull inspection using the CetusII AUV and MIRIS high-resolution sonar (2002) Proceedings of the IEEE/MTS OCEANS Conference and Exhibition, 2, pp. 1172-1175. , Biloxi, MS; VanMiddlesworth, M., Kaess, M., Hover, F., Leonard, J., Mapping 3D underwater environments with smoothed submaps (2013) Proceedings of the International Conference on Field and Service Robotics, pp. 17-30. , Brisbane, Australia; Walter, M., Hover, F., Leonard, J., SLAM for ship hull inspection using exactly sparse extended information filters (2008) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 1463-1470. , Pasadena, CA; Weingarten, J., Siegwart, R., 3D SLAM using planar segments (2006) Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 3062-3067. , Beijing, China},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928197207&doi=10.1002%2frob.21582&partnerID=40&md5=6a622d7d83d9cb22408e58d13ed80ff6},
}

@conference{schmuck-chli:2019:00071,
  author = {P. Schmuck and M. Chli},
  journal = {Proceedings - 2019 International Conference on 3D Vision, 3DV 2019},
  title = {On the Redundancy Detection in Keyframe-Based SLAM},
  pages = {594--603},
  doi = {10.1109/3DV.2019.00071},
  note = {cited By 3; Conference of 7th International Conference on 3D Vision, 3DV 2019 ; Conference Date: 15 September 2019 Through 18 September 2019;  Conference Code:153712},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {Proc. - Int. Conf. 3D Vis., 3DV},
  abstract = {Egomotion and scene estimation is a key component in automating robot navigation, as well as in virtual reality applications for mobile phones or head-mounted displays. It is well known, however, that with long exploratory trajectories and multi-session mapping for long-term autonomy or collaborative applications, the maintenance of the ever-increasing size of these maps quickly becomes a bottleneck. With the explosion of data resulting in increasing runtime of the optimization algorithms ensuring the accuracy of the Simultaneous Localization And Mapping (SLAM) estimates, the large quantity of collected experiences is imposing hard limits on the scalability of such techniques. Considering the keyframe-based paradigm of SLAM techniques, this paper investigates the redundancy inherent in SLAM maps, by quantifying the information of different experiences of the scene as encoded in keyframes. Here we propose and evaluate different information-theoretic and heuristic metrics to remove dispensable scene measurements with minimal impact on the accuracy of the SLAM estimates. Evaluating the proposed metrics in two state-of-the-art centralized collaborative SLAM systems, we provide our key insights into how to identify redundancy in keyframe-based SLAM. © 2019 IEEE.},
  affiliation = {Vision for Robotics Lab, ETH Zurich, Zurich, 8092, Switzerland},
  art_number = {8885807},
  author_keywords = {Collaborative SLAM;  Graph Compression;  Keyframe Selection;  Multi Robot Systems;  Redundancy Detection;  SLAM},
  document_type = {Conference Paper},
  funding_details = {National Centre of Competence in Research RoboticsNational Centre of Competence in Research Robotics},
  funding_text1 = {∗This research was supported by the Swiss National Science Foundation (SNSF, Agreement no. PP00P2183720) and NCCR Robotics.},
  isbn = {9781728131313},
  keywords = {Global system for mobile communications;  Helmet mounted displays;  Information theory;  Mapping;  Multipurpose robots;  Redundancy;  Virtual reality, Collaborative SLAM;  Graph compressions;  Key frame selection;  Multi-robot systems;  SLAM, Robotics},
  language = {English},
  references = {Burri, M., Nikolic, J., Gohl, P., Schneider, T., Rehder, J., Omari, S., Achtelik, M.W., Siegwart, R., The euroc micro aerial vehicle datasets (2016) International Journal of Robotics Research (IJRR), 35 (10), pp. 1157-1163. , 6; Carlevaris-Bianco, N., Kaess, M., Eustice, R.M., Generic node removal for factor-graph slam (2014) IEEE Transactions on Robotics (T-RO), 30 (6), pp. 1371-1385. , 2, 5; Carlone, L., Censi, A., Dellaert, F., Selecting good measurements via l1 relaxation: A convex approach for robust estimation over graphs (2014) Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems (IROS), (2), pp. 2667-2674. , IEEE; Chli, M., Davison, A.J., Active matching (2008) Proceedings of the European Conference on Computer Vision (ECCV), 2, pp. 72-85. , Springer; Choudhary, S., Indelman, V., Christensen, H.I., Dellaert, F., Information-based reduced landmark slam (2015) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2, pp. 4620-4627. , IEEE; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) International Journal of Robotics Research (IJRR), 14 (2), pp. 1645-1661; Davison, A.J., Active search for real-time vision (2005) Proceedings of the International Conference on Computer Vision (ICCV), 1, pp. 66-73. , IEEE 4; Deutsch, I., Liu, M., Siegwart, R., A framework for multi-robot pose graph slam (2016) IEEE International Conference on Real-time Computing and Robotics (RCAR), p. 3; Eade, E., Fong, P., Munich, M.E., Monocular graph slam with complexity reduction (2010) Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems (IROS), (2), pp. 3017-3024. , IEEE; Forster, C., Lynen, S., Kneip, L., Scaramuzza, D., Collaborative monocular slam with multiple micro aerial vehicles (2013) Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems (IROS, p. 3; Hepp, B., Nießner, M., Hilliges, O., Plan3d: Viewpoint and trajectory optimization for aerial multi-view stereo reconstruction (2018) ACM Transactions on Graphics (TOG), 38 (1-4), p. 2; Hsiung, J., Hsiao, M., Westman, E., Valencia, R., Kaess, M., (2018) Information Sparsification in Visual-inertial Odometry, p. 2; Huang, G., Kaess, M., Leonard, J.J., Consistent sparsification for graph optimization (2013) European Conference on Mobile Robots (ECMR), (2), pp. 150-157. , IEEE; Ila, V., Porta, J.M., Andrade-Cetto, J., Information-based compact pose slam (2010) IEEE Transactions on Robotics (TRO), 26 (1), pp. 78-93. , 2; Johannsson, H., Kaess, M., Fallon, M., Leonard, J.J., Temporally scalable visual slam using a reduced pose graph (2013) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), (2), pp. 54-61. , IEEE; Karrer, M., Schmuck, P., Chli, M., Cvi-slam-collaborative visual-inertial slam (2018) IEEE Robotics and Automation Letters (RA-L), 3 (4), pp. 2762-2769. , 1, 2, 3, 4, 5, 6, 7; Konolige, K., Agrawal, M., Frameslam: From bundle adjustment to real-time visual mapping (2008) IEEE Transactions on Robotics (T-RO), 24 (5), pp. 1066-1077. , 2; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based slam (2012) International Journal of Robotics Research (IJRR), 31 (11), pp. 1219-1230. , 2; Leutenegger, S., Lynen, S., Bosse, M., Siegwart, R., Furgale, P., Keyframe-based visual-inertial odometry using nonlinear optimization (2015) International Journal of Robotics Research (IJRR), 34 (3), pp. 314-334. , 1; Mazuran, M., Burgard, W., Tipaldi, G.D., Nonlinear factor recovery for long-term slam (2016) International Journal of Robotics Research (IJRR), 35 (1-3), pp. 50-72. , 2, 5; Mu, B., Paull, L., Agha-Mohammadi, A.-A., Leonard, J.J., How, J.P., Two-stage focused inference for resourceconstrained minimal collision navigation (2017) IEEE Transactions on Robotics (T-RO), 33 (1), pp. 124-140. , 2; Mur-Artal, R., Montiel, J., Tardós, J.D., Orb-slam: A versatile and accurate monocular slam system (2015) IEEE Transactions on Robotics (T-RO), 31 (5), pp. 1147-1163. , 1, 3, 4, 5, 6, 7; Mur-Artal, R., Tardós, J.D., Visual-inertial monocular slam with map reuse (2017) IEEE Robotics and Automation Letters (RA-L), 2 (2), pp. 796-803. , 1; Paull, L., Huang, G., Leonard, J.J., A unified resourceconstrained framework for graph slam (2016) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), (3), pp. 1346-1353. , IEEE; Qin, T., Li, P., Shen, S., Vins-mono: A robust and versatile monocular visual-inertial state estimator (2018) IEEE Transactions on Robotics (T-RO), 34 (4), pp. 1004-1020. , 1, 3, 5; Riazuelo, L., Civera, J., Montiel, J., C2tam: A cloud framework for cooperative tracking and mapping (2014) Robotics and Autonomous Systems (RAS), 62 (4), pp. 401-413. , 3; Schmuck, P., Chli, M., Multi-uav collaborative monocular slam (2017) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA, p. 1; Schmuck, P., Chli, M., Ccm-slam: Robust and efficient centralized collaborative monocular simultaneous localization and mapping for robotic teams (2019) Journal of Field Robotics (JFR), 36 (4), pp. 763-781. , 1, 2, 3, 5, 7, 8; Schneider, T., Li, M., Burri, M., Nieto, J., Siegwart, R., Gilitschenski, I., Visual-inertial self-calibration on informative motion segments (2017) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), (2), pp. 6487-6494. , IEEE; Snavely, N., Seitz, S.M., Szeliski, R., Skeletal graphs for efficient structure from motion (2008) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1 (2), p. 2; Strasdat, H., Montiel, J.M., Davison, A.J., (2012) Visual SLAM: Why Filter Image and Vision Computing, 30 (2), pp. 65-77. , 1; Usenko, V., Demmel, N., Schubert, D., Stückler, J., Cremers, D., (2019) Visual-inertial Mapping with Non-linear Factor Recovery, p. 8; Vallvé, J., Solà, J., Andrade-Cetto, J., Graph slam sparsification with populated topologies using factor descent optimization (2018) IEEE Robotics and Automation Letters (RA-L), 3 (2), pp. 1322-1329. , 2; Vial, J., Durrant-Whyte, H., Bailey, T., Conservative sparsification for efficient and consistent approximate estimation (2011) Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems (IROS), 3, pp. 886-893. , IEEE},
  source = {Scopus},
  sponsors = {et al.; Huawei; Innovmetric; INO; Polyrix; Wrnch},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074975753&doi=10.1109%2f3DV.2019.00071&partnerID=40&md5=1e08202b3a5556a5948113d200ecdddb},
}

@article{yin-et-al:2021:3061375,
  author = {P. Yin and L. Xu and J. Zhang and H. Choset},
  journal = {IEEE Robotics and Automation Letters},
  title = {FusionVLAD: A Multi-View Deep Fusion Networks for Viewpoint-Free 3D Place Recognition},
  volume = {6},
  number = {2},
  pages = {2304--2310},
  doi = {10.1109/LRA.2021.3061375},
  note = {cited By 4},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Real-time 3D place recognition is a crucial technology to recover from localization failure in applications like autonomous driving, last-mile delivery, and service robots. However, it is challenging for 3D place retrieval methods to be accurate, efficient, and robust to the variant viewpoints differences. In this letter, we propose FusionVLAD, a fusion-based network that encodes a multi-view representation of sparse 3D point clouds into viewpoint-free global descriptors. The system consists of two parallel branches: a spherical-view branch for orientation-invariant feature extraction, and the top-down view branch for translation-insensitive feature extraction. Furthermore, we design a parallel fusion module to enhance the combination of region-wise feature connection between the two branches. Experiments on two public datasets and two generated datasets show that our method outperforms state-of-the-art with robust place recognition accuracy and efficient inference time. Besides, FusionVLAD requires limited computation resources and makes it extremely suitable for low-cost robots' long-term place recognition task. © 2016 IEEE.},
  affiliation = {Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States},
  art_number = {9361316},
  author_keywords = {Recognition;  SLAM;  visual learning},
  correspondence_address1 = {Xu, L.; Robotics Institute, United States; email: hitmaxtom@gmail.com},
  document_type = {Article},
  issn = {23773766},
  keywords = {Agricultural robots;  Extraction;  Robots, Autonomous driving;  Computation resources;  Crucial technology;  Global Descriptors;  Insensitive features;  Invariant feature extraction;  Place recognition;  Retrieval methods, Feature extraction},
  language = {English},
  references = {Qi, C.R., Su, H., Mo, K., Guibas, L.J., Pointnet: Deep learning on point sets for 3d classification and segmentation (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 652-660; Qi, C.R., Yi, L., Su, H., Guibas, L.J., Pointnet : Deep hierarchical feature learning on point sets in a metric space (2017) Proc. Adv. Neural Inf. Process. Syst., pp. 5099-5108; Uy, M.A., Lee, G.H., Pointnetvlad:Deep point cloud based retrieval for large-scale place recognition (2018) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 4470-4479. , Jun; Liu, Z., Lpd-net: 3d point cloud learning for large-scale place recognition and environment analysis (2019) Proc. IEEE Int. Conf. Comput. Vis., pp. 2831-2840; Zhang, W., Xiao, C., Pcan: 3d attention map learning using contextual information for point cloud based retrieval (2019) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 12436-12445; Lowe, D.G., Object recognition from local scale-invariant features (1999) Proc. 7th IEEE Int. Conf. Comput. Vis., 2, pp. 1150-1157; Bay, H., Tuytelaars, T., Van Gool, L., Surf: Speeded up robust features (2006) Eur. Conf. Comput. Vis. Berlin, pp. 404-417. , Germany: Springer; Wohlkinger, W., Vincze, M., Ensemble of shape functions for 3 d object classification (2011) Proc. IEEE Int. Conf. Robot. Biomimetics., pp. 2987-2992; Kim, G., Kim, A., Scan context: Egocentric spatial descriptor for place recognition within 3 d point cloud map (2018) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 4802-4809; Tombari, F., Salti, S., Di Stefano, L., Unique signatures of histograms for local surface description (2010) Proc. Eur. Conf. Comput. Vis. Berlin, pp. 356-369. , Germany: Springer; Röhling, T., Mack, J., Schulz, D., A fast histogram-based similarity measure for detecting loop closures in 3-d lidar data (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 736-741; He, L., Wang, X., Zhang, H., M2dp: A novel 3d point cloud descriptor and its application in loop closure detection (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 231-237; Zhang, J., Singh, S., Loam: Lidar odometry and mapping in real-time (2014) Robot.: Sci. Syst., 2, p. 9; Dubé, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., Segmatch: Segment based place recognition in 3 d point clouds (2017) Proc. IEEE Int. Conf. Robot. Automat., pp. 5266-5272. , May; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., Netvlad: Cnn architecture forweakly supervised place recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 5297-5307. , Jun; Rho, E., Jo, S., Octomap-based semi-autonomous quadcopter navigation with biosignal classification (2018) Proc. 6th Int. Conf. Brain-Comput. Interface, pp. 1-4. , Jan; Schnabel, R., Wahl, R., Klein, R., Efficient ransac for point-cloud shape detection (2007) Computer Graphics Forum, 26 (2), pp. 214-226. , Wiley Online Library; Esteves, C., Allen-Blanchette, C., Makadia, A., Daniilidis, K., Learning so (3) equivariant representations with spherical cnns (2018) Proc. Eur. Conf. Comput. Vis., pp. 52-68; Wohlkinger, W., Vincze, M., Ensemble of shape functions for 3d object classification (2011) Proc. IEEE Int. Conf. Robot. Biomimetics, pp. 2987-2992; Röhling, T., Mack, J., Schulz, D., A fast histogram-based similarity measure for detecting loop closures in 3-d lidar data (2015) 2015 IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 736-741; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Automat., pp. 1643-1649. , May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101756700&doi=10.1109%2fLRA.2021.3061375&partnerID=40&md5=83956754921b8e7dea2e5676e9ba60f4},
}

@conference{yin-et-al:2018:8593562,
  author = {P. Yin and L. Xu and Z. Liu and L. Li and H. Salman and Y. He and W. Xu and H. Wang and H. Choset},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition},
  pages = {1162--1167},
  doi = {10.1109/IROS.2018.8593562},
  note = {cited By 10; Conference of 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2018 ; Conference Date: 1 October 2018 Through 5 October 2018;  Conference Code:144267},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms. © 2018 IEEE.},
  affiliation = {State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, Hong Kong; Robotics Institute at Carnegie Mellon University, Pittsburgh, United States; Department of Mechanical Engineering, University of Auckland, New Zealand},
  art_number = {8593562},
  coden = {85RBA},
  document_type = {Conference Paper},
  isbn = {9781538680940},
  issn = {21530858},
  keywords = {Intelligent robots;  Mapping;  Optical radar, Adversarial networks;  Conditional entropy;  Geometry matching;  Inference efficiency;  Localization and mappings;  Real time performance;  Robotic platforms;  Unsupervised feature learning, Machine learning},
  language = {English},
  references = {Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet? Challenging SeqSLAM on a 3000 km journey across all four seasons (2013) Workshop on Long-Term Autonomy, IEEE International Conference on Robotics and Automation (ICRA); Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan North Campus long-term vision and lidar dataset (2016) The International Journal of Robotics Research, 35 (9), pp. 1023-1035; Zhang, J., Singh, S., LOAM: Lidar odometry and mapping in real-time (2014) Robotics: Science and Systems, 2, pp. 9-17; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3354-3361; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2D LIDAR SLAM (2016) IEEE International Conference on Robotics and Automation (ICRA), pp. 1271-1278; Fossel, J., Tuyls, K., Schnieders, B., Claes, D., Hennes, D., NOctoSLAM: Fast octree surface normal mapping and registration (2017) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 6764-6769; Dubé, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., SegMatch: Segment based place recognition in 3D point clouds (2017) IEEE International Conference on Robotics and Automation (ICRA), pp. 5266-5272; Bay, H., Tuytelaars, T., Van Gool, L., Surf: Speeded up robust features (2006) European Conference on Computer Vision (ECCV), pp. 404-417; Ng, P.C., Henikoff, S., SIFT: Predicting amino acid changes that affect protein function (2003) Nucleic Acids Research, 31 (13), pp. 3812-3814; Filliat, D., A visual bag of words method for interactive qualitative localization and mapping (2007) IEEE International Conference on Robotics and Automation (ICRA), pp. 3921-3926; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual routebased navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation (ICRA), pp. 1643-1649; Besl, P.J., McKay, N.D., Method for registration of 3-D shapes (1992) IEEE Transactions on Pattern Analysis and Machine Intelligence, 14 (2), pp. 239-256; Donahue, J., Krähenbühl, P., Darrell, T., (2016) Adversarial Feature Learning, , arXiv preprint arXiv: 1605. 09782; Goodfellow, I., Generative adversarial nets (2014) Advances in Neural Information Processing Systems (NIPS), pp. 2672-2680; Martin, A., Bottou, L., (2017) Towards Principled Methods for Training Generative Adversarial Networks, , arXiv preprint arXiv: 1701. 04862; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems (NIPS), pp. 1097-1105; Garg, S., Jacobson, A., Kumar, S., Milford, M., Improving condition-and environment-invariant place recognition with semantic place categorization (2017) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 6863-6870; Latif, Y., Garg, R., Milford, M., Reid, I., (2017) Addressing Challenging Place Recognition Tasks Using Generative Adversarial Networks, , arXiv preprint arXiv: 1709. 08810; Hornung, A., Wurm, K.M., Bennewitz, M., Stachniss, C., Burgard, W., OctoMap: An Efficient probabilistic 3D mapping framework based on octrees (2013) Autonomous Robots, 34 (3), pp. 189-206; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , MIT press},
  source = {Scopus},
  sponsors = {Bosch; et al.; JD.Com; Kuka; PAL Robotics; Santander},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062952780&doi=10.1109%2fIROS.2018.8593562&partnerID=40&md5=1514be492fd378c184ff696d0250624f},
}

@article{meng-et-al:2021:3062647,
  author = {Q. Meng and H. Guo and X. Zhao and D. Cao and H. Chen},
  journal = {IEEE/ASME Transactions on Mechatronics},
  title = {Loop-Closure Detection with a Multiresolution Point Cloud Histogram Mode in Lidar Odometry and Mapping for Intelligent Vehicles},
  volume = {26},
  number = {3},
  pages = {1307--1317},
  doi = {10.1109/TMECH.2021.3062647},
  note = {cited By 1},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE ASME Trans Mechatron},
  abstract = {Precise positioning is the basic condition for intelligent vehicles to complete perception, decision making and control tasks. In response to this challenge, in this article, lidar simultaneous localization and mapping (SLAM) is taken as the research object, and a SLAM system is designed that integrates motion compensation and ground information removal functions, and can construct a real-time environment map and determine its own position on the map while the vehicle is driving. A loop-closure detection method with a multiresolution point cloud histogram mode is proposed, which can effectively detect whether the vehicle passes through the same position and perform optimization to obtain globally consistent pose and map information in the urban conditions with more driving loops. We conduct experiments on the well-known KITTI dataset and compare the results with those of state-of-the-art systems. The experiments confirm that the lidar SLAM system designed in this article can provide accurate and effective positioning information for intelligent vehicles. The proposed loop-closure detection algorithm has an excellent real-time performance and accuracy, which can guarantee the long-term driving operation of these vehicles. © 1996-2012 IEEE.},
  affiliation = {State Key Laboratory of Automotive Simulation, And Control Jilin University Campus Nanling, Changchun, China},
  art_number = {9366410},
  author_keywords = {KITTI dataset;  lidar simultaneous localization and mapping (SLAM);  loop-closure detection;  multiresolution histogram;  pose estimation},
  coden = {IATEF},
  correspondence_address1 = {Meng, Q.; State Key Laboratory of Automotive Simulation, China; email: qymeng19@mails.jlu.edu.cn},
  document_type = {Article},
  funding_details = {Jilin Province Development and Reform CommissionJilin Province Development and Reform Commission, 2019C036-5},
  funding_text1 = {Manuscript received September 18, 2020; revised December 31, 2020; accepted February 12, 2021. Date of publication March 1, 2021; date of current version June 15, 2021. Recommended by Technical Editor C. Lv and Senior Editor V. Ivanov. This work was supported in part by the National Nature Science Foundation of China under Grant U19A2069 and Grant 61790563, in part by the Project of the Science and Technology Department of Jilin Province (20200401088GX, 20200501011GX), and in part by the Project of the National Development and Reform Commission of Jilin Province under Grant 2019C036-5. (Corresponding author: Hongyan Guo.) Qingyu Meng, Hongyan Guo, and Xiaoming Zhao are with the State Key Laboratory of Automotive Simulation, and Control, Jilin University (Campus Nanling), Changchun 130025, China, and also with the Department of Control Science and Engineering, Jilin University (Campus Nanling), Changchun 130025, China (e-mail: qymeng19@mails.jlu.edu.cn; guohy11@jlu.edu.cn; zhaoxm19@mails.jlu.edu.cn).},
  issn = {10834435},
  keywords = {Decision making;  Intelligent vehicle highway systems;  Mapping;  Motion compensation;  Optical radar;  SLAM robotics, Detection algorithm;  Driving operations;  Positioning information;  Precise positioning;  Real time performance;  Real-time environment;  Simultaneous localisation and mappings;  State-of-the-art system, Vehicles},
  language = {English},
  references = {Soualmi, B., Sentouh, C., Popieul, J., Debernard, S., Automation-driver cooperative driving in presence of undetected obstacles (2014) Control Eng. Pract., 24, pp. 106-119; Huang, Y., Wang, H., Khajepour, A., He, H., Ji, J., Model predictive control power management strategies for HEVs: A review (2017) J. Power Sources, 341, pp. 91-106; Lin, C.-F., Juang, J.-C., Li, K.-R., Active collision avoidance system for steering control of autonomous vehicles (2014) IET Intell. Transport Syst., 8 (6), pp. 550-557; Wen, W., Zhang, G., Hsu, L.-T., Object-detection-aided GNSS and its integration with lidar in highly urbanized areas (2020) IEEE Intell. Transp. Syst. Mag., 12 (3), pp. 53-69. , Jun; Chen, Y., Huang, S., Fitch, R., Active SLAM for mobile robots with area coverage and obstacle avoidance (2020) IEEE/ASME Trans. Mechatronics, 25 (3), pp. 1182-1192. , Jun; Tang, D., Fang, Q., Shen, L., Hu, T., Onboard detectiontracking-localization (2020) IEEE/ASME Trans. Mechatronics, 25 (3), pp. 1555-1565. , Jun; Duan, J., Shi, H., Liu, D., Yu, H., Square root cubature kalman filterkalman filter algorithm for intelligent vehicle position estimate (2016) Procedia Eng., 137 (11), pp. 267-276; Guclu, O., Can, A.B., Integrating global and local image features for enhanced loop closure detection in RGB-DSLAMsystems (2020) Vis. Comput., 36 (6), pp. 1271-1290; Memon, A.R., Wang, H., Hussain, A., Loop closure detection using supervised and unsupervised deep neural networks for monocular SLAM systems (2020) Robot. Auton. Syst., 126; Li, S.-P., Zhang, T., Gao, X., Wang, D., Xian, Y., Semi-direct monocular visual and visual-inertial SLAM with loop closure detection (2019) Robot. Auton. Syst., 112, pp. 201-210; Jo, H., Cho, H.M., Jo, S., Kim, E., Efficient grid-based raoblackwellized particle filter SLAM with interparticle map sharing (2018) IEEE/ASME Trans. Mechatronics, 23 (2), pp. 714-724. , Apr; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Trans. Robot., 31 (5), pp. 1147-1163. , Oct; Nguyen, T., Mann, G.K., Vardy, A., Gosine, R.G., CKF-based visual inertial odometry for long-term trajectory operations (2020) J. Robot., 2020, pp. 1-14; Jin, L., Zhang, H., Ye, C., Camera intrinsic parameters estimation by visual-inertial odometry for a mobile phone with application to assisted navigation (2020) IEEE/ASME Trans. Mechatronics, 25 (4), pp. 1803-1811. , Aug; Eckenhoff, K., Geneva, P., Huang, G., Closed-form preintegration methods for graph-based visual-inertial navigation (2019) Int. J. Robot. Res., 38 (5), pp. 563-586; Liu, W., Wu, S., Wu, Z., Wu, X., Incremental pose map optimization for monocular vision SLAM based on similarity transformation (2019) Sensors, 19 (22), pp. 4945-4968; Zhang, J., Singh, S., Low-drift and real-time lidar odometry and mapping (2017) Auton. Robots, 41 (2), pp. 401-416; Tomono, M., Loop detection for 3 d lidar SLAM using segment-group matching (2020) Adv. Robot., 34 (23), pp. 1530-1544; Shan, T., Englot, B., LEGO-LOAM: Lightweight and groundoptimized lidar odometry and mapping on variable terrain (2018) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 4758-4765; Röhling, T., Mack, J., Schulz, D., A fast histogram-based similarity measure for detecting loop closures in 3-d lidar data (2015) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 736-741; Dubé, R., SegMap: Segment-based mapping and localization using data-driven descriptors (2020) Int. J. Robot. Res., 39 (2-3), pp. 339-355; Schöps, T., Sattler, T., Pollefeys, M., SurfelMeshing: Online surfelbased mesh reconstruction (2020) IEEE Trans. Pattern Anal. Mach. Intell., 42 (10), pp. 2494-2507. , Oct; Lin, J., Zhang, F., Loam_livox: A fast, robust, high-precision lidar odometry and mapping package for lidars of small FoV (2020) Proc. IEEE Int. Conf. Rob. Automat. (ICRA), pp. 3126-3131; Dubé, R., Cramariuc, A., Dugas, D., Nieto, J., Siegwart, R., Cadena, C., (2018) SegMap: 3 D Segment Mapping Using Data-driven Descriptors; Zhang, J., Singh, S., Loam: Lidar odometry and mapping in real-time (2014) Robot., Sci. Syst., 2 (9), pp. 1-9; Moré, J.J., The Levenberg-Marquardt algorithm: Implementation and theory (1978) Numerical Analysis, pp. 105-116. , Berlin, Germany: Springer; Kim, M.D., Ueda, J., Dynamics-based motion deblurring improves the performance of optical character recognition during fast scanning of a robotic eye (2018) IEEE/ASME Trans. Mechatronics, 23 (1), pp. 491-495. , Feb; Neuhaus, F., Koß, T., Kohnen, R., Paulus, D., Mc2SLAM: Real-time inertial lidar odometry using two-scan motion compensation (2018) Proc. German Conf. Pattern Recognit., pp. 60-72; Song, W., Yang, Y., Fu, M., Qiu, F., Wang, M., Real-time obstacles detection and status classification for collision warning in a vehicle active safety system (2018) IEEE Trans. Intell. Transp. Syst., 19 (3), pp. 758-773. , Mar; Ortiz-Gonzalez, A., Kober, V., Karnaukhov, V., Mozerov, M., Algorithm for the design of a three-dimensional map of the environment with a depth camera (2020) J. Commun. Technol. Electron., 65 (6), pp. 690-697; Zhang, F., Gao, Y., Xu, L., An adaptive image feature matchingmethod using mixed vocabulary-kd tree (2020) Multimedia Tools Appl., 79 (23), pp. 16421-16439; Handa, A., (2014) Simplified Jacobians in 6-DoF Camera Tracking, pp. 8-18. , Univ. Cambridge, Cambridge, U. K., Tech. Rep; Wen, W., Hsu, L.-T., Zhang, G., Performance analysis of NDT-based graph SLAM for autonomous vehicle in diverse typical driving scenarios of Hong Kong (2018) Sensors, 18 (11), pp. 3928-3949; Magnusson, M., Andreasson, H., Nüchter, A., Lilienthal, A.J., Automatic appearance-based loop detection from three-dimensional laser data using the normal distributions transform (2009) J. Field Robot., 26 (11-12), pp. 892-914; McDonald, J., Kaess, M., Cadena, C., Neira, J., Leonard, J.J., Real-time 6-DoF multi-session visual SLAM over large-scale environments (2013) Robot. Auton. Syst., 61 (10), pp. 1144-1158; Lin, J., Zhang, F., (2019) A Fast, Complete, Point Cloud Based Loop Closure for Lidar Odometry and Mapping; Dellaert, F., (2012) Factor Graphs and GTSAM: A Hands-on Introduction, , Georgia Inst. Technol., Atlanta, GA, USA, Tech. Rep., report number:GTRIM-CP&R-2012-002; Grisetti, G., Kümmerle, R., Strasdat, H., Konolige, K., G2o: A. general framework for (hyper) graph optimization (2011) Proc. IEEEInt. Conf. Robot. Autom., pp. 9-13; Agarwal, S., Mierle, K., (2019) Ceres Solver-a Large Scale Non-linear Optimization Library, , http://ceres-solver.org/; Chen, L.-H., Peng, C.-C., A robust 2D-SLAM technology with environmental variation adaptability (2019) IEEE Sensors J., 19 (23), pp. 11475-11491. , Dec; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The KITTI dataset (2013) Int. J. Robot. Res., 32 (11), pp. 1231-1237; Quigley, M., ROS: An open-source robot operating system (2009) Proc. ICRA Workshop Open Source Softw., 3, pp. 5-11; Grupp, M., (2017) Evo: Python Package for the Evaluation of Odometry and SLAM, , https://github.com/MichaelGrupp/evo; Kim, G., Park, B., Kim, A., 1-day learning, 1-year localization: Longterm lidar localization using scan context image (2019) IEEE Robot. Autom. Lett., 4 (2), pp. 1948-1955. , Apr},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102292282&doi=10.1109%2fTMECH.2021.3062647&partnerID=40&md5=b228c0eaa7aa4b6916bb4c620ab72874},
}

@article{arroyo-et-al:2018:7,
  author = {R. Arroyo and P. F. Alcantarilla and L. M. Bergasa and E. Romera},
  journal = {Autonomous Robots},
  title = {Are you ABLE to perform a life-long visual topological localization?},
  volume = {42},
  number = {3},
  pages = {665--85},
  doi = {10.1007/s10514-017-9664-7},
  note = {life-long visual topological localization;dynamic elements;long-term visual place recognition;robotics community;mobile autonomous robots;robust life-long localization;cameras;ABLE;image sequence;image matching;},
  address = {Germany},
  year = {2018},
  abstract = {Visual topological localization is a process typically required by varied mobile autonomous robots, but it is a complex task if long operating periods are considered. This is because of the appearance variations suffered in a place: dynamic elements, illumination or weather. Due to these problems, long-term visual place recognition across seasons has become a challenge for the robotics community. For this reason, we propose an innovative method for a robust and efficient life-long localization using cameras. In this paper, we describe our approach (ABLE), which includes three different versions depending on the type of images: monocular, stereo and panoramic. This distinction makes our proposal more adaptable and effective, because it allows to exploit the extra information that can be provided by each type of camera. Besides, we contribute a novel methodology for identifying places, which is based on a fast matching of global binary descriptors extracted from sequences of images. The presented results demonstrate the benefits of using ABLE, which is compared to the most representative state-of-the-art algorithms in long-term conditions.},
  copyright = {Copyright 2018, The Institution of Engineering and Technology},
  issn = {0929-5593},
  keywords = {image matching;image sequences;mobile robots;robot dynamics;robot vision;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1007/s10514-017-9664-7},
}

@article{mur-artal-et-al:2015:2463671,
  author = {R. Mur-Artal and J. M. M. Montiel and J. D. Tardos},
  journal = {IEEE Transactions on Robotics},
  title = {ORB-SLAM: A Versatile and Accurate Monocular SLAM System},
  volume = {31},
  number = {5},
  pages = {1147--1163},
  doi = {10.1109/TRO.2015.2463671},
  note = {cited By 3399},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2015},
  abbrev_source_title = {IEEE Trans. Rob.},
  abstract = {This paper presents ORB-SLAM, a feature-based monocular simultaneous localization and mapping (SLAM) system that operates in real time, in small and large indoor and outdoor environments. The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization. Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks: tracking, mapping, relocalization, and loop closing. A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets. ORB-SLAM achieves unprecedented performance with respect to other state-of-the-art monocular SLAM approaches. For the benefit of the community, we make the source code public. © 2004-2012 IEEE.},
  affiliation = {Instituto de Investigacion en Ingenieria de Aragon, Universidad de Zaragoza, Zaragoza, 50018, Spain},
  art_number = {7219438},
  author_keywords = {Lifelong mapping;  localization;  monocular vision;  recognition;  Simultaneous localization and mapping (SLAM)},
  document_type = {Article},
  issn = {15523098},
  keywords = {Mapping;  Robotics;  Vision, Automatic initialization;  localization;  Monocular vision;  Outdoor environment;  recognition;  Simultaneous localization and mapping;  State of the art;  Survival-of-the-Fittest, Indoor positioning systems},
  language = {English},
  references = {Triggs, B., McLauchlan, P.F., Hartley, R.I., Fitzgibbon, A.W., Bundle adjustment a modern synthesis (2000) Vision Algorithms: Theory and Practice, pp. 298-372. , New York, NY, USA: Springer; Hartley, R., Zisserman, A., (2004) Multiple View Geometry in Computer Vision, 2nd Ed, , Cambridge, U. K. : Cambridge Univ. Press; Mouragnon, E., Lhuillier, M., Dhome, M., Dekeyser, F., Sayd, P., Real time localization and 3D reconstruction (2006) Proc. IEEE Comput. Soc. Conf. Comput. Vision Pattern Recog., 1, pp. 363-370; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) Proc. IEEE ACM Int. Symp. Mixed Augmented Reality, Nara, Japan, pp. 225-234. , Nov; Gálvez-López, D., Tardós, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197. , Oct; Strasdat, H., Montiel, J.M.M., Davison, A.J., Scale drift-aware large scale monocular SLAM (2010) Proc. Robot.:Sci. Syst., Zaragoza, Spain, , Jun; Strasdat, H., Davison, A.J., Montiel, J.M.M., Konolige, K., Double window optimisation for constant time visual SLAM (2011) Proc. IEEE Int. Conf. Comput. Vision, Barcelona, Spain, pp. 2352-2359. , Nov; Mei, C., Sibley, G., Newman, P., Closing loops without places (2010) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Taipei, Taiwan, pp. 3738-3744. , Oct; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) Proc. IEEE Int. Conf. Comput. Vision, Barcelona, Spain, pp. 2564-2571. , Nov; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Large-scale direct monocular SLAM (2014) Proc. Eur. Conf. Comput. Vision, Zurich, Switzerland, pp. 834-849. , Sep; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based SLAM (2014) Proc. IEEE Int. Conf. Robot. Autom. , Hong Kong, pp. 846-853. , Jun; Mur-Artal, R., Tardós, J.D., ORB-SLAM: Tracking and mapping recognizable features (2014) MVIGRO Workshop Robot. Sci. Syst., , Berkeley, CA, USA Jul; Williams, B., Cummins, M., Neira, J., Newman, P., Reid, I., Tardós, J.D., A comparison of loop closing techniques in monocular SLAM (2009) Robot. Auton. Syst., 57 (12), pp. 1188-1197; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree (2006) Proc. IEEE Comput. Soc. Conf. Comput. Vision Pattern Recog., 2, pp. 2161-2168. , New York, NY, USA, Jun; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2. 0 (2011) Int. J. Robot. Res., 30 (9), pp. 1100-1123; Calonder, M., Lepetit, V., Strecha, C., Fua, P., BRIEF: Binary robust independent elementary features (2010) Proc. Eur. Conf. Comput. Vision, Hersonissos, Greece, pp. 778-792. , Sep; Rosten, E., Drummond, T., Machine learning for high-speed corner detection (2006) Proc. Eur. Conf. Comput. Vision, Graz, Austria, pp. 430-443. , May; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) Proc. Eur. Conf. Comput. Vision, Graz, Austria, pp. 404-417. , May; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vision, 60 (2), pp. 91-110; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Trans. Pattern Anal. Mach. Intell., 29 (6), pp. 1052-1067. , Jun; Civera, J., Davison, A.J., Montiel, J.M.M., Inverse depth parametrization for monocular SLAM (2008) IEEE Trans. Robot., 24 (5), pp. 932-945. , Oct; Forster, C., Pizzoli, M., Scaramuzza, D., SVO: Fast semi-direct monocular visual odometry (2014) Proc. IEEE Int. Conf. Robot. Autom. ,HongKong, pp. 15-22. , Jun; Faugeras, O.D., Lustman, F., Motion and structure from motion in a piecewise planar environment (1988) Int. J. Pattern Recog. Artif. Intell., 2 (3), pp. 485-508; Tan, W., Liu, H., Dong, Z., Zhang, G., Bao, H., Robust monocularSLAM in dynamic environments (2013) Proc. IEEE Int. Symp. Mixed Augmented Reality, pp. 209-218. , Adelaide, Australia, Oct; Lim, H., Lim, J., Kim, H.J., Real-time 6-DOF monocular visual SLAM in a large-scale environment (2014) Proc. IEEE Int. Conf. Robot. Autom. , Hong Kong, pp. 1532-1539. , Jun; Nistér, D., An efficient solution to the five-point relative pose problem (2004) IEEE Trans. Pattern Anal. Mach. Intell., 26 (6), pp. 756-770. , Jun; Longuet-Higgins, H., The reconstruction of a plane surface from two perspective projections (1986) Proc. Royal Soc. London Ser. B, Biol, Sci., 227 (1249), pp. 399-410; Torr, P.H., Fitzgibbon, A.W., Zisserman, A., The problem of degeneracy in structure and motion recovery from uncalibrated image sequences (1999) Int. J. Comput. Vision, 32 (1), pp. 27-44; Chiuso, A., Favaro, P., Jin, H., Soatto, S., Structure frommotion causally integrated over time (2002) IEEE Trans. Pattern Anal. Mach. Intell., 24 (4), pp. 523-535. , Apr; Eade, E., Drummond, T., Scalable monocular SLAM (2006) Proc. IEEE Comput. Soc. Conf. Comput. Vision Pattern Recog., 1, pp. 469-476. , New York, NY, USA, Jun; Strasdat, H., Montiel, J.M.M., Davison, A.J., Visual SLAM: Why filter? (2012) Image Vision Comput., 30 (2), pp. 65-77; Klein, G., Murray, D., Improving the agility of keyframe-based SLAM (2008) Proc. Eur. Conf. Comput. Vision,Marseille, France, pp. 802-815. , Oct; Pirker, K., Ruther, M., Bischof, H., CD SLAM-continuous localization and mapping in a dynamic world (2011) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 3990-3997. , San Francisco, CA, USA, Sep; Song, S., Chandraker, M., Guest, C.C., Parallel, real-time monocular visual odometry (2013) Proc. IEEE Int. Conf. Robot. Autom., pp. 4698-4705; Alcantarilla, P.F., Nuevo, J., Bartoli, A., Fast explicit diffusion for accelerated features in nonlinear scale spaces (2013) Brit. Mach. Vision Conf., , Bristol, U. K; Yang, X., Cheng, K.-T., LDB: An ultra-fast feature for scalable augmented reality on mobile devices (2012) Proc. IEEE Int. Symp. Mixed Augmented Reality, pp. 49-57; Kuemmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proc. IEEE Int. Conf. Robot. Autom. , Shanghai, China, pp. 3607-3613. , May; Sturm, J., Engelhard, N., Endresw. Burgard, F., Cremers, D., A benchmark for the evaluation of RGB-DSLAMsystems (2012) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 573-580. , Vilamoura, Portugal, Oct; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) Int. J. Robot. Res., 28 (5), pp. 595-599; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: The KITTI dataset (2013) Int. J. Robot. Res., 32 (11), pp. 1231-1237; Lepetit, V., Moreno-Noguer, F., Fua, P., EPnP: An accurate O(n) solution to the PnP problem (2009) Int. J. Comput. Vision, 81 (2), pp. 155-166; Horn, B.K.P., Closed-form solution of absolute orientation using unit quaternions (1987) J. Opt. Soc. Amer. A, 4 (4), pp. 629-642; Endres, F., Hess, J., Sturm, J., Cremers, D., Burgard, W., 3-D mapping with an RGB-D camera (2014) IEEE Trans. Robot., 30 (1), pp. 177-187. , Feb; Newcombe, R.A., Lovegrove, S.J., Davison, A.J., DTAM: Dense tracking and mapping in real-time (2011) Proc. IEEE Int. Conf. Comput. Vision, Barcelona, Spain, pp. 2320-2327. , Nov; Lovegrove, S., Davison, A.J., Ibanez-Guzmán, J., Accurate visual odometry from a rear parking camera (2011) Proc. IEEE Intell. Vehicles Symp., pp. 788-793; Torr, P.H., Zisserman, A., Feature based methods for structure and motion estimation (2000) Vision Algorithms: Theory and Practice, pp. 278-294. , NewYork, NY, USA: Springer; Mur-Artal, R., Tardos, J.D., Probabilistic semi-dense mapping from highly accurate feature-based monocular SLAM (2015) Proc. Robot. : Sci. Syst. , Rome, Italy, , Jul; Strasdat, H., (2012) Local Accuracy and Global Consistency for Efficient Visual SLAM, , Ph. D. dissertation Imperial College London, London, U. K Oct},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988339174&doi=10.1109%2fTRO.2015.2463671&partnerID=40&md5=4b4977ad9316c26565f7ec3db1348c31},
}

@article{paul-newman:2013:0278364913509859,
  author = {R. Paul and P. Newman},
  journal = {International Journal of Robotics Research},
  title = {Self-help: Seeking out perplexing images for ever improving topological mapping},
  volume = {32},
  number = {14},
  pages = {1742--1766},
  doi = {10.1177/0278364913509859},
  note = {cited By 3},
  year = {2013},
  abbrev_source_title = {Int J Rob Res},
  abstract = {In this work, we present a novel approach that allows a robot to improve its own navigation performance through introspection and then targeted data retrieval. It is a step in the direction of life-long learning and adaptation and is motivated by the desire to build robots that have plastic competencies which are not baked in. They should react to and benefit from use. We consider a particular instantiation of this problem in the context of place recognition. Based on a topic-based probabilistic representation for images, we use a measure of perplexity to evaluate how well a working set of background images explain the robot's online view of the world. Offline, the robot then searches an external resource to seek out additional background images that bolster its ability to localize in its environment when used next. In this way the robot adapts and improves performance through use. We demonstrate this approach using data collected from a mobile robot operating in outdoor workspaces. © The Author(s) 2013.},
  affiliation = {Oxford University Mobile Robotics Research Group, United Kingdom},
  author_keywords = {Life-long learning;  perplexity;  topic models;  topological mapping},
  coden = {IJRRE},
  correspondence_address1 = {Paul, R.; Robotics Research Group, Parks Road, Oxford, OX1 3PJ, United Kingdom; email: rohanp@robots.ox.ac.uk},
  document_type = {Article},
  funding_details = {Engineering and Physical Sciences Research CouncilEngineering and Physical Sciences Research Council, EPSRC, EP/I005021/1},
  issn = {02783649},
  keywords = {External resources;  Life long learning;  Navigation performance;  perplexity;  Place recognition;  Probabilistic representation;  Topic model;  Topological mapping, Topology, Robots},
  language = {English},
  references = {Angeli, A., Filliat, D., Doncieux, S., Meyer, J., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Transactions on Robotics, Special Issue on Visual SLAM, 24 (5), pp. 1027-1037; Banerjee, A., Basu, S., Topic models over text streams: A study of batch and online unsupervised learning Proceedings of the Seventh SIAM International Conference on Data Mining; Bay, H., Tuytelaars, T., Van Gool, L., Surf: Speeded up robust features Computer Vision-ECCV 2006; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots Proceedings of Robotics: Science and Systems (RSS); Blei, D., Lafferty, J., A correlated topic model of science (2007) The Annals of Applied Statistics, 1 (1), pp. 17-35; Blei, D., Ng, A., Jordan, M., Latent Dirichlet allocation (2003) The Journal of Machine Learning Research, 3, pp. 993-1022; Boiman, O., Irani, M., Detecting irregularities in images and in video (2007) International Journal of Computer Vision, 74 (1), pp. 17-31; Boyd-Graber, J., Blei, D., Syntactic topic models (2010) Arxiv Preprint ArXiv, 1002, p. 4665; Churchill, W., Newman, P., Practice makes perfect managing and leveraging visual experiences for lifelong navigation 2012 IEEE International Conference on Robotics and Automation (ICRA); Cummins, M., Newman, P., Probabilistic appearance based navigation and loop closing 2007 IEEE International Conference on Robotics and Automation; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2011) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Cussens, J., Bayes and pseudo-Bayes estimates of conditional probabilities and their reliability Machine Learning: ECML-93; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots 2008 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Endres, F., Plagemann, C., Stachniss, C., Burgard, W., (2009) Proceedings of Robotics: Science and Systems, p. 34. , USA: Seattle;; Fei-Fei, L., Perona, P., A Bayesian hierarchical model for learning natural scene categories 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR); Girdhar, Y., Dudek, G., Online navigation summaries 2010 IEEE International Conference on Robotics and Automation (ICRA); Girdhar, Y., Dudek, G., Onsum: A system for generating online navigation summaries Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Girdhar, Y., Giguere, P., Dudek, G., Autonomous adaptive underwater exploration using online topic modelling International Symposium on Experimental Robotics; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., FAB-MAP+ RatSLAM: Appearance-based SLAM for multiple times of day 2010 IEEE International Conference on Robotics and Automation (ICRA); Griffiths, T., Steyvers, M., Finding scientific topics (2004) Proceedings of the National Academy of Sciences of the United States of America, 101, p. 5228; Heinrich, G., (2005) Parameter Estimation for Text Analysis, , http://www.arbylon.net/publications/text-est.pdf, URL; Hendel, A., Weinshall, D., Peleg, S., Identifying surprising events in videos using Bayesian topic models Computer Vision-ACCV 2010; Ho, K., Newman, P., Detecting loop closure with scene sequences (2007) International Journal of Computer Vision, 74 (3), pp. 261-286; Hoffman, M., Blei, D., Bach, F., Online learning for latent Dirichlet allocation (2010) Advances in Neural Information Processing Systems, 23, pp. 856-864; Hoi, S., Jin, R., Zhu, J., Lyu, M., Batch mode active learning and its application to medical image classification Proceedings of the 23rd International Conference on Machine Learning; Holub, A., Perona, P., Burl, M., Entropy-based active learning for object recognition 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW); Horster, E., Lienhart, R., Slaney, M., Image retrieval on large-scale image databases Proceedings of the 6th ACM International Conference on Image and Video Retrieval; Hospedales, T., Gong, S., Xiang, T., Finding rare classes: Active learning with generative and discriminative models (2011) IEEE Transactions on Knowledge and Data Engineering, (99), pp. 1-1; Itti, L., Baldi, P., A principled approach to detecting surprising events in video 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR); Joho, D., Tipaldi, G.D., Engelhard, N., Stachniss, C., Burgard, W., Nonparametric Bayesian models for unsupervised scene analysis and reconstruction Proceedings of Robotics: Science and Systems (RSS); Joshi, A., Porikli, F., Papanikolopoulos, N., Multi-class active learning for image classification 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Kapoor, A., Grauman, K., Urtasun, R., Darrell, T., Gaussian processes for object categorization (2010) International Journal of Computer Vision, 88 (2), pp. 169-188; Konolige, K., Bowman, J., Towards lifelong visual maps 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Konolige, K., Bowman, J., Chen, J., Mihelich, P., Calonder, M., Lepetit, V., Fua, P., View-based maps (2010) The International Journal of Robotics Research, 29 (8), pp. 941-957; Lavrenko, V., (2009) A Generative Theory of Relevance, , New York: Springer-Verlag;; Lawrence, N., Seeger, M., Herbrich, R., Fast sparse Gaussian process methods: The informative vector machine (2002) Advances in Neural Information Processing Systems, pp. 609-616; Levin, A., Szeliski, R., Visual odometry and map correlation Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR); Liu, X., Croft, W., Cluster-based retrieval using language models Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Lowe, D., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Mackay, D., Peto, L., A hierarchical Dirichlet language model (1995) Natural Language Engineering, 1 (3), pp. 1-19; Maddern, W., Milford, M., Wyeth, G., CAT-SLAM: Probabilistic localisation and mapping using a continuous appearance-based trajectory (2012) The International Journal of Robotics Research, 31 (4), pp. 429-451; Manning, C., Raghavan, P., Schutze, H., (2008) Introduction to Information Retrieval, , Cambridge: Cambridge University Press;; Mei, C., Sibley, G., Newman, P., Closing loops without places 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired SLAM system (2010) The International Journal of Robotics Research, 29 (9), pp. 1131-1153; Murillo, A.C., Kosecka, J., Experiments in place recognition using gist panoramas 2009 IEEE 12th International Conference on Computer Vision Workshops (ICCV Workshops); Paul, R., Newman, P., FAB-MAP 3D: Topological mapping with spatial and visual appearance 2010 IEEE International Conference on Robotics and Automation (ICRA); Paul, R., Newman, P., Self help: Seeking out perplexing images for ever improving navigation 2011 IEEE International Conference on Robotics and Automation (ICRA); Philbin, J., Sivic, J., Zisserman, A., Geometric LDA: A generative model for particular object discovery Proceedings of the British Machine Vision Conference (BMVC); Ranganathan, A., Dellaert, F., Bayesian surprise and landmark detection 2009 IEEE International Conference on Robotics and Automation (ICRA); Seeger, M., Williams, C., Lawrence, N., Fast forward selection to speed up sparse Gaussian process regression Ninth International Workshop on AI and Statistics; Settles, B., (2010) Active Learning Literature Survey, , Madison, USA: University of Wisconsin;; Silpa-Anan, C., Hartley, R., Localisation using an image-map Proceedings of the Australian Conference on Robotics and Automation; Silpa-Anan, C., Hartley, R., Optimised kd-trees for fast image descriptor matching 2008 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Singh, G., Kosecka, J., Visual loop closing using gist descriptors in manhattan world Omnidirectional Robot Vision Workshop, with IEEE International Conference on Robotics and Automation (ICRA); Sivic, J., Russell, B., Zisserman, A., Freeman, W., Efros, A., Unsupervised discovery of visual object class hierarchies 2008 IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Sivic, J., Zisserman, A., Video google: A text retrieval approach to object matching in videos Proceedings of Ninth IEEE International Conference on Computer Vision; Tellex, S., Thaker, P., Roy, N., Toward information theoretic human-robot dialog Proceedings of Robotics: Science and Systems; Teh, Y., Jordan, M., Beal, M., Blei, D., Hierarchical Dirichlet processes (2006) Journal of the American Statistical Association, 101 (476), pp. 1566-1581; Valgren, C., Lilienthal, A., Sift, surf and seasons: Long-term outdoor localization using local features Proceedings of the European Conference on Mobile Robots (ECMR); Varadarajan, J., Odobez, J., Topic models for scene analysis and abnormality detection IEEE 12th International Conference on Computer Vision Workshops (ICCV Workshops); Wallach, H., Topic modeling: Beyond bag-of-words Proceedings of the 23rd International Conference on Machine Learning; Wang, C., Blei, D., Li, F., Simultaneous image classification and annotation IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Wang, C., Paisley, J., Blei, D., Online variational inference for the hierarchical Dirichlet process Proceedings of Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS); Wang, X., Grimson, E., Spatial latent Dirichlet allocation (2007) Advances in Neural Information Processing Systems, 20, pp. 1577-1584; Wang, X., Ma, X., Grimson, W., Unsupervised activity perception in crowded and complicated scenes using hierarchical Bayesian models (2009) IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (3), pp. 539-555; Wei, X., Croft, W., LDA-based document models for ad-hoc retrieval Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Zhai, C., Lafferty, J., A study of smoothing methods for language models applied to ad hoc information retrieval Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Zhang, Y., Callan, J., Minka, T., Novelty and redundancy detection in adaptive filtering Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Zhu, J., Xing, E.P., Conditional topic random fields International Conference on Machine Learning (ICML)},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892570749&doi=10.1177%2f0278364913509859&partnerID=40&md5=ae84e124e6511bb39915fcda8cfb006d},
}

@article{griffith-pradalier:2017:21664,
  author = {S. Griffith and C. Pradalier},
  journal = {Journal of Field Robotics},
  title = {Survey Registration for Long-Term Natural Environment Monitoring},
  volume = {34},
  number = {1},
  pages = {188--208},
  doi = {10.1002/rob.21664},
  note = {cited By 6},
  publisher = {John Wiley and Sons Inc.},
  year = {2017},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {This paper presents a survey registration framework to assist in the recurrent inspection of a natural environment. Our framework coarsely aligns surveys at the image-level using visual simultaneous localization and mapping (SLAM), and it registers images at the pixel-level using SIFT Flow, which enables rapid manual inspection. The variation in appearance of natural environments makes data association a primary challenge of this work. We discuss this and other challenges, including 1) alternative approaches for coarsely aligning surveys of a natural environment, 2) how to select which images to compare between two surveys, and 3) strategies to boost image registration accuracy. We evaluate each stage of our approach, emphasizing alignment accuracy and stability with respect to large seasonal variations. Our domain is lakeshore monitoring, in which an autonomous surface vessel surveyed a 1-km lakeshore 33 times in 14 months. Our results show that our framework precisely aligns a significant number of images between surveys captured up to roughly three months apart, often across marked variation in appearance. Using these results, a human was able to spot several changes between surveys that would have otherwise gone unnoticed. © 2016 Wiley Periodicals, Inc.},
  affiliation = {GeorgiaTech Lorraine-UMI 2958 GT-CNRS, France},
  document_type = {Article},
  issn = {15564959},
  keywords = {Robotics, Alignment accuracy;  Autonomous surface vessels;  Data association;  Manual inspection;  Natural environments;  Registration accuracy;  Seasonal variation;  Visual simultaneous localization and mappings, Surveys},
  language = {English},
  references = {Bargoti, S., Underwood, J.P., Nieto, J.I., Sukkarieh, S., A pipeline for trunk detection in trellis structured apple orchards (2015) Journal of Field Robotics, 32 (8), pp. 1075-1094; Beall, C., Dellaert, F., Appearance-based localization across seasons in a Metric Map (2014) 6th PPNIV, September 14, 2014, , In, Chicago, USA; Bradski, G., The OpenCV Library (2000) Dr. Dobb's Journal of Software Tools, , www.drdobbs.com, published online at, URL; Cabrol, N., Grin, E., Haberle, C., Moersch, J., Jacobsen, R., Sommaruga, R., Fleming, E., Blanco, Y., Planetary lake lander: Using technology relevant to Titan's exploration to investigate the impact of deglaciation on past and present planetary lakes (2012) Proc. Lunar and Planetary Sci. Conf. (LPSC), , The Woodlands, Texas; Carlone, L., Dong, J., Fenu, S., Rains, G.C., Dellaert, F., Towards 4D crop analysis in precision agriculture: Estimating plant height and crown radius over time via expectation-maximization (2015) ICRA Workshop on Robotics in Agriculture, , In, May, 2015, Seattle, Washington; Carlone, L., Kira, Z., Beall, C., Indelman, V., Dellaert, F., Eliminating conditionally independent sets in factor graphs: A unifying perspective based on smart factors (2014) IEEE International Conference on Robotics and Automation (ICRA), , In, Hong Kong, China, May, 2014; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) IJRR, 32 (14), pp. 1645-1661; Chvatal, V., A greedy heuristic for the set-covering problem (1979) Mathematics of Operations Research, 4 (3), pp. 233-235; Corke, P., Paul, R., Churchill, W., Newman, P., Dealing with shadows: Capturing intrinsic scene appearance for image-based outdoor localization (2013) IROS, pp. 2085-2092. , In, IEEE; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) International Journal of Robotics Research, 27 (6), pp. 647-665; Dellaert, F., Factor graphs and GTSAM: A hands-on introduction (2012) Technical Report GT-RIM-CP&R-2012-002, GT RIM; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Large-scale direct monocular SLAM (2014) Computer Vision–ECCV, pp. 834-849. , In, September, 2014, (, Springer, Zurich; Giusti, A., Guzzi, J., Ciresan, D., He, F.-L., Rodriguez, J.P., Fontana, F., Faessler, M., Di Caro, G., A machine learning approach to visual perception of forest trails for mobile robots (2015) IEEE Robotics and Automation Letters, (2), pp. 661-667. , July, 2016,1; Griffith, S., Dellaert, F., Pradalier, C., Robot-enabled lakeshore monitoring Using Visual SLAM and SIFT Flow (2015) RSS Workshop on Multi-View Geometry in Robotics, , In, July, 2015, Rome, Italy; Griffith, S., Drews, P., Pradalier, C., Towards autonomous lakeshore monitoring (2014) International Symposium on Experimental Robotics (ISER), , In, Marrakesh, Morocco, June, 2014; Griffith, S., Pradalier, C., A spatially and temporally scalable approach for long-term lakeshore monitoring (2015) International Conf. on Field and Service Robotics, , In, June, 2015, Montreal, Canada; Gu, J., Ramamoorthi, R., Belhumeur, P., Nayar, S., Removing image artifacts due to dirty camera lenses and thin occluders (2009) ACM Transactions on Graphics (TOG), 28 (5), p. 144; He, X., Zemel, R., Mnih, V., Topological map learning from outdoor image sequences (2006) JFR, 23 (11-12), pp. 1091-1104; Heidarsson, H., Sukhatme, G., Obstacle detection from overhead imagery using self-supervised learning for autonomous surface vehicles (2011) IROS, pp. 3160-3165. , In, IEEE, San Francisco, California; Hitz, G., Gotovos, A., Pomerleau, F., Garneau, M.-E., Pradalier, C., Krause, A., Siegwart, R.Y., Fully autonomous focused exploration for robotic environmental monitoring (2014) IEEE International Conference on Robotics and Automation (ICRA), pp. 2658-2664. , a)., In, IEEE, Hong Kong, China; Hitz, G., Pomerleau, F., Colas, F., Siegwart, R., State estimation for shore monitoring using an autonomous surface vessel (2014) International Symposium on Experimental Robotics (ISER), , b)., In, June, 2014, Marrakesh, Morocco; Jain, S., Nuske, S.T., Chambers, A.D., Yoder, L., Cover, H., Chamberlain, L.J., Scherer, S., Singh, S., Autonomous river exploration (2013) Field and Service Robotics, , In, December, 2013, Brisbane, Australia; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., (2014) Caffe: Convolutional architecture for fast feature embedding, , arXiv preprint arXiv1408.5093; Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J.J., Dellaert, F., iSAM2: Incremental smoothing and mapping using the Bayes tree (2012) IJRR, 31 (2), pp. 216-235; Kim, J., Liu, C., Sha, F., Grauman, K., Deformable spatial pyramid matching for fast dense correspondences (2013) Computer Vision and Pattern Recognition (CVPR), pp. 2307-2314. , In, Portland, Oregon, (,). IEEE; Košecka, J., Detecting changes in images of street scenes (2013) Computer Vision–ACCV 2012, volume 7727 of LNCS, pp. 590-601. , In, Springer, Berlin; Krajnik, T., Santos, J.M., Duckett, T., Life-long spatio-temporal exploration of dynamic environments (2015) Mobile Robots (ECMR), 2015 European Conference on September, 2015, pp. 1-8. , In, IEEE, Lincoln, UK; Kularatne, D., Hsieh, A., Tracking attracting Lagrangian coherent structures in flows (2015) Proceedings of Robotics: Science and Systems, , In, July, 2015, Rome, Italy; Kwatra, V., Schödl, A., Essa, I., Turk, G., Bobick, A., Graphcut textures: Image and video synthesis using graph cuts (2003) ACM Transactions on Graphics (ToG), 22, pp. 277-286. , In, volume, ACM, New York, NY; Liu, C., Yuen, J., Torralba, A., SIFT Flow: Dense correspondence across scenes and its applications (2011) PAMI, 33 (5), pp. 978-994; Lowe, D., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Lucas, B.D., Kanade, T., An iterative image registration technique with an application to stereo vision (1981) In IJCAI, August 24-28, 1981, Vancouver, British Columbia, volume 81, pp. 674-679; Martin-Brualla, R., Gallup, D., Seitz, S.M., Time-lapse mining from Internet photos (2015) ACM Transactions on Graphics (TOG), 34 (4), p. 62; McManus, C., Upcroft, B., Newman, P., Scene signatures: Localized and point-less features for localization (2014) RSS, , In, Berkeley, USA; Milford, M., Firn, J., Beattie, J., Jacobson, A., Pepperell, E., Mason, E., Kimlin, M., Dunbabin, M., Automated sensory data alignment for environmental and epidermal change monitoring (2014) Australasian Conference on Robotics and Automation 2014, pp. 1-10. , In, Australian Robotic and Automation Association, Melbourne, Australia; Milford, M.J., Wyeth, G.F., SeqSLAM : Visual route-based navigation for sunny summer days and stormy winter nights (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference on, pp. 1643-1649. , In, IEEE, St. Paul, Minnesota; Milford, M.J., Wyeth, G.F., Rasser, D., RatSLAM : A hippocampal model for simultaneous localization and mapping (2004) Robotics and Automation, 2004. Proceedings. ICRA'04. 2004 IEEE International Conference on, 1, pp. 403-408. , In, volume, IEEE, New Orleans, Louisiana; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual SLAM across seasons (2015) Intelligent Robotics and Systems IROS, pp. 2529-2535. , September, 2015, Hamburg, Germany; Nelson, P., Churchill, W., Posner, I., Newman, P., From Dusk till Dawn: Localisation at Night using Artificial Light Sources (2015) ICRA, , In, Seattle, Washington; Neubert, P., Sünderhauf, N., Protzel, P., Superpixel-based appearance change prediction for long-term navigation across seasons (2014) RAS, pp. 15-27. , In,), 2015; Shi, J., Tomasi, C., Good features to track (1994) Computer Vision and Pattern Recognition, 1994. Proceedings CVPR'94, 1994 IEEE Computer Society Conference on, pp. 593-600. , In,). IEEE,, Seattle, Washington; Subramanian, A., Gong, X., Riggins, J., Stilwell, D., Wyatt, C., Shoreline mapping using an omni-directional camera for autonomous surface vehicle applications (2006) OCEANS, pp. 1-6. , In, IEEE, Singapore; Sünderhauf, N., Dayoub, F., Shirazi, S., Upcroft, B., Milford, M., (2015) On the performance of ConvNET features for place recognition, , arXiv preprint arXiv1501.04158, Singapore; Sünderhauf, N., Neubert, P., Protzel, P., Are we there yet? challenging SeqSLAM on a 3000 km journey across all four seasons (2013) In Proc. of Workshop on Long-Term Autonomy, IEEE International Conference on Robotics and Automation (ICRA), May, 2013. Citeseer, , Karlsruhe, Germany; Sunderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with ConvNET landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proceedings of Robotics: Science and Systems XII, , July, 2015,, Rome, Italy; Wang, O., Schroers, C., Zimmer, H., Gross, M., Sorkine-Hornung, A., VideoSnapping: Interactive Synchronization of Multiple Videos (2014) ACM Trans. Graph., 33 (4), pp. 77:1-77:10; Yang, H., Lin, W.-Y., Lu, J., Daisy filter flow: A generalized discrete approach to dense correspondences (2014) 2014 IEEE conference on computer vision and pattern recognition, pp. 3406-3413. , In,). IEEE; Zhou, B., Lapedriza, A., Xiao, J., Torralba, A., Oliva, A., Learning deep features for scene recognition using places database (2014) Advances in Neural Information Processing Systems 27, pp. 487-495. , In, Ghahramani, Z., Welling, M., Cortes, C., Lawrence, N., #x0026;, Weinberger, K., (eds.),,). Curran Associates, Montreal, Canada},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978300256&doi=10.1002%2frob.21664&partnerID=40&md5=8f24475aa12c1a445ba7ae2aa797e1a7},
}

@conference{hochdorfer-schlegel:2009,
  author = {S. Hochdorfer and C. Schlegel},
  journal = {2009 International Conference on Advanced Robotics, ICAR 2009},
  title = {Towards a robust visual SLAM approach: Addressing the challenge of life-long operation},
  pages = {1--6},
  note = {cited By 12; Conference of 2009 International Conference on Advanced Robotics, ICAR 2009 ; Conference Date: 22 June 2009 Through 26 June 2009;  Conference Code:78376},
  address = {Munich},
  year = {2009},
  abbrev_source_title = {Int. Conf. Adv. Rob., ICAR},
  abstract = {Localization and mapping are fundamental problems in service robotics. Knowledge about the own pose and representations of the environment are needed for a series of high level applications. Service robots should be designed for life-long and robust operation in dynamic environments. The contribution of this paper is twofold. First, an approach to address the ever growing number of landmarks in life-long operation is presented. Typically, SLAM approaches just accumulate features over time and do not discard them anymore. Therefore, the required resources in terms of memory and processing power are growing over time. In our approach, the absolute number of landmarks can be restricted by an upper bound since we introduce a method to specifically select and replace landmarks once the upper bound has been reached. The second contribution is related to improving the robustness of the landmark assignment problem in case of image based features as needed with natural landmarks. The approach has been successfully evaluated in a real world experiment on a Pioneer-3DX platform within a complex unmodified indoor environment.},
  affiliation = {Department of Computer Science, University of Applied Sciences Ulm, 89075 Ulm, Germany},
  art_number = {5174794},
  correspondence_address1 = {Hochdorfer, S.; Department of Computer Science, , 89075 Ulm, Germany; email: hochdorfer@hs-ulm.de},
  document_type = {Conference Paper},
  isbn = {9781424448555},
  keywords = {Absolute number;  Assignment problems;  Dynamic environments;  Fundamental problem;  High level applications;  Image-based features;  Indoor environment;  Natural landmark;  Processing power;  Real world experiment;  Robust operation;  Service robotics;  Service robots;  SLAM approach;  Upper Bound;  Visual SLAM, Robotics, Robots},
  language = {English},
  references = {Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) 9th European Conference on Computer Vision, , Graz Austria, May; Bailey, T., Constrained initialisation for bearing-only SLAM (2003) IEEE International Conference on Robotics and Automation (ICRA), 2, pp. 1966-1971. , Sept; Schlegel, C., Hochdorfer, S., (2008) Service Robotics, pp. 253-278. , ITECH, ISBN 978-3-902613-29-5, ch. Localization and Mapping for Service Robots: Bearing-Only SLAM with an Omnicam; Strasdat, H., Stachniss, C., Bennewitz, M., Burgard, W., Visual bearing-only simultaneous localization and mapping with improved feature matching (2007) AMS, pp. 15-21. , ser. Informatik Aktuell, K. Berns and T. Luksch, Eds. Springer; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (6), pp. 1052-1067; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60, pp. 91-110; Maksarov, D., Durrant-Whyte, H., Mobile vehicle navigation in unknown environments: A multiple hypothesis approach (1995) IEEE Proceedings - Control Theory and Applications, 142 (4), pp. 385-400. , Jul; Dissanayake Gamini, Durrant-Whyte Hugh, Bailey Tim, Computationally efficient solution to the simultaneous localisation and map building (SLAM) problem (2000) Proceedings - IEEE International Conference on Robotics and Automation, 2, pp. 1009-1014; Bentley, J.L., Multidimensional binary search trees used for associative searching (1975) Commun. ACM, 18 (9), pp. 509-517; Kiang, K.-M., Willgoss, R., Blair, A., Distinctness analysis on natural landmark descriptors (2006) Field and Service Robotics, 25, pp. 67-78. , ser. Springer Tracts in Advanced Robotics, P. I. Corke and S. Sukkarieh, Eds., Springer},
  source = {Scopus},
  url = {https://ieeexplore.ieee.org/document/5174794},
}

@conference{hochdorfer-et-al:2009:5339626,
  author = {S. Hochdorfer and M. Lutz and C. Schlegel},
  journal = {2009 IEEE International Conference on Technologies for Practical Robot Applications, TePRA 2009},
  title = {Lifelong localization of a mobile service-robot in everyday indoor environments using omnidirectional vision},
  pages = {161--166},
  doi = {10.1109/TEPRA.2009.5339626},
  note = {cited By 5; Conference of 2009 IEEE International Conference on Technologies for Practical Robot Applications, TePRA 2009 ; Conference Date: 9 November 2009 Through 10 November 2009;  Conference Code:78905},
  address = {Woburn, MA},
  year = {2009},
  abbrev_source_title = {IEEE Int. Conf. Technol. Pract. Rob. Appl., TePRA},
  abstract = {SLAM (Simultaneous Localization and Mapping) mechanisms are a key component towards advanced service robotics applications. Currently, a major hurdle on the way to lifelong localization is the handling of the ever growing amount of landmarks over time. Therefore, the required resources in terms of memory and processing power are also growing over time. An approach to restrict the absolute number of landmarks by an upper bound was presented in [1]. The key was a method to specifically select and replace landmarks once an upper bound has been reached. In this paper, we extend that landmark rating and selection approach. The here presented extension improves the landmark rating and selection process. Landmarks are kept such that their visibility regions better approximate the robot's operational area. A landmark with a low information content in a sparsely known region is often more useful than a landmark with a higher information content in a well-known region. Clustering algorithms are used to identify regions in the environment with a high landmark density. Removing a landmark from a cluster with high localization support will have the smallest degradation of robot localization quality. Real-world experiments are used to demonstrate the performance of our approach. These experiments are performed on a P3DX-platform with a bearing-only SLAM approach. All three approaches of handling landmarks (the standard approach without upper bound on the number of landmarks, the improved and the previous landmark rating and selection process) are compared against each other. ©2009 IEEE.},
  affiliation = {University of Applied Sciences Ulm, Computer Science Department, Prittwitzstr. 10, D-89075 Ulm, Germany},
  art_number = {5339626},
  correspondence_address1 = {Hochdorfer, S.; University of Applied Sciences Ulm, Prittwitzstr. 10, D-89075 Ulm, Germany; email: hochdorfer@hs-ulm.de},
  document_type = {Conference Paper},
  isbn = {9781424449927},
  keywords = {Absolute number;  Bearing-only;  Indoor environment;  Information contents;  Key component;  Mobile service;  Omni-directional vision;  Operational area;  Processing power;  Real world experiment;  Robot localization;  Selection process;  Service robotics;  SLAM (simultaneous localization and mapping);  SLAM approach;  Upper Bound, Clustering algorithms;  Robot applications, Robots},
  language = {English},
  references = {Hochdorfer, S., Schlegel, C., Landmark rating and selection according to localization coverage: Addressing the challenge of lifelong operation of SLAM in service robots (2009) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), , October; Bailey, T., Constrained initialisation for bearing-only SLAM (2003) IEEE International Conference on Robotics and Automation (ICRA), 2, pp. 1966-1971. , Sept; C. Schlegel and S. Hochdorfer, Bearing-Only SLAM with an Omnicam - An Experimental Evaluation for Service Robotics Applications, in Autonome Mobile Systeme (AMS) 2005, 19. Fachgespräch, Stuttgart, 2005, ser. Springer, Informatik Aktuell. Springer, 2005, pp. 99-106; S. Hochdorfer and C. Schlegel, Bearing-Only SLAM with an Omnicam: Robust Selection of SIFT Features for Service Robots, in Autonome Mobile Systeme (AMS) 2005, 20. Fachgespräch, Kaiser-slautern, 2007, ser. Springer, Informatik Aktuell. Springer, 2007, pp. 8-14; Seber, G.A.F., (1984) Multivariate Observations, , New York: Wiley; Spath, H., (1985) Cluster Dissection and Analysis: Theory, FORTRAN Programs, Examples, , Halsted Press,New York, 226 pp; Dissanayake, G., Durrant-Whyte, H.F., Bailey, T., A Computationally Efficient Solution to the Simultaneous Localisation and Map Building (SLAM) Problem (2000) IEEE International Conference on Robotics and Automation (ICRA), pp. 1009-1014; Strasdat, H., Stachniss, C., Burgard, W., Which Landmark is Useful? Learning Selection Policies for Navigation in Unknown Environments (2009) IEEE International Conference on Robotics and Automation (ICRA), , Kobe, Japan; Tran, T.N., Wehrens, R., Buydens, L.M., Clustering multispectral images: A tutorial (2005) Chemometrics and Intelligent Laboratory Systems, 77, pp. 3-17; Ester, M., Kriegel, H.-P., Sander, J., Xu, X., A density-based algorithm for discovering clusters in large spatial databases with noise (1996) Proc. 2nd Int. Conf. on Knowledge Discovery and Data Mining (KDD'96 ), pp. 226-231. , E. Simoudis, J. Han, and U. Fayyad, Eds. AAAI Press; Yip, A., Ding, C., Chan, T., Dynamic cluster formation using level set methods (2006) Pattern Analysis and Machine Intelligence, IEEE Transactions on, 28, pp. 877-889. , June; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) 9th European Conference on Computer Vision, , Graz Austria, May},
  source = {Scopus},
  sponsors = {IEEE Boston Section},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-71849120407&doi=10.1109%2fTEPRA.2009.5339626&partnerID=40&md5=d4275ef0f8c53e56efb4e8b783fd1447},
}

@conference{luthardt-et-al:2018:8569323,
  author = {S. Luthardt and V. Willert and J. Adamy},
  journal = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
  title = {LLama-SLAM: Learning High-Quality Visual Landmarks for Long-Term Mapping and Localization},
  volume = {2018-November},
  pages = {2645--2652},
  doi = {10.1109/ITSC.2018.8569323},
  note = {cited By 5; Conference of 21st IEEE International Conference on Intelligent Transportation Systems, ITSC 2018 ; Conference Date: 4 November 2018 Through 7 November 2018;  Conference Code:143575},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Conf Intell Transport Syst Proc ITSC},
  abstract = {The precise localization of vehicles is an important requirement for autonomous driving or advanced driver assistance systems. Using common GNSS the ego position can be measured but not with the reliability and precision necessary. An alternative approach to achieve precise localization is the usage of visual landmarks observed by a camera mounted in the vehicle. However, this raises the necessity of reliable visual landmarks that are easily recognizable and persistent. We propose a novel SLAM algorithm that focuses on learning and mapping such visual long-term landmarks (LLamas). The algorithm therefore processes stereo image streams from several recording sessions in the same spatial area. The key part within LLama-SLAM is the assessment of the landmarks with quality values that are inferred as viewpoint dependent probabilities from observation statistics. By adding solely landmarks of high quality to the final LLama Map, it can be kept compact while still allowing reliable localization. Due to the long-term evaluation of the GNSS measurement during the sessions, the landmarks can be positioned precisely in a global referenced coordinate system. For a first assessment of the algorithm's capabilities, we present some experimental results from the mapping process combining three sessions recorded over two months on the same route. © 2018 IEEE.},
  affiliation = {Control Methods and Robotics, TU Darmstadt, Germany},
  art_number = {8569323},
  document_type = {Conference Paper},
  isbn = {9781728103235},
  keywords = {Automobile drivers;  Global positioning system;  Image recording;  Intelligent systems;  Mapping;  Stereo image processing, Autonomous driving;  Co-ordinate system;  Long-term evaluation;  Mapping and localization;  Mapping process;  Quality value;  SLAM algorithm;  Visual landmarks, Advanced driver assistance systems},
  language = {English},
  references = {Scaramuzza, D., Fraundorfer, F., Visual odometry: Part i: The first 30 years and fundamentals (2011) IEEE Robot. Automat. Mag, 18 (4), pp. 80-92; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., Leonard, J.J., Past, present, and future of simultaneous localization and mapping: Toward the robust-perception age (2016) IEEE Trans. Robot, 32 (6), pp. 1309-1332; Bresson, G., Alsayed, Z., Yu, L., Glaser, S., Simultaneous localization and mapping: A survey of current trends in autonomous driving (2017) IEEE Trans. Intell. Transport. Syst, 2 (3), pp. 194-220; Churchill, W., Newman, P., Experience-based navigation for longterm localisation (2014) Int. J. Robotics Research, 32 (14), pp. 1645-1661; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) IEEE/RSJ Int. Conf. on Intelligent Robots and Systems, pp. 1156-1163; Levinson, J., Thrun, S., Robust vehicle localization in urban environments using probabilistic maps (2010) IEEE Int. Conf. on Robotics and Automation, pp. 4372-4378; Krajnik, T., Fentanes, J.P., Santos, J.M., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2017) IEEE Trans. Robot, 33 (4), pp. 964-977; Johns, E., Yang, G.-Z., Generative methods for long-term place recognition in dynamic scenes (2014) Int. J. Comput. Vision, 106 (3), pp. 297-314; Sons, M., Lauer, M., Keller, C.G., Stiller, C., Mapping and localization using surround view (2017) IEEE Intelligent Vehicles Symp., pp. 1158-1163; Schuster, F., Zhang, W., Keller, C.G., Haueis, M., Curio, C., Joint graph optimization towards crowd based mapping (2017) IEEE 20th Int. Conf. on Intelligent Transportation Systems, pp. 1-6; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) J. Field Robotics, 33 (5), pp. 561-590; Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The GIST of maps-summarizing experience for lifelong localization (2015) IEEE Int. Conf. on Robotics and Automation, pp. 2767-2773; Dayoub, F., Cielniak, G., Duckett, T., Long-term experiments with an adaptive spherical view representation for navigation in changing environments (2011) Robotics and Autonomous Systems, 59 (5), pp. 285-295; Delobel, L., Aufrere, R., Chapuis, R., Debain, C., Chateau, T., Towards automated map updating for mobile robot localization (2017) IEEE Intelligent Vehicles Symp., pp. 1342-1347; Stübler, M., Reuter, S., Dietmayer, K., A continuously learning feature-based map using a bernoulli filtering approach (2017) Symp. on Sensor Data Fusion, pp. 1-6; Grisetti, G., Kümmerle, R., Stachniss, C., Burgard, W., A tutorial on graph-based slam (2010) IEEE Intell. Transport. Syst. Mag, 2 (4), pp. 31-43; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) IEEE Int. Conf. on Robotics and Automation, pp. 3607-3613; Bishop, C.M., (2006) Pattern Recognition and Machine Learning, Ser. Information Science and Statistics, , New York, NY: Springer; Willert, V., Eggert, J., Belief propagation in spatiotemporal graph topologies for the analysis of image sequences (2010) Int. Conf. on Computer Vision Theory and Applications, pp. 117-124; Buczko, M., Willert, V., How to distinguish inliers from outliers in visual odometry for high-speed automotive applications (2016) IEEE Intelligent Vehicles Symp., pp. 478-483; Buczko, M., Willert, V., Monocular outlier detection for visual odometry (2017) IEEE Intelligent Vehicles Symp., pp. 739-745; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., Orb: An efficient alternative to sift or surf (2011) IEEE Int. Conf. on Computer Vision, pp. 2564-2571; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., Orb-slam: A versatile and accurate monocular slam system (2015) IEEE Trans. Robot, 31 (5), pp. 1147-1163; Cvisic, I., Cesic, J., Markovic, I., Petrovic, I., Soft-slam: Computationally efficient stereo visual simultaneous localization and mapping for autonomous unmanned aerial vehicles (2017) J. Field Robotics, 13 (2), p. 99; Fraundorfer, F., Scaramuzza, D., Visual odometry: Part II: Matching, robustness, optimization, and applications (2012) IEEE Robot. Automat. Mag, 19 (2), pp. 78-90; Willert, V., Eggert, J., A stochastic dynamical system for optical flow estimation (2009) IEEE 12th Int. Conf. on Computer Vision Workshops, pp. 711-718},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060435416&doi=10.1109%2fITSC.2018.8569323&partnerID=40&md5=c3c0d03fa57e999e0de3ad4ebd75fa83},
}

@article{nuske-et-al:2009:20306,
  author = {S. Nuske and J. Roberts and G. Wyeth},
  journal = {Journal of Field Robotics},
  title = {Robust outdoor visual localization using a three-dimensional-edge map},
  volume = {26},
  number = {9},
  pages = {728--756},
  doi = {10.1002/rob.20306},
  note = {cited By 26},
  year = {2009},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {Visual localization systems that are practical for autonomous vehicles in outdoor industrial applications must perform reliably in a wide range of conditions. Changing outdoor conditions cause difficulty by drastically altering the information available in the camera images. To confront the problem, we have developed a visual localization system that uses a surveyed three-dimensional (3D)-edge map of permanent structures in the environment. The map has the invariant properties necessary to achieve long-term robust operation. Previous 3D-edge map localization systems usually maintain a single pose hypothesis, making it difficult to initialize without an accurate prior pose estimate and also making them susceptible to misalignment with unmapped edges detected in the camera image. A multihypothesis particle filter is employed here to perform the initialization procedure with significant uncertainty in the vehicle's initial pose. A novel observation function for the particle filter is developed and evaluated against two existing functions. The new function is shown to further improve the abilities of the particle filter to converge given a very coarse estimate of the vehicle's initial pose. An intelligent exposure control algorithm is also developed that improves the quality of the pertinent information in the image. Results gathered over an entire sunny day and also during rainy weather illustrate that the localization system can operate in a wide range of outdoor conditions. The conclusion is that an invariant map, a robust multihypothesis localization algorithm, and an intelligent exposure control algorithm all combine to enable reliable visual localization through challenging outdoor conditions. © 2009 Wiley Periodicals, Inc.},
  affiliation = {School of Information Technology and Electrical Engineering, University of Queensland, St Lucia, QLD 4072, Australia; Autonomous Systems Lab., CSIROICT Centre, P.O. Box 883, Kenmore, QLD 4069, Australia; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213, United States},
  correspondence_address1 = {Nuske, S.; School of Information Technology and Electrical Engineering, , St Lucia, QLD 4072, Australia; email: nuske@cmu.edu},
  document_type = {Article},
  issn = {15564959},
  keywords = {Autonomous Vehicles;  Camera images;  Edge map;  Invariant properties;  Localization algorithm;  Localization system;  Particle filter;  Robust operation;  Three-dimensional (3D);  Visual localization, Air filters;  Algorithms;  Cameras;  Exposure controls;  Industrial applications;  Nonlinear filtering;  Three dimensional, Edge detection},
  language = {English},
  references = {(2000) IIDC 1394-based Digital Camera Specification, , 1394-Trade-Association, 1.30 ed 1394-Trade-Association, Santa Clara, CA; Canny, J., A computational approach to edge detection (1986) IEEE Transactions on Pattern Analysis and Machine Intelligence, 8 (6), pp. 679-698; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) International Journal of Robotics Research, 27 (6), pp. 647-665; Davison, A.J., Molton, N.D., MonoSLAM: Realtime single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (6), pp. 1052-1067; Drummond, T., Cipolla, R., Real-time visual tracking of complex structures (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (7), pp. 932-946; Fox, D., Adapting the sample size in particle filters through KLD-sampling (2003) International Journal of Robotics Research, 22, pp. 985-1005; Georgiev, A., Allen, P.K., Vision for mobile robot localization in urban environments (2002) IEEE International Conference on Intelligent Robots and Systems, 1, pp. 472-477; Geyer, C., Danilidis, K., Catadioptric projective geometry (2001) International Journal of Computer Vision, 45 (3), pp. 223-243; Klein, G., Murray, D., Full-3D edge tracking with a particle filter (2006) In British Machine Vision Conference, , September, Edinburgh, UK; Kosaka, A., Kak, A., Fast vision-guided mobile robot navigation using model-based reasoning and prediction of uncertainties (1992) In Proceedings International Conference on Intelligent Robots and Systems, , July, Raleigh, NC; Lowe, D., Distinctive image features from scale- invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Lowe, D., Se, S., Little, J., Mobile robot localization and mapping with uncertainty using scale-invariant visual landmarks (2002) International Journal of Robotics Research, 21 (8), pp. 735-758; Maimone, M., Cheng, Y., Matthies, L., Two years of visual odometry on the Mars exploration rovers (2007) Journal of Field Robotics, 24 (3), pp. 169-186; Marks, T., Howard, A., Bajracharya, M., Cottrell, G., Matthies, L., Gamma-SLAM: Using stereo vision and variance grid maps for SLAM in unstructured environments (2008) In IEEE International Conference on Robotics and Automation, pp. 3717-3724. , May, 2008. ICRA 2008, Pasadena, CA; Michel, P., Chestnut, J., Kagami, S., Nishiwaki, K., Kuffner, J., Kanade, T., GPU-accelerated realtime 3D tracking for humanoid locomotion and stair climbing (2007) In IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 463-469. , October,2007. IROS 2007, San Diego, CA; Mikolajczyk, K., Schmid, C., A performance evaluation of local descriptors (2005) IEEE Transactions on Pattern Analysis and Machine Intelligence, 27 (10), pp. 1615-1630; Nistér, D., Naroditsky, O., Bergen, J., Visual odom- etry for ground vehicle applications (2006) Journal of Field Robotics, 23, pp. 3-20; Nuske, S., Roberts, J., Wyeth, G., Extending the dynamic range of robotic vision (2006) In Proceedings of the IEEE International Conference on Robotics and Automation, pp. 162-167. , May, Orlando, FL; Nuske, S., Roberts, J., Wyeth, G., Outdoor visual localisation in industrial building environments (2008) In Proceedings of the IEEE International Conference on Robotics and Automation, , May, Pasadena, CA; (2007) NVIDIA OpenGL Extension Specifications, , NVIDIA Corporation, Santa Clara, CA: NVIDIA Corporation; Paz, L., Pinies, P., Tardos, J., Neira, J., Large-scale 6-DOF SLAM with stereo-in-hand (2008) IEEE Transactions on Robotics, 24 (5), pp. 946-957; Pradalier, C., Tews, A., Roberts, J., Vision-based operations of a large industrial vehicle: Autonomous hot metal carrier (2008) Journal of Field Robotics, 25 (4-5), pp. 243-267; Reitmayr, G., Drummond, T., October Going out: Robust model-based tracking for outdoor augmented reality (2006) In International Symposium on Mixed and Augmented Reality, pp. 109-118. , Santa Barbara, CA; Roberts, J., Tews, A., Nuske, S., Redundant sensing for localisation in outdoor industrial environments (2008) In Proceedings of the 6th IARP/IEEE- RAS/EURon Workshop on Technical Challenges for Dependable Robots in Human Environments, , May, Pasadena, CA; Roberts, J., Tews, A., Pradalier, C., Usher, K., Autonomous hot metal carrier-Navigation and manipulation with a 20 tonne industrial vehicle (2007) In Proceedings of IEEE International Conference on Robotics and Automation, pp. 2770-2771. , Rome, Italy, video paper; Shimizu, S., Kondo, T., Kohashi, T., Tsurata, M., Komuro, T., A new algorithm for exposure control based on fuzzy logic for video cameras (1992) IEEE Transactions on Consumer Electronics, 38 (3), pp. 617-623; Sim, R., Dudek G, Comparing image- based localization methods (2003) In International Joint Conference on Artificial Intelligence, , August, Acapulco, Mexico; Tews, A., Pradalier, C., Roberts, J., Autonomous hot metal carrier (2007) In Proceedings of IEEE International Conference on Robotics and Automation, pp. 1176-1182. , Rome, Italy; Thrun, S., Burgard, W., Fox, D., (2005) Probabalistic Robotics, , Cambridge, MA: MIT Press; Valgren, C., Lilienthal, A., SIFT, SURF and seasons: Long-term outdoor localization using local features (2007) In European Conference on Mobile Robots, Freiburg, Germany., , September; Valgren, C., Lilienthal, A., Incremental spectral clustering and seasons: Appearance-based localization in outdoor environments (2008) In IEEE International Conference on Robotics and Automation, , May, Pasadena, CA; Yang, M., Wu, Y., Crenshaw, J., Augustine, B., Mareachen, R., Face detection for automatic exposure control in handheld camera (2006) In IEEE International Conference on Computer Vision Systems, pp. 17-17. , 2006 ICVS ́06; Ying, X., Hu, Z., Can we consider central cata- dioptric cameras and fisheye cameras within a unified imaging model? (2004) In Computer Vision-ECCV 2004, pp. 442-455. , (vol. 3021/2004, Lecture Notes in Computer Science). Berlin: Springer},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449347269&doi=10.1002%2frob.20306&partnerID=40&md5=69c315cf2d49f400e52e72af3182bb6e},
}

@article{ouerghi-et-al:2018:s18040939,
  author = {S. Ouerghi and R. Boutteau and X. Savatier and F. Thai},
  journal = {SENSORS},
  title = {Visual Odometry and Place Recognition Fusion for Vehicle Position
Tracking in Urban Environments},
  volume = {18},
  number = {4},
  pages = {939},
  doi = {10.3390/s18040939},
  publisher = {MDPI},
  address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
  year = {2018},
  month = {4},
  abstract = {In this paper, we address the problem of vehicle localization in urban
environments. We rely on visual odometry, calculating the incremental
motion, to track the position of the vehicle and on place recognition to
correct the accumulated drift of visual odometry, whenever a location is
recognized. The algorithm used as a place recognition module is SeqSLAM,
addressing challenging environments and achieving quite remarkable
results. Specifically, we perform the long-term navigation of a vehicle
based on the fusion of visual odometry and SeqSLAM. The template library
for this latter is created online using navigation information from the
visual odometry module. That is, when a location is recognized, the
corresponding information is used as an observation of the filter. The
fusion is done using the EKF and the UKF, the well-known nonlinear state
estimation methods, to assess the superior alternative. The algorithm is
evaluated using the KITTI dataset and the results show the reduction of
the navigation errors by loop-closure detection. The overall position
error of visual odometery with SeqSLAM is 0.22\% of the trajectory,
which is much smaller than the navigation errors of visual odometery
alone 0.45\%. In addition, despite the superiority of the UKF in a
variety of estimation problems, our results indicate that the UKF
performs as efficiently as the EKF at the expense of an additional
computational overhead. This leads to the conclusion that the EKF is a
better choice for fusing visual odometry and SeqSlam in a long-term
navigation context.},
  affiliation = {Ouerghi, S (Corresponding Author), Carthage Univ, SUPCOM, GRESCOM, El Ghazela 2083, Tunisia.
Ouerghi, Safa; Thai, Fethi, Carthage Univ, SUPCOM, GRESCOM, El Ghazela 2083, Tunisia.
Boutteau, Remi; Savatier, Xavier, Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, F-76000 Rouen, France.},
  affiliations = {Universite de Carthage},
  article-number = {939},
  author-email = {safa.ouerghi@supcom.tn
remi.boutteau@esigelec.fr
xavier.savatier@esigelec.fr
fethi.tlili@supcom.tn},
  cited-references = {Baatz G, 2012, INT J COMPUT VISION, V96, P315, DOI 10.1007/s11263-011-0458-7.
Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
Bonardi F, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051167.
Brubaker MA, 2016, IEEE T PATTERN ANAL, V38, P652, DOI 10.1109/TPAMI.2015.2453975.
Chu H., 2015, ARXIV151009171.
Clipp B, 2010, IEEE INT C INT ROBOT, P3961, DOI 10.1109/IROS.2010.5653696.
Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
Floros G, 2013, IEEE INT CONF ROBOT, P1054, DOI 10.1109/ICRA.2013.6630703.
Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
Hentschel M, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1645, DOI 10.1109/ITSC.2010.5625092.
Kaess M., 2009, P IEEE INT C ROB AUT.
Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
Kalman R. E., 1960, J FLUIDS ENG, V82, P34, DOI {[}https://doi.org/10.1115/1.3662552, DOI 10.1115/1.3662552].
Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582.
Kummerle R., 2011, P 2011 IEEE INT C RO.
Majdik AL, 2014, IEEE INT CONF ROBOT, P920, DOI 10.1109/ICRA.2014.6906964.
Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
Milford M., 2012, P ROB SCI SYST RSS S.
Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
OH S, 2004, P IEEE RSJ INT C INT.
Ouerghi S., 2017, P 25 INT C COMP GRAP.
Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
Pepperell E., 2013, P AUSTR C ROB AUT AR.
Ranganathan A, 2011, INT J ROBOT RES, V30, P755, DOI 10.1177/0278364910393287.
Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
Stone T., 2014, P ROB SCI SYST 10 RS.
Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
Sunderhauf N, 2013, P IEEE INT C ROB AUT.
Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
Thrun Sebastian, 2005, PROBABILISTIC ROBOTI, V1.
Zhou DF, 2016, IEEE INT VEH SYM, P490, DOI 10.1109/IVS.2016.7535431.},
  da = {2022-05-17},
  doc-delivery-number = {GJ7NS},
  eissn = {1424-8220},
  journal-iso = {Sensors},
  keywords = {real-time navigation; visual-odometry; SeqSLAM; loop-closure; EKF; UKF},
  keywords-plus = {FAB-MAP; LOCALIZATION},
  language = {English},
  number-of-cited-references = {36},
  oa = {Green Published, Green Submitted, gold},
  orcid-numbers = {Boutteau, Rémi/0000-0003-1078-5043},
  research-areas = {Chemistry; Engineering; Instruments \& Instrumentation},
  researcherid-numbers = {SAVATIER, Xavier/AAG-6093-2019
Boutteau, Rémi/U-7674-2019},
  times-cited = {6},
  type = {Article},
  unique-id = {WOS:000435574800011},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {12},
  web-of-science-categories = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
Instruments \& Instrumentation},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
}

@conference{siva-zhang:2018:8461042,
  author = {S. Siva and H. Zhang},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Omnidirectional multisensory perception fusion for long-term place recognition},
  pages = {5175--5181},
  doi = {10.1109/ICRA.2018.8461042},
  note = {cited By 13; Conference of 2018 IEEE International Conference on Robotics and Automation, ICRA 2018 ; Conference Date: 21 May 2018 Through 25 May 2018;  Conference Code:139796},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation. © 2018 IEEE.},
  affiliation = {Department of Computer Science, Human-Centered Robotics Lab Colorado School of Mines, Golden, CO  80401, United States},
  art_number = {8461042},
  coden = {PIIAE},
  document_type = {Conference Paper},
  funding_details = {Army Research OfficeArmy Research Office, ARO, W911NF-17-1-0447},
  funding_text1 = {This work was funded in part by the ARO grant W911NF-17-1-0447.},
  isbn = {9781538630815},
  issn = {10504729},
  keywords = {Large dataset, Large-scale dataset;  Multiple sensors;  Multisensory data;  Multisensory perceptions;  Omni-directional sensors;  Place recognition;  Simultaneous localization and mapping;  Surrounding environment, Robotics},
  language = {English},
  references = {Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) International Conference on Robotics and Automation; Han, F., Wang, H., Zhang, H., Learning of integrated holismlandmark representations for long-term loop closure detection (2018) Association for the Advancement of Artificial Intelligence; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Conference on Artificial Intelligence; Oliva, A., Torralba, A., Building the GIST of a scene: The role of global image features in recognition (2006) Progress in Brain Research, 155, pp. 23-36; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Conference on Computer Vision and Pattern Recognition; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., Towards life-long visual localization using an efficient matching of binary sequences from images (2015) International Conference on Robotics and Automation; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features-SURF (2008) Computer Vision and Image Understanding, 110 (3), pp. 346-359; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., Orb-SLAM: A versatile and accurate monocular slam system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163; Lowry, S., Sunderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Labbe, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE Transactions on Robotics, 29 (3), pp. 734-745; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) The International Journal of Robotics Research, 27 (6), pp. 647-665; Milford, M.J., Wyeth, G.F., Prasser, D., Rat-SLAM: A hippocampal model for simultaneous localization and mapping (2004) International Conference on Robotics and Automation; Zhang, H., Han, F., Wang, H., Robust multimodal sequence-based loop closure detection via structured sparsity (2016) Robotics: Science and Systems; Chen, C., Wang, H., Appearance-based topological Bayesian inference for loop-closing detection in a cross-country environment (2006) The International Journal of Robotics Research, 25 (10), pp. 953-983; Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) International Journal of Computer Vision, 42 (3), pp. 145-175; Sunderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proceedings of Robotics: Science and Systems; Sunderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) Intelligent Robots and Systems; Chen, Z., Lam, O., Jacobson, A., Milford, M., Convolutional neural network-based place recognition (2014) Australian Conference of Robotics and Automation; Salas-Moreno, R.F., Newcombe, R.A., Strasdat, H., Kelly, P.H., Davison, A.J., Slam++: Simultaneous localisation and mapping at the level of objects (2013) Conference on Computer Vision and Pattern Recognition; Han, F., Yang, X., Deng, Y., Rentschler, M., Yang, D., Zhang, H., SRAL: Shared representative appearance learning for long-term visual place recognition (2017) IEEE Robotics and Automation Letters, 2 (2), pp. 1172-1179},
  source = {Scopus},
  sponsors = {Csiro; Department of Defence; DJI; et al.; Queensland University of Technology (QUT); Woodside},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063155590&doi=10.1109%2fICRA.2018.8461042&partnerID=40&md5=8bbd4edf62e44e00f08c8ea0f729f192},
}

@conference{siva-et-al:2020:9340992,
  author = {S. Siva and Z. Nahman and H. Zhang},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Voxel-based representation learning for place recognition based on 3D point clouds},
  pages = {8351--8357},
  doi = {10.1109/IROS45743.2020.9340992},
  note = {cited By 2; Conference of 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2020 ; Conference Date: 24 October 2020 Through 24 January 2021;  Conference Code:167055},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Place recognition is a critical component towards addressing the key problem of Simultaneous Localization and Mapping (SLAM). Most existing methods use visual images; whereas, place recognition using 3D point clouds, especially based on the voxel representations, has not been well addressed yet. In this paper, we introduce the novel approach of voxel-based representation learning (VBRL) that uses 3D point clouds to recognize places with long-term environment variations. VBRL splits a 3D point cloud input into voxels and uses multi-modal features extracted from these voxels to perform place recognition. Additionally, VBRL uses structured sparsity-inducing norms to learn representative voxels and feature modalities that are important to match places under long-term changes. Both place recognition, and voxel and feature learning are integrated into a unified regularized optimization formulation. As the sparsity-inducing norms are non-smooth, it is hard to solve the formulated optimization problem. Thus, we design a new iterative optimization algorithm, which has a theoretical convergence guarantee. Experimental results have shown that VBRL performs place recognition well using 3D point cloud data and is capable of learning the importance of voxels and feature modalities. © 2020 IEEE.},
  affiliation = {Human-Centered Robotics Lab at Colorado School of Mines, Golden, CO  80401, United States},
  art_number = {9340992},
  coden = {85RBA},
  document_type = {Conference Paper},
  isbn = {9781728162126},
  issn = {21530858},
  keywords = {Agricultural robots;  Iterative methods;  Optimization, Critical component;  Iterative optimization algorithms;  Optimization problems;  Place recognition;  Regularized optimizations;  Simultaneous localization and mapping;  Structured sparsities;  Voxel representation, Intelligent robots},
  language = {English},
  references = {Meng, L., De Silva, C.W., Zhang, J., 3D visual slam for an assistive robot in indoor environments using RGB-D cameras (2014) ICCSE; De La Cruz, C., Bastos, T.F., Cheein, F.A.A., Carelli, R., Slambased robotic wheelchair navigation system designed for confined spaces (2010) ISIE; Belavadi, S.S., Beri, R., Malik, V., Frontier exploration technique for 3D autonomous slam using k-means based divisive clustering (2017) AMS; Sim, R., Roy, N., Global a-optimal robot exploration in slam (2005) ICRA; Singandhupe, A., La, H., A review of slam techniques and security in autonomous driving (2019) IRC; Wolcott, R.W., Eustice, R.M., Visual localization within lidar maps for automated urban driving (2014) IROS; Lowry, S.M., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D.D., Corke, P.I., Milford, M., Visual place recognition: A survey (2016) TRO, 32, pp. 1-19; Han, F., Yang, X., Deng, Y., Rentschler, M., Yang, D., Zhang, H., SRAL: Shared representative appearance learning for long-term visual place recognition (2017) R-AL; Siva, S., Zhang, H., Omnidirectional multisensory perception fusion for long-term place recognition (2018) ICRA; Grzonka, S., Steder, B., Burgard, W., 3D place recognition and object detection using a small-sized quadrotor (2011) RSS; Bosse, M., Zlot, R., Place recognition using keypoint voting in large 3D lidar datasets (2013) ICRA; Magnusson, M., Andreasson, H., Nuchter, A., Lilienthal, A.J., Appearance-based loop detection from 3D laser data using the normal distributions transform (2009) ICRA; Uy, M.A., Lee, G.H., Pointnetvlad: Deep point cloud based retrieval for large-scale place recognition (2018) CoRR; Ryde, J., Delmerico, J.A., Extracting edge voxels from 3D volumetric maps to reduce map size and accelerate mapping alignment (2012) CRV; Shim, I., Choe, Y., Jin Chung, M., 3D mapping in urban environment using geometric featured voxel (2011) URAI; Liu, Z., Chen, H., Di, H., Tao, Y., Gong, J., Xiong, G., Qi, J., Realtime 6D lidar slam in large scale natural terrains for ugv (2018) IV; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., A fast and incremental method for loop-closure detection using bags of visual words (2008) TRO, pp. 1027-1037; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) TRO, 28 (5), pp. 1188-1197; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based slam (2014) ICRA; Oliva, A., Torralba, A., Building the gist of a scene: The role of global image features in recognition (2006) Progress in Brain Research, 155, pp. 23-36; Sünderhauf, N., Protzel, P., Brief-gist-closing the loop by simple means (2011) IROS; Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., Towards life-long visual localization using an efficient matching of binary sequences from images (2015) ICRA; Sünderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) RSS; Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition IROS; Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T., Caffe: Convolutional architecture for fast feature embedding (2014) ACM MM, pp. 675-678; Pepperell, E., Corke, P.I., Milford, M.J., All-environment visual place recognition with smart (2014) ICRA; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) IJCAI; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) ICRA; Chen, Z., Maffra, F., Sa, I., Chli, M., Only look once, mining distinctive landmarks from convnet for visual place recognition (2017) IROS; Steder, B., Grisetti, G., Burgard, W., Robust place recognition for 3D range data based on point features (2010) ICRA; Cieslewski, T., Stumm, E., Gawel, A., Bosse, M., Lynen, S., Siegwart, R., Point cloud descriptors for place recognition using sparse visual information (2016) ICRA; Röhling, T., Mack, J., Schulz, D., A fast histogram-based similarity measure for detecting loop closures in 3-d lidar data (2015) IROS; Fazl-Ersi, E., Tsotsos, J.K., Histogram of oriented uniform patterns for robust place recognition and categorization (2012) IJRR; Zlot, R., Bosse, M., Place recognition using keypoint similarities in 2d lidar maps (2009) Experimental Robotics; Dube, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., Segmatch: Segment based place recognition in 3D point clouds (2017) ICRA; Yin, H., Ding, X., Tang, L., Wang, Y., Xiong, R., Efficient 3D lidar based loop closing using deep neural network (2017) ICRB; Qi, C.R., Su, H., Mo, K., Guibas, L.J., Pointnet: Deep learning on point sets for 3D classification and segmentation (2017) CVPR; Elbaz, G., Avraham, T., Fischer, A., 3D point cloud registration for localization using a deep neural network auto-encoder (2017) CVPR; Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., Xiao, J., 3D shapenets: A deep representation for volumetric shapes (2015) CVPR; Wohlhart, P., Lepetit, V., Learning descriptors for object recognition and 3d pose estimation (2015) CVPR; Shah, S., Dey, D., Lovett, C., Kapoor, A., Airsim: High-fidelity visual and physical simulation for autonomous vehicles (2017) FSR; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan North Campus long-term vision and lidar dataset (2015) IJRR},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102409922&doi=10.1109%2fIROS45743.2020.9340992&partnerID=40&md5=901ba2eba9cb42bbb3aa0d8657670586},
}

@article{williams-et-al:2014:0278364914531056,
  author = {S. Williams and V. Indelman and M. Kaess and R. Roberts and J. J. Leonard and F. Dellaert},
  journal = {International Journal of Robotics Research},
  title = {Concurrent filtering and smoothing: A parallel architecture for real-time navigation and full smoothing},
  volume = {33},
  number = {12},
  pages = {1544--1568},
  doi = {10.1177/0278364914531056},
  note = {cited By 18},
  publisher = {SAGE Publications Inc.},
  year = {2014},
  abbrev_source_title = {Int J Rob Res},
  abstract = {We present a parallelized navigation architecture that is capable of running in real-time and incorporating long-term loop closure constraints while producing the optimal Bayesian solution. This architecture splits the inference problem into a low-latency update that incorporates new measurements using just the most recent states (filter), and a high-latency update that is capable of closing long loops and smooths using all past states (smoother). This architecture employs the probabilistic graphical models of factor graphs, which allows the low-latency inference and high-latency inference to be viewed as sub-operations of a single optimization performed within a single graphical model. A specific factorization of the full joint density is employed that allows the different inference operations to be performed asynchronously while still recovering the optimal solution produced by a full batch optimization. Due to the real-time, asynchronous nature of this algorithm, updates to the state estimates from the high-latency smoother will naturally be delayed until the smoother calculations have completed. This architecture has been tested within a simulated aerial environment and on real data collected from an autonomous ground vehicle. In all cases, the concurrent architecture is shown to recover the full batch solution, even while updated state estimates are produced in real-time. © 2014 The Author(s).},
  affiliation = {Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, 801 Atlantic Drive, Atlanta, GA  30309, United States; Field Robotics Center, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, United States},
  author_keywords = {filtering;  Information fusion;  probabilistic graphical models;  real time navigation;  SLAM;  smoothing},
  coden = {IJRRE},
  correspondence_address1 = {Indelman, V.; Institute for Robotics and Intelligent Machines, 801 Atlantic Drive, United States},
  document_type = {Article},
  funding_details = {Air Force Research LaboratoryAir Force Research Laboratory, AFRL, FA8650-11-C-7137},
  funding_text1 = {This work was supported by the All Source Positioning and Navigation (ASPN) program of the Air Force Research Laboratory (AFRL) (contract number FA8650-11-C-7137). The views expressed in this work have not been endorsed by the sponsors.},
  issn = {02783649},
  keywords = {Agricultural robots;  Antennas;  Filtration;  Graphic methods;  Information filtering;  Information fusion;  Navigation;  State estimation, Autonomous ground vehicles;  Concurrent architecture;  Loop closure constraints;  Navigation architectures;  Probabilistic graphical models;  Real-time navigation;  SLAM;  smoothing, Parallel architectures},
  language = {English},
  references = {Aharoni, R., Berger, E., Menger's theorem for infinite graphs (2009) Inventiones Mathematicae, 176 (1), pp. 1-62; Bar-Shalom, Y., Update with out-of-sequence measurements in tracking: Exact solution (2002) IEEE Transactions on Aerospace and Electronic Systems, 38, pp. 769-777; Bar-Shalom, Y., Li, X., (1995) Multitarget-multisensor Tracking: Principles and Techniques, , Storrs, CT: YBS Publishing;; Davis, T., Gilbert, J., Larimore, S., A column approximate minimum degree ordering algorithm (2004) ACM Transactions on Mathematical Software, 30 (3), pp. 353-376; Dellaert, F., Kaess, M., Square Root SAM: Simultaneous localization and mapping via square root information smoothing (2006) International Journal of Robotics Research, 25 (12), pp. 1181-1203; Eustice, R., Singh, H., Leonard, J., Exactly sparse delayed-state filters for view-based SLAM (2006) IEEE Transactions on Robotics, 22 (6), pp. 1100-1114; Farrell, J., (2008) Aided Navigation: GPS with High Rate Sensors, , New York: McGraw-Hill;; Folkesson, J., Christensen, H., Graphical SLAM - A self-correcting map Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? the KITTI vision benchmark suite Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR); Grisetti, G., Stachniss, C., Grzonka, S., A tree parameterization for efficiently computing maximum likelihood maps using gradient descent Proceedings of Robotics: Science and Systems (RSS); GTSAM, GTSAM 2.3.1, , https://collab.cc.gatech.edu/borg/, (n.d.) Institute for Robotics and Intelligent Machines, College of Computing, Georgia Institute of Technology; Heggernes, P., Matstoms, P., Finding good column orderings for sparse QR factorization Proceedings of the 2nd SIAM Conference on Sparse Matrices; Indelman, V., Melim, A., Dellaert, F., Incremental light bundle adjustment for robotics navigation Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Indelman, V., Williams, S., Kaess, M., Factor graph based incremental smoothing in inertial navigation systems Proceedings of the International Conference on Information Fusion (FUSION); Indelman, V., Williams, S., Kaess, M., Information fusion in navigation systems via factor graph based incremental smoothing (2013) Robotics and Autonomous Systems, 61 (8), pp. 721-738; Jones, E., Soatto, S., Visual-inertial navigation, mapping and localization: A scalable real-time causal approach (2011) International Journal of Robotics Research, 30 (4), pp. 407-430; Kaess, M., Ila, V., Roberts, R., The Bayes tree: An algorithmic foundation for probabilistic robot mapping Proceedings of the International Workshop on the Algorithmic Foundations of Robotics; Kaess, M., Ila, V., Roberts, R., (2010) Algorithmic Foundations of Robotics IX, pp. 157-173. , Hsu D Isler V Latombe J-C, ed. Berlin: Springer;; Kaess, M., Johannsson, H., Roberts, R., ISAM2: Incremental smoothing and mapping with fluid relinearization and incremental variable reordering Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Kaess, M., Johannsson, H., Roberts, R., ISAM2: Incremental smoothing and mapping using the Bayes tree (2012) International Journal of Robotics Research, 31, pp. 217-236; Kaess, M., Williams, S., Indelman, V., Concurrent filtering and smoothing Proceedings of the International Conference on Information Fusion (FUSION); Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces Proceedings of the IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR); Konolige, K., Agrawal, M., FrameSLAM: From bundle adjustment to realtime visual mapping (2008) IEEE Transactions on Robotics, 24 (5), pp. 1066-1077; Konolige, K., Grisetti, G., Kuemmerle, R., Efficient sparse pose adjustment for 2D mapping Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Kschischang, F., Frey, B., Loeliger, H.A., Factor graphs and the sum-product algorithm (2001) IEEE Transactions on Information Theory, 47 (2), pp. 498-519; Kullback, S., Leibler, R.A., On information and sufficiency (1951) The Annals of Mathematical Statistics, 22 (1), pp. 79-86; Lowe, D., Object recognition from local scale-invariant features Proceedings of the International Conference on Computer Vision (ICCV); Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Autonomous Robots, 4 (4), pp. 333-349; Lupton, T., Sukkarieh, S., Visual-inertial-aided navigation for high-dynamic motion in built environments without initial conditions (2012) IEEE Transactions on Robotics, 28 (1), pp. 61-76; Mahon, I., Williams, S., Pizarro, O., Efficient view-based SLAM using visual loop closures (2008) IEEE Transactions on Robotics, 24 (5), pp. 1002-1014; Maybeck, P., (1979) Stochastic Models, Estimation and Control, , New York: Academic Press;; Mei, C., Sibley, G., Cummins, M., RSLAM: A system for large-scale mapping in constant-time using stereo (2011) International Journal of Computer Vision, 94 (2), pp. 198-214; Menger, K., Zur allgemeinen kurventheorie (1927) Fundamenta Mathematicae, 10 (1), pp. 96-115; Mourikis, A., Roumeliotis, S., A multi-state constraint Kalman filter for vision-aided inertial navigation Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Mourikis, A., Roumeliotis, S., A dual-layer estimator architecture for long-term localization Proceedings of the Workshop on Visual Localization for Mobile Platforms at CVPR; Moutarlier, P., Chatila, R., An experimental system for incremental environment modelling by an autonomous mobile robot Proceedings of Experimental Robotics I, the First International Symposium; Newcombe, R.A., Lovegrove, S., Davison, A., DTAM: Dense tracking and mapping in real-time Proceedings of the International Conference on Computer Vision (ICCV); Newcombe, R.A., Izadi, S., Hilliges, O., KinectFusion: Real-time dense surface mapping and tracking Proceedings of the IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR); Ranganathan, A., Kaess, M., Dellaert, F., Fast 3D pose estimation with out-of-sequence measurements Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Shen, X., Son, E., Zhu, Y., Globally optimal distributed Kalman fusion with local out-of-sequence-measurement updates (2009) IEEE Transactions on Automatic Control, 54 (8), pp. 1928-1934; Sibley, G., Mei, C., Reid, I., Adaptive relative bundle adjustment Proceedings of Robotics: Science and Systems (RSS); Smith, D., Singh, S., Approaches to multisensor data fusion in target tracking: A survey (2006) IEEE Transactions on Knowledge and Data Engineering, 18 (12); Smith, R., Self, M., Cheeseman, P., A stochastic map for uncertain spatial relationships Proceedings of the International Symposium on Robotics Research (ISRR); Smith, R., Self, M., Cheeseman, P., (1990) Autonomous Robot Vehicles, pp. 167-193. , Cox I Wilfong G, ed. New York: Springer-Verlag;; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics, , Cambridge, MA: MIT Press;; Triggs, B., McLauchlan, P., Hartley, R., (2000) Vision Algorithms: Theory and Practice, pp. 298-372. , Triggs W Zisserman A Szeliski R, ed. Berlin; New York: Springer Verlag;; Vial, J., Durrant-Whyte, H., Bailey, T., Conservative sparsification for efficient and consistent approximate estimation Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS); Zahng, S., Bar-Shalom, Y., Optimal update with multiple out-of-sequence measurements Proceedings of the SPIE, Signal Processing, Sensor Fusion, and Target Recognition XX; Zhu, Z., Oskiper, T., Samarasekera, S., Ten-fold improvement in visual odometry using landmark matching Proceedings of the International Conference on Computer Vision (ICCV)},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910065546&doi=10.1177%2f0278364914531056&partnerID=40&md5=5510798a1a83009b95aa1a26029fbbed},
}

@article{yang-et-al:2020:s20082432,
  author = {S. Yang and G. Fan and L. Bai and C. Zhao and D. Li},
  journal = {Sensors (Switzerland)},
  title = {SGC-VSLAM: A semantic and geometric constraints VSLAM for dynamic indoor environments},
  volume = {20},
  number = {8},
  pages = {2432},
  doi = {10.3390/s20082432},
  note = {cited By 2},
  publisher = {MDPI AG},
  year = {2020},
  abbrev_source_title = {Sensors},
  abstract = {As one of the core technologies for autonomous mobile robots, Visual Simultaneous Localization and Mapping (VSLAM) has been widely researched in recent years. However, most state-of-the-art VSLAM adopts a strong scene rigidity assumption for analytical convenience, which limits the utility of these algorithms for real-world environments with independent dynamic objects. Hence, this paper presents a semantic and geometric constraints VSLAM (SGC-VSLAM), which is built on the RGB-D mode of ORB-SLAM2 with the addition of dynamic detection and static point cloud map construction modules. In detail, a novel improved quadtree-based method was adopted for SGC-VSLAM to enhance the performance of the feature extractor in ORB-SLAM (Oriented FAST and Rotated BRIEF-SLAM). Moreover, a new dynamic feature detection method called semantic and geometric constraints was proposed, which provided a robust and fast way to filter dynamic features. The semantic bounding box generated by YOLO v3 (You Only Look Once, v3) was used to calculate a more accurate fundamental matrix between adjacent frames, which was then used to filter all of the truly dynamic features. Finally, a static point cloud was estimated by using a new drawing key frame selection strategy. Experiments on the public TUM RGB-D (Red-Green-Blue Depth) dataset were conducted to evaluate the proposed approach. This evaluation revealed that the proposed SGC-VSLAM can effectively improve the positioning accuracy of the ORB-SLAM2 system in high-dynamic scenarios and was also able to build a map with the static parts of the real environment, which has long-term application value for autonomous mobile robots. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
  affiliation = {School of Mechanical and Precision Instrument Engineering, Xi’an University of Technology, Xi’an, 710048, China},
  art_number = {2432},
  author_keywords = {Dynamic feature filtering;  Dynamic indoor environment;  ORB-SLAM2;  Point cloud map;  Visual SLAM},
  correspondence_address1 = {Yang, S.; School of Mechanical and Precision Instrument Engineering, China; email: yangsq@xaut.edu.cn},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, 51475365},
  funding_text1 = {Funding: This research was supported by the National Natural Science Foundation of China under Grant No. 51475365.},
  issn = {14248220},
  keywords = {Geometry;  Indoor positioning systems;  Mobile robots;  Navigation, Autonomous Mobile Robot;  Fundamental matrix;  Geometric constraint;  Indoor environment;  Key frame selection;  Positioning accuracy;  Real world environments;  Visual simultaneous localization and mappings, Semantics},
  language = {English},
  pubmed_id = {32344724},
  references = {Vidal, A.R., Rebecq, H., Horstschaefer, T., Scaramuzza, D., Ultimate SLAM? Combining Events, Images, and IMU for Robust Visual SLAM in HDR and High-Speed Scenarios (2018) IEEE Robot. Autom. Lett., 3, pp. 994-1001; Li, R., Wang, S., Gu, D., Ongoing Evolution of Visual SLAM from Geometry to Deep Learning: Challenges and Opportunities (2018) Cogn. Comput., 10, pp. 875-889; Klein, G., Murray, D., Parallel Tracking and Mapping for Small AR Workspaces (2007) Proceedings of the 2007 6Th IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 225-234. , Nara, Japan, 13–16 November; Mur-Artal, R., Montiel, J.M.M., Tardos, J., Orb-Slam, T., A Versatile and Accurate Monocular SLAM System (2015) IEEE Trans. Robot., 31, pp. 1147-1163; Mur-Artal, R., Tardos, J., ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras (2017) IEEE Trans. Robot., 33, pp. 1255-1262; Stühmer, J., Gumhold, S., Cremers, D., Real-time dense geometry from a handheld camera (2010) Joint Pattern Recognition Symposium, pp. 11-20. , Springer: Berlin, Heidelberg; Engel, J., Schöps, T., Cremers, D.L.S.D.-S.L.A.M., (2014) Large-Scale Direct Monocular SLAM, pp. 834-849. , Proceedings of the European Conference on Computer Vision, Zurich, Switzerland, 6–12 September 2014, Springer, Cham, Switzerland; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J.L., Reid, I.D., Leonard, J.J., Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age (2016) IEEE Trans. Robot., 32, pp. 1309-1332; Taketomi, T., Uchiyama, H., Ikeda, S., Visual SLAM algorithms: A survey from 2010 to 2016 (2017) IPSJ Trans. Comput. Vis. Appl., 9; Rublee, E., Rabaud, V., Konolige, K., Bradski, G.O.R.B., (2011) An Efficient Alternative to SIFT Or SURF. Computer Vision (ICCV)., pp. 2564-2571. , In Proceedings of the 2011 International conference on computer vision, Barcelona, Spain, 6–13 November; Fan, Y., Han, H., Tang, Y., Zhi, T., Dynamic objects elimination in SLAM based on image fusion (2019) Pattern Recognit. Lett., 127, pp. 191-201; Sun, Y., Liu, M., Meng, M.Q.-H., Motion removal for reliable RGB-D SLAM in dynamic environments (2018) Robot. Auton. Syst., 108, pp. 115-128; Sedaghat, A., Mokhtarzade, M., Ebadi, H., Uniform Robust Scale-Invariant Feature Matching for Optical Remote Sensing Images (2011) IEEE Trans. Geosci. Remote. Sens., 49, pp. 4516-4527; Paul, S., Pati, U.C., Remote Sensing Optical Image Registration Using Modified Uniform Robust SIFT (2016) IEEE Geosci. Remote. Sens. Lett., 13, pp. 1300-1304; Bescos, B., Facil, J.M., Civera, J., Neira, J., DynaSLAM: Tracking, Mapping, and Inpainting in Dynamic Scenes (2018) IEEE Robot. Autom. Lett., 3, pp. 4076-4083; Yazdi, M., Bouwmans, T., New trends on moving object detection in video images captured by a moving camera: A survey (2018) Comput. Sci. Rev., 28, pp. 157-177; Wangsiripitak, S., Murray, D.W., Avoiding moving outliers in visual SLAM by tracking moving objects (2009) Proceedings of the 2009 IEEE International Conference on Robotics and Automation, pp. 375-380. , Kobe, Japan, 12–17 May 2009; Institute of Electrical and Electronics Engineers (IEEE): Hoboken, USA; Moo Yi, K., Yun, K., Wan Kim, S., Jin Chang, H., Young Choi, J., Detection of moving objects with non-stationary cameras in 5.8 ms (2013) Bringing Motion Detection to Your Mobile Device. in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 27-34. , Portland, OR, USA, 23–28 June; Sun, Y., Liu, M., Meng, M.Q.-H., Improving RGB-D SLAM in dynamic environments: A motion removal approach (2017) Robot. Auton. Syst., 89, pp. 110-122; Kim, D.H., Kim, J.H., Effective background model-based RGB-D dense visual odometry in a dynamic environment (2016) IEEE Trans. Robot., 32, pp. 1565-1573; Zhao, L., Liu, Z., Chen, J., Cai, W., Wang, W., Zeng, L., A Compatible Framework for RGB-D SLAM in Dynamic Scenes (2019) IEEE Access, 7, pp. 75604-75614; Li, S., Lee, D., RGB-D SLAM in Dynamic Environments Using Static Point Weighting (2017) IEEE Robot. Autom. Lett., 2, pp. 2263-2270; Redmon, J., Divvala, S., Girshick, R., Farhadi, A., (2016) You Only Look Once: Unified, Real-Time Object Detection., pp. 779-788. , In Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Las Vegas, NV, USA, 27–30 June; Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y., Berg, A.C., (2016) Ssd: Single Shot Multibox Detector, pp. 21-37. , Proceedings of the European Conference on Computer Vision, Amsterdam, The Netherlands, 11–14 October 2016; Springer, Cham, Switzerland; Badrinarayanan, V., Badrinarayanan, V., Cipolla, R., SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation (2017) IEEE Trans. Pattern Anal. Mach. Intell., 39, pp. 2481-2495; He, K., Gkioxari, G., Dollár, P., Girshick, R., Mask R-CNN (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 2961-2969. , Venice, Italy, 22–29 October; Zhang, L., Wei, L., Shen, P., Wei, W., Zhu, G., Song, J., Semantic SLAM Based on Object Detection and Improved Octomap (2018) IEEE Access, 6, pp. 75545-75559; Li, P., Zhang, G., Zhou, J., Yao, R., Zhang, X., Study on Slam Algorithm Based on Object Detection in Dynamic Scene (2019) Proceedings of the 2019 International Conference on Advanced Mechatronic Systems (Icamechs), , Shiga, Japan, 26–28 August; Zhong, F., Wang, S., Zhang, Z., Chen, C., Wang, Y., Detect-SLAM: Making Object Detection and SLAM Mutually Beneficial (2018) Proceedings of the 2018 IEEE Winter Conference on Applications of Computer Vision (WACV), pp. 1001-1010. , Tahoe, NV, USA, 12–15 March; Yu, C., Liu, Z., Liu, X., Xie, F., Yang, Y., Wei, Q., Fei, Q., DS-SLAM: A Semantic Visual SLAM towards Dynamic Environments (2018) Proceedings of the 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1168-1174. , Madrid, Spain, 1–5 October; Han, S., Xi, Z., Dynamic Scene Semantics SLAM Based on Semantic Segmentation (2020) IEEE Access, 8, pp. 43563-43570; Kovacs, A., Sziranyi, T., Improved Harris Feature Point Set for Orientation-Sensitive Urban-Area Detection in Aerial Images (2012) IEEE Geosci. Remote. Sens. Lett., 10, pp. 796-800; Rosten, E., Porter, R., Drummond, T., Faster and Better: A Machine Learning Approach to Corner Detection (2008) IEEE Trans. Pattern Anal. Mach. Intell., 32, pp. 105-119; Xie, H., Yuan, B., Xie, W., Moving target detection algorithm based on LK optical flow and three-frame difference method (2016) Appl. Sci. Technol., 3, pp. 23-27; Everingham, M., van Gool, L., Williams, C.K.I., Winn, J., Zisserman, A., The Pascal Visual Object Classes (VOC) Challenge (2009) Int. J. Comput. Vis., 88, pp. 303-338; Sturm, J., Engelhard, N., Endres, F., Burgard, W., Cremers, D., A benchmark for the evaluation of RGB-D SLAM systems (2012) Proceedings of the 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 573-580. , Vilamoura, Algarve, 7–12 October; Kerl, C., Sturm, J., Cremers, D., Robust odometry estimation for RGB-D cameras (2013) Proceedings of the 2013 IEEE International Conference on Robotics and Automation, pp. 6-10. , Karlsruhe, Germany, May; Chum, O., Matas, J., Kittler, J., Locally Optimized RANSAC (2003) Proceedings of the Joint Pattern Recognition Symposium, pp. 236-243. , Magdeburg, Germany, 10–12 September},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084169421&doi=10.3390%2fs20082432&partnerID=40&md5=b537da1df8b9754e0e37ba9435b039bf},
}

@conference{zhu-et-al:2021:9561584,
  author = {S. Zhu and X. Zhang and S. Guo and J. Li and H. Liu},
  journal = {Proceedings - IEEE International Conference on Robotics and Automation},
  title = {Lifelong Localization in Semi-Dynamic Environment},
  volume = {2021-May},
  pages = {14389--14395},
  doi = {10.1109/ICRA48506.2021.9561584},
  note = {cited By 0; Conference of 2021 IEEE International Conference on Robotics and Automation, ICRA 2021 ; Conference Date: 30 May 2021 Through 5 June 2021;  Conference Code:177050},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {Proc IEEE Int Conf Rob Autom},
  abstract = {Mapping and localization in non-static environments are fundamental problems in robotics. Most of previous methods mainly focus on static and highly dynamic objects in the environment, which may suffer from localization failure in semi-dynamic scenarios without considering objects with lower dynamics, such as parked cars and stopped pedestrians. In this paper, we introduce semantic mapping and lifelong localization approaches to recognize semi-dynamic objects in non-static environments. We also propose a generic framework that can integrate mainstream object detection algorithms with mapping and localization algorithms. The mapping method combines an object detection algorithm and a SLAM algorithm to detect semi-dynamic objects and constructs a semantic map that only contains semi-dynamic objects in the environment. During navigation, the localization method can classify observation corresponding to static and non-static objects respectively and evaluate whether those semi-dynamic objects have moved, to reduce the weight of invalid observation and localization fluctuation. Real-world experiments show that the proposed method can improve the localization accuracy of mobile robots in non-static scenarios. © 2021 IEEE},
  affiliation = {The State Key Laboratory of Automotive Safety and Energy, The School of Vehicle and Mobility, Tsinghua University, Beijing, 100084, China; The Department of Computer Science and Technology, Tsinghua University, Beijing, 100084, China},
  coden = {PIIAE},
  correspondence_address1 = {Zhang, X.; The State Key Laboratory of Automotive Safety and Energy, China; email: xyzhang@tsinghua.edu.cn},
  document_type = {Conference Paper},
  funding_details = {2019GQG1010},
  funding_text1 = {This work was supported by the National High Technology Research and Development Program of China under Grant No. 2018YFE0204300, and the Beijing Science and Technology Plan Project (Z191100007419008), and the Guoqiang Research Institute Project (2019GQG1010), and the National Natural Science Foundation of China under Grant No. U1964203.},
  funding_text2 = {This work was supported by the National High Technology Research and Development Program of China under Grant No. 2018YFE0204300, and the Beijing Science and Technology Plan Project (Z191100007419008), and the Guoqiang Research Institute Project (2019GQG1010), and the National Natural Science Foundation of China under Grant No. U1964203. It is sponsored by Tsinghua University-Didi Joint Research Center for Future Mobility.},
  isbn = {9781728190778},
  issn = {10504729},
  language = {English},
  references = {Thrun, S., Burgard, W., Fox, D., A probabilistic approach to concurrent mapping and localization for mobile robots (1998) Autonomous Robots, 5 (3-4), pp. 253-271; Tardós, J.D., Neira, J., Newman, P.M., Leonard, J.J., Robust mapping and localization in indoor environments using sonar data (2002) The International Journal of Robotics Research, 21 (4), pp. 311-330; Aycard, O., Laroche, P., Charpillet, F., Mobile robot localization in dynamic environments using places recognition (1998) Proceedings. 1998 IEEE International Conference on Robotics and Automation (Cat. No. 98CH36146), 4, pp. 3135-3140; Andrade-Cetto, J., Sanfeliu, A., Concurrent map building and localization on indoor dynamic environments (2002) International Journal of Pattern Recognition and Artificial Intelligence, 16, pp. 361-374. , 03; Wan, G., Yang, X., Cai, R., Li, H., Zhou, Y., Wang, H., Song, S., Robust and precise vehicle localization based on multi-sensor fusion in diverse city scenes (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 4670-4677; Fox, D., Burgard, W., Thrun, S., Markov localization for mobile robots in dynamic environments (1999) Journal of Artificial Intelligence Research, 11, pp. 391-427; Hahnel, D., Triebel, R., Burgard, W., Thrun, S., Map building with mobile robots in dynamic environments (2003) 2003 IEEE International Conference on Robotics and Automation (Cat. No. 03CH37422), 2, pp. 1557-1563; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 90-97; Aldibaja, M., Suganuma, N., Yoneda, K., Robust intensity-based localization method for autonomous driving on snow-wet road surface (2017) IEEE Transactions on Industrial Informatics, 13 (5), pp. 2369-2378; Valencia, R., Saarinen, J., Andreasson, H., Vallvé, J., Andrade-Cetto, J., Lilienthal, A.J., Localization in highly dynamic environments using dual-timescale NDT-mcl (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3956-3962; Wang, C.-C., Thorpe, C., Thrun, S., Hebert, M., Durrant-Whyte, H., Simultaneous localization, mapping and moving object tracking (2007) The International Journal of Robotics Research, 26 (9), pp. 889-916; Stenborg, E., Toft, C., Hammarstrand, L., Long-term visual localization using semantically segmented images (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 6484-6490; Doherty, K., Fourie, D., Leonard, J., Multimodal semantic slam with probabilistic data association (2019) 2019 International Conference on Robotics and Automation (ICRA), pp. 2419-2425; Chen, S.W., Nardari, G.V., Lee, E.S., Qu, C., Liu, X., Romero, R.A.F., Kumar, V., SloaM: Semantic lidar odometry and mapping for forest inventory (2020) IEEE Robotics and Automation Letters, 5 (2), pp. 612-619; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2d lidar slam (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 1271-1278; Burgard, W., Cremers, A.B., Fox, D., Hähnel, D., Lakemeyer, G., Schulz, D., Steiner, W., Thrun, S., Experiences with an interactive museum tour-guide robot (1999) Artificial Intelligence, 114 (1-2), pp. 3-55; Hähnel, D., Schulz, D., Burgard, W., Map building with mobile robots in populated environments (2002) IROS, pp. 496-501; Wang, C.-C., Thorpe, C., Simultaneous localization and mapping with detection and tracking of moving objects (2002) Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292), 3, pp. 2918-2924; Wolf, D.F., Sukhatme, G.S., Mobile robot simultaneous localization and mapping in dynamic environments (2005) Autonomous Robots, 19 (1), pp. 53-65; Krajník, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4558-4563; Gallagher, G., Srinivasa, S.S., Bagnell, J.A., Ferguson, D., GATMO: A generalized approach to tracking movable objects (2009) 2009 IEEE International Conference on Robotics and Automation, pp. 2043-2048; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots (2005) Robotics: Science and Systems, pp. 17-24; Montesano, L., Minguez, J., Montano, L., Modeling the static and the dynamic parts of the environment to improve sensor-based navigation (2005) Proceedings of the 2005 IEEE International Conference on Robotics and Automation, pp. 4556-4562; Meyer-Delius, D., Beinhofer, M., Burgard, W., Occupancy grid models for robot mapping in changing environments (2012) Twenty-Sixth AAAI Conference on Artificial Intelligence; Akai, N., Morales, L.Y., Murase, H., Mobile robot localization considering class of sensor observations (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3159-3166; Li, A.Q., Xanthidis, M., O'Kane, J.M., Rekleitis, I., Active localization with dynamic obstacles (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1902-1909; Ding, W., Hou, S., Gao, H., Wan, G., Song, S., Lidar inertial odometry aided robust lidar localization system in changing city scenes (2020) 2020 Proceedings of the IEEE International Conference on Robotics and Automation (ICRA); Egger, P., Borges, P.V., Catt, G., Pfrunder, A., Siegwart, R., Dubé, R., PoseMap: Lifelong, multi-environment 3d lidar localization (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3430-3437; Meyer-Delius, D., Hess, J., Grisetti, G., Burgard, W., Temporary maps for robust localization in semi-static environments (2010) 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 5750-5755; Tipaldi, G.D., Meyer-Delius, D., Burgard, W., Lifelong localization in changing environments (2013) The International Journal of Robotics Research, 32 (14), pp. 1662-1678; Xiao, L., Wang, J., Qiu, X., Rong, Z., Zou, X., Dynamic-slam: Semantic monocular visual localization and mapping based on deep learning in dynamic environment (2019) Robotics and Autonomous Systems, 117, pp. 1-16; Bescos, B., Fácil, J.M., Civera, J., Neira, J., Dynaslam: Tracking, mapping, and inpainting in dynamic scenes (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 4076-4083; Brasch, N., Bozic, A., Lallemand, J., Tombari, F., Semantic monocular slam for highly dynamic environments (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 393-400; Vineet, V., Miksik, O., Lidegaard, M., Nießner, M., Golodetz, S., Prisacariu, V.A., Kähler, O., Pérez, P., Incremental dense semantic stereo fusion for large-scale semantic scene reconstruction (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 75-82; Yu, C., Liu, Z., Liu, X.-J., Xie, F., Yang, Y., Wei, Q., Fei, Q., DSSLAM: A semantic visual slam towards dynamic environments (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1168-1174; Wang, B.H., Chao, W.-L., Wang, Y., Hariharan, B., Weinberger, K.Q., Campbell, M., Ldls: 3-d object segmentation through label diffusion from 2-d images (2019) IEEE Robotics and Automation Letters, 4 (3), pp. 2902-2909; Redmon, J., Farhadi, A., (2018) Yolov3: An Incremental Improvement, , arXiv preprint; Grupp, M., (2017) Evo: Python Package for the Evaluation of Odometry and Slam, , https://github.com/MichaelGrupp/evo},
  source = {Scopus},
  sponsors = {Baidu; Biomimetic Intelligence and Robotics; dji; et al.; Mech Mind Robotics Technologies; Toyota Research Institute},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125438883&doi=10.1109%2fICRA48506.2021.9561584&partnerID=40&md5=cd3e37612d5d11bb6fe9b4fa8507f254},
}

@article{an-et-al:2016:0,
  author = {S.-Y. An and L.-K. Lee and S.-Y. Oh},
  journal = {Autonomous Robots},
  title = {Ceiling vision-based active SLAM framework for dynamic and wide-open environments},
  volume = {40},
  number = {2},
  pages = {291--324},
  doi = {10.1007/s10514-015-9453-0},
  note = {cited By 5},
  publisher = {Springer New York LLC},
  year = {2016},
  abbrev_source_title = {Auton. Robots},
  abstract = {A typical indoor environment can be divided into three categories; office (or room), hallway, and wide-open space such as lobby and hall. There have been numerous approaches for solving simultaneous localization and mapping (SLAM) problem in office (or room) and hallway. However, direct application of the existing approaches to wide-open space may be failed, because it has some distinguished features compared to other indoor places. To solve this problem, this paper proposes a new ceiling vision-based active SLAM framework, with an emphasis on practical deployment of service robot for commercial use in dynamically changing and wide-open environments by adopting the ceiling vision. First, for defining ceiling feature which can be extracted regardless of complexity of ceiling pattern we introduce a model-free landmark, i.e., visual node descriptor, which consists of edge points and their orientations in image space. Second, a recursive ‘explore and exploit’ is proposed for autonomous mapping. It is recursively performed by spreading out mapped area gradually while the robot is actively localized in the map. It can improve map accuracy due to frequent small loop closing. Third, a dynamic edge link (DEL) is proposed to cope with environmental changes in the map. Owing to DEL, we do not need to filter out corrupted sensor data and to distinguish moving object from static one. Also, a self-repairing map mechanism is introduced to deal with unexpected installation or removal of inner structures. We therefore achieve long-term navigation. Several simulations and real experiments in various places show that the proposed active SLAM framework could build a topologically consistent map, and demonstrated that it can be applied well to real environments such as wide-open space in a city hall and railway station. © 2015, Springer Science+Business Media New York.},
  affiliation = {Electronics and Telecommunications Research Institute (ETRI), Daegu, 711-883, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology (POSTECH), Pohang, Gyungbuk  790-784, South Korea},
  author_keywords = {Ceiling vision;  Dynamic environment;  Mobile robot;  SLAM;  Wide-open area},
  coden = {AUROF},
  correspondence_address1 = {An, S.-Y.; Electronics and Telecommunications Research Institute (ETRI)South Korea; email: syong.an@etri.re.kr},
  document_type = {Article},
  issn = {09295593},
  keywords = {Ceilings;  Mapping;  Mobile robots;  Robotics;  Robots, Dynamic environments;  Environmental change;  Indoor environment;  Railway stations;  Real environments;  Simultaneous localization and mapping problems;  SLAM;  Wide-open area, Indoor positioning systems},
  language = {English},
  references = {Albrecht, S., An analysis of VISUAL MONO-SLAM (2009) Master Thesis; An, S.-Y., Kang, J.-G., Lee, L.-K., Oh, S.-Y., Line segment-based indoor mapping with salient line feature extraction (2012) Advanced Robotics, 26 (5-6), pp. 437-460; An, S.-Y., Lee, L.-K., Oh, S.-Y., Ceiling vision-based topological mapping and exploration in wide-open area (2013) In RO-MAN, 2013 IEEE, 2013, pp. 1-6; Ayoung, K., Eustice, R.M., Real-time visual SLAM for autonomous underwater hull inspection using visual saliency (2013) IEEE Transactions on Robotics, 29 (3), pp. 719-733; Bailey, T., Nieto, J., Guivant, J., Stevens, M., Nebot, E., Consistency of the EKF-SLAM algorithm (2006) In 2006 IEEE/RSJ International Conference on intelligent robots and systems, pp. 3562-3568; Bay, H., Tuytelaars, T., & Van Gool, L. (2006). Surf: Speeded up robust features. In Computer vision–ECCV 2006 (pp. 404–417). New York: Springer; Breu, H., Gil, J., Kirkpatrick, D., Werman, M., Linear time Euclidean distance transform algorithms (1995) IEEE Transactions on Pattern Analysis and Machine Intelligence, 17 (5), pp. 529-533; Burgard, W., Stachniss, C., Grisetti, G., Steder, B., Kummerle, R., Dornhege, C., et al. (2009). A comparison of SLAM algorithms based on a graph of relations. In IEEE/RSJ International Conference on intelligent robots and systems, 2009. IROS 2009 (pp. 2089–2095). St. Louis, MO : IEEE; Callmer, J., Granström, K., Nieto, J., Ramos, F., Tree of words for visual loop closure detection in urban SLAM (2008) In Proceedings of the 2008 Australasian conference on robotics and automation, p. 8; Choi, J., Ahn, S., Choi, M., & Chung, W. K. (2006). Metric SLAM in home environment with visual objects and sonar features. In 2006 IEEE/RSJ international conference on intelligent robots and systems (pp. 4048-4053). San Diego: IEEE; Davison, A.J., Reid, I.D., Molton, N.D., Stasse, O., MonoSLAM: Real-time single camera SLAM (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 29 (6), pp. 1052-1067; Delaunay, B., Sur la sphère vide (1934) Bulletin of the Academy of Sciences of the USSR, 7, pp. 793-800; Dijkstra, E.W., A note on two problems in connexion with graphs (1959) Numerische Mathematik, 1 (1), pp. 269-271; Diosi, A., & Kleeman, L. (2005). Laser scan matching in polar coordinates with application to SLAM. In 2005 IEEE/RSJ international conference on intelligent robots and systems. (IROS 2005) (pp. 3317–3322). Edmonton, AB: IEEE; Dissanayake, M.G., Newman, P., Clark, S., Durrant-Whyte, H.F., Csorba, M., A solution to the simultaneous localization and map building (SLAM) problem (2001) IEEE Transactions on Robotics and Automation, 17 (3), pp. 229-241; Doucet, A., De Freitas, N., Murphy, K., & Russell, S. (2000). Rao-Blackwellised particle filtering for dynamic Bayesian networks. In Proceedings of the sixteenth conference on uncertainty in artificial intelligence (pp. 176–183). San Francisco: Morgan Kaufmann Publishers Inc; Estrada, C., Neira, J., Tardós, J.D., Hierarchical SLAM: Real-time accurate mapping of large environments (2005) IEEE Transactions on Robotics, 21 (4), pp. 588-596; Gaspar, J., Winters, N., Santos-Victor, J., Vision-based navigation and environmental representations with an omnidirectional camera (2000) IEEE Transactions on Robotics and Automation, 16 (6), pp. 890-898; Grisettiyz, G., Stachniss, C., & Burgard, W. (2005). Improving grid-based slam with rao-blackwellized particle filters by adaptive proposals and selective resampling. In Proceedings of the 2005 IEEE international conference on robotics and automation, 2005. ICRA 2005 (pp. 2432–2437). Barcelona: IEEE; Guivant, J.E., Nebot, E.M., Optimization of the simultaneous localization and map-building algorithm for real-time implementation (2001) IEEE Transactions on Robotics and Automation, 17 (3), pp. 242-257; (2003) Proceedings. ICRA’03, 2, pp. 1557-1563; Holz, D., Basilico, N., Amigoni, F., Behnke, S., Evaluating the efficiency of frontier-based exploration strategies (2010) In Robotics (ISR), 2010 41st international symposium on and 2010 6th German conference on robotics (ROBOTIK), 7–9 June, 2010 (2010), pp. 1-8; Hwang, S.-Y., Song, J.-B., Stable monocular SLAM with indistinguishable features on estimated ceiling plane using upward camera. In International conference on control, automation and systems, 2008 (2008) ICCAS, 2008, pp. 704-709; Hwang, S.-Y., Song, J.-B., Monocular vision-based SLAM in indoor environment using corner, lamp, and door features from upward-looking camera (2011) IEEE Transactions on Industrial Electronics, 58 (10), pp. 4804-4812; Jeong, W., Lee, K.M., CV-SLAM: A new ceiling vision-based SLAM technique (2005) In 2005 IEEE/RSJ international conference on intelligent robots and systems, 2005 (IROS 2005), pp. 3195-3200; Jeong, W.Y., Lee, K.M., Visual SLAM with line and corner features (2006) In 2006 IEEE/RSJ international conference on intelligent robots and systems, pp. 2570-2575; Julier, S.J., Uhlmann, J.K., Using covariance intersection for SLAM (2007) Robotics and Autonomous Systems, 55 (1), pp. 3-20; Kang, J.-G., An, S.-Y., Oh, S.-Y., Navigation strategy for the service robot in the elevator environment. In International conference on control, automation and systems, 2007 (2007) ICCAS’07, pp. 1092-1097; Karlsson, N., Di Bernardo, E., Ostrowski, J., Goncalves, L., Pirjanian, P., Munich, M.E., The vSLAM algorithm for robust localization and mapping. In Proceedings of the 2005 (2005) IEEE international conference on robotics and automation, 2005. ICRA, 2005, pp. 24-29; Kim, J., Sukkarieh, S., Real-time implementation of airborne inertial-SLAM (2007) Robotics and Autonomous Systems, 55 (1), pp. 62-71; Kröse, B.J., Vlassis, N., Bunschoten, R., Motomura, Y., A probabilistic model for appearance-based robot localization (2001) Image and Vision Computing, 19 (6), pp. 381-391; Kundu, A., Krishna, K.M., Jawahar, C., Realtime multibody visual slam with a smoothly moving monocular camera (2011) In 2011 IEEE international conference on computer vision (ICCV), pp. 2080-2087; (2002) Proceedings. ICRA’02, 4, pp. 3918-3923; Lee, J.-S., Chung, W.K., Robust mobile robot localization in highly non-static environments (2010) Autonomous Robots, 29 (1), pp. 1-16; Leung, C., Huang, S., Dissanayake, G., Active SLAM in structured environments. In (2008) IEEE international conference on robotics and automation, 2008. ICRA, 8, pp. 1898-1903; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Martinez-Cantin, R., de Freitas, N., Brochu, E., Castellanos, J., Doucet, A., A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot (2009) Autonomous Robots, 27 (2), pp. 93-103; Montemerlo, M., Thrun, S., Koller, D., Wegbreit, B., FastSLAM: A factored solution to the simultaneous localization and mapping problem (2002) In AAAI/IAAI, 2002, pp. 593-598; Nieto, J., Bailey, T., & Nebot, E. (2006). Scan-slam: Combining ekf-slam and scan correlation. In Field and service robotics, 2006 (pp. 167–178). New York: Springer; Nieto, J., Bailey, T., Nebot, E., Recursive scan-matching SLAM (2007) Robotics and Autonomous Systems, 55 (1), pp. 39-49; Paz, L.M., Tardós, J.D., Neira, J., Divide and conquer: EKF SLAM in O(n) (2008) IEEE Transactions on Robotics, 24 (5), pp. 1107-1120; Roda, J.P., Sáez, J.M., Escolano, F., Ceiling mosaics through information-based SLAM. In IEEE/RSJ international conference on intelligent robots and systems, 2007 (2007) IROS, 7, pp. 3898-3904; Rosten, E., Porter, R., Drummond, T., Faster and better: A machine learning approach to corner detection (2010) IEEE Transactions on Pattern Analysis and Machine Intelligence, 32 (1), pp. 105-119; Rusinkiewicz, S., Levoy, M., Efficient variants of the ICP algorithm (2001) In Proceedings of third international conference on 3-D digital imaging and modeling, 2001, pp. 145-152; Shafait, F., Keysers, D., Breuel, T.M., Efficient implementation of local adaptive thresholding techniques using integral images (2008) DRR, 6815, p. 681510; Sim, R., Roy, N., Global a-optimal robot exploration in slam. In Proceedings of the 2005 (2005) IEEE international conference on robotics and automation, 2005. ICRA, pp. 661-666; Sunderhauf, N., & Protzel, P. Towards a robust back-end for pose graph SLAM. In 2012 IEEE international conference on robotics and automation (ICRA) (pp. 1254–1261); Tardós, J.D., Neira, J., Newman, P.M., Leonard, J.J., Robust mapping and localization in indoor environments using sonar data (2002) The International Journal of Robotics Research, 21 (4), pp. 311-330; Thrun, S., Beetz, M., Bennewitz, M., Burgard, W., Cremers, A.B., Dellaert, F., Probabilistic algorithms and the interactive museum tour-guide robot minerva (2000) The International Journal of Robotics Research, 19 (11), pp. 972-999; Thrun, S., Bennewitz, M., Burgard, W., Cremers, A.B., Dellaert, F., Fox, D., MINERVA: A second-generation museum tour-guide robot (1999) In Proceedings of 1999 IEEE international conference on robotics and automation, 3; Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic robotics, , MIT Press, Cambridge, MA; Thrun, S., Montemerlo, M., The graph SLAM algorithm with applications to large-scale mapping of urban structures (2006) The International Journal of Robotics Research, 25 (5-6), pp. 403-429; Ulrich, I., Nourbakhsh, I., Appearance-based place recognition for topological localization. In Proceedings of (2000) IEEE international conference on robotics and automation, 2000. ICRA’00, 2, pp. 1023-1029; Viola, P., Jones, M.J., Robust real-time face detection (2004) International Journal of Computer Vision, 57 (2), pp. 137-154; Wang, C.-C., Thorpe, C., Thrun, S., Hebert, M., Durrant-Whyte, H., Simultaneous localization, mapping and moving object tracking (2007) The International Journal of Robotics Research, 26 (9), pp. 889-916; Wilson, S.W., (1996). Explore/exploit strategies in autonomy (1996) In From animals to animats 4: Proceedings of the 4th international conference on simulation of adaptive behavior, pp. 325-332; Wolf, D.F., Sukhatme, G.S., Mobile robot simultaneous localization and mapping in dynamic environments (2005) Autonomous Robots, 19 (1), pp. 53-65; Xu, D., Han, L., Tan, M., Li, Y.F., Ceiling-based visual positioning for an indoor mobile robot with monocular vision (2009) IEEE Transactions on Industrial Electronics, 56 (5), pp. 1617-1628},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955714361&doi=10.1007%2fs10514-015-9453-0&partnerID=40&md5=e80767e732bc3e6c550a488949184c68},
}

@article{krajnik-et-al:2017:2665664,
  author = {T. Krajnik and J. P. Fentanes and J. M. Santos and T. Duckett},
  journal = {IEEE Transactions on Robotics},
  title = {FreMEn: Frequency map enhancement for long-term mobile robot autonomy in changing environments},
  volume = {33},
  number = {4},
  pages = {964--977},
  doi = {10.1109/TRO.2017.2665664},
  note = {cited By 64},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2017},
  abbrev_source_title = {IEEE Trans. Rob.},
  abstract = {We present a new approach to long-term mobile robot mapping in dynamic indoor environments. Unlike traditional world models that are tailored to represent static scenes, our approach explicitly models environmental dynamics. We assume that some of the hidden processes that influence the dynamic environment states are periodic and model the uncertainty of the estimated state variables by their frequency spectra. The spectral model can represent arbitrary timescales of environment dynamics with low memory requirements. Transformation of the spectral model to the time domain allows for the prediction of the future environment states, which improves the robot's long-term performance in changing environments. Experiments performed over time periods of months to years demonstrate that the approach can efficiently represent large numbers of observations and reliably predict future environment states. The experiments indicate that the model's predictive capabilities improve mobile robot localization and navigation in changing environments. © 2004-2012 IEEE.},
  affiliation = {Lincoln Centre for Autonomous Systems, University of Lincoln, Lincoln, LN6 7TS, United Kingdom; Faculty of Electrical Engineering, Czech Technical University, Prague, 16636, Czech Republic},
  art_number = {7878680},
  author_keywords = {Localization;  long-term autonomy;  mapping},
  correspondence_address1 = {Krajnik, T.; Lincoln Centre for Autonomous Systems, United Kingdom; email: tkrajnik@lincoln.ac.uk},
  document_type = {Article},
  issn = {15523098},
  keywords = {Mobile robots;  Robot applications;  Uncertainty analysis, Changing environment;  Dynamic environments;  Environment dynamics;  Environmental dynamics;  Long term performance;  Mobile robot localization;  Mobile robot mappings;  Predictive capabilities, Robots},
  language = {English},
  references = {Thrun, S., Burgard, W., Fox, D., (2005) Probabilistic Robotics (Intelligent Robotics and Autonomous Agents, , Cambridge MA USA MIT Press; Austin, D., Fletcher, L., Zelinsky, A., Mobile robotics in the long term-exploring the fourth dimension (2001) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, 2, pp. 613-618; Churchill, W.S., Newman, P., Experience-based navigation for longterm localisation (2013) Int. J. Robot. Res, 32, pp. 1645-1661; Krajník, T., Fentanes, J.P., Mozos, O.M., Duckett, T., Ekekrantz, J., Hanheide, M., Long-Term topological localization for service robots in dynamic environments using spectral maps (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 4537-4542; Tipaldi, G.D., Meyer-Delius, D., Burgard, W., Lifelong localization in changing environments (2013) Int. J. Robot. Res, 32, pp. 1662-1678; Neubert, P., Sünderhauf, N., Protzel, P., Superpixel-based appearance change prediction for long-Term navigation across seasons (2014) Robot. Auton. Syst, 69, pp. 15-27; Krajník, T., Fentanes, J.P., Cielniak, G., Dondrup, C., Duckett, T., Spectral analysis for long-Term robotic mapping (2014) Proc. IEEE Int. Conf. Robot. Autom, pp. 3706-3711; Krajník, T., Kulich, M., Mudrová, L., Ambrus, R., Duckett, T., Where's waldo at time t? Using spatio-Temporal models for mobile robot search (2015) Proc. Int. Conf. Robot. Autom, pp. 2140-2146; Krajník, T., Santos, J., Seemann, B., Duckett, T., Froctomap: An efficient spatio-Temporal environment representation (2014) Advances in Autonomous Robotics Systems, pp. 281-282. , New York, NY, USA Springer; Santos, J.M., Krajnik, T., Pulido Fentanes, J., Duckett, T., Lifelong information-driven exploration to complete and refine 4D spatio-Temporal maps (2016) IEEE Robot. Autom. Lett, 1 (2), pp. 684-691. , Jul; Thrun, S., Robotic mapping: A survey (2002) Exploring Artificial Intelligence in the New Millennium, pp. 1-35. , San Mateo, CA, USA: Morgan Kaufmann; Hähnel, D., Schulz, D., Burgard, W., Mobile robot mapping in populated environments (2003) Adv. Robot, 17, pp. 579-597; Wolf, D., Sukhatme, G., Mobile robot simultaneous localization and mapping in dynamic environments (2005) Auton. Robots, 19, pp. 53-65; Wang, C.-C., Thorpe, C., Thrun, S., Hebert, M., Durrant-Whyte, H., Simultaneous localization, mapping and moving object tracking (2007) Int. J. Robot. Res, 26 (9), pp. 889-916; Migliore, D., Rigamonti, R., Marzorati, D., Matteucci, M., Sorrenti, D.G., Use a single camera for simultaneous localization and mapping with mobile object tracking in dynamic environments (2009) Proc. ICRA Workshop Safe Navigation Dynamic Environ; Ambrus, R., Bore, N., Folkesson, J., Jensfelt, P., Meta-rooms: Building and maintaining long term spatial models in a dynamic world (2014) Proc. Int. Conf. Intell. Robots Syst, pp. 1854-1861; Biber, P., Duckett, T., Dynamicmaps for long-Term operation ofmobile service robots (2005) Proc. Robot., Sci. Syst, pp. 17-24; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired SLAM system (2010) Int. J. Robot. Res, 29 (9), pp. 1131-1153; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Proc. Int. Conf. Intell. Robots Syst, pp. 1156-1163; Hochdorfer, S., Schlegel, C., Towards a robust visual SLAMapproach (2009) Proc. Int. Conf. Adv. Robot, pp. 1-6; Stachniss, C., Burgard, W., Mobile robot mapping and localization in non-static environments (2005) Proc. 20th Nat. Conf. Artif. Intell, pp. 1324-1329; Mitsou, N., Tzafestas, C., Temporal occupancy grid for mobile robot dynamic environment mapping (2007) Proc. Mediterranean Conf. Control Autom, pp. 1-8; Arbuckle, D., Howard, A., Mataric, M., Temporal occupancy grids: A method for classifying the spatio-Temporal properties of the environment (2002) Proc. IEEE/RSJ Int.Conf. Intell. Robots Syst, 1, pp. 409-414; Dayoub, F., Cielniak, G., Duckett, T., Long-Term experiments with an adaptive spherical view representation for navigation in changing environments (2011) J. Robot. Auton. Syst, 59, pp. 285-295; Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong feature-based mapping in semi-static environments (2016) Proc. Int. Conf. Robot. Autom, pp. 1063-1070; Yguel, M., Aycard, O., Laugier, C., Wavelet occupancy grids: Amethod for compact map building (2006) Field and Service Robotics, pp. 219-230. , NewYork, NY, USA Springer; Kucner, T., Saarinen, J., Magnusson, M., Lilienthal, A.J., Conditional transition maps: Learning motion patterns in dynamic environments (2013) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 1-6. , Nov. 3-8; Krajnik, T., Pulido Fentanes, J., Machado Santos, J., Duckett, T., Frequency map enhancement: Introducing dynamics into static environment models (2016) Proc. ICRA 2016 Workshop AI Long-Term Autonomy; Bracewell, R.N., Bracewell, R., (1986) The Fourier Transform and Its Applications, p. 31999. , New York NY USA McGraw-Hill; Krajník, T., Fentanes, J.P., Mozos, O.M., Duckett, T., Ekekrantz, J., Hanheide, M., Long-Term mobile robot localization in dynamic environments using spectral maps (2015) Proc. AAAI Conf. Artif. Intell. (Video Session, , http://www.aaaivideos.org/2015/03_spectral_map_localization/, Online]. Available; Hawes, N., The STRANDS project: Long-Term autonomy in everyday environments (2017) IEEE Robot. Autom. Mag, , to be published; (2016) The FFTW C Library, , http://www.fftw.org/, Online]. Available; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2015) J. Field Robot, 33, pp. 561-590. , http://dx.doi.org/10.1002/rob.21595, Online]. Available; Calonder, M., Lepetit, V., Strecha, C., Fua, P., BRIEF: Binary robust independent elementary features (2010) Proc. 11th Eur. Conf. Comput. Vis, pp. 778-792; Krajnik, T., Cristóforis, P., Nitsche, M., Kusumam, K., Duckett, T., Image features and seasons revisited (2015) Proc. IEEE Eur. Conf. Mobile Robots, pp. 1-7; Krajník, T., Cristóforis, P., Kusumam, K., Neubert, P., Duckett, T., Image features for visual teach-And-repeat navigation in changing environments (2016) Robot. Auton. Syst, 88, pp. 127-141; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) Proc. IEEE Int. Conf. Robot. Autom, pp. 90-97; Carlevaris-Bianco, N., Eustice, R.M., Learning visual feature descriptors for dynamic lighting conditions (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 2769-2776; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan north campus long-Term vision and lidar dataset (2015) Int. J. Robot. Res, 35, pp. 1023-1035; (2017) Stromovka Dataset, , http://mobilerobotics.eu/datasets/stromovka, Online]. Available; Krajník, T., Simple, yet stable bearing-only navigation (2010) J. Field Robot, 27, pp. 511-533. , Sep./Oct; Krajník, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 4558-4563; Mishkin, D., Perdoch, M., Matas, J., Place recognition with WxBS retrieval (2015) Proc. CVPRWorkshop Visual Place Recog. Changing Environ; Cadena, C., Past, present, and future of simultaneous localization and mapping: Towards the robust-perception age (2016) IEEE Trans. Robot, 32 (6), pp. 1309-1332; Krajník, T., Nitsche, M., Faigl, J., Duckett, T., Mejail, M., Přeučil, L., External localization system for mobile robotics (2013) Proc. Int. Conf. Advanced Robot; Fentanes, J.P., Lacerda, B., Krajník, T., Hawes, N., Hanheide, M., Now or later? Predicting and maximising success of navigation actions from long-Term experience (2015) Int. Conf. Robot. Autom, pp. 1112-1117. , May; Santos, M.J., Krajník, T., Duckett, T., Spatio-Temporal exploration strategies for long-Term autonomy of mobile robots (2016) Robot. Auton. Syst, , Elsevier},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015635452&doi=10.1109%2fTRO.2017.2665664&partnerID=40&md5=4d33d405535b3dd578db6a208b94485d},
}

@conference{naseer-et-al:2015:7324181,
  author = {T. Naseer and B. Suger and M. Ruhnke and W. Burgard},
  journal = {2015 European Conference on Mobile Robots, ECMR 2015 - Proceedings},
  title = {Vision-based Markov localization across large perceptual changes},
  pages = {1--6},
  doi = {10.1109/ECMR.2015.7324181},
  note = {cited By 8; Conference of European Conference on Mobile Robots, ECMR 2015 ; Conference Date: 2 September 2015 Through 4 September 2015;  Conference Code:118603},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2015},
  abbrev_source_title = {Eur. Conf. Mob. Robots, ECMR 2015 - Proc.},
  abstract = {Recently, there has been significant progress towards lifelong, autonomous operation of mobile robots, especially in the field of localization and mapping. One important challenge in this context is visual localization under substantial perceptual changes, for example, coming from different seasons. In this paper, we present an approach to localize a mobile robot with a low frequency camera with respect to an image sequence, recorded previously within a different season. Our approach uses a discrete Bayes filter and a sensor model based on whole image descriptors. Thereby it exploits sequential information to model the dynamics of the system. Since we compute a probability distribution over the whole state space, our approach can handle more complex trajectories that may include same season loop-closures as well as fragmented sub-sequences. Throughout an extensive experimental evaluation on challenging datasets, we demonstrate that our approach outperforms state-of-the-art techniques. © 2015 IEEE.},
  affiliation = {Autonomous Intelligent Systems Group, University of Freiburg, Germany},
  art_number = {7324181},
  author_keywords = {Cameras;  Context;  Databases;  Lead;  Matched filters;  Robot sensing systems},
  document_type = {Conference Paper},
  isbn = {9781467391634},
  keywords = {Cameras;  Database systems;  Image processing;  Lead;  Matched filters;  Mobile robots;  Probability distributions, Autonomous operations;  Context;  Experimental evaluation;  Localization and mappings;  Markov localizations;  Robot sensing system;  Sequential information;  State-of-the-art techniques, Robots},
  language = {English},
  references = {Badino, H., Huber, D., Kanade, T., Real-time topometric localization (2012) Robotics and Automation (ICRA), 2012 IEEE International Conference On. IEEE, pp. 1635-1642; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (SURF) (2008) Comput. Vis. Image Underst., 110 (3), pp. 346-359; Bennewitz, M., Stachniss, C., Burgard, W., Behnke, S., Metric localization with scale-invariant visual features using a single perspective camera (2006) European Robotics Symposium, pp. 143-157; Cadena, C., Galvez-Lopez, D., Tardos, J.D., Neira, Robust place recognition with stereo sequences (2012) Robotics, IEEE Transactions on, 28 (4), pp. 871-885; Churchill, W., Newman, P., Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation (2012) Proc. of the IEEE Int. Con! on Robitics and Automation (ICRA); Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) The International Fournal of Robotics Research (LJRR), 27 (6), pp. 647-665; Cummins, M., Newman, P., Highly scalable appearance-only SLAM-FAB-MAP 2. 0 (2009) Proc. of Robotics: Science and Systems, , Seattle, USA, June; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) Proc. of the IEEE Int. Con! on Computer Vision and Pattern Recognition (CVPR); Davison, A.J., Reid, D., Molton, N.D., Stasse, O., Monoslam: Real-time single camera slam (2007) IEEE Trans. Pattern Anal. Mach. Intell., 29, p. 2007; Fox, D., Hightower, J., Liao, L., Schulz, D., Borriello, G., Bayesian filtering for location estimation (2003) IEEE Pervasive Computing, 2 (3), pp. 24-33; Glover, A., Maddern, W., Milford, M., Wyeth, G., FAB-MAP + RatSLAM: Appearance-based slam for multiple times of day (2010) Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), pp. 3507-3512; Hansen, P., Browning, B., Visual place recognition using hmm sequence matching (2014) Intelligent Robots and Systems (IROS 2014), 2014 IEEEIRSf International Conference On. IEEE, pp. 4549-4555; Lowe, D., Distinctive image features from scale-invariant keypoints (2004) Int. F. Comput. Vision, 60 (2), pp. 91-110. , Nov; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired slam system (2010) Int. 1. Rob. Res., 29 (9), pp. 1131-1153. , Aug; Milford, M., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. of the IEEE Int. Con! on Robitics and Automation (ICRA); Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) AAAI Conference on Artificial Intelligence (AAAI); Neubert, P., Siinderhauf, N., Nd Protzel P, A., Superpixel-based appearance change prediction for long-term navigation across seasons (2014) Robotics and Autonomous Systems; Pepperell, E., Corke, P., Milford, M., Towards persistent visual navigation using smart (2013) Proc. of Australasian Conference on Robotics and Automation (ACRA). ARAA; Valgren, C., Lilienthal, A., SIFT, SURF & Seasons: Appearancebased long-term localization in outdoor environments (2010) Robotics and Autonomous Systems, 85 (2), pp. 149-156; Vysotska, O., Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Efficient and effective matching of image sequences under substantial appearance changes exploiting GPS priors (2015) Proc. of the IEEE Int. Con! on Robotics & Automation (ICRA)},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962272490&doi=10.1109%2fECMR.2015.7324181&partnerID=40&md5=0450cc0fa1e6c4c9196d2d181a5f0d30},
}

@inproceedings{naseer-et-al:2017:7989305,
  author = {T. Naseer and G. L. Oliveira and T. Brox and W. Burgard},
  journal = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {Semantics-aware visual localization under challenging perceptual conditions},
  pages = {2614--20},
  doi = {10.1109/ICRA.2017.7989305},
  note = {semantics-aware visual localization;visual place recognition;long-term visual navigation;robot localization;image feature descriptions;deep convolutional neural networks;spatially inconsistent image matches;nonperfect image matches;discriminative holistic image representation;dense scene description;salient scene description;image segmentation;perceptual scene dynamics;structural scene dynamics;Freiburg;},
  address = {Piscataway, NJ, USA},
  year = {2017},
  abstract = {Visual place recognition under difficult perceptual conditions remains a challenging problem due to changing weather conditions, illumination and seasons. Long-term visual navigation approaches for robot localization should be robust to these dynamics of the environment. Existing methods typically leverage feature descriptions of whole images or image regions from Deep Convolutional Neural Networks. Some approaches also exploit sequential information to alleviate the problem of spatially inconsistent and non-perfect image matches. In this paper, we propose a novel approach for learning a discriminative holistic image representation which exploits the image content to create a dense and salient scene description. These salient descriptions are learnt over a variety of datasets under large perceptual changes. Such an approach enables us to precisely segment the regions of an image which are geometrically stable over large time lags. We combine features from these salient regions and an off-the-shelf holistic representation to form a more robust scene descriptor. We also introduce a semantically labeled dataset which captures extreme perceptual and structural scene dynamics over the course of 3 years. We evaluated our approach with extensive experiments on data collected over several kilometers in Freiburg and show that our learnt image representation outperforms off-the-shelf features from the deep networks and hand-crafted features.},
  copyright = {Copyright 2017, The Institution of Engineering and Technology},
  keywords = {convolution;image matching;image representation;image segmentation;neural nets;robot vision;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/ICRA.2017.7989305},
}

@conference{qin-et-al:2020:9340939,
  author = {T. Qin and T. Chen and Y. Chen and Q. Su},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {AVP-SLAM: Semantic visual mapping and localization for autonomous vehicles in the parking lot},
  pages = {5939--5945},
  doi = {10.1109/IROS45743.2020.9340939},
  note = {cited By 12; Conference of 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2020 ; Conference Date: 24 October 2020 Through 24 January 2021;  Conference Code:167055},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Autonomous valet parking is a specific application for autonomous vehicles. In this task, vehicles need to navigate in narrow, crowded and GPS-denied parking lots. Accurate localization ability is of great importance. Traditional visual-based methods suffer from tracking lost due to texture-less regions, repeated structures, and appearance changes. In this paper, we exploit robust semantic features to build the map and localize vehicles in parking lots. Semantic features contain guide signs, parking lines, speed bumps, etc, which typically appear in parking lots. Compared with traditional features, these semantic features are long-term stable and robust to the perspective and illumination change. We adopt four surround-view cameras to increase the perception range. Assisting by an IMU (Inertial Measurement Unit) and wheel encoders, the proposed system generates a global visual semantic map. This map is further used to localize vehicles at the centimeter level. We analyze the accuracy and recall of our system and compare it against other methods in real experiments. Furthermore, we demonstrate the practicability of the proposed system by the autonomous parking application. © 2020 IEEE.},
  affiliation = {IAS BU, Huawei Technologies, Shanghai, China},
  art_number = {9340939},
  coden = {85RBA},
  document_type = {Conference Paper},
  isbn = {9781728162126},
  issn = {21530858},
  keywords = {Agricultural robots;  Cameras;  Intelligent robots;  Semantics;  Textures;  Traffic signs, Autonomous Parking;  Centimeter levels;  Illumination changes;  Inertial measurement unit;  Semantic features;  Visual mapping;  Visual semantics;  Wheel encoders, Autonomous vehicles},
  language = {English},
  references = {Mur-Artal, R., Tardós, J.D., Orb-slam2: An open-source slam system for monocular, stereo, and RGB-D cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Engel, J., Schöps, T., Cremers, D., Lsd-slam: Large-scale direct monocular slam (2014) European Conference on Computer Vision. Springer International Publishing, pp. 834-849; Qin, T., Li, P., Shen, S., Vins-mono: A robust and versatile monocular visual-inertial state estimator (2018) IEEE Trans. Robot., 34 (4), pp. 1004-1020; Leutenegger, S., Lynen, S., Bosse, M., Siegwart, R., Furgale, P., Keyframe-based visual-inertial odometry using nonlinear optimization (2014) Int. J. Robot. Research, 34 (3), pp. 314-334. , Mar; Mourikis, A.I., Roumeliotis, S.I., A multi-state constraint Kalman filter for vision-aided inertial navigation (2007) Proc. of the IEEE Int. Conf. of Robot. of Autom., Roma, Italy, pp. 3565-3572. , Apr; Zhang, J., Singh, S., Loam: Lidar odometry and mapping in realtime (2014) Robotics: Science and Systems, 2, p. 9; Le Gentil, C., Vidal-Calleja, T., Huang, S., In2lama: Inertial lidar localisation and mapping (2019) 2019 International Conference on Robotics and Automation (ICRA). IEEE, pp. 6388-6394; Yin, H., Wang, Y., Tang, L., Ding, X., Huang, S., Xiong, R., 3d lidar map compression for efficient localization on resource constrained vehicles (2020) IEEE Transactions on Intelligent Transportation Systems; Klein, G., Murray, D., Parallel tracking and mapping for small ar workspaces (2007) Mixed and Augmented Reality, 2007. IEEE and ACM International Symposium on, pp. 225-234; Forster, C., Pizzoli, M., Scaramuzza, D., SVO: Fast semi-direct monocular visual odometry (2014) Proc. of the IEEE Int. Conf. of Robot. of Autom., , May, Hong Kong, China; Kitt, B., Geiger, A., Lategahn, H., Visual odometry based on stereo image sequences with ransac-based outlier rejection scheme (2010) 2010 Ieee Intelligent Vehicles Symposium. IEEE, pp. 486-492; Forster, C., Carlone, L., Dellaert, F., Scaramuzza, D., On-manifold preintegration for real-time visual-inertial odometry (2017) IEEE Trans. Robot., 33 (1), pp. 1-21; Lynen, S., Sattler, T., Bosse, M., Hesch, J.A., Pollefeys, M., Siegwart, R., Get out of My Lab: Large-scale, Real-time Visual-inertial Localization; Bürki, M., Gilitschenski, I., Stumm, E., Siegwart, R., Nieto, J., Appearance-based landmark selection for efficient long-term visual localization (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 4137-4143; Schneider, T., Dymczyk, M., Fehr, M., Egger, K., Lynen, S., Gilitschenski, I., Siegwart, R., Maplab: An open framework for research in visual-inertial mapping and localization (2018) IEEE Robotics and Automation Letters, 3 (3), pp. 1418-1425; Qin, T., Li, P., Shen, S., Relocalization, global optimization and map merging for monocular visual-inertial slam (2018) Proc. of the IEEE Int. Conf. of Robot. of Autom., , Brisbane, Australia, accepted; Schreiber, M., Knöppel, C., Franke, U., Laneloc: Lane marking based localization using highly accurate maps (2013) 2013 IEEE Intelligent Vehicles Symposium (IV). IEEE, pp. 449-454; Ranganathan, A., Ilstrup, D., Wu, T., Light-weight localization for vehicles using road markings (2013) 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, pp. 921-927; Lu, Y., Huang, J., Chen, Y.-T., Heisele, B., Monocular localization in urban environments using road markings (2017) 2017 IEEE Intelligent Vehicles Symposium (IV). IEEE, pp. 468-474; Li, M., Mourikis, A., High-precision, consistent EKF-based visualinertial odometry (2013) Int. J. Robot. Research, 32 (6), pp. 690-711. , May; Rehder, E., Albrecht, A., Submap-based slam for road markings (2015) 2015 IEEE Intelligent Vehicles Symposium (IV). IEEE, pp. 1393-1398; Jeong, J., Cho, Y., Kim, A., Road-slam: Road marking based slam with lane-level accuracy (2017) 2017 IEEE Intelligent Vehicles Symposium (IV). IEEE, pp. 1736-1473; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3431-3440; Ronneberger, O., Fischer, P., Brox, T., U-net: Convolutional networks for biomedical image segmentation (2015) International Conference on Medical Image Computing and Computer-assisted Intervention. Springer, pp. 234-241; Badrinarayanan, V., Kendall, A., Cipolla, R., Segnet: A deep convolutional encoder-decoder architecture for image segmentation (2017) IEEE Transactions on Pattern Analysis and Machine Intelligence},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098088026&doi=10.1109%2fIROS45743.2020.9340939&partnerID=40&md5=33fc7efe5b80a1c30d2caac0f3be48bf},
}

@conference{taisho-kanji:2016:7866383,
  author = {T. Taisho and T. Kanji},
  journal = {2016 IEEE International Conference on Robotics and Biomimetics, ROBIO 2016},
  title = {Mining DCNN landmarks for long-term visual SLAM},
  pages = {570--576},
  doi = {10.1109/ROBIO.2016.7866383},
  note = {cited By 2; Conference of 2016 IEEE International Conference on Robotics and Biomimetics, ROBIO 2016 ; Conference Date: 3 December 2016 Through 7 December 2016;  Conference Code:126712},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2016},
  abbrev_source_title = {IEEE Int. Conf. Robot. Biomim., ROBIO},
  abstract = {Long-term visual SLAM, in familiar, semi-dynamic, and partially changing environments is an important area of research in robotics. The main problem we faced is the question of how to describe a scene discriminatively and compactly-both of which are necessary in order to cope with changes in appearance and a large amount of visual information. In this study, we address the above issues by mining visual experience. Our strategy is to mine a library of raw visual images, termed visual experience, to find the relevant visual patterns to effectively explain the input scene. From a practical point of view, our work offers three main contributions over the previous work. First, it is the first application of discriminative visual features from deep convolutional neural networks (DCNN) to the task of visual landmark mining. Second, we show how to interpret a high-dimensional DCNN feature to a compact semantic representation of visual word. Third, we show that our approach can turn the scene description task with any feature (including the DCNN feature) into the task of mining visual experience. Experiments on a challenging cross-domain visual place recognition validate efficacy of the proposed approach. © 2016 IEEE.},
  affiliation = {Graduate School of Engineering, University of Fukui, Japan},
  art_number = {7866383},
  document_type = {Conference Paper},
  isbn = {9781509043644},
  keywords = {Biomimetics;  Neural networks;  Semantics, Changing environment;  Convolutional neural network;  High-dimensional;  Place recognition;  Scene description;  Semantic representation;  Visual experiences;  Visual information, Robotics},
  language = {English},
  references = {Sünderhauf, N., Shirazi, S., Dayoub, F., Upcroft, B., Milford, M., On the performance of convnet features for place recognition (2015) IEEE/RSJ Int. Conf. IROS, pp. 4297-4304; Naseer, T., Ruhnke, M., Stachniss, C., Spinello, L., Burgard, W., Robust visual slam across seasons (2015) /RSJ Int. Conf. IROS. IEEE, pp. 2529-2535; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) IEEE ICRA. IEEE, pp. 90-97; Sunderhauf, N., Milford, M., Corke, P., (2015) ICRA 2015 Workshop on Visual Place Recognition in Changing Environments (VPRiCE); Morita, H., Hild, M., Miura, J., Shirai, Y., View-based localization in outdoor environments based on support vector learning (2005) IROS. IEEE, pp. 2965-2970; Krajnik, T., Fentanes, J.P., Santos, J.M., Kusumam, K., Duckett, T., Fremen: Frequency map enhancement for long-term mobile robot autonomy in changing environments (2015) ICRA15 WS VPRiCE; Bruce, J., Wawerla, J., Vaughan, R., The sfu mountain dataset: Semi-structured woodland trails under changing environmental conditions (2015) ICRA15 WS VPRiCE; Lowry, S., Milford, M.J., Change removal: Robust online learning for changing appearance and changing viewpoint (2015) ICRA15 WS VPRiCE; Vysotska, O., Stachniss, C., Lazy sequences matching under substantial appearance changes (2015) ICRA15 WS VPRiCE; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan north campus long-term vision and lidar dataset (2015) I. J. Robotics Research; Masatoshi, A., Yuuto, C., Kanji, T., Kentaro, Y., Leveraging imagebased prior in cross-season place recognition (2015) ICRA. IEEE; Tanaka, K., Cross-season place recognition using nbnn scene descriptor (2015) IEEE/RSJ Int. Conf. IROS. IEEE, pp. 729-735; Isola, P., Liu, C., Scene collaging: Analysis and synthesis of natural images with semantic layers (2013) IEEE ICCV, pp. 3048-3055; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) NIPS, pp. 1097-1105; Ma, J., Zhao, J., Tian, J., Yuille, A.L., Tu, Z., Robust point matching via vector field consensus (2014) IEEE TIP, 23 (4), pp. 1706-1721; Sivic, J., Zisserman, A., Video google: A text retrieval approach to object matching in videos (2003) ICCV, pp. 1470-1477; Babenko, A., Slesarev, A., Chigorin, A., Lempitsky, V.S., Neural codes for image retrieval (2014) ECCV, pp. 584-599; Jégou, H., Perronnin, F., Douze, M., Sánchez, J., Pérez, P., Schmid, C., Aggregating local image descriptors into compact codes (2012) IEEE Trans. PAMI, 34 (9), pp. 1704-1716; Arandjelovíc, R., Zisserman, A., Three things everyone should know to improve object retrieval (2012) IEEE CVPR. IEEE, pp. 2911-2918; Boiman, O., Shechtman, E., Irani, M., In defense of nearestneighbor based image classification (2008) CVPR, pp. 1-8; Tommasi, T., Caputo, B., Frustratingly easy NBNN domain adaptation (2013) ICCV, pp. 897-904; Tuytelaars, T., Fritz, M., Saenko, K., Darrell, T., The nbnn kernel (2011) ICCV, pp. 1824-1831; Rematas, K., Fritz, M., Tuytelaars, T., The pooled nbnn kernel: Beyond image-to-class and image-to-image (2013) ACCV, pp. 176-189; Carrillo, H., Latif, Y., Neira, J., Castellanos, J.A., Place categorization using sparse and redundant representations (2014) IROS, pp. 4950-4957; Tanaka, K., Chokushi, Y., Ando, M., Mining visual phrases for long-term visual slam (2014) IROS, pp. 136-142; Kentaro, Y., Masatoshi, A., Yuuto, C., Kanji, T., An experimental study of the effects of landmark discovery and retrieval on visual place recognition across seasons (2015) ICRA15 WS VPRiCE; Tanaka, K., Unsupervised part-based scene modeling for visual robot localization (2015) ICRA. IEEE, pp. 6359-6365; Tanaka, K., Self-localization from images with small overlap (2016) IEEE/RSJ Int. Conf. IROS; Alexe, B., Deselaers, T., Ferrari, V., Measuring the objectness of image windows (2012) Pattern Analysis and Machine Intelligence, IEEE Transactions on, 34 (11), pp. 2189-2202; Cummins, M., Newman, P., Appearance-only slam at large scale with fab-map 2.0 (2011) Int. J. Robotics Research, 30 (9), p. 11001123},
  source = {Scopus},
  sponsors = {},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016791083&doi=10.1109%2fROBIO.2016.7866383&partnerID=40&md5=e36421b6149f38e2c8739cd54eaa2a80},
}

@article{zeng-si:2021:6,
  author = {T. Zeng and B. Si},
  journal = {Cognitive Neurodynamics},
  title = {A brain-inspired compact cognitive mapping system},
  volume = {15},
  number = {1},
  pages = {91--101},
  doi = {10.1007/s11571-020-09621-6},
  note = {cited By 5},
  publisher = {Springer Science and Business Media B.V.},
  year = {2021},
  abbrev_source_title = {Cogn. Neurodynamics},
  abstract = {In many simultaneous localization and mapping (SLAM) systems, the map of the environment grows over time as the robot explores the environment. The ever-growing map prevents long-term mapping, especially in large-scale environments. In this paper, we develop a compact cognitive mapping approach inspired by neurobiological experiments. Mimicking the firing activities of neighborhood cells, neighborhood fields determined by movement information, i.e. translation and rotation, are modeled to describe one of the distinct segments of the explored environment. The vertices with low neighborhood field activities are avoided to be added into the cognitive map. The optimization of the cognitive map is formulated as a robust non-linear least squares problem constrained by the transitions between vertices, and is numerically solved efficiently. According to the cognitive decision-making of place familiarity, loop closure edges are clustered depending on time intervals, and then batch global optimization of the cognitive map is performed to satisfy the combined constraint of the whole cluster. After the loop closure process, scene integration is performed, in which revisited vertices are removed subsequently to further reduce the size of the cognitive map. The compact cognitive mapping approach is tested on a monocular visual SLAM system in a naturalistic maze for a biomimetic animated robot. Our results demonstrate that the proposed method largely restricts the growth of the size of the cognitive map over time, and meanwhile, the compact cognitive map correctly represents the overall layout of the environment. The compact cognitive mapping method is well suitable for the representation of large-scale environments to achieve long-term robot navigation. © 2020, Springer Nature B.V.},
  affiliation = {Institute of Science and Technology for Brain-Inspired Intelligence, Fudan University, Shanghai, China; Key Laboratory of Computational Neuroscience and Brain-Inspired Intelligence (Fudan University), Ministry of Education, Shanghai, China; School of Systems Science, Beijing Normal University, Beijing, 100875, China},
  author_keywords = {Compact cognitive map;  Long-term mapping;  Neighborhood cells;  Neighborhood fields;  SLAM},
  correspondence_address1 = {Si, B.; School of Systems Science, China; email: bailusi@bnu.edu.cn},
  document_type = {Article},
  funding_details = {National Key Research and Development Program of ChinaNational Key Research and Development Program of China, NKRDPC, 2016YFC0801808},
  funding_text1 = {The authors would like to thank the support from the National Key Research and Development Program of China (No. 2016YFC0801808).},
  issn = {18714080},
  keywords = {article;  brain;  cognitive map;  decision making;  human;  human experiment;  least square analysis;  neighborhood;  robotics;  rotation},
  language = {English},
  references = {Agarwal, S., Mierle, K., (2012), http://ceres-solver.org, Others, Ceres solver; Ball, D., Heath, S., Wyeth, G., Wiles, J., IRat: Intelligent rat animat technology (2010) Proceedings of the 2010 Australasian Conference on Robotics and Automation, pp. 1-3; Ball, D., Heath, S., Wiles, J., Wyeth, G., Corke, P., Milford, M., OpenRatSLAM: an open source brain-based SLAM system (2013) Autonomous Robots, 34 (3), pp. 149-176; Bos, J.J., Vinck, M., van Mourik-Donga, L.A., Jackson, J.C., Witter, M.P., Pennartz, C.M., Perirhinal firing patterns are sustained across large spatial segments of the task environment (2017) Nat Commun, 8, p. 15602. , COI: 1:CAS:528:DC%2BC2sXovVGrsro%3D; Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I., Leonard, J.J., Past, present, and future of simultaneous localization and mapping: toward the robust-perception age (2016) IEEE Trans Robot, 32 (6), pp. 1309-1332; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph slam (2013) 2013 IEEE International Conference on Robotics and Automation (ICRA), IEEE, pp. 5748-5755; Carr, M.F., Jadhav, S.P., Frank, L.M., Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval (2011) Nat Neurosci, 14 (2), pp. 147-153. , COI: 1:CAS:528:DC%2BC3MXhtFShtL4%3D; Eichenbaum, H., Time cells in the hippocampus: a new dimension for mapping memories (2014) Nat Rev Neurosci, 15 (11), pp. 732-744. , COI: 1:CAS:528:DC%2BC2cXhs1Gmt7rN; Hafting, T., Fyhn, M., Molden, S., Moser, M.B., Moser, E.I., Microstructure of a spatial map in the entorhinal cortex (2005) Nature, 436 (7052), pp. 801-806. , COI: 1:CAS:528:DC%2BD2MXnt1Siurk%3D; Ila, V., Porta, J.M., Andrade-Cetto, J., Information-based compact pose slam (2010) IEEE Trans Robot, 26 (1), pp. 78-93; Johannsson, H., Kaess, M., Fallon, M., Leonard, J.J., Temporally scalable visual slam using a reduced pose graph (2013) 2013 IEEE International Conference on Robotics and Automation (ICRA), pp. 54-61. , IEEE; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based slam (2012) Int J Robot Res, 31 (11), pp. 1219-1230; Kropff, E., Carmichael, J.E., Moser, M.B., Moser, E.I., Speed cells in the medial entorhinal cortex (2015) Nature, 523 (7561), pp. 419-424. , COI: 1:CAS:528:DC%2BC2MXhtFyltLrK; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G 2 o: A general framework for graph optimization (2011) 2011 IEEE International Conference on Robotics and Automation (ICRA), IEEE, pp. 3607-3613; Larkin, M.C., Lykken, C., Tye, L.D., Wickelgren, J.G., Frank, L.M., Hippocampal output area ca1 broadcasts a generalized novelty signal during an object-place recognition task (2014) Hippocampus, 24 (7), pp. 773-783; Lever, C., Burton, S., Jeewajee, A., O’Keefe, J., Burgess, N., Boundary vector cells in the subiculum of the hippocampal formation (2009) J Neurosci, 29 (31), pp. 9771-9777. , COI: 1:CAS:528:DC%2BD1MXpvFOmur4%3D; Lu, F., Milios, E., Globally consistent range scan alignment for environment mapping (1997) Auton Robot, 4 (4), pp. 333-349; MacDonald, C.J., Lepage, K.Q., Eden, U.T., Eichenbaum, H., Hippocampal “time cells” bridge the gap in memory for discontiguous events (2011) Neuron, 71 (4), pp. 737-749. , COI: 1:CAS:528:DC%2BC3MXhtV2hurzJ; Mazuran, M., Burgard, W., Tipaldi, G.D., Nonlinear factor recovery for long-term slam (2016) Int J Robot Res, 35 (1-3), pp. 50-72; McNaughton, B.L., Battaglia, F.P., Jensen, O., Moser, E.I., Moser, M.B., Path integration and the neural basis of the ’cognitive map’ (2006) Nat Rev Neurosci, 7 (8), pp. 663-678; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired slam system (2010) Int J Robot Res, 29 (9), pp. 1131-1153; Mittelstaedt, M.L., Mittelstaedt, H., Homing by path integration in a mammal (1980) Naturwissenschaften, 67 (11), pp. 566-567; Moser, E.I., Kropff, E., Moser, M.B., Place cells, grid cells, and the brain’s spatial representation system (2008) Ann Rev Neurosci, 31, pp. 69-89. , COI: 1:CAS:528:DC%2BD1cXpt12nsr8%3D; Moser, M.B., Rowland, D.C., Moser, E.I., Place cells, grid cells, and memory (2015) Cold Spring Harbor Perspect Biol, 7 (2); Naidoo, R., Chase, M.J., Beytell, P., Du Preez, P., Landen, K., Stuart-Hill, G., Taylor, R., A newly discovered wildlife migration in Namibia and Botswana is the longest in Africa (2016) Oryx, 50 (1), pp. 138-146; O’Keefe, J., Dostrovsky, J., The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat (1971) Brain research, 34 (1), pp. 171-175; Taube, J.S., Muller, R.U., Ranck, J.B., Head-direction cells recorded from the postsubiculum in freely moving rats. I. Description and quantitative analysis (1990) J Neurosci, 10 (2), pp. 420-435. , COI: 1:STN:280:DyaK3c7lsFCisA%3D%3D; Tolman, E.C., Cognitive maps in rats and men (1948) Psychol Rev, 55 (4), p. 189; Zeng, T., Si, B., Cognitive mapping based on conjunctive representations of space and movement (2017) Front Neurorobot, 11, p. 61; Zeng, T., Tang, F., Ji, D., Si, B., Neurobayesslam: Neurobiologically inspired bayesian integration of multisensory information for robot navigation (2020) Neural Netw off J Int Neural Netw Soc, 126, pp. 21-35; Zhao, D., Si, B., Tang, F., Unsupervised feature learning for visual place recognition in changing environments (2019) Proceedings of the 2019 International Joint Conference on Neural Networks},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088837751&doi=10.1007%2fs11571-020-09621-6&partnerID=40&md5=6700e97fd085d68511c5eedc83964960},
}

@article{nguyen-et-al:2022:3094157,
  author = {T.-M. Nguyen and M. Cao and S. Yuan and T. H. Y. A. N. Lyu and L. Xie},
  journal = {IEEE TRANSACTIONS ON ROBOTICS},
  title = {VIRAL-Fusion: A Visual-Inertial-Ranging-Lidar Sensor Fusion Approach},
  volume = {38},
  number = {2},
  pages = {958--977},
  doi = {10.1109/TRO.2021.3094157},
  publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
  address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
  year = {2022},
  month = {4},
  abstract = {In recent years, onboard self-localization (OSL) methods based on
cameras or lidar have achieved many significant progresses. However,
some issues such as estimation drift and robustness in low-texture
environment still remain inherent challenges for OSL methods. On the
other hand, infrastructure-based methods can generally overcome these
issues, but at the expense of some installation cost. This poses an
interesting problem of how to effectively combine these methods, so as
to achieve localization with long-term consistency as well as
flexibility compared to any single method. To this end, we propose a
comprehensive optimization-based estimator for the 15-D state of an
unmanned aerial vehicle (UAV), fusing data from an extensive set of
sensors: inertial measurement unit (IMU), ultrawideband (UWB) ranging
sensors, and multiple onboard visual-inertial and lidar odometry
subsystems. In essence, a sliding window is used to formulate a sequence
of robot poses, where relative rotational and translational constraints
between these poses are observed in the IMU preintegration and OSL
observations, while orientation and position are coupled in the
body-offset UWB range observations. An optimization-based approach is
developed to estimate the trajectory of the robot in this sliding
window. We evaluate the performance of the proposed scheme in multiple
scenarios, including experiments on public datasets, high-fidelity
graphical-physical simulation, and field-collected data from UAV flight
tests. The result demonstrates that our integrated localization method
can effectively resolve the drift issue, while incurring minimal
installation requirements.},
  affiliation = {Nguyen, TM (Corresponding Author), Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.
Nguyen, Thien-Minh; Cao, Muqing; Yuan, Shenghai; Lyu, Yang; Nguyen, Thien Hoang; Xie, Lihua, Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.},
  affiliations = {Nanyang Technological University \& National Institute of Education
(NIE) Singapore; Nanyang Technological University},
  author-email = {thienminh.npn@gmail.com
mqcao@ntu.edu.sg
shyuan@ntu.edu.sg
lyu.yang@ntu.edu.sg
e180071@e.ntu.edu.sg
elhxie@ntu.edu.sg},
  cited-references = {Agarwal S., 2018, CERES SOLVER TUTORIA.
Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389.
Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
Campos Carlos, 2021, IEEE Transactions on Robotics, V37, P1874, DOI 10.1109/TRO.2021.3075644.
Cao MQ, 2020, IEEE INT CONF CON AU, P1149, DOI 10.1109/ICCA51439.2020.9264577.
Cao YJ, 2020, VIR SLAM VISUAL INER.
Chirikjian GS, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-4944-9.
Dellaert F, 2017, FDN TRENDS ROBOT, V6, P1.
Djugash J, 2012, INT J ROBOT RES, V31, P604, DOI 10.1177/0278364912441039.
Eckenhoff K, 2019, INT J ROBOT RES, V38, P563, DOI 10.1177/0278364919835021.
Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
Fang X, 2021, IEEE T SYST MAN CY-S, V51, P6830, DOI 10.1109/TSMC.2020.2964713.
Fang X, 2018, I C CONT AUTOMAT ROB, P1973, DOI 10.1109/ICARCV.2018.8581124.
Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
Guo KX, 2016, UNMANNED SYST, V4, P23, DOI 10.1142/S2301385016400033.
Huang WB, 2020, IEEE T ROBOT, V36, P1153, DOI 10.1109/TRO.2019.2959161.
Karrer M., 2020, DISTRIBUTED VARIABLE.
Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
Li JX, 2018, IEEE INT CONF CON AU, P100, DOI 10.1109/ICCA.2018.8444329.
Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917.
Mautz R., 2012, THESIS, DOI {[}10.3929/ethz-a-007313554, DOI 10.3929/ETHZ-A-007313554].
Mueller MW, 2015, IEEE INT CONF ROBOT, P1730, DOI 10.1109/ICRA.2015.7139421.
Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
Nguyen T.-M., INT J ROBOT RES, V2021.
Nguyen T.-M., 2016, 2016 INT MICR VEH C, P56.
Nguyen TM, 2020, IEEE T ROBOT, V36, P553, DOI 10.1109/TRO.2019.2954677.
Nguyen TM, 2020, IEEE T CONTR SYST T, V28, P2021, DOI 10.1109/TCST.2019.2916089.
Oleynikova H, 2020, J FIELD ROBOT, V37, P642, DOI 10.1002/rob.21950.
Paredes JA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010089.
Qin T, 2018, IEEE INT C INT ROBOT, P3662, DOI 10.1109/IROS.2018.8593603.
Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
Queralta J. P., 2020, VIO UWBBASED COLLABO.
Shah S., 2017, FIELD SERVICE ROBOTI, P621, DOI DOI 10.1007/978-3-319-67361-5.
Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
Sola J., 2018, ARXIV PREPRINT ARXIV.
Song Y, 2019, IEEE INT CONF ROBOT, P6568, DOI 10.1109/ICRA.2019.8794222.
Nguyen TH, 2020, IEEE INT CONF ROBOT, P665, DOI 10.1109/ICRA40945.2020.9196794.
Nguyen TH, 2020, AUTON ROBOT, V44, P1519, DOI 10.1007/s10514-020-09944-7.
Nguyen TH, 2020, UNMANNED SYST, V8, P179, DOI 10.1142/S2301385020500119.
Nguyen TM, 2019, IEEE ROBOT AUTOM LET, V4, P3641, DOI 10.1109/LRA.2019.2926671.
Tiemann J, 2017, INT C INDOOR POSIT, DOI 10.1109/ipin.2017.8115937.
Wang C, 2017, IEEE INT C INT ROBOT, P1602, DOI 10.1109/IROS.2017.8205968.
Weinstein Aaron, 2018, IEEE Robotics and Automation Letters, V3, P1801, DOI 10.1109/LRA.2018.2800119.
Xu H, 2020, IEEE INT CONF ROBOT, P8776, DOI 10.1109/ICRA40945.2020.9196944.
Ye HY, 2019, IEEE INT CONF ROBOT, P3144, DOI 10.1109/ICRA.2019.8793511.
Yuan SH, 2021, UNMANNED SYST, V9, P129, DOI 10.1142/S230138502150014X.
Zhang J, 2018, J FIELD ROBOT, V35, P1242, DOI 10.1002/rob.21809.
Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941.},
  da = {2022-05-17},
  doc-delivery-number = {0H8BQ},
  earlyaccessdate = {JUL 2021},
  eissn = {1941-0468},
  funding-acknowledgement = {Autonomous Systems and Software Program (WASP) - Knut and Alice
Wallenberg Foundation, under the Wallenberg-NTU Presidential
Postdoctoral Fellowship Program},
  funding-text = {This work was supported by theWallenberg AI, Autonomous Systems and
Software Program (WASP), funded by the Knut and Alice Wallenberg
Foundation, under the Wallenberg-NTU Presidential Postdoctoral
Fellowship Program. This paper was recommended for publication by
Associate Editor R. Tron and Editor F. Chaumette upon evaluation of the
reviewers' comments.},
  issn = {1552-3098},
  journal-iso = {IEEE Trans. Robot.},
  keywords = {Quaternions; Location awareness; Matrix converters; Visualization;
Simultaneous localization and mapping; Laser radar; Distance
measurement; Aerial robots; localization; optimization},
  keywords-plus = {LOCALIZATION; VERSATILE; ODOMETRY; SLAM},
  language = {English},
  number-of-cited-references = {50},
  oa = {Green Submitted},
  orcid-numbers = {Nguyen, Thien/0000-0003-1218-0910
Nguyen, Thien-Minh/0000-0003-1315-0967
Xie, Lihua/0000-0002-7137-4136},
  research-areas = {Robotics},
  times-cited = {4},
  type = {Article},
  unique-id = {WOS:000733501100001},
  usage-count-last-180-days = {10},
  usage-count-since-2013 = {10},
  web-of-science-categories = {Robotics},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
}

@article{nguyen-et-al:2013:004,
  author = {V. A. Nguyen and J. A. Starzyk and W.-B. Goh},
  journal = {Robotics and Autonomous Systems},
  title = {A spatio-temporal Long-term Memory approach for visual place recognition in mobile robotic navigation},
  volume = {61},
  number = {12},
  pages = {1744--1758},
  doi = {10.1016/j.robot.2012.12.004},
  note = {cited By 6},
  year = {2013},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {This paper proposes a solution to the problem of mobile robotic localization using visual indoor image sequences with a biologically inspired spatio-temporal neural network approach. The system contains three major subsystems: a feature extraction module, a scene quantization module and a spatio-temporal long-term memory (LTM) module. During learning, the scene quantization module clusters the visual images set into scene tokens. A K-Iteration Fast Learning Artificial Neural Network (KFLANN) is employed as the core unit of the quantization module. The KFLANN network is driven by intrinsic statistics of the data stream and therefore does not require the number of clusters to be predefined. In addition, the KFLANN performance is less sensitive to data presentation ordering compared to popular clustering methods such as k-means, and can therefore produce a consistent number of stable centroids. Using scene tokens, the topological structure of the environment can be composed into sequences of tokens. These sequences are then learnt and stored in memory units in an LTM architecture, which is able to continuously and robustly recognize the visual input stream. The design of memory units addresses two critical problems in spatio-temporal learning, namely error tolerance and memory forgetting. The primary objective of this work is to explore the synergy between the strength of KFLANN and LTM models to address the visual topological localization problem. We demonstrate the efficiency and efficacy of the proposed framework on the challenging COsy Localization Dataset. © 2013 Elsevier B.V. All rights reserved.},
  affiliation = {CeMNet, N4-B2c-06, School of Computer Engineering, Nanyang Technological University, Singapore 639798, Singapore; School of Electrical Engineering and Computer Science, Russ College of Engineering and Technology, Ohio University, United States; Department of Applied Information Systems, University of Information Technology and Management, Rzeszow, Poland},
  author_keywords = {Long-term Memory;  Spatio-temporal neural networks;  Topological robotic mapping;  Visual place recognition},
  coden = {RASOE},
  correspondence_address1 = {Nguyen, V.A.; CeMNet, N4-B2c-06, , Singapore 639798, Singapore; email: anhngv102@gmail.com},
  document_type = {Article},
  issn = {09218890},
  keywords = {Fast learning artificial neural networks;  Long term memory;  Place recognition;  Robotic mapping;  Spatio-temporal;  Spatio-temporal learning;  Topological localization;  Topological structure, Feature extraction;  Iterative methods;  Neural networks;  Topology, Robotics},
  language = {English},
  references = {Starzyk, J.A., (2008) Motivation in Embodied Intelligence, pp. 83-110. , Frontiers in Robotics, Automation and Control I-Tech Education and Publishing Vienna, Austria; O'Reilly, R., Munakata, Y., (2000) Computational Explorations in Cognitive Neuroscience, , MIT Press; Filliat, D., Meyer, J., Map-based navigation in mobile robots-i. A review of localization strategies (2003) Cognitive Systems Research, 4 (4), pp. 243-282; Filliat, D., Meyer, J., Map-based navigation in mobile robots-ii. A review of mapping and path-planning strategies (2003) Cognitive Systems Research, 4 (4), pp. 283-317; Durrant-Whyte, H., Bailey, T., Simultaneous localization and mapping: Part i (2006) IEEE Robotics and Automation Magazine, 13 (2), pp. 99-108; Wolf, J., Burgard, W., Bukhardt, H., Robust vision-based localization by combining an image-retrieval system with Monte-Carlo localization (2005) IEEE Transactions on Robotics, 21 (2), pp. 208-216; Dissanayake, M., Newman, P., Clark, S., Durrant-Whyte, H., Csorba, M., A solution to the simultaneous localization and map building (2001) IEEE Transactions on Robotics and Automation, 17 (3), pp. 229-241; Kuipers, B., Byun, Y., A robot exploration and mapping strategy based on a semantic hierarchy of spatial representations (1991) Robotics and Autonomous Systems, 8, pp. 47-63; Pronobis, A., Caputo, B., Jensfelt, P., Christensen, H., A realistic benchmark for visual indoor place recognition (2010) Robotic and Autonomous Systems, 58 (1), pp. 81-96. , Elsevier; Thrun, S., Learning metric-topological maps for indoor mobile robot navigation (1998) Artificial Intelligence, 99 (1), pp. 21-71; Ulrich, I., Nourbakhsh, I., Appearance-based place recognition for topological localization (2000) IEEE International Conference on Robotics and Automation, Vol. 2, pp. 1023-1029; Wu, J., Christensen, H., Rehg, J.M., Visual place categorization: Problem, dataset and algorithm (2009) IEEE/RSJ International Conference on Intelligent Robotics and Systems, pp. 4763-4770; Rottmann, A., Martínez Mozos, O., Stachniss, C., Burgard, W., Semantic place classification of indoor environments with mobile robots using boosting (2005) Proc. of the National Conference on Artificial Intelligence, pp. 1306-1311. , Pittsburgh, PA, USA; Ullah, M., Pronobis, A., Caputo, B., Luo, J., Jenfelt, P., Christensen, H., Towards robust place recognition for robot localization (2008) IEEE International Conference on Robotics and Automation, pp. 530-537; Ackerman, C., Itti, L., Robot steering with spectral image formation (2005) IEEE Transactions on Robotics, 21 (2), pp. 247-251; Siagian, C., Itti, L., Rapid biologically inspired scene classification using features shared with visual attention (2007) IEEE Transactions on Pattern Analysis and Machine Intelligence, 20 (2), pp. 300-312; Torralba, A., Murphy, K.P., Rubin, M.A., Context-based vision system for place and object recognition (2003) IEEE International Conference on Computer Vision, 1, pp. 273-280; Angeli, A., Filliat, D., Doncieux, S., Meyer, J.-A., A fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Transactions on Robotics, 24 (5), pp. 1027-1037. , (Special Issue on Visual SLAM); Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) International Journal of Computer Vision, 42 (3), pp. 145-175; Quattoni, A., Torralba, A., Recognizing indoor scenes (2009) IEEE Conference on Computer Vision and Pattern Recognition, pp. 413-420; Wu, J., Rehg, J.M., Centrist: A visual descriptor for scene categorization (2011) IEEE Transactions on Pattern Analysis and Machine Intelligence, 33 (8), pp. 1489-1501; Tay, A.L.P., Tan, L.P., Bastion, C.A., Zhang, K., Biologically inspired KFLANN place fields for robot localization (2006) IEEE International Joint Conference on Neural Networks, pp. 4201-4208; Tay, A.L.P., Zurada, J.M., Ping, W.L., Xu, J., The hierarchical fast learning neural network-an autonomous platform for hierarchical neural network construction (2007) IEEE Transactions on Neural Networks, 18 (6), pp. 1645-1657; Starzyk, J.A., He, H., Anticipation based temporal sequences learning in hierarchical structure (2007) IEEE Transactions on Neural Networks, 18 (2), pp. 344-358; Starzyk, J.A., He, H., Spatio-temporal memories for machine learning: A long-term memory organization (2009) IEEE Transactions on Neural Networks, 20 (5), pp. 768-780; Nguyen, V.A., Starzyk, J.A., Goh, W.-B., Jachyra, D., Neural network structure for spatio-temporal long-term memory (2012) IEEE Transactions on Neural Networks and Learning Systems, 23 (6), pp. 971-983; Carpenter, G.A., Grossberg, S., A massively parallel architecture for a self-organizing neural pattern recognition machine (1987) Computer Vision and Image Understanding, 37 (1), pp. 54-115; Tse, R., Tay, A.L.P., Hutama, W., Robot navigation using KFLANN place field (2008) IEEE International Conference on Systems, Man and Cybernetics, pp. 3034-3039; Nguyen, V.A., Tay, A.L.P., Combination of hippocampal-like place cells with visual cues in bio-mimetic navigation (2009) International Conference on Cognitve and Neural Systems, , Boston, MA, USA; Nguyen, V.A., Starzyk, J.A., Tay, A.L.P., Goh, W.B., Spatio-temporal sequence learning of visual place cells for robotic navigation (2010) IEEE International Joint Conference on Neural Networks, pp. 1-8; Pronobis, A., Mozos, O.M., Caputo, B., SVM-based discriminative accumulation scheme for place recognition (2008) IEEE International Conference on Robotics and Automation, pp. 522-529; Goedeme, T., Gool, L.V., Robust vision-only mobile robot navigation with topological maps (2008) Mobile Robots Motion Planning: New Challenges, pp. 63-88. , J. Xing-Jian, InTech Austria; Torralba, A., Fergus, R., Freeman, W., 80 millions tiny images: A large dataset for non-parametric object and scene recognition (2008) IEEE Transactions on Pattern Analysis and Machine Intelligence, 30 (11), pp. 1958-1970; Isard, M., Blake, A., Condensation-conditional density propagation for visual tracking (1998) International Journal of Computer Vision, 29 (1), pp. 5-28; Starner, T., Schiele, B., Pentland, A., Visual contextual awareness in wearable computing (1998) Second International Symposium on Wearable Computing, pp. 50-57; Starner, T., (1999) Wearable Computing and Visual Awareness, , Ph.D. Thesis, School of Architecture and Planning, MIT; Redish, A.D., (1999) Beyond the Cognitive Map: From Place Cells to Episodic Memory, , MIT Press; O'Keefe, J., Dotrovsky, J., The hippocampus as a spatial map: Preliminary evidence from unit activity in the freely moving rat (1971) Brain Research, 34 (1), pp. 171-175; Poucet, B., Lenck-Santini, P.-P., Paz-Villagran, V., Save, E., Place cells, neocortex and spatial navigation: A short review (2003) Journal Physiology, 97 (46), pp. 537-546; Arleo, A., Smeraldi, F., Gerstner, W., Cognitive navigation based on nonuniform gabor space sampling, unsupervised growing networks and reinforcement learning (2004) IEEE Transactions on Neural Networks, 15 (3), pp. 639-652; Gnadt, W., Grossberg, S., Sovereign: An autonomous neural system for incrementally learning planned action sequences to navigate towards a rewarded goal (2008) Neural Networks, 21 (5), pp. 699-758; Eichenbaum, H., Dudchenko, P., Wood, E., Shapiro, M., Tanila, H., The hippocampus, memory and place cells: Is it spatial memory or a memory space (1999) Neuron, 23 (2), pp. 209-226; Kremer, S.C., Spatio-temporal connectionist networks: A taxonomy and review (2001) Neural Computation, 13 (2), pp. 249-306; McGaugh, J., Memory-a century of consolidation (2000) Science, 287 (5451), pp. 248-251; Burgess, N., Hitch, G., Computational models of working memory: Putting long term memory into context (2005) Trends in Cognitive Science, 9 (11), pp. 535-541; Hebb, D.O., (1949) The Organization of Behavior, , Wiley New York; Sun, R., Giles, C.L., Sequence learning: From recognition and prediction to sequence decision making (2001) IEEE Intelligent Systems, 16 (4), pp. 67-70; Wang, D., Arbib, M.A., Complex temporal sequence learning based on short-term memory (1990) Proceedings to the IEEE, 78 (9), pp. 1536-1543; Wang, D., Arbib, M.A., Timing and chunking in processing temporal order (1993) IEEE Transactions on Systems, Man and Cybernetics, 23 (4), pp. 993-1009; Wang, D., Yuwono, B., Anticipation-based temporal pattern generation (1995) IEEE Transactions on Systems, Man and Cybernetics, 25 (4), pp. 615-628; Grossberg, S., Huang, T., Artscene: A neural system for natural scene classification (2009) Journal of Vision, 9 (4), pp. 1-19; Harris, C., Stephens, M., A combined corner and edge detector (1988) Alvey Vision Conference, pp. 147-151; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., Surf: Speeded up robust features (2008) Computer Vision and Image Understanding, 110 (3), pp. 346-359; Li, F., Perona, P., Bayesian hierarchical model for learning natural science categories (2005) IEEE International Conference on Computer Vision and Pattern Recognition, 2, pp. 524-531; Mikolajczyk, K., Schmid, C., A performance evaluation of local descriptors (2005) IEEE Transactions on Pattern Analysis and Machine Intelligence, 27 (10), pp. 1615-1630; Zabih, R., Woodfill, J., Non-parametric local transforms for computing visual correspondences (1994) European Conference on Computer Vision, pp. 151-158. , Springer Verlag; Lazebnik, S., Schmid, C., Ponce, J., Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories (2006) IEEE Conference on Computer Vision and Pattern Recognition, 2, pp. 2169-2178; http://c2inet.sce.ntu.edu.sg/Jianxin/PACT/PACT.htm; Ping, W.L., Tay, A.L.P., Centroid stability with k-means fast learning artificial neural networks (2003) IEEE International Joint Conference on Neural Networks, 2, pp. 1517-1522; Davies, D., Bouldin, D., A cluster separation measure (1979) IEEE Transactions on Pattern Analysis and Machine Intelligence, 1 (2), pp. 224-227; Itti, L., Baldi, P., Bayesian surprise attracts human attention (2009) Vision Research, 49 (10), pp. 1295-1306; Mahadevan, V., Vasconcelos, N., Spatio-temporal saliency in dynamic scenes (2010) IEEE Transactions on Pattern Analysis and Machine Intelligence, 32 (1), pp. 171-177; Ridella, S., Rovetta, S., Zunino, R., Representation and generalization properties of class-entropy networks (1999) IEEE Transactions on Neural Networks, 10 (1), pp. 31-47; Cover, T., Thomas, J., (1991) Elements of Information Theory, , Wiley New York; Chang, C.-C., Lin, C.-J., Libsvm: A library for support vector machines (2011) ACM Transactions on Intelligent Systems and Technology, 2 (27), pp. 1-27; Vapnik, V., (1998) Statistical Learning Theory, , Wiley and Sons; Pronobis, A., Jie, L., Caputo, B., The more you learn, the less you store: Memory-controlled incremental SVM for visual place recognition (2010) Image and Vision Computing, 28 (7), pp. 1080-1097. , (Special issue Online Pattern Recognition and Machine Learning Technique for Computer Vision: Theory and Applications); Burges, C.J.C., A tutorial on support vector machines for pattern recognition (1998) Data Mining and Knowledge Discovery, 2 (2), pp. 121-167; Shastri, L., Episodic memory trace formation in the hippocampal system: A model of cortico-hippocampal interaction (2001) Tech. Rep., International Computer Science, , Berkeley, California, US; Tulving, E., Episodic and semantic memory (1972) Organization of Memory, pp. 381-403. , E. Tulving, W. Donaldson, Academic Press New York},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887220871&doi=10.1016%2fj.robot.2012.12.004&partnerID=40&md5=d003d8a8ff3d0e1d3d41a67aa9350880},
}

@article{ila-et-al:2017:0278364917691110,
  author = {V. Ila and L. Polok and M. Solony and P. Svoboda},
  journal = {International Journal of Robotics Research},
  title = {SLAM++1-A highly efficient and temporally scalable incremental SLAM framework},
  volume = {36},
  number = {2},
  pages = {210--230},
  doi = {10.1177/0278364917691110},
  note = {cited By 51},
  publisher = {SAGE Publications Inc.},
  year = {2017},
  abbrev_source_title = {Int J Rob Res},
  abstract = {The most common way to deal with the uncertainty present in noisy sensorial perception and action is to model the problem with a probabilistic framework. Maximum likelihood estimation is a well-known estimation method used in many robotic and computer vision applications. Under Gaussian assumption, the maximum likelihood estimation converts to a nonlinear least squares problem. Efficient solutions to nonlinear least squares exist and they are based on iteratively solving sparse linear systems until convergence. In general, the existing solutions provide only an estimation of the mean state vector, the resulting covariance being computationally too expensive to recover. Nevertheless, in many simultaneous localization and mapping (SLAM) applications, knowing only the mean vector is not enough. Data association, obtaining reduced state representations, active decisions and next best view are only a few of the applications that require fast state covariance recovery. Furthermore, computer vision and robotic applications are in general performed online. In this case, the state is updated and recomputed every step and its size is continuously growing, therefore, the estimation process may become highly computationally demanding. This paper introduces a general framework for incremental maximum likelihood estimation called SLAM++, which fully benefits from the incremental nature of the online applications, and provides efficient estimation of both the mean and the covariance of the estimate. Based on that, we propose a strategy for maintaining a sparse and scalable state representation for large scale mapping, which uses information theory measures to integrate only informative and non-redundant contributions to the state representation. SLAM++ differs from existing implementations by performing all the matrix operations by blocks. This led to extremely fast matrix manipulation and arithmetic operations used in nonlinear least squares. Even though this paper tests SLAM++ efficiency on SLAM problems, its applicability remains general. © The Author(s) 2017.},
  affiliation = {Australian National University, Canberra, Australia; Faculty of Information Technology, Brno University of Technology, Brno, Czech Republic},
  author_keywords = {compact state representation;  incremental covariance recovery;  long-term SLAM;  loop closure;  Nonlinear least squares},
  coden = {IJRRE},
  correspondence_address1 = {Ila, V.115 North Road, Australia; email: viorela.ila@anu.edu.au},
  document_type = {Article},
  issn = {02783649},
  keywords = {Computer vision;  Information theory;  Iterative methods;  Linear systems;  Mapping;  Matrix algebra;  Maximum likelihood;  Nonlinear analysis;  Recovery;  Robotics, Covariance recoveries;  long-term SLAM;  Loop closure;  Non-linear least squares;  State representation, Maximum likelihood estimation},
  language = {English},
  references = {Agarwal, S., Mierle, K., (2012) Ceres Solver, , http://code.google.com/p/ceres-solver/, (accessed 20 August 2015); Agarwal, S., Snavely, N., Simon, I., Building Rome in a day (2009) International Conference on Computer Vision (ICCV), pp. 72-79. , Kyoto, Japan, 29 September-2 October, IEEE; Barfoot, T., Furgale, P., Associating uncertainty with three-dimensional poses for use in estimation problems (2014) IEEE Transactions on Robotics, 30 (3), pp. 679-693; Beall, C., Lawrence, B., Ila, V., 3D reconstruction of underwater structures (2010) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4418-4423. , 18-22 October, IEEE; Björck, A., (1996) Numerical Methods for Least Squares Problems, , SIAM. ISBN: 978-0-89871-360-2; Blanco, J.L., (2010) A Tutorial on SE(3) Transformation Parameterizations and On-manifold Optimization, , Technical report, University of Malaga, Spain; Carlevaris-Bianco, N., Eustice, R.M., Generic node removal for factor-graph SLAM (2014) IEEE Transactions on Robotics, 30 (6), pp. 1371-1385; Carlevaris-Bianco, N., Eustice, R.M., Generic factor-based node marginalization and edge sparsification for pose-graph SLAM (2013) IEEE International Conference on Robotics and Automation (ICRA), pp. 5728-5735. , Karlsruhe, Germany, 6-10 May, IEEE; Carlevaris-Bianco, N., Eustice, R.M., Conservative edge sparsification for graph SLAM node removal (2014) IEEE International Conference on Robotics and Automation (ICRA), pp. 854-860. , Hong Kong, 31 May-7 June, IEEE; Chow, C., Liu, C., Approximating discrete probability distributions with dependence trees (1968) IEEE Transactions on Information Theory, 14 (3), pp. 462-467; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2010) The International Journal of Robotics Research, 30 (9), pp. 1100-1123; Davis, T., (2006) Csparse, , http://www.cise.ufl.edu/research/sparse/CSparse/, (accessed 20 August 2015); Davis, T.A., (2006) Direct Methods for Sparse Linear Systems (Fundamentals of Algorithms 2), , SIAM. ISBN: 978-0-89871-613-9; Davis, T.A., Hager, W.W., Modifying a sparse cholesky factorization (1997) SIAM Journal on Matrix Analysis and Applications, 20 (3), pp. 606-627. , SIAM; Davison, A., Murray, D., Simulataneous localization and map-building using active vision (2002) IEEE Transactions on Pattern Analysis and Machine Intelligence, 24 (7), pp. 865-880; Dellaert, F., Kaess, M., Square root SAM: Simultaneous localization and mapping via square root information smoothing (2006) The International Journal of Robotics Research, 25 (12), pp. 1181-1203; Dissanayake, G., Williams, S.B., Durrant-Whyte, H., Map management for efficient simultaneous localization and mapping (SLAM) (2002) Autonomous Robots, 12 (3), pp. 267-286; Eustice, R., Singh, H., Leonard, J., Visually mapping the RMS Titanic: Conservative covariance estimates for SLAM information filters (2006) The International Journal of Robotics Research, 25 (12), pp. 1223-1242; Geiger, A., Lenz, P., Stiller, C., Vision meets robotics: The KITTI dataset (2013) The International Journal of Robotics Research, 32 (11), pp. 1231-1237; Golub, G.H., Plemmons, R.J., Large-scale geodetic least-squares adjustment by dissection and orthogonal decomposition (1980) Linear Algebra and Its Applications, 34, pp. 3-28; Grisetti, G., Stachniss, C., Grzonka, S., A tree parameterization for efficiently computing maximum likelihood maps using gradient descent (2007) Robotics: Science and Systems (RSS), pp. 27-30. , Atlanta, Georgia, 27-30 June; Hager, W.W., Updating the inverse of a matrix (1989) SIAM Review, 31 (2), pp. 221-239; Haner, S., Heyden, A., Covariance propagation and next best view planning for 3D reconstruction (2012) European Conference on Computer Vision (ECCV), pp. 545-556. , Firenze, Italy, 7-13 October, Berlin Heidelberg: Springer; Huang, G., Kaess, M., Leonard, J., Consistent sparsification for graph optimization (2013) European Conference on Mobile Robots (ECMR), pp. 150-157. , Barcelona, Spain, 25-27 September, IEEE; Huang, G.P., Mourikis, A., Roumeliotis, S., An observability-constrained sliding window filter for SLAM (2011) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 65-72. , 25-30 September, San Francisco, CA, USA: IEEE; Ila, V., Polok, L., Šolony, M., Fast covariance recovery in incremental nonlinear least square solvers (2015) IEEE International Conference on Robotics and Automation (ICRA), pp. 4636-4643. , 6-10 May, Karlsruhe, Germany: IEEE; Ila, V., Porta, J.M., Andrade-Cetto, J., Information-based compact pose SLAM (2010) IEEE Transactions on Robotics, 26 (1), pp. 78-93; Indelman, V., Roberts, R., Beall, C., Incremental light bundle adjustment (2012) British Machine Vision Conference (BMVC), pp. 1341-13411. , 3-7 September, Guildford, UK: BMVA Press; Johannsson, H., Kaess, M., Fallon, M., Temporally scalable visual SLAM using a reduced pose graph (2013) IEEE International Conference on Robotics and Automation (ICRA), pp. 54-61. , Karlsruhe, Germany, 6-10 May, IEEE; Kabsch, W., A solution for the best rotation to relate two sets of vectors (1976) Acta Crystallographica Section A: Crystal Physics, Diffraction, Theoretical and General Crystallography, 32 (5), pp. 922-923; Kaess, M., Dellaert, F., Covariance recovery from a square root information matrix for data association (2009) Robotics and Autonomous Systems, 57 (12), pp. 1198-1210. , Elsevier; Kaess, M., Ila, V., Roberts, R., The Bayes tree: An algorithmic foundation for probabilistic robot mapping (2010) International Workshop on the Algorithmic Foundations of Robotics, NUS, pp. 150-157. , Singapore, 13-15 December, Berlin Heidelberg: Springer; Kaess, M., Johannsson, H., Roberts, R., ISAM2: Incremental smoothing and mapping with fluid relinearization and incremental variable reordering (2011) IEEE International Conference on Robotics and Automation (ICRA), pp. 3281-3288. , Shanghai, China, 9-13 May, IEEE; Kaess, M., Johannsson, H., Roberts, R., ISAM2: Incremental smoothing and mapping using the Bayes tree (2011) The International Journal of Robotics Research, 31, pp. 217-236; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) IEEE Transactions on Robotics, 24 (6), pp. 1365-1378; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) IEEE and ACM International Symposium on Mixed and Augmented Reality (ISMAR), pp. 225-234. , Nara, Japan, 13-16 November, ACM; Konolige, K., Sparse sparse bundle adjustment (2010) British Machine Vision Conference (BMVC), pp. 1021-10211. , Aberystwyth, Wales, 31 August-3 September; Konolige, K., Grisetti, G., Kümmerle, R., Efficient sparse pose adjustment for 2D mapping (2010) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 22-29. , Taipei, Taiwan. 18-22 October, IEEE; Kretzschmar, H., Stachniss, C., Information-theoretic compression of pose graphs for laser-based SLAM (2012) The International Journal of Robotics Research, 31 (11), pp. 1219-1230; Kretzschmar, H., Stachniss, C., Grisetti, G., Efficient information-theoretic graph pruning for graph-based SLAM with laser range finders (2011) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 865-871. , 25-30 September, San Francisco, CA, USA: IEEE; Kümmerle, R., Grisetti, G., Strasdat, H., G2o: A general framework for graph optimization (2011) Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), pp. 3607-3613. , Shanghai, China, 9-13 May, IEEE; Kummerle, R., Steder, B., Dornhege, C., On measuring the accuracy of SLAM algorithms (2009) Autonomous Robots, 27 (4), pp. 387-407. , US: Springer; Neira, J., Tardos, J., Data association in stochastic mapping using the joint compatibility test (2001) IEEE Transactions on Robotics and Automation, 17 (6), pp. 890-897; Polok, L., Ila, V., Smrz, P., Cache efficient implementation for block matrix operations (2013) Proceedings of the High Performance Computing Symposium, pp. 698-706. , San Diego, CA, USA, 7-10 April, ACM; Polok, L., Ila, V., Šolony, M., Smrz, P., Incremental block Cholesky factorization for nonlinear least squares in robotics (2013) Robotics: Science and Systems (RSS), pp. 421-428. , Berlin, Germany, 24-28 June; Polok, L., Šolony, M., Ila, V., Efficient implementation for block matrix operations for nonlinear least squares problems in robotic applications (2013) IEEE International Conference on Robotics and Automation (ICRA), pp. 2263-2269. , 6-10 May, Karlsruhe, Germany: IEEE; Prentice, S., Roy, N., The belief roadmap: Efficient planning in linear POMDPs by factoring the covariance (2011) Proceedings of the International Symposium of Robotics Research (ISRR), pp. 293-305. , Flagstaff, AZ, USA, 28 August-1 September, Heidelberg: Springer; Salas-Moreno, R.F., Newcombe, R.A., Strasdat, H., SLAM++: Simultaneous localisation and mapping at the level of objects (2013) IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 1352-1359. , Portland, OR, USA, 25-27 June, IEEE; Sibley, G., Matthies, L., Sukhatme, G., Kragic, D., Kyrki, V., A sliding window filter for incremental SLAM (2008) Unifying Perspectives in Computational and Robot Vision, Lecture Notes in Electrical Engineering, 8, pp. 103-112. , Springer, US: Springer; Sim, R., Stable exploration for bearings-only SLAM (2005) IEEE International Conference on Robotics and Automation (ICRA), pp. 2422-2427. , Barcelona, Spain, 18-22 April, IEEE; Smith, R.C., Cheeseman, P., On the representation and estimation of spatial uncertainly (1986) The International Journal of Robotics Research, 5 (4), pp. 56-68; Sturm, J., Engelhard, N., Endres, F., A benchmark for the evaluation of RGB-D SLAM systems (2012) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 573-580. , Algarve, Portugal, 8-11 October, IEEE; Thrun, S., Liu, Y., Koller, D., Simultaneous localization and mapping with sparse extended information filters (2004) The International Journal of Robotics Research, 23 (7-8), pp. 693-716; Tipaldi, G.D., Grisetti, G., Burgard, W., Approximate covariance estimation in graphical approaches to SLAM (2007) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 3460-3465. , San Diego, CA, USA, 29 October-2 November, IEEE; Valencia, R., Morta, M., Andrade-Cetto, J., Planning reliable paths with pose SLAM (2013) IEEE Transactions on Robotics, 29 (4), pp. 1050-1059; Vidal-Calleja, T., Davison, A., Andrade-Cetto, J., Active control for single camera SLAM (2006) IEEE International Conference on Robotics and Automation (ICRA), pp. 1930-1936. , Orlando, FL, USA, 15-19 May},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018786448&doi=10.1177%2f0278364917691110&partnerID=40&md5=96366e7817914c3554d762e11fe5740f},
}

@article{ali-et-al:2021:3100882,
  author = {W. Ali and P. Liu and R. Ying and Z. Gong},
  journal = {IEEE Sensors Journal},
  title = {A Life-Long SLAM Approach Using Adaptable Local Maps Based on Rasterized LIDAR Images},
  volume = {21},
  number = {19},
  pages = {21740--21749},
  doi = {10.1109/JSEN.2021.3100882},
  note = {cited By 1},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Sensors J.},
  abstract = {Most real-Time autonomous robot applications require a robot to traverse through a dynamic space for a long time. In some cases, a robot needs to work in the same environment. Such applications give rise to the problem of a life-long SLAM system. Life-long SLAM presents two main challenges i.e.The tracking should not fail in a dynamic environment and the need for a robust and efficient mapping strategy. The system should update maps with new information; while also keeping track of older observations. But, mapping for a long time can require higher computational requirements. In this paper, we propose a solution to the problem of life-long SLAM. We represent the global map as a set of rasterized images of local maps along with a map management system responsible for updating local maps and keeping track of older values. We also present an efficient approach of using the bag of visual words method for loop closure detection and relocalization. We evaluate the performance of our system on the KITTI dataset and an indoor dataset. Our loop closure system reported recall and precision of above 90 percent. The computational cost of our system is much lower as compared to state-of-The-Art methods. Our method reports lower computational requirements even for long-Term operation. © 2001-2012 IEEE.},
  affiliation = {School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, China},
  author_keywords = {bag of words;  Laser scanning;  mapping;  mapping;  place recognition;  rasterization;  simultaneous localization},
  correspondence_address1 = {Ali, W.; School of Electronic Information and Electrical Engineering, China; email: vaqas11@sjtu.edu.cn},
  document_type = {Article},
  issn = {1530437X},
  keywords = {Artificial life;  Mapping;  Rasterization;  Robot applications;  Robots, Bag-of-visual-words;  Computational costs;  Computational requirements;  Dynamic environments;  Mapping strategy;  Re-localization;  Recall and precision;  State-of-the-art methods, Indoor positioning systems},
  language = {English},
  references = {Thrun, S., Probabilistic robotics (2002) Commun Acm, 45 (3), pp. 52-57; Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Proc IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 1156-1163. , Oct; Naima, A., (2011) Long-Term Robot Mapping in Dynamic Environments, , Ph.D. dissertation Dept. Elect. Eng. Comput. Sci., MIT, Cambridge, MA, USA; Steder, B., Ruhnke, M., Grzonka, S., Burgard, W., Place recognition in 3D scans using a combination of bag of words and point feature based relative pose estimation (2011) Proc IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 1249-1255. , Sep; Steder, B., Grisetti, G., Burgard, W., Robust place recognition for 3D range data based on point features (2010) Proc Ieee Int. Conf. Robot. Autom., pp. 1400-1405. , May; Rohling, T., Mack, J., Schulz, D., A fast histogram-based similarity measure for detecting loop closures in 3-D LIDAR data (2015) Proc IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 736-741. , Sep; Magnusson, M., Andreasson, H., Nuchter, A., Lilienthal, A.J., Appearance-based loop detection from 3D laser data using the normal distributions transform (2009) Proc Ieee Int. Conf. Robot. Autom, pp. 23-28. , May; Galvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) Ieee Trans. Robot, 28 (5), pp. 1188-1197. , Oct; Kejriwal, N., Kumar, S., Shibata, T., High performance loop closure detection using bag of word pairs (2016) Robot. Auton. Syst, 77, pp. 55-65. , Mar; Angeli, A., Doncieux, S., Meyer, J.-A., Filliat, D., Real-Time visual loop-closure detection (2008) Proc Ieee Int. Conf. Robot. Autom, pp. 1842-1847. , May; Nicosevici, T., Garcia, R., Automatic visual bag-of-words for online robot navigation and mapping (2012) Ieee Trans. Robot, 28 (4), pp. 886-898. , Aug; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-Time loop closure in 2D LIDAR SLAM Proc Ieee Int. Conf. Robot. Autom. (ICRA), pp. 1271-1278. , May 2016; Behley, J., Stachniss, C., Efficient surfel-based SLAM using 3D laser range data in urban environments (2018) Proc. Robot., Sci. Syst. (RSS), , Pittsburgh, PA, USA; Ali, W., Liu, P., Ying, R., Gong, Z., (2021) 6-Dof Feature Based Lidar Slam Using Orb Features from Rasterized Images of 3D Lidar Point Cloud, , http://arxiv.org/abs/2103.10678, arXiv:2103 10678; Yamauchi, B., Beer, R., Spatial learning for navigation in dynamic environments (1996) Ieee Trans. Syst., Man, Cybern., B Cybern, 26 (3), pp. 496-505. , Jun; Stachniss, C., Burgard, W., Mobile robot mapping and localization in non-static environments (2005) Proc. Aaai, pp. 1324-1329; Bosse, M., Newman, P., Leonard, J., Teller, S., Simultaneous localization and map building in large-scale cyclic environments using the atlas framework (2004) Int. J. Robot. Res, 23 (12), pp. 1113-1139. , Dec; Biber, P., Dynamic maps for long-Term operation of mobile service robots (2005) Proc. Robot., Sci. Syst. (RSS), pp. 17-24. , Cambridge, MA, USA; Biber, P., Duckett, T., Experimental analysis of sample-based maps for long-Term SLAM (2009) Int. J. Robot. Res, 28 (1), pp. 20-33. , Jan; Kretzschmar, H., Stachniss, C., Grisetti, G., Efficient informationtheoretic graph pruning for graph-based SLAM with laser range finders (2011) Proc IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 865-871. , Sep; Stachniss, C., Kretzschmar, H., Pose graph compression for laserbased SLAM (2017) Robotics Research, pp. 271-287. , Cham, Switzerland Springer; McDonald, J., Kaess, M., Cadena, C., Neira, J., Leonard, J.J., 6-DOF multi-session visual SLAM using anchor nodes (2011) Proc. Eur. Conf. Mobile Robots (ECMR), pp. 69-76. , Sep; Fentanes, J.P., Lacerda, B., Krajnik, T., Hawes, N., Hanheide, M., Now or later? Predicting and maximising success of navigation actions from long-Term experience (2015) Proc Ieee Int. Conf. Robot. Autom. (ICRA), pp. 1112-1117. , May; Wolf, D.F., Sukhatme, G.S., Mobile robot simultaneous localization and mapping in dynamic environments (2005) Auto. Robots, 19 (1), pp. 53-65. , Jul; Banerjee, N., Lisin, D., Briggs, J., Llofriu, M., Munich, M.E., Lifelong mapping using adaptive local maps Proc. Eur. Conf. Mobile Robots (ECMR), 2019, pp. 1-8. , Sep; Mur-Artal, R., Tardós, J.D., ORB-SLAM2: An open-source slam system for monocular, stereo, and RGB-D cameras Ieee Trans. Robot, 33 (5), pp. 1255-1262. , Oct. 2017; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) Proc. Int. Conf. Comput. Vis., pp. 2564-2571. , Nov; Fischler, M.A., Bolles, R., Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography (1981) Commun. Acm, 24 (6), pp. 381-395; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) Proc Ieee Conf. Comput. Vis. Pattern Recognit., pp. 3354-3361. , Jun; Zhang, J., Singh, S., LOAM: Lidar odometry and mapping in real-Time (2014) Proc. Robot., Sci. Syst. RSS, 2, p. 9. , Rome, Italy; Segal, A., Haehnel, D., Thrun, S., Generalized-ICP (2009) Proc. Robot., Sci. Syst. (RSS, 2 (4), p. 435. , Seattle, WA, USA; Qin, T., Pan, J., Cao, S., Shen, S., (2019) A General Optimization-based Framework for Local Odometry Estimation with Multiple Sensors, , https://arxiv.org/abs/1901.03638, arXiv 1901 03638; Wang, H., Wang, C., Xie, L., Intensity scan context: Coding intensity and geometry relations for loop closure detection (2020) Proc Ieee Int. Conf. Robot. Automat. (ICRA), pp. 2095-2101. , May/Aug; Pan, Y., Xiao, P., He, Y., Shao, Z., Li, Z., (2021) MULLS: Versatile LiDAR Slam Via Multi-metric Linear Least Square, , http://arxiv.org/abs/2102.03771, arXiv:2102 03771; Chen, X., Milioto, A., Palazzolo, E., Giguère, P., Behley, J., Stachniss, C., SuMa++: Efficient LiDAR-based semantic slam (2019) Proc IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), pp. 4530-4537. , Nov; Rosten, E., Drummond, T., Machine learning for high-speed corner detection (2006) Proc. Eur. Conf. Comput. Vis, pp. 430-443. , Berlin, Germany Springer},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112591954&doi=10.1109%2fJSEN.2021.3100882&partnerID=40&md5=aabb8ee3623483cf83881b2657334f5b},
}

@article{churchill-newman:2013:0278364913499193,
  author = {W. Churchill and P. Newman},
  journal = {International Journal of Robotics Research},
  title = {Experience-based navigation for long-term localisation},
  volume = {32},
  number = {14},
  pages = {1645--1661},
  doi = {10.1177/0278364913499193},
  note = {cited By 149},
  year = {2013},
  abbrev_source_title = {Int J Rob Res},
  abstract = {This paper is about long-term navigation in environments whose appearance changes over time, suddenly or gradually. We describe, implement and validate an approach which allows us to incrementally learn a model whose complexity varies naturally in accordance with variation of scene appearance. It allows us to leverage the state of the art in pose estimation to build over many runs, a world model of sufficient richness to allow simple localisation despite a large variation in conditions. As our robot repeatedly traverses its workspace, it accumulates distinct visual experiences that in concert, implicitly represent the scene variation: each experience captures a visual mode. When operating in a previously visited area, we continually try to localise in these previous experiences while simultaneously running an independent vision-based pose estimation system. Failure to localise in a sufficient number of prior experiences indicates an insufficient model of the workspace and instigates the laying down of the live image sequence as a new distinct experience. In this way, over time we can capture the typical time-varying appearance of an environment and the number of experiences required tends to a constant. Although we focus on vision as a primary sensor throughout, the ideas we present here are equally applicable to other sensor modalities. We demonstrate our approach working on a road vehicle operating over a 3-month period at different times of day, in different weather and lighting conditions. We present extensive results analysing different aspects of the system and approach, in total processing over 136,000 frames captured from 37 km of driving. © The Author(s) 2013.},
  affiliation = {Oxford University Mobile Robotics Group, Oxford, UK, United Kingdom},
  author_keywords = {field and service robotics;  field robots;  Localisation;  mapping;  mobile and distributed robotics;  SLAM},
  coden = {IJRRE},
  correspondence_address1 = {Churchill, W.; Department of Engineering Science, , Oxford OX1 3PJ, United Kingdom; email: winston.churchill@eng.ox.ac.uk},
  document_type = {Article},
  funding_details = {Engineering and Physical Sciences Research CouncilEngineering and Physical Sciences Research Council, EPSRC, EP/I005021/1, EP/J012017/1},
  issn = {02783649},
  keywords = {Distributed robotics;  Field and service robotics;  Field robot;  Localisation;  SLAM, Mapping;  Robotics;  Sensors, Robots},
  language = {English},
  references = {Bailey, T., Durrant-Whyte, H., Simultaneous localisation and mapping (SLAM): Part II state of the art (2006) Robotics and Automation Magazine, 13 (3), pp. 108-117; Bay, H., Ess, A., Tuytelaars, T., Gool, L.V., SURF: Speeded up robust features (2008) Computer Vision and Image Understanding, 110, pp. 346-359; Biber, P., Duckett, T., Dynamic maps for long-term operation of mobile service robots Proceedings of IEEE Robotics: Science and Systems; Borrmann, D., Elseberg, J., Rauniyar, S.S., Nuchter, A., Lifelong 3D mapping - Monitoring with a 3D scanner IEEE International Conference on Intelligent Robots and Systems (IROS) - Workshop on Robotics for Environmental Monitoring; Burgard, W., Stachniss, C., Haehnel, D., (2007) Autonomous Navigation in Dynamic Environments (Springer Tracts in Advanced Robotics, p. 27. , New York: Springer;; Calonder, M., Lepetit, V., Ozuysal, M., Trzinski, T., Strecha, C., Fua, P., BRIEF: Computing a local binary descriptor very fast (2011) IEEE Transactions on Pattern Analysis and Machine Intelligence, 34 (7), pp. 1281-1298; Cummins, M., Newman, P., Highly scalable appearance-only SLAM - FAB-MAP 2.0 (2009) Robotics Science and Systems; Dayoub, F., Cielniak, G., Duckett, T., Long-term experiments with an adaptive spherical view representation for navigation in changing environments (2011) Robotics and Autonomous Systems, 59 (5), pp. 285-295; Dayoub, F., Duckett, T., An adaptive appearance-based map for long-term topological localization of mobile robots Proceedings of IEEE International Conference on Intelligent Robots and Systems (IROS); Furgale, P., Barfoot, T.D., Visual teach and repeat for long-range rover autonomy (2010) Journal of Field Robotics, 27 (5), pp. 534-560; Konolige, K., Agrawal, M., Solà, J., Large scale visual odometry for rough terrain International Symposium on Research in Robotics (ISRR); Lategahn, H., Stiller, C., City GPS using stereo vision Proceedings of IEEE International Conference on Vehicular Electronics and Safety; McManus, C., Furgale, P., Stenning, B., Barfoot, T.D., Visual teach and repeat using appearance-based lidar Proceedings of IEEE International Conference on Robotics and Automation (ICRA); Mei, C., Benhimane, S., Malis, E., Rives, P., Efficient homography-based tracking and 3-D reconstruction for single-viewpoint sensors (2008) IEEE Transactions on Robotics, 24 (6), pp. 1352-1364; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired SLAM system (2009) The International Journal of Robotics Research, 29 (9), pp. 1131-1153; Milford, M., Wyeth, G., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights IEEE International Conferece on Robotics and Automation (ICRA 2012); Newman, P., Sibley, G., Smith, M., Navigating, recognising and describing urban spaces with vision and laser (2009) The International Journal of Robotics Research, 28 (1112), pp. 1406-1433; Rosten, E., Porter, R., Drummond, T., Faster and better: A machine learning approach to corner detection (2008) IEEE Transactions on Pattern Analysis and Machine Intelligence, 32 (1), pp. 105-119; Schindlera, K., Essb, A., Leibec, B., Gool, L.V., Automatic detection and tracking of pedestrians from a moving stereo rig (2010) ISPRS International Journal of Photogrammetry and Remote Sensing, 65, pp. 523-537; Sibley, G., Mei, C., Reid, I., Newman, P., Vast scale outdoor navigation using adaptive relative bundle adjustment (2010) The International Journal of Robotics Research, 29, pp. 958-980; Taneja, A., Ballan, L., Pollefeys, M., Image based detection of geometric changes in urban environments Proceedings of IEEE International Conference on Computer Vision (ICCV); (2012) Weather Online UK, , http://www.weatheronline.co.uk; Wolf, D., Sukhatme, G.S., Online simultaneous localization and mapping in dynamic environments Proceedings of IEEE International Conference on Robotics and Automation (ICRA)},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892567711&doi=10.1177%2f0278364913499193&partnerID=40&md5=07183a43950661361caa62650a4485a9},
}

@inproceedings{maddern-et-al:2012:6224622,
  author = {W. Maddern and M. Milford and G. Wyeth},
  booktitle = {2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
  title = {Capping Computation Time and Storage Requirements for Appearance-based
Localization with CAT-SLAM},
  pages = {822--827},
  doi = {10.1109/ICRA.2012.6224622},
  note = {IEEE International Conference on Robotics and Automation (ICRA), St
Paul, MN, MAY 14-18, 2012},
  publisher = {IEEE},
  address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
  year = {2012},
  abstract = {Appearance-based localization is increasingly used for loop closure
detection in metric SLAM systems. Since it relies only upon the
appearance-based similarity between images from two locations, it can
perform loop closure regardless of accumulated metric error. However,
the computation time and memory requirements of current appearance-based
methods scale linearly not only with the size of the environment but
also with the operation time of the platform. These properties impose
severe restrictions on long-term autonomy for mobile robots, as loop
closure performance will inevitably degrade with increased operation
time. We present a set of improvements to the appearance-based SLAM
algorithm CAT-SLAM to constrain computation scaling and memory usage
with minimal degradation in performance over time. The appearance-based
comparison stage is accelerated by exploiting properties of the particle
observation update, and nodes in the continuous trajectory map are
removed according to minimal information loss criteria. We demonstrate
constant time and space loop closure detection in a large urban
environment with recall performance exceeding FAB-MAP by a factor of 3
at 100\% precision, and investigate the minimum computational and memory
requirements for maintaining mapping performance.},
  affiliation = {Maddern, W (Corresponding Author), Queensland Univ Technol, Fac Sci \& Engn, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4001, Australia.
Maddern, Will; Milford, Michael; Wyeth, Gordon, Queensland Univ Technol, Fac Sci \& Engn, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4001, Australia.},
  affiliations = {Queensland University of Technology (QUT)},
  author-email = {w.maddern@qut.edu.au
michael.milford@qut.edu.au
gordon.wyeth@qut.edu.au},
  book-group-author = {IEEE},
  cited-references = {Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
Cummins M., 2009, ROB SCI SYST C SEATT.
Cummins M., 2008, IEEE INT C ROB AUT P.
Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
Cummins M, 2010, IEEE T ROBOT, V26, P1042, DOI 10.1109/TRO.2010.2080390.
Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178.
Knight J., 2001, IEEE RSJ INT C INT R.
LEONARD J, 2003, INT JOINT C ART INT.
Liu JS, 2001, STAT ENG IN, P225.
Maddern W., INT J ROBOT IN PRESS.
Maddern W., 2010, AUSTR C ROB AUT BRIS.
Milford M., 2010, INT J ROBOTICS RES.
Milford M., 2013, IEEE INT C ROB AUT.
Milford M., 2004, IEEE INT C ROB AUT N.
Nerurkar ED, 2011, INT J ROBOT RES, V30, P772, DOI 10.1177/0278364910390539.
Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
Teynor A, 2007, LECT NOTES COMPUT SC, V4841, P610.
Thrun S., 2002, WORKSH ALG FDN ROB N.
Torii A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS).},
  da = {2022-05-17},
  doc-delivery-number = {BCA25},
  eissn = {2577-087X},
  isbn = {978-1-4673-1405-3},
  issn = {1050-4729},
  language = {English},
  number-of-cited-references = {20},
  orcid-numbers = {Milford, Michael/0000-0002-5162-1793
Wyeth, Gordon/0000-0002-4996-3612},
  research-areas = {Automation \& Control Systems; Engineering; Robotics},
  researcherid-numbers = {Milford, Michael/J-1304-2012},
  series = {IEEE International Conference on Robotics and Automation ICRA},
  times-cited = {31},
  type = {Proceedings Paper},
  unique-id = {WOS:000309406700122},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {1},
  web-of-science-categories = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
Robotics},
  web-of-science-index = {Conference Proceedings Citation Index - Science (CPCI-S)},
}

@conference{ding-et-al:2019:8968550,
  author = {X. DIng and Y. Wang and L. Tang and H. Yin and R. Xiong},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Communication constrained cloud-based long-term visual localization in real time},
  pages = {2159--2166},
  doi = {10.1109/IROS40897.2019.8968550},
  note = {cited By 0; Conference of 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2019 ; Conference Date: 3 November 2019 Through 8 November 2019;  Conference Code:157163},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2019},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {Visual localization is one of the primary capabilities for mobile robots. Long-term visual localization in real time is particularly challenging, in which the robot is required to efficiently localize itself using visual data where appearance may change significantly over time. In this paper, we propose a cloud-based visual localization system targeting at long-term localization in real time. On the robot, we employ two estimators to achieve accurate and real-time performance. One is a sliding-window based visual inertial odometry, which integrates constraints from consecutive observations and self-motion measurements, as well as the constraints induced by localization results from the cloud. This estimator builds a local visual submap as the virtual observation which is then sent to the cloud as new localization constraints. The other one is a delayed state Extended Kalman Filter to fuse the pose of the robot localized from the cloud, the local odometry and the high-frequency inertial measurements. On the cloud, we propose a longer sliding-window based localization method to aggregate the virtual observations for larger field of view, leading to more robust alignment between virtual observations and the map. Under this architecture, the robot can achieve drift-free and real-time localization using onboard resources even in a network with limited bandwidth, high latency and existence of package loss, which enables the autonomous navigation in real-world environment. We evaluate the effectiveness of our system on a dataset with challenging seasonal and illuminative variations. We further validate the robustness of the system under challenging network conditions. © 2019 IEEE.},
  affiliation = {Zhejiang University, State Key Laboratory of Industrial Control and Technology, Hangzhou, China},
  art_number = {8968550},
  coden = {85RBA},
  correspondence_address1 = {Wang, Y.; Zhejiang University, China; email: wangyue@iipc.zju.edu.cn},
  document_type = {Conference Paper},
  funding_details = {U1609210},
  funding_text1 = {ACKNOWLEDGEMENT This work was supported by the National Nature Science Foundation of China (Grant No. U1609210) and Science and Technology Project of Zhejiang Province (Grant No. 2019C01043), the State Key Laboratory of Industrial Control Technology (ITC1904) and Science and Technology on Space Intelligent Control Laboratory (Grant No. HTKJ2019KL502002).},
  isbn = {9781728140049},
  issn = {21530858},
  keywords = {Kalman filters, Autonomous navigation;  Inertial measurements;  Localization method;  Real time performance;  Real-time localization;  Sliding window-based;  Virtual observations;  Visual localization, Intelligent robots},
  language = {English},
  references = {Jegou, H., Douze, M., Schmid, C., Perez, P., Aggregating local descriptors into a compact image representation (2010) Proc Cvpr, 238 (6), pp. 3304-3311; Gálvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Transactions on Robotics, 28 (5), pp. 1188-1197; Naseer, T., Oliveira, G.L., Brox, T., Burgard, W., Semantics-Aware visual localization under challenging perceptual conditions (2017) IEEE International Conference on Robotics and Automation; Paull, L., Huang, G., Seto, M., Leonard, J.J., Communicationconstrained multi-Auv cooperative slam (2015) 2015 IEEE international conference on robotics and automation (ICRA). IEEE, pp. 509-516; Mohanarajah, G., Usenko, V., Singh, M., D'Andrea, R., Waibel, M., Cloud-based collaborative 3d mapping in real-Time with low-cost robots (2015) IEEE Transactions on Automation Science and Engineering, 12 (2), pp. 423-431; Middelberg, S., Sattler, T., Untzelmann, O., Kobbelt, L., Scalable 6-dof localization on mobile devices (2014) European conference on computer vision, pp. 268-283. , Springer; Zhu, X., Qiu, C., Deng, F., Pang, S., Ou, Y., Cloudbased realtime outsourcing localization for a ground mobile robot in largescale outdoor environments (2017) Journal of Field Robotics, 34; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation, pp. 1643-1649; Maddern, W., Milford, M., Wyeth, G., Cat-slam: Probabilistic localisation and mapping using a continuous appearance-based trajectory (2012) International Journal of Robotics Research, 31 (4), pp. 429-451; Lynen, S., Achtelik, M., Weiss, S., Chli, M., Siegwart, R., A robust and modular multi-sensor fusion approach applied to mav navigation (2013) Proc. of the IEEE/RSJ Conference on Intelligent Robots and Systems (IROS; Wu, K.J., Ahmed, A.M., Georgiou, G.A., Roumeliotis, S.I., A square root inverse filter for efficient vision-Aided inertial navigation on mobile devices (2015) 2015 Robotics: Science and Systems Conference, RSS 2015, , MIT Press Journals; Mourikis, A.I., Roumeliotis, S.I., A multi-state constraint kalman filter for vision-Aided inertial navigation (2007) Robotics and automation, 2007 IEEE international conference on. IEEE, pp. 3565-3572; Leutenegger, S., Lynen, S., Bosse, M., Siegwart, R., Furgale, P., Keyframe-based visual-inertial odometry using nonlinear optimization (2015) The International Journal of Robotics Research, 34 (3), pp. 314-334; Forster, C., Carlone, L., Dellaert, F., Scaramuzza, D., On-manifold preintegration for real-Time visual-inertial odometry (2016) IEEE Transactions on Robotics, 33 (1), pp. 1-21; Ding, X., Yue, W., Li, D., Li, T., Rong, X., Laser map aided visual inertial localization in changing environment (2018) Intelligent Robots and Systems (IROS), 2018 IEEE/RSJ International Conference on. IEEE, pp. 4794-4801; Kim, Y., Jeong, J., Kim, A., Stereo camera localization in 3d lidar maps (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 5826-5833; Paton, M., Mactavish, K., Warren, M., Barfoot, T.D., Bridging the appearance gap: Multi-experience localization for long-Term visual teach and repeat (2016) IEEE/rsj International Conference on Intelligent Robots and Systems, pp. 1918-1925; Tang, L., Wang, Y., Ding, X., Yin, H., Xiong, R., Huang, S., Topological local-metric framework for mobile robots navigation: A long term perspective (2019) Autonomous Robots, 43 (1), pp. 197-211; Churchill, W., Newman, P., Experience-based navigation for longterm localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Bürki, M., Gilitschenski, I., Stumm, E., Siegwart, R., Nieto, J., Appearance-based landmark selection for efficient long-Term visual localization (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, pp. 4137-4143; Lowry, S., Snderhauf, N., Newman, P., Leonard, J.J., Visual place recognition: A survey (2016) IEEE Transactions on Robotics, 32 (1), pp. 1-19; Guo, C.X., Sartipi, K., DuToit, R.C., Georgiou, G.A., Li, R., O'Leary, J., Nerurkar, E.D., Roumeliotis, S.I., Resource-Aware large-scale cooperative three-dimensional mapping using multiple mobile devices (2018) IEEE Transactions on Robotics, (99), pp. 1-21; Mur-Artal, R., Tardós, J.D., Visual-inertial monocular slam with map reuse (2017) IEEE Robotics and Automation Letters, 2 (2), pp. 796-803; Wang, Y., Xiong, R., Huang, S., A pose pruning driven solution to pose feature graphslam (2015) Advanced Robotics, 29 (10), pp. 683-698; Sattler, T., Maddern, W., Toft, C., Torii, A., Hammarstrand, L., Stenborg, E., Safari, D., Sivic, J., Benchmarking 6dof outdoor visual localization in changing conditions (2018) Proc. CVPR, 1; Sinha, R.S., Wei, Y., Hwang, S.H., A survey on lpwa technology: Lora and nb-iot (2017) Ict Express, 3 (1); Sturm, J., Burgard, W., Cremers, D., Evaluating egomotion and structure-from-motion approaches using the tum rgb-d benchmark (2012) Proc. of the Workshop on Color-Depth Camera Fusion in Robotics at the IEEE/RJS International Conference on Intelligent Robot Systems (IROS},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081157270&doi=10.1109%2fIROS40897.2019.8968550&partnerID=40&md5=86e32650397f0d38cecbd132b2b583d1},
}

@article{ding-et-al:2020:2942760,
  author = {X. Ding and Y. Wang and R. Xiong and D. Li and L. Tang and H. Yin and L. Zhao},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  title = {Persistent Stereo Visual Localization on Cross-Modal Invariant Map},
  volume = {21},
  number = {11},
  pages = {4646--4658},
  doi = {10.1109/TITS.2019.2942760},
  note = {cited By 4},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2020},
  abbrev_source_title = {IEEE Trans. Intell. Transp. Syst.},
  abstract = {Autonomous mobile vehicles are expected to perform persistent and accurate localization with low-cost equipment. To achieve this goal, we propose a stereo camera based visual localization method using a modified laser map, which takes the advantage of both the low cost of camera, and high geometric precision of laser data to achieve long-term performance. Considering that LiDAR and camera give measurements of the same environment in different modalities, the cross-modal invariance is investigated to modify the laser map for visual localization. Specifically, a map learning algorithm is introduced to sample the robust subsets in laser maps that are useful for visual localization using multi-session visual and laser data. Further, a generative map model is derived to describe this cross-modal invariance, based on which two types of measurements are defined to model the laser map points as appropriate visual observations. Tightly coupling these measurements within the local bundle adjustment during online sliding-window based visual odometry, the vehicle can achieve robust localization even one year after the map was built. The effectiveness of the proposed method is evaluated on both the public KITTI datasets and self-collected datasets in our campus, which include seasonal, illumination and object variations. On all experimental localization sessions, our method provides satisfactory results, even when the direction is opposite to that in the mapping session, verifying the superior performance of the laser map based visual localization method. © 2000-2011 IEEE.},
  affiliation = {State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, 310007, China; Center for Autonomous Systems (CAS), University of Technology Sydney, Sydney, NSW  2007, Australia},
  art_number = {8853391},
  author_keywords = {map incorporated bundle adjustment;  map maintenance;  persistent autonomy;  Visual localization},
  correspondence_address1 = {Wang, Y.; State Key Laboratory of Industrial Control and Technology, China; email: wangyue@iipc.zju.edu.cn; Xiong, R.; State Key Laboratory of Industrial Control and Technology, China; email: rxiong@zju.edu.cn},
  document_type = {Article},
  funding_details = {Key Technology Research and Development Program of ShandongKey Technology Research and Development Program of Shandong, 2019C01043},
  funding_text1 = {This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFC0806501, in part by the Key Research and Development Program of Zhejiang Province, China, Grant 2019C01043, and in part by the National Nature Science Foundation of China under Grant 61903332.},
  funding_text2 = {Manuscript received August 19, 2018; revised January 6, 2019, May 4, 2019 and July 22, 2019; accepted September 6, 2019. Date of publication September 30, 2019; date of current version October 30, 2020. This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFC0806501, in part by the Key Research and Development Program of Zhejiang Province, China, Grant 2019C01043, and in part by the National Nature Science Foundation of China under Grant 61903332. The Associate Editor for this article was B. Fidan. (Corresponding authors: Yue Wang; Rong Xiong.) X. Ding, Y. Wang, R. Xiong, D. Li, L. Tang, and H. Yin are with the State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou 310007, China (e-mail: wangyue@iipc.zju.edu.cn; rxiong@zju.edu.cn).},
  issn = {15249050},
  keywords = {Cameras;  Costs;  Stereo image processing, Autonomous mobile vehicles;  Geometric precision;  Local bundle adjustments;  Long term performance;  Low-cost equipment;  Sliding window-based;  Visual localization;  Visual observations, Learning algorithms},
  language = {English},
  references = {Badino, H., Huber, D., Kanade, T., Visual topometric localization (2011) Proc. Ieee Intell. Vehicles Symp. (IV), Jun., pp. 794-799; Milford, M.J., Wyeth, G.F., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. Ieee Int. Conf. Robot. Autom., May, pp. 1643-1649; Surber, J., Teixeira, L., Chli, M., Robust visual-inertial localization with weak GPS priors for repetitive UAV flights (2017) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May/Jun., pp. 6300-6306; Withers, D., Newman, P., Modelling scene change for large-scale long term laser localisation (2017) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May/Jun., pp. 6233-6239; Hata, A.Y., Ramos, F.T., Wolf, D.F., Monte Carlo localization on Gaussian process occupancy maps for urban environments (2017) Ieee Trans. Intell. Transp. Syst., 19 (9), pp. 2893-2902. , Sep; Lategahn, H., Stiller, C., Vision-only localization (2014) Ieee Trans. Intell. Transp. Syst., 15 (3), pp. 1246-1257. , Jun; Pomerleau, F., Krüsi, P., Colas, F., Furgale, P., Siegwart, R., Longterm 3D map maintenance in dynamic environments (2014) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May/Jun., pp. 3712-3719; Wang, Y., Huang, S., Xiong, R., Wu, J., A framework for multisession RGBD SLAM in low dynamic workspace environment (2016) Caai Trans. Intell. Technol., 1 (1), pp. 90-103; Walcott-Bryant, A., Kaess, M., Johannsson, H., Leonard, J.J., Dynamic pose graph SLAM: Long-term mapping in low dynamic environments (2012) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Oct., pp. 1871-1878; Fehr, M., TSDF-based change detection for consistent long-term dense reconstruction and dynamic object discovery (2017) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May/Jun., pp. 5237-5244; Wang, Y., Xiong, R., Huang, S., A pose pruning driven solution to pose feature GraphSLAM (2015) Adv. Robot., 29 (10), pp. 683-698; Wang, Y., Xiong, R., Li, Q., Huang, S., Kullback-leibler divergence based graph pruning in robotic feature mapping (2013) Proc. Eur. Conf. Mobile Robots, pp. 32-37; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) Proc. Ieee Acm Int. Symp. Mixed Augmented Reality, pp. 1-10; Mur-Artal, R., Montiel, J.M.M., Tardós, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) Ieee Trans. Robot., 31 (5), pp. 1147-1163. , Oct; Mourikis, A.I., Roumeliotis, S.I., A multi-state constraint Kalman filter for vision-aided inertial navigation (2007) Proc. Ieee Int. Conf. Robot. Autom., Apr., pp. 3565-3572; Santoso, F., Garratt, M.A., Anavatti, S.G., Visual-inertial navigation systems for aerial robotics: Sensor fusion and technology (2017) Ieee Trans. Autom. Sci. Eng., 14 (1), pp. 260-275. , Jan; Yang, Z., Shen, S., Monocular visual-inertial state estimation with online initialization and camera-IMU extrinsic calibration (2017) Ieee Trans. Autom. Sci. Eng., 14 (1), pp. 39-51. , Jan; Li, D., Eckenhoff, K., Wu, K., Wang, Y., Xiong, R., Huang, G., Gyro-aided camera-odometer online calibration and localization (2017) Proc. Amer. Control Conf., pp. 3579-3586; Tang, L., Wang, Y., Ding, X., Yin, H., Xiong, R., Huang, S., Topolog-ical local-metric framework for mobile robots navigation: A long term perspective (2018) Auto. Robots, 43 (4), pp. 197-211; Churchill, W., Newman, P., Experience-based navigation for longterm localisation (2013) Int. J. Robot. Res., 32 (14), pp. 1645-1661. , Dec; Valgren, C., Lilienthal, A.J., SIFT, SURF & seasons: Appearance-based long-term localization in outdoor environments (2010) Robot. Auto. Syst., 58 (2), pp. 149-156; McManus, C., Upcroft, B., Newmann, P., Scene signatures: Localised and point-less features for localisation (2014) Robotics: Science and Systems X, , Berkeley, CA, USA: Univ. California, Berkeley; Linegar, C., Churchill, W., Newman, P., Made to measure: Bespoke landmarks for 24-hour, all-weather localisation with a camera (2016) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May, pp. 787-794; Sons, M., Lauer, M., Keller, C.G., Stiller, C., Mapping and localization using surround view (2017) Proc. Ieee Int. Conf. Intell. Vehicles Symp. (IV), Jun., pp. 1158-1163; Sattler, T., Benchmarking 6DOF outdoor visual localization in changing conditions (2018) Proc. Cvpr, 1, pp. 8601-8610; Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The gist of maps-Summarizing experience for lifelong localization (2015) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May, pp. 2767-2773; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) J. Field Robot., 33 (5), pp. 561-590; Labbé, M., Michaud, F., Long-term online multi-session graph-based SPLAM with memory management (2018) Auto. Robots, 42 (6), pp. 1133-1150; Wolcott, R.W., Eustice, R.M., Visual localization within LIDAR maps for automated urban driving (2014) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), Sep., pp. 176-183; Pascoe, G., Maddern, W.P., Newman, P., Robust direct visual localisation using normalised information distance (2015) Proc. Brit. Mach. Vis. Conf., p. 70; Caselitz, T., Steder, B., Ruhnke, M., Burgard, W., Monocular camera localization in 3D LiDAR maps (2016) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., Oct., pp. 1926-1931; Arun, K.S., Huang, T.S., Blostein, S.D., Least-squares fitting of two 3-D point sets (1987) Ieee Trans. Pattern Anal. Mach. Intell., PAMI-9 (5), pp. 698-700. , Sep; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May, pp. 90-97; Milford, M., Wyeth, G., Persistent navigation and mapping using a biologically inspired SLAM system (2010) Int. J. Robot. Res., 29 (9), pp. 1131-1153; Schneider, T., MAPLAB: An open framework for research in visual-inertial mapping and localization (2018) Ieee Robot. Autom. Lett., 3 (3), pp. 1418-1425. , Jul; Milford, M.J., Wyeth, G.F., Mapping a suburb with a single camera using a biologically inspired SLAM system (2008) Ieee Trans. Robot., 24 (5), pp. 1038-1053. , Oct; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) Int. J. Comput. Vis., 60 (2), pp. 91-110; Bay, H., Tuytelaars, T., Van Gool, L., SURF: Speeded up robust features (2006) Proc. Eur. Conf. Comput. Vis, pp. 404-417. , Berlin, Germany: Springer; Calonder, M., Lepetit, V., Ozuysal, M., Trzcinski, T., Strecha, C., Fua, P., BRIEF: Computing a local binary descriptor very fast (2012) Ieee Trans. Pattern Anal. Mach. Intell., 34 (7), pp. 1281-1298. , Jul; Rublee, E., Rabaud, V., Konolige, K., Bradski, G., ORB: An efficient alternative to SIFT or SURF (2011) Proc. Ieee Int. Conf. Comput. Vis. (ICCV), Nov., pp. 2564-2571; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Proc. Aaai, pp. 2564-2570; Corke, P., Paul, R., Churchill, W., Newman, P., Dealing with shadows: Capturing intrinsic scene appearance for image-based outdoor localisation (2013) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. (IROS), Nov., pp. 2085-2092; Xu, Y., John, V., Mita, S., Tehrani, H., Ishimaru, K., Nishino, S., 3D point cloud map based vehicle localization using stereo camera (2017) Proc. Ieee Intell. Vehicles Symp. (IV), Jun., pp. 487-492; Ozog, P., Johnson-Roberson, M., Eustice, R.M., Mapping underwater ship hulls using a model-assisted bundle adjustment framework (2016) Robot. Auto. Syst., 87, pp. 329-347. , Jan; Sattler, T., Are large-scale 3D models really necessary for accurate visual localization? (2017) Proc. Ieee Conf. Comput. Vis. Pattern Recognit. (CVPR), Jul., pp. 1637-1646; Wang, Y., Xiong, R., Li, Q., EM-based point to plane ICP for 3D simultaneous localization and mapping (2013) Int. J. Robot. Autom., 28 (3), pp. 234-244; Besag, J., On the statistical analysis of dirty pictures (1986) J. Roy. Stat. Soc. B, Methodol., 48 (3), pp. 259-302; Tang, L., Ding, X., Yin, H., Wang, Y., Xiong, R., From one to many: Unsupervised traversable area segmentation in off-road environment (2018) Proc. Ieee Int. Conf. Robot. Biomimetics, Dec., pp. 787-792; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proc. Ieee Int. Conf. Robot. Autom., May, pp. 3607-3613; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) Proc. Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 3354-3361. , Jun; Levinson, J., Thrun, S., Robust vehicle localization in urban environments using probabilistic maps (2010) Proc. Ieee Int. Conf. Robot. Autom. (ICRA), May, pp. 4372-4378; McManus, C., Upcroft, B., Newman, P., Learning place-dependant features for long-term vision-based localisation (2015) Auto. Robots, 39 (3), pp. 363-387; Mur-Artal, R., Tardós, J.D., ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras (2017) Ieee Trans. Robot., 33 (5), pp. 1255-1262. , Oct; Sturm, J., Burgard, W., Cremers, D., Evaluating egomotion and structure-from-motion approaches using the TUM RGB-D benchmark (2012) Proc. Workshop Color-Depth Camera Fusion Robot. IEEE/RJS Int. Conf. Intell. Robot Syst. (IROS), Oct., pp. 1-7; Wang, R., Schworer, M., Cremers, D., Stereo DSO: Large-scale direct sparse visual odometry with stereo cameras (2017) Proc. Ieee Int. Conf. Comput. Vis., Oct., pp. 3903-3911; Heyde, C.C., (2008) Quasi-Likelihood and Its Application: A General Approach to Optimal Parameter Estimation, , Springer; McManus, C., Furgale, P., Stenning, B., Barfoot, T.D., Lighting-invariant visual teach and repeat using appearance-based lidar (2013) J. Field Robot., 30 (2), pp. 254-287},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096218582&doi=10.1109%2fTITS.2019.2942760&partnerID=40&md5=ddbd709c48aa1d0a30a37cfece3d07b6},
}

@article{xu-et-al:2021:3060741,
  author = {X. Xu and H. Yin and Z. Chen and Y. Li and Y. Wang and R. Xiong},
  journal = {IEEE Robotics and Automation Letters},
  title = {DiSCO: Differentiable Scan Context with Orientation},
  volume = {6},
  number = {2},
  pages = {2791--2798},
  doi = {10.1109/LRA.2021.3060741},
  note = {cited By 6},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Global localization is essential for robot navigation, of which the first step is to retrieve a query from the map database. This problem is called place recognition. In recent years, LiDAR scan based place recognition has drawn attention as it is robust against the appearance change. In this letter, we propose a LiDAR-based place recognition method, named Differentiable Scan Context with Orientation (DiSCO), which simultaneously finds the scan at a similar place and estimates their relative orientation. The orientation can further be used as the initial value for the down-stream local optimal metric pose estimation, improving the pose estimation especially when a large orientation between the current scan and retrieved scan exists. Our key idea is to transform the feature into the frequency domain. We utilize the magnitude of the spectrum as the place descriptor, which is theoretically rotation-invariant. In addition, based on the differentiable phase correlation, we can efficiently estimate the global optimal relative orientation using the spectrum. With such structural constraints, the network can be learned in an end-to-end manner, and the backbone is fully shared by the two tasks, achieving better interpretability and lightweight. Finally, DiSCO is validated on three datasets with long-term outdoor conditions, showing better performance than the compared methods. Codes are released at https://github.com/MaverickPeter/DiSCO-pytorch. © 2016 IEEE.},
  affiliation = {State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, Zhejiang, 310027, China; Zhejiang Lab, Hangzhou Zhejiang, 310014, China},
  art_number = {9359460},
  author_keywords = {Localization;  range sensing;  SLAM},
  correspondence_address1 = {Wang, Y.; State Key Laboratory of Industrial Control Technology, China; email: ywang24@zju.edu.cn},
  document_type = {Article},
  funding_details = {State Administration for Science, Technology and Industry for National DefenseState Administration for Science, Technology and Industry for National Defense, SASTIND, HTKJ2019KL502005},
  funding_text1 = {Manuscript received October 15, 2020; accepted February 3, 2021. Date of publication February 19, 2021; date of current version March 17, 2021. This letter was recommended for publication by Associate Editor L. Merino and Editor J. Civera upon evaluation of the reviewers’ comments. This letter was recommended for publication by Editor Javier, Civera upon evaluation of the Associate Editor and reviewers’ comments. This work was supported in part by the National Key R&D Program of China under Grant 2018AAA0102700 and in part by the stable support project of State Administration of Science, Technology and Industry for National Defence Grant, PRC under Grant HTKJ2019KL502005. (Corresponding author: Yue Wang.) Xuecheng Xu, Huan Yin, Zexi Chen, Yue Wang, and Rong Xiong are with the State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, Zhejiang 310027, China (e-mail: xuechengxu@zju.edu.cn; zjuyinhuan@gmail.com; chenzexi@zju.edu.cn; ywang24@zju.edu.cn; rxiong_zju@hotmail.com).},
  issn = {23773766},
  keywords = {Agricultural robots;  Maps;  Optical radar;  Query processing;  Robots, Frequency domains;  Global localization;  Interpretability;  Phase correlation;  Place recognition;  Relative orientation;  Rotation invariant;  Structural constraints, Frequency domain analysis},
  language = {English},
  references = {Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of michigan north campus long-term vision and LiDAR dataset (2016) Int. J. Robot. Res., 35 (9), pp. 1023-1035; Lowry, S., Visual place recognition: A survey (2016) Ieee Trans. Robot., 32 (1), pp. 1-19. , Feb; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2018) Ieee Trans. Pattern Anal. Mach. Intell., 40 (6), pp. 1437-1451. , Jun; Tang, L., Wang, Y., Luo, Q., Ding, X., Xiong, R., Adversarial feature disentanglement for place recognition across changing appearance (2020) Proc. Ieee Int. Conf. Robot. Automat., pp. 1301-1307; Steder, B., Ruhnke, M., Grzonka, S., Burgard, W., Place recognition in 3D scans using a combination of bag of words and point feature based relative pose estimation (2011) Proc. Ieee Int. Conf. Intell. Robots Syst., pp. 1249-1255; Wang, S., Pokrovsky, A., Urtasun, R., Learning to localize using a LiDAR intensity map (2018) Conf. Robot Learn., pp. 605-616; Besl, P.J., McKay, N.D., Method for registration of 3-D shapes (1992) Ieee Trans. Pattern Anal. Mach. Intell., 14 (2), pp. 239-256; Kim, G., Kim, A., Scan context: Egocentric spatial descriptor for place recognition within 3D point cloud map (2018) Proc. Ieee Int. Conf. Intell. Robots Syst., pp. 4802-4809; Tombari, F., Salti, S., Di Stefano, L., A combined texture-shape descriptor for enhanced 3D feature matching (2011) Proc. Int. Conf. Image Process., pp. 809-812; Stein, F., Medioni, G., Structural indexing: Efficient 2-D object recognition (1992) Ieee Trans. Pattern Anal. Mach. Intelli., 14 (12), pp. 1198-1204. , Dec; Knopp, J., Prasad, M., Willems, G., Timofte, R., Van Gool, L., Hough transform and 3D SURF for robust three dimensional classification (2010) Proc. 11th Europ. Conf. Comput. Vis.: Part Vi, pp. 589-602; Rusu, R.B., Bradski, G., Thibaux, R., Hsu, J., Fast 3D recognition and pose using the viewpoint feature histogram (2010) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst., pp. 2155-2162; He, L., Wang, X., Zhang, H., M2DP: A novel 3D point cloud descriptor and its application in loop closure detection (2016) Proc. Ieee Int. Conf. Intell. Robots Syst., pp. 231-237; Dube, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., SegMatch: Segment based place recognition in 3D point clouds (2017) Proc. Ieee Int. Conf. Robot. Automat., May, pp. 5266-5272; Dubé, R., Incremental segment-based localization in {3D} point clouds (2018) Ieee Robot. Autom. Lett., 3 (3), pp. 1832-1839; Yin, H., Tang, L., Ding, X., Wang, Y., Xiong, R., LocNet: Global localization in 3D point clouds for mobile vehicles (2018) Proc. Ieee Intell. Veh. Symp., pp. 728-733; Yin, H., Wang, Y., Ding, X., Tang, L., Huang, S., Xiong, R., 3D LiDAR-Based global localization using siamese neural network (2020) Ieee Trans. Intell. Transp. Syst., 21 (4), pp. 1380-1392. , Apr; Kim, G., Park, B., Kim, A., 1-day learning, 1-year localization: Long-term lidar localization using scan context image (2019) Ieee Robot. Autom. Lett., 4 (2), pp. 1948-1955; Uy, M.A., Lee, G.H., PointNetVLAD: Deep point cloud based retrieval for large-scale place recognition (2018) Proc. Ieee Comput. Soc. Conf. Comput. Vis. Pattern Recognit., pp. 4470-4479; Qi, C.R., Su, H., Mo, K., Guibas, L.J., PointNet: Deep learning on point sets for 3D classification and segmentation (2017) Proc. 30th Ieee Conf. Comput. Vis. Pattern Recognit., pp. 652-660; Schaupp, L., Burki, M., Dube, R., Siegwart, R., Cadena, C., OREOS: Oriented recognition of 3D point clouds in outdoor scenarios (2019) Proc. Ieee Int. Conf. Intell. Robots Syst., pp. 3255-3261; Chen, X., OverlapNet: Loop Closing for LiDAR-based SLAM (2020) Proc. Robot. Sci. Syst. (RSS), , https://github.com/PRBonn/OverlapNet, [Online]; Barnes, D., Weston, R., Posner, I., Masking by moving: Learning distraction-free radar odometry from pose information (2020) Conf. Robot Learn., pp. 303-316; Chen, Z., Xu, X., Wang, Y., Xiong, R., (2020) Deep Phase Correlation for End-to-end Heterogeneous Sensor Measurements Matching; Bülow, H., Birk, A., Scale-freeregistrationsin3D:7degreesoffreedom with fourier mellin soft transforms (2018) Int. J. Comput. Vis., 126 (7), pp. 731-750; Bülow, H., Mueller, C.A., Chavez, A.G., Buda, F., Birk, A., A divide and conquer method for 3 d registration of inhomogeneous, partially overlapping scans with fourier mellin soft (FMS) (2020) Proc. Ieee Int. Conf. Robot. Automat., pp. 8594-8601; Kingma, D.P., Ba, J.L., Adam: A method for stochastic optimization (2015) 3rd Int. Conf. Learn. Represent., {ICLR}; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000 km: The oxford robotcar dataset (2017) Int. J. Robot. Res., 36 (1), pp. 3-15; Kim, G., Park, Y.S., Cho, Y., Jeong, J., Kim, A., MulRan: Multimodal range dataset for urban place recognition (2020) Proc. Ieee Int. Conf. Robot. Automat., pp. 6246-6253; Cummins, M., Newman, P., Fab-map: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665; Xu, X., Yin, H., Chen, Z., Wang, Y., Xiong, R., (2021) Disco: Differentiable Scan Context with Orientation},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101737460&doi=10.1109%2fLRA.2021.3060741&partnerID=40&md5=023af0c57f7fca9526f233dc73fba59d},
}

@article{bouaziz-et-al:2022:4,
  author = {Y. Bouaziz and E. Royer and G. Bresson and M. Dhome},
  journal = {Multimedia Tools and Applications},
  title = {Map management for robust long-term visual localization of an autonomous shuttle in changing conditions},
  doi = {10.1007/s11042-021-11870-4},
  note = {cited By 0},
  publisher = {Springer},
  year = {2022},
  abbrev_source_title = {Multimedia Tools Appl},
  abstract = {Changes in appearance present a tremendous problem for the visual localization of an autonomous vehicle in outdoor environments. Data association between the current image and the landmarks in the map can be challenging in cases where the map was built with different environmental conditions. This paper introduces a solution to build and use multi-session maps incorporating sequences recorded in different conditions (day, night, fog, snow, rain, change of season, etc.). During visual localization, we exploit a ranking function to extract the most relevant keyframes from the map. This ranking function is designed to take into account the pose of the vehicle as well as the current environmental condition. In the mapping phase, covering all conditions by constantly adding data to the map leads to a continuous growth in the map size which in turn deteriorates the localization speed and performance. Our map management strategy is an incremental approach that aims to limit the size of the map while keeping it as diverse as possible. Our experiments were performed on real data collected with our autonomous shuttle as well as on a widely used public dataset. The results demonstrate that our keyframe-based ranking function is suitable for long-term scenarios. Our map management algorithm aims to build a map with as much diversity as possible whereas some state of the art approaches tend to filter out the less observed landmarks. This strategy shows a reduction of localization failures while maintaining real-time performance. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
  affiliation = {Institut Pascal, CNRS, Clermont-Ferrand, Institut VEDECOM, Versailles, France; Institut Pascal, CNRS, SIGMA Clermont, Clermont-Ferrand, France; Institut VEDECOM, Versailles, France},
  author_keywords = {Computer vision for transportation;  SLAM;  Visual-based navigation},
  coden = {MTAPF},
  correspondence_address1 = {Bouaziz, Y.; Institut Pascal, France; email: youssef.bouaziz@etu.uca.fr},
  document_type = {Article},
  funding_details = {ANR-10-LABX-16-01},
  funding_text1 = {This work has been sponsored by the French government research program “Investissements d’Avenir” through the IMobS3 Laboratory of Excellence (ANR-10-LABX-16-01) and the RobotEx Equipment of Excellence (ANR-10-EQPX-44), by the European Union through the Regional Competitiveness and Employment program 2014-2020 (ERDF - AURA region) and by the AURA region.},
  issn = {13807501},
  keywords = {Information retrieval;  Robotics, Computer vision for transportation;  Condition;  Environmental conditions;  Key-frames;  Localisation;  Map managements;  Ranking functions;  SLAM;  Visual localization;  Visual-based navigation, Computer vision},
  language = {English},
  references = {Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., Netvlad: Cnn architecture for weakly supervised place recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 5297-5307; Bay, H., Tuytelaars, T., van Gool, L., Surf: Speeded up robust features (2006) European Conference on Computer Vision, pp. 404-417. , Springer; Berrio, J.S., Ward, J., Worrall, S., Nebot, E., Identifying robust landmarks in feature-based maps (2019) 2019 IEEE Intelligent Vehicles Symposium (IV), pp. 1166-1172. , IEEE; Bouaziz, Y., Royer, E., Bresson, G., Dhome, M., Keyframes retrieval for robust long-term visual localization in changing conditions (2021) 2021 IEEE 19Th World Symposium on Applied Machine Intelligence and Informatics (SAMI), pp. 093-100. , IEEE; Bouaziz, Y., Royer, E., Bresson, G., Dhome, M., Over two years of challenging environmental conditions for localization: The iplt dataset (2021) 18Th International Conference on Informatics in Control, Automation and Robotics; Bürki, M., Cadena, C., Gilitschenski, I., Siegwart, R., Nieto, J., Appearance-based landmark selection for visual localization (2019) Journal of Field Robotics, 36 (6), pp. 1041-1073; IEEE Intelligent vehicles symposium (IV). pp. 682–688 (2018) IEEE; Bürki, M., Gilitschenski, I., Stumm, E., Siegwart, R., Nieto, J., Appearance-based landmark selection for efficient long-term visual localization (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4137-4143. , IEEE; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan North Campus long-term vision and lidar dataset (2015) Int J Robot Res, 35 (9), pp. 1023-1035; Chen, C., Wang, B., Lu, C.X., Trigoni, A., Markham, A., A survey on deep learning for localization and mapping: Towards the age of spatial machine intelligence (2020) Arxiv, 2006, p. 12567; Churchill, W., Newman, P., Practice makes perfect? Managing and leveraging visual experiences for lifelong navigation (2012) 2012 IEEE International Conference on Robotics and Automation, pp. 4525-4532. , IEEE; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) The International Journal of Robotics Research, 32 (14), pp. 1645-1661; Clark, R., Wang, S., Markham, A., Trigoni, N., Wen, H., (2017) Vidloc: A deep spatio-temporal model for 6-dof video-clip relocalization, (7), pp. 2652-2660. , https://doi.org/10.1109/CVPR.2017.284; Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Schiele, B., The cityscapes dataset for semantic urban scene understanding (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3213-3223; Diaz-Escobar, J., Kober, V., Gonzalez-Fraga, J.A., Luift: Luminance invariant feature transform (2018) Math Probl Eng, 2018, pp. 1-17; Dusmanu, M., Rocco, I., Pajdla, T., Pollefeys, M., Sivic, J., Torii, A., Sattler, T., D2-net: A trainable cnn for joint description and detection of local features (2019) Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 8092-8101; Dymczyk, M., Lynen, S., Cieslewski, T., Bosse, M., Siegwart, R., Furgale, P., The gist of maps-summarizing experience for lifelong localization (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 2767-2773. , IEEE; Dymczyk, M., Schneider, T., Gilitschenski, I., Siegwart, R., Stumm, E., Erasing bad memories: Agent-side summarization for long-term mapping (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4572-4579. , IEEE; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets robotics: the kitti dataset (2013) The International Journal of Robotics Research, 32 (11), pp. 1231-1237; Gridseth, M., Barfoot, T.D., Deepmel: Compiling visual multi-experience localization into a deep neural network (2020) 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 1674-1681. , IEEE; Halodová, L., Dvoráková, E., Majer, F., Vintr, T., Mozos, O.M., Dayoub, F., Krajník, T., Predictive and adaptive maps for long-term visual navigation in changing environments (2019) 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 7033-7039. , IEEE; Harris, C.G., Stephens, M., (1988); Jatzkowski, I., Wilke, D., Maurer, M., A deep-learning approach for the detection of overexposure in automotive camera images (2018) 2018 21St International Conference on Intelligent Transportation Systems (ITSC), pp. 2030-2035. , IEEE; Kendall, A., Grimes, M., Cipolla, R., Posenet: A convolutional network for real-time 6-dof camera relocalization (2015) Proceedings of the IEEE International Conference on Computer Vision, pp. 2938-2946; Krajník, T., Fentanes, J.P., Hanheide, M., Duckett, T., Persistent localization and life-long mapping in changing environments using the frequency map enhancement (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4558-4563. , IEEE; Krajník, T., Vintr, T., Molina, S., Fentanes, J.P., Cielniak, G., Mozos, O.M., Broughton, G., Duckett, T., Warped hypertime representations for long-term autonomy of mobile robots (2019) IEEE Robotics and Automation Letters, 4 (4), pp. 3310-3317; Laskar, Z., Melekhov, I., Kalia, S., Kannala, J., Camera relocalization by computing pairwise relative poses using convolutional neural network (2017) Proceedings of the IEEE International Conference on Computer Vision Workshops, pp. 929-938; Lébraly, P., Royer, E., Ait-Aider, O., Deymier, C., Dhome, M., Fast calibration of embedded non-overlapping cameras (2011) 2011 IEEE International Conference on Robotics and Automation, pp. 221-227. , IEEE; Linegar, C., Churchill, W., Newman, P., Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 90-97. , IEEE; Lowe, D.G., Distinctive image features from scale-invariant keypoints (2004) International Journal of Computer Vision, 60 (2), pp. 91-110; MacTavish, K., Paton, M., Barfoot, T.D., Selective memory: Recalling relevant experience for long-term visual localization (2018) Journal of Field Robotics, 35 (8), pp. 1265-1292; Maddern, W., Pascoe, G., Linegar, C., Newman, P., 1 year, 1000km: the oxford robotcar dataset (2017) The International Journal of Robotics Research (IJRR), 36 (1), pp. 3-15; Maddern, W., Pascoe, G., Gadd, M., Barnes, D., Yeomans, B., Newman, P., (2020) Real-Time Kinematic Ground Truth for the Oxford Robotcar Dataset; Magnago, V., Palopoli, L., Passerone, R., Fontanelli, D., Macii, D., Effective landmark placement for robot indoor localization with position uncertainty constraints (2019) IEEE Trans Instrum Meas, 68 (11), pp. 4443-4455; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) 2012 IEEE International Conference on Robotics and Automation, pp. 1643-1649. , IEEE; Mühlfellner, P., Bürki, M., Bosse, M., Derendarz, W., Philippsen, R., Furgale, P., Summary maps for lifelong visual localization (2016) Journal of Field Robotics, 33 (5), pp. 561-590; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., Orb-slam: a versatile and accurate monocular slam system (2015) IEEE Transactions on Robotics, 31 (5), pp. 1147-1163; Murillo, A.C., Kosecka, J., Experiments in place recognition using gist panoramas (2009) 2009 IEEE 12Th International Conference on Computer Vision Workshops, ICCV Workshops, pp. 2196-2203. , IEEE; Naseer, T., Oliveira, G.L., Brox, T., Burgard, W., Semantics-aware visual localization under challenging perceptual conditions (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 2614-2620. , IEEE; Pascoe, G., Maddern, W., Tanner, M., Piniés, P., Newman, P., Nid-slam: Robust monocular slam using normalised information distance (2017) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1435-1444; Pepperell, E., Corke, P., Milford, M., Routed roads: Probabilistic vision-based place recognition for changing conditions, split streets and varied viewpoints (2016) The International Journal of Robotics Research, 35 (9), pp. 1057-1179; Rosen, D.M., Mason, J., Leonard, J.J., Towards lifelong feature-based mapping in semi-static environments (2016) 2016 IEEE International Conference on Robotics and Automation (ICRA), pp. 1063-1070. , IEEE; Royer, E., Marmoiton, F., Alizon, S., Ramadasan, D., Slade, M., Nizard, A., Dhome, M., Bonjean, F., Lessons learned after more than 1000 km in an autonomous shuttle guided by vision (2016) 2016 IEEE 19Th International Conference on Intelligent Transportation Systems (ITSC), pp. 2248-2253. , IEEE; Schneider, T., Dymczyk, M., Fehr, M., Egger, K., Lynen, S., Gilitschenski, I., Siegwart, R., Maplab: an open framework for research in visual-inertial mapping and localization (2018) IEEE Robotics and Automation Letters, 3 (3), pp. 1418-1425; Schönberger, J.L., Pollefeys, M., Geiger, A., Sattler, T., Semantic visual localization (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6896-6906; Stenborg, E., Sattler, T., Hammarstrand, L., Using image sequences for long-term visual localization (2020) 2020 International Conference on 3D Vision (3DV), pp. 938-948. , https://doi.org/10.1109/3DV50981.2020.00104; Tian, Y., Yu, X., Fan, B., Wu, F., Heijnen, H., Balntas, V., Sosnet: Second order similarity regularization for local descriptor learning (2019) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 11016-11025; Walch, F., Hazirbas, C., Leal-Taixe, L., Sattler, T., Hilsenbeck, S., Cremers, D., Image-based localization using lstms for structured feature correlation (2017) Proceedings of the IEEE International Conference on Computer Vision, pp. 627-637; Yan, Z., Sun, L., Krajník, T., Ruichek, Y., Eu long-term dataset with multiple sensors for autonomous driving (2020) 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 10697-10704. , https://doi.org/10.1109/IROS45743.2020.9341406; Yi, K.M., Trulls, E., Lepetit, V., Fua, P., Lift: Learned invariant feature transform (2016) European Conference on Computer Vision, pp. 467-483. , Springer},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128007063&doi=10.1007%2fs11042-021-11870-4&partnerID=40&md5=5fd1fe540df0e3cc196b34c691ad9280},
}

@conference{latif-et-al:2012:6385879,
  author = {Y. Latif and C. Cadena and J. Neira},
  journal = {IEEE International Conference on Intelligent Robots and Systems},
  title = {Realizing, reversing, recovering: Incremental robust loop closing over time using the iRRR algorithm},
  pages = {4211--4217},
  doi = {10.1109/IROS.2012.6385879},
  note = {cited By 20; Conference of 25th IEEE/RSJ International Conference on Robotics and Intelligent Systems, IROS 2012 ; Conference Date: 7 October 2012 Through 12 October 2012;  Conference Code:94955},
  address = {Vilamoura, Algarve},
  year = {2012},
  abbrev_source_title = {IEEE Int Conf Intell Rob Syst},
  abstract = {The ability to reconsider information over time allows to detect failures and is crucial for long term robust autonomous robot applications. This applies to loop closure decisions in localization and mapping systems. This paper describes a method to analyze all available information up to date in order to robustly remove past incorrect loop closures from the optimization process. The main novelties of our algorithm are: 1. incrementally reconsidering loop closures and 2. handling multi-session, spatially related or unrelated experiments. We validate our proposal in real multi-session experiments showing better results than those obtained by state of the art methods. © 2012 IEEE.},
  affiliation = {Instituto de Investigación en Ingeniería de Aragón (I3A), Universidad de Zaragoza, Zaragoza 50018, Spain},
  art_number = {6385879},
  coden = {85RBA},
  correspondence_address1 = {Latif, Y.; Instituto de Investigación en Ingeniería de Aragón (I3A), , Zaragoza 50018, Spain; email: ylatif@unizar.es},
  document_type = {Conference Paper},
  isbn = {9781467317375},
  issn = {21530858},
  keywords = {Loop closing;  Loop closure;  Mapping systems;  Optimization process;  State-of-the-art methods, Experiments;  Intelligent systems;  Robot applications, Algorithms},
  language = {English},
  references = {Konolige, K., Bowman, J., Towards lifelong visual maps (2009) Intelligent Robots and Systems, 2009. IROS 2009. IEEE/RSJ International Conference on, pp. 1156-1163. , IEEE; McDonald, J., Kaess, M., Cadena, C., Neira, J., Leonard, J., 6-DOF multi-session visual SLAM using anchor nodes (2011) European Conference on Mobile Robotics, ECMR; Sibley, G., Mei, C., Reid, I., Newman, P., Vast-scale outdoor navigation using adaptive relative bundle adjustment (2010) The International Journal of Robotics Research, 29 (8), pp. 958-980; Cummins, M., Newman, P., Appearance-only SLAM at large scale with FAB-MAP 2.0 (2010) The International Journal of Robotics Research, , http://ijr.sagepub.com/content/early/2010/11/11/0278364910385483.abstract; Cadena, C., Gálvez-López, D., Tardós, J., Neira, J., Robust place recognition with stereo sequences (2012) IEEE Transaction on RObotics, 28 (4). , to appear; Ranganathan, A., Dellaert, F., Online probabilistic topological mapping (2011) The International Journal of Robotics Research, 30 (6), pp. 755-771. , http://ijr.sagepub.com/content/early/2011/01/23/0278364910393287.abstract, May; Tully, S., Kantor, G., Choset, H., A unified bayesian framework for global localization and slam in hybrid metric/topological maps (2012) The International Journal of Robotics Research, , http://ijr.sagepub.com/content/early/2012/01/16/0278364911433617.abstract; Sünderhauf, N., Protzel, P., Towards a robust back-end for pose graph slam (2012) Proc. IEEE Int. Conf. Robotics and Automation; Latif, Y., Cadena, C., Neira, J., Robust loop closing over time (2012) Proceedings of Robotics: Science and Systems, , Sydney, Australia, July; Kümmerle, R., Grisetti, G., Strasdat, H., Konolige, K., Burgard, W., G2o: A general framework for graph optimization (2011) Proc. of the IEEE Int. Conf. on Robotics and Automation (ICRA), , Shanghai, China, May; Bar-Shalom, Y., Li, X.R., Kirubarajan, T., (2001) Estimation with Applications to Tracking and Navigation, , New York: John Willey and Sons; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) The International Journal of Robotics Research, 28 (5), pp. 595-599. , http://www.robots.ox.ac.uk/NewCollegeData/, May; (2009) Robotics Advancement Through Webpublishing of Sensorial and Elaborated Extensive Data Sets (Project FP6-IST-045144), , http://www.rawseeds.org/rs/datasets; Kaess, M., Ranganathan, A., Dellaert, F., ISAM: Incremental smoothing and mapping (2008) IEEE Trans. on Robotics, TRO, 24 (6), pp. 1365-1378. , Dec; Mei, C., Sibley, G., Cummins, M., Newman, P., Reid, I., RSLAM: A system for large-scale mapping in constant-time using stereo (2011) International Journal of Computer Vision, 94, pp. 198-214. , http://dx.doi.org/10.1007/s11263-010-0361-7, 10.1007/s11263-010-0361-7; Strasdat, H., Davison, A., Montiel, J., Konolige, K., Double window optimisation for constant time visual SLAM (2011) IEEE International Conference on Computer Vision (ICCV)},
  source = {Scopus},
  sponsors = {IEEE Robotics and Automation Society (RAS); IEEE Industrial Electronics Society (IES); Robotics Society of Japan (RSJ); Society of Instrument and Control Engineers (SICE); New Technology Foundation (NTF)},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872329568&doi=10.1109%2fIROS.2012.6385879&partnerID=40&md5=ed60f89bc7db0bd163164b2a28f50d90},
}

@article{latif-et-al:2017:016,
  author = {Y. Latif and G. Huang and J. Leonard and J. Neira},
  journal = {Robotics and Autonomous Systems},
  title = {Sparse optimization for robust and efficient loop closing},
  volume = {93},
  pages = {13--26},
  doi = {10.1016/j.robot.2017.03.016},
  note = {cited By 10},
  publisher = {Elsevier B.V.},
  year = {2017},
  abbrev_source_title = {Rob Autom Syst},
  abstract = {It is essential for a robot to be able to detect revisits or loop closures for long-term visual navigation. A key insight explored in this work is that the loop-closing event inherently occurs sparsely, i.e., the image currently being taken matches with only a small subset (if any) of previous images. Based on this observation, we formulate the problem of loop-closure detection as a sparse, convexℓ1-minimization problem. By leveraging fast convex optimization techniques, we are able to efficiently find loop closures, thus enabling real-time robot navigation. This novel formulation requires no offline dictionary learning, as required by most existing approaches, and thus allows online incremental operation. Our approach ensures a unique hypothesis by choosing only a single globally optimal match when making a loop-closure decision. Furthermore, the proposed formulation enjoys a flexible representation with no restriction imposed on how images should be represented, while requiring only that the representations are “close” to each other when the corresponding images are visually similar. The proposed algorithm is validated extensively using real-world datasets. © 2017 Elsevier B.V.},
  affiliation = {ARC Center for Robotic Vision, University of Adelaide, Adelaide, SA  5005, Australia; Department of Mechanical Engineering, University of Delaware, Newark, DE  19716, United States; Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology, Cambridge, MA  02139, United States; Instituto de Investigación en Ingeniería de Aragón (I3A) Universidad de Zaragoza, Zaragoza, Spain},
  author_keywords = {Place recognition;  Relocalization;  SLAM;  Sparse optimization},
  coden = {RASOE},
  correspondence_address1 = {Latif, Y.; ARC Center for Robotic Vision, Australia; email: yasir.latif@adelaide.edu.au},
  document_type = {Article},
  funding_details = {National Science FoundationNational Science Foundation, NSF, HDTRA 1-16-1-0039, IIS-1318392, IIS-1566129},
  funding_text1 = {This work was partially supported by the MINECO-FEDER project DPI2015-68905-P, by the research grant BES-2010-033116, by the travel grant EEBB-I-13-07010, by the ONR grants N00014-10-1-0936, N00014-11-1-0688 and N00014-13-1-0588, by the NSF awards IIS-1318392 and IIS-1566129, and by the DTRA award HDTRA 1-16-1-0039.},
  issn = {09218890},
  keywords = {Convex optimization, Convex optimization techniques;  Minimization problems;  Off-line dictionaries;  Place recognition;  Re-localization;  Real-world datasets;  SLAM;  Sparse optimizations, Robots},
  language = {English},
  references = {Sugiyama, H., Tsujioka, T., Murata, M., Collaborative movement of rescue robots for reliable and effective networking in disaster area (2005) International Conference on Collaborative Computing: Networking, Applications and Worksharing, , San Jose, CA Dec. 19–21; Capezio, F., Mastrogiovanni, F., Sgorbissa, A., Zaccaria, R., Robot-assisted surveillance in large environments (2009) J. Comput. Inf. Technol., 17 (1), pp. 95-108; Cannell, C.J., Stilwell, D.J., A comparison of two approaches for adaptive sampling of environmental processes using autonomous underwater vehicles MTS/IEEE OCEANS, Washington, DC, Dec. 19–23 2005, pp. 1514–1521; Lowry, S., Sünderhauf, N., Newman, P., Leonard, J.J., Cox, D., Corke, P., Milford, M.J., Visual place recognition: A survey (2016) IEEE Trans. Robot., 32 (1), pp. 1-19; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of appearance (2008) Int. J. Robot. Res., 27 (6), pp. 647-665. , http://ijr.sagepub.com/cgi/reprint/27/6/647.pdf, arXiv; Galvez-Lopez, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Robot., 28 (5), pp. 1188-1197; Latif, Y., Cadena, C., Neira, J., Robust loop closing over time for pose graph SLAM (2013) Int. J. Robot. Res., 32 (14), pp. 1611-1626; Rosten, E., Drummond, T., Fusing points and lines for high performance tracking (2005) IEEE International Conference on Computer Vision, ICCV, vol. 2, Beijing, China, Oct. 17–20, pp. 1508-1515; Calonder, M., Lepetit, V., Strecha, C., Fua, P., BRIEF: Binary robust independent elementary features (2010) European Conference on Computer Vision, ECCV, pp. 778-792. , Springer Crete, Greece, Sept. 5–11; Nister, D., Stewenius, H., Scalable recognition with a vocabulary tree , pp. 2161-2168. , http://dx.doi.org/10.1109/CVPR.2006.264, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, vol. 2, 2006; Sivic, J., Zisserman, A., Video Google: A text retrieval approach to object matching in videos (2003) Proceedings of the International Conference on Computer Vision, pp. 1470-1477. , vol. 2, Oct; Milford, M., Wyeth, G., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) IEEE International Conference on Robotics and Automation, ICRA, St. Paul, MN, May 14–18, pp. 1643-1649; Churchill, W., Newman, P., Experience-based navigation for long-term localisation (2013) Int. J. Robot. Res., 32 (14), pp. 1645-1661; Paul, R., Newman, P., Self-help: Seeking out perplexing images for ever improving topological mapping (2013) Int. J. Robot. Res., 32 (14), pp. 1742-1766; Lee, J.H., Zhang, G., Lim, J., Suh, I.H., Place recognition using straight lines for vision-based SLAM (2013) Robotics and Automation, ICRA, 2013 IEEE International Conference on, IEEE, pp. 3799-3806; Lee, J.H., Lee, S., Zhang, G., Lim, J., Chung, W.K., Suh, I.H., Outdoor place recognition in urban environments using straight lines (2014) 2014 IEEE International Conference on Robotics and Automation, pp. 5550-5557. , ICRA, May; Bengio, Y., Deep learning of representations for unsupervised and transfer learning (2012) Unsupervised Transf. Learn. Chall. Mach. Learn., 7, p. 19; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) Handb. Brain Theory Neural Netw., 3361 (10); Sünderhauf, N., Dayoub, F., Shirazi, S., Upcroft, B., Milford, M., On the performance of convNet features for place recognition (2015) Proc. IEEE/RJS Int. Conference on Intelligent Robots and Systems; Sunderhauf, N., Shirazi, S., Jacobson, A., Dayoub, F., Pepperell, E., Upcroft, B., Milford, M., Place recognition with Convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proceedings of Robotics: Science and Systems XII; Latif, Y., Huang, G., Leonard, J., Neira, J., An online sparsity-cognizant loop-closure algorithm for visual navigation (2014) Proceedings of Robotics: Science and Systems, Berkeley, USA, July; Shakeri, M., Zhang, H., (2015), Online loop-closure detection via dynamic sparse representation, Field and Service Robotics, FSR; Zhang, H., Han, F., Wang, H., Robust multimodal sequence-based loop closure detection via structured sparsity (2016) Proceedings of Robotics: Science and Systems, AnnArbor, Michigan, June, , http://dx.doi.org/10.15607/RSS.2016.XII.043; Elad, M., Figueiredo, M., Ma, Y., On the role of sparse and redundant representations in image processing (2010) Proc. IEEE, 98 (6), pp. 972-982; Elad, M., Aharon, M., Image denoising via sparse and redundant representations over learned dictionaries (2006) IEEE Trans. Image Process., 15 (12), pp. 3736-3745; Cheng, B., Yang, J., Yan, S., Fu, Y., Huang, T., Learning with ℓ1-graph for image analysis (2010) IEEE Trans. Image Process., 19 (4), pp. 858-866; Casafranca, J.J., Paz, L.M., Pinies, P., (2013), ℓ1 Factor Graph SLAM: going beyond the ℓ2 norm, in: Robust and Multimodal Inference in Factor Graphs Workshop, IEEE International Conference on Robots and Automation, ICRA, Karlsruhe, Germany; Casafranca, J.J., Paz, L.M., Pinies, P., (2013), A back-end ℓ1 norm based solution for factor graph SLAM, in: IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS, Tokyo, Japan, November 3–8, pp. 17–23; Donoho, D.L., For most large underdetermined systems of linear equations the minimal 1-norm solution is also the sparsest solution (2006) Comm. Pure Appl. Math., 59 (6), pp. 797-829; Amaldi, E., Kann, V., On the approximability of minimizing nonzero variables or unsatisfied relations in linear systems (1998) Theoret. Comput. Sci., 209 (12), pp. 237-260; Donoho, D.L., Compressed sensing (2006) IEEE Trans. Signal Process., 52 (4), pp. 1289-1306; Bach, F., Jenatton, R., Mairal, J., Obozinski, G., Convex optimization with sparsity-inducing norms (2011) Optim. Mach. Learn., pp. 19-53; Dalal, N., Triggs, B., Histograms of oriented gradients for human detection (2005) IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR, vol. 2, San Diego, CA, pp. 886-893; Oliva, A., Torralba, A., Modeling the shape of the scene: A holistic representation of the spatial envelope (2001) Int. J. Comput. Vis., 42 (3), pp. 145-175; Boyd, S., Vandenberghe, L., Convex Optimization (2004), Cambridge University Press; Malioutov, D.M., Cetin, M., Willsky, A.S., Homotopy continuation for sparse signal representation (2005) IEEE International Conference on Acoustics, Speech, and Signal Processing; Donoho, D.L., Tsaig, Y., (2006) Fast Solution of ℓ1-Minimization Problems when the solution may be sparse, Technical Report, , Dept. of Statistics, Stanford University; Milford, M., Vision-based place recognition: how low can you go? (2013) Int. J. Robot. Res., 32 (7), pp. 766-789; Smith, M., Baldwin, I., Churchill, W., Paul, R., Newman, P., The new college vision and laser data set (2009) Int. J. Robot. Res., 28 (5), pp. 595-599; (2009), RAWSEEDS, Robotics advancement through Webpublishing of sensorial and elaborated extensive data sets (project FP6-IST-045144); Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) Computer Vision and Pattern Recognition, CVPR, 2012, IEEE Conference on, IEEE, pp. 3354-3361; Asif, M., (2008) Primal dual Pursuit: A Homotopy Based Algorithm for the Dantzig Selector, , Dept. of Electrical and Computer Engineering, Georgia Institute of Technology; Everingham, M., VanGool, L., Williams, C.K.I., Winn, J., Zisserman, A., (2012), http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html, The PASCAL Visual Object Classes Challenge 2012, VOC2012, Results; Latif, Y., Cadena, C., Neira, J., Robust graph SLAM back-ends: A comparative analysis (2014) Intelligent Robots and Systems, IROS 2014, 2014 IEEE/RSJ International Conference on, IEEE, pp. 2683-2690; Kumar, B.G.V., Carneiro, G., Reid, I., Learning local image descriptors with deep siamese and triplet convolutional networks by minimising global loss functions (2016) The IEEE Conference on Computer Vision and Pattern Recognition, CVPR, June; Sünderhauf, N., (2015), https://roboticvision.atlassian.net/wiki/pages/viewpage.action?pageId=14188617, Visual Place Recogniton in Challenge Enviornments, VPRiCE Challenge},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019598639&doi=10.1016%2fj.robot.2017.03.016&partnerID=40&md5=42a608af6dad7479faaba36e0f74e344},
}

@inproceedings{song-et-al:2019:8967749,
  author = {Y. Song and D. Zhu and J. Li and Y. Tian and M. Li},
  journal = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Learning Local Feature Descriptor with Motion Attribute For Vision-based Localization},
  pages = {3794--801},
  doi = {10.1109/IROS40897.2019.8967749},
  note = {local feature point;fully convolutional network;MD-Net;motion attribute estimation;feature description;local feature descriptor;vision-based localization algorithm;camera-based localization;open-loop localization;re-localization;loop closure detection;},
  address = {Piscataway, NJ, USA},
  year = {2019},
  abstract = {In recent years, camera-based localization has been widely used for robotic applications, and most proposed algorithms rely on local features extracted from recorded images. For better performance, the features used for open-loop localization are required to be short-term globally static, and the ones used for re-localization or loop closure detection need to be long-term static. Therefore, the motion attribute of a local feature point could be exploited to improve localization performance, e.g., the feature points extracted from moving persons or vehicles can be excluded from these systems due to their unsteadiness. In this paper, we design a fully convolutional network (FCN), named MD-Net, to perform motion attribute estimation and feature description simultaneously. MD-Net has a shared backbone network to extract features from the input image and two network branches to complete each sub-task. With MD-Net, we can obtain the motion attribute while avoiding increasing much more computation. Experimental results demonstrate that the proposed method can learn distinct local feature descriptor along with motion attribute only using an FCN, by outperforming competing methods by a wide margin. We also show that the proposed algorithm can be integrated into a vision-based localization algorithm to improve estimation accuracy significantly.},
  copyright = {Copyright 2020, The Institution of Engineering and Technology},
  keywords = {cameras;convolutional neural nets;feature extraction;learning (artificial intelligence);robot vision;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/IROS40897.2019.8967749},
}

@inproceedings{yue-et-al:2020:9197072,
  author = {Y. Yue and C. Yang and J. Zhang and M. Wen and Z. Wu and H. Zhang and D. Wang},
  journal = {2020 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {Day and Night Collaborative Dynamic Mapping in Unstructured Environment Based on Multimodal Sensors},
  pages = {2981--7},
  doi = {10.1109/ICRA40945.2020.9197072},
  note = {dynamic collaborative mapping;multimodal environmental perception;heterogeneous sensor fusion model;local 3D maps;night rainforest;3D map fusion missions;multimodal sensors;long-term operation;collaborative robots;dynamic environment;dynamic objects;},
  address = {Piscataway, NJ, USA},
  year = {2020},
  abstract = {Enabling long-term operation during day and night for collaborative robots requires a comprehensive understanding of the unstructured environment. Besides, in the dynamic environment, robots must be able to recognize dynamic objects and collaboratively build a global map. This paper proposes a novel approach for dynamic collaborative mapping based on multimodal environmental perception. For each mission, robots first apply heterogeneous sensor fusion model to detect humans and separate them to acquire static observations. Then, the collaborative mapping is performed to estimate the relative position between robots and local 3D maps are integrated into a globally consistent 3D map. The experiment is conducted in the day and night rainforest with moving people. The results show the accuracy, robustness, and versatility in 3D map fusion missions.},
  copyright = {Copyright 2020, The Institution of Engineering and Technology},
  keywords = {groupware;image fusion;mobile robots;multi-robot systems;path planning;sensor fusion;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/ICRA40945.2020.9197072},
}

@article{chen-et-al:2018:2859916,
  author = {Z. Chen and L. Liu and I. Sa and Z. Ge and M. Chli},
  journal = {IEEE Robotics and Automation Letters},
  title = {Learning Context Flexible Attention Model for Long-Term Visual Place Recognition},
  volume = {3},
  number = {4},
  pages = {4015--4022},
  doi = {10.1109/LRA.2018.2859916},
  note = {cited By 44},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2018},
  abbrev_source_title = {IEEE Robot. Autom.},
  abstract = {Identifying regions of interest in an image has long been of great importance in a wide range of tasks, including place recognition. In this letter, we propose a novel attention mechanism with flexible context, which can be incorporated into existing feedforward network architecture to learn image representations for long-term place recognition. In particular, in order to focus on regions that contribute positively to place recognition, we introduce a multiscale context-flexible network to estimate the importance of each spatial region in the feature map. Our model is trained end-to-end for place recognition and can detect regions of interest of arbitrary shape. Extensive experiments have been conducted to verify the effectiveness of our approach and the results demonstrate that our model can achieve consistently better performance than the state of the art on standard benchmark datasets. Finally, we visualize the learned attention maps to generate insights into what attention the network has learned. © 2016 IEEE.},
  affiliation = {Vision for Robotics Lab, ETH Zurich, Zurich, 8092, Switzerland; School of Computer Science, University of Adelaide, Adelaide, SA  5005, Australia; Autonomous Systems Lab, ETH Zurich, Zurich, 8092, Switzerland; EResearch Centre, University of Monash, Melbourne, VIC  3800, Australia},
  art_number = {8421024},
  author_keywords = {deep learning in robotics and automation;  Localization;  visual-based navigation},
  correspondence_address1 = {Chen, Z.; Vision for Robotics Lab, Switzerland; email: chenze@ethz.ch},
  document_type = {Article},
  funding_details = {Horizon 2020 Framework ProgrammeHorizon 2020 Framework Programme, H2020, 644227},
  issn = {23773766},
  keywords = {Benchmarking;  Network architecture;  Robots, Attention mechanisms;  Benchmark datasets;  Feed-forward network;  Flexible networks;  Image representations;  Localization;  Place recognition;  Regions of interest, Deep learning},
  language = {English},
  references = {Cummins, M., Newman, P., Highly scalable appearance-only SLAM-FAB-MAP 2.0 (2009) Proc. Robot., Sci. Syst, , Seattle, WA, USA; Arandjelovic, R., Gronat, P., Torii, A., Pajdla, T., Sivic, J., NetVLAD: CNN architecture for weakly supervised place recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 5297-5307; Chen, Z., Deep learning features at scale for visual place recognition (2017) Proc. Int. Conf. Robot. Automat, pp. 3223-3230; Wang, F., Residual attention network for image classification (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3156-3164; Wang, P., Liu, L., Shen, C., Huang, Z., Van Den Hengel, A., Shen, H.T., Multi-Attention network for one shot learning (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 6212-6220; Chen, L.-C., Yang, Y., Wang, J., Xu, W., Yuille, A.L., Attention to scale: Scale-Aware semantic image segmentation (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3640-3649; Kim, H.J., Dunn, E., Frahm, J.-M., Learned contextual feature reweighting for image geo-localization (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3251-3260; Sunderhauf, N., Place recognition with ConvNet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Proc. Robot.: Sci. Syst; Chen, Z., Maffra, F., Sa, I., Chli, M., Only look once, mining distinctive landmarks from convnet for visual place recognition (2017) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst, pp. 9-16; Mousavian, A., Kosecka, J., Lien, J.-M., Semantically guided location recognition for outdoors scenes (2015) Proc. IEEE Int. Conf. Robot. Automat, pp. 4882-4889; Chu, X., Yang, W., Ouyang, W., Ma, C., Yuille, A.L., Wang, X., Multicontext attention for human pose estimation (2017) Proc.Comput. Vis. Pattern Recognit, pp. 5669-5678; Liu, L., Shen, C., Van Den Hengel, A., The treasure beneath convolutional layers: Cross-convolutional-layer pooling for image classification (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4749-4757; Milford, M., Wyeth, G., SeqSLAM: Visual route-based navigation for sunny summer days and stormy winter nights (2012) Proc. IEEE Int. Conf. Robot. Automat., St Paul, MN, USA, pp. 1643-1649; Cummins, M., Newman, P., Appearance-only SLAMat large scale with FAB-MAP 2.0 (2011) Int. J. Robot. Res, 30, pp. 1100-1123. , Aug; Lowry, S., Andreasson, H., Lightweight, viewpoint-invariant visual place recognition in changing environments (2018) IEEE Robot. Autom. Lett, 3 (2), pp. 957-964. , Apr; McManus, C., Upcroft, B., Newmann, P., Scene signatures: Localised and point-less features for localisation (2014) Proc. Robot., Sci. Syst; Naseer, T., Spinello, L., Burgard, W., Stachniss, C., Robust visual robot localization across seasons using network flows (2014) Proc. Nat. Conf. Artif. Intell, pp. 2564-2570; Chen, Z., Obadiah, L., Jacobson, A., Milford, M., Convolutional neural network based place recognition (2014) Australasian Conference on Robotics and Automation, Melbourne, VIC, Australia; Sunderhauf, N., Dayoub, F., Shirazi, S., Upcroft, B., Milford, M., On the performance of ConvNet features for place recognition (2015) IEEE/RSJ International Conference on Intelligent Robots and Systems, Hamburg, Germany; Kendall, A., Grimes, M., Cipolla, R., Posenet: A convolutional network for real-Time 6-dof camera relocalization (2015) Proc. IEEE Int. Conf. Comput. Vis, pp. 2938-2946; Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A., Places: A 10 million image database for scene recognition (2018) IEEE Trans. Pattern Anal. Mach. Intell, 40 (6), pp. 1452-1464. , Jun; Choi, J., Chang, H.J., Jeong, J., Demiris, Y., Choi, J.Y., Visual tracking using attention-modulated disintegration and integration (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4321-4330; Fang, H., From captions to visual concepts and back (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1473-1482; Chen, X., Lawrence Zitnick, C., Mind's eye: A recurrent visual representation for image caption generation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 2422-2431; Siagian, C., Itti, L., Biologically inspired mobile robot vision localization (2009) IEEE Trans. Robot, 25 (4), pp. 861-873. , Aug; Chen, L., Zhang, H., Xiao, J., Nie, L., Shao, J., Chua, T.-S., SCA-CNN: Spatial and channel-wise attention in convolutional networks for image captioning (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 6298-6306; Arbelaez, P., Maire, M., Fowlkes, C., Malik, J., Contour detection and hierarchical image segmentation (2011) IEEE Trans. Pattern Anal. Mach. Intell, 33 (5), pp. 898-916. , May; Gidaris, S., Komodakis, N., Object detection via a multi-region and semantic segmentation-Aware cnn model (2015) Proc. IEEE Int. Conf. Comput. Vis, pp. 1134-1142; Girshick, R., Iandola, F., Darrell, T., Malik, J., Deformable part models are convolutional neural networks (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 437-446; Yu, D., Fu, J., Mei, T., Rui, Y., Multi-level attention networks for visual question answering (2017) Proc. Comput. Vis. Pattern Recognit, pp. 4187-4195; Glover, A.J., Maddern, W.P., Milford, M.J., Wyeth, G.F., FAB-MAP+ RatSLAM: Appearance-based SLAM for multiple times of day (2010) Proc. Int. Conf. Robot. Automat, pp. 3507-3512. , Anchorage, AK, USA; Neubert, P., Sunderhauf, N., Protzel, P., Superpixel-based appearance change prediction for long-Term navigation across seasons (2015) Robot. Auton. Syst, 69, pp. 15-27; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2015) Int. Conf. Learn. Representations; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 770-778; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1-9; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, , Lake Tahoe, NV, USA; Noh, H., Araujo, A., Sim, J., Weyand, T., Han, B., Large-scale image retrieval with attentive deep local features (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3456-3465; Liu, L., Shen, C., Van Den Hengel, A., Cross-convolutional-layer pooling for image recognition (2017) IEEE Trans. Pattern Anal. Mach. Intell, 39 (11), pp. 2305-2313. , Nov; Bay, H., Ess, A., Tuytelaars, T., Van Gool, L., Speeded-up robust features (SURF) (2008) Comput. Vis. Image Understanding, 110, pp. 346-359},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060562544&doi=10.1109%2fLRA.2018.2859916&partnerID=40&md5=a6b78ef6a8cc54753d01a85b58c07b54},
}

@article{hong-et-al:2022:02783649221080483,
  author = {Z. Hong and Y. Petillot and A. Wallace and S. Wang},
  journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
  title = {RadarSLAM: A robust simultaneous localization and mapping system for all
weather conditions},
  doi = {10.1177/02783649221080483},
  publisher = {SAGE PUBLICATIONS LTD},
  address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
  year = {2022},
  abstract = {A Simultaneous Localization and Mapping (SLAM) system must be robust to
support long-term mobile vehicle and robot applications. However, camera
and LiDAR based SLAM systems can be fragile when facing challenging
illumination or weather conditions which degrade the utility of imagery
and point cloud data. Radar, whose operating electromagnetic spectrum is
less affected by environmental changes, is promising although its
distinct sensor model and noise characteristics bring open challenges
when being exploited for SLAM. This paper studies the use of a Frequency
Modulated Continuous Wave radar for SLAM in large-scale outdoor
environments. We propose a full radar SLAM system, including a novel
radar motion estimation algorithm that leverages radar geometry for
reliable feature tracking. It also optimally compensates motion
distortion and estimates pose by joint optimization. Its loop closure
component is designed to be simple yet efficient for radar imagery by
capturing and exploiting structural information of the surrounding
environment. Extensive experiments on three public radar datasets,
ranging from city streets and residential areas to countryside and
highways, show competitive accuracy and reliability performance of the
proposed radar SLAM system compared to the state-of-the-art LiDAR,
vision and radar methods. The results show that our system is
technically viable in achieving reliable SLAM in extreme weather
conditions on the RADIATE Dataset, for example, heavy snow and dense
fog, demonstrating the promising potential of using radar for
all-weather localization and mapping.},
  affiliation = {Wang, S (Corresponding Author), Heriot Watt Univ, Sch Engn \& Phys Sci, Inst Sensors Signals \& Syst, Edinburgh EH14 4AS, Midlothian, Scotland.
Hong, Ziyang; Petillot, Yvan; Wallace, Andrew; Wang, Sen, Heriot Watt Univ, Edinburgh Ctr Robot, Edinburgh, Midlothian, Scotland.},
  affiliations = {Heriot Watt University},
  article-number = {02783649221080483},
  author-email = {s.wang@hw.ac.uk},
  cited-references = {Aldera R, 2019, IEEE INT C INTELL TR, P2835, DOI 10.1109/ITSC.2019.8917111.
Aldera R, 2019, IEEE INT CONF ROBOT, P1190, DOI 10.1109/ICRA.2019.8794014.
Aldibaja M, 2016, IEEE/SICE I S SYS IN, P212, DOI 10.1109/SII.2016.7844000.
Almalioglu Y, 2021, IEEE SENS J, V21, P3314, DOI 10.1109/JSEN.2020.3023243.
Bailo O, 2018, PATTERN RECOGN LETT, V106, P53, DOI 10.1016/j.patrec.2018.02.020.
Barnes D., 2020, C ROB LEARN, P303.
Barnes D, 2020, IEEE INT CONF ROBOT, P6433, DOI 10.1109/ICRA40945.2020.9196884.
Barnes D, 2020, IEEE INT CONF ROBOT, P9484, DOI 10.1109/ICRA40945.2020.9196835.
Behley J, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
Burnett K, 2021, IEEE ROBOT AUTOM LET, V6, P771, DOI 10.1109/LRA.2021.3052439.
Campos C., 2020, ORB SLAM3 ACCURATE O.
Carballo A., 2020, ARXIV PREPRINT ARXIV.
Cen SH, 2019, IEEE INT CONF ROBOT, P298, DOI 10.1109/ICRA.2019.8793990.
Cen SH, 2018, IEEE INT CONF ROBOT, P6045, DOI 10.1109/ICRA.2018.8460687.
CHALLIS JH, 1995, J BIOMECH, V28, P733, DOI 10.1016/0021-9290(94)00116-L.
Chandran M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P808, DOI 10.1109/IROS.2006.281673.
Charron N, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P254, DOI 10.1109/CRV.2018.00043.
Checchin P, 2010, SPRINGER TRAC ADV RO, V62, P151.
Clark S, 1998, IEEE INT CONF ROBOT, P3697, DOI 10.1109/ROBOT.1998.681411.
De Martini D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216002.
Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
Gadd Matthew, 2020, 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), P270, DOI 10.1109/PLANS46316.2020.9109951.
Gadd M., 2021, ARXIV PREPRINT ARXIV.
Garg K, 2004, PROC CVPR IEEE, P528.
He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
Himstedt M, 2014, IEEE INT C INT ROBOT, P5030, DOI 10.1109/IROS.2014.6943277.
Holder M, 2019, IEEE INT VEH SYM, P1145, DOI 10.1109/IVS.2019.8813841.
Hong ZY, 2020, IEEE INT C INT ROBOT, P5164, DOI 10.1109/IROS45743.2020.9341287.
Howard A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3946, DOI 10.1109/IROS.2008.4651147.
Huang HY, 2019, IEEE INT C INTELL TR, P1290, DOI 10.1109/ITSC.2019.8916977.
Jokela M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112341.
Jose E., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3087, DOI 10.1109/IROS.2005.1545232.
Kim G, 2020, IEEE INT CONF ROBOT, P6246.
Konc J, 2007, MATCH-COMMUN MATH CO, V58, P569.
Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299.
Lucas BD, 1981, ITERATIVE IMAGE REGI.
Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
Marck JW, 2013, EUROP RADAR CONF, P471.
Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
Ort T, 2020, IEEE ROBOT AUTOM LET, V5, P3267, DOI 10.1109/LRA.2020.2976310.
Park YS, 2020, IEEE INT CONF ROBOT, P2617, DOI 10.1109/ICRA40945.2020.9197231.
Park YS, 2019, IEEE INT C INT ROBOT, P1307, DOI 10.1109/IROS40897.2019.8967633.
Porav H, 2019, IEEE INT CONF ROBOT, P7087, DOI 10.1109/ICRA.2019.8793486.
Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
Ren WH, 2017, PROC CVPR IEEE, P2838, DOI 10.1109/CVPR.2017.303.
Rouveure R., 2009, INT RAD C SURV SAF W, P1.
Saftescu S, 2020, IEEE INT CONF ROBOT, P4358, DOI 10.1109/ICRA40945.2020.9196682.
Schubert D, 2018, LECT NOTES COMPUT SC, V11212, P699, DOI 10.1007/978-3-030-01237-3\_42.
Schuster F, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2559, DOI 10.1109/ITSC.2016.7795967.
Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
Sheeny M., 2021, IEEE INT C ROB AUT I.
Sola J., 2018, ABS181201537 CORR.
Tang TY, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
Tang TYQ, 2020, IEEE ROBOT AUTOM LET, V5, P1087, DOI 10.1109/LRA.2020.2965907.
Vivet D, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56636.
Vivet D, 2012, IEEE INT CONF ROBOT, P2618, DOI 10.1109/ICRA.2012.6224573.
Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2\_11.
Yamada M, 2019, IEEE INT C INTELL TR, P293, DOI 10.1109/ITSC.2019.8917241.
Yoneda K, 2018, IEEE INT VEH SYM, P971, DOI 10.1109/IVS.2018.8500378.
Zhang C, 2018, IEEE INT C INT ROBOT, P3409, DOI 10.1109/IROS.2018.8593703.
Zhang J., 2014, ROBOT SCI SYST, V2, P9.
Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941.},
  da = {2022-05-17},
  doc-delivery-number = {0U4LQ},
  earlyaccessdate = {APR 2022},
  eissn = {1741-3176},
  funding-acknowledgement = {EPSRC Robotics and Artificial Intelligence ORCA Hub {[}EP/R026173/1]; EU
H2020 Programme under EUMarineRobots project {[}ID 731103]},
  funding-text = {The author(s) disclosed receipt of the following financial support for
the research, authorship, and/or publication of this article: This work
was supported by EPSRC Robotics and Artificial Intelligence ORCA Hub
(grant No. EP/R026173/1) and EU H2020 Programme under EUMarineRobots
project (grant ID 731103).},
  issn = {0278-3649},
  journal-iso = {Int. J. Robot. Res.},
  keywords = {radar sensing; simultaneous localization and mapping; all-weather
perception},
  keywords-plus = {SLAM; VERSATILE},
  language = {English},
  number-of-cited-references = {66},
  oa = {hybrid},
  research-areas = {Robotics},
  times-cited = {0},
  type = {Article; Early Access},
  unique-id = {WOS:000787623300001},
  usage-count-last-180-days = {1},
  usage-count-since-2013 = {1},
  web-of-science-categories = {Robotics},
  web-of-science-index = {Science Citation Index Expanded (SCI-EXPANDED)},
}

@article{pan-et-al:2019:s19194252,
  author = {Z. Pan and H. Chen and S. Li and Y. Liu},
  journal = {Sensors (Switzerland)},
  title = {Clustermap building and relocalization in urban environments for unmanned vehicles},
  volume = {19},
  number = {19},
  pages = {4252},
  doi = {10.3390/s19194252},
  note = {cited By 3},
  publisher = {MDPI AG},
  year = {2019},
  abbrev_source_title = {Sensors},
  abstract = {Map building and map-based relocalization techniques are important for unmanned vehicles operating in urban environments. The existing approaches require expensive high-density laser range finders and suffer from relocalization problems in long-term applications. This study proposes a novel map format called the ClusterMap, on the basis of which an approach to achieving relocalization is developed. The ClusterMap is generated by segmenting the perceived point clouds into different point clusters and filtering out clusters belonging to dynamic objects. A location descriptor associated with each cluster is designed for differentiation. The relocalization in the global map is achieved by matching cluster descriptors between local and global maps. The solution does not require high-density point clouds and high-precision segmentation algorithms. In addition, it prevents the effects of environmental changes on illumination intensity, object appearance, and observation direction. A consistent ClusterMap without any scale problem is built by utilizing a 3D visual–LIDAR simultaneous localization and mapping solution by fusing LIDAR and visual information. Experiments on the KITTI dataset and our mobile vehicle illustrates the effectiveness of the proposed approach. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
  affiliation = {School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, 518055, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong; Shenzhen University Town, Building G1011, Nanshan, Shenzhen, 518055, China; Chinese University of Hong Kong, Room 208, William M.W. Mong Engineering Building, Shatin, Hong Kong},
  art_number = {4252},
  author_keywords = {ClusterMap;  LIDAR-based Map Building;  Localization;  Map Descriptor;  Relocalization;  SLAM},
  correspondence_address1 = {Chen, H.; School of Mechanical Engineering and Automation, China; email: hychen5@hit.edu.cn},
  document_type = {Article},
  funding_details = {20170505160946600},
  funding_text1 = {Funding: This work was partially supported by grants from the National Natural Science Foundation of China (Reference No. 61673131, U1713206 and U1613218) and the Bureau of Industry and Information Technology of Shenzhen (Reference No. 20170505160946600).},
  issn = {14248220},
  keywords = {Image segmentation;  Optical radar;  Range finders;  Robotics;  Urban planning, ClusterMap;  Descriptors;  Localization;  Map Building;  Re-localization;  SLAM, Unmanned vehicles},
  language = {English},
  pubmed_id = {31574973},
  references = {Cadena, C., Carlone, L., Carrillo, H., Latif, Y., Scaramuzza, D., Neira, J., Reid, I.D., Leonard, J.J., Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age (2016) IEEE Trans. Robot., 32, pp. 1309-1332; Zhang, J., Singh, S., Laser–visual–inertial odometry and mapping with high robustness and low drift (2018) J. Field Robot., 35, pp. 1242-1264; Wang, H., Guo, D., Liang, X., Chen, W., Hu, G., Leang, K.K., Adaptive vision-based leader-follower formation control of mobile robots (2017) IEEE Trans. Ind. Electron., 64, pp. 2893-2902; Lin, L.S., Yang, Y.J., Cheng, H., Chen, X.C., Autonomous Vision-Based Aerial Grasping for Rotorcraft Unmanned Aerial Vehicles (2019) Sensors, 19, p. 3410; Schauwecker, K., Zell, A., Robust and efficient volumetric occupancy mapping with an application to stereo vision (2014) Proceedings of the IEEE International Conference on Robotics and Automation, pp. 6102-6107. , Hong Kong, China; Bogoslavskyi, I., Stachniss, C., Efficient online segmentation for sparse 3d laser scans (2017) Photogramm. Remote Sens. Geoinf. Sci., 85, pp. 41-52; Lynen, S., Achtelik, M.W., Weiss, S., Chli, M., Siegwart, R., A robust and modular multisensor fusion approach applied to mav navigation (2013) In Proceedings of the Intelligent Robots and Systems (IROS), Tokyo, Japan, 3–7 November, pp. 3923-3929; Wan, G., Yang, X., Cai, R., Li, H., Wang, H., Song, S., (2017) Robust and Precise Vehicle Localization Based on Multi-Sensor Fusion in Diverse City Scenes; Mur-Artal, R., Montiel, J.M.M., Tardos, J.D., ORB-SLAM: A versatile and accurate monocular SLAM system (2015) IEEE Trans. Robot., 31, pp. 1147-1163; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Large-scale direct monocular SLAM (2014) Proceedings of the European Conference on Computer Vision, pp. 834-849. , Zurich, Switzerland, 6–12 September; Engel, J., Koltun, V., Cremers, D., Direct Sparse Odometry (2018) IEEE Trans. Pattern Anal. Mach. Intell., 40, pp. 611-625; Mur-Artal, R., Tardós, J.D., Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras (2017) IEEE Trans. Robot., 33, pp. 1255-1262; Grisetti, G., Stachniss, C., Burgard, W., Improved techniques for grid mapping with rao-blackwellized particle filters (2007) IEEE Trans. Robot., 23, pp. 34-46; Hess, W., Kohler, D., Rapp, H., Andor, D., Real-time loop closure in 2D LIDAR SLAM (2016) Proceedings of the Robotics and Automation (ICRA), pp. 1271-1278. , Stockholm, Sweden, 16–21 May; Zhang, J., Singh, S., Low-drift and real-time lidar odometry and mapping (2017) Auton. Robot., 41, pp. 401-416; Pfrunder, A., Borges, P.V., Romero, A.R., Catt, G., Elfes, A., Real-time autonomous ground vehicle navigation in heterogeneous environments using a 3D LiDAR (2017) In Proceedings of the Intelligent Robots and Systems (IROS), pp. 2601-2608. , Vancouver, BC, Canada, 24–28 September; Opromolla, R., Fasano, G., Rufino, G., Grassi, M., Savvaris, A., LIDAR-inertial integration for UAV localization and mapping in complex environments (2016) In Proceedings of the Unmanned Aircraft Systems (ICUAS), pp. 649-656. , Arlington, VA, USA; Brenneke, C., Wulf, O., Wagner, B., Using 3d laser range data for slam in outdoor environments (2003) Proceedings of the Intelligent Robots and Systems, Las Vegas, 1, pp. 188-193. , NV, USA, 27–31 October; Wang, L., Zhang, Y., Wang, J., Map-based localization method for autonomous vehicles using 3D-LIDAR (2017) Ifac-Papersonline, 50, pp. 276-281; Zhang, J., Kaess, M., Singh, S., A real-time method for depth enhanced visual odometry (2017) Auton. Robot., 41, pp. 31-43; Lenac, K., Kitanov, A., Cupec, R., Petrović, I., Fast planar surface 3D SLAM using LIDAR (2017) Robot. Auton. Syst., 92, pp. 197-220; Zhu, Z., Yang, S., Dai, H., Li, F., Loop Detection and Correction of 3D Laser-Based SLAM with Visual Information (2018) Proceedings of the 31St International Conference on Computer Animation and Social Agents, pp. 53-58. , Beijing, China, 21–23 May; Chen, H., Huang, H., Qin, Y., Liu, Y., Vision and Laser Fused SLAM in Indoor Environments with Multi-Robot System (2019) Assem. Autom., 39; Karami, E., Prasad, S., Shehata, M.S., Image Matching Using SIFT, SURF, BRIEF and ORB: Performance Comparison for Distorted Images; Bosse, M., Zlot, R., Place recognition using keypoint voting in large 3D lidar datasets (2013) In Proceedings of the Robotics and Automation (ICRA), pp. 2677-2684. , Karlsruhe, Germany, 6–10 May; Gawel, A., Cieslewski, T., Dubé, R., Bosse, M., Siegwart, R., Nieto, J., Structure-based vision-laser matching (2016) Proceedings of the 2016 IEEE/RSJ International Intelligent Robots and Systems (IROS), pp. 182-188. , Daejeon, Korea; Dubé, R., Dugas, D., Stumm, E., Nieto, J., Siegwart, R., Cadena, C., (2016) Segmatch: Segment Based Loop-Closure for 3D Point Clouds; Dubé, R., Cramariuc, A., Dugas, D., Nieto, J., Siegwart, R., Cadena, C., SegMap: 3D Segment Mapping using Data-Driven Descriptors (2018) Proceedings of the Robotics: Science and Systems (RSS), , Pittsburgh, PA, USA, 26–30 June; Finman, R., Paull, L., Leonard, J.J., Toward object-based place recognition in dense rgb-d maps (2015) Proceedings of the ICRA Workshop Visual Place Recognition in Changing Environments, , Seattle, WA, USA, 26–30 May; Rusu, R.B., Blodow, N., Marton, Z.C., Beetz, M., Aligning point cloud views using persistent feature histograms Proceedings of the Intelligent Robots and Systems, pp. 3384-3391. , Nice, France, 22–2, September 2008; Rusu, R.B., Blodow, N., Beetz, M., (2009) Fast Point Feature Histograms (FPFH) for 3D Registration, pp. 3212-3217. , Proceedings of the Robotics and Automation, Kobe, Japan, May; Scaramuzza, D., Fraundorfer, F., Visual odometry [tutorial] (2011) IEEE Robot. Autom. Mag., 18, pp. 80-92; Dhall, A., Chelani, K., Radhakrishnan, V., Krishna, K.M., LiDAR-Camera Calibration using 3D–3D Point correspondences Arxiv; Geiger, A., Lenz, P., Stiller, C., Urtasun, R., Vision meets Robotics: The KITTI Dataset (2013) Int. J. Robot. Res.},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072847843&doi=10.3390%2fs19194252&partnerID=40&md5=3fed38ddd93130619cc093b9e7f332b8},
}

@conference{wang-et-al:2021:9739599,
  author = {Z. Wang and S. Li and M. Cao and H. Chen and Y. Liu},
  journal = {2021 IEEE International Conference on Robotics and Biomimetics, ROBIO 2021},
  title = {Pole-like Objects Mapping and Long-Term Robot Localization in Dynamic Urban Scenarios},
  pages = {998--1003},
  doi = {10.1109/ROBIO54168.2021.9739599},
  note = {cited By 0; Conference of 2021 IEEE International Conference on Robotics and Biomimetics, ROBIO 2021 ; Conference Date: 27 December 2021 Through 31 December 2021;  Conference Code:178223},
  publisher = {Institute of Electrical and Electronics Engineers Inc.},
  year = {2021},
  abbrev_source_title = {IEEE Int. Conf. Robot. Biomimetics, ROBIO},
  abstract = {Localization on 3D data is a challenging task for unmanned vehicles, especially in long-term dynamic urban scenarios. Due to the generality and long-term stability, the pole-like objects are very suitable as landmarks for unmanned vehicle localization in time-varying scenarios. In this paper, a long-term LiDAR-only localization algorithm based on semantic cluster map is proposed. At first, the Convolutional Neural Network(CNN) is used to infer the semantics of LiDAR point clouds. Combined with the point cloud segmentation, the static objects pole/trunk are extracted and registered into global semantic cluster map. When the unmanned vehicle re-enters the environment again, the relocalization is completed by matching the clusters of current scan with the clusters of the global map. Furthermore, the matching between the local and global maps stably outputs the global pose at 2Hz to correct the drift of the 3D LiDAR odometry. The experimental results on our campus dataset demonstrate that the proposed approach performs better in localization accuracy compared with the current state-of-the-art methods. The source of this paper is available at: http://www.github.com/HITSZ-NRSL/long-term-localization. © 2021 IEEE.},
  affiliation = {Harbin Institute of Technology, School of Mechanical Engineering and Automation, Shenzhen, China; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong},
  correspondence_address1 = {Chen, H.; Harbin Institute of Technology, China; email: hychen5@hit.edu.cn},
  document_type = {Conference Paper},
  funding_details = {JCYJ20180507183456108, JCYJ20180507183837726, JCYJ20200109113412326},
  funding_text1 = {This study was supported in part by the National Natural Science Foundation of China under Grants U1713206, the Shenzhen Science and Innovation Committee under Grants JCYJ20200109113412326, JCYJ20180507183837726, and JCYJ20180507183456108, and the National Key Research and Development Program of China under Grant 2018YFB1309300.},
  isbn = {9781665405355},
  keywords = {Autonomous vehicles;  Intelligent vehicle highway systems;  Neural networks;  Poles;  Robot applications;  Semantics;  Unmanned vehicles, 'current;  3D data;  Cluster maps;  Global map;  Localisation;  Long term dynamics;  Matchings;  Robot localization;  Semantic clusters;  Urban scenarios, Optical radar},
  language = {English},
  references = {Ji, Z., Singh, S., Loam: Lidar odometry and mapping in real-time (2014) Robotics: Science and Systems, 2; Shan, T., Englot, B., Lego-loam: Lightweight and ground-optimized lidar odometry and mapping on variable terrain (2018) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4758-4765; Pomerleau, F., Krüsi, P., Colas, F., Furgale, P., Siegwart, R., Long-term 3d map maintenance in dynamic environments (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 3712-3719; Schaefer, A., Büscher, D., Vertens, J., Luft, L., Burgard, W., Long-term vehicle localization in urban environments based on pole landmarks extracted from 3-d lidar scans (2021) Robotics and Autonomous Systems, 136, p. 103709; Kim, G., Park, B., Kim, A., 1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image (2019) IEEE Robotics and Automation Letters, 4 (2), pp. 1948-1955; Kong, X., Yang, X., Zhai, G., Zhao, X., Zeng, X., Wang, M., Liu, Y., Wen, F., Semantic graph based place recognition for point clouds (2020) 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 8216-8223; Ratz, S., Dymczyk, M., Siegwart, R., Dubé, R., Oneshot global localization: Instant lidar-visual pose estimation (2020) 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 5415-5421; Milioto, A., Vizzo, I., Behley, J., Stachniss, C., RangeNet++: Fast and Accurate LiDAR Semantic Segmentation (2019) IEEE/RSJ Intl. Conf. on Intelligent Robots and Systems (IROS); Bogoslavskyi, I., Stachniss, C., Fast range image-based segmentation of sparse 3d laser scans for online operation (2016) Proc. of The International Conference on Intelligent Robots and Systems (IROS); Shan, T., Englot, B., Meyers, D., Wang, W., Ratti, C., Daniela, R., Lio-sam: Tightly-coupled lidar inertial odometry via smoothing and mapping (2020) IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5135-5142; Rusu, R.B., Cousins, S., 3d is here: Point cloud library (pcl) (2011) Robotics and Automation (ICRA), 2011 IEEE International Conference on, pp. 1-4. , May; Pan, Z., Chen, H., Li, S., Liu, Y., Clustermap building and relocalization in urban environments for unmanned vehicles (2019) Sensors, 19 (19), p. 4252; Gollub, M.G., Dubé, R., Sommer, H., Gilitschenski, I., Siegwart, R., A partitioned approach for efficient graph-based place recognition (2017) Proc. IEEE/RSJ Int. Conf. Intell. Robots Syst. /Workshop Planning, Perception Navigat. Intell. Veh; Derpanis, K.G., Overview of the ransac algorithm (2010) Image Rochester NY, 4 (1), pp. 2-3; Carlevaris-Bianco, N., Ushani, A.K., Eustice, R.M., University of Michigan north campus long-term vision and lidar dataset (2016) The International Journal of Robotics Research, 35 (9), pp. 1023-1035; Behley, J., Garbade, M., Milioto, A., Quenzel, J., Behnke, S., Stachniss, C., Gall, J., Semantickitti: A dataset for semantic scene understanding of lidar sequences (2019) Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 9297-9307},
  source = {Scopus},
  sponsors = {Chiba Institute of Technology; et al.; IEEE Robotics and Automation Society; Nankai University; Shenyang Institute of Automation; Shenzhen Academy of Robotics},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128207203&doi=10.1109%2fROBIO54168.2021.9739599&partnerID=40&md5=a1f4a3dc07c3e38e9fc08e9a53382167},
}

@inproceedings{xin-et-al:2017:8310121,
  author = {Z. Xin and X. Cui and J. Zhang and Y. Yang and Y. Wang},
  journal = {2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA)},
  title = {Visual place recognition with CNNs: from global to partial},
  pages = {6pp.--},
  doi = {10.1109/IPTA.2017.8310121},
  note = {long-term mobile robot autonomy;partial reranking process;potential places;global image representations;partial image representations;recognition precision;pre-trained convolutional neural networks;visual place recognition pipeline;CNN;},
  address = {Piscataway, NJ, USA},
  year = {2017},
  abstract = {Visual place recognition is one of the most challenging problems in computer vision, due to the large diversities that real-world places can represent. Recently, visual place recognition has become a key part of loop closure detection and topological localization in long-term mobile robot autonomy. In this work, we build up a novel visual place recognition pipeline composed of a first filtering stage followed by a partial reranking process. In the filtering stage, image-wise features are utilized to find a small set of potential places. Afterwards, stable region-wise landmarks are extracted for more accurate matching in the partial reranking process. All global and partial image representations are derived from pre-trained Convolutional Neural Networks (CNNs), and the landmarks are extracted by object proposal techniques. Moreover, a new similarity measurement is provided by considering both spatial and scale distribution of landmarks. Compared with current methods only considering scale distribution, the presented similarity measurement can benefit recognition precision and robustness effectively. Experiments with varied viewpoints and environmental conditions demonstrate that the proposed method achieves superior performance against state-of-the-art methods.},
  copyright = {Copyright 2018, The Institution of Engineering and Technology},
  keywords = {computer vision;feature extraction;feedforward neural nets;image matching;image recognition;image representation;learning (artificial intelligence);mobile robots;object detection;object recognition;robot vision;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/IPTA.2017.8310121},
}

@article{xing-et-al:2022:22062,
  author = {Z. Xing and X. Zhu and D. Dong},
  journal = {Journal of Field Robotics},
  title = {DE-SLAM: SLAM for highly dynamic environment},
  doi = {10.1002/rob.22062},
  note = {cited By 0},
  publisher = {John Wiley and Sons Inc},
  year = {2022},
  abbrev_source_title = {J. Field. Rob.},
  abstract = {Simultaneous localization and mapping (SLAM) is crucial for autonomous mobile robots. Most of the current SLAM systems are based on an assumption: the environment is static. However, the real environment is full of dynamic elements, such as pedestrians or vehicles, as well as changes in illumination and appearance over time. In this paper, DE-SLAM, a visual SLAM system that can deal with short-term and long-term dynamic elements at the same time is proposed. A novel dynamic detection and tracking module that utilizes both semantic and metric information is proposed, and the localization accuracy is highly improved by eliminating features falling on the dynamic objects. A unified loop detection, loop check and global optimization module is used to perform loop closure. Experimental results on datasets and real environments show that DE-SLAM outperforms other state-of-the-art SLAM systems in dynamic environments. © 2022 Wiley Periodicals LLC.},
  affiliation = {School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, Shenzhen, China},
  author_keywords = {localization;  SLAM},
  correspondence_address1 = {Zhu, X.; School of Mechanical Engineering and Automation, China; email: zhuxiaorui@hotmail.com},
  document_type = {Article},
  funding_details = {National Natural Science Foundation of ChinaNational Natural Science Foundation of China, NSFC, U1813219},
  funding_text1 = {This study was supported by the National Key R&D Program of China under grant 2018YFB1305500 and the Natural Science Foundation of China under Grant U1813219.},
  issn = {15564959},
  keywords = {Global optimization;  Robotics, 'current;  Autonomous Mobile Robot;  Dynamic elements;  Dynamic environments;  Localisation;  Localisation Systems;  Mapping systems;  Real environments;  Simultaneous localization and mapping;  Visual simultaneous localization and mappings, Semantics},
  language = {English},
  references = {Arroyo, R., Alcantarilla, P.F., Bergasa, L.M., Romera, E., (2016), pp. 965-970. , &,) Openable An open-source toolbox for application in life-long visual localization of autonomous vehicles. In, IEEE International Conference on Intelligent Transportation Systems, Rio de Janeiro, Brazil IEEE; Bescós, B., Fácil, J., Civera, J., Neira, J., Dynslam: Tracking, mapping and inpainting in dynamic scenes (2018) IEEE Robotics and Automation Letters, 3 (4), pp. 4076-4083; Brasch, N., Bozic, A., Lallemand, J., Tombari, F., (2018), pp. 393-400. , &,) Semantic monocular slam for highly dynamic environments. In, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Madrid, Spain IEEE; Burri, M., Nikolic, J., Gohl, P., Schneider, T., Rehder, J., Omari, S., The euroc micro aerial vehicle datasets (2016) The International Journal of Robotics Research, 35 (10), pp. 1157-1163; Chancán, M., Hernandez-Nunez, L., Narendra, A., Barron, A., Milford, M., A hybrid compact neural architecture for visual place recognition (2020) IEEE Robotics and Automation Letters, 5 (2), pp. 993-1000; Chen, Z., Lam, O., Jacobson, A., Milford, M., Convolutional neural network-based place recognition (2014) Proceedings of the 16th Australasian Conference on Robotics and Automation, 2014, pp. 1-8. , &, Chen, C., (Ed.), Australian Robotics and Automation Association Inc; Dai, W., Zhang, Y., Li, P., Fang, Z., Scherer, S., Rgb-d slam in dynamic environments using point correlations (2022) IEEE Transactions on Pattern Analysis and Machine Intelligence, 44 (1), pp. 373-389; Dalal, N., Triggs, B., (2005), pp. 886-893. , &,) Histograms of oriented gradients for human detection. In, IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2005), San Diego, CA, USA IEEE; Filliat, D., (2007), pp. 3921-3926. , A visual bag of words method for interactive qualitative localization and mapping. In, 2007 IEEE International Conference on Robotics and Automation, Rome, Italy IEEE; Gao, P., Zhang, H., (2020), pp. 1070-1076. , &,) Long-term place recognition through worst-case graph matching to integrate landmark appearances and spatial relationships. In, 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France IEEE; Geiger, A., Lenz, P., Urtasun, R., (2012), pp. 3354-3361. , &,) Are we ready for autonomous driving? The kitti vision benchmark suite. In, Conference on Computer Vision and Pattern Recognition (CVPR), Providence, RI, USA. IEEE; Henein, M., Zhang, J., Mahony, R., Ila, V., (2020), pp. 2123-2129. , &,) Dynamic slam The need for speed. In, 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France IEEE; Hou, Y., Zhang, H., Zhou, S., (2015), pp. 2238-2245. , &,) Convolutional neural network-based image representation for visual loop closure detection. In, 2015 IEEE International Conference on Information and Automation, Lijiang, China IEEE; Klein, G., Murray, D., (2007), pp. 225-234. , &,) Parallel tracking and mapping for small ar workspaces. In 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality (, ISMAR), Nara, Japan, IEEE; Lianos, K.N., Schnberger, J.L., Pollefeys, M., Sattler, T., Ferrari, V., Hebert, M., Sminchisescu, C., Weiss, Y., (2018) Vso: Visual semantic odometry, pp. 246-263. , &, &, (Eds.) 2018, European Conference on Computer Vision (ECCV), Munich, Germany, Springer International Publishing; Merrill, N., Huang, G., (2018), &,) Lightweight unsupervised deep loop closure. In Proceedings of, Robotics Science and Systems 2018, Pittsburgh, Pennsylvania, USA; Milford, M.J., Wyeth, G.F., Seqslam: Visual route-based navigation for sunny summer days and stormy winter nights (2012) 2012 IEEE International Conference on Robotics and Automation (ICRA), pp. 1643-1649. , &, Saint Paul; Mur-Artal, R., Tardos, J., Orb-slam2: An open-source slam system for monocular, stereo and rgb-d cameras (2017) IEEE Transactions on Robotics, 33 (5), pp. 1255-1262; Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.C., (2018), pp. 4510-4520. , &,) Mobilenetv2 Inverted residuals and linear bottlenecks. In, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA. IEEE; Stenborg, E., Toft, C., Hammarstrand, L., Long-term visual localization using semantically segmented images (2018) 2018 IEEE International Conference on Robotics and Automation (ICRA), pp. 6484-6490. , &, Brisbane, QLD, Australia IEEE; Sun, Y., Liu, M., Meng, M., Improving rgb-d slam in dynamic environments: A motion removal approach (2017) Robotics and Autonomous Systems, 89. , &, 1; Tan, W., Liu, H., Dong, Z., Zhang, G., Bao, H., (2013), &,) Robust monocular slam in dynamic environments. In, IEEE International Symposium on Mixed and Augmented Reality; Tzoumas, V., Antonante, P., Carlone, L., (2019), pp. 5383-5390. , &,) Outlier-robust spatial perception Hardness, general-purpose algorithmsguarantees. In, 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Macau, China IEEE; Wang, Y., Huang, S., (2014), pp. 1841-1846. , &,) Towards dense moving object segmentation based robust dense RGB-D SLAM in dynamic scenarios. In, 2014 13th International Conference on Control Automation Robotics Vision (ICARCV), Singapore IEEE; Yang, H., Antonante, P., Tzoumas, V., Carlone, L., Graduated non-convexity for robust spatial perception: From non-minimal solvers to global outlier rejection (2020) IEEE Robotics and Automation Letters, 5 (2), pp. 1127-1134; Yu, C., Liu, Z., Liu, X., Xie, F., Yang, Y., Wei, Q., (2018), p. 1168. , Ds-slam A semantic visual slam towards dynamic environments. In, 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems; Zhang, T., Zhang, H., Li, Y., Nakamura, Y., Zhang, L., (2020), pp. 7322-7328. , &,) Flowfusion Dynamic dense rgb-d slam based on optical flow. In, 2020 IEEE International Conference on Robotics and Automation (ICRA), Paris, France IEEE; Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A., (2018), 40 (6), pp. 1452-1464. , &,) Places A 10 million image database for scene recognition., IEEE Transactions on Pattern Analysis and Machine Intelligence},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124594693&doi=10.1002%2frob.22062&partnerID=40&md5=822d8ca8ca362491b59dc80ae35d924d},
}

@article{yang-et-al:2021:12054,
  author = {Z. Yang and Y. Pan and L. Deng and Y. Xie and R. Huan},
  journal = {IET Intelligent Transport Systems},
  title = {PLSAV: Parallel loop searching and verifying for loop closure detection},
  volume = {15},
  number = {5},
  pages = {683--698},
  doi = {10.1049/itr2.12054},
  note = {cited By 0},
  publisher = {Institution of Engineering and Technology},
  year = {2021},
  abbrev_source_title = {IET Intel. Transport Syst.},
  abstract = {Visual simultaneous localization and mapping (vSLAM), one of the most important applications in autonomous vehicles and robots to estimate the position and pose using inexpensive visual sensors, suffers from error accumulation for long-term navigation without loop closure detection. Recently, deep neural networks (DNNs) are leveraged to achieve high accuracy for loop closure detection, however the execution time is much slower than those employing handcrafted visual features. In this paper, a parallel loop searching and verifying method for loop closure detection with both high accuracy and high speed, which combines two parallel tasks using handcrafted and DNN features, respectively, is proposed. A fast loop searching is proposed to link the bag-of-words features and histogram for higher accuracy, and it splits the images into multiple grids for high parallelism; meanwhile, a DNN feature extractor is utilized for further verification. A loop state control method based on a finite state machine to control these tasks is designed, wherein the loop closure detection is described as a context-related procedure. The framework is implemented on a real machine, and the top-2 best accuracy and fastest execution time of 80-543 frames per second (min: 1.84ms, and max: 12.45ms) are achieved on several public benchmarks compared with some existing algorithms. © 2021 The Authors. IET Intelligent Transport Systems published by John Wiley & Sons Ltd on behalf of The Institution of Engineering and Technology},
  affiliation = {College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA, United States; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China},
  correspondence_address1 = {Pan, Y.; College of Information Science and Electronic Engineering, China; email: panyun@zju.edu.cn},
  document_type = {Article},
  funding_details = {Key Technology Research and Development Program of ShandongKey Technology Research and Development Program of Shandong, 2021C03027},
  funding_text1 = {The authors would like to thank the anonymous referees for their valuable comments and helpful suggestions. This work was supported in part by the International Cooperation Research for Doctoral Students in Zhejiang University, the Zhejiang Provincial Natural Science Foundation of China (Grant No. LY19F020032), and the Zhejiang Provincial Key Research and Development Program of China (Grant No. 2021C03027).},
  issn = {1751956X},
  keywords = {Deep neural networks;  Robots;  Visual servoing, Error accumulation;  Feature extractor;  Frames per seconds;  Parallel loops;  Parallel task;  Visual feature;  Visual sensor;  Visual simultaneous localization and mappings, Feature extraction},
  language = {English},
  references = {Liu, K., Visual place recognition via robust L2-norm distance based holism and landmark integration (2019) AAAI, 33 (1), pp. 8034-8041; Mur-Artal, R., ORB-SLAM2: An open-source SLAM system for monocular, stereo, and RGB-D cameras (2017) IEEE Trans. Rob, 33 (5), pp. 1255-1262; Newman, P., Cole, D., Ho, K., Outdoor SLAM using visual appearance and laser ranging (2006) Proceedings 2006 IEEE International Conference on Robotics and Automation, pp. 1180-1187; Mirowski, P., SignalSLAM: Simultaneous localization and mapping with mixed WiFi, Bluetooth, LTE and magnetic signals (2013) International Conference on Indoor Positioning and Indoor Navigation, pp. 1-10; Muresan, M.P., Nedevschi, S., Multi-object tracking of 3D cuboids using aggregated features (2019) 2019 IEEE 15th International Conference on Intelligent Computer Communication and Processing (ICCP), pp. 11-18; Xu, Y., (2020) How to train your deep multi-object tracker; Pang, J., (2020) Quasi-dense similarity learning for multiple object tracking; Yu, C., DS-SLAM: A semantic visual SLAM towards dynamic environments (2018) 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1168-1174; Li, L., Dense 3D Semantic SLAM of traffic environment based on stereo vision (2018) 2018 IEEE Intelligent Vehicles Symposium (IV), pp. 965-970; Galvez-López, D., Tardos, J.D., Bags of binary words for fast place recognition in image sequences (2012) IEEE Trans. Rob., 28 (6), pp. 1188-1197; Engel, J., Schöps, T., Cremers, D., LSD-SLAM: Large-scale direct monocular SLAM (2014) Computer Vision–ECCV 2014, pp. 834-849. , Springer; Williams, B., A comparison of loop closing techniques in monocular SLAM (2009) Rob. Auton. Syst, 57 (12), pp. 1188-1197; Angeli, A., Fast and incremental method for loop-closure detection using bags of visual words (2008) IEEE Trans. Rob, 24 (5), pp. 1027-1037; Cummins, M., Newman, P., FAB-MAP: Probabilistic localization and mapping in the space of Appearance (2008) Int. J. Robot Res., 27 (6), pp. 647-665; Mur-Artal, R., Tardós, J.D., Fast relocalisation and loop closing in keyframe-based SLAM (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 846-853. , p., IEEE; Kejriwal, N., Kumar, S., Shibata, T., High performance loop closure detection using bag of word pairs (2016) Robot Auton. Syst., 77, pp. 55-65; Yang, Z., Gridding place recognition for fast loop closure detection on mobile platforms (2019) Electron. Lett, 55 (17), pp. 931-933; Klein, G., Murray, D., Parallel tracking and mapping for small AR workspaces (2007) 2007 6th IEEE and ACM International Symposium on Mixed and Augmented Reality, pp. 225-234; Fan, H., Ling, H., Parallel tracking and verifying: A framework for real-time and high accuracy visual tracking (2017) 2017 IEEE International Conference on Computer Vision (ICCV), pp. 5487-5495. , p., IEEE, Venice; Rublee, E., ORB: An efficient alternative to SIFT or SURF (2011) 2011 International Conference on Computer Vision, pp. 2564-2571. , IEEE; Zhang, H., BoRF: Loop-closure detection with scale invariant visual features (2011) 2011 IEEE International Conference on Robotics and Automation, pp. 3125-3130. , IEEE, Shanghai; Shahbazi, H., Zhang, H., Application of locality sensitive hashing to realtime loop closure detection (2011) 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 1228-1233. , San Francisco; Yin, J., Li, D., He, G., Mobile robot loop closure detection using endpoint and line feature visual dictionary (2017) 2017 2nd International Conference on Robotics and Automation Engineering (ICRAE), pp. 73-78; Garcia-Fidalgo, E., Ortiz, A., Hierarchical place recognition for topological mapping (2017) IEEE Trans. Rob., 33 (5), pp. 1061-1074; Milford, M., Condition-invariant, top-down visual place recognition (2014) 2014 IEEE International Conference on Robotics and Automation (ICRA), pp. 5571-5577. , IEEE, Hong Kong; Naseer, T., Burgard, W., Stachniss, C., Robust visual localization across seasons (2018) IEEE Trans. Rob., 34 (2), pp. 289-302; Neubert, P., Protzel, P., Beyond holistic descriptors, keypoints, and fixed patches: Multiscale superpixel grids for place recognition in changing environments (2016) IEEE Robot. Autom. Lett., 1 (1), pp. 484-491; Cadena, C., Robust place recognition with stereo sequences (2012) IEEE Trans. Rob, 28 (4), pp. 871-885; Chen, J., A compact loop closure detection based on spatial partitioning (2017) 2017 2nd International Conference on Image, Vision and Computing (ICIVC), pp. 371-375. , IEEE, Chengdu; Garcia-Fidalgo, E., Ortiz, A., iBoW-LCD: An appearance-based loop closure detection approach using incremental bags of binary words (2018) IEEE Rob. Autom. Lett., 3 (4), pp. 3051-3057; Chen, Z., (2014) Convolutional neural network-based place recognition; Sünderhauf, N., Place recognition with convnet landmarks: Viewpoint-robust, condition-robust, training-free (2015) Robotics: Science and Systems XI, pp. 1-10; Hou, Y., Zhang, H., Zhou, S., Convolutional neural network-based image representation for visual loop closure detection (2015) 2015 IEEE International Conference on Information and Automation, pp. 2238-2245. , IEEE; Zhang, K., Zhang, W., Loop closure detection based on generative adversarial networks for simultaneous localization and mapping systems (2017) 2017 Chinese Automation Congress (CAC), pp. 7916-7919. , Jinan; Kim, S., Ho, Y., Place recognition for SLAM using texture-independent features and DCGAN (2018) TENCON 2018—2018 IEEE Region 10 Conference, pp. 1269-1272. , Jeju; Shin, D.-W., Ho, Y.-S., Kim, E.-S., Loop closure detection in simultaneous localization and mapping using descriptor from generative adversarial network (2019) JEI, 28 (1); Arroyo, R., Towards life-long visual localization using an efficient matching of binary sequences from images (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 6328-6335. , IEEE; Bampis, L., Amanatiadis, A., Gasteratos, A., Encoding the description of image sequences: A two-layered pipeline for loop closure detection (2016) 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 4530-4536. , IEEE, Daejeon; Li, Y., Image sequence matching using both holistic and local features for loop closure detection (2017) IEEE Access, 5, pp. 13835-13846; Siam, S.M., Zhang, H., Fast-SeqSLAM: A fast appearance based place recognition algorithm (2017) 2017 IEEE International Conference on Robotics and Automation (ICRA), pp. 5702-5708; Kim, D.-H., Kim, J.-H., Visual loop-closure detection method using average feature descriptors (2014) Robot Intelligence Technology and Applications 2, pp. 113-118. , Advances in Intelligent Systems and Computing, Springer, Cham; Bampis, L., A LoCATe-based visual place recognition system for mobile robotics and GPGPUs (2018) Concurr. Comp. Pract, E 30 (7); Lazebnik, S., Schmid, C., Ponce, J., Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories (2006) 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2 (CVPR'06), 2, pp. 2169-2178. , p., IEEE, New York; Abadi, M., (2016) Tensorflow: Large-scale machine learning on heterogeneous distributed systems, , arXiv preprint; Zhou, B., Places: A 10 million image database for scene recognition (2017) IEEE Trans. Pattern Anal. Mach. Intell., 40, pp. 1452-1464; Bianco, S., Benchmark analysis of representative deep neural network architectures (2018) IEEE Access, 6, pp. 64270-64277; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition; Smith, M., The new college vision and laser data set (2009) Int. J. Robot Res, 28 (5), pp. 595-599; Blanco, J.-L., A collection of outdoor robotic datasets with centimeter-accuracy ground truth (2009) Auton. Robot, 27 (4), p. 327; Geiger, A., Lenz, P., Urtasun, R., Are we ready for autonomous driving? The KITTI vision benchmark suite (2012) 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 3354-3361; Labbé, M., Michaud, F., Appearance-based loop closure detection for online large-scale and long-term operation (2013) IEEE T. Robot., 29 (3), pp. 734-745; Zhang, X., Graph-based place recognition in image sequences with CNN features (2019) J. Intell. Robot. Syst, 95 (2), pp. 389-403; Vlaminck, M., Luong, H., Philips, W., Have I seen this place before? A fast and robust loop detection and correction method for 3D LIDAR SLAM (2018) Sensors, 19 (1), p. 23; Ceriani, S., Rawseeds ground truth collection systems for indoor self-localization and mapping (2009) Auton. Robot, 27 (4), p. 353; Khan, S., Wollherr, D., IBuILD: Incremental bag of binary words for appearance based loop closure detection (2015) 2015 IEEE International Conference on Robotics and Automation (ICRA), pp. 5441-5447. , IEEE},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102304010&doi=10.1049%2fitr2.12054&partnerID=40&md5=e8ada28dd07dc1e251d2e75f2a31bd18},
}

@article{du-et-al:2022:3028218,
  author = {Z.-J. Du and S.-S. Huang and T.-J. Mu and Q. Zhao and R. R. Martin and K. Xu},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  title = {Accurate Dynamic SLAM Using CRF-Based Long-Term Consistency},
  volume = {28},
  number = {4},
  pages = {1745--57},
  doi = {10.1109/TVCG.2020.3028218},
  note = {efficient initial camera;estimation method;distinguishing dynamic;conditional random fields;accurate camera trajectory estimation;highly dynamic environments;accurate dynamic SLAM;CRF-based long-term consistency;world dynamic 3D reconstruction;reality applications;novel RGB-D SLAM approach;dynamic components;short time-span;consecutive frames;accurate dynamic 3D landmark detection method;long-term observations;},
  address = {USA},
  year = {2022},
  abstract = {Accurate camera pose estimation is essential and challenging for real world dynamic 3D reconstruction and augmented reality applications. In this article, we present a novel RGB-D SLAM approach for accurate camera pose tracking in dynamic environments. Previous methods detect dynamic components only across a short time-span of consecutive frames. Instead, we provide a more accurate dynamic 3D landmark detection method, followed by the use of long-term consistency via conditional random fields, which leverages long-term observations from multiple frames. Specifically, we first introduce an efficient initial camera pose estimation method based on distinguishing dynamic from static points using graph-cut RANSAC. These static/dynamic labels are used as priors for the unary potential in the conditional random fields, which further improves the accuracy of dynamic 3D landmark detection. Evaluation using the TUM and Bonn RGB-D dynamic datasets shows that our approach significantly outperforms state-of-the-art methods, providing much more accurate camera trajectory estimation in a variety of highly dynamic environments. We also show that dynamic 3D reconstruction can benefit from the camera poses estimated by our RGB-D SLAM approach.},
  copyright = {Copyright 2022, The Institution of Engineering and Technology},
  issn = {1941-0506},
  keywords = {augmented reality;cameras;feature extraction;graph theory;image reconstruction;image sequences;motion estimation;pose estimation;SLAM (robots);},
  language = {English},
  url = {http://dx.doi.org/10.1109/TVCG.2020.3028218},
}
