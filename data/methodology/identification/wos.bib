
@inproceedings{ WOS:000755125502091,
Author = {Zhao, Min and Guo, Xin and Song, Le and Qin, Baoxing and Shi, Xuesong
   and Lee, Gim Hee and Sun, Guanghui},
Book-Group-Author = {IEEE},
Title = {A General Framework for Lifelong Localization and Mapping in Changing
   Environment},
Booktitle = {2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2021},
Pages = {3305-3312},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, SEP 27-OCT 01, 2021},
Abstract = {The environment of most real-world scenarios such as malls and
   supermarkets changes at all times. A pre-built map that does not account
   for these changes becomes out-of-date easily. Therefore, it is necessary
   to have an up-to-date model of the environment to facilitate long-term
   operation of a robot. To this end, this paper presents a general
   lifelong simultaneous localization and mapping (SLAM) framework. Our
   framework uses a multiple session map representation, and exploits an
   efficient map updating strategy that includes map building, pose graph
   refinement and sparsification. To mitigate the unbounded increase of
   memory usage, we propose a map-trimming method based on the Chow-Liu
   maximum-mutual-information spanning tree. The proposed SLAM framework
   has been comprehensively validated by over a month of robot deployment
   in real supermarket environment. Furthermore, we release the dataset
   collected from the indoor and outdoor changing environment with the hope
   to accelerate lifelong SLAM research in the community. Our dataset is
   available at https://github.com/sanduan168/lifelong-SLAM-dataset.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhao, M (Corresponding Author), Gaussian Robot, Shanghai, Peoples R China.
   Zhao, Min; Guo, Xin; Song, Le; Qin, Baoxing, Gaussian Robot, Shanghai, Peoples R China.
   Shi, Xuesong, Intel Labs China, Beijing, Peoples R China.
   Lee, Gim Hee, Natl Univ Singapore, Sch Comp, Dept Comp Sci, Comp Vis \& Robot Percept Lab, Singapore, Singapore.
   Sun, Guanghui, Harbin Inst Technol, Dept Control Sci \& Engn, Harbin, Peoples R China.},
DOI = {10.1109/IROS51168.2021.9635985},
ISSN = {2153-0858},
ISBN = {978-1-6654-1714-3},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {zhaomin@gs-robot.com},
Affiliations = {Intel Corporation; National University of Singapore; Harbin Institute of
   Technology},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2019YFB1312000]},
Funding-Text = {This work was supported in part by the National Key R\&D Program of
   China (No. 2019YFB1312000).},
Cited-References = {Agarwal S., CERES SOLVER.
   Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   Carlone L, 2012, ROBOTICS: SCIENCE AND SYSTEMS VII, P41.
   Censi A, 2008, IEEE INT CONF ROBOT, P19, DOI 10.1109/ROBOT.2008.4543181.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Ding WD, 2020, IEEE INT CONF ROBOT, P4322.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Grisetti G., 2011, IEEE INT C ROB AUT I, P9.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Kretzschmar H, 2010, KUNSTL INTELL, V24, P199, DOI 10.1007/s13218-010-0034-2.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Blanco-Claraco JL, 2019, ROBOTICS: SCIENCE AND SYSTEMS XV.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {19},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS6ZK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000755125502091},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000712319502037,
Author = {Shi, Xuesong and Li, Dongjiang and Zhao, Pengpeng and Tian, Qinbin and
   Tian, Yuxin and Long, Qiwei and Zhu, Chunhao and Song, Jingwei and Qiao,
   Fei and Song, Le and Guo, Yangquan and Wang, Zhigang and Zhang, Yimin
   and Qin, Baoxing and Yang, Wei and Wang, Fangshi and Chan, Rosa H. M.
   and She, Qi},
Book-Group-Author = {IEEE},
Title = {Are We Ready for Service Robots? The OpenLORIS-Scene Datasets for
   Lifelong SLAM},
DOI = {10.1109/ICRA40945.2020.9196638},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2020},
Pages = {3139-3145},
Note = {IEEE International Conference on Robotics and Automation (ICRA), ELECTR
   NETWORK, MAY 31-JUN 15, 2020},
Abstract = {Service robots should be able to operate autonomously in dynamic and
   daily changing environments over an extended period of time. While
   Simultaneous Localization And Mapping (SLAM) is one of the most
   fundamental problems for robotic autonomy, most existing SLAM works are
   evaluated with data sequences that are recorded in a short period of
   time. In real-world deployment, there can be out-of-sight scene changes
   caused by both natural factors and human activities. For example, in
   home scenarios, most objects may be movable, replaceable or deformable,
   and the visual features of the same place may be significantly different
   in some successive days. Such out-of-sight dynamics pose great
   challenges to the robustness of pose estimation, and hence a robot's
   long-term deployment and operation. To differentiate the forementioned
   problem from the conventional works which are usually evaluated in a
   static setting in a single run, the term lifelong SLAM is used here to
   address SLAM problems in an ever-changing environment over a long period
   of time. To accelerate lifelong SLAM research, we release the
   OpenLORIS-Scene datasets. The data are collected in real-world indoor
   scenes, for multiple times in each place to include scene changes in
   real life. We also design benchmarking metrics for lifelong SLAM, with
   which the robustness and accuracy of pose estimation are evaluated
   separately. The datasets and benchmark are available online at
   lifelong-robotic-vision.github.io/dataset/scene.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Shi, XS (Corresponding Author), Intel Labs China, Beijing 100190, Peoples R China.
   Qiao, F (Corresponding Author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   Qiao, F (Corresponding Author), Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
   Shi, Xuesong; Zhao, Pengpeng; Wang, Zhigang; Zhang, Yimin; She, Qi, Intel Labs China, Beijing 100190, Peoples R China.
   Li, Dongjiang; Tian, Qinbin; Tian, Yuxin; Long, Qiwei; Zhu, Chunhao; Song, Jingwei; Qiao, Fei, Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   Li, Dongjiang; Tian, Qinbin; Tian, Yuxin; Long, Qiwei; Zhu, Chunhao; Song, Jingwei; Qiao, Fei, Tsinghua Univ, BNRist, Beijing 100084, Peoples R China.
   Song, Le; Guo, Yangquan; Qin, Baoxing, Gaussian Robot, Shanghai 201203, Peoples R China.
   Li, Dongjiang; Tian, Qinbin; Long, Qiwei; Zhu, Chunhao; Song, Jingwei; Yang, Wei; Wang, Fangshi, Beijing Jiaotong Univ, Beijing 100044, Peoples R China.
   Zhao, Pengpeng; Tian, Yuxin, Beihang Univ, Beijing 100191, Peoples R China.
   Chan, Rosa H. M., City Univ Hong Kong, Hong Kong, Peoples R China.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-7281-7395-5},
Keywords-Plus = {LOCALIZATION; ROBUST},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {xuesong.shi@intel.com
   qiaofei@tsinghua.edu.cn},
Affiliations = {Intel Corporation; Tsinghua University; Tsinghua University; Beijing
   Jiaotong University; Beihang University; City University of Hong Kong},
Cited-References = {Bodin B, 2018, IEEE INT CONF ROBOT, P3637.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Deng CY, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2949423.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614.
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514.
   Geiger A., 2012, P IEEE COMP SOC C CO.
   Grunnet-Jepsen A., BEST KNOWN METHODS T.
   Kahler O, 2015, IEEE T VIS COMPUT GR, V21, P1241, DOI 10.1109/TVCG.2015.2459891.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Krajnik T, 2015, IEEE INT CONF ROBOT, P2140, DOI 10.1109/ICRA.2015.7139481.
   Li Wenbin, 2018, BRIT MACH VIS C BMVC.
   McCormac J., 2016, ARXIV PREPRINT ARXIV.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Pronobis A, 2009, INT J ROBOT RES, V28, P588, DOI 10.1177/0278364909103912.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Schubert D, 2018, IEEE INT C INT ROBOT, P1680, DOI 10.1109/IROS.2018.8593419.
   She Q., 2019, ARXIV191106487.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573.
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237.
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691.
   Zhang Q., 2004, 2004 IEEERSJ INT C I, V3, P2301, DOI {[}10.1109/IROS.2004.1389752, DOI 10.1109/IROS.2004.1389752].
   Zhao Y, 2019, IEEE I CONF COMP VIS, P1110, DOI 10.1109/ICCV.2019.00120.},
Number-of-Cited-References = {25},
Times-Cited = {17},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BS3LB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000712319502037},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000413736600104,
Author = {Han, Fei and Yang, Xue and Deng, Yiming and Rentschler, Mark and Yang,
   Dejun and Zhang, Hao},
Title = {SRAL: Shared Representative Appearance Learning for Long-Term Visual
   Place Recognition},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2017},
Volume = {2},
Number = {2},
Pages = {1172-1179},
Month = {APR},
Abstract = {Place recognition, or loop closure detection, is an essential component
   to address the problem of visual simultaneous localization and mapping
   (SLAM). Long-term navigation of robots in outdoor environments
   introduces new challenges to enable life-long SLAM, including the strong
   appearance change resulting fromvegetation, weather, and illumination
   variations across various times of the day, different days, months, or
   even seasons. In this paper, we propose a new shared representative
   appearance learning (SRAL) approach to address long-term visual place
   recognition. Different from previous methods using a single feature
   modality or a concatenation of multiple features, our SRAL method
   autonomously learns representative features that are shared in all scene
   scenarios, and then fuses the features together to represent the
   long-term appearance of environments observed by a robot during
   life-long navigation. By formulating SRAL as a regularized optimization
   problem, we use structured sparsity-inducing norms to model
   interrelationships of feature modalities. In addition, an optimization
   algorithm is developed to efficiently solve the formulated optimization
   problem, which holds a theoretical convergence guarantee. Extensive
   empirical study was performed to evaluate the SRAL method using
   large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland
   datasets. Experimental results have shown that our SRAL method obtains
   superior performance for life-long place recognition using individual
   images, outperforms previous single image-based methods, and is capable
   of estimating the importance of feature modalities.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Han, F (Corresponding Author), Colorado Sch Mines, Div Comp Sci, Golden, CO 80401 USA.
   Han, Fei; Yang, Xue; Yang, Dejun; Zhang, Hao, Colorado Sch Mines, Div Comp Sci, Golden, CO 80401 USA.
   Deng, Yiming, Michigan State Univ, Dept Elect \& Comp Engn, E Lansing, MI 48824 USA.
   Rentschler, Mark, Univ Colorado, Dept Mech Engn, Boulder, CO 80309 USA.},
DOI = {10.1109/LRA.2017.2662061},
ISSN = {2377-3766},
Keywords = {Loop closure detection; long-term place recognition; simultaneous
   localization and mapping (SLAM); visual learning},
Keywords-Plus = {LOCALIZATION; NAVIGATION; SEQUENCES; WORDS; BAGS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {fhan@mines.edu
   xueyang@mines.edu
   dengyimi@msu.edu
   mark.rentschler@colorado.edu
   djyang@mines.edu
   hzhang@mines.edu},
Affiliations = {Colorado School of Mines; Michigan State University; University of
   Colorado System; University of Colorado Boulder},
ResearcherID-Numbers = {Yang, Dejun/AAO-4817-2020
   Deng, Yiming/AAE-6096-2020
   },
ORCID-Numbers = {Yang, Dejun/0000-0002-1811-4423
   Zhang, Hao/0000-0001-8043-9184},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Chen C, 2006, INT J ROBOT RES, V25, P953, DOI 10.1177/0278364906068375.
   Chen Z., 2014, P AUSTR C ROB AUT.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Feldman D., 2016, ADV NEURAL INFORM PR, V29, P2766.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Gutmann J.-S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P318, DOI 10.1109/CIRA.1999.810068.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148.
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Klopschitz M., 2008, P 3D DAT PROC VIS TR.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Latif Y., 2014, P ROB SCI SYST.
   Lee D., 2013, P ROB INT TECHN APPL, P485.
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Neubert P., 2013, INT C ROB AUT ICRA W, DOI 10.1016/j.cell.2007.12.011.
   Newman P, 2009, P ROB SCI SYST.
   Pepperell E, 2014, IEEE INT CONF ROBOT, P1612, DOI 10.1109/ICRA.2014.6907067.
   Qiao YL, 2015, LECT NOTES ARTIF INT, V9414, P393, DOI 10.1007/978-3-319-27101-9\_30.
   Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939.
   Stumm E, 2016, PROC CVPR IEEE, P4535, DOI 10.1109/CVPR.2016.491.
   SUNDERHAUF N, 2015, P IEEE RSJ INT C INT, P4297.
   SUNDERHAUF N, 2011, P IEEE RSJ INT C INT, P1234.
   Sunderhauf N., 2015, P ROB SCI SYST.
   Zhang H., 2016, P ROB SCI SYST.},
Number-of-Cited-References = {38},
Times-Cited = {32},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {FK8DB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000413736600104},
DA = {2022-05-17},
}

@inproceedings{ WOS:000755125504033,
Author = {Bujanca, Mihai and Shi, Xuesong and Spear, Matthew and Zhao, Pengpeng
   and Lennox, Barry and Lujan, Mikel},
Book-Group-Author = {IEEE},
Title = {Robust SLAM Systems: Are We There Yet?},
Booktitle = {2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2021},
Pages = {5320-5327},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, SEP 27-OCT 01, 2021},
Abstract = {Progress in the last decade has brought about significant improvements
   in the accuracy and speed of SLAM systems, broadening their mapping
   capabilities. Despite these advancements, long-term operation remains a
   major challenge, primarily due to the wide spectrum of perturbations
   robotic systems may encounter.
   Increasing the robustness of SLAM algorithms is an ongoing effort,
   however it usually addresses a specific perturbation. Generalisation of
   robustness across a large variety of challenging scenarios is not
   well-studied nor understood. This paper presents a systematic evaluation
   of the robustness of open-source state-of-the-art SLAM algorithms with
   respect to challenging conditions such as fast motion, non-uniform
   illumination, and dynamic scenes. The experiments are performed with
   perturbations present both independently of each other, as well as in
   combination in long-term deployment settings in unconstrained
   environments (lifelong operation).
   The detailed results (approx. 20,000 experiments) along with
   comprehensive documentation of the benchmarking tool for integrating new
   datasets and evaluating SLAM algorithms not studied in this work are
   available at https://robustslam.github.io/evaluation.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bujanca, M (Corresponding Author), Univ Manchester, Manchester, Lancs, England.
   Bujanca, Mihai; Spear, Matthew; Lennox, Barry; Lujan, Mikel, Univ Manchester, Manchester, Lancs, England.
   Shi, Xuesong; Zhao, Pengpeng, Intel Labs China, Beijing, Peoples R China.
   Zhao, Pengpeng, Beihang Univ, Beijing, Peoples R China.},
DOI = {10.1109/IROS51168.2021.9636814},
ISSN = {2153-0858},
ISBN = {978-1-6654-1714-3},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; VISUAL SLAM; ENVIRONMENTS},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Affiliations = {University of Manchester; Intel Corporation; Beihang University},
Funding-Acknowledgement = {EPSRC, grant RAIN Hub {[}EP/R026084/1]; Arm/RAEng Research Chair Award;
   Royal Society Wolfson Fellowship},
Funding-Text = {This research is supported by the EPSRC, grant RAIN Hub EP/R026084/1.
   Mikel Luj ` an is supported by an Arm/RAEng Research Chair Award and a
   Royal Society Wolfson Fellowship. Thanks to Patrick Geneva for assisting
   with experiments on OpenVINS. Thanks to all researchers who provided the
   datasets.},
Cited-References = {Alismail H., 2016, ARXIV160400990.
   Alismail H, 2017, IEEE ROBOT AUTOM LET, V2, P444, DOI 10.1109/LRA.2016.2635686.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Bodin B, 2018, IEEE INT CONF ROBOT, P3637.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Bujanca M., 2019, P IEEE INT C COMP VI, P0.
   Bujanca M, 2019, IEEE INT CONF ROBOT, P6351, DOI 10.1109/ICRA.2019.8794369.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Campos C., 2020, ORB SLAM3 ACCURATE O.
   Cheng JY, 2019, ADV ROBOTICS, V33, P576, DOI 10.1080/01691864.2019.1610060.
   Derome M, 2015, UNMANNED SYST, V3, P253, DOI 10.1142/S2301385015400026.
   Einhorn E, 2015, ROBOT AUTON SYST, V69, P28, DOI 10.1016/j.robot.2014.08.008.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   FOLKESSON J, 2004, IFAC P VOLUMES, V37, P722.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Geiger A., 2012, P IEEE COMP SOC C CO.
   Geneva P., 2020, IEEE INT C ROB AUT I.
   Greene WN, 2017, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2017.502.
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054.
   Johannsson H., 2013, THESIS.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kretzschmar H, 2010, KUNSTL INTELL, V24, P199, DOI 10.1007/s13218-010-0034-2.
   Lee HS, 2011, IEEE I CONF COMP VIS, P1203, DOI 10.1109/ICCV.2011.6126370.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li DJ, 2020, IEEE INT C INT ROBOT, P4958, DOI 10.1109/IROS45743.2020.9340907.
   Lomps J., 2020, ARXIV200905427.
   Lynen S., 2015, ROBOTICS SCI SYSTEMS, V1.
   Mu XK, 2020, IEEE ACCESS, V8, P465, DOI 10.1109/ACCESS.2019.2961762.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mustaniemi J, 2018, INT C PATT RECOG, P3068, DOI 10.1109/ICPR.2018.8546041.
   Palazzolo E, 2019, IEEE INT C INT ROBOT, P7855, DOI 10.1109/IROS40897.2019.8967590.
   Pascoe G, 2017, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2017.158.
   Pfister H, 2000, COMP GRAPH, P335.
   Porav H, 2019, IEEE INT C INTELL TR, P33, DOI 10.1109/ITSC.2019.8917073.
   Porav H, 2019, IEEE INT CONF ROBOT, P7087, DOI 10.1109/ICRA.2019.8793486.
   Pretto Alberto, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P2250, DOI 10.1109/ROBOT.2009.5152447.
   Prokhorov D, 2019, PROCEEDINGS OF MVA 2019 16TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA).
   Pyojin Kim, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5447, DOI 10.1109/ICRA.2017.7989640.
   Roesler O., 2020, ROBOT 2019, P28.
   Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853.
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499.
   Scona R, 2018, IEEE INT CONF ROBOT, P3849, DOI 10.1109/ICRA.2018.8460681.
   Seonwook Park, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4523, DOI 10.1109/ICRA.2017.7989525.
   Sheng C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041467.
   Shi XS, 2020, IEEE INT CONF ROBOT, P3139, DOI 10.1109/ICRA40945.2020.9196638.
   Shim I, 2019, IEEE T CIRC SYST VID, V29, P1569, DOI 10.1109/TCSVT.2018.2846292.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752.
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Torii A., 2015, IEEE CVF C COMP VIS.
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573.
   Wang F, 2007, INT J COMPUT VISION, V74, P201, DOI 10.1007/s11263-006-0011-2.
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Xiao LH, 2019, ROBOT AUTON SYST, V117, P1, DOI 10.1016/j.robot.2019.03.012.
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691.
   Zichao Zhang, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3894, DOI 10.1109/ICRA.2017.7989449.},
Number-of-Cited-References = {59},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS6ZK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000755125504033},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000262143800002,
Author = {Biber, Peter and Duckett, Tom},
Title = {Experimental Analysis of Sample-Based Maps for Long-Term SLAM},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2009},
Volume = {28},
Number = {1},
Pages = {20-33},
Month = {JAN},
Abstract = {This paper presents a system for long-term SLAM (simultaneous
   localization and mapping) by mobile service robots and its experimental
   evaluation in a real dynamic environment. To deal with the
   stability-plasticity dilemma (the trade-off between adaptation to new
   patterns and preservation of old patterns), the environment is
   represented by multiple timescales simultaneously (five in our
   experiments). A sample-based representation is proposed, where older
   memories fade at different rates depending on the timescale and robust
   statistics are used to interpret the samples. The dynamics of this
   representation are analyzed in a five-week experiment, measuring the
   relative influence of short- and long-term memories over time and
   further demonstrating the robustness of the approach.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Biber, P (Corresponding Author), Univ Tubingen, Dept Comp Sci, WSI GRIS, Tubingen, Germany.
   Biber, Peter, Univ Tubingen, Dept Comp Sci, WSI GRIS, Tubingen, Germany.
   Duckett, Tom, Lincoln Univ, Dept Comp \& Informat, Lincoln LN6 7TS, England.},
DOI = {10.1177/0278364908096286},
ISSN = {0278-3649},
Keywords = {simultaneous localization and mapping; dynamic environments; mobile
   robot navigation; lifelong learning; multi-timescale representations},
Keywords-Plus = {DYNAMIC ENVIRONMENTS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {dr.peter.biber@googleemail.com
   tduckett@lincoln.ac.uk},
Affiliations = {Eberhard Karls University of Tubingen; University of Lincoln},
Cited-References = {Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   ANGUELOV D, 2002, P 17 ANN C UNC AI UA.
   BIBER P, 2003, INT C INT ROB SYST I.
   BIBER P, 2005, P ROB SCI SYST CAMBR, V1.
   BIBER P, 2007, THESIS U TUBINGEN GE.
   Burgard W, 1999, ARTIF INTELL, V114, P3, DOI 10.1016/S0004-3702(99)00070-3.
   Dennis J.E, 1996, SIAM CLASSICS APPL M.
   Duda R., 2001, PATTERN CLASSIFICATI, Vxx.
   GROSSBERG S, 1988, ADAPTIVE BRAIN.
   HAHNEL D, 2003, MAP BUILDING MOBILE.
   Huber P. J, 2011, ROBUST STAT.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   STACHNISS C, 2005, P NAT C ART INT AAAI.
   Sutton R., 1998, INTRO REINFORCEMENT.
   Thrun S., 1999, ICRA.
   Thrun S., 2003, ICRA.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.
   ZIMMER U, 1995, THESIS U KAISERSLAUT.},
Number-of-Cited-References = {18},
Times-Cited = {44},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {390DF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000262143800002},
OA = {Green Submitted, Green Accepted},
DA = {2022-05-17},
}

@article{ WOS:000751573800002,
Author = {Wei, Wei and Zhu, Xiaorui and Wang, Yi},
Title = {Novel robust simultaneous localization and mapping for long-term
   autonomous robots},
Journal = {FRONTIERS OF INFORMATION TECHNOLOGY \& ELECTRONIC ENGINEERING},
Year = {2022},
Volume = {23},
Number = {2},
Pages = {234-245},
Month = {FEB},
Abstract = {A fundamental task for mobile robots is simultaneous localization and
   mapping (SLAM). Moreover, long-term robustness is an important property
   for SLAM. When vehicles or robots steer fast or steer in certain
   scenarios, such as low-texture environments, long corridors, tunnels, or
   other duplicated structural environments, most SLAM systems might fail.
   In this paper, we propose a novel robust visual inertial light detection
   and ranging (LiDaR) navigation (VILN) SLAM system, including stereo
   visual-inertial LiDaR odometry and visual-LiDaR loop closure. The
   proposed VILN SLAM system can perform well with low drift after
   long-term experiments, even when the LiDaR or visual measurements are
   degraded occasionally in complex scenes. Extensive experimental results
   show that the robustness has been greatly improved in various scenarios
   compared to state-of-the-art SLAM systems.},
Publisher = {ZHEJIANG UNIV PRESS},
Address = {Xixi Campus, Zhejiang University, No. 148 Tianmushan Road, Hangzhou,
   Zhejiang, PEOPLES R CHINA},
Type = {Article},
Language = {English},
Affiliation = {Zhu, XR (Corresponding Author), Harbin Inst Technol, Sch Mech Engn \& Automat, Shenzhen 518055, Peoples R China.
   Zhu, XR (Corresponding Author), Zhuhai Big Data Res Inst, Zhuhai 519000, Peoples R China.
   Wei, Wei; Zhu, Xiaorui; Wang, Yi, Harbin Inst Technol, Sch Mech Engn \& Automat, Shenzhen 518055, Peoples R China.
   Zhu, Xiaorui, Zhuhai Big Data Res Inst, Zhuhai 519000, Peoples R China.},
DOI = {10.1631/FITEE.2000358},
EarlyAccessDate = {FEB 2022},
ISSN = {2095-9184},
EISSN = {2095-9230},
Keywords = {Simultaneous localization and mapping (SLAM); Long-term; Robustness;
   Light detection and ranging (LiDaR); Visual inertial LiDaR navigation
   (VILN)},
Keywords-Plus = {SLAM},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical \& Electronic},
Author-Email = {weirui9003@gmail.com
   xiaoruizhu@hit.edu.cn
   wangyi601@aliyun.com},
Affiliations = {Harbin Institute of Technology},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018YFB1305500]; National Natural
   Science Foundation of China {[}U1813219]},
Funding-Text = {Project supported by the National Key R\&D Program of China (No.
   2018YFB1305500) and the National Natural Science Foundation of China
   (No. U1813219)},
Cited-References = {Banerjee N, 2019, IEEE INT C INT ROBOT, P7871, DOI 10.1109/IROS40897.2019.8968245.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Deschaud JE, 2018, IEEE INT CONF ROBOT, P2480.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hemann G, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1659, DOI 10.1109/IROS.2016.7759267.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Kim G, 2019, IEEE ROBOT AUTOM LET, V4, P1948, DOI 10.1109/LRA.2019.2897340.
   Klein George, 2007, P1.
   Konolige K, 2010, IEEE INT C INT ROBOT.
   Lee J, 2020, AD VO SCALE RESILIEN.
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Nair GB, 2020, MULTIOBJECT MONOCULA.
   Neubert P., 2013, INT C ROB AUT ICRA W, DOI 10.1016/j.cell.2007.12.011.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Patel N, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P523, DOI 10.1109/ICAR46387.2019.8981658.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Shao WZ, 2019, IEEE INT C INT ROBOT, P370, DOI 10.1109/IROS40897.2019.8968012.
   Sibley G, 2010, J FIELD ROBOT, V27, P587, DOI 10.1002/rob.20360.
   Wagstaff B, 2020, IEEE INT CONF ROBOT, P2331, DOI 10.1109/ICRA40945.2020.9197562.
   Wang ZJ, 2020, IEEE ACCESS, V8, P2847, DOI 10.1109/ACCESS.2019.2962554.
   Xu YL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P121, DOI 10.1109/CBS.2018.8612212.
   Zhang J, 2015, IEEE INT CONF ROBOT, P2174, DOI 10.1109/ICRA.2015.7139486.
   Zhao HJ, 2008, IEEE INT CONF ROBOT, P1455, DOI 10.1109/ROBOT.2008.4543407.
   Zhao Z., 2019, 2019 2 CHIN S COGN C, P149.
   Zhu XR, 2017, J FIELD ROBOT, V34, P1313, DOI 10.1002/rob.21712.},
Number-of-Cited-References = {33},
Times-Cited = {0},
Usage-Count-Last-180-days = {19},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Front. Inform. Technol. Elect. Eng.},
Doc-Delivery-Number = {ZV1RZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000751573800002},
DA = {2022-05-17},
}

@inproceedings{ WOS:000755125502092,
Author = {Kurz, Gerhard and Holoch, Matthias and Biber, Peter},
Book-Group-Author = {IEEE},
Title = {Geometry-based Graph Pruning for Lifelong SLAM},
Booktitle = {2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2021},
Pages = {3313-3320},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, SEP 27-OCT 01, 2021},
Abstract = {Lifelong SLAM considers long-term operation of a robot where already
   mapped locations are revisited many times in changing environments. As a
   result, traditional graph-based SLAM approaches eventually become
   extremely slow due to the continuous growth of the graph and the loss of
   sparsity. Both problems can be addressed by a graph pruning algorithm.
   It carefully removes vertices and edges to keep the graph size
   reasonable while preserving the information needed to provide good SLAM
   results. We propose a novel method that considers geometric criteria for
   choosing the vertices to be pruned. It is efficient, easy to implement,
   and leads to a graph with evenly spread vertices that remain part of the
   robot trajectory. Furthermore, we present a novel approach of
   marginalization that is more robust to wrong loop closures than existing
   methods. The proposed algorithm is evaluated on two publicly available
   real-world long-term datasets and compared to the unpruned case as well
   as ground truth. We show that even on a long dataset (25h), our approach
   manages to keep the graph sparse and the speed high while still
   providing good accuracy (40 times speed up, 6cm map error compared to
   unpruned case).},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kurz, G (Corresponding Author), Robert Bosch GmbH, Corp Res, Renningen, Germany.
   Kurz, Gerhard; Holoch, Matthias; Biber, Peter, Robert Bosch GmbH, Corp Res, Renningen, Germany.},
DOI = {10.1109/IROS51168.2021.9636530},
ISSN = {2153-0858},
ISBN = {978-1-6654-1714-3},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {gerhard2.kurz@de.bosch.com
   matthias.holoch@de.bosch.com
   peter.biber@de.bosch.com},
Affiliations = {Bosch},
Cited-References = {Biber P., 2003, 2003 IEEE RSJ INT C.
   Burgard W, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2089, DOI 10.1109/IROS.2009.5354691.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Carlevaris-Bianco N., 2013, 2013 IEEE INT C ROB.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Dellaert F., 2012, RIMCPR2012002.
   Ta N, 2018, IEEE INT CONF ROBOT, P2494, DOI 10.1109/ICRA.2018.8460979.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Grisetti G., 2012, 2012 IEEE RSJ INT C.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136.
   Krajnik T., 2016, 2016 IEEE RSJ INT C.
   Kretzschmar H, 2010, KUNSTL INTELL, V24, P199, DOI 10.1007/s13218-010-0034-2.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lazaro MT, 2018, IEEE INT C INT ROBOT, P153, DOI 10.1109/IROS.2018.8594310.
   Lee G. H., 2013, 2013 IEEE RSJ INT C.
   Mazuran M, 2016, INT J ROBOT RES, V35, P50, DOI 10.1177/0278364915581629.
   Underwood JP, 2013, IEEE INT CONF ROBOT, P4735, DOI 10.1109/ICRA.2013.6631251.
   Wang Y, 2015, ADV ROBOTICS, V29, P683, DOI 10.1080/01691864.2014.998707.},
Number-of-Cited-References = {21},
Times-Cited = {0},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BS6ZK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000755125502092},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000465104900043,
Author = {Zaffar, Mubariz and Ehsan, Shoaib and Stolkin, Rustam and Maier, Klaus
   McDonald},
Book-Group-Author = {IEEE},
Title = {Sensors, SLAM and Long-term Autonomy: A Review},
DOI = {10.1109/AHS.2018.8541483},
Booktitle = {2018 NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS (AHS 2018)},
Series = {NASA/ESA Conference on Adaptive Hardware and Systems},
Year = {2018},
Pages = {285-290},
Note = {NASA/ESA Conference on Adaptive Hardware and Systems (AHS), Univ
   Edinburgh, Edinburgh, SCOTLAND, AUG 06-09, 2018},
Abstract = {Simultaneous Localization and Mapping, commonly known as SLAM, has been
   an active research area in the field of Robotics over the past three
   decades. For solving the SLAM problem, every robot is equipped with
   either a single sensor or a combination of similar/different sensors.
   This paper attempts to review, discuss, evaluate and compare these
   sensors. Keeping an eye on future, this paper also assesses the
   characteristics of these sensors against factors critical to the long-
   term autonomy challenge.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zaffar, M (Corresponding Author), Univ Essex, Embedded \& Intelligent Syst Lab, Colchester, Essex, England.
   Zaffar, Mubariz; Ehsan, Shoaib; Maier, Klaus McDonald, Univ Essex, Embedded \& Intelligent Syst Lab, Colchester, Essex, England.
   Stolkin, Rustam, Univ Birmingham, Extreme Robot Lab, Birmingham, W Midlands, England.},
ISSN = {1939-7003},
ISBN = {978-1-5386-7753-7},
Keywords = {SLAM; Long-term Autonomy; Sensors},
Keywords-Plus = {LOCALIZATION; VISION; STEREO},
Research-Areas = {Engineering; Computer Science},
Web-of-Science-Categories  = {Engineering, Aerospace; Computer Science, Hardware \& Architecture;
   Computer Science, Information Systems},
Author-Email = {mz18963@essex.ac.uk
   sehsan@essex.ac.uk
   r.stolkin@cs.bham.ac.uk
   kdm@essex.ac.uk},
Affiliations = {University of Essex; University of Birmingham},
ResearcherID-Numbers = {Zaffar, Mubariz/AAJ-4482-2020
   },
ORCID-Numbers = {McDonald-Maier, Klaus/0000-0002-6412-8519},
Funding-Acknowledgement = {UK EPSRC {[}EP/R02572X/1, EP/P017487/1]; EPSRC {[}EP/P017487/1] Funding
   Source: UKRI},
Funding-Text = {This work is supported by the UK EPSRC through grants EP/R02572X/1 and
   EP/P017487/1.},
Cited-References = {{[}Anonymous], Primesense Patent, Patent No. {[}US20070216894, 20070216894].
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Ben-Ari M., 2018, ELEMENTS ROBOTICS.
   Brooker Graham, 2007, SENSORS AND SIGNALS.
   Burgard W., 2008, SPRINGER HDB ROBOTIC, P853.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Djugash J., 2006, ICRA.
   ELFES A, 1987, IEEE T ROBOTIC AUTOM, V3, P249, DOI 10.1109/JRA.1987.1087096.
   Elinas P., 2006, P 2006 IEEE INT C RO.
   Endres F., 2012, ICRA.
   Engel J., 2015, IEEE RSJ IROS.
   Evers C., 2016, IEEE ICASSP.
   Grasa OG, 2011, IEEE INT CONF ROBOT.
   Grisettiyz G., P 2005 IEEE ICRA.
   Grisettiyz G., 2005, ICRA.
   Hess W., 2016, ICRA.
   Horstschafer Timo, 2016, PARALLEL TRACKING DE.
   Huang A.S., 2016, VISUAL ODOMETRY MAPP, P235.
   Kerl C., 2013, IEEE RSJ IROS.
   Kerl C., 2013, IEEE ICRA.
   Kim Jac-Hean, 2003, P 2003 IEEE RSJ IROS, DOI {[}10.1109/iros.2003.1250669, DOI 10.1109/IROS.2003.1250669].
   Klingauf Uwe, 2011, 2011 IEEE INT S SAF.
   Krekovic M., 2016, IEEE ICASSP.
   Kyto M, 2011, PROC SPIE, V7864, DOI 10.1117/12.872015.
   Lemaire T, 2007, INT J COMPUT VISION, V74, P343, DOI 10.1007/s11263-007-0042-3.
   Lowe D. G., 1999, P IEEE ICCV.
   Montemerlo M., 2003, IEEE ICRA.
   Mueggler Elias, 2017, IEEE T ROBOT.
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2.
   Paya L, 2017, J SENSORS, V2017, DOI 10.1155/2017/3497650.
   Paz LM, 2008, IEEE T ROBOT, V24, P946, DOI 10.1109/TRO.2008.2004637.
   Rebecq H, 2017, IEEE ROBOT AUTOM LET, V2, P593, DOI 10.1109/LRA.2016.2645143.
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y.
   Tamimi H, 2006, ROBOT AUTON SYST, V54, P758, DOI 10.1016/j.robot.2006.04.018.
   Tipaldi GD, 2014, EXPT ROBOTICS, P695.
   Tomono M., 2009, ICRA.
   Vidal AR, 2018, IEEE ROBOT AUTOM LET, V3, P994, DOI 10.1109/LRA.2018.2793357.
   Wang K., 2012, ROBIO.
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   2015, PROCEDIA COMPUTER SC, V76, P174, DOI DOI 10.1016/J.PROCS.2015.12.336.},
Number-of-Cited-References = {42},
Times-Cited = {11},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {12},
Doc-Delivery-Number = {BM5JA},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000465104900043},
OA = {Green Accepted, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000702716000071,
Author = {Ali, Waqas and Liu, Peilin and Ying, Rendong and Gong, Zheng},
Title = {A Life-Long SLAM Approach Using Adaptable Local Maps Based on Rasterized
   LIDAR Images},
Journal = {IEEE SENSORS JOURNAL},
Year = {2021},
Volume = {21},
Number = {19},
Pages = {21740-21749},
Month = {OCT 1},
Abstract = {Most real-time autonomous robot applications require a robot to traverse
   through a dynamic space for a long time. In some cases, a robot needs to
   work in the same environment. Such applications give rise to the problem
   of a life-long SLAM system. Life-long SLAM presents two main challenges
   i.e. the tracking should not fail in a dynamic environment and the need
   for a robust and efficient mapping strategy. The system should update
   maps with new information; while also keeping track of older
   observations. But, mapping for a long time can require higher
   computational requirements. In this paper, we propose a solution to the
   problem of life-long SLAM. We represent the global map as a set of
   rasterized images of local maps along with a map management system
   responsible for updating local maps and keeping track of older values.
   We also present an efficient approach of using the bag of visual words
   method for loop closure detection and relocalization. We evaluate the
   performance of our system on the KITTI dataset and an indoor dataset.
   Our loop closure system reported recall and precision of above 90
   percent. The computational cost of our system is much lower as compared
   to state-of-the-art methods. Our method reports lower computational
   requirements even for long-term operation.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Ali, W (Corresponding Author), Shanghai Jiao Tong Univ, Sch Elect Informat \& Elect Engn, Shanghai 200240, Peoples R China.
   Ali, Waqas; Liu, Peilin; Ying, Rendong; Gong, Zheng, Shanghai Jiao Tong Univ, Sch Elect Informat \& Elect Engn, Shanghai 200240, Peoples R China.},
DOI = {10.1109/JSEN.2021.3100882},
ISSN = {1530-437X},
EISSN = {1558-1748},
Keywords = {Simultaneous localization and mapping; Three-dimensional displays;
   Feature extraction; Robots; Databases; Laser radar; Sensors; Laser
   scanning; place recognition; bag of words; rasterization; mapping;
   simultaneous localization; mapping},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; NAVIGATION; WORDS; BAG},
Research-Areas = {Engineering; Instruments \& Instrumentation; Physics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Instruments \& Instrumentation;
   Physics, Applied},
Author-Email = {vaqas11@sjtu.edu.cn},
Affiliations = {Shanghai Jiao Tong University},
Cited-References = {Ali W., ARXIV210310678, V2021.
   Angeli A, 2008, IEEE INT CONF ROBOT, P1842, DOI 10.1109/ROBOT.2008.4543475.
   Banerjee N, 2020, PARASITOLOGY, V147, P841, DOI 10.1017/S0031182019001422.
   Behley J, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Chen XYL, 2019, IEEE INT C INT ROBOT, P4530, DOI 10.1109/IROS40897.2019.8967704.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Fentanes JP, 2015, IEEE INT CONF ROBOT, P1112, DOI 10.1109/ICRA.2015.7139315.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Haehnel D., 2009, P ROBOT SCI SYST, P435, DOI 10.15607/RSS.2009.V.021.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Magnusson Martin, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P23, DOI 10.1109/ROBOT.2009.5152712.
   McDonald J., 2011, P EUR C MOB ROB ECMR, P69.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Naima A., 2011, THESIS DEP ELECT ENG.
   Nicosevici T, 2012, IEEE T ROBOT, V28, P886, DOI 10.1109/TRO.2012.2192013.
   Pan Y., ARXIV210203771, V2021.
   Qin T., 2019, ARXIV190103638.
   Rohling T, 2015, IEEE INT C INT ROBOT, P736, DOI 10.1109/IROS.2015.7353454.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Stachniss C., 2005, P C ART INT, P1324.
   Stachniss C, 2017, SPRINGER TRAC ADV RO, V100, DOI 10.1007/978-3-319-29363-9\_16.
   Steder B, 2011, IEEE INT C INT ROBOT, P1249, DOI 10.1109/IROS.2011.6048325.
   Steder B, 2010, IEEE INT CONF ROBOT, P1400, DOI 10.1109/ROBOT.2010.5509401.
   Thrun S, 2002, COMMUN ACM, V45, P52.
   Wang H, 2020, IEEE INT CONF ROBOT, P2095, DOI 10.1109/ICRA40945.2020.9196764.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.
   Zhang J., 2014, ROBOT SCI SYST, V2, P9.},
Number-of-Cited-References = {36},
Times-Cited = {0},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {9},
Journal-ISO = {IEEE Sens. J.},
Doc-Delivery-Number = {WA2IU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000702716000071},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000544658404052,
Author = {Song, Bowen and Chen, Weidong and Wang, Jingwang and Wang, Hesheng},
Book-Group-Author = {IEEE},
Title = {Long-Term Visual Inertial SLAM based on Time Series Map Prediction},
Booktitle = {2019 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
DOI = {10.1109/IROS40897.2019.8968017},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2019},
Pages = {5364-5369},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Macau, PEOPLES R CHINA, NOV 04-08, 2019},
Abstract = {With the advance in the field of mobile robots, autonomous robots are
   required for long-term deployment in dynamic and complex environments.
   However, the performance of Visual Inertial SLAM systems in long-term
   operation is not satisfactory, and most long-term SLAM systems assumes
   periodic changes in the environment. This paper presents a novel
   solution for long-term monocular VI SLAM system in dynamic environment
   based on autoregression(AR) modeling and map prediction. Map points are
   first classified into static and semi-static map points according to a
   memory model. Modeling and prediction of the different states of
   semi-static map points are performed that are derived from time series
   models. The predicted map is then fused with the current map to achieve
   a better forecast for the next frame if the prediction is not
   satisfactory enough. Experiments are carried out on an embedded system.
   The results indicate that the map prediction is reliable and the
   proposed approach improves the performance of long-term localization and
   mapping in dynamic environments.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Chen, WD (Corresponding Author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   Chen, WD (Corresponding Author), Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China.
   Chen, WD (Corresponding Author), Minist Educ, Key Lab Syst Control \& Informat Proc, Shanghai 200240, Peoples R China.
   Song, Bowen; Chen, Weidong; Wang, Jingwang; Wang, Hesheng, Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   Song, Bowen; Chen, Weidong; Wang, Jingwang; Wang, Hesheng, Shanghai Jiao Tong Univ, Inst Med Robot, Shanghai 200240, Peoples R China.
   Song, Bowen; Chen, Weidong; Wang, Jingwang; Wang, Hesheng, Minist Educ, Key Lab Syst Control \& Informat Proc, Shanghai 200240, Peoples R China.},
ISSN = {2153-0858},
ISBN = {978-1-7281-4004-9},
Keywords-Plus = {MOBILE; AUTONOMY},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods; Robotics},
Author-Email = {kenneth9@sjtu.edu.cn
   wdchen@sjtu.edu.cn
   jchwang@sjtu.edu.cn
   wanghesheng@sjtu.edu.cn},
Affiliations = {Shanghai Jiao Tong University; Shanghai Jiao Tong University},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}U181320, 61573243]},
Funding-Text = {This work is partly supported by the National Natural Science Foundation
   of China under grant U181320 and grant 61573243.},
Cited-References = {AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705.
   Ambrus R, 2014, IEEE INT C INT ROBOT, P1854, DOI 10.1109/IROS.2014.6942806.
   Dayoub F., 2010, P INT S REM WHO WE A, P21.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Grisetti G, 2005, IEEE INT CONF ROBOT, P2432.
   Hahnel D, 2003, ADV ROBOTICS, V17, P579, DOI 10.1163/156855303769156965.
   Hartley R., 2003, MULTIPLE VIEW GEOMET.
   Hochdorfer S., 2009, INTENSIVMED, P1.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Liang NX, 2018, IEEE T MULTIMEDIA, V20, P2289, DOI 10.1109/TMM.2018.2803518.
   Madhavrao Pandit S., 1983, TIME SERIES SYSTEM A.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Mitsou N.C., 2007, CONTR AUT 2007 MED 0, P1.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Quigley M, 2009, ICRA WORKSH OP SOURC, V3, P2.
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X\_15.
   Santos JM, 2017, ROBOT AUTON SYST, V88, P116, DOI 10.1016/j.robot.2016.11.016.
   Stachniss C., 2017, ROBOTICS RES, P271.
   Theodoridis S., 2015, MACHINE LEARNING BAY.
   Ullah S, 2018, IEEE ROMAN, P880, DOI 10.1109/ROMAN.2018.8525794.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.},
Number-of-Cited-References = {24},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BP2QS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000544658404052},
DA = {2022-05-17},
}

@article{ WOS:000353082700004,
Author = {Einhorn, Erik and Gross, Horst-Michael},
Title = {Generic NDT mapping in dynamic environments and its application for
   lifelong SLAM},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2015},
Volume = {69},
Number = {SI},
Pages = {28-39},
Month = {JUL},
Abstract = {In this paper, we present a new, generic approach for Simultaneous
   Localization and Mapping (SLAM). First of all, we propose an abstraction
   of the underlying sensor data using Normal Distribution Transform (NDT)
   maps that are suitable for making our approach independent from the used
   sensor and the dimension of the generated maps. We present several
   modifications for the original NDT mapping to handle free-space
   measurements explicitly. We additionally describe a method to detect and
   handle dynamic objects such as moving persons. This enables the usage of
   the proposed approach in highly dynamic environments. In the second part
   of this paper we describe our graph-based SLAM approach that is designed
   for lifelong usage. Therefore, the memory and computational complexity
   is limited by pruning the pose graph in an appropriate way. (C) 2014
   Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Einhorn, E (Corresponding Author), Ilmenau Univ Technol, Ilmenau, Germany.
   Einhorn, Erik; Gross, Horst-Michael, Ilmenau Univ Technol, Ilmenau, Germany.},
DOI = {10.1016/j.robot.2014.08.008},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Lifelong SLAM; Detection and tracking of moving objects; 20 and 3D
   mapping; Normal Distribution Transform; Occupancy mapping; Map
   registration; Mobile robots},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {Erik.Einhorn@tu-ilmenau.de},
Affiliations = {Technische Universitat Ilmenau},
Funding-Acknowledgement = {German Federal Ministry of Education and Research as part of the ROREAS
   project {[}16SV6133]},
Funding-Text = {This work has received funding from the German Federal Ministry of
   Education and Research as part of the ROREAS project under grant
   agreement no. 16SV6133.},
Cited-References = {Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Brechtel Sebastian, 2010, 2010 IEEE International Conference on Robotics and Automation (ICRA 2010), P3932, DOI 10.1109/ROBOT.2010.5509931.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Einhorn E, 2010, IEEE INT C INT ROBOT, P816, DOI 10.1109/IROS.2010.5651741.
   Einhorn E, 2011, IEEE INT CONF ROBOT, P1843, DOI 10.1109/ICRA.2011.5980084.
   Fairfield N., 2007, J FIELD ROBOTICS.
   Fox D, 2001, ADV NEURAL INFORM PR, V14.
   Frese U, 2010, KUNSTL INTELL, V24, P191, DOI 10.1007/s13218-010-0040-4.
   Frisken S., 2003, J GRAPHICS TOOLS, V7.
   Gindele T, 2009, IEEE INT VEH SYM, P669, DOI 10.1109/IVS.2009.5164357.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Gross H-M, 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2430, DOI 10.1109/IROS.2011.6048377.
   Gross HM, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2005, DOI 10.1109/IROS.2009.5354497.
   Kaess Michael, 2011, 2011 IEEE International Conference on Robotics and Automation, P3281.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968.
   Kretzschmar H, 2010, KUNSTL INTELL, V24, P199, DOI 10.1007/s13218-010-0034-2.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Magnusson M, 2009, THESIS OREBRO U.
   Moravec H, 1996, TECHNICAL REPORT.
   Olesen SM, 2015, J REAL-TIME IMAGE PR, V10, P105, DOI 10.1007/s11554-012-0261-x.
   Park JH, 2012, SENSORS-BASEL, V12, P8640, DOI 10.3390/s120708640.
   Payeur P., 1997, P IEEE INT C ROB AUT.
   Rusinkiewicz S., 2001, INT C 3 D DIG IM MOD.
   Saarinen J, 2013, IEEE INT CONF ROBOT, P2233, DOI 10.1109/ICRA.2013.6630878.
   Saarinen JP, 2013, INT J ROBOT RES, V32, P1627, DOI 10.1177/0278364913499415.
   Schroeter C, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2078, DOI 10.1109/IROS.2008.4651137.
   Stoyanov Todor, 2011, 2011 IEEE International Conference on Robotics and Automation, P4080.
   Stoyanov T, 2012, IEEE INT CONF ROBOT, P5196, DOI 10.1109/ICRA.2012.6224717.
   Stricker R., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P695, DOI 10.1109/ROMAN.2012.6343832.
   Sunderhauf N, 2012, IEEE INT C INT ROBOT, P1879, DOI 10.1109/IROS.2012.6385590.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   WANG CC, 2003, P IEEE INT C ROB AUT.
   Wurm K. M., 2010, P IEEE INT C ROB AUT.},
Number-of-Cited-References = {34},
Times-Cited = {28},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {40},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {CG2CO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000353082700004},
DA = {2022-05-17},
}

@article{ WOS:000756469700001,
Author = {Xing, Zhiwei and Zhu, Xiaorui and Dong, Dingcheng},
Title = {DE-SLAM: SLAM for highly dynamic environment},
Journal = {JOURNAL OF FIELD ROBOTICS},
Abstract = {Simultaneous localization and mapping (SLAM) is crucial for autonomous
   mobile robots. Most of the current SLAM systems are based on an
   assumption: the environment is static. However, the real environment is
   full of dynamic elements, such as pedestrians or vehicles, as well as
   changes in illumination and appearance over time. In this paper,
   DE-SLAM, a visual SLAM system that can deal with short-term and
   long-term dynamic elements at the same time is proposed. A novel dynamic
   detection and tracking module that utilizes both semantic and metric
   information is proposed, and the localization accuracy is highly
   improved by eliminating features falling on the dynamic objects. A
   unified loop detection, loop check and global optimization module is
   used to perform loop closure. Experimental results on datasets and real
   environments show that DE-SLAM outperforms other state-of-the-art SLAM
   systems in dynamic environments.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Zhu, XR (Corresponding Author), Harbin Inst Technol, Sch Mech Engn \& Automat, Shenzhen 518000, Peoples R China.
   Xing, Zhiwei; Zhu, Xiaorui; Dong, Dingcheng, Harbin Inst Technol, Sch Mech Engn \& Automat, Shenzhen 518000, Peoples R China.},
DOI = {10.1002/rob.22062},
EarlyAccessDate = {FEB 2022},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {localization; SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {zhuxiaorui@hotmail.com},
Affiliations = {Harbin Institute of Technology},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018YFB1305500]; Natural Science
   Foundation of China {[}U1813219]},
Funding-Text = {This study was supported by the National Key R\&D Program of China under
   grant 2018YFB1305500 and the Natural Science Foundation of China under
   Grant U1813219.},
Cited-References = {Arroyo R, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P965, DOI 10.1109/ITSC.2016.7795672.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Brasch N, 2018, IEEE INT C INT ROBOT, P393, DOI 10.1109/IROS.2018.8593828.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Chancan M, 2020, IEEE ROBOT AUTOM LET, V5, P993, DOI 10.1109/LRA.2020.2967324.
   Dai WC, 2022, IEEE T PATTERN ANAL, V44, P373, DOI 10.1109/TPAMI.2020.3010942.
   Dalal N., 2005, IEEE COMP SOC C COMP.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Gao P, 2020, IEEE INT CONF ROBOT, P1070, DOI 10.1109/ICRA40945.2020.9196906.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Henein M, 2020, IEEE INT CONF ROBOT, P2123.
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659.
   Klein George, 2007, P1.
   Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0\_15.
   Merrill N, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012.
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781.
   Tzoumas V, 2019, IEEE INT C INT ROBOT, P5383, DOI 10.1109/IROS40897.2019.8968174.
   Wang YB, 2014, I C CONT AUTOMAT ROB, P1841, DOI 10.1109/ICARCV.2014.7064596.
   Yang H, 2020, IEEE ROBOT AUTOM LET, V5, P1127, DOI 10.1109/LRA.2020.2965893.
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691.
   Zhang TW, 2020, IEEE INT CONF ROBOT, P7322.
   Zhao C., 2014, P IEEE INT C MULT EX, P1.
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009.},
Number-of-Cited-References = {28},
Times-Cited = {0},
Usage-Count-Last-180-days = {58},
Usage-Count-Since-2013 = {58},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {ZA9IT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000756469700001},
DA = {2022-05-17},
}

@article{ WOS:000654301300010,
Author = {Tanaka, Kanji},
Title = {Fault-Diagnosing Deep-Visual-SLAM for 3D Change Object Detection},
Journal = {JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT
   INFORMATICS},
Year = {2021},
Volume = {25},
Number = {3},
Pages = {356-364},
Month = {MAY},
Abstract = {Although image change detection (ICD) methods provide good detection
   accuracy for many scenarios, most existing methods rely on
   place-specific background modeling. The time/space cost for such
   place-specific models is prohibitive for large-scale scenarios, such as
   long-term robotic visual simultaneous localization and mapping (SLAM).
   Therefore, we propose a novel ICD framework that is specifically
   customized for long-term SLAM. This study is inspired by the
   multimap-based SLAM framework, where multiple maps can perform mutual
   diagnosis and hence do not require any explicit background
   modeling/model. We extend this multi-map-based diagnosis approach to a
   more generic single-map-based object-level diagnosis framework (i.e.,
   ICD), where the self-localization module of SLAM, which is the change
   object indicator, can be used in its original form. Furthermore, we
   consider map diagnosis on a state-of-the-art deep convolutional neural
   network (DCN)-based SLAM system (instead of on conventional bag-of-words
   or landmark-based systems), in which the blackbox nature of the DCN
   complicates the diagnosis problem. Additionally, we consider a
   three-dimensional point cloud (PC)-based (instead of typical monocular
   color image-based) SLAM and adopt a state-of-the-art scan context PC
   descriptor for map diagnosis for the first time.},
Publisher = {FUJI TECHNOLOGY PRESS LTD},
Address = {1-15-7, UCHIKANDA, CHIYODA-KU, UNIZO UCHIKANDA 1-CHOME BLDG 2F, TOKYO,
   101-0047, JAPAN},
Type = {Article},
Language = {English},
Affiliation = {Tanaka, K (Corresponding Author), Univ Fukui, Grad Sch Engn, 3-9-1 Bunkyo, Fukui, Fukui 9108507, Japan.
   Tanaka, Kanji, Univ Fukui, Grad Sch Engn, 3-9-1 Bunkyo, Fukui, Fukui 9108507, Japan.},
DOI = {10.20965/jaciii.2021.p0356},
ISSN = {1343-0130},
EISSN = {1883-8014},
Keywords = {SLAM; diagnosing; deep neural network; 3D change detection},
Keywords-Plus = {LOCALIZATION; NAVIGATION; MAPS},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Funding-Acknowledgement = {JSPS KAKENHI {[}26330297, 17K00361]},
Funding-Text = {Our work has been supported in part by JSPS KAKENHI Grantin-Aid for
   Scientific Research (C)26330297 and (C)17K00361.},
Cited-References = {Ambrus R, 2014, IEEE INT C INT ROBOT, P1854, DOI 10.1109/IROS.2014.6942806.
   Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Andreasson H, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3435.
   {[}Anonymous], 2019, IEEE INT TRANSP SYST.
   {[}Anonymous], 2019, IEEE INT TRANSP SYST.
   {[}Anonymous], 2019, INT C ROB AUT ICRA.
   {[}Anonymous], 2018, 21 INT C INT TRANSP.
   {[}Anonymous], 2016, IEEE INT C ROB BIOM.
   {[}Anonymous], 2018, IEEE INT C SYST MAN.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040.
   Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   Burgard W., 2012, 26 AAAI C ART INT, P2024.
   Burki Mathias, 2018, 2018 IEEE Intelligent Vehicles Symposium (IV), P682, DOI 10.1109/IVS.2018.8500432.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Christiansen P, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111904.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Erkent O, 2012, IEEE INT CONF ROBOT, P3497, DOI 10.1109/ICRA.2012.6225367.
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614.
   Fehr M, 2016, IEEE INT CONF ROBOT, P2449, DOI 10.1109/ICRA.2016.7487397.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Garcia-Fidalgo Emilio, 2018, IEEE Robotics and Automation Letters, V3, P3051, DOI 10.1109/LRA.2018.2849609.
   Goel P., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2302, DOI 10.1109/ROBOT.2000.846370.
   Gong MG, 2017, IEEE GEOSCI REMOTE S, V14, P2310, DOI 10.1109/LGRS.2017.2762694.
   Gueguen L, 2015, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2015.7298737.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659.
   Imhof M, 2018, INFORM RETRIEVAL J, V21, P81, DOI 10.1007/s10791-017-9322-x.
   Iqbal R, 2019, IEEE T IND INFORM, V15, P3077, DOI 10.1109/TII.2019.2902274.
   Jensfelt P, 2001, IEEE T ROBOTIC AUTOM, V17, P748, DOI 10.1109/70.964673.
   Kim G, 2019, IEEE ROBOT AUTOM LET, V4, P1948, DOI 10.1109/LRA.2019.2897340.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004.
   Kosecka J., 2012, AS C COMP VIS, P590.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Luft L, 2018, IEEE ROBOT AUTOM LET, V3, P1299, DOI 10.1109/LRA.2018.2797317.
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492.
   Manso LJ, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/57360.
   Mason J, 2012, IEEE INT C INT ROBOT, P3851, DOI 10.1109/IROS.2012.6385729.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Morales Y, 2008, IEEE INT CONF ROBOT, P449, DOI 10.1109/ROBOT.2008.4543248.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Osherov E, 2017, IEEE I CONF COMP VIS, P550, DOI 10.1109/ICCV.2017.67.
   Palazzolo E, 2018, IEEE INT CONF ROBOT, P6308.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Paul R, 2014, IEEE INT CONF ROBOT, P1304, DOI 10.1109/ICRA.2014.6907021.
   Pollard T, 2007, PROC CVPR IEEE, P793.
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698.
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91.
   Rueckert E., 2019, EUR C MOB ROB ECMR, P1.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Schuster F, 2016, IEEE INT VEH SYM, P839, DOI 10.1109/IVS.2016.7535485.
   Shah M, 2015, IMAGE VISION COMPUT, V38, P52, DOI 10.1016/j.imavis.2015.02.001.
   Shaik N, 2017, LECT NOTES ARTIF INT, V10505, P249, DOI 10.1007/978-3-319-67190-1\_19.
   Siam M, 2019, IEEE INT CONF ROBOT, P50, DOI 10.1109/ICRA.2019.8794254.
   Simonyan K., 2014, PROC INT C LEARN REP.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sugimoto T., 2019, ARXIV PREPRINT ARXIV.
   Szegedy C, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4278.
   Takuma S, 2018, IEEE INT VEH SYM, P397, DOI 10.1109/IVS.2018.8500475.
   Tanaka K., 2019, ARXIV PREPRINT ARXIV.
   Taneja A, 2015, IEEE T PATTERN ANAL, V37, P2193, DOI 10.1109/TPAMI.2015.2404834.
   Taneja A, 2013, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2013.22.
   Taneja A, 2011, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2011.6126515.
   TAYLOR CJ, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1615, DOI 10.1109/ROBOT.1992.220021.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Tibaldi F., 2010, 41 INT S ROB ISR 6 G, P1.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Tomoya M, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P31, DOI 10.1109/ACPR.2017.21.
   Ulusoy AO, 2014, LECT NOTES COMPUT SC, V8691, P31, DOI 10.1007/978-3-319-10578-9\_3.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687.
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004.
   Wu XL, 2019, IEEE INT CONF ROBOT, P2392, DOI 10.1109/ICRA.2019.8793607.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.
   Zhang C, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P5733.},
Number-of-Cited-References = {79},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Journal-ISO = {J. Adv. Comput. Intell. Inform.},
Doc-Delivery-Number = {SH7GD},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000654301300010},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000381564700050,
Author = {Hidalgo, Franco and Braeunl, Thomas},
Editor = {Bailey, D and Gupta, GS and Demidenko, S},
Title = {Review of Underwater SLAM Techniques},
DOI = {10.1109/ICARA.2015.7081165},
Booktitle = {PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION,
   ROBOTICS AND APPLICATIONS (ICARA)},
Year = {2015},
Pages = {306-311},
Note = {6th International Conference on Automation, Robotics and Applications
   (ICARA), Queenstown, NEW ZEALAND, FEB 17-19, 2015},
Abstract = {SLAM (Simultaneous Localization and Mapping) for underwater vehicles is
   a challenging research topic due to the limitations of underwater
   localization sensors and error accumulation over long-term operations.
   Furthermore, acoustic sensors for mapping often provide noisy and
   distorted images or low-resolution ranging, while video images provide
   highly detailed images but are often limited due to turbidity and
   lighting. This paper presents a review of the approaches used in
   state-of-the-art SLAM techniques: Extended Kalman Filter SLAM
   (EKF-SLAM), FastSLAM, GraphSLAM and its application in underwater
   environments.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Hidalgo, F (Corresponding Author), Univ Western Australia, Sch EECE, Perth, WA, Australia.
   Hidalgo, Franco; Braeunl, Thomas, Univ Western Australia, Sch EECE, Perth, WA, Australia.},
ISBN = {978-1-4799-6466-6},
Keywords = {component: Simultaneous Localization and Mapping (SLAM); Extended Kalman
   Filter (EKF); Particle Filter (PF); FastSLAM; GraphSLAM; Underwater
   Vehicle; AUV},
Keywords-Plus = {LOCALIZATION; NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {franco.hidalgoherencia@research.uwa.edu.au},
Affiliations = {University of Western Australia},
ResearcherID-Numbers = {Hidalgo, Franco/AAX-1689-2020
   },
ORCID-Numbers = {Hidalgo, Franco/0000-0003-0531-6656
   Braunl, Thomas/0000-0003-3215-0161},
Cited-References = {Arulampalam M. S., 2007, TUTORIAL PARTICLE FI, V50, P174.
   Aulinas J, 2010, IEEE INT C INT ROBOT, P2552, DOI 10.1109/IROS.2010.5650438.
   Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644.
   Burguera A, 2011, IEEE INT C INT ROBOT, P3577, DOI 10.1109/IROS.2011.6048431.
   Daum F, 2005, IEEE AERO EL SYS MAG, V20, P57, DOI 10.1109/MAES.2005.1499276.
   Doucet A., 1998, SEQUENTIAL SIMULATIO.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Fallon MF, 2013, IEEE J OCEANIC ENG, V38, P500, DOI 10.1109/JOE.2012.2235664.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Gustafsson F, 2010, IEEE AERO EL SYS MAG, V25, P53, DOI 10.1109/MAES.2010.5546308.
   He B, 2012, SENSORS-BASEL, V12, P9386, DOI 10.3390/s120709386.
   He B, 2009, IEEE INT VEH SYM, P459, DOI 10.1109/IVS.2009.5164321.
   Hiebert-Treuer B., 2007, BACHELOR ARTS COMPUT.
   Jaulin L, 2009, IEEE T ROBOT, V25, P88, DOI 10.1109/TRO.2008.2010358.
   Johannsson H, 2010, IEEE INT C INT ROBOT, P4396, DOI 10.1109/IROS.2010.5650831.
   Khong WL, 2012, UKSIM EURO SYMP COMP, P243, DOI 10.1109/EMS.2012.72.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Koh A. C. T., 2009, OCEANS 2009, P1.
   Latif D. M. A., 2013, P 4 EUR C COMP SCI E, P288.
   Lee D, 2013, INT CONF UBIQ ROBOT, P526, DOI 10.1109/URAI.2013.6677329.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Mahon I, 2008, IEEE T ROBOT, V24, P1002, DOI 10.1109/TRO.2008.2004888.
   Mallios A., 2010, P OCEANS IEEE SYDNEY, P1.
   Maskell S., 2001, TUTORIAL PARTOCLE FI.
   Montemerlo M, 2003, IEEE INT CONF ROBOT, P1985, DOI 10.1109/ROBOT.2003.1241885.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Ribas D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1461.
   Ribas D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5040, DOI 10.1109/IROS.2006.282532.
   Ruiz IT, 2004, IEEE J OCEANIC ENG, V29, P442, DOI 10.1109/JOE.2004.829790.
   Siegwart R., 2004, INTRO AUTONOMOUS MOB, V23, P47.
   Stachniss C., 2013, AUTONOME INTELLIGENT.
   Thrun S., 2005, PROBABILISTIC ROBOTI, P647.
   Walter M, 2008, IEEE INT CONF ROBOT, P1463, DOI 10.1109/ROBOT.2008.4543408.
   Yan J., 2009, 2009 INT FORUM INF T, V2, P435.},
Number-of-Cited-References = {35},
Times-Cited = {28},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {25},
Doc-Delivery-Number = {BF4QD},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000381564700050},
DA = {2022-05-17},
}

@article{ WOS:000346070400007,
Author = {Carlevaris-Bianco, Nicholas and Kaess, Michael and Eustice, Ryan M.},
Title = {Generic Node Removal for Factor-Graph SLAM},
Journal = {IEEE TRANSACTIONS ON ROBOTICS},
Year = {2014},
Volume = {30},
Number = {6},
Pages = {1371-1385},
Month = {DEC},
Abstract = {This paper reports on a generic factor-based method for node removal in
   factor-graph simultaneous localization and mapping (SLAM), which we call
   generic linear constraints (GLCs). The need for a generic node removal
   tool is motivated by long-term SLAM applications, whereby nodes are
   removed in order to control the computational cost of graph
   optimization. GLC is able to produce a new set of linearized factors
   over the elimination clique that can represent either the true
   marginalization (i.e., dense GLC) or a sparse approximation of the true
   marginalization using a Chow-Liu tree (i.e., sparse GLC). The proposed
   algorithm improves upon commonly used methods in two key ways: First, it
   is not limited to graphs with strictly full-state relative-pose factors
   and works equally well with other low-rank factors, such as those
   produced by monocular vision. Second, the new factors are produced in
   such a way that accounts for measurement correlation, which is a problem
   encountered in other methods that rely strictly upon pairwise
   measurement composition. We evaluate the proposed method over multiple
   real-world SLAM graphs and show that it outperforms other recently
   proposed methods in terms of Kullback-Leibler divergence. Additionally,
   we experimentally demonstrate that the proposed GLC method provides a
   principled and flexible tool to control the computational complexity of
   long-term graph SLAM, with results shown for 34.9 h of real-world
   indoor-outdoor data covering 147.4 km collected over 27 mapping sessions
   spanning a period of 15 months.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Carlevaris-Bianco, N (Corresponding Author), Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Carlevaris-Bianco, Nicholas, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Kaess, Michael, Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Eustice, Ryan M., Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
DOI = {10.1109/TRO.2014.2347571},
ISSN = {1552-3098},
EISSN = {1941-0468},
Keywords = {Factor-graphs; long-term autonomy; marginalization; mobile robotics;
   simultaneous localization and mapping (SLAM)},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; POSE GRAPHS; INFORMATION; ALIGNMENT; FILTERS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {carlevar@umich.edu
   kaess@cmu.edu
   eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; Carnegie Mellon
   University; University of Michigan System; University of Michigan},
ORCID-Numbers = {Kaess, Michael/0000-0002-7590-3357
   Eustice, Ryan/0000-0002-9989-4942},
Funding-Acknowledgement = {National Science Foundation {[}IIS-0746455]; Office of Naval Research
   {[}N00014-12-1-0092, N00014-12-1-0093]; Naval Sea Systems Command
   through the Naval Engineering Education Center {[}N65540-10-C-0003]},
Funding-Text = {This work was supported in part by the National Science Foundation under
   Award IIS-0746455, by the Office of Naval Research under Award
   N00014-12-1-0092 and Award N00014-12-1-0093, and by the Naval Sea
   Systems Command through the Naval Engineering Education Center under
   Award N65540-10-C-0003. This paper was presented in part at the 2013
   IEEE International Conference on Robotics and Automation {[}1] and at
   the 2013 IEEE/RSJ International Conference on Intelligent Robots and
   Systems {[}2].},
Cited-References = {Carlevaris-Bianco N, 2014, IEEE INT CONF ROBOT, P854, DOI 10.1109/ICRA.2014.6906954.
   Carlevaris-Bianco N, 2013, IEEE INT C INT ROBOT, P1034, DOI 10.1109/IROS.2013.6696478.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Cunningham A., 2013, P IEEE INT C ROB AUT, P5200.
   Davison AJ, 2005, IEEE I CONF COMP VIS, P66.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Eustice R., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3281.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Folkesson J, 2004, IEEE INT CONF ROBOT, P383, DOI 10.1109/ROBOT.2004.1307180.
   FRESE U, 2004, SPATIAL COGNITION, V4.
   Frese U, 2007, IEEE INT CONF ROBOT, P4814, DOI 10.1109/ROBOT.2007.364221.
   Friedman N., 2009, PROBABILISTIC GRAPHI.
   Hover FS, 2012, INT J ROBOT RES, V31, P1445, DOI 10.1177/0278364912461059.
   Huang GQ, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P150, DOI 10.1109/ECMR.2013.6698835.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kaess M., 2010, OPEN SOURCE IMPLEMEN.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Magnusson M., 2009, THESIS.
   Mazuran M., 2014, ROBOTICS SCI SYSTEMS, P1.
   MINKA T, 2001, INFERRING GAUSSIAN D.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Ozog P, 2014, IEEE INT CONF ROBOT, P3832, DOI 10.1109/ICRA.2014.6907415.
   Rao C., 1971, GEN INVERSE MATRICES.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Vial J, 2011, IEEE INT C INT ROBOT, P886, DOI 10.1109/IROS.2011.6048728.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Walter MR, 2007, INT J ROBOT RES, V26, P335, DOI 10.1177/0278364906075026.
   Wang Y, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P32, DOI 10.1109/ECMR.2013.6698816.},
Number-of-Cited-References = {40},
Times-Cited = {47},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {25},
Journal-ISO = {IEEE Trans. Robot.},
Doc-Delivery-Number = {AW1SO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000346070400007},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000425113800010,
Author = {Arroyo, Roberto and Alcantarilla, Pablo F. and Bergasa, Luis M. and
   Romera, Eduardo},
Title = {Are you ABLE to perform a life-long visual topological localization?},
Journal = {AUTONOMOUS ROBOTS},
Year = {2018},
Volume = {42},
Number = {3},
Pages = {665-685},
Month = {MAR},
Abstract = {Visual topological localization is a process typically required by
   varied mobile autonomous robots, but it is a complex task if long
   operating periods are considered. This is because of the appearance
   variations suffered in a place: dynamic elements, illumination or
   weather. Due to these problems, long-term visual place recognition
   across seasons has become a challenge for the robotics community. For
   this reason, we propose an innovative method for a robust and efficient
   life-long localization using cameras. In this paper, we describe our
   approach (ABLE), which includes three different versions depending on
   the type of images: monocular, stereo and panoramic. This distinction
   makes our proposal more adaptable and effective, because it allows to
   exploit the extra information that can be provided by each type of
   camera. Besides, we contribute a novel methodology for identifying
   places, which is based on a fast matching of global binary descriptors
   extracted from sequences of images. The presented results demonstrate
   the benefits of using ABLE, which is compared to the most representative
   state-of-the-art algorithms in long-term conditions.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Arroyo, R (Corresponding Author), Univ Alcala UAH, Dept Elect, Madrid 28871, Spain.
   Arroyo, Roberto; Bergasa, Luis M.; Romera, Eduardo, Univ Alcala UAH, Dept Elect, Madrid 28871, Spain.
   Alcantarilla, Pablo F., iRobot Corp, 10 Greycoat Pl, London, England.},
DOI = {10.1007/s10514-017-9664-7},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Localization across seasons; Visual place recognition; Loop closure
   detection; Image matching; Binary descriptors},
Keywords-Plus = {ROBUST PLACE RECOGNITION; LOOP CLOSURE; FAB-MAP; IMAGE FEATURES; SLAM;
   VISION; BINARY; SCALE; GIST},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {roberto.arroyo@depeca.uah.es
   palcantarilla@irobot.com
   luism.bergasa@uah.es
   eduardo.romera@depeca.uah.es},
Affiliations = {Universidad de Alcala},
ResearcherID-Numbers = {Bergasa, Luis M./H-9810-2013
   },
ORCID-Numbers = {Bergasa, Luis M./0000-0002-0087-3077
   Fernandez Alcantarilla, Pablo/0000-0001-7185-2911},
Funding-Acknowledgement = {Spanish MINECO through the SmartElderlyCar project
   {[}TRA2015-70501-C2-1-R]; RoboCity2030-III-CM project (Robotica aplicada
   a la mejora de la calidad de vida de los ciudadanos. fase III)
   {[}S2013/MIT-2748]; Programas de actividades I+D (CAM); EU Structural
   Funds},
Funding-Text = {This work has been funded in part from the Spanish MINECO through the
   SmartElderlyCar project (TRA2015-70501-C2-1-R) and from the
   RoboCity2030-III-CM project (Robotica aplicada a la mejora de la calidad
   de vida de los ciudadanos. fase III; S2013/MIT-2748), funded by
   Programas de actividades I+D (CAM) and cofunded by EU Structural Funds.},
Cited-References = {Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715.
   Alcantarilla P., 2016, P ROB SCI SYST, DOI {[}10.15607/RSS.2016.XII.044, DOI 10.15607/RSS.2016.XII.044].
   Alcantarilla PF, 2013, AUTON ROBOT, V34, P47, DOI 10.1007/s10514-012-9312-1.
   Arroyo R, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P965, DOI 10.1109/ITSC.2016.7795672.
   Arroyo R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4656, DOI 10.1109/IROS.2016.7759685.
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Arroyo R, 2014, IEEE INT C INT ROBOT, P3089, DOI 10.1109/IROS.2014.6942989.
   Arroyo R, 2014, IEEE INT VEH SYM, P1378, DOI 10.1109/IVS.2014.6856457.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Cadena C, 2010, IEEE INT C INT ROBOT, P5182, DOI 10.1109/IROS.2010.5650234.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Campos FM, 2013, LECT NOTES ARTIF INT, V8154, P247, DOI 10.1007/978-3-642-40669-0\_22.
   Caramazana L., 2016, OP C FUT TRENDS ROB, P97.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Ceriani S, 2009, AUTON ROBOT, V27, P353, DOI 10.1007/s10514-009-9156-5.
   Clemente L.A., 2007, P ROB SCI SYST, P297.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Cummins M, 2010, IEEE T ROBOT, V26, P1042, DOI 10.1109/TRO.2010.2080390.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Drouilly R, 2015, IEEE INT CONF ROBOT, P1106, DOI 10.1109/ICRA.2015.7139314.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Erkent O, 2015, IEEE INT CONF ROBOT, P5462, DOI 10.1109/ICRA.2015.7139962.
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2.
   Garcia-Fidalgo E, 2015, ROBOT AUTON SYST, V64, P1, DOI 10.1016/j.robot.2014.11.009.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6\_3.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Korrapati H, 2017, AUTON ROBOT, V41, P967, DOI 10.1007/s10514-016-9560-6.
   Korrapati H, 2013, IEEE INT C INT ROBOT, P3684, DOI 10.1109/IROS.2013.6696882.
   Lee GH, 2014, IEEE INT CONF ROBOT, P1510, DOI 10.1109/ICRA.2014.6907052.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Liu Y, 2012, IEEE INT C INT ROBOT, P1051, DOI 10.1109/IROS.2012.6386145.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S., 2015, WORKSH VIS PLAC REC.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lv Q, 2007, VLDB, DOI DOI 10.1145/1143844.1143857.
   Masatoshi A, 2015, IEEE INT CONF ROBOT, P5455, DOI 10.1109/ICRA.2015.7139961.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   Milford M., 2012, P 2012 ROB SCI SYST, P297, DOI {[}10.15607/RSS.2012.VIII.038, DOI 10.15607/RSS.2012.VIII.038].
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mohan M, 2015, IEEE INT CONF ROBOT, P5487, DOI 10.1109/ICRA.2015.7139966.
   Mousavian A, 2015, IEEE INT CONF ROBOT, P4882, DOI 10.1109/ICRA.2015.7139877.
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60.
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murillo AC, 2013, IEEE T ROBOT, V29, P146, DOI 10.1109/TRO.2012.2220211.
   Carrasco PLN, 2016, AUTON ROBOT, V40, P1403, DOI 10.1007/s10514-015-9522-4.
   Nelson P, 2015, IEEE INT CONF ROBOT, P5245, DOI 10.1109/ICRA.2015.7139930.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4.
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2.
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Pepperell E, 2015, IEEE INT CONF ROBOT, P1118, DOI 10.1109/ICRA.2015.7139316.
   Pepperell E, 2014, IEEE INT CONF ROBOT, P1612, DOI 10.1109/ICRA.2014.6907067.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N., 2013, WORKSH LONG TERM AUT.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Upcroft B, 2014, IEEE INT CONF ROBOT, P1712, DOI 10.1109/ICRA.2014.6907082.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Williams B, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2053, DOI 10.1109/IROS.2008.4650996.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150.},
Number-of-Cited-References = {81},
Times-Cited = {14},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {FW2DY},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000425113800010},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000320598900020,
Author = {Anwar, Shahzad and Zhao, Qingjie and Qadeer, Nouman and Khan, Saqib
   Ishaq},
Editor = {Munir, A and Khan, AM and ZafarUzZaman, M and Samar, R and Mughal, MA and Abbasi, AA and Raza, A and Rafique, M and Durrani, N and Aslam, M and Abbas, SA and Majid, I and Ahsan, N},
Title = {A Framework for RF-Visual SLAM},
DOI = {10.1109/IBCAST.2013.6512139},
Booktitle = {2013 10TH INTERNATIONAL BHURBAN CONFERENCE ON APPLIED SCIENCES AND
   TECHNOLOGY (IBCAST)},
Series = {International Bhurban Conference on Applied Sciences and Technology},
Year = {2013},
Pages = {103-108},
Note = {10th International Bhurban Conference on Applied Science and Technology
   (IBCAST), Natl Ctr Phys, Islamabad, PAKISTAN, JAN 15-19, 2013},
Abstract = {Simultaneous Localization and Mapping, SLAM, is an important topic in
   the field of robotics and autonomous navigation. The metric SLAM suffers
   from sensor inaccuracies and thus cannot be used for long-term
   navigation. In such case, Visual SLAM or a Hybrid SLAM based on both
   metric and visual approach is a good alternative. In this paper, in
   order to speed up a Visual SLAM, we propose a novel concept of dynamic
   dictionary generated on the results of triangulation done on RF, radio
   frequency, signals from nearest cell towers of a cellular network. This
   dynamic dictionary efficiently manages the scalability of a Visual SLAM
   and make it possible to work in a large-scale environment. A framework
   is proposed along with triangulation data of a city and with simulations
   to support the concept.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Anwar, S (Corresponding Author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
   Anwar, Shahzad; Zhao, Qingjie; Qadeer, Nouman, Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.},
ISSN = {2151-1403},
ISBN = {978-1-4673-4426-5; 978-1-4673-4425-8},
Keywords-Plus = {LOOP-CLOSURE DETECTION; SIMULTANEOUS LOCALIZATION},
Research-Areas = {Engineering; Materials Science; Telecommunications},
Web-of-Science-Categories  = {Engineering, Aerospace; Engineering, Marine; Engineering, Electrical \&
   Electronic; Materials Science, Multidisciplinary; Telecommunications},
Author-Email = {malikanwer@gmail.com
   zhaoqj@bit.edu.cn
   noumansoomro@gmail.com
   sikhan@gamil.com},
Affiliations = {Beijing Institute of Technology},
ORCID-Numbers = {Soomro, Nouman Qadeer/0000-0003-0589-1028
   Anwar, Shahzad/0000-0002-1023-9846},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bolla R., 2000, WIR COMM NETW C 2000.
   Bruno L., 2011, P INT C IND POS IND, P1, DOI DOI 10.1109/IPIN.2011.6071916.
   Burgard W., 1999, MACHINE LEARNING.
   Calabrese F., 2010, IEEE T INTELLIGENT T.
   Challa S., 2005, INT SENS SENS NETW I.
   Chen ZH, 2007, ADV ROBOTICS, V21, P233, DOI 10.1163/156855307780132081.
   Cummins M, 2008, IEEE INT CONF ROBOT, P1828, DOI 10.1109/ROBOT.2008.4543473.
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615.
   Fink J, 2010, IEEE INT CONF ROBOT, P1940, DOI 10.1109/ROBOT.2010.5509574.
   Guivant J., 2001, ROBOTICS AUTOMATION, P1.
   Kawewong A., 2010, THESIS TOKYO I TECHN.
   Kawewong A, 2011, ROBOT AUTON SYST, V59, P727, DOI 10.1016/j.robot.2011.05.007.
   Kawewong A, 2011, INT J ROBOT RES, V30, P33, DOI 10.1177/0278364910371855.
   Kummerle R, 2011, AUTON ROBOT, V30, P25, DOI 10.1007/s10514-010-9204-1.
   LEONARD J, 2003, P INT JOINT C ART IN, P1143.
   Lovell DJ, 2001, ITS J, V6, P303.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   McGeough J., 2002, WIRELESS LOCATION PO, P1.
   Montemerlo M., 2003, FASTSLAM 2 0 IMPROVE.
   Muja M., 2009, C COMP VIS THEOR.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Pfingsthorn M., 2008, LECT NOTES COMPUTER.
   Ribas D., 2008, J FIELD ROBOT, V24, P1.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   Shahbazi H, 2011, IEEE INT C INT ROBOT, P1228, DOI 10.1109/IROS.2011.6048862.
   SMITH B, 2001, P 11 ANN M ITS AM MI.
   Thrun S., 2002, MORGAN KAUFMANN SERI.
   Ygnace J. L., 2000, TRAVELTIME ESTIMATES.},
Number-of-Cited-References = {32},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BFN28},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000320598900020},
DA = {2022-05-17},
}

@article{ WOS:000374846000002,
Author = {Ozog, Paul and Carlevaris-Bianco, Nicholas and Kim, Ayoung and Eustice,
   Ryan M.},
Title = {Long-term Mapping Techniques for Ship Hull Inspection and Surveillance
   using an Autonomous Underwater Vehicle},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2016},
Volume = {33},
Number = {3, 1, SI},
Pages = {265-289},
Month = {MAY},
Abstract = {This paper reports on a system for an autonomous underwater vehicle to
   perform in situ, multiple session hull inspection using long-term
   simultaneous localization and mapping (SLAM). Our method assumes very
   little a priori knowledge, and it does not require the aid of acoustic
   beacons for navigation, which is a typical mode of navigation in this
   type of application. Our system combines recent techniques in underwater
   saliency-informed visual SLAM and a method for representing the ship
   hull surface as a collection of many locally planar surface features.
   This methodology produces accurate maps that can be constructed in
   real-time on consumer-grade computing hardware. A single-session SLAM
   result is initially used as a prior map for later sessions, where the
   robot automatically merges the multiple surveys into a common
   hull-relative reference frame. To perform the relocalization step, we
   use a particle filter that leverages the locally planar representation
   of the ship hull surface, and a fast visual descriptor matching
   algorithm. Finally, we apply the recently developed graph sparsification
   tool, generic linear constraints, as a way to manage the computational
   complexity of the SLAM system as the robot accumulates information
   across multiple sessions. We show results for 20 SLAM sessions for two
   large vessels over the course of days, months, and even up to three
   years, with a total path length of approximately 10.2 km.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Eustice, RM (Corresponding Author), Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.
   Ozog, Paul; Carlevaris-Bianco, Nicholas, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Kim, Ayoung, Korea Adv Inst Sci \& Technol, Dept Civil \& Environm Engn, Daejeon, South Korea.
   Eustice, Ryan M., Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
DOI = {10.1002/rob.21582},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; DATA ASSOCIATION; POSE GRAPHS; INFORMATION;
   NAVIGATION; SLAM; SYSTEM; MAP; SAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {paulozog@umich.edu
   carlevar@umich.edu
   ayoungk@kaist.ac.kr
   eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; Korea Advanced
   Institute of Science \& Technology (KAIST); University of Michigan
   System; University of Michigan},
Funding-Acknowledgement = {Office of Naval Research {[}N00014-12-1-0092]},
Funding-Text = {This work was supported by the Office of Naval Research under award
   N00014-12-1-0092.},
Cited-References = {Agarwal P, 2013, IEEE INT CONF ROBOT, P62, DOI 10.1109/ICRA.2013.6630557.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Belcher E, 2001, OCEANS 2001 MTS/IEEE: AN OCEAN ODYSSEY, VOLS 1-4, CONFERENCE PROCEEDINGS, P6, DOI 10.1109/OCEANS.2001.968656.
   Bonnin-Pascual F, 2010, FRONT ARTIF INTEL AP, V220, P111, DOI 10.3233/978-1-60750-643-0-111.
   Boon B., 2009, INT SHIP OFFSH STRUC, V2, P313.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Bowen A. D., 2009, P IEEE MTS OCEANS C, P1, DOI DOI 10.23919/OCEANS.2009.5422311.
   Carlevaris-Bianco Nicholas, 2011, IEEE International Conference on Robotics and Automation, P423.
   Carlevaris-Bianco N, 2014, IEEE INT CONF ROBOT, P854, DOI 10.1109/ICRA.2014.6906954.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   Carvalho AA, 2003, APPL OCEAN RES, V25, P235, DOI 10.1016/j.apor.2004.02.004.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Eustice RM, 2008, IEEE J OCEANIC ENG, V33, P103, DOI 10.1109/JOE.2008.923547.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Grisetti G., 2007, ROBOTICS SCI SYSTEMS, V3, P65.
   Gustafson E., 2011, POL PETR POT C EXH, P714.
   Harris SE, 1999, OCEANS `99 MTS/IEEE : RIDING THE CREST INTO THE 21ST CENTURY, VOLS 1-3, P493, DOI 10.1109/OCEANS.1999.799792.
   Hover FS, 2007, MAR TECHNOL SOC J, V41, P44, DOI 10.4031/002533207787442196.
   Hover FS, 2012, INT J ROBOT RES, V31, P1445, DOI 10.1177/0278364912461059.
   Ishizu Kensei, 2012, 2012 OCEANS YEOSU, P1.
   Johannsson H, 2010, IEEE INT C INT ROBOT, P4396, DOI 10.1109/IROS.2010.5650831.
   Julier SJ, 2002, P AMER CONTR CONF, V1-6, P4555, DOI 10.1109/ACC.2002.1025369.
   Kaess M., 2010, OPEN SOURCE IMPLEMEN.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kim A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1559, DOI 10.1109/IROS.2009.5354132.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Kunz C, 2009, J FIELD ROBOT, V26, P411, DOI 10.1002/rob.20288.
   Leonard J., 1999, P INT S ROB RES SALT.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Menegaldo LL, 2008, AMC `08: 10TH INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P27.
   Menegaldo LL, 2009, IEEE T IND ELECTRON, V56, P3717, DOI 10.1109/TIE.2009.2025716.
   Milne P. H., 1983, UNDERWATER ACOUSTIC.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Negahdaripour S, 2006, IEEE J OCEANIC ENG, V31, P551, DOI 10.1109/JOE.2005.851391.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Ni K, 2007, IEEE INT CONF ROBOT, P1678, DOI 10.1109/ROBOT.2007.363564.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Ozog P, 2014, IEEE INT CONF ROBOT, P3832, DOI 10.1109/ICRA.2014.6907415.
   Ozog P, 2013, IEEE INT C INT ROBOT, P1042, DOI 10.1109/IROS.2013.6696479.
   Ozog P, 2013, IEEE INT CONF ROBOT, P3777, DOI 10.1109/ICRA.2013.6631108.
   Pizarro O, 2009, IEEE J OCEANIC ENG, V34, P150, DOI 10.1109/JOE.2009.2016071.
   Ridao P, 2010, J FIELD ROBOT, V27, P759, DOI 10.1002/rob.20351.
   Roman C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2422, DOI 10.1109/IROS.2005.1545340.
   Segal A., 2009, P ROB SCI SYST C SEA.
   Singh H., 2004, SUBSURF SENS TECHNOL, V5, P25, DOI {[}10.1023/B:SSTA.0000018445.25977.f3, DOI 10.1023/B:SSTA.0000018445.25977.F3].
   Smith R., 1986, P 2 C ANN C UNC ART, P267.
   Sunderhauf N, 2012, IEEE INT C INT ROBOT, P1879, DOI 10.1109/IROS.2012.6385590.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Trevor AJB, 2012, IEEE INT CONF ROBOT, P3041, DOI 10.1109/ICRA.2012.6225287.
   Trimble GM, 2002, OCEANS 2002 MTS/IEEE CONFERENCE \& EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS, P1172.
   VanMiddlesworth M, 2013, C FIELD SERV ROB FSR, P17.
   Walter M, 2008, IEEE INT CONF ROBOT, P1463, DOI 10.1109/ROBOT.2008.4543408.
   Weingarten J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3062, DOI 10.1109/IROS.2006.282245.},
Number-of-Cited-References = {62},
Times-Cited = {37},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {27},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {DK3VR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000374846000002},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000458335100006,
Author = {Labbe, Mathieu and Michaud, Francois},
Title = {RTAB-Map as an open-source lidar and visual simultaneous localization
   and mapping library for large-scale and long-term online operation},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2019},
Volume = {36},
Number = {2},
Pages = {416-446},
Month = {MAR},
Abstract = {Distributed as an open-source library since 2013, real-time
   appearance-based mapping (RTAB-Map) started as an appearance-based loop
   closure detection approach with memory management to deal with
   large-scale and long-term online operation. It then grew to implement
   simultaneous localization and mapping (SLAM) on various robots and
   mobile platforms. As each application brings its own set of constraints
   on sensors, processing capabilities, and locomotion, it raises the
   question of which SLAM approach is the most appropriate to use in terms
   of cost, accuracy, computation power, and ease of integration. Since
   most of SLAM approaches are either visual- or lidar-based, comparison is
   difficult. Therefore, we decided to extend RTAB-Map to support both
   visual and lidar SLAM, providing in one package a tool allowing users to
   implement and compare a variety of 3D and 2D solutions for a wide range
   of applications with different robots and sensors. This paper presents
   this extended version of RTAB-Map and its use in comparing, both
   quantitatively and qualitatively, a large selection of popular
   real-world datasets (e.g., KITTI, EuRoC, TUM RGB-D, MIT Stata Center on
   PR2 robot), outlining strengths, and limitations of visual and lidar
   SLAM configurations from a practical perspective for autonomous
   navigation applications.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Labbe, M (Corresponding Author), Univ Sherbrooke, Interdisciplinary Inst Technol Innovat 3IT, Dept Elect Engn \& Comp Engn, Sherbrooke, PQ J1K 0A5, Canada.
   Labbe, Mathieu; Michaud, Francois, Univ Sherbrooke, Interdisciplinary Inst Technol Innovat 3IT, Dept Elect Engn \& Comp Engn, Sherbrooke, PQ J1K 0A5, Canada.},
DOI = {10.1002/rob.21831},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {perception; position estimation; SLAM},
Keywords-Plus = {SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {Mathieu.M.Labbe@USherbrooke.ca},
Affiliations = {University of Sherbrooke},
ORCID-Numbers = {Michaud, Francois/0000-0002-3639-7770
   Labbe, Mathieu/0000-0003-0778-5595},
Funding-Acknowledgement = {Natural Sciences and Engineering Research Council of Canada},
Funding-Text = {Natural Sciences and Engineering Research Council of Canada},
Cited-References = {Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Bradski G., 2008, LEARNING OPENCV.
   Burhanpurkar M, 2017, INT C REHAB ROBOT, P1079, DOI 10.1109/ICORR.2017.8009393.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Calonder M., 2010, P EUR C COMP VIS ECC.
   Carlone L, 2012, ROBOTICS: SCIENCE AND SYSTEMS VII, P41.
   Chen YF, 2015, LECT NOTES ARTIF INT, V9513, P60, DOI 10.1007/978-3-319-29339-4\_5.
   Cvisic I, 2018, J FIELD ROBOT, V35, P578, DOI 10.1002/rob.21762.
   Dai A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3054739.
   Della Corte B., 2017, GEN FRAMEWORK FLEXIB.
   Dellaert F., 2012, GTRIMCPR2012002 GEOR.
   Dube R., 2016, SEGMATCH SEGMENT BAS.
   Dube R, 2017, IEEE INT C INT ROBOT, P1004, DOI 10.1109/IROS.2017.8202268.
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412.
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Fallon M, 2013, INT J ROBOT RES, V32, P1695, DOI 10.1177/0278364913509035.
   Foote T., 2013, TECHN PRACT ROB APPL, P1, DOI DOI 10.1109/TEPRA.2013.6556373.
   Foresti H., 2016, EMOTIVE ROBOTICS I Z.
   Forster C., 2014, P IEEE INT C ROB AUT.
   Fox D, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P343.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A., 2011, P INT VEH S BAD BAD.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Goebel P., 2014, WINNING IROS 2014 MI.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Gutierrez-Gomez D, 2016, ROBOT AUTON SYST, V75, P571, DOI 10.1016/j.robot.2015.09.026.
   Harmat A, 2015, J INTELL ROBOT SYST, V78, P291, DOI 10.1007/s10846-014-0085-y.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Huang A. S., 2011, P INT S ROB RES FLAG.
   Kahler O, 2016, LECT NOTES COMPUT SC, V9912, P500, DOI 10.1007/978-3-319-46484-8\_30.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Klein G., 2000, P IEEE ACM INT S MIX.
   Kohlbrecher S., 2016, ROBOCUP RESCUE 2016.
   Kohlbrecher S, 2011, P IEEE INT S SAF SEC.
   Konolige K., 1998, Robotics Research. Eighth International Symposium, P203.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Labbe M., 2017, AUTONOMOUS ROBOTS.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Laniel Sebastien, 2017, IEEE Int Conf Rehabil Robot, V2017, P809, DOI 10.1109/ICORR.2017.8009347.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Lin Y, 2018, J FIELD ROBOT, V35, P23, DOI 10.1002/rob.21732.
   Liu Peidong, 2018, P IEEE INT C ROB AUT.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lucas B. D., 1981, INT JOINT C ART INT, V2, P674, DOI DOI 10.5555/1623264.1623280.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   Moore T, 2014, P INT C INT AUT SYST.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Pire T, 2017, ROBOT AUTON SYST, V93, P27, DOI 10.1016/j.robot.2017.03.019.
   Pizzoli M., 2014, P IEEE INT C ROB AUT.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Quigley M., 2009, P IEEE INT C ROB AUT.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Schlegel D., 2017, PROSLAM GRAPH SLAM P.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Stachniss C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1153.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Steux B, 2010, I C CONT AUTOMAT ROB, P1975, DOI 10.1109/ICARCV.2010.5707402.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Sun K, 2018, IEEE ROBOT AUTOM LET, V3, P965, DOI 10.1109/LRA.2018.2793349.
   Thrun S., 2002, EXPLOR ARTIF INTELL, V1-35, P1.
   Vincent R, 2010, P SOC PHOTO-OPT INS, V7664, DOI 10.1117/12.849593.
   Whelan T, 2016, INT J ROBOT RES, V35, P1697, DOI 10.1177/0278364916669237.
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008.
   Xu W, 2010, PROC CVPR IEEE, P263, DOI 10.1109/CVPR.2010.5540202.
   Yun DS, 2014, I C INF COMM TECH CO, P609, DOI 10.1109/ICTC.2014.6983225.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.
   Zollhofer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386.},
Number-of-Cited-References = {79},
Times-Cited = {163},
Usage-Count-Last-180-days = {33},
Usage-Count-Since-2013 = {155},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {HK9TP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000458335100006},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000377221103127,
Author = {Ozog, Paul and Eustice, Ryan M.},
Book-Group-Author = {IEEE},
Title = {Toward Long-term, Automated Ship Hull Inspection with Visual SLAM,
   Explicit Surface Optimization, and Generic Graph-Sparsification},
DOI = {10.1109/ICRA.2014.6907415}, 
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2014},
Pages = {3832-3839},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014},
Abstract = {This paper reports on a method for an autonomous underwater vehicle to
   perform real-time visual simultaneous localization and mapping (SLAM) on
   large ship hulls over multiple sessions. Along with a monocular camera,
   our method uses a piecewise-planar model to explicitly optimize the ship
   hull surface in our factor-graph framework, and anchor nodes to
   co-register multiple surveys. To enable realtime performance for
   long-term SLAM, we use the recent Generic Linear Constraints (GLC)
   framework to sparsify our factor-graph. This paper analyzes how our
   single-session SLAM techniques can be used in the GLC framework, and
   describes a particle filter reacquisition algorithm so that an
   underwater session can be automatically re-localized to a previously
   built SLAM graph. We provide real-world experimental results involving
   automated ship hull inspection, and show that our localization filter
   out-performs Fast Appearance-Based Mapping (FAB-MAP), a popular
   place-recognition system. Using our approach, we can automatically align
   surveys that were taken days, months, and even years apart.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ozog, P (Corresponding Author), Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Ozog, Paul, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M., Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-3685-4},
Keywords-Plus = {POSE GRAPHS; SYSTEM},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {paulozog@umich.edu
   eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan},
ORCID-Numbers = {Eustice, Ryan/0000-0002-9989-4942},
Cited-References = {Carlevaris-Bianco N., 2013, P IEEE RSJ IN PRESS.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   Carvalho AA, 2003, APPL OCEAN RES, V25, P235, DOI 10.1016/j.apor.2004.02.004.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Hover FS, 2012, INT J ROBOT RES, V31, P1445, DOI 10.1177/0278364912461059.
   Ishizu Kensei, 2012, 2012 OCEANS YEOSU, P1.
   Kaess M., 2010, OPEN SOURCE IMPLEMEN.
   Kaess M., 2010, P INT S TECH MIN PRO.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Negahdaripour S, 2006, IEEE J OCEANIC ENG, V31, P551, DOI 10.1109/JOE.2005.851391.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Ozog P., 2013, P IEEE RSJ IN PRESS.
   Ridao P, 2010, J FIELD ROBOT, V27, P759, DOI 10.1002/rob.20351.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Trevor AJB, 2012, IEEE INT CONF ROBOT, P3041, DOI 10.1109/ICRA.2012.6225287.
   Trimble GM, 2002, OCEANS 2002 MTS/IEEE CONFERENCE \& EXHIBITION, VOLS 1-4, CONFERENCE PROCEEDINGS, P1172.
   Walter M, 2008, IEEE INT CONF ROBOT, P1463, DOI 10.1109/ROBOT.2008.4543408.
   Weingarten J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3062, DOI 10.1109/IROS.2006.282245.},
Number-of-Cited-References = {26},
Times-Cited = {12},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE9BP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000377221103127},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921704087,
Author = {Krajnik, Tomas and Fentanes, Jaime Pulido and Hanheide, Marc and
   Duckett, Tom},
Book-Group-Author = {IEEE},
Title = {Persistent Localization and Life-long Mapping in Changing Environments
   using the Frequency Map Enhancement},
DOI = {10.1109/IROS.2016.7759671},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {4558-4563},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {We present a lifelong mapping and localisation system for long-term
   autonomous operation of mobile robots in changing environments. The core
   of the system is a spatio-temporal occupancy grid that explicitly
   represents the persistence and periodicity of the individual cells and
   can predict the probability of their occupancy in the future. During
   navigation, our robot builds temporally local maps and integrates then
   into the global spatio-temporal grid. Through re-observation of the same
   locations, the spatio-temporal grid learns the long-term environment
   dynamics and gains the ability to predict the future environment states.
   This predictive ability allows to generate time-specific 2d maps used by
   the robot's localisation and planning modules. By analysing data from a
   long-term deployment of the robot in a human-populated environment, we
   show that the proposed representation improves localisation accuracy and
   the efficiency of path planning. We also show how to integrate the
   method into the ROS navigation stack for use by other roboticists.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Krajnik, T (Corresponding Author), Lincoln Univ, Brayford Pool, Lincoln, England.
   Krajnik, Tomas; Fentanes, Jaime Pulido; Hanheide, Marc; Duckett, Tom, Lincoln Univ, Brayford Pool, Lincoln, England.},
ISBN = {978-1-5090-3762-9},
Keywords = {mobile robotics; long-term autonomy},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Affiliations = {University of Lincoln},
ResearcherID-Numbers = {Krajník, Tomáš/O-2339-2013},
ORCID-Numbers = {Krajník, Tomáš/0000-0002-4408-7916},
Funding-Acknowledgement = {EU ICT {[}600623]},
Funding-Text = {All authors are with the University of Lincoln, UK. This work was funded
   by the EU ICT project 600623 `STRANDS'},
Cited-References = {Biber P., 2009, INT J ROBOTICS RES.
   Cadena C., 2012, IEEE T ROBOTICS.
   Churchill W., 2012, P ICRA.
   Dayoub F., 2011, ROBOTICS AUTONOMOUS.
   Fentanes J. Pulido, 2015, P ICRA.
   Konolige K., 2009, P IROS.
   Krajnik T., 2014, P ICRA.
   Krajnik T., 2013, P ICAR.
   Krajnik T., 2014, P IROS.
   Krajnik T, 2015, IEEE INT CONF ROBOT, P2140, DOI 10.1109/ICRA.2015.7139481.
   Krajnik T, 2014, J INTELL ROBOT SYST, V76, P539, DOI 10.1007/s10846-014-0041-x.
   Kucner T., 2013, PROC IROS.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Montesano L, 2008, AUTON ROBOT, V25, P231, DOI 10.1007/s10514-008-9092-9.
   Quigley M., 2009, P ICRA WORKSH OP SOU, V3, P5.
   Thrun S. a. o., 2002, EXPLORING ARTIFICIAL, V1, P1.
   Wolf D., 2005, AUTONOMOUS ROBOTS.
   Yguel M, 2006, SPRINGER TRAC ADV RO, V25, P219.},
Number-of-Cited-References = {19},
Times-Cited = {18},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921704087},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000308650000002,
Author = {Kretzschmar, Henrik and Stachniss, Cyrill},
Title = {Information-theoretic compression of pose graphs for laser-based SLAM},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2012},
Volume = {31},
Number = {11, SI},
Pages = {1219-1230},
Month = {SEP},
Note = {15th International Symposium on Robotics Research (ISSR), Flagstaff, AZ,
   AUG 28-31, 2011},
Abstract = {In graph-based simultaneous localization and mapping (SLAM), the pose
   graph grows over time as the robot gathers information about the
   environment. An ever growing pose graph, however, prevents long-term
   mapping with mobile robots. In this paper, we address the problem of
   efficient information-theoretic compression of pose graphs. Our approach
   estimates the mutual information between the laser measurements and the
   map to discard the measurements that are expected to provide only a
   small amount of information. Our method subsequently marginalizes out
   the nodes from the pose graph that correspond to the discarded laser
   measurements. To maintain a sparse pose graph that allows for efficient
   map optimization, our approach applies an approximate marginalization
   technique that is based on Chow-Liu trees. Our contributions allow the
   robot to effectively restrict the size of the pose graph. Alternatively,
   the robot is able to maintain a pose graph that does not grow unless the
   robot explores previously unobserved parts of the environment.
   Real-world experiments demonstrate that our approach to pose graph
   compression is well suited for long-term mobile robot mapping.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Stachniss, C (Corresponding Author), Univ Freiburg, Dept Comp Sci, Geroges Kohler Allee 79, D-79110 Freiburg, Germany.
   Kretzschmar, Henrik; Stachniss, Cyrill, Univ Freiburg, Dept Comp Sci, Geroges Kohler Allee 79, D-79110 Freiburg, Germany.},
DOI = {10.1177/0278364912455072},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {SLAM; long-term; pose graph; compression; mutual information},
Keywords-Plus = {SPACE},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {stachnis@informatik.uni-freiburg.de},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
ORCID-Numbers = {Stachniss, Cyrill/0000-0003-1173-6972},
Cited-References = {Bachrach A, 2011, J FIELD ROBOT, V28, P644, DOI 10.1002/rob.20400.
   Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Davison A. J., 2009, P IEEE INT C ROB AUT, P387.
   Davison A. J., 2005, P INT C COMP VIS ICC, V1.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Folkesson J, 2005, IEEE INT CONF ROBOT, P30.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INT CONF ROBOT, P273, DOI 10.1109/ROBOT.2010.5509407.
   He R, 2008, IEEE INT CONF ROBOT, P1814, DOI 10.1109/ROBOT.2008.4543471.
   Howard A., 2003, ROBOTICS DATA SET RE.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kim A, 2011, IEEE INT C INT ROBOT, P1647, DOI 10.1109/IROS.2011.6048439.
   Kollar T, 2008, P NAT C ART INT AAAI, P1369.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   KRAUSE A, 2005, P UNC ART INT UAI.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   MacKay DJ., 2003, INFORM THEORY INFERE.
   Ni K, 2007, IEEE INT CONF ROBOT, P1678, DOI 10.1109/ROBOT.2007.363564.
   Olson E., 2008, THESIS.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   SNAVELY N, 2008, P IEEE C COMP VIS PA, P1.
   Stachniss C, 2011, P INT S ROB RES ISRR.
   Stachniss C., 2005, ROBOTICS SCI SYSTEMS, P65.},
Number-of-Cited-References = {31},
Times-Cited = {66},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {20},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {003ZN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000308650000002},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000388438500120,
Author = {Pastor-Moreno, Daniel and Shin, Hyo-Sang and Waldock, Antony},
Book-Group-Author = {IEEE},
Title = {Optical Flow Localisation and Appearance Mapping (OFLAAM) for Long-term
   Navigation},
DOI = {10.1109/ICUAS.2015.7152387},
Booktitle = {2015 INTERNATIONAL CONFERENCE ON UNMANNED AIRCRAFT SYSTEMS (ICUAS'15)},
Series = {International Conference on Unmanned Aircraft Systems},
Year = {2015},
Pages = {980-988},
Note = {International Conference on Unmanned Aircraft Systems (ICUAS), Denver,
   CO, JUN 09-12, 2015},
Abstract = {This paper presents a novel method to use optical flow navigation for
   long term navigation. Unlike standard SLAM approaches for augmented
   reality, OFLAAM is designed for Micro Air Vehicles (MAV). It uses a
   optical flow camera pointing downwards, a IMU and a monocular camera
   pointing frontwards. That configuration avoids the computational
   expensive mapping and tracking of the 3D features. It only maps these
   features in a vocabulary list by a localization module to tackle the
   optical flow drift and the lose of the navigation estimation. That
   module, based on the well established algorithm DBoW2, will be also used
   to close the loop and allow long-term navigation in previously visited
   areas. The combination of high speed optical flow navigation with a low
   rate localization algorithm allows fully autonomous navigation for MAV,
   at the same time it reduces the overall computational load. This
   framework is implemented in ROS (Robot Operating System) and tested
   attached to a laptop. A representative scenario is used to validate and
   analyze the performance of the system.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pastor-Moreno, D (Corresponding Author), Cranfield Univ, Sch Engn, Cranfield MK43 0AL, Beds, England.
   Pastor-Moreno, Daniel, Cranfield Univ, Sch Engn, Cranfield MK43 0AL, Beds, England.
   Shin, Hyo-Sang, Cranfield Univ, Sch Engn, Dept Engn Phys, Cranfield MK43 0AL, Beds, England.
   Waldock, Antony, BAE Syst, London, England.},
ISSN = {2373-6720},
ISBN = {978-1-4799-6010-1},
Keywords-Plus = {SLAM},
Research-Areas = {Engineering; Remote Sensing},
Web-of-Science-Categories  = {Engineering, Aerospace; Engineering, Electrical \& Electronic; Remote
   Sensing},
Affiliations = {Cranfield University; Cranfield University; Bae Systems},
ResearcherID-Numbers = {Shin, Hyo-Sang/AAI-6362-2021
   },
ORCID-Numbers = {Shin, Hyo-Sang/0000-0001-9938-0370},
Cited-References = {Achtelik Markus, 2011, IEEE International Conference on Robotics and Automation, P3056.
   Ahn S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2588, DOI 10.1109/IROS.2006.281936.
   Alpen M., 2010, INT SOC OPTICS PHOTO.
   Bry A, 2012, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2012.6225295.
   Clemente L.A., 2007, ROBOTICS SCI SYSTEMS, V2.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Engel J, 2012, IEEE INT C INT ROBOT, P2815, DOI 10.1109/IROS.2012.6385458.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Giachetti A, 1998, IEEE T ROBOTIC AUTOM, V14, P34, DOI 10.1109/70.660838.
   Grabe V, 2012, IEEE INT CONF ROBOT, P491, DOI 10.1109/ICRA.2012.6225328.
   Honegger D, 2013, IEEE INT CONF ROBOT, P1736, DOI 10.1109/ICRA.2013.6630805.
   Klein George, 2007, P1.
   Kruger W., 1995, Proceedings of the Intelligent Vehicles `95. Symposium (Cat. No.95TH8132), P304, DOI 10.1109/IVS.1995.528298.
   Meier L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P2992, DOI 10.1109/ICRA.2011.5980229.
   Montemerlo M., 2002, AAAI IAAI, DOI DOI 10.1007/S00244-005-7058-X.
   Mur-Artal R., ORB SLAM TRACKING MA.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Parrot A., 2012, DRONE, V75.
   Pradalier C., 2012, ADV AUTONOMOUS MINI, P89.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552.
   Watman Daniel, 2011, IEEE International Conference on Robotics and Automation, P2986.
   Williams B, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2053, DOI 10.1109/IROS.2008.4650996.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Zingg S, 2010, IEEE INT CONF ROBOT, P3361, DOI 10.1109/ROBOT.2010.5509777.},
Number-of-Cited-References = {28},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG3ZW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000388438500120},
DA = {2022-05-17},
}

@article{ WOS:000434397300004,
Author = {Lenac, Kruno and Cesic, Josip and Markovic, Ivan and Petrovic, Ivan},
Title = {Exactly sparse delayed state filter on Lie groups for long-term pose
   graph SLAM},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2018},
Volume = {37},
Number = {6},
Pages = {585-610},
Month = {MAY},
Abstract = {In this paper we propose a simultaneous localization and mapping (SLAM)
   back-end solution called the exactly sparse delayed state filter on Lie
   groups (LG-ESDSF). We derive LG-ESDSF and demonstrate that it retains
   all the good characteristics of the classic Euclidean ESDSF, the main
   advantage being the exact sparsity of the information matrix. The key
   advantage of LG-ESDSF in comparison with the classic ESDSF lies in the
   ability to respect the state space geometry by negotiating uncertainties
   and employing filtering equations directly on Lie groups. We also
   exploit the special structure of the information matrix in order to
   allow long-term operation while the robot is moving repeatedly through
   the same environment. To prove the effectiveness of the proposed SLAM
   solution, we conducted extensive experiments on two different publicly
   available datasets, namely the KITTI and EuRoC datasets, using two
   front-ends: one based on the stereo camera and the other on the 3D
   LIDAR. We compare LG-ESDSF with the general graph optimization framework
   (g(2)o) when coupled with the same front-ends. Similarly to g(2)o the
   proposed LG-ESDSF is front-end agnostic and the comparison demonstrates
   that our solution can match the accuracy of g(2)o, while maintaining
   faster computation times. Furthermore, the proposed back-end coupled
   with the stereo camera front-end forms a complete visual SLAM solution
   dubbed LG-SLAM. Finally, we evaluated LG-SLAM using the online KITTI
   protocol and at the time of writing it achieved the second best result
   among the stereo odometry solutions and the best result among the tested
   SLAM algorithms.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Lenac, K (Corresponding Author), Univ Zagreb, Fac Elect Engn \& Comp, Unska 3, Zagreb 10000, Croatia.
   Lenac, Kruno; Cesic, Josip; Markovic, Ivan; Petrovic, Ivan, Univ Zagreb, Fac Elect Engn \& Comp, Unska 3, Zagreb 10000, Croatia.},
DOI = {10.1177/0278364918767756},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {SLAM; exactly sparse delayed state filter; Lie groups; graph
   optimization},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; KALMAN FILTER; OPTIMIZATION; ALGORITHM;
   MOTION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {kruno.lenac@fer.hr},
Affiliations = {University of Zagreb},
ResearcherID-Numbers = {Markovic, Ivan/AAL-2382-2021
   Petrovic, Ivan/AAJ-9398-2021},
ORCID-Numbers = {Markovic, Ivan/0000-0003-4138-1113
   Petrovic, Ivan/0000-0001-9961-5627},
Funding-Acknowledgement = {Unity Through Knowledge Fund {[}24/15]; Ministry of Science and
   Education of the Republic of Croatia {[}533-19-15-0007]},
Funding-Text = {This work has been supported from the Unity Through Knowledge Fund (no.
   24/15) under the project Cooperative Cloud based Simultaneous
   Localization and Mapping in Dynamic Environments (cloudSLAM) and has
   been carried out within the activities of the Centre of Research
   Excellence for Data Science and Cooperative Systems supported by the
   Ministry of Science and Education of the Republic of Croatia under Grant
   533-19-15-0007.},
Cited-References = {Agarwal S., 2010, CERES SOLVER.
   Arrigoni F, 2016, SIAM J IMAGING SCI, V9, P1963, DOI 10.1137/16M1060248.
   Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Barfoot TD, 2014, IEEE T ROBOT, V30, P679, DOI 10.1109/TRO.2014.2298059.
   Barrau A, 2015, IEEE T AUTOMAT CONTR, V60, P436, DOI 10.1109/TAC.2014.2342911.
   BELL BM, 1994, SIAM J OPTIMIZ, V4, P626, DOI 10.1137/0804035.
   BELL BM, 1993, IEEE T AUTOMAT CONTR, V38, P294, DOI 10.1109/9.250476.
   Bourmaud G, 2016, J MATH IMAGING VIS, V55, P284, DOI 10.1007/s10851-015-0622-8.
   Bourmaud G, 2015, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2015.7298772.
   Bourmaud G, 2015, J MATH IMAGING VIS, V51, P209, DOI 10.1007/s10851-014-0517-0.
   Bourmaud G, 2013, 2013 PROCEEDINGS OF THE 21ST EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO).
   Briales J, 2017, IEEE ROBOT AUTOM LET, V2, P2127, DOI 10.1109/LRA.2017.2718661.
   Briales J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4630, DOI 10.1109/IROS.2016.7759681.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   Carlone L, 2015, IEEE INT CONF ROBOT, P4597, DOI 10.1109/ICRA.2015.7139836.
   Carlone L, 2013, IEEE INT CONF ROBOT, P965, DOI 10.1109/ICRA.2013.6630690.
   Cesic J, 2017, AUTOMATICA, V82, P226, DOI 10.1016/j.automatica.2017.04.056.
   Chirikjian GS, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-4944-9.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345.
   Cvii I, 2015, EUR C MOB ROB ECMR, P0.
   Davis T., 2006, DIRECT METHODS SPARS.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dellaert F., 2012, FACTOR GRAPHS GTSAM.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Dissanayake G, 2011, 2011 6 INT C IND INF, P477.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eade E, 2008, MONOCULAR SIMULTANEO.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Engel J, 2014, LSD SLAM LARGE SCALE.
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Geiger A., 2012, P IEEE COMP SOC C CO.
   Gilitschenski I, 2015, IEEE T AUTOMATIC CON.
   Glover J, 2013, TECHNICAL REPORT.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Guennebaud G., 2010, EIGEN V3.
   Guivant J, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2731, DOI 10.1109/ROBOT.2002.1013645.
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382.
   Hertzberg C, 2013, INFORM FUSION, V14, P57, DOI 10.1016/j.inffus.2011.08.003.
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kohlhepp P., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P722.
   Konolige, 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.102.
   Konolige K., 2010, 2010 IEEERSJ INT C I, P22.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lenac K, 2017, IEEE RSJ INT C INT R.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Montemerlo M., 2003, P 18 INT JOINT C ART, P1151.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   MURARTAL R, 2017, IEEE T ROBOTICS, P1, DOI DOI 10.1109/TR0.2017.2705103.
   Nikolic J, 2014, IEEE INT CONF ROBOT, P431, DOI 10.1109/ICRA.2014.6906892.
   Park W, 2010, INT J ROBOT RES, V29, P813, DOI 10.1177/0278364909357228.
   Pire T, 2015, IEEE INT C INT ROBOT, P1373, DOI 10.1109/IROS.2015.7353546.
   Polok L, 2013, INT AUT VEH S IFAC B.
   Selig JM, 2004, NATO SCI SER II MATH, V136, P101.
   Stachniss C., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1505.
   Stoyanov T, 2012, INT J ROBOT RES, V31, P1377, DOI 10.1177/0278364912460895.
   Tardos JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Walter M, 2007, PROVABLY CONSISTENT, P214.
   Wang YF, 2008, INT J ROBOT RES, V27, P1258, DOI 10.1177/0278364908097583.
   Wang Z, 2006, IMPLEMENTATION ISSUE, P155.
   Weingarten J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3062, DOI 10.1109/IROS.2006.282245.},
Number-of-Cited-References = {71},
Times-Cited = {8},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {26},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {GI5FV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000434397300004},
DA = {2022-05-17},
}

@article{ WOS:000442338200002,
Author = {Bescos, Berta and Facil, Jose M. and Civera, Javier and Neira, Jose},
Title = {DynaSLAM: Tracking, Mapping, and Inpainting in Dynamic Scenes},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {4076-4083},
Month = {OCT},
Abstract = {The assumption of scene rigidity is typical in SLAM algorithms. Such a
   strong assumption limits the use of most visual SLAM systems in
   populated real-world environments, which are the target of several
   relevant applications like service robotics or autonomous vehicles. In
   this letter we present DynaSLAM, a visual SLAM system that, building on
   ORB-SLAM2, adds the capabilities of dynamic object detection and
   background inpainting. DynaSLAM is robust in dynamic scenarios for
   monocular, stereo, and RGB-D configurations. We are capable of detecting
   the moving objects either by multiview geometry, deep learning, or both.
   Having a static map of the scene allows inpainting the frame background
   that has been occluded by such dynamic objects. We evaluate our system
   in public monocular, stereo, and RGB-D datasets. We study the impact of
   several accuracy/speed trade-offs to assess the limits of the proposed
   methodology. DynaSLAM outperforms the accuracy of standard visual SLAM
   baselines in highly dynamic scenarios. And it also estimates a map of
   the static parts of the scene, which is a must for long-term
   applications in real-world environments.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Bescos, B (Corresponding Author), Univ Zaragoza, I3A, Zaragoza 50018, Spain.
   Bescos, Berta; Facil, Jose M.; Civera, Javier; Neira, Jose, Univ Zaragoza, I3A, Zaragoza 50018, Spain.},
DOI = {10.1109/LRA.2018.2860039},
ISSN = {2377-3766},
Keywords = {SLAM; visual-based navigation; localization},
Keywords-Plus = {SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {bbescos@unizar.es
   jmfacil@unizar.es
   jcivera@unizar.es
   jneira@unizar.es},
Affiliations = {University of Zaragoza},
ResearcherID-Numbers = {Neira, Jose/AAM-6571-2020
   Civera, Javier/I-3651-2015
   Neira Parra, Jose/F-8887-2013},
ORCID-Numbers = {Civera, Javier/0000-0003-1368-1151
   Bescos Torcal, Berta/0000-0003-1188-8415
   Facil, Jose M./0000-0002-8757-4749
   Neira Parra, Jose/0000-0003-0668-977X},
Funding-Acknowledgement = {NVIDIA; Spanish Ministry of Economy and Competitiveness
   {[}DPI2015-68905-P, DPI2015-67275-P]; FPI {[}BES-2016-077836]; Aragon
   regional government (Grupo DGA T04-FSE)},
Funding-Text = {This work was supported in part by NVIDIA through the donation of a
   Titan X GRU, in part by the Spanish Ministry of Economy and
   Competitiveness under Projects DPI2015-68905-P and DPI2015-67275-P, FPI
   Grant BES-2016-077836, and in part by the Aragon regional government
   (Grupo DGA T04-FSE).},
Cited-References = {Alcantarilla PF, 2012, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2012.6224690.
   Ambrus R., 2016, P IEEE RAS 16 INT C.
   Concha A, 2015, IEEE INT C INT ROBOT, P5686, DOI 10.1109/IROS.2015.7354184.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Gerlach NL, 2014, BRIT J ORAL MAX SURG, V52, P838, DOI 10.1016/j.bjoms.2014.07.253.
   Graber G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P708, DOI 10.1109/ICCVW.2011.6130318.
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322.
   Kim DH, 2016, IEEE T ROBOT, V32, P1565, DOI 10.1109/TRO.2016.2609395.
   Klein George, 2007, P1.
   Li SL, 2017, IEEE ROBOT AUTOM LET, V2, P2263, DOI 10.1109/LRA.2017.2724759.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Montiel J.M.M., 2017, 2017 EUR C MOB ROB E, P1.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278.
   Stuhmer J, 2010, LECT NOTES COMPUT SC, V6376, P11.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012.
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781.
   Wang YB, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3122, DOI 10.1109/WCICA.2014.7053228.
   Wangsiripitak S, 2009, IEEE INT CONF ROBOT, P705.},
Number-of-Cited-References = {24},
Times-Cited = {179},
Usage-Count-Last-180-days = {34},
Usage-Count-Since-2013 = {127},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GR1UO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000442338200002},
OA = {Green Published, Green Submitted},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000463352600011,
Author = {Pan, Liangliang and Cheng, Jun and Feng, Wei and Ji, Xiaopeng},
Editor = {Liu, M and Chen, H and Vincze, M},
Title = {A Robust RGB-D Image-Based SLAM System},
Booktitle = {COMPUTER VISION SYSTEMS, ICVS 2017},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10528},
Pages = {120-130},
Note = {11th International Conference on Computer Vision Systems (ICVS),
   Shenzhen, PEOPLES R CHINA, JUL 10-13, 2017},
Abstract = {Visual SLAM is widely used in robotics and computer vision. Although
   there have been many excellent achievements over the past few decades,
   there are still some challenges. 2D feature-based SLAM algorithm has
   been suffering from the inaccurate or insufficient correspondences while
   dealing with the case of textureless or frequently repeating regions.
   Furthermore, most of the SLAM systems cannot be used for long-term
   localization in a wide range of environment because of the heavy burden
   of calculating and memory. In this paper, we propose a robust RGB-D
   keyframe-based SLAM algorithm. The novelty of proposed approach lies in
   using both 2D and 3D features for tracking, pose estimation and bundle
   adjustment. By using 2D and 3D features, the SLAM system can achieve
   high accuracy and robustness in some challenging environments. The
   experimental results on TUM RGB-D dataset {[}1] and ICL-NUIM dataset
   {[}2] verify the effectiveness of our algorithm.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Cheng, J (Corresponding Author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Robot \& Intelligent Syst, Shenzhen, Peoples R China.
   Cheng, J (Corresponding Author), Chinese Univ Hong Kong, Hong Kong, Peoples R China.
   Pan, Liangliang; Cheng, Jun; Feng, Wei; Ji, Xiaopeng, Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Robot \& Intelligent Syst, Shenzhen, Peoples R China.
   Pan, Liangliang; Ji, Xiaopeng, Univ Chinese Acad Sci, Shenzhen Coll Adv Technol, Shenzhen, Peoples R China.
   Pan, Liangliang; Cheng, Jun; Feng, Wei; Ji, Xiaopeng, Chinese Univ Hong Kong, Hong Kong, Peoples R China.},
DOI = {10.1007/978-3-319-68345-4\_11},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-68345-4; 978-3-319-68344-7},
Keywords = {RGB-D; SLAM; Visual feature; Mapping},
Keywords-Plus = {LOCALIZATION; 3D},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods},
Author-Email = {ll.pan@siat.ac.cn
   jun.cheng@siat.ac.cn
   wei.feng@siat.ac.cn
   xp.ji@siat.ac.cn},
Affiliations = {Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS; Chinese University of Hong Kong},
ORCID-Numbers = {Ji, Xiaopeng/0000-0003-3920-8362},
Funding-Acknowledgement = {CAS Key Technology Talent Program Shenzhen Technology Project
   {[}JSGG20160331185256983, JSGG20160229115709109]; Guangdong Technology
   Project {[}2016B010108010, 2016B010125003]; State Joint Engineering
   Laboratory for Robotics and Intelligent Manufacturing - National
   Development and Reform Commission {[}2015581]; Key Laboratory of
   Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of
   Advanced Technology, Chinese Academy of Sciences {[}2014DP173025]},
Funding-Text = {This work supported by CAS Key Technology Talent Program Shenzhen
   Technology Project (JSGG20160331185256983, JSGG20160229115709109),
   Guangdong Technology Project(2016B010108010, 2016B010125003), State
   Joint Engineering Laboratory for Robotics and Intelligent Manufacturing
   funded by National Development and Reform Commission (No. 2015581), Key
   Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen
   Institutes of Advanced Technology, Chinese Academy of Sciences
   (2014DP173025).},
Cited-References = {Ataer-Cansizoglu E, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P51, DOI 10.1109/ICCVW.2013.14.
   Bevington PR., 1993, DATA REDUCTION ERROR, V7, P415.
   Chen ZH, 2007, ADV ROBOTICS, V21, P233, DOI 10.1163/156855307780132081.
   Di KC, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081285.
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054.
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Mur-Artal R., 2016, ARXIV161006475.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Neira J, 2008, IEEE T ROBOT, V24, P929, DOI 10.1109/TRO.2008.2004620.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   Steinbrucker F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P719, DOI 10.1109/ICCVW.2011.6130321.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Taguchi Y, 2013, IEEE INT CONF ROBOT, P5182, DOI 10.1109/ICRA.2013.6631318.
   Trevor AJB, 2012, IEEE INT CONF ROBOT, P3041, DOI 10.1109/ICRA.2012.6225287.
   WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O.
   Weingarten J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3062, DOI 10.1109/IROS.2006.282245.
   Whelan T., 2015, RSS, V2015.
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008.
   Xiang G., 2017, 14 LECT VISUAL SLAM.},
Number-of-Cited-References = {25},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BM4IC},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000463352600011},
DA = {2022-05-17},
}

@inproceedings{ WOS:000618059700062,
Author = {Schmuck, Patrik and Chli, Margarita},
Book-Group-Author = {IEEE Comp Soc},
Title = {On the Redundancy Detection in Keyframe-based SLAM},
Booktitle = {2019 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2019)},
Series = {International Conference on 3D Vision},
Year = {2019},
Pages = {594-603},
Note = {7th International Conference on 3D Vision (3DV), Quebec City, CANADA,
   SEP 15-18, 2019},
Abstract = {Egomotion and scene estimation is a key component in automating robot
   navigation, as well as in virtual reality applications for mobile phones
   or head-mounted displays. It is well known, however, that with long
   exploratory trajectories and multi-session mapping for long-term
   autonomy or collaborative applications, the maintenance of the
   ever-increasing size of these maps quickly becomes a bottleneck. With
   the explosion of data resulting in increasing runtime of the
   optimization algorithms ensuring the accuracy of the Simultaneous
   Localization And Mapping (SLAM) estimates, the large quantity of
   collected experiences is imposing hard limits on the scalability of such
   techniques. Considering the keyframe-based paradigm of SLAM techniques,
   this paper investigates the redundancy inherent in SLAM maps, by
   quantifying the information of different experiences of the scene as
   encoded in keyframes. Here we propose and evaluate different
   information-theoretic and heuristic metrics to remove dispensable scene
   measurements with minimal impact on the accuracy of the SLAM estimates.
   Evaluating the proposed metrics in two state-of-the-art centralized
   collaborative SLAM systems, we provide our key insights into how to
   identify redundancy in keyframe-based SLAM.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Schmuck, P (Corresponding Author), Swiss Fed Inst Technol, Vis Robot Lab, CH-8092 Zurich, Switzerland.
   Schmuck, Patrik; Chli, Margarita, Swiss Fed Inst Technol, Vis Robot Lab, CH-8092 Zurich, Switzerland.},
DOI = {10.1109/3DV.2019.00071},
ISSN = {2378-3826},
EISSN = {2475-7888},
ISBN = {978-1-7281-3131-3},
Keywords-Plus = {GRAPH SLAM; VERSATILE},
Research-Areas = {Computer Science; Engineering; Imaging Science \& Photographic
   Technology},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Engineering, Electrical \& Electronic; Imaging Science \&
   Photographic Technology},
Affiliations = {ETH Zurich},
ORCID-Numbers = {Chli, Margarita/0000-0001-5611-7492},
Funding-Acknowledgement = {Swiss National Science Foundation (SNSF) {[}PP00P2183720]; NCCR Robotics},
Funding-Text = {This research was supported by the Swiss National Science Foundation
   (SNSF, Agreement no. PP00P2183720) and NCCR Robotics.},
Cited-References = {Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   Carlone L, 2014, IEEE INT C INT ROBOT, P2667, DOI 10.1109/IROS.2014.6942927.
   Chli M, 2008, LECT NOTES COMPUT SC, V5302, P72, DOI 10.1007/978-3-540-88682-2\_7.
   Choudhary S, 2015, IEEE INT CONF ROBOT, P4620, DOI 10.1109/ICRA.2015.7139839.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Davison AJ, 2005, IEEE I CONF COMP VIS, P66.
   Deutsch I., 2016, IEEE INT C REAL TIM.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Forster C, 2013, DROUGHT AND THE HUMAN STORY: BRAVING THE BULL OF HEAVEN, P1.
   Hepp B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3233794.
   Hsiung J, 2018, IEEE INT C INT ROBOT, P1146, DOI 10.1109/IROS.2018.8594007.
   Huang GQ, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P150, DOI 10.1109/ECMR.2013.6698835.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Karrer M, 2018, IEEE ROBOT AUTOM LET, V3, P2762, DOI 10.1109/LRA.2018.2837226.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Mazuran M, 2016, INT J ROBOT RES, V35, P50, DOI 10.1177/0278364915581629.
   Mu BP, 2017, IEEE T ROBOT, V33, P124, DOI 10.1109/TRO.2016.2623344.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Paull L, 2016, IEEE INT CONF ROBOT, P1346, DOI 10.1109/ICRA.2016.7487268.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Riazuelo L, 2014, ROBOT AUTON SYST, V62, P401, DOI 10.1016/j.robot.2013.11.007.
   Schmuck P., 2017, P IEEE INT C ROB AUT.
   Schmuck P, 2019, J FIELD ROBOT, V36, P763, DOI 10.1002/rob.21854.
   Schneider Thomas, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6487, DOI 10.1109/ICRA.2017.7989766.
   Snavely N., 2008, CVPR, V1, P2.
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009.
   Usenko Vladyslav, 2019, ARXIV190406504.
   Vallve J, 2018, IEEE ROBOT AUTOM LET, V3, P1322, DOI 10.1109/LRA.2018.2798283.
   Vial J, 2011, IEEE INT C INT ROBOT, P886, DOI 10.1109/IROS.2011.6048728.},
Number-of-Cited-References = {34},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BQ7OG},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000618059700062},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000317042702066,
Author = {Walcott-Bryant, Aisha and Kaess, Michael and Johannsson, Hordur and
   Leonard, John J.},
Book-Group-Author = {IEEE
   Robotics Society of Japan},
Title = {Dynamic Pose Graph SLAM: Long-term Mapping in Low Dynamic Environments},
DOI = {10.1109/IROS.2012.6385561},
Booktitle = {2012 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2012},
Pages = {1871-1878},
Note = {25th IEEE\textbackslash{}RSJ International Conference on Intelligent
   Robots and Systems (IROS), Algarve, PORTUGAL, OCT 07-12, 2012},
Abstract = {Maintaining a map of an environment that changes over time is a critical
   challenge in the development of persistently autonomous mobile robots.
   Many previous approaches to mapping assume a static world. In this work
   we incorporate the time dimension into the mapping process to enable a
   robot to maintain an accurate map while operating in dynamical
   environments. This paper presents Dynamic Pose Graph SLAM (DPG-SLAM), an
   algorithm designed to enable a robot to remain localized in an
   environment that changes substantially over time. Using incremental
   smoothing and mapping (iSAM) as the underlying SLAM state estimation
   engine, the Dynamic Pose Graph evolves over time as the robot explores
   new places and revisits previously mapped areas. The approach has been
   implemented for planar indoor environments, using laser scan matching to
   derive constraints for SLAM state estimation. Laser scans for the same
   portion of the environment at different times are compared to perform
   change detection; when sufficient change has occurred in a location, the
   dynamic pose graph is edited to remove old poses and scans that no
   longer match the current state of the world. Experimental results are
   shown for two real-world dynamic indoor laser data sets, demonstrating
   the ability to maintain an up-to-date map despite long-term
   environmental changes.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Walcott-Bryant, A (Corresponding Author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Walcott-Bryant, Aisha; Kaess, Michael; Johannsson, Hordur; Leonard, John J., MIT, Cambridge, MA 02139 USA.},
ISSN = {2153-0858},
ISBN = {978-1-4673-1736-8},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {aisha.w.bryant@gmail.com
   kaess@mit.edu
   hordurj@mit.edu
   jleonard@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT)},
ORCID-Numbers = {Kaess, Michael/0000-0002-7590-3357},
Cited-References = {Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Biber P., 2005, P ROB SCI SYST RSS.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Biswas R, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1014.
   Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   Fox D., 1998, P NAT C ART INT AAAI.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   GUTMANN JS, 1999, INT S COMP INT ROB A.
   Hahnel D, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P496, DOI 10.1109/IRDS.2002.1041439.
   Ji XC, 2009, LECT NOTES COMPUT SC, V5399, P507.
   Johannsson H., 2012, MITCSAILTR2012013.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Meyer-Delius D., 2011, THESIS U FREIBURG.
   Mitsou N.C., 2007, CONTR AUT 2007 MED 0, P1.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Wang CC, 2003, IEEE INT CONF ROBOT, P842.
   Wolf DF, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P594.
   Wyeth G., 2009, P 14 INT S ROB RES I.},
Number-of-Cited-References = {19},
Times-Cited = {75},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {10},
Doc-Delivery-Number = {BEK21},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000317042702066},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000389849700001,
Author = {Cadena, Cesar and Carlone, Luca and Carrillo, Henry and Latif, Yasir and
   Scaramuzza, Davide and Neira, Jose and Reid, Ian and Leonard, John J.},
Title = {Past, Present, and Future of Simultaneous Localization and Mapping:
   Toward the Robust-Perception Age},
Journal = {IEEE TRANSACTIONS ON ROBOTICS},
Year = {2016},
Volume = {32},
Number = {6},
Pages = {1309-1332},
Month = {DEC},
Abstract = {Simultaneous localization and mapping (SLAM) consists in the concurrent
   construction of a model of the environment (the map), and the estimation
   of the state of the robot moving within it. The SLAM community has made
   astonishing progress over the last 30 years, enabling large-scale
   real-world applications and witnessing a steady transition of this
   technology to industry. We survey the current state of SLAM and consider
   future directions. We start by presenting what is now the de-facto
   standard formulation for SLAM. We then review related work, covering a
   broad set of topics including robustness and scalability in long-term
   mapping, metric and semantic representations for mapping, theoretical
   performance guarantees, active SLAM and exploration, and other new
   frontiers. This paper simultaneously serves as a position paper and
   tutorial to those who are users of SLAM. By looking at the published
   research with a critical eye, we delineate open challenges and new
   research issues, that still deserve careful scientific investigation.
   The paper also contains the authors' take on two questions that often
   animate discussions during robotics conferences: Do robots need SLAM?
   and Is SLAM solved?},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Cadena, C (Corresponding Author), ETH, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Cadena, Cesar, ETH, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Carlone, Luca, MIT, Lab Informat \& Decis Syst, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Carrillo, Henry, Univ Sergio Arboleda, Escuela Ciencias Exactas \& Ingn, Bogota, Colombia.
   Carrillo, Henry, Pontificia Univ Javeriana, Bogota, Colombia.
   Latif, Yasir; Reid, Ian, Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
   Latif, Yasir; Reid, Ian, Australian Ctr Robot Vis, Brisbane, Qld 4000, Australia.
   Scaramuzza, Davide, Univ Zurich, Robot \& Percept Grp, CH-8006 Zurich, Switzerland.
   Neira, Jose, Univ Zaragoza, Dept Informat \& Ingn Sistemas, Zaragoza 50029, Spain.
   Leonard, John J., MIT, Marine Robot Grp, 77 Massachusetts Ave, Cambridge, MA 02139 USA.},
DOI = {10.1109/TRO.2016.2624754},
ISSN = {1552-3098},
EISSN = {1941-0468},
Keywords = {Factor graphs; localization; mapping; maximum a posteriori estimation;
   perception; robots; sensing; simultaneous localization and mapping
   (SLAM)},
Keywords-Plus = {VISUAL ODOMETRY; DATA ASSOCIATION; HAND-HELD; SLAM; TIME; UNCERTAINTY;
   NAVIGATION; OPTIMIZATION; EXPLORATION; SENSOR},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {cesarc@ethz.ch
   lcarlone@mit.edu
   henry.carrillo@usa.edu.co
   yasir.latif@adelaide.edu.au
   sdavide@ifi.uzh.ch
   jneira@unizar.es
   ian.reid@adelaide.edu.au
   jleonard@mit.edu},
Affiliations = {ETH Zurich; Massachusetts Institute of Technology (MIT); University
   Sergio Arboleda; Pontificia Universidad Javeriana; University of
   Adelaide; Australian Centre for Robotic Vision; League of European
   Research Universities - LERU; University of Zurich; University of
   Zaragoza; Massachusetts Institute of Technology (MIT)},
ResearcherID-Numbers = {Neira, Jose/AAM-6571-2020
   Cadena, Cesar/AAM-4987-2020
   Neira Parra, Jose/F-8887-2013
   },
ORCID-Numbers = {Cadena, Cesar/0000-0002-2972-6011
   Neira Parra, Jose/0000-0003-0668-977X
   Carrillo Lindado, Henry David/0000-0002-1088-8942
   Reid, Ian/0000-0001-7790-6423},
Funding-Acknowledgement = {ARC {[}DP130104413, CE140100016, FL130100102]; NCCR Robotics;
   EU-FP7-ICT-Project TRADR {[}609763];  {[}MINECO-FEDER DPI2015-68905-P]; 
   {[}Grupo DGA T04-FSE];  {[}PUJ 6601];  {[}EU-H2020-688652]; 
   {[}SERI-15.0284]},
Funding-Text = {This work was supported in part by the following: Grant MINECO-FEDER
   DPI2015-68905-P, Grant Grupo DGA T04-FSE; ARC Grants DP130104413, Grant
   CE140100016 and Grant FL130100102; NCCR Robotics; Grant PUJ 6601;
   EU-FP7-ICT-Project TRADR 609763, Grant EU-H2020-688652, and Grant
   SERI-15.0284. This paper was presented in part at the workshop ``The
   problem of mobile sensors: Setting future goals and indicators of
   progress for SLAM{''} at the Robotics: Science and System Conference,
   Rome, Italy, July 2015. Additional material for this paper, including an
   extended list of references (bibtex) and a table of pointers to online
   datasets for SLAM, can be found at https://slam-future.github.io/},
Cited-References = {Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1.
   Ackerman E., 2014, IEEE SPECTR.
   Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9\_3.
   Agarwal Sameer, 2016, CERES SOLVER.
   Anderson S, 2015, AUTON ROBOT, V39, P221, DOI 10.1007/s10514-015-9455-y.
   Anderson S, 2014, IEEE INT CONF ROBOT, P373, DOI 10.1109/ICRA.2014.6906884.
   {[}Anonymous], 2004, P IEEE RSJ INT C INT, V3, P2155.
   Aragues R, 2012, IEEE T ROBOT, V28, P840, DOI 10.1109/TRO.2012.2192012.
   Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968.
   Bao SY, 2012, PROC CVPR IEEE, P2703, DOI 10.1109/CVPR.2012.6247992.
   Barto A. G., 1981, AFWALTR811070.
   Bibby C., 2007, P ROBOTICS SCI SYSTE, P105.
   Bibby C., 2010, P IEEE INT C ROB AUT, P1050.
   Binford T. O., 1971, P IEEE C SYST CONTR, P116.
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168.
   Blanco JL, 2008, INT J ROBOT RES, V27, P73, DOI 10.1177/0278364907082610.
   Bloomenthal J., 1997, INTRO IMPLICIT SURFA.
   Bodis-Szomoru A., 2015, COMPUT VIS IMAGE UND, V66, P91.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Bosse M., 2009, 2009 IEEE INT C ROBO, P4312, DOI {[}10.1109/ROBOT.2009.5152851, DOI 10.1109/ROBOT.2009.5152851].
   Bosse M, 2012, IEEE T ROBOT, V28, P1104, DOI 10.1109/TRO.2012.2200990.
   Bosse M, 2009, ROBOT AUTON SYST, V57, P1211, DOI 10.1016/j.robot.2009.07.009.
   Bourgault F, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P540, DOI 10.1109/IRDS.2002.1041446.
   Brand C., 2014, P IEEE RSJ INT C INT, P2153.
   Burgard W, 2005, IEEE T ROBOT, V21, P376, DOI 10.1109/TRO.2004.839232.
   Cadena C., 2015, PROBLEM MOBILE SENSO.
   Cadena C., 2016, P ROB SCI SYST C, P377.
   Cadena C, 2015, IEEE INT CONF ROBOT, P4859, DOI 10.1109/ICRA.2015.7139874.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   Carlone L, 2016, IEEE T ROBOT, V32, P545, DOI 10.1109/TRO.2016.2544304.
   Carlone L, 2015, IEEE INT C INT ROBOT, P125, DOI 10.1109/IROS.2015.7353364.
   Carlone L, 2015, IEEE INT CONF ROBOT, P4597, DOI 10.1109/ICRA.2015.7139836.
   Carlone L, 2015, IEEE INT CONF ROBOT, P4589, DOI 10.1109/ICRA.2015.7139835.
   Carlone L, 2014, IEEE INT C INT ROBOT, P2667, DOI 10.1109/IROS.2014.6942927.
   Carlone L, 2014, J INTELL ROBOT SYST, V75, P291, DOI 10.1007/s10846-013-9981-9.
   Carlone L, 2014, INT J ROBOT RES, V33, P965, DOI 10.1177/0278364914523689.
   Carlone L, 2014, IEEE T ROBOT, V30, P475, DOI 10.1109/TRO.2013.2291626.
   Carlone L, 2013, IEEE INT CONF ROBOT, P965, DOI 10.1109/ICRA.2013.6630690.
   Carr JC, 2001, COMP GRAPH, P67.
   Carrillo H, 2015, IEEE INT CONF ROBOT, P1476, DOI 10.1109/ICRA.2015.7139384.
   Carrillo H, 2015, IEEE INT CONF ROBOT, P487, DOI 10.1109/ICRA.2015.7139224.
   Carrillo H, 2013, IEEE INT CONF ROBOT, P3653, DOI 10.1109/ICRA.2013.6631090.
   Carrillo H, 2012, IEEE INT C INT ROBOT, P2504, DOI 10.1109/IROS.2012.6385927.
   Carrillo H, 2012, IEEE INT CONF ROBOT, P2080, DOI 10.1109/ICRA.2012.6224890.
   Castle R, 2007, IEEE INT CONF ROBOT, P4102, DOI 10.1109/ROBOT.2007.364109.
   Censi A, 2015, IEEE INT CONF ROBOT, P3319, DOI 10.1109/ICRA.2015.7139657.
   Chiuso A, 2008, COMMUN INF SYST, V8, P185.
   Choudhary S., 2015, P IEEE INT C ROB AUT, P5261.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cieslewski T, 2015, IEEE INT CONF ROBOT, P6241, DOI 10.1109/ICRA.2015.7140075.
   Civera J, 2011, IEEE INT C INT ROBOT, P1277, DOI 10.1109/IROS.2011.6048293.
   Cohen A, 2012, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2012.6247841.
   Costante G, 2016, IEEE ROBOT AUTOM LET, V1, P18, DOI 10.1109/LRA.2015.2505717.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cunningham A, 2013, IEEE INT CONF ROBOT, P5220, DOI 10.1109/ICRA.2013.6631323.
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH `96, P303.
   Dame A, 2013, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2013.170.
   Dansereau D. G., 2013, P SPIE C COMP IM, V8657, P1.
   Dansereau DG, 2016, COMPUT VIS IMAGE UND, V145, P160, DOI 10.1016/j.cviu.2015.12.008.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Dellaert F., 2012, GTRIMCPR2012002.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Dellaert F, 2010, IEEE INT C INT ROBOT, P2566, DOI 10.1109/IROS.2010.5650422.
   Dissanayake G., 2011, 2011 IEEE 6th International Conference on Industrial and Information Systems (ICIIS 2011), P477, DOI 10.1109/ICIINFS.2011.6038117.
   Dong FC, 2013, INT J ROBOT RES, V32, P206, DOI 10.1177/0278364912469420.
   Dong J, 2015, IEEE INT CONF ROBOT, P5807, DOI 10.1109/ICRA.2015.7140012.
   Dube R, 2016, IEEE INT CONF ROBOT, P4792, DOI 10.1109/ICRA.2016.7487683.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   DurrantWhyte HF, 1996, INT J ROBOT RES, V15, P407, DOI 10.1177/027836499601500501.
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304.
   ELFES A, 1987, IEEE T ROBOTIC AUTOM, V3, P249, DOI 10.1109/JRA.1987.1087096.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Eustice RM, 2006, INT J ROBOT RES, V25, P1223, DOI 10.1177/0278364906072512.
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4.
   Fairfield N, 2007, J FIELD ROBOT, V24, P3, DOI 10.1002/rob.20165.
   Fairfield N, 2010, SPRINGER TRAC ADV RO, V62, P173.
   Feder H. J. S., 1999, THESIS.
   Ferris B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2480.
   Flint A, 2011, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2011.6126501.
   Foley J., 1992, COMPUTER GRAPHICS PR.
   Folkesson J, 2007, J FIELD ROBOT, V24, P51, DOI 10.1002/rob.20174.
   Forster C., IEEE T ROBO IN PRESS.
   Forster C., IEEE T ROBOT.
   Fox D, 2006, P IEEE, V94, P1325, DOI 10.1109/JPROC.2006.876927.
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810.
   Fredriksson Johan, 2012, LECT NOTES COMPUTER, V7726, P245.
   Frese U, 2010, KUNSTL INTELL, V24, P255, DOI 10.1007/s13218-010-0047-x.
   Furgale P, 2012, IEEE INT CONF ROBOT, P2088, DOI 10.1109/ICRA.2012.6225005.
   Gallego G., 2016, CORR, P1.
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8\_45.
   Garg R, 2013, PROC CVPR IEEE, P1272, DOI 10.1109/CVPR.2013.168.
   Gibson J.J., 1979, ECOLOGICAL APPROACH.
   Golovin D, 2011, J ARTIF INTELL RES, V42, P427.
   Govindu VM, 2001, PROC CVPR IEEE, P218.
   Grasa OG, 2014, IEEE T MED IMAGING, V33, P135, DOI 10.1109/TMI.2013.2282997.
   Grisetti G., 2007, ROBOTICS SCI SYSTEMS, V3, P65.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Grisetti G, 2010, IEEE INT CONF ROBOT, P273, DOI 10.1109/ROBOT.2010.5509407.
   Grisetti G, 2009, IEEE T INTELL TRANSP, V10, P428, DOI 10.1109/TITS.2009.2026444.
   Gutmann J.-S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P318, DOI 10.1109/CIRA.1999.810068.
   Hane C, 2013, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2013.20.
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0.
   Henry P., 2014, RGBD MAPPING USING D, P477, DOI DOI 10.1007/978-3-642-28572-1\_33.
   Hesch JA, 2014, INT J ROBOT RES, V33, P182, DOI 10.1177/0278364913509675.
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Huang GQ, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P150, DOI 10.1109/ECMR.2013.6698835.
   Huang GQP, 2011, IEEE INT C INT ROBOT, P65, DOI 10.1109/IROS.2011.6048760.
   Huang SD, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416669482.
   Huang SD, 2012, IEEE INT CONF ROBOT, P2074, DOI 10.1109/ICRA.2012.6224876.
   Huber P. J, 2011, ROBUST STAT.
   Montoya JI, 2006, CUADERNOS HISPANOAM, P81.
   IEEE RAS Map Data Representation Working Group, 2016, IEEE STAND ROB MAP D.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Indelman V, 2016, IEEE CONTR SYST MAG, V36, P41, DOI 10.1109/MCS.2015.2512031.
   Indelman V, 2015, INT J ROBOT RES, V34, P849, DOI 10.1177/0278364914561102.
   Irani M, 1999, P INT WORKSH VIS ALG, P267, DOI DOI 10.1007/3-540-44480-7-18.
   Jachnik J, 2012, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2012.6402544.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990.
   Jorge VA, 2015, IEEE INT CONF ROBOT, P2125, DOI 10.1109/ICRA.2015.7139479.
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X.
   Kaess M, 2015, IEEE INT CONF ROBOT, P4605, DOI 10.1109/ICRA.2015.7139837.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Keidar M, 2014, INT J ROBOT RES, V33, P215, DOI 10.1177/0278364913494911.
   Kelly A, 2013, MOBILE ROBOTICS: MATHEMATICS, MODELS, AND METHODS, P1.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Khosoussi K, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kim H, 2016, LECT NOTES COMPUT SC, V9910, P349, DOI 10.1007/978-3-319-46466-4\_21.
   Kim JH, 2016, IEEE INT CONF ROBOT, P1308, DOI 10.1109/ICRA.2016.7487263.
   Kim V. G., 2014, ACM T GRAPHIC, V33.
   Klein George, 2007, P1.
   Klingensmith M., 2015, P ROB SCI SYST C, P367.
   Knuth J, 2013, IEEE INT CONF ROBOT, P1534, DOI 10.1109/ICRA.2013.6630774.
   Knuth J, 2013, ROBOT AUTON SYST, V61, P229, DOI 10.1016/j.robot.2012.11.001.
   Kottas D. G., 2012, P INT S EXP ROB, P303.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Kristensen R, 2016, ARBEJDSPAPIR DOGMEPR, P1.
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572.
   Kueng B, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P16, DOI 10.1109/IROS.2016.7758089.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Kundu A, 2014, LECT NOTES COMPUT SC, V8694, P703, DOI 10.1007/978-3-319-10599-4\_45.
   Lai K, 2010, INT J ROBOT RES, V29, P1019, DOI 10.1177/0278364910369190.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Lazaro MT, 2013, IEEE INT C INT ROBOT, P1069, DOI 10.1109/IROS.2013.6696483.
   Leung C, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5026, DOI 10.1109/IROS.2006.282530.
   Leung C, 2006, ROBOT AUTON SYST, V54, P898, DOI 10.1016/j.robot.2006.05.008.
   Levinson J.S., 2011, THESIS.
   Li CH, 2015, IEEE INT SYMP CIRC S, P718, DOI 10.1109/ISCAS.2015.7168734.
   Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337.
   Lim JJ, 2013, IEEE I CONF COMP VIS, P2992, DOI 10.1109/ICCV.2013.372.
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152.
   Liu MJ, 2012, IEEE INT C INT ROBOT, P1898, DOI 10.1109/IROS.2012.6385742.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Lu Y, 2015, IEEE T ROBOT, V31, P736, DOI 10.1109/TRO.2015.2424032.
   Lynen S., 2015, P ROB SCI SYST C RSS, P338.
   MacKay DJC., 2002, INFORM THEORY INFERE.
   Magnabosco M, 2013, ROBOT AUTON SYST, V61, P195, DOI 10.1016/j.robot.2012.09.023.
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184.
   Marques L, 2002, THIN SOLID FILMS, V418, P51, DOI 10.1016/S0040-6090(02)00593-X.
   Martinec Daniel, 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383115.
   Mozos OM, 2007, ROBOT AUTON SYST, V55, P391, DOI 10.1016/j.robot.2006.12.003.
   Martinez-Cantin R, 2009, AUTON ROBOT, V27, P93, DOI 10.1007/s10514-009-9130-2.
   Mazuran M, 2016, INT J ROBOT RES, V35, P50, DOI 10.1177/0278364915581629.
   Mendel J.M., 1995, LESSONS ESTIMATION T.
   Merrell P, 2011, IEEE T VIS COMPUT GR, V17, P715, DOI 10.1109/TVCG.2010.112.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mueggler E, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Mueller E, 2015, IEEE DECIS CONTR P, P992, DOI 10.1109/CDC.2015.7402002.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Nerurkar ED, 2009, IEEE INT CONF ROBOT, P1375.
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Newman P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1802, DOI 10.1109/ROBOT.2002.1014803.
   Ng R., 2005, CSTR200502 STANF U D.
   Ni K, 2010, IEEE INT C INT ROBOT, P2558, DOI 10.1109/IROS.2010.5650197.
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508374.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Nuchter A, 2009, SPRINGER TRAC ADV RO, V52, P1.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Olson E, 2013, INT J ROBOT RES, V32, P826, DOI 10.1177/0278364913479413.
   Open Geospatial Consortium (OGC), 2016, OGC INDOORGML STAND.
   Open Geospatial Consortium (OGC), 2016, CITYGML 2 0 0.
   Patil S, 2015, SPRINGER TRAC ADV RO, V107, P515, DOI 10.1007/978-3-319-16595-0\_30.
   Patron-Perez A, 2015, INT J COMPUT VISION, V113, P208, DOI 10.1007/s11263-015-0811-3.
   Paull L, 2015, IEEE INT CONF ROBOT, P509, DOI 10.1109/ICRA.2015.7139227.
   Pazman A, 1986, FDN OPTIMUM EXPT DES.
   Peters JR, 2015, SIAM J CONTROL OPTIM, V53, P3534, DOI 10.1137/140957743.
   Phillips CJ, 2015, IEEE INT CONF ROBOT, P1352, DOI 10.1109/ICRA.2015.7139366.
   Pillai S., 2015, ROB SCI SYST C, P310.
   Piovan G, 2013, AUTOMATICA, V49, P206, DOI 10.1016/j.automatica.2012.09.014.
   Pizzoli M, 2014, IEEE INT CONF ROBOT, P2609, DOI 10.1109/ICRA.2014.6907233.
   Polok L, 2013, ROBOTICS SCI SYSTEMS, P328.
   Posch C, 2008, IEEE INT SYMP CIRC S, P2130, DOI 10.1109/ISCAS.2008.4541871.
   Pronobis A, 2012, IEEE INT CONF ROBOT, P3515, DOI 10.1109/ICRA.2012.6224637.
   Rebecq H., IEEE ROBOT IN PRESS.
   Renyi A., 1960, P 4 BERK S MATH STAT.
   Requicha A. A. G., 1980, Computing Surveys, V12, P437.
   Riazuelo L, 2014, ROBOT AUTON SYST, V62, P401, DOI 10.1016/j.robot.2013.11.007.
   Robotics Kuka, 2016, KUKA NAVIGATION SOLU.
   Rosen DM, 2015, IEEE INT CONF ROBOT, P5822, DOI 10.1109/ICRA.2015.7140014.
   Rosen DM, 2013, IEEE INT CONF ROBOT, P1025, DOI 10.1109/ICRA.2013.6630699.
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y.
   Sabatta D, 2010, IEEE INT CONF ROBOT, P1008, DOI 10.1109/ROBOT.2010.5509382.
   Saeedi S, 2016, J FIELD ROBOT, V33, P3, DOI 10.1002/rob.21620.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Sengupta S, 2015, IEEE INT CONF ROBOT, P1874, DOI 10.1109/ICRA.2015.7139442.
   Shah J. J., 1995, PARAMETRIC FEATURE B.
   Shapiro V., 2002, HDB COMPUTER AIDED G, V20, P473, DOI 10.1016/B978-044451104-1/50021-6.
   Shen C, 2004, ACM T GRAPHIC, V23, P896, DOI 10.1145/1015706.1015816.
   Shoudong Huang, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P3011, DOI 10.1109/IROS.2010.5652603.
   Sibley G., 2009, P ROB SCI SYST C, P177.
   Singer A, 2011, SIAM J IMAGING SCI, V4, P543, DOI 10.1137/090767777.
   Singer A, 2011, APPL COMPUT HARMON A, V30, P20, DOI 10.1016/j.acha.2010.02.001.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Smith BM, 2009, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2009.5459270.
   Soatto S., 2016, CORR, P1.
   Soatto S., 2011, ARXIV11102053, P1.
   Song L., 2010, P 27 INT C MACH LEAR, P991.
   Srinaga Nikhil N, 2015, 2015 IEEE APPL EL C, P1, DOI {[}10.1109/AEMC.2015.7509236, DOI 10.1109/AEMC.2015.7509236].
   Stachniss C., 2005, ROBOTICS SCI SYSTEMS, P65.
   Stachniss C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1153.
   Stachniss C, 2009, SPRINGER TRAC ADV RO, V55, P3.
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Strub C, 2014, J IEEE I C DEVELOP L, P26, DOI 10.1109/DEVLRN.2014.6982950.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Thrun S., 1995, HDB BRAIN SCI NEURAL, P381.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Tipaldi GD, 2010, IEEE INT CONF ROBOT, P3616, DOI 10.1109/ROBOT.2010.5509864.
   Tong CH, 2013, INT J ROBOT RES, V32, P507, DOI 10.1177/0278364913478672.
   Triggs B., 2000, VISION ALGORITHMS TH, V1883, DOI {[}DOI 10.1007/3-540-44480-7\_21, 10.1007/3-540-44480-7\_21].
   Tron R., 2012, 2012 IEEE 51 IEEE C, P2052, DOI {[}10.1109/CDC.2012.6426677, DOI 10.1109/CDC.2012.6426677].
   Valencia R, 2012, IEEE INT C INT ROBOT, P1885, DOI 10.1109/IROS.2012.6385637.
   Valentin J, 2015, PROC CVPR IEEE, P4400, DOI 10.1109/CVPR.2015.7299069.
   Vallivaara I, 2010, 2010 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2010), P14, DOI 10.1109/MFI.2010.5604465.
   Vallve J, 2015, ROBOT AUTON SYST, V69, P68, DOI 10.1016/j.robot.2014.08.009.
   van den Berg J, 2012, INT J ROBOT RES, V31, P1263, DOI 10.1177/0278364912456319.
   Vineet V, 2015, IEEE INT CONF ROBOT, P75, DOI 10.1109/ICRA.2015.7138983.
   Wahlstrom Niklas, 2015, IFAC - Papers Online, V48, P1059, DOI 10.1016/j.ifacol.2015.12.271.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wang LH, 2013, INF INFERENCE, V2, P145, DOI 10.1093/imaiai/iat005.
   Wang SJ, 2014, INT CONF ACOUST SPEE.
   Wang Z., 2011, SIMULTANEOUS LOCALIZ.
   Whelan T., 2012, P RSS WORKSH RGB D A.
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Williams S, 2014, INT J ROBOT RES, V33, P1544, DOI 10.1177/0278364914531056.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.
   Wood R., 2015, ROBOBEES PROJECT.
   Yamauchi B, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA `97, PROCEEDINGS, P146, DOI 10.1109/CIRA.1997.613851.
   Yu KT, 2015, IEEE INT C INT ROBOT, P1208, DOI 10.1109/IROS.2015.7353523.
   Zach C., 2007, P 11 IEEE INT C COMP, V1, P1, DOI {[}10.1109/ICCV.2007.4408983, DOI 10.1109/ICCV.2007.4408983].
   Zhang J, 2016, IEEE INT CONF ROBOT, P809, DOI 10.1109/ICRA.2016.7487211.
   Zhang ST, 2012, MED IMAGE ANAL, V16, P265, DOI 10.1016/j.media.2011.08.004.
   Zhao L, 2013, IEEE INT C INT ROBOT, P24, DOI 10.1109/IROS.2013.6696327.},
Number-of-Cited-References = {266},
Times-Cited = {1188},
Usage-Count-Last-180-days = {175},
Usage-Count-Since-2013 = {844},
Journal-ISO = {IEEE Trans. Robot.},
Doc-Delivery-Number = {EE8BO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000389849700001},
OA = {Green Accepted, Green Submitted, Green Published},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000648775600027,
Author = {Li, ZiYuan and Yu, HuaPeng and Shen, TongSheng and Li, ZhiHui},
Book-Group-Author = {IEEE},
Title = {Segmented Matching Method of Multi-Geophysics Field SLAM Data Based on
   LSTM},
DOI = {10.1109/ICUS50048.2020.9274964},
Booktitle = {PROCEEDINGS OF 2020 3RD INTERNATIONAL CONFERENCE ON UNMANNED SYSTEMS
   (ICUS)},
Year = {2020},
Pages = {147-151},
Note = {3rd International Conference on Unmanned Systems (ICUS), Harbin, PEOPLES
   R CHINA, NOV 27-28, 2020},
Abstract = {At present, simultaneous localization and mapping (SLAM) has become an
   important method for autonomous underwater vehicles (AUVs) to realize
   long-term navigation. However, using only bathymetric data in unknown
   environment has its own disadvantages, that are low precision and large
   computational load. To tackle with requirements of high-precision
   navigation tinder large-scale and long-term voyage condition, a SLAM
   method and corresponding matching algorithm for integrating multi
   -geophysical field data are proposed. By dividing the feature data and
   location data of geophysical field obtained into various submaps and
   sub-segments during AUV sailing, the dominant navigation data of each
   segment is identified using long short-term memory network. Validity of
   the proposed method is done by simulation experiments. During the
   simulation, the loop closure detection of each submap is used, and the
   matching counter is set to check the correct matching rate. Finally, the
   matching results with single geophysics field data under the same
   conditions are compared with multi -geophysics field data and analyzed.
   The experimental results have demonstrated the feasibility and
   correctness of the proposed method.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Shen, TS (Corresponding Author), Natl Innovat Inst Def Technol, Beijing, Peoples R China.
   Li, ZiYuan; Li, ZhiHui, Harbin Engn Univ, Sci \& Technol Underwater Vehicle Lab, Harbin, Peoples R China.
   Li, ZiYuan; Yu, HuaPeng; Shen, TongSheng, Natl Innovat Inst Def Technol, Beijing, Peoples R China.},
ISBN = {978-1-7281-8025-0},
Keywords = {SLAM; LSTM; navigation; multi-geophysics field data; matching},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; AIDED NAVIGATION; UNDERWATER},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {liziyuan@hrbeu.edu.cn
   hpyu\_qtxy@163.com
   shents\_bj@126.com
   2876616669@qq.com},
Affiliations = {Harbin Engineering University},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61803381, 51309066,
   E091002]; National Key R\&D Program of china {[}2017YFC0305700,
   QNLM2016ORP0406]},
Funding-Text = {This work is supported by National Natural Science Foundation of China
   (61803381, 51309066, E091002), National Key R\&D Program of china
   (2017YFC0305700)and open fund project of the Qingdo National Labrotary
   for Marine Science and Technology (QNLM2016ORP0406).},
Cited-References = {Albert P, 2016, SENSORS, V16, P560.
   Barkby S, 2012, INT J ROBOT RES, V31, P1409, DOI 10.1177/0278364912459666.
   Barkby S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P219, DOI 10.1109/IROS.2009.5354248.
   Chang S, 2019, J UNMANNED UNDERSEA, V27, P277.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Hullos Natalia, 2015, J FIELD ROBOTICS, V32, P123.
   Johannsson H, 2010, IEEE INT C INT ROBOT, P4396, DOI 10.1109/IROS.2010.5650831.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Li Y, 2017, J NAVIGATION, V70, P1062, DOI 10.1017/S037346331700011X.
   Liu Y, 2007, IND EL APPL 2 IEEE C.
   Liu Z, 2016, MEASUREMENT SCI TECH, V27.
   Ma T, 2018, OCEAN ENG, V166, P336, DOI 10.1016/j.oceaneng.2018.08.029.
   Mallios A, 2014, AUTON ROBOT, V36, P181, DOI 10.1007/s10514-013-9345-0.
   Mu H W., 2013, RES AUV INTEGRATED N.
   Palomer A, 2013, OCEANS-IEEE.
   Peng HQ, 2006, GEOMAGNETIC MODEL GE, P76.
   Ribas D, 2008, J FIELD ROBOT, V25, P898, DOI 10.1002/rob.20249.
   Roman C, 2007, J FIELD ROBOT, V24, P23, DOI 10.1002/rob.20164.
   Roy N, 2012, P ROBOTICS SCI SYSTE, V32, P1611.
   Wang B, 2019, IEEE T IND ELECTRON, V66, P1203, DOI 10.1109/TIE.2018.2831171.
   Wu M, 2015, INT CONF UNMAN AIRCR, P839, DOI 10.1109/ICUAS.2015.7152369.
   Zhuo X, 2018, CHIN INSIGHT, P1, DOI 10.1007/978-981-10-6379-4.},
Number-of-Cited-References = {23},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BR3QE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000648775600027},
DA = {2022-05-17},
}

@inproceedings{ WOS:000769986900004,
Author = {Nevalainen, Paavo and Movahedi, Parisa and Queralta, Jorge Pena and
   Westerlund, Tomi and Heikkonen, Jukka},
Editor = {Lipping, T and Linna, P and Narra, N},
Title = {Long-Term Autonomy in Forest Environment Using Self-Corrective SLAM},
Booktitle = {NEW DEVELOPMENTS AND ENVIRONMENTAL APPLICATIONS OF DRONES},
Year = {2022},
Pages = {82-106},
Note = {FinDrones Conference, ELECTR NETWORK, NOV 12, 2020},
Abstract = {Vehicles with prolonged autonomous missions have to maintain environment
   awareness by simultaneous localization and mapping (SLAM). Closed-loop
   correction used for SLAM consistency maintenance is proposed to be
   substituted by interpolation in rigid body transformation space in order
   to systematically reduce the accumulated error over different scales.
   The computation is divided into an edge-computed lightweight SLAM and
   iterative corrections in the cloud environment. Tree locations in the
   forest environment are sent via a potentially limited communication
   bandwidth. Data from a real forest site is used in the verification of
   the proposed algorithm. The algorithm adds new iterative closest point
   (ICP) cases to the initial SLAM and measures the resulting map quality
   by the mean of the root mean squared error (RMSE) of individual tree
   clusters. Adding 4\% more match cases yields the mean RMSE of 0.15 m on
   a large site with 180 m odometric distance.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Nevalainen, P (Corresponding Author), Univ Turku, Fac Technol, Dept Comp, Turku, Finland.
   Nevalainen, Paavo; Movahedi, Parisa; Queralta, Jorge Pena; Westerlund, Tomi; Heikkonen, Jukka, Univ Turku, Fac Technol, Dept Comp, Turku, Finland.},
DOI = {10.1007/978-3-030-77860-6\_5},
ISBN = {978-3-030-77860-6; 978-3-030-77859-0},
Keywords = {Odometry; SLAM; Sparse point clouds; Lidar; Laser scanning; Forest
   localization; Autonomous navigation},
Keywords-Plus = {UAV LIDAR; REGISTRATION},
Research-Areas = {Agriculture; Forestry; Robotics; Remote Sensing},
Web-of-Science-Categories  = {Agronomy; Forestry; Robotics; Remote Sensing},
Author-Email = {ptneva@utu.fi
   parmov@utu.fi
   jopequ@utu.fi
   tovewe@utu.fi
   jukhei@utu.fi},
Affiliations = {University of Turku},
ResearcherID-Numbers = {Westerlund, Tomi/I-2167-2019},
ORCID-Numbers = {Nevalainen, Paavo/0000-0002-7646-929X
   Movahedi, Parisa/0000-0002-2571-9279
   Westerlund, Tomi/0000-0002-1793-2694},
Cited-References = {Akkiraju N., 1995, P INT COMP GEOM SOFT.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203.
   Chang L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174702.
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C.
   Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997.
   Chisholm RA, 2013, J UNMANNED VEH SYST, V1, P61, DOI 10.1139/juvs-2013-0017.
   Dantam N.T., 2018, WORKSH ALG FDN ROB, P639.
   Dorst L., 2010, GEOMETRIC ALGEBRA CO.
   Einhorn E, 2015, ROBOT AUTON SYST, V69, P28, DOI 10.1016/j.robot.2014.08.008.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Franceschetti G., 2007, SCATTERING NATURAL S, P21.
   Li QQ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12111870.
   Lin JR, 2020, IEEE INT CONF ROBOT, P3126, DOI 10.1109/ICRA40945.2020.9197440.
   Liu R., 2019, ARXIV190605096.
   Lynch K.M., 2017, MODERN ROBOTICS MECH.
   Moler C, 2003, SIAM REV, V45, P3, DOI 10.1137/S00361445024180.
   Nevalainen P, 2020, REPLICATION DATA NAV, DOI {[}10.4225/13/511C71F8612C3, DOI 10.4225/13/511C71F8612C3].
   Nevalainen P, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12244088.
   Ortiz Arteaga A., 2019, ISPRS INT ARCH PHOTO, V42, P233.
   PARK FC, 1995, J MECH DESIGN, V117, P48, DOI 10.1115/1.2826116.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Queralta J. P., 2020, VIO UWB BASED COLLAB.
   Queralta JP, 2020, IEEE ACCESS, V8, P191617, DOI 10.1109/ACCESS.2020.3030190.
   Sankey T, 2017, REMOTE SENS ENVIRON, V195, P30, DOI 10.1016/j.rse.2017.04.007.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Tang J, 2015, FORESTS, V6, P4588, DOI 10.3390/f6124390.
   The Mathworks Inc., 2020, MATLAB VERSION 9 8 0.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Wu JX, 2020, RESULTS ENG, V6, DOI 10.1016/j.rineng.2020.100106.
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405.
   Zefran M, 1998, COMPUT AIDED DESIGN, V30, P179, DOI 10.1016/S0010-4485(97)00060-2.
   Zhongli Wang, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P929, DOI 10.1109/RCAR47638.2019.9044021.},
Number-of-Cited-References = {33},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS8BD},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000769986900004},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000349834602115,
Author = {Labbe, Mathieu and Michaud, Francois},
Book-Group-Author = {IEEE},
Title = {Online Global Loop Closure Detection for Large-Scale Multi-Session
   Graph-Based SLAM},
DOI = {10.1109/IROS.2014.6942926},
Booktitle = {2014 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2014)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2014},
Pages = {2661-2666},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Chicago, IL, SEP 14-18, 2014},
Abstract = {For large-scale and long-term simultaneous localization and mapping
   (SLAM), a robot has to deal with unknown initial positioning caused by
   either the kidnapped robot problem or multi-session mapping. This paper
   addresses these problems by tying the SLAM system with a global loop
   closure detection approach, which intrinsically handles these
   situations. However, online processing for global loop closure detection
   approaches is generally influenced by the size of the environment. The
   proposed graph-based SLAM system uses a memory management approach that
   only consider portions of the map to satisfy online processing
   requirements. The approach is tested and demonstrated using five indoor
   mapping sessions of a building using a robot equipped with a laser
   rangefinder and a Kinect.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Labbe, M (Corresponding Author), Univ Sherbrooke, Interdisciplinary Inst Technol Innovat 3IT, 2500 Boul Univ, Sherbrooke, PQ J1K 2R1, Canada.
   Labbe, Mathieu; Michaud, Francois, Univ Sherbrooke, Interdisciplinary Inst Technol Innovat 3IT, Sherbrooke, PQ J1K 2R1, Canada.},
ISSN = {2153-0858},
ISBN = {978-1-4799-6934-0},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {Mathieu.M.Labbe@USherbrooke.ca
   Francois.Michaud@USherbrooke.ca},
Affiliations = {University of Sherbrooke},
ORCID-Numbers = {Labbe, Mathieu/0000-0003-0778-5595},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Atkinson, 1968, PSYCHOL LEARNING MOT, V2, P89, DOI {[}DOI 10.1016/S0079-7421(08)60422-3, 10.1016/s0079-7421(08)60422-3.].
   Baddeley, 1997, HUMAN MEMORY THEORY.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Booij O, 2009, ROBOT AUTON SYST, V57, P1225, DOI 10.1016/j.robot.2009.06.006.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Botterill T, 2011, J FIELD ROBOT, V28, P204, DOI 10.1002/rob.20368.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Ferland F, 2010, IEEE INT C INT ROBOT, P2515, DOI 10.1109/IROS.2010.5649041.
   Folkesson J, 2007, IEEE T ROBOT, V23, P731, DOI 10.1109/TRO.2007.900608.
   Grisetti G, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3478.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Johannsson H, 2012, RSS WORKSH LONG TERM.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Latif Y., 2012, ROBOTICS SCI SYSTEMS.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   McDonald J., 2012, ROBOTICS AUTONOMOUS, V61, P1144.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.},
Number-of-Cited-References = {23},
Times-Cited = {217},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {33},
Doc-Delivery-Number = {BC0YL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000349834602115},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000502543900016,
Author = {Ganti, Pranav and Waslander, Steven L.},
Book-Group-Author = {IEEE},
Title = {Network Uncertainty Informed Semantic Feature Selection for Visual SLAM},
Booktitle = {2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019)},
Year = {2019},
Pages = {121-128},
Note = {16th Conference on Computer and Robot Vision (CRV), Kingston, CANADA,
   MAY 29-31, 2019},
Abstract = {In order to facilitate long-term localization using a visual
   simultaneous localization and mapping (SLAM) algorithm, careful feature
   selection can help ensure that reference points persist over long
   durations and the runtime and storage complexity of the algorithm remain
   consistent. We present SIVO (Semantically Informed Visual Odometry and
   Mapping), a novel information-theoretic feature selection method for
   visual SLAM which incorporates semantic segmentation and neural network
   uncertainty into the feature selection pipeline. Our algorithm selects
   points which provide the highest reduction in Shannon entropy between
   the entropy of the current state and the joint entropy of the state,
   given the addition of the new feature with the classification entropy of
   the feature from a Bayesian neural network. Each selected feature
   significantly reduces the uncertainty of the vehicle state and has been
   detected to be a static object (building, traffic sign, etc.) repeatedly
   with a high confidence. This selection strategy generates a sparse map
   which can facilitate long-term localization. The KITTI odometry dataset
   is used to evaluate our method, and we also compare our results against
   ORB\_SLAM2. Overall, SIVO performs comparably to the baseline method
   while reducing the map size by almost 70\%.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ganti, P (Corresponding Author), Univ Waterloo, Dept Mech \& Mechatron Engn, Waterloo, ON, Canada.
   Ganti, Pranav, Univ Waterloo, Dept Mech \& Mechatron Engn, Waterloo, ON, Canada.
   Waslander, Steven L., Univ Toronto, Inst Aerosp Studies, Toronto, ON, Canada.},
DOI = {10.1109/CRV.2019.00024},
ISBN = {978-1-7281-1838-3},
Keywords = {Localization; Mapping; SLAM; Deep Learning; Information Theory; Semantic
   Segmentation},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {pganti@uwaterloo.ca
   stevenw@utias.utoronto.ca},
Affiliations = {University of Waterloo; University of Toronto},
Cited-References = {An LF, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417735667.
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203.
   Chli M., 2010, THESIS.
   Choudhary S, 2015, IEEE INT CONF ROBOT, P4620, DOI 10.1109/ICRA.2015.7139839.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Cover T. M., 2012, ELEMENTS INFORM THEO.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Davison AJ, 2005, IEEE I CONF COMP VIS, P66.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Gal Y., 2015, ARXIV150602158.
   Gal Y., 2016, UNCERTAINTY DEEP LEA.
   Gal Y., 2015, ARXIV150602157.
   Gal Y, 2016, PR MACH LEARN RES, V48.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Hochdorfer S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P382, DOI 10.1109/IROS.2009.5354433.
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kendall A., 2015, ARXIV151102680.
   Kendall A., 2017, P ADV NEUR INF PROC, P5574.
   Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679.
   Kumar RT., 2017, P 2017 IEEE 20 INT C, P1.
   Li X., 2016, ARXIV161104144.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mu BP, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4602, DOI 10.1109/IROS.2016.7759677.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Neal R. M., 1995, THESIS.
   Nister David, 2004, IEEE C COMP VIS PATT, V1.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Strasdat H., 2009, IEEE INT C ROB AUT K, P1410.
   Zhang F, 2005, 2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings, P2117.},
Number-of-Cited-References = {38},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {10},
Doc-Delivery-Number = {BO1TX},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000502543900016},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000389516200128,
Author = {Rosen, David M. and Mason, Julian and Leonard, John J.},
Editor = {Okamura, A and Menciassi, A and Ude, A and Burschka, D and Lee, D and Arrichiello, F and Liu, H and Moon, H and Neira, J and Sycara, K and Yokoi, K and Martinet, P and Oh, P and Valdastri, P and Krovi, V},
Title = {Towards Lifelong Feature-Based Mapping in Semi-Static Environments},
DOI = {10.1109/ICRA.2016.7487237},
Booktitle = {2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2016},
Pages = {1063-1070},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Royal
   Inst Technol, Ctr Autonomous Syst, Stockholm, SWEDEN, MAY 16-21, 2016},
Abstract = {The feature-based graphical approach to robotic mapping provides a
   representationally rich and computationally efficient framework for an
   autonomous agent to learn a model of its environment. However, this
   formulation does not naturally support long-term autonomy because it
   lacks a notion of environmental change; in reality, ``everything changes
   and nothing stands still,{''} and any mapping and localization system
   that aims to support truly persistent autonomy must be similarly
   adaptive. To that end, in this paper we propose a novel feature-based
   model of environmental evolution over time. Our approach is based upon
   the development of an expressive probabilistic generative feature
   persistence model that describes the survival of abstract semi-static
   environmental features over time. We show that this model admits a
   recursive Bayesian estimator, the persistence filter, that provides an
   exact online method for computing, at each moment in time, an explicit
   Bayesian belief over the persistence of each feature in the environment.
   By incorporating this feature persistence estimation into current
   state-of-the-art graphical mapping techniques, we obtain a flexible,
   computationally efficient, and information-theoretically rigorous
   framework for lifelong environmental modeling in an ever-changing world.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Rosen, DM (Corresponding Author), MIT, Comp Sci \& Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Rosen, David M.; Leonard, John J., MIT, Comp Sci \& Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Mason, Julian, Google, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4673-8026-3},
Keywords-Plus = {LARGE-SCALE; SLAM; MAPS},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {dmrosen@mit.edu
   jmason@google.com
   jleonard@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT); Google Incorporated},
Cited-References = {Biber P., 2005, ROBOTICS SCI SYSTEMS.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Burgard W., 2012, 26 AAAI C ART INT, P2024.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dellaert F., 2012, GTRIMCPR2012002.
   Friedman N., 2009, PROBABILISTIC GRAPHI.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Grisetti G, 2009, IEEE T INTELL TRANSP, V10, P428, DOI 10.1109/TITS.2009.2026444.
   Huang GQ, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P150, DOI 10.1109/ECMR.2013.6698835.
   Ibrahim J.G., 2001, BAYESIAN SURVIVAL AN, V1st ed..
   JAYNES ET, 1968, IEEE T SYST SCI CYB, VSSC4, P227, DOI 10.1109/TSSC.1968.300117.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Konolige K., IEEE RSJ INT C INT R, P1156.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Mazuran M., 2014, ROBOTICS SCI SYSTEMS.
   MORAVEC HP, 1985, IEEE T ROBOTIC AUTOM, P116.
   Rosen DM, 2014, IEEE T ROBOT, V30, P1091, DOI 10.1109/TRO.2014.2321852.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Thrun S, 2008, PROBABILISTIC ROBOTI.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {27},
Times-Cited = {31},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG5KH},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000389516200128},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000235460100103,
Author = {Newman, P and Ho, K},
Book-Group-Author = {IEEE},
Title = {SLAM - Loop closing with visually salient features},
DOI = {10.1109/ROBOT.2005.1570189},
Booktitle = {2005 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA),
   VOLS 1-4},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2005},
Pages = {635-642},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Barcelona, SPAIN, APR 18-22, 2005},
Abstract = {Within the context of Simultaneous Localisation and Mapping (SLAM),
   ``loop closing{''} is the task of deciding whether or not a vehicle has,
   after an excursion of arbitrary length, returned to a previously visited
   area. Reliable loop closing is both essential and hard. It is without
   doubt one of the greatest impediments to long term, robust SLAM.
   This paper illustrates how visual features, used in conjunction with
   scanning laser data, can be used to a great advantage. We use the notion
   of visual saliency to focus the selection of suitable (affine invariant)
   image-feature descriptors for storage in a database. When queried with a
   recently taken image the database returns the capture time of matching
   images. This time information is used to discover loop closing events.
   Crucially this is achieved independently of estimated map and vehicle
   location.
   We integrate the above technique into a SLAM algorithm using delayed
   vehicle states and scan matching to form interpose geometric
   constraints. We present initial results using this system to close loops
   (around 100m) in an indoor environment.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Newman, P (Corresponding Author), Univ Oxford, Dept Engn Sci, Robot Res Grp, Parks Rd, Oxford OX1 3PJ, England.
   Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {0-7803-8914-X},
Keywords = {mobile robotics; SLAM; loop closing; saliency; visual features},
Keywords-Plus = {SCALE},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {pnewman@robots.ox.ac.uk
   klh@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
ResearcherID-Numbers = {Newman, Paul M/E-9190-2011},
Cited-References = {ARRAS KO, 2003, ROBOTICS AUTONOMOUS, V1056, P1.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Choset H., 2001, IEEE T ROBOTICS AUTO, V17.
   Cormen T.H., 2002, INTRO ALGORITHMS.
   Davison A. J., 2002, IEEE T PATTERN ANAL.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   ELIAZAR A, P INT JOINT C ART IN.
   FOX D, 2003, P INT S ROB RES.
   FRAUNDORFER F, 2002, 26 WORKSH AUSTR ASS, P249.
   Gilles S., 1998, THESIS U OXFORD.
   GUTMANN JS, 1999, P C INT ROB APPL CIR.
   HAHNEL D, 2003, 11 INT S ROB RES SIE.
   HAYET JB, 2003, P INT C COMP VIS PAT.
   HYGOUNENC E, 2003, INT J ROBOTICS RES.
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855.
   KNIGHT J, 2001, P IEEE RSJ INT C INT, P406.
   KONOLIGE K, 2004, P NAT C AI AAAI SAN.
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95.
   LEONARD JJ, 2001, P 10 INT S ROB RES.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   MCLAUCHLAN PF, 2000, INT C COMP VIS PATT, V2, P738.
   Montemerlo M, 2002, P AAAI NAT C ART INT.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   NEIRA J, 2003, IEEE T ROBOTICS AUTO.
   NEISSER U, 1964, SCI AM, V210, P94, DOI 10.1038/scientificamerican0664-94.
   NEWMAN PM, 2001, P NOV 2001 SPIE C BO.
   Ortin D, 2003, IEEE INT CONF ROBOT, P1007.
   Paskin M. A., 2003, P 18 INT JOINT C ART, P1157.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   SIVIC J, 2003, P INT C COMP VIS OCT.
   Smith R., 1987, 4 INT S ROB RES.},
Number-of-Cited-References = {33},
Times-Cited = {95},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BDU48},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000235460100103},
DA = {2022-05-17},
}

@article{ WOS:000787623300001,
Author = {Hong, Ziyang and Petillot, Yvan and Wallace, Andrew and Wang, Sen},
Title = {RadarSLAM: A robust simultaneous localization and mapping system for all
   weather conditions},
Year = {2022},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Abstract = {A Simultaneous Localization and Mapping (SLAM) system must be robust to
   support long-term mobile vehicle and robot applications. However, camera
   and LiDAR based SLAM systems can be fragile when facing challenging
   illumination or weather conditions which degrade the utility of imagery
   and point cloud data. Radar, whose operating electromagnetic spectrum is
   less affected by environmental changes, is promising although its
   distinct sensor model and noise characteristics bring open challenges
   when being exploited for SLAM. This paper studies the use of a Frequency
   Modulated Continuous Wave radar for SLAM in large-scale outdoor
   environments. We propose a full radar SLAM system, including a novel
   radar motion estimation algorithm that leverages radar geometry for
   reliable feature tracking. It also optimally compensates motion
   distortion and estimates pose by joint optimization. Its loop closure
   component is designed to be simple yet efficient for radar imagery by
   capturing and exploiting structural information of the surrounding
   environment. Extensive experiments on three public radar datasets,
   ranging from city streets and residential areas to countryside and
   highways, show competitive accuracy and reliability performance of the
   proposed radar SLAM system compared to the state-of-the-art LiDAR,
   vision and radar methods. The results show that our system is
   technically viable in achieving reliable SLAM in extreme weather
   conditions on the RADIATE Dataset, for example, heavy snow and dense
   fog, demonstrating the promising potential of using radar for
   all-weather localization and mapping.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Wang, S (Corresponding Author), Heriot Watt Univ, Sch Engn \& Phys Sci, Inst Sensors Signals \& Syst, Edinburgh EH14 4AS, Midlothian, Scotland.
   Hong, Ziyang; Petillot, Yvan; Wallace, Andrew; Wang, Sen, Heriot Watt Univ, Edinburgh Ctr Robot, Edinburgh, Midlothian, Scotland.},
DOI = {10.1177/02783649221080483},
EarlyAccessDate = {APR 2022},
Article-Number = {02783649221080483},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {radar sensing; simultaneous localization and mapping; all-weather
   perception},
Keywords-Plus = {SLAM; VERSATILE},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {s.wang@hw.ac.uk},
Affiliations = {Heriot Watt University},
Funding-Acknowledgement = {EPSRC Robotics and Artificial Intelligence ORCA Hub {[}EP/R026173/1]; EU
   H2020 Programme under EUMarineRobots project {[}ID 731103]},
Funding-Text = {The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by EPSRC Robotics and Artificial Intelligence ORCA Hub
   (grant No. EP/R026173/1) and EU H2020 Programme under EUMarineRobots
   project (grant ID 731103).},
Cited-References = {Aldera R, 2019, IEEE INT C INTELL TR, P2835, DOI 10.1109/ITSC.2019.8917111.
   Aldera R, 2019, IEEE INT CONF ROBOT, P1190, DOI 10.1109/ICRA.2019.8794014.
   Aldibaja M, 2016, IEEE/SICE I S SYS IN, P212, DOI 10.1109/SII.2016.7844000.
   Almalioglu Y, 2021, IEEE SENS J, V21, P3314, DOI 10.1109/JSEN.2020.3023243.
   Bailo O, 2018, PATTERN RECOGN LETT, V106, P53, DOI 10.1016/j.patrec.2018.02.020.
   Barnes D., 2020, C ROB LEARN, P303.
   Barnes D, 2020, IEEE INT CONF ROBOT, P6433, DOI 10.1109/ICRA40945.2020.9196884.
   Barnes D, 2020, IEEE INT CONF ROBOT, P9484, DOI 10.1109/ICRA40945.2020.9196835.
   Behley J, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Burnett K, 2021, IEEE ROBOT AUTOM LET, V6, P771, DOI 10.1109/LRA.2021.3052439.
   Campos C., 2020, ORB SLAM3 ACCURATE O.
   Carballo A., 2020, ARXIV PREPRINT ARXIV.
   Cen SH, 2019, IEEE INT CONF ROBOT, P298, DOI 10.1109/ICRA.2019.8793990.
   Cen SH, 2018, IEEE INT CONF ROBOT, P6045, DOI 10.1109/ICRA.2018.8460687.
   CHALLIS JH, 1995, J BIOMECH, V28, P733, DOI 10.1016/0021-9290(94)00116-L.
   Chandran M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P808, DOI 10.1109/IROS.2006.281673.
   Charron N, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P254, DOI 10.1109/CRV.2018.00043.
   Checchin P, 2010, SPRINGER TRAC ADV RO, V62, P151.
   Clark S, 1998, IEEE INT CONF ROBOT, P3697, DOI 10.1109/ROBOT.1998.681411.
   De Martini D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216002.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Gadd Matthew, 2020, 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), P270, DOI 10.1109/PLANS46316.2020.9109951.
   Gadd M., 2021, ARXIV PREPRINT ARXIV.
   Garg K, 2004, PROC CVPR IEEE, P528.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Himstedt M, 2014, IEEE INT C INT ROBOT, P5030, DOI 10.1109/IROS.2014.6943277.
   Holder M, 2019, IEEE INT VEH SYM, P1145, DOI 10.1109/IVS.2019.8813841.
   Hong ZY, 2020, IEEE INT C INT ROBOT, P5164, DOI 10.1109/IROS45743.2020.9341287.
   Howard A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3946, DOI 10.1109/IROS.2008.4651147.
   Huang HY, 2019, IEEE INT C INTELL TR, P1290, DOI 10.1109/ITSC.2019.8916977.
   Jokela M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112341.
   Jose E., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3087, DOI 10.1109/IROS.2005.1545232.
   Kim G, 2020, IEEE INT CONF ROBOT, P6246.
   Konc J, 2007, MATCH-COMMUN MATH CO, V58, P569.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299.
   Lucas BD, 1981, ITERATIVE IMAGE REGI.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Marck JW, 2013, EUROP RADAR CONF, P471.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Ort T, 2020, IEEE ROBOT AUTOM LET, V5, P3267, DOI 10.1109/LRA.2020.2976310.
   Park YS, 2020, IEEE INT CONF ROBOT, P2617, DOI 10.1109/ICRA40945.2020.9197231.
   Park YS, 2019, IEEE INT C INT ROBOT, P1307, DOI 10.1109/IROS40897.2019.8967633.
   Porav H, 2019, IEEE INT CONF ROBOT, P7087, DOI 10.1109/ICRA.2019.8793486.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Ren WH, 2017, PROC CVPR IEEE, P2838, DOI 10.1109/CVPR.2017.303.
   Rouveure R., 2009, INT RAD C SURV SAF W, P1.
   Saftescu S, 2020, IEEE INT CONF ROBOT, P4358, DOI 10.1109/ICRA40945.2020.9196682.
   Schubert D, 2018, LECT NOTES COMPUT SC, V11212, P699, DOI 10.1007/978-3-030-01237-3\_42.
   Schuster F, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2559, DOI 10.1109/ITSC.2016.7795967.
   Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Sheeny M., 2021, IEEE INT C ROB AUT I.
   Sola J., 2018, ABS181201537 CORR.
   Tang TY, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
   Tang TYQ, 2020, IEEE ROBOT AUTOM LET, V5, P1087, DOI 10.1109/LRA.2020.2965907.
   Vivet D, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56636.
   Vivet D, 2012, IEEE INT CONF ROBOT, P2618, DOI 10.1109/ICRA.2012.6224573.
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2\_11.
   Yamada M, 2019, IEEE INT C INTELL TR, P293, DOI 10.1109/ITSC.2019.8917241.
   Yoneda K, 2018, IEEE INT VEH SYM, P971, DOI 10.1109/IVS.2018.8500378.
   Zhang C, 2018, IEEE INT C INT ROBOT, P3409, DOI 10.1109/IROS.2018.8593703.
   Zhang J., 2014, ROBOT SCI SYST, V2, P9.
   Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941.},
Number-of-Cited-References = {66},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {0U4LQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000787623300001},
OA = {hybrid},
DA = {2022-05-17},
}

@inproceedings{ WOS:000457881302097,
Author = {Luthardt, Stefan and Willert, Volker and Adamy, Juergen},
Book-Group-Author = {IEEE},
Title = {LLama-SLAM: Learning High-Quality Visual Landmarks for Long-Term Mapping
   and Localization},
DOI = {10.1109/ITSC.2018.8569323},
Booktitle = {2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2018},
Pages = {2645-2652},
Note = {21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC), Maui, HI, NOV 04-07, 2018},
Abstract = {The precise localization of vehicles is an important requirement for
   autonomous driving or advanced driver assistance systems. Using common
   GNSS the ego position can be measured but not with the reliability and
   precision necessary. An alternative approach to achieve precise
   localization is the usage of visual landmarks observed by a camera
   mounted in the vehicle. However, this raises the necessity of reliable
   visual landmarks that are easily recognizable and persistent. We propose
   a novel SLAM algorithm that focuses on learning and mapping such visual
   long-term landmarks (LLamas). The algorithm therefore processes stereo
   image streams from several recording sessions in the same spatial area.
   The key part within LLama-SLAM is the assessment of the landmarks with
   quality values that are inferred as viewpoint dependent probabilities
   from observation statistics. By adding solely landmarks of high quality
   to the final LLama Map, it can be kept compact while still allowing
   reliable localization. Due to the long-term evaluation of the GNSS
   measurement during the sessions, the landmarks can be positioned
   precisely in a global referenced coordinate system. For a first
   assessment of the algorithm's capabilities, we present some experimental
   results from the mapping process combining three sessions recorded over
   two months on the same route.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Luthardt, S (Corresponding Author), Tech Univ Darmstadt, Control Methods \& Robot, Darmstadt, Germany.
   Luthardt, Stefan; Willert, Volker; Adamy, Juergen, Tech Univ Darmstadt, Control Methods \& Robot, Darmstadt, Germany.},
ISSN = {2153-0009},
ISBN = {978-1-7281-0323-5},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering;
   Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Transportation
   Science \& Technology},
Affiliations = {Technical University of Darmstadt},
Cited-References = {Bishop, 2006, INFORM SCI STAT, V1.
   Bresson G, 2017, IEEE T INTELL VEHICL, V2, P194, DOI 10.1109/TIV.2017.2749181.
   Buczko M, 2017, IEEE INT VEH SYM, P739, DOI 10.1109/IVS.2017.7995805.
   Buczko M, 2016, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2016.7535429.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cvisic I., 2017, J FIELD ROBOT, V13, P99.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Delobel L, 2017, IEEE INT VEH SYM, P1342, DOI 10.1109/IVS.2017.7995898.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Schuster F., 2017, IEEE 20 INT C INT TR, P1.
   Sons M, 2017, IEEE INT VEH SYM, P1158, DOI 10.1109/IVS.2017.7995869.
   Stubler M, 2017, 2017 SENSOR DATA FUSION: TRENDS, SOLUTIONS, APPLICATIONS (SDF).
   Willert Volker, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P711, DOI 10.1109/ICCVW.2009.5457632.
   Willert V, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P117.},
Number-of-Cited-References = {26},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BL9OB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000457881302097},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000377221103109,
Author = {Pomerleau, Francois and Krusi, Philipp and Colas, Francis and Furgale,
   Paul and Siegwart, Roland},
Book-Group-Author = {IEEE},
Title = {Long-term 3D map maintenance in dynamic environments},
DOI = {10.1109/ICRA.2014.6907397},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2014},
Pages = {3712-3719},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014},
Abstract = {New applications of mobile robotics in dynamic urban areas require more
   than the single-session geometric maps that have dominated simultaneous
   localization and mapping (SLAM) research to date; maps must be updated
   as the environment changes and include a semantic layer (such as road
   network information) to aid motion planning in dynamic environments. We
   present an algorithm for long-term localization and mapping in real time
   using a three-dimensional (3D) laser scanner. The system infers the
   static or dynamic state of each 3D point in the environment based on
   repeated observations. The velocity of each dynamic point is estimated
   without requiring object models or explicit clustering of the points. At
   any time, the system is able to produce a most-likely representation of
   underlying static scene geometry. By storing the time history of
   velocities, we can infer the dominant motion patterns within the map.
   The result is an online mapping and localization system specifically
   designed to enable long-term autonomy within highly dynamic
   environments. We validate the approach using data collected around the
   campus of ETH Zurich over seven months and several kilometers of
   navigation. To the best of our knowledge, this is the first work to
   unify long-term map update with tracking of dynamic objects.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pomerleau, F (Corresponding Author), ETH, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Pomerleau, Francois; Krusi, Philipp; Colas, Francis; Furgale, Paul; Siegwart, Roland, ETH, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-3685-4},
Keywords = {Long-term mapping; dynamic obstacles; ICP; kd-tree; registration; scan
   matching; robot; SLAM},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {f.pomerleau@gmail.com},
Affiliations = {ETH Zurich},
ResearcherID-Numbers = {Pomerleau, François/N-7629-2017
   Siegwart, Roland/A-4495-2008},
ORCID-Numbers = {Pomerleau, François/0000-0003-1288-2744
   Siegwart, Roland/0000-0002-2760-7983},
Cited-References = {Aijazi AK, 2013, REMOTE SENS-BASEL, V5, P3701, DOI 10.3390/rs5083701.
   Alonso-Mora J, 2012, INT J ROBOT RES, V31, P753, DOI 10.1177/0278364912442095.
   Anderson-Sprecher Peter, 2011, IEEE International Conference on Robotics and Automation, P3104.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Burgard W., 2007, AUTONOMOUS NAVIGATIO, P3, DOI 10.1007/978-3-540-73422- 2\_1.
   Elseberg J., 2012, J SOFT ENG ROBOT, V3, P2.
   FELDMAR J, 1994, CVPR 1994 SEATTL WA, P496.
   Furgale P, 2013, IEEE INT VEH SYM, P809, DOI 10.1109/IVS.2013.6629566.
   Kaestner R, 2012, IEEE INT CONF ROBOT, P3075, DOI 10.1109/ICRA.2012.6224585.
   Kim K., 2011, P IEEE INT C COMP VI.
   Kummerle R., 2013, P IEEE INT C ROB AUT.
   Moosmann F, 2010, IEEE INT CONF ROBOT, P142, DOI 10.1109/ROBOT.2010.5509381.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Rufli M, 2013, IEEE T ROBOT, V29, P899, DOI 10.1109/TRO.2013.2258733.
   Ryde J, 2011, IEEE INT CONF ROBOT, P1484.
   Shackleton J, 2010, P 7 IEEE INT C ADV V, P420, DOI DOI 10.1109/AVSS.2010.52.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wurm K. M., 2010, WORKSH BEST PRACT 3D.},
Number-of-Cited-References = {18},
Times-Cited = {57},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {17},
Doc-Delivery-Number = {BE9BP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000377221103109},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000463352600012,
Author = {Chen, Xieyuanli and Lu, Huimin and Xiao, Junhao and Zhang, Hui and Wang,
   Pan},
Editor = {Liu, M and Chen, H and Vincze, M},
Title = {Robust Relocalization Based on Active Loop Closure for Real-Time
   Monocular SLAM},
Booktitle = {COMPUTER VISION SYSTEMS, ICVS 2017},
Series = {Lecture Notes in Computer Science},
Year = {2017},
Volume = {10528},
Pages = {131-143},
Note = {11th International Conference on Computer Vision Systems (ICVS),
   Shenzhen, PEOPLES R CHINA, JUL 10-13, 2017},
Abstract = {Remarkable performance has been achieved using the state-of-the-art
   monocular Simultaneous Localization and Mapping (SLAM) algorithms.
   However, tracking failure is still a challenging problem during the
   monocular SLAM process, and it seems to be even inevitable when carrying
   out long-term SLAM in large-scale environments. In this paper, we
   propose an active loop closure based relocalization system, which
   enables the monocular SLAM to detect and recover from tracking failures
   automatically even in previously unvisited areas where no keyframe
   exists. We test our system by extensive experiments including using the
   most popular KITTI dataset, and our own dataset acquired by a hand-held
   camera in outdoor large-scale and indoor small-scale real-world
   environments where man-made shakes and interruptions were added. The
   experimental results show that the least recovery time (within 5 ms) and
   the longest success distance (up to 46 m) were achieved comparing to
   other relocalization systems. Furthermore, our system is more robust
   than others, as it can be used in different kinds of situations, i.e.,
   tracking failures caused by the blur, sudden motion and occlusion.
   Besides robots or autonomous vehicles, our system can also be employed
   in other applications, like mobile phones, drones, etc.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Lu, HM (Corresponding Author), Natl Univ Def Technol, Coll Mechatron \& Automat, Changsha 410073, Hunan, Peoples R China.
   Chen, Xieyuanli; Lu, Huimin; Xiao, Junhao; Zhang, Hui; Wang, Pan, Natl Univ Def Technol, Coll Mechatron \& Automat, Changsha 410073, Hunan, Peoples R China.},
DOI = {10.1007/978-3-319-68345-4\_12},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-68345-4; 978-3-319-68344-7},
Keywords = {Relocalization; Monocular SLAM; Active loop closure; Robots},
Keywords-Plus = {VISION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods},
Author-Email = {chenxieyuanli@hotmail.com
   lhmnew@nudt.edu.cn},
Affiliations = {National University of Defense Technology - China},
ResearcherID-Numbers = {Chen, Xieyuanli/AAH-6401-2020
   },
ORCID-Numbers = {Chen, Xieyuanli/0000-0003-0955-6681
   Xiao, Junhao/0000-0002-4751-539X},
Funding-Acknowledgement = {National Science Foundation of China {[}61403409, 61503401]},
Funding-Text = {This work was supported by National Science Foundation of China (No.
   61403409, No. 61503401).},
Cited-References = {Bay H., 2006, EUR C COMP VIS, P404.
   Clemente L.A., 2007, P ROB SCI SYST, P297.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Eade E., 2008, P BRIT MACH VIS C, V13, P136.
   Feder HJS, 1999, INT J ROBOT RES, V18, P650, DOI 10.1177/02783649922066484.
   Feng YJ, 2015, LECT NOTES COMPUT SC, V9008, P206, DOI 10.1007/978-3-319-16628-5\_15.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518.
   Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4\_59.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Pupilli M, 2005, BRIT MACH VIS C BMVC.
   Rahimi A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P315, DOI 10.1109/ICCV.2001.937535.
   Reitmayr Gerhard, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P109, DOI 10.1109/ISMAR.2006.297801.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Se S, 2005, IEEE T ROBOT, V21, P364, DOI 10.1109/TRO.2004.839228.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Stachniss C, 2010, IEEE RSJ INT C INT R, P1505.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Straub J, 2013, IEEE IMAGE PROC, P2548, DOI 10.1109/ICIP.2013.6738525.
   Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.},
Number-of-Cited-References = {26},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BM4IC},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000463352600012},
DA = {2022-05-17},
}

@article{ WOS:000432977900002,
Author = {Labbe, Mathieu and Michaud, Francois},
Title = {Long-term online multi-session graph-based SPLAM with memory management},
Journal = {AUTONOMOUS ROBOTS},
Year = {2018},
Volume = {42},
Number = {6},
Pages = {1133-1150},
Month = {AUG},
Abstract = {For long-term simultaneous planning, localization and mapping (SPLAM), a
   robot should be able to continuously update its map according to the
   dynamic changes of the environment and the new areas explored. With
   limited onboard computation capabilities, a robot should also be able to
   limit the size of the map used for online localization and mapping. This
   paper addresses these challenges using a memory management mechanism,
   which identifies locations that should remain in a Working Memory (WM)
   for online processing from locations that should be transferred to a
   Long-Term Memory (LTM). When revisiting previously mapped areas that are
   in LTM, the mechanism can retrieve these locations and place them back
   in WM for online SPLAM. The approach is tested on a robot equipped with
   a short-range laser rangefinder and a RGB-D camera, patrolling
   autonomously 10.5 km in an indoor environment over 11 sessions while
   having encountered 139 people.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Labbe, M (Corresponding Author), Univ Sherbrooke, Interdisciplinary Inst Technol Innovat 3IT, Sherbrooke, PQ, Canada.
   Labbe, Mathieu; Michaud, Francois, Univ Sherbrooke, Interdisciplinary Inst Technol Innovat 3IT, Sherbrooke, PQ, Canada.},
DOI = {10.1007/s10514-017-9682-5},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {SLAM; Path planning; Pose graph; Multi-session; Loop closure detection},
Keywords-Plus = {LOOP CLOSURE DETECTION; ROBUST; SLAM},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {mathieu.m.labbe@usherbrooke.ca
   francois.michaud@usherbrooke.ca},
Affiliations = {University of Sherbrooke},
ORCID-Numbers = {Labbe, Mathieu/0000-0003-0778-5595},
Funding-Acknowledgement = {Natural Sciences and Engineering Research Council of Canada (NSERC);
   Canada Research Chair program; Canadian Foundation for Innovation},
Funding-Text = {This work was supported by the Natural Sciences and Engineering Research
   Council of Canada (NSERC), the Canada Research Chair program and the
   Canadian Foundation for Innovation.},
Cited-References = {Atkinson, 1968, PSYCHOL LEARNING MOT, V2, P89, DOI {[}DOI 10.1016/S0079-7421(08)60422-3, 10.1016/s0079-7421(08)60422-3.].
   Baddeley, 1997, HUMAN MEMORY THEORY.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Carrera G., 2011, P 5 EUR C MOB ROB OR, P77.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Ferland F, 2010, IEEE INT C INT ROBOT, P2515, DOI 10.1109/IROS.2010.5649041.
   Folkesson J, 2007, IEEE T ROBOT, V23, P731, DOI 10.1109/TRO.2007.900608.
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977.
   Garcia-Fidalgo E, 2015, ROBOT AUTON SYST, V64, P1, DOI 10.1016/j.robot.2014.11.009.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Grisetti Giorgio, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3472, DOI 10.1109/IROS.2007.4399030.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Lee GH, 2013, IEEE INT C INT ROBOT, P556, DOI 10.1109/IROS.2013.6696406.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   MCDONALD J, 2012, ROBOTICS AUTONOMOUS, V61, P1144.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Pirker K, 2011, IEEE INT C INT ROBOT, P3990, DOI 10.1109/IROS.2011.6048253.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Stachniss C, 2009, SPRINGER TRAC ADV RO, V55, P3.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Valencia R, 2013, IEEE T ROBOT, V29, P1050, DOI 10.1109/TRO.2013.2257577.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {38},
Times-Cited = {33},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {GG8VW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000432977900002},
DA = {2022-05-17},
}

@article{ WOS:000456142200010,
Author = {Tang, Li and Wang, Yue and Ding, Xiaqing and Yin, Huan and Xiong, Rong
   and Huang, Shoudong},
Title = {Topological local-metric framework for mobile robots navigation: a long
   term perspective},
Journal = {AUTONOMOUS ROBOTS},
Year = {2019},
Volume = {43},
Number = {1},
Pages = {197-211},
Month = {JAN},
Abstract = {Long term mapping and localization are the primary components for mobile
   robots in real world application deployment, of which the crucial
   challenge is the robustness and stability. In this paper, we introduce a
   topological local-metric framework (TLF), aiming at dealing with
   environmental changes, erroneous measurements and achieving constant
   complexity. TLF organizes the sensor data collected by the robot in a
   topological graph, of which the geometry is only encoded in the edge,
   i.e. the relative poses between adjacent nodes, relaxing the global
   consistency to local consistency. Therefore the TLF is more robust to
   unavoidable erroneous measurements from sensor information matching
   since the error is constrained in the local. Based on TLF, as there is
   no global coordinate, we further propose the localization and navigation
   algorithms by switching across multiple local metric coordinates.
   Besides, a lifelong memorizing mechanism is presented to memorize the
   environmental changes in the TLF with constant complexity, as no global
   optimization is required. In experiments, the framework and algorithms
   are evaluated on 21-session data collected by stereo cameras, which are
   sensitive to illumination, and compared with the state-of-art global
   consistent framework. The results demonstrate that TLF can achieve
   similar localization accuracy with that from global consistent
   framework, but brings higher robustness with lower cost. The
   localization performance can also be improved from sessions because of
   the memorizing mechanism. Finally, equipped with TLF, the robot
   navigates itself in a 1km session autonomously.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou, Zhejiang, Peoples R China.
   Wang, Y (Corresponding Author), Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou, Zhejiang, Peoples R China.
   Wang, Y (Corresponding Author), iPlusBot, Hangzhou, Zhejiang, Peoples R China.
   Tang, Li; Wang, Yue; Ding, Xiaqing; Yin, Huan; Xiong, Rong, Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou, Zhejiang, Peoples R China.
   Tang, Li; Wang, Yue; Ding, Xiaqing; Yin, Huan; Xiong, Rong, Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou, Zhejiang, Peoples R China.
   Wang, Yue, iPlusBot, Hangzhou, Zhejiang, Peoples R China.
   Huang, Shoudong, Univ Technol Sydney, CAS, Sydney, NSW, Australia.},
DOI = {10.1007/s10514-018-9724-7},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Mobile robot; Localization; Navigation; Lifelong learning},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; PLACE RECOGNITION; VISUAL TEACH; SLAM;
   VISION; REPEAT; TIME; EKF},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {litang.cv@gmail.com
   wangyue@iipc.zju.edu.cn
   dingxiaq@gmail.com
   zjuyinhuan@gmail.com
   rxiong@zju.edu.cn
   shoudong.huang@uts.edu.au},
Affiliations = {Zhejiang University; Zhejiang University; University of Technology
   Sydney},
ResearcherID-Numbers = {Yin, Huan/AAD-8616-2019
   Yin, Huan/ABC-9483-2020
   Huang, Shoudong/B-4255-2013
   },
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202
   Yin, Huan/0000-0002-0872-8202
   Huang, Shoudong/0000-0002-6124-4178},
Funding-Acknowledgement = {National Nature Science Foundation of China {[}U1609210, 61473258,
   61621002]; National Key Research and Development Program
   {[}2017YFB1300400]; University of Technology, Sydney; Zhejiang
   University},
Funding-Text = {This work was supported by the National Nature Science Foundation of
   China (Grant Nos. U1609210, 61473258 and 61621002), National Key
   Research and Development Program (Grant No. 2017YFB1300400), and in part
   by the Joint Centre for Robotics Research between Zhejiang University
   and the University of Technology, Sydney.},
Cited-References = {Angeli Adrien, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P4300, DOI 10.1109/ROBOT.2009.5152501.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Blaer P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1031, DOI 10.1109/ROBOT.2002.1013491.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   Choi J, 2016, IEEE T INTELL TRANSP, V17, P2440, DOI 10.1109/TITS.2016.2519536.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Corcoran P, 2011, IEEE T INTELL TRANSP, V12, P1177, DOI 10.1109/TITS.2011.2143706.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Fox D, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P343.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Huang GP, 2010, INT J ROBOT RES, V29, P502, DOI 10.1177/0278364909353640.
   Huang GPQ, 2009, SPRINGER TRAC ADV RO, V54, P373.
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Krusi P, 2015, J FIELD ROBOT, V32, P534, DOI 10.1002/rob.21524.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Lauer M, 2015, IEEE T INTELL TRANSP, V16, P970, DOI 10.1109/TITS.2014.2345498.
   Lee GH, 2013, IEEE INT C INT ROBOT, P556, DOI 10.1109/IROS.2013.6696406.
   Liao Y., 2016, IEEE T IMAGE PROCESS, P2839.
   Liu M, 2012, IEEE INT C INT ROBOT, P567, DOI 10.1109/IROS.2012.6385640.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   McDonald J, 2013, ROBOT AUTON SYST, V61, P1144, DOI 10.1016/j.robot.2012.08.008.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   McManus C, 2013, J FIELD ROBOT, V30, P254, DOI 10.1002/rob.21444.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Pascoe G., 2015, FARLAP FAST ROBUST L.
   Paton M, 2017, J FIELD ROBOT, V34, P98, DOI 10.1002/rob.21669.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Rybski PE, 2008, AUTON ROBOT, V24, P229, DOI 10.1007/s10514-007-9067-2.
   Simhon S, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1708, DOI 10.1109/IROS.1998.724844.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Tully S, 2012, INT J ROBOT RES, V31, P271, DOI 10.1177/0278364911433617.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Wang Y, 2015, ADV ROBOTICS, V29, P683, DOI 10.1080/01691864.2014.998707.
   Wang Y, 2016, CAAI T INTELL TECHNO, V1, P90, DOI 10.1016/j.trit.2016.03.009.
   Wang Y, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P32, DOI 10.1109/ECMR.2013.6698816.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.},
Number-of-Cited-References = {51},
Times-Cited = {17},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {20},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {HI0OW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000456142200010},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000750224700001,
Author = {Jang, Junwoo and Kim, Jinwhan},
Title = {Topographic SLAM Using a Single Terrain Altimeter in GNSS-Restricted
   Environment},
Journal = {IEEE ACCESS},
Year = {2022},
Volume = {10},
Pages = {10806-10815},
Abstract = {In a Global Navigation Satellite System (GNSS)-restricted area, a mobile
   robot navigation system exploits surrounding environment information.
   For an aerial or underwater vehicle, undulating terrain of a land or
   seabed surface is a valuable information resource that leads to the
   development of terrain-referenced navigation (TRN) algorithms. However,
   due to the vast amount of a vehicle's activity area, surveying all the
   regions to obtain a high-resolution terrain map is impractical and
   requires simultaneous localization and mapping (SLAM) as a highly
   desirable capability. This paper presents a topographic SLAM algorithm
   using only a single terrain altimeter, which is low-cost,
   computationally efficient, and sufficiently stable for long-term
   operation. The proposed rectangular panel map structure and update
   method enable robust and efficient SLAM. As terrain elevation changes
   are inherently nonlinear, an extended Kalman filter (EKF)-based SLAM
   filter is adopted. The feasibility and validity of the proposed
   algorithm are demonstrated through simulations using terrain elevation
   data from a real-world undersea environment.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Kim, J (Corresponding Author), Korea Adv Inst Sci \& Technol, Dept Mech Engn, Daejeon 34141, South Korea.
   Jang, Junwoo; Kim, Jinwhan, Korea Adv Inst Sci \& Technol, Dept Mech Engn, Daejeon 34141, South Korea.},
DOI = {10.1109/ACCESS.2022.3145978},
ISSN = {2169-3536},
Keywords = {Simultaneous localization and mapping; Navigation; Global navigation
   satellite system; Sensors; Surface topography; Kalman filters; Sea
   measurements; Terrain-referenced navigation; simultaneous localization
   and mapping; extended Kalman filter; topography; bathymetry; autonomous
   underwater vehicle},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; UNDERWATER VEHICLES; NAVIGATION},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {jinwhan@kaist.ac.kr},
Affiliations = {Korea Advanced Institute of Science \& Technology (KAIST)},
ORCID-Numbers = {Jang, Junwoo/0000-0003-0414-9622
   Kim, Jinwhan/0000-0001-6886-2449},
Funding-Acknowledgement = {National Research and Development Program through the National Research
   Foundation of Korea (NRF) - Ministry of Science and ICT (MSIT)
   {[}2020M3C1C1A02086303]},
Funding-Text = {This work was supported by the National Research and Development Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science and ICT (MSIT) under Grant 2020M3C1C1A02086303.},
Cited-References = {Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Baker W., 1977, TR7761 WRIGHTP AFB.
   Barkby S, 2012, INT J ROBOT RES, V31, P1409, DOI 10.1177/0278364912459666.
   Barkby S, 2011, J FIELD ROBOT, V28, P19, DOI 10.1002/rob.20382.
   Bichucher V, 2015, OCEANS-IEEE.
   Carr SC, 2010, INT CULT PSYCHOL, P1, DOI 10.1007/978-1-4419-6208-9\_1.
   Cowie M, 2008, IEEE POSITION LOCAT, P658.
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382.
   Hostetler L., 1978, P AIAA GUID CONTR C, DOI {[}10.2514/6.1978-1243, DOI 10.2514/6.1978-1243].
   Jang J, 2019, OCEANS-IEEE.
   Jang J, 2019, IEEE UNDERWATER TECH.
   Johnston A. E., 2008, Proceedings - International Fertiliser Society, P1.
   Kim J, 2004, IEEE T AERO ELEC SYS, V40, P1031, DOI 10.1109/TAES.2004.1337472.
   Langelaan J, 2005, AEROSP CONF PROC, P3011.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   Ma T, 2018, OCEAN ENG, V166, P336, DOI 10.1016/j.oceaneng.2018.08.029.
   Maki T, 2008, IEEE AUTO UNDER VEH, P83.
   Meduna DK, 2008, OCEANS-IEEE, P1643.
   Mok SH, 2013, INT J AERONAUT SPACE, V14, P85, DOI 10.5139/IJASS.2013.14.1.85.
   Morice C, 2009, OCEANS-IEEE, P441.
   Norgren P, 2018, IEEE ACCESS, V6, P26318, DOI 10.1109/ACCESS.2018.2830819.
   Nygren I, 2004, IEEE J OCEANIC ENG, V29, P906, DOI 10.1109/JOE.2004.833222.
   Palomer A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040560.
   Paul AS, 2005, IEEE IJCNN, P2784.
   Roman C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2422, DOI 10.1109/IROS.2005.1545340.
   Salavasidis G, 2021, J FIELD ROBOT, V38, P402, DOI 10.1002/rob.21994.
   Sistiaga M, 1998, OCEANS'98 - CONFERENCE PROCEEDINGS, VOLS 1-3, P747, DOI 10.1109/OCEANS.1998.724338.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Stuckey R.A., 2012, IFAC P, V45, P118, DOI {[}10.3182/20120410-3-PT-4028.00021, DOI 10.3182/20120410-3-PT-4028.00021].
   Thrun S., 2005, PROBABILISTIC ROBOTI.},
Number-of-Cited-References = {30},
Times-Cited = {0},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {YR8ET},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000750224700001},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000521238101001,
Author = {Luthardt, Stefan and Ziegler, Christoph and Willert, Volker and Adamy,
   Juergen},
Book-Group-Author = {IEEE},
Title = {How to Match Tracks of Visual Features for Automotive Long-Term SLAM},
DOI = {10.1109/ITSC.2019.8916895},
Booktitle = {2019 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC)},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2019},
Pages = {934-941},
Note = {IEEE Intelligent Transportation Systems Conference (IEEE-ITSC),
   Auckland, NEW ZEALAND, OCT 27-30, 2019},
Abstract = {Accurate localization is a vital prerequisite for future assistance or
   autonomous driving functions in intelligent vehicles. To achieve the
   required localization accuracy and availability, long-term visual SLAM
   algorithms like LLama-SLAM are a promising option. In such algorithms
   visual feature tracks, i. e. landmark observations over several
   consecutive image frames, have to be matched to feature tracks recorded
   days, weeks or months earlier. This leads to a more challenging matching
   problem than in short-term visual localization and known descriptor
   matching methods cannot be applied directly. In this paper, we devise
   several approaches to compare and match feature tracks and evaluate
   their performance on a long-term data set. With the proposed descriptor
   combination and masking ({''}CoMa{''}) method the best track matching
   performance is achieved with minor computational cost. This method
   creates a single combined descriptor for each feature track and
   furthermore increases the robustness by capturing the appearance
   variations of this track in a descriptor mask.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Luthardt, S (Corresponding Author), Tech Univ Darmstadt, Control Methods \& Robot Lab, Darmstadt, Germany.
   Luthardt, Stefan; Ziegler, Christoph; Willert, Volker; Adamy, Juergen, Tech Univ Darmstadt, Control Methods \& Robot Lab, Darmstadt, Germany.},
ISSN = {2153-0009},
ISBN = {978-1-5386-7024-8},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation Science \& Technology},
Affiliations = {Technical University of Darmstadt},
ORCID-Numbers = {Ziegler, Christoph/0000-0001-6311-4417},
Cited-References = {Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bouguet J.Y., 2000, PYRAMIDAL IMPLEMENTA.
   Bresson G, 2017, IEEE T INTELL VEHICL, V2, P194, DOI 10.1109/TIV.2017.2749181.
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54.
   Buczko M, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1161, DOI 10.1109/ITSC.2016.7795703.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810.
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3\_54.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Luthardt S, 2018, IEEE INT C INTELL TR, P2645, DOI 10.1109/ITSC.2018.8569323.
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188.
   Richardson A, 2015, IEEE INT C INT ROBOT, P74, DOI 10.1109/IROS.2015.7353357.
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961.
   Urban S, 2017, COMPUT VIS IMAGE UND, V162, P71, DOI 10.1016/j.cviu.2017.08.011.
   Zhang G, 2016, IEEE INT CONF ROBOT, P765, DOI 10.1109/ICRA.2016.7487205.
   Zhao Q, 2015, INT J COMPUT VISION, V113, P143, DOI 10.1007/s11263-014-0787-4.},
Number-of-Cited-References = {21},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BO6LS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000521238101001},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000557246500059,
Author = {Chen, Shilang and Wu, Junjun and Wang, Yanran and Zhou, Lin and Lu,
   Qinghua and Zhang, Yunzhi},
Book-Group-Author = {IEEE},
Title = {Robust Loop-Closure Detection with a Learned Illumination Invariant
   Representation for Robot vSLAM},
DOI = {10.1109/ICARM.2019.8833730},
Booktitle = {2019 IEEE 4TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS AND
   MECHATRONICS (ICARM 2019)},
Year = {2019},
Pages = {342-347},
Note = {4th IEEE International Conference on Advanced Robotics and Mechatronics
   (ICARM), Osaka, JAPAN, JUL 03-05, 2019},
Abstract = {Robust loop-closure detection plays a key role for the long-term robot
   visual Simultaneous Localization and Mapping(SLAM) in indoor or outdoor
   environment, due to illumination changes can greatly affect the accuracy
   of online image matching, and keypoints may fail to match between images
   taken at thesame location but different seasons. In this paper, we
   propose a robust loop-closure detection method for robot visual SLAM,
   which adopts invariant representation as image descriptors composed of
   learned features and adapts to changes in illumination and seasons. We
   evaluate our method on real datasets and demonstrate its excellent
   ability to handle illumination changes.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wu, JJ (Corresponding Author), Foshan Univ, Sch Mechatron Engn, Foshan 528000, Peoples R China.
   Chen, Shilang; Wu, Junjun; Zhou, Lin; Lu, Qinghua; Zhang, Yunzhi, Foshan Univ, Sch Mechatron Engn, Foshan 528000, Peoples R China.
   Wang, Yanran, Jinan Univ, Dept Comp Sci, Guangzhou 510632, Peoples R China.},
ISBN = {978-1-7281-0064-7},
Keywords = {Visual SLAM; Loop Closure Detection; Visual Place Recognition;
   Illumination Invariant Feature; Moblie Robot; Convolutional Neural
   Network},
Research-Areas = {Engineering; Robotics},
Web-of-Science-Categories  = {Engineering, Manufacturing; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {jjunwu@fosu.edu.cn},
Affiliations = {Foshan University; Jinan University},
ResearcherID-Numbers = {Chen, Shilang/ABE-4076-2021},
ORCID-Numbers = {Chen, Shilang/0000-0002-0891-5956},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61603103]; Natural
   Science Foundation of Guangdong, China {[}2016A030310293,
   2018A030310352]; Science and Technology Program of Guangzhou, China
   {[}201707010013]; Foshan University Graduate Freedom Exploration Fund
   Project},
Funding-Text = {This work is supported by National Natural Science Foundation of
   China(61603103); Natural Science Foundation of Guangdong,
   China(2016A030310293, 2018A030310352); Science and Technology Program of
   Guangzhou, China(201707010013); Foshan University Graduate Freedom
   Exploration Fund Project.},
Cited-References = {Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Cao FK, 2018, IEEE SENS J, V18, P4242, DOI 10.1109/JSEN.2018.2815956.
   Hou Y, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/8104386.
   Hou Y, 2018, AUTON ROBOT, V42, P1169, DOI 10.1007/s10514-017-9684-3.
   Hou Y, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881416686951.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Siam Sayem Mohammad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5702, DOI 10.1109/ICRA.2017.7989671.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4\_28.},
Number-of-Cited-References = {11},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BP5OC},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000557246500059},
DA = {2022-05-17},
}

@article{ WOS:000487951900017,
Author = {Hashemifar, Zakieh S. and Adhivarahan, Charuvahan and Balakrishnan,
   Anand and Dantu, Karthik},
Title = {Augmenting visual SLAM with Wi-Fi sensing for indoor applications},
Journal = {AUTONOMOUS ROBOTS},
Year = {2019},
Volume = {43},
Number = {8},
Pages = {2245-2260},
Month = {DEC},
Abstract = {Recent trends have accelerated the development of spatial applications
   on mobile devices and robots. These include navigation, augmented
   reality, human-robot interaction, and others. A key enabling technology
   for such applications is the understanding of the device's location and
   the map of the surrounding environment. This generic problem, referred
   to as Simultaneous Localization and Mapping (SLAM), is an extensively
   researched topic in robotics. However, visual SLAM algorithms face
   several challenges including perceptual aliasing and high computational
   cost. These challenges affect the accuracy, efficiency, and viability of
   visual SLAM algorithms, especially for long-term SLAM, and their use in
   resource-constrained mobile devices. A parallel trend is the ubiquity of
   Wi-Fi routers for quick Internet access in most urban environments. Most
   robots and mobile devices are equipped with a Wi-Fi radio as well. We
   propose a method to utilize Wi-Fi received signal strength to alleviate
   the challenges faced by visual SLAM algorithms. To demonstrate the
   utility of this idea, this work makes the following contributions: (i)
   We propose a generic way to integrate Wi-Fi sensing into visual SLAM
   algorithms, (ii) We integrate such sensing into three well-known SLAM
   algorithms, (iii) Using four distinct datasets, we demonstrate the
   performance of such augmentation in comparison to the original visual
   algorithms and (iv) We compare our work to Wi-Fi augmented FABMAP
   algorithm. Overall, we show that our approach can improve the accuracy
   of visual SLAM algorithms by 11\% on average and reduce computation time
   on average by 15\% to 25\%.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Hashemifar, ZS (Corresponding Author), SUNY Buffalo, Comp Sci \& Engn Dept, 338 Davis Hall, Buffalo, NY 14222 USA.
   Hashemifar, Zakieh S.; Adhivarahan, Charuvahan; Dantu, Karthik, SUNY Buffalo, Comp Sci \& Engn Dept, 338 Davis Hall, Buffalo, NY 14222 USA.
   Balakrishnan, Anand, Univ Southern Calif, Comp Sci Dept, 941 Bloom Walk, Los Angeles, CA 90089 USA.},
DOI = {10.1007/s10514-019-09874-z},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Visual SLAM; Wi-Fi sensing; Perceptual aliasing},
Keywords-Plus = {LOOP CLOSURE DETECTION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {zakiehsa@buffalo.edu
   charuvah@buffalo.edu
   anandbal@usc.edu
   kdantu@buffalo.edu},
Affiliations = {State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; University of Southern California},
ORCID-Numbers = {Balakrishnan, Anand/0000-0002-8781-4810
   hashemifar, zakieh sadat/0000-0003-2157-9448},
Funding-Acknowledgement = {National Science Foundation {[}RI 1514395, CNS 1846320]},
Funding-Text = {National Science Foundation (Grant Nos. RI 1514395, CNS 1846320).},
Cited-References = {Belter D, 2016, IEEE INT CONF ROBOT, P1279, DOI 10.1109/ICRA.2016.7487259.
   Berkvens R, 2014, IEEE INT C INT ROBOT, P1804, DOI 10.1109/IROS.2014.6942799.
   Biswas J, 2010, IEEE INT CONF ROBOT, P4379, DOI 10.1109/ROBOT.2010.5509842.
   Clark R, 2016, IEEE-RAS INT C HUMAN, P973, DOI 10.1109/HUMANOIDS.2016.7803390.
   Codd-Downey Robert, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5163, DOI 10.1109/ICRA.2017.7989604.
   Cummins M, 2008, IEEE INT CONF ROBOT, P1828, DOI 10.1109/ROBOT.2008.4543473.
   Dong J, 2015, SENSYS'15: PROCEEDINGS OF THE 13TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P85, DOI 10.1145/2809695.2809722.
   Engelhard N., 2011, P RGB D WORKSH 3D PE.
   Garcia S, 2016, IEEE INT CONF AUTON, P205, DOI 10.1109/ICARSC.2016.46.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Heshmat Mohamed, 2013, 2013 IEEE International Symposium on Robotic and Sensors Environments (ROSE 2013), P154, DOI 10.1109/ROSE.2013.6698435.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Huang J, 2011, IEEE INT CONF ROBOT, P1038.
   Ito S, 2014, IEEE INT CONF ROBOT, P417, DOI 10.1109/ICRA.2014.6906890.
   Jacobson A., 2015, AUSTR C ROB AUT ACRA.
   Jung J, 2015, ROBOT AUTON SYST, V70, P92, DOI 10.1016/j.robot.2015.03.003.
   KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873.
   Karanam CR, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P254, DOI 10.1109/IPSN.2018.00053.
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003.
   Kotaru M, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P269, DOI 10.1145/2785956.2787487.
   Kumar S. S., 2018, US Patent, Patent No. {[}9,885,774, 9885774].
   Kuo YS, 2014, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM `14), P447, DOI 10.1145/2639108.2639109.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Labbe M, 2011, IEEE INT C INT ROBOT, P1271, DOI 10.1109/IROS.2011.6048225.
   Lu CX, 2018, MOBICOM'18: PROCEEDINGS OF THE 24TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P607, DOI 10.1145/3241539.3241540.
   Luo CW, 2014, PROCEEDINGS OF THE 13TH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN' 14), P143, DOI 10.1109/IPSN.2014.6846748.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Nguyen DP, 2016, COMP SEMICOND INTEGR, P158.
   Nowakowski M, 2017, IEEE INT C INT ROBOT, P3339, DOI 10.1109/IROS.2017.8206171.
   Nowicki M., 2014, J AUTOMATION MOBILE, V8, P10, DOI DOI 10.14313/JAMRIS\_3-2014/22.
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537.
   Quigley M, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P2039, DOI 10.1109/IROS.2010.5651783.
   Soltanaghaei E, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P376, DOI 10.1145/3210240.3210347.
   Wang S, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1910, DOI 10.1109/IROS.2016.7759302.
   Xia YF, 2016, IEEE IJCNN, P2274, DOI 10.1109/IJCNN.2016.7727481.
   Yang S., 2016, IEEE INT C ROB AUT I.
   Yang SW, 2014, IEEE INT CONF ROBOT, P1991, DOI 10.1109/ICRA.2014.6907123.
   Yang Z, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P269.
   Zhang C, 2016, MOBICOM'16: PROCEEDINGS OF THE 22ND ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P230, DOI 10.1145/2973750.2973767.},
Number-of-Cited-References = {40},
Times-Cited = {6},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {76},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {JA6KS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000487951900017},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000404553300234,
Author = {Yuan, Xin and Martinez-Ortega, Jose-Fernan and Sanchez Fernandez, Jose
   Antonio and Eckert, Martina},
Title = {AEKF-SLAM: A New Algorithm for Robotic Underwater Navigation},
Pages = {1174},
Journal = {SENSORS},
Year = {2017},
Volume = {17},
Number = {5},
Month = {MAY},
Abstract = {In this work, we focus on key topics related to underwater Simultaneous
   Localization and Mapping (SLAM) applications. Moreover, a detailed
   review of major studies in the literature and our proposed solutions for
   addressing the problem are presented. The main goal of this paper is the
   enhancement of the accuracy and robustness of the SLAM-based navigation
   problem for underwater robotics with low computational costs. Therefore,
   we present a new method called AEKF-SLAM that employs an Augmented
   Extended Kalman Filter (AEKF)-based SLAM algorithm. The AEKF-based SLAM
   approach stores the robot poses and map landmarks in a single state
   vector, while estimating the state parameters via a recursive and
   iterative estimation-update process. Hereby, the prediction and update
   state (which exist as well in the conventional EKF) are complemented by
   a newly proposed augmentation stage. Applied to underwater robot
   navigation, the AEKF-SLAM has been compared with the classic and popular
   FastSLAM 2.0 algorithm. Concerning the dense loop mapping and line
   mapping experiments, it shows much better performances in map management
   with respect to landmark addition and removal, which avoid the long-term
   accumulation of errors and clutters in the created map. Additionally,
   the underwater robot achieves more precise and efficient
   self-localization and a mapping of the surrounding landmarks with much
   lower processing times. Altogether, the presented AEKF-SLAM method
   achieves reliably map revisiting, and consistent map upgrading on loop
   closure.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Yuan, X (Corresponding Author), Univ Politecn Madrid, Ctr Invest Tecnol Software \& Sistemas Sostenibili, Campus Sur, Madrid 28031, Spain.
   Yuan, Xin; Martinez-Ortega, Jose-Fernan; Sanchez Fernandez, Jose Antonio; Eckert, Martina, Univ Politecn Madrid, Ctr Invest Tecnol Software \& Sistemas Sostenibili, Campus Sur, Madrid 28031, Spain.},
DOI = {10.3390/s17051174},
Article-Number = {1174},
EISSN = {1424-8220},
Keywords = {underwater simultaneous localization and mapping (SLAM); augmented
   extended Kalman filter (AEKF); FastSLAM 2.0; loop closure; computational
   complexity},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {xin.yuan@upm.es
   jf.martinez@upm.es
   j.sanchez@upm.es
   martina.eckert@upm.es},
Affiliations = {Universidad Politecnica de Madrid; Centro de Investigacion en
   Tecnologias Software Sistemas Multimedia para la Sostenibilidad (CITSEM)},
ResearcherID-Numbers = {Eckert, Martina/H-9241-2015
   },
ORCID-Numbers = {Eckert, Martina/0000-0002-4531-9918
   Yuan, Xin/0000-0001-6616-9640
   MARTINEZ ORTEGA, JOSE FERNAN/0000-0002-7635-4564},
Funding-Acknowledgement = {SWARMs European project (Smart and Networking Underwater Robots in
   Cooperation Meshes) {[}662107-SWARMs-ECSEL-2014-1]; ECSEL JU; Spanish
   Ministry of Economy and Competitiveness {[}PCIN-2014-022-C02-02]; China
   Scholarship Council (CSC)},
Funding-Text = {The research leading to the presented results has been undertaken within
   the SWARMs European project (Smart and Networking Underwater Robots in
   Cooperation Meshes), under Grant Agreement n.
   662107-SWARMs-ECSEL-2014-1, partially supported by the ECSEL JU and the
   Spanish Ministry of Economy and Competitiveness (Ref.:
   PCIN-2014-022-C02-02), and also by the China Scholarship Council (CSC),
   which has partially supported the first author's research described in
   this paper.},
Cited-References = {Al Rashidi MJ, 2017, P COMBUST INST, V36, P469, DOI 10.1016/j.proci.2016.05.036.
   Allotta B, 2016, OCEAN ENG, V113, P121, DOI 10.1016/j.oceaneng.2015.12.058.
   Allotta B., P OC 2015 GEN GEN IT, P1.
   Aulinas J., P 2011 IEEE OC SANT, P1.
   Aulinas J, 2010, IEEE INT C INT ROBOT, P2552, DOI 10.1109/IROS.2010.5650438.
   AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Balasuriya BLEA, 2016, 2ND INTERNATIONAL MERCON 2016 MORATUWA ENGINEERING RESEARCH CONFERENCE, P403, DOI 10.1109/MERCon.2016.7480175.
   Barkby S., P MTS IEEE OC C EXH, V2, P1.
   Blackman S., 1999, DESIGN ANAL MODERN T.
   Burguera A, 2011, IEEE INT C INT ROBOT, P3577, DOI 10.1109/IROS.2011.6048431.
   Chandran V, 2002, IEEE J OCEANIC ENG, V27, P610, DOI 10.1109/JOE.2002.1040943.
   Chatila R., P IEEE INT C ROB AUT, P135.
   Csorba M., 1997, THESIS.
   Daniel M., P 35 JORN AUT VAL SP, P1.
   Dissanayake G., P 2000 IEEE INT C RO, P1009.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Durrant-Whyte H., P 10 INT S ROB RES I.
   DURRANTWHYTE HF, 1988, IEEE J ROBOT AUTOM, V4, P23, DOI 10.1109/56.768.
   Edward T., P 2007 IEEE C OC EUR, P1.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Fairfield N., P MTS IEEE OCEANS QU, P1.
   Fairfield N, 2007, J FIELD ROBOT, V24, P3, DOI 10.1002/rob.20165.
   Folkesson J, 2007, IEEE T ROBOT, V23, P731, DOI 10.1109/TRO.2007.900608.
   Gil A, 2010, ROBOT AUTON SYST, V58, P68, DOI 10.1016/j.robot.2009.07.026.
   Guivant J, 2000, INTELLIGENT AUTONOMOUS SYSTEMS 6, P581.
   Gustafsson F, 2010, IEEE AERO EL SYS MAG, V25, P53, DOI 10.1109/MAES.2010.5546308.
   Guth F, 2014, P IEEE RAS-EMBS INT, P981, DOI 10.1109/BIOROB.2014.6913908.
   Hahne D., 2004, THESIS.
   He B, 2012, SENSORS-BASEL, V12, P9386, DOI 10.3390/s120709386.
   Hidalgo F., P 6 INT C AUT ROB AP, P305.
   Kohlbrecher S., 2012, HECTOR SLAM ROBUST M.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Leonard J., 1992, SPRINGER INT SERIES.
   Mallios A., P 2009 EUR OC BREM G, P1.
   Menegatti E., P 2009 IEEE INT C RO, P8.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   MORAVEC HP, 1988, AI MAG, V9, P61.
   Moreno L, 2009, ROBOT AUTON SYST, V57, P441, DOI 10.1016/j.robot.2008.05.005.
   Nourbakhsh I. R., 2004, INTRO AUTONOMOUS MOB.
   Ribas D., P 2007 IEEE RSJ INT, P1455.
   Ribas D., 2005, THESIS.
   Ribas D, 2008, J FIELD ROBOT, V25, P898, DOI 10.1002/rob.20249.
   Roman C, 2007, J FIELD ROBOT, V24, P23, DOI 10.1002/rob.20164.
   Royer E., 2006, THESIS.
   Ruiz IT, 2004, IEEE J OCEANIC ENG, V29, P442, DOI 10.1109/JOE.2004.829790.
   Scaramuzza Davide, 2009, International Journal of Robotics Research, V28, P149, DOI 10.1177/0278364908099858.
   Sebastian T., 2005, PROBABILISTIC ROBOTI, P1.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Stachniss C., 2013, AUTONOMY INTELLIGENT.
   Thrun S, 2008, SPRINGER TRAC ADV RO, V38, P13.
   Wang H. J., P 2011 IEEE INT C ME, P2254.
   Wijk O, 1998, IEEE INT CONF ROBOT, P3419, DOI 10.1109/ROBOT.1998.680966.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Williams S, 2004, IEEE INT CONF ROBOT, P1771, DOI 10.1109/ROBOT.2004.1308080.
   Williams S. B., 2001, THESIS.
   Yuan X, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071148.
   ZELINSKY W, 1992, CULTURAL GEOGRAPHY U.
   Zeyneb K. Y., P 2012 IEEE 16 INT C, P61.
   Zeyneb K. Y., P 2012 IEEE 16 INT C, P37.},
Number-of-Cited-References = {61},
Times-Cited = {19},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {38},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {EZ2QB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000404553300234},
OA = {Green Submitted, gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000258095001096,
Author = {Leung, Cindy and Huang, Shoudong and Dissanayake, Gamini},
Book-Group-Author = {IEEE},
Title = {Active SLAM in structured environments},
Booktitle = {2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-9},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2008},
Pages = {1898-1903},
Note = {IEEE International Conference on Robotics and Automation, Pasadena, CA,
   MAY 19-23, 2008},
Abstract = {This paper considers the trajectory planning problem for line-feature
   based SLAM in structured indoor environments. The robot poses and line
   features are estimated using Smooth and Mapping (SAM) which is found to
   provide more consistent estimates than the Extended Kalman Filter (EKF).
   The objective of trajectory planning is to minimise the uncertainty of
   the estimates and to maximise coverage. Trajectory planning is performed
   using Model Predictive Control (MPC) with an attractor incorporating
   long term goals. This planning is demonstrated both in simulation an in
   a real-time experiment with a Pioneer2DX robot.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Leung, C (Corresponding Author), Univ Technol Sydney, Fac Engn, Sydney, NSW 2007, Australia.
   Leung, Cindy; Huang, Shoudong; Dissanayake, Gamini, Univ Technol Sydney, Fac Engn, Sydney, NSW 2007, Australia.},
DOI = {10.1109/ROBOT.2008.4543484},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4244-1646-2},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {c.leung@cas.edu.au
   s.huang@cas.edu.au
   g.dissanayake@cas.edu.au},
Affiliations = {University of Technology Sydney},
ResearcherID-Numbers = {Huang, Shoudong/B-4255-2013
   Dissanayake, Gamini/F-7361-2017
   },
ORCID-Numbers = {Dissanayake, Gamini/0000-0002-7992-0680
   Huang, Shoudong/0000-0002-6124-4178},
Cited-References = {ALEMPIJEVIC A, AUSTR C ROB AUT CANB.
   Castellanos JA, 1999, IEEE T ROBOTIC AUTOM, V15, P948, DOI 10.1109/70.795798.
   Dellaert F., INT J ROBOTICS RES, V25, P1181.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   GARULLI A, 44 IEEE C DEC CONTR.
   Gonzalez-Banos HH, 2002, INT J ROBOT RES, V21, P829, DOI 10.1177/0278364902021010834.
   Jarvis R. A., 1985, MECH ENG T I ENG, VME10.
   Leung C, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5026, DOI 10.1109/IROS.2006.282530.
   Leung C, 2006, ROBOT AUTON SYST, V54, P898, DOI 10.1016/j.robot.2006.05.008.
   PFISTER ST, 2006, P 2006 IEEE INT C RO.
   Rodriguez-Losada D, 2006, IEEE INT CONF ROBOT, P418, DOI 10.1109/ROBOT.2006.1641747.
   SIM R, 2005, P INT C ROB AUT ICRA.
   YUEN DCK, AUSTR C ROB AUT BRIS.},
Number-of-Cited-References = {13},
Times-Cited = {31},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BIB31},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000258095001096},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000327208400087,
Author = {Saleiro, Mario and Rodrigues, J. M. F. and du Buf, J. M. H.},
Editor = {Filipe, J and Fred, A},
Title = {MINIMALISTIC VISION-BASED COGNITIVE SLAM},
Booktitle = {ICAART: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON AGENTS AND
   ARTIFICIAL INTELLIGENCE, VOL 1},
Year = {2012},
Pages = {614-623},
Note = {4th International Conference on Agents and Artificial Intelligence,
   PORTUGAL, FEB 06-08, 2012},
Abstract = {The interest cognitive robotics is still increasing, a major goal being
   to create a system which can adapt to dynamic environments and which can
   learn from its own experiences. We present a new cognitive SLAM
   architecture, but one which is minimalistic in terms of sensors and
   memory. It employs only camera with pan and tilt control and three
   memories, without additional sensors nor any odometry. Short-term memory
   is an egocentric map which holds information at close range at the
   actual robot position, Long-term memory is used for mapping the
   environment and registration of encountered objects. Object memory holds
   features of learned objects which are used as navigation landmarks and
   task targets. Saliency maps are used to sequentially focus important
   areas for object and obstacle detection, but also for selecting
   directions of movements. Reinforcement learning is used to consolidate
   or enfeeble environmental information long-term memory. The system is
   able to achieve complex tasks by executing sequences of visuomotor
   action, decisions being taken by goal-detection and goal-completion
   tasks. Experimental results show that the system is capable of executing
   tasks like localizing specific objects while building a map, after which
   manages to return to the start position even when new obstacles have
   appeared.},
Publisher = {SCITEPRESS},
Address = {AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Saleiro, M (Corresponding Author), Univ Algarve, ISE, Vis Lab, LARSyS, Campus Gambelas, P-8005139 Faro, Portugal.
   Saleiro, Mario, Univ Algarve, ISE, Vis Lab, LARSyS, P-8005139 Faro, Portugal.},
DOI = {10.5220/0003881306140623},
ISBN = {978-989-8425-95-9},
Keywords = {Robotics; SLAM; Navigation; Memory},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering},
Affiliations = {Universidade do Algarve},
ResearcherID-Numbers = {Rodrigues, João/D-1617-2010
   RODRIGUES, JOÃO/AAC-6993-2019
   du Buf, Hans/M-5125-2013},
ORCID-Numbers = {Rodrigues, João/0000-0002-3562-6025
   du Buf, Hans/0000-0002-4345-1237},
Cited-References = {Alami R., 2006, ASSOCIATION FOR THE.
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105.
   Butko N., 2008, P INT C ROB AUT ICRA, P2398.
   du Buf J., 2011, ACCEPTED FOR 17TH PO.
   Evans C., 2009, TECH REP CSTR 09 001.
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558.
   Jose J, 2010, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON SOFTWARE DEVELOPMENT FOR ENHANCING ACCESSIBILITY AND FIGHTING INFO-EXCLUSION (DSAI 2010), P175.
   Kawamura K., 2002, International Journal of Robotics \& Automation, V17, P135.
   Kleinmann L, 2011, C IND ELECT APPL, P936, DOI 10.1109/ICIEA.2011.5975721.
   Meger D, 2008, ROBOT AUTON SYST, V56, P503, DOI 10.1016/j.robot.2008.03.008.
   Meinert P., 2008, THESIS, P173.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Papauschek Christian, 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P519, DOI 10.1109/ROBIO.2010.5723380.
   Patnaik S., 2007, ROBOT COGNITION AND.
   Ratanaswasd P, 2005, 2005 IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION (RO-MAN), P440.
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667.
   Rodrigues J, 2006, BIOSYSTEMS, V86, P75, DOI 10.1016/j.biosystems.2006.02.019.
   Rodrigues J, 2009, BIOSYSTEMS, V95, P206, DOI 10.1016/j.biosystems.2008.10.006.
   Saleiro M, 2009, DSAI 2009: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON SOFTWARE DEVELOPMENT FOR ENHANCING ACCESSIBILITY AND FIGHTING INFO-EXCLUSION, P165.},
Number-of-Cited-References = {20},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BIB31},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000327208400087},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000270815500046,
Author = {Hochdorfer, Siegfried and Schlegel, Christian},
Book-Group-Author = {IEEE},
Title = {Towards a robust Visual SLAM Approach: Addressing the Challenge of
   life-long Operation},
Booktitle = {ICAR: 2009 14TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, VOLS 1
   AND 2},
Year = {2009},
Pages = {285-290},
Note = {14th International Conference on Advanced Robotics, Munich, GERMANY, JUN
   22-26, 2009},
Abstract = {Localization and mapping are fundamental problems in service robotics.
   Knowledge about the own pose and representations of the environment are
   needed for a series of high level applications. Service robots should be
   designed for life-long and robust operation in dynamic environments.
   The contribution of this paper is twofold. First, an approach to address
   the ever growing number of landmarks in life-long operation is
   presented. Typically, SLAM approaches just accumulate features over time
   and do not discard them anymore. Therefore, the required resources in
   terms of memory and processing power are growing over time. In our
   approach, the absolute number of landmarks can be restricted by an upper
   bound since we introduce a method to specifically select and replace
   landmarks once the upper bound has been reached.
   The second contribution is related to improving the robustness of the
   landmark assignment problem in case of image based features as needed
   with natural landmarks.
   The approach has been successfully evaluated in a real world experiment
   on a Pioneer-3DX platform within a complex unmodified indoor
   environment.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Hochdorfer, S (Corresponding Author), Univ Appl Sci Ulm, Dept Comp Sci, Collaborat Ctr Appl Res Serv Robot, D-89075 Ulm, Germany.
   Hochdorfer, Siegfried; Schlegel, Christian, Univ Appl Sci Ulm, Dept Comp Sci, Collaborat Ctr Appl Res Serv Robot, D-89075 Ulm, Germany.},
ISBN = {978-1-4244-4855-5},
Research-Areas = {Engineering; Robotics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Robotics},
Author-Email = {hochdorfer@hs-ulm.de
   schlegel@hs-ulm.de},
Affiliations = {Ulm University},
Cited-References = {Bailey T, 2003, IEEE INT CONF ROBOT, P1966, DOI 10.1109/ROBOT.2003.1241882.
   Bay H, 2006, 9 EUR C COMP VIS GRA.
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   Kiang KM, 2006, SPRINGER TRAC ADV RO, V25, P67.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   MAKSAROV D, 1995, IEE P-CONTR THEOR AP, V142, P385, DOI 10.1049/ip-cta:19951872.
   SCHLEGEL C, 2008, SERVICE ROBOTICS, P253.
   STRASDAT H, 2007, INFORM AKTUELL, P15.},
Number-of-Cited-References = {10},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BLQ69},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000270815500046},
DA = {2022-05-17},
}

@inproceedings{ WOS:000458872700017,
Author = {Lazaro, Maria T. and Capobianco, Roberto and Grisetti, Giorgio},
Editor = {Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L},
Book-Author = {Kosecka, J},
Title = {Efficient Long-term Mapping in Dynamic Environments},
DOI = {10.1109/IROS.2018.8594310},
Booktitle = {2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2018},
Pages = {153-160},
Note = {25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Madrid, SPAIN, OCT 01-05, 2018},
Abstract = {As autonomous robots are increasingly being introduced in real-world
   environments operating for long periods of time, the difficulties of
   long-term mapping are attracting the attention of the robotics research
   community. This paper proposes a full SLAM system capable of handling
   the dynamics of the environment across a single or multiple mapping
   sessions.
   Using the pose graph SLAM paradigm, the system works on local maps in
   the form of 2D point cloud data which are updated over time to store the
   most up-to-date state of the environment. The core of our system is an
   efficient ICP-based alignment and merging procedure working on the
   clouds that copes with non-static entities of the environment.
   Furthermore, the system retains the graph complexity by removing
   out-dated nodes upon robust inter-and intra-session loop closure
   detections while graph coherency is preserved by using condensed
   measurements. Experiments conducted with real data from longterm SLAM
   datasets demonstrate the efficiency, accuracy and effectiveness of our
   system in the management of the mapping problem during long-term robot
   operation.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Lazaro, MT (Corresponding Author), Sapienza Univ Rome, Dipartimento Ingn Informat Automat \& Gest Antonio, Rome, Italy.
   Lazaro, Maria T.; Capobianco, Roberto; Grisetti, Giorgio, Sapienza Univ Rome, Dipartimento Ingn Informat Automat \& Gest Antonio, Rome, Italy.},
ISSN = {2153-0858},
ISBN = {978-1-5386-8094-0},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {mtlazaro@diag.uniroma1.it
   capobianco@diag.uniroma1.it
   grisetti@diag.uniroma1.it},
Affiliations = {Sapienza University Rome},
ResearcherID-Numbers = {GRAÑON, MARIA TERESA LAZARO/AAI-6857-2021
   Capobianco, Roberto/AAH-7703-2021},
ORCID-Numbers = {GRAÑON, MARIA TERESA LAZARO/0000-0002-7742-2442
   Capobianco, Roberto/0000-0002-2219-215X},
Cited-References = {Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Biswas  R., 2002, IEEE RSJ INT C INT R.
   Burgard W, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2089, DOI 10.1109/IROS.2009.5354691.
   Fallon M, 2013, INT J ROBOT RES, V32, P1695, DOI 10.1177/0278364913509035.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2012, IEEE INT C INT ROBOT, P581, DOI 10.1109/IROS.2012.6385779.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hanheide  M., 2017, ACM IEEE INT C HUM R.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Iocchi L, 2015, LECT NOTES ARTIF INT, V9336, P465, DOI 10.1007/978-3-319-24309-2\_35.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kohlbrecher S, 2011, P IEEE INT S SAF SEC.
   Krajnik  T., 2016, IEEE RSJ INT C INT R.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Latif  Y., 2013, EUR C MOB ROB BARC S.
   Lazaro M. T., 2013, IEEE RSJ INT C INT R.
   McDonald  J., 2011, ECMR.
   Serafin J, 2017, ROBOT AUTON SYST, V92, P91, DOI 10.1016/j.robot.2017.03.008.
   Triebel R, 2016, SPRINGER TRAC ADV RO, V113, P607, DOI 10.1007/978-3-319-27702-8\_40.
   Vallve J, 2018, IEEE ROBOT AUTOM LET, V3, P1322, DOI 10.1109/LRA.2018.2798283.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Wolf D, 2004, IEEE INT CONF ROBOT, P1301, DOI 10.1109/ROBOT.2004.1308004.},
Number-of-Cited-References = {24},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BM0LT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000458872700017},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921703067,
Author = {Maffei, Renan and Jorge, Vitor A. M. and Rey, Vitor F. and Kolberg,
   Mariana and Prestes, Edson},
Book-Group-Author = {IEEE},
Title = {Long-term place recognition using multi-level words of spatial densities},
DOI = {10.1109/IROS.2016.7759504},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {3269-3274},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {Proper place recognition on an environment that can change over time is
   fundamental for long-term SLAM. In such scenarios the observations
   obtained in the same region can drastically differ due to changes caused
   by semi-static objects, such as doors, furniture, etc. In this work, we
   extend a strategy that represents environment regions using words, based
   on spatial density information extracted from laser readings. This time,
   in order to deal with changes in the environment, our method not only
   builds words representing the real observations made by the robot, but
   also alternative multi-level words to account for possible changes in a
   place's observations generated by non-static objects. Place recognition
   is made by searching matches of sequences of N consecutive words (both
   real or alternatives). Experiments performed in real and simulated
   scenarios are shown, and demonstrate the advantages associated to the
   use of multi-level words.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Maffei, R (Corresponding Author), Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.
   Maffei, Renan; Jorge, Vitor A. M.; Rey, Vitor F.; Kolberg, Mariana; Prestes, Edson, Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.},
ISBN = {978-1-5090-3762-9},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; DYNAMIC ENVIRONMENTS; SLAM; MAP},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {rqmaffei@inf.ufrgs.br
   vamjorge@inf.ufrgs.br
   vfrey@inf.ufrgs.br
   mariana.kolberg@inf.ufrgs.br
   prestes@inf.ufrgs.br},
Affiliations = {Universidade Federal do Rio Grande do Sul},
ResearcherID-Numbers = {Jorge, Vitor Augusto Machado/Z-1757-2019
   Kolberg, Mariana/AAG-2662-2020
   },
ORCID-Numbers = {Kolberg, Mariana/0000-0002-8117-4402
   Maffei, Renan/0000-0003-0637-9747},
Cited-References = {Biber P., 2005, P ROB SCI SYST JUN.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Maffei R, 2015, IEEE INT C INT ROBOT, P3850, DOI 10.1109/IROS.2015.7353918.
   Maffei R, 2015, IEEE INT CONF ROBOT, P6352, DOI 10.1109/ICRA.2015.7140091.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Thrun S., 2005, INTELLIGENT ROBOTICS.
   Tipaldi G., 2011, IEEE RSJ IROS WORKSH.
   Tipaldi G. D., 2012, P ROB SCI SYST 2012.
   Walcott A., 2012, P 2012 IEEE RSJ INT.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.},
Number-of-Cited-References = {16},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921703067},
DA = {2022-05-17},
}

@inproceedings{ WOS:000285372900062,
Author = {Hochdorfer, Siegfried and Schlegel, Christian},
Book-Group-Author = {IEEE},
Title = {Landmark rating and selection according to localization coverage:
   Addressing the challenge of lifelong operation of SLAM in service robots},
Booktitle = {2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS},
Year = {2009},
Pages = {382-387},
Note = {IEEE RSJ International Conference on Intelligent Robots and Systems, St
   Louis, MO, OCT 10-15, 2009},
Abstract = {Acting in everyday-life environments is still a great challenge in
   service robotics. Although algorithms and solutions already exist for
   many relevant subproblems, in particular the aspect of robustness and
   suitability for everyday use has been neglected so far very often.
   Robustness and suitability for everyday use are features affecting not
   only the overall system design but have impact on each single algorithm
   of each component.
   Although an overwhelming amount of work is available to address the SLAM
   problem, the challenge of applying a SLAM algorithm over the whole
   lifecycle of a service robot, perhaps even in different environments,
   has not been brought into focus very often. An obvious problem to be
   solved is the continuously growing number of landmarks. A lifelong
   running SLAM approach requires means to select landmarks such that they
   best cover the working environment given bounded SLAM resources like the
   maximum number of manageable landmarks.
   This paper proposes a novel solution for selecting appropriate landmarks
   to limit the number of landmarks. The idea is to quantify the
   contribution of a landmark to the ability of the robot to localize
   itself in its working environment. Thus, the core contribution is to
   base the landmark selection process upon the landmarks' coverage of the
   working environment.
   Real-world experiments on a P3DX-platform with a bearing-only SLAM
   approach and an omnicam confirm that the addressed question and the
   proposed first approach might be another step towards the overall goal
   of suitability for everyday use.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Hochdorfer, S (Corresponding Author), Univ Appl Sci Ulm, Dept Comp Sci, Prittwitzstr 10, D-89075 Ulm, Germany.
   Hochdorfer, Siegfried; Schlegel, Christian, Univ Appl Sci Ulm, Dept Comp Sci, D-89075 Ulm, Germany.},
DOI = {10.1109/IROS.2009.5354433},
ISBN = {978-1-4244-3803-7},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {hochdorfer@hs-ulm.de
   schlegel@hs-ulm.de},
Affiliations = {Ulm University},
Cited-References = {Bailey T, 2003, IEEE INT CONF ROBOT, P1966, DOI 10.1109/ROBOT.2003.1241882.
   Bay H, 2006, 9 EUR C COMP VIS GRA.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   MAKSAROV D, 1995, IEE P-CONTR THEOR AP, V142, P385, DOI 10.1049/ip-cta:19951872.
   SCHLEGEL C, 2008, LOCALIZATION MAPPING, P253.
   Seber GAF, 1984, MULTIVARIATE OBSERVA.
   Spath H, 1985, CLUSTER DISSECTION A.
   Thrun S., 2005, PROBABILISTIC ROBOTI.},
Number-of-Cited-References = {8},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BSQ11},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000285372900062},
DA = {2022-05-17},
}

@inproceedings{ WOS:000427752100040,
Author = {Shen, Qihui and Sun, Hanxu and Ye, Ping},
Book-Group-Author = {IEEE},
Title = {Research of Large-Scale Offline Map Management in Visual SLAM},
DOI = {10.1109/ICSAI.2017.8248292},
Booktitle = {2017 4TH INTERNATIONAL CONFERENCE ON SYSTEMS AND INFORMATICS (ICSAI)},
Series = {International Conference on Systems and Informatics},
Year = {2017},
Pages = {215-219},
Note = {4th International Conference on Systems and Informatics (ICSAI),
   Hangzhou, PEOPLES R CHINA, NOV 11-13, 2017},
Abstract = {This paper presents a novel method of visual simultaneous localization
   and mapping (SLAM), which is a method of real-time localization and
   mapping. It is important for a mobile robot to build a map while
   autonomously navigation. Due to the complexity of the robot work scene,
   the SLAM method proposed in this paper optimizes map management. It will
   cost a lot of time and space when a robot long-term works in a same
   large scene. Therefore, we propose a method in this paper to save a
   detail map as an offline map in advance. At the same time in order to
   facilitate the follow-up optimization, the offline map can be divided
   into several sub-graphs according to the similarity of the scene. Since
   the segmented offline map has been saved to local system, it can be
   loaded at any time to localization and obtain the pose of current frame.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Shen, QH (Corresponding Author), Beijing Univ Post \& Telecommun, Sch Automat, Beijing, Peoples R China.
   Shen, Qihui; Sun, Hanxu; Ye, Ping, Beijing Univ Post \& Telecommun, Sch Automat, Beijing, Peoples R China.},
ISSN = {2474-0217},
ISBN = {978-1-5386-1107-4},
Keywords = {SLAM; offline map; segment graph; normalized-cut},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic},
Affiliations = {Beijing University of Posts \& Telecommunications},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61305126]},
Funding-Text = {This work is supported in part by the National Natural Science
   Foundation of China under grant No. 61305126.},
Cited-References = {Blanco J. L, 2009, SUBJECTIVE LOCAL MAP.
   Chen Yanzhi, 2009, COMPUTER TECHNOLOGY, V19, P228.
   Durrantwhyte Hugh, 2002, MULT FUS INT INT SYS, P92.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Mei C, 2010, IEEE INT C INT ROBOT, P3738, DOI 10.1109/IROS.2010.5652266.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Shi Jianbo, 2000, NORMALIZED CUTS IMAG.
   XI Qiu-bo, 2010, THESIS.},
Number-of-Cited-References = {9},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BJ7WO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000427752100040},
DA = {2022-05-17},
}

@article{ WOS:000673308000001,
Author = {Lu, Shouyi and Zhi, Yongshuai and Zhang, Sumin and He, Rui and Bao,
   Zhipeng},
Title = {Semi-Direct Monocular SLAM With Three Levels of Parallel Optimizations},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {86801-86810},
Abstract = {In practical applications, how to use the complementary strengths of the
   direct and the feature-based methods for effective fusion may be the
   main challenge of simultaneous localization and mapping (SLAM). To solve
   this challenge, we propose the DO-SLAM, a novel fast and accurate
   semi-direct visual SLAM framework, which can maintain the direct
   method's fast performance and the high precision and loop closure
   capability of the feature-based method. The direct method is used as the
   first half of the DO-SLAM to track the camera pose rapidly and robustly.
   The feature-based method is used as the second half of the DO-SLAM to
   refine the keyframe poses, perform loop closures, and build a globally
   consistent, long-term, sparse feature map that can be reused. The
   proposed pipeline fuses direct odometry and feature-based SLAM to
   perform three levels of parallel optimizations: (1) In the direct method
   module, the keyframe poses are estimated by minimizing the photometric
   error, (2) In the feature-based module, using the poses calculated by
   the inter-frame matching to correct and fuse the poses calculated by the
   direct method module as the initial poses, and the initial poses are
   optimized by the motion-only bundle adjustment, and (3) A pose graph
   optimization is used to achieve global map consistency in the presence
   of loop closures. Experimental evaluation on two benchmark datasets
   demonstrates that the proposed approach achieves higher accuracy and
   robustness on motion estimation compared to the other state-of-the-art
   methods.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhang, SM (Corresponding Author), Jilin Univ, State Key Lab Automot Simulat \& Control, Changchun 130022, Peoples R China.
   Lu, Shouyi; Zhi, Yongshuai; Zhang, Sumin; He, Rui; Bao, Zhipeng, Jilin Univ, State Key Lab Automot Simulat \& Control, Changchun 130022, Peoples R China.},
DOI = {10.1109/ACCESS.2021.3071921},
ISSN = {2169-3536},
Keywords = {Feature extraction; Cameras; Simultaneous localization and mapping;
   Optimization; Visualization; Unmanned aerial vehicles; Sensor phenomena
   and characterization; Simultaneous localization and mapping (SLAM);
   semi-direct SLAM; three levels of parallel optimizations},
Keywords-Plus = {VISUAL ODOMETRY},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {zhangsumin@jlu.edu.cn},
Affiliations = {Jilin University},
ORCID-Numbers = {zhang, sumin/0000-0002-4860-0019
   Zhi, Yongshuai/0000-0003-3512-7805},
Funding-Acknowledgement = {Research on Construction and Simulation Technology of Hardware in Loop
   Testing Scenario for Self-driving Electric Vehicle in China
   {[}2018YFB0105103]; National Science Foundation of China {[}U1564211];
   Graduate Innovation Fund of Jilin University},
Funding-Text = {This work was supported in part by the Research on Construction and
   Simulation Technology of Hardware in Loop Testing Scenario for
   Self-driving Electric Vehicle in China under Grant 2018YFB0105103, in
   part by the National Science Foundation of China under Grant U1564211,
   and in part by the Graduate Innovation Fund of Jilin University.},
Cited-References = {Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd.
   Bloesch M, 2018, PROC CVPR IEEE, P2560, DOI 10.1109/CVPR.2018.00271.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Campos C., ARXIV200711898.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Engel J., 2016, PHOTOMETRICALLY CALI.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Fu Q, 2019, IEEE SENS J, V19, P9908, DOI 10.1109/JSEN.2019.2927405.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376.
   Gomez-Ojeda R, 2019, IEEE T ROBOT, V35, P734, DOI 10.1109/TRO.2019.2899783.
   Gomez-Ojeda R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4211, DOI 10.1109/IROS.2016.7759620.
   Grupp Michael, EVO.
   Hongjian Li, 2019, 2019 IEEE International Conferences on Ubiquitous Computing \& Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS), P422, DOI 10.1109/IUCC/DSCI/SmartCNS.2019.00096.
   Kim P, 2019, AUTON ROBOT, V43, P1605, DOI 10.1007/s10514-018-9816-4.
   Klein George, 2007, P1.
   Krombach N, 2018, ROBOT AUTON SYST, V109, P38, DOI 10.1016/j.robot.2018.08.002.
   Lee SH, 2019, IEEE ROBOT AUTOM LET, V4, P399, DOI 10.1109/LRA.2018.2889156.
   Lee TJ, 2019, IEEE T IND ELECTRON, V66, P318, DOI 10.1109/TIE.2018.2826471.
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6.
   Li SP, 2019, ROBOT AUTON SYST, V112, P201, DOI 10.1016/j.robot.2018.11.009.
   Liu QP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051511.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Strasdat H., 2010, ROBOTICS SCI SYSTEMS.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Sumikura S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2292, DOI 10.1145/3343031.3350539.
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695.
   Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421.},
Number-of-Cited-References = {35},
Times-Cited = {0},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {17},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {TJ2GY},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000673308000001},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000368032600004,
Author = {Mazuran, Mladen and Burgard, Wolfram and Tipaldi, Gian Diego},
Title = {Nonlinear factor recovery for long-term SLAM},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2016},
Volume = {35},
Number = {1-3, SI},
Pages = {50-72},
Month = {JAN-MAR},
Note = {10th Conference on Robotics - Science and Systems (RSS), Univ Calif,
   Berkeley, CA, JUN, 2014},
Abstract = {For long-term operations, graph-based simultaneous localization and
   mapping (SLAM) approaches require nodes to be marginalized in order to
   control the computational cost. In this paper, we present a method to
   recover a set of nonlinear factors that best represents the marginal
   distribution in terms of Kullback-Leibler divergence. The proposed
   method, which we call nonlinear factor recovery (NFR), estimates both
   the mean and the information matrix of the set of nonlinear factors,
   where the recovery of the latter is equivalent to solving a convex
   optimization problem. NFR is able to provide either the dense
   distribution or a sparse approximation of it. In contrast to previous
   algorithms, our method does not necessarily require a global
   linearization point and can be used with any nonlinear measurement
   function. Moreover, we are not restricted to only using tree-based
   sparse approximations and binary factors, but we can include any
   topology and correlations between measurements. Experiments performed on
   several publicly available datasets demonstrate that our method
   outperforms the state of the art with respect to the Kullback-Leibler
   divergence and the sparsity of the solution.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Mazuran, M (Corresponding Author), Univ Freiburg, Dept Comp Sci, Georges Koehler Allee 79, D-79110 Freiburg, Germany.
   Mazuran, Mladen; Burgard, Wolfram; Tipaldi, Gian Diego, Univ Freiburg, Dept Comp Sci, D-79110 Freiburg, Germany.},
DOI = {10.1177/0278364915581629},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Mobile robotics; SLAM; localization; mapping; graphical models;
   nonlinear optimization},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mazuran@informatik.uni-freiburg.de},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
ResearcherID-Numbers = {Burgard, Wolfram/N-2381-2019},
ORCID-Numbers = {Burgard, Wolfram/0000-0002-5680-6500},
Cited-References = {Banerjee O., 2006, P INT C MACH LEARN.
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016.
   Boyd S., 2009, CONVEX OPTIMIZATION.
   Carlevaris-Bianco N., 2013, P IEEE INT C ROB AUT.
   Carlevaris-Bianco N, 2013, P IEEE RSJ INT C INT.
   Carlevaris-Bianco N, 2014, IEEE T ROBO IN PRESS.
   Carlevaris-Bianco N, 2014, P IEEE INT C ROB AUT.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Duchi J. C., 2008, P C UNC ART INT.
   Eade E, 2010, P IEEE RSJ INT C INT.
   Eustice R., 2005, P IEEE RSJ INT C INT.
   FOLKESSON J, 2004, P IEEE INT C ROB AUT, V1.
   FRESE U, 2007, P IEEE INT C ROB AUT.
   Frese U, 2006, AUTON ROBOT, V21, P103, DOI 10.1007/s10514-006-9043-2.
   Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045.
   Golub G. H., 1996, MATRIX COMPUTATIONS.
   Grisetti G., 2007, P ROB SCI SYST.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   HIGHAM NJ, 1988, LINEAR ALGEBRA APPL, V103, P103, DOI 10.1016/0024-3795(88)90223-6.
   Huang G, 2013, P EUR C MOB ROB.
   Huang SD, 2009, AUTON ROBOT, V27, P409, DOI 10.1007/s10514-009-9153-8.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Johannsson H, 2013, P IEEE INT C ROB AUT.
   Kaess M., 2007, P IEEE INT C ROB AUT.
   Konolige K, 2009, P IEEE RSJ INT C INT.
   Kretzschmar H., 2011, P IEEE RSJ INT C INT.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kummerle R., 2011, P IEEE INT C ROB AUT.
   Mazuran M, 2014, P ROB SCI SYST.
   NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.2307/2006193.
   Olson E., 2006, P IEEE INT C ROB AUT.
   Paskin MA, 2003, P INT JOINT C ART.
   Schmidt M., 2009, P INT C ART INT STAT.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Vandenberghe L, 1998, SIAM J MATRIX ANAL A, V19, P499, DOI 10.1137/S0895479896303430.
   Vial J, 2011, P IEEE RSJ INT C INT.},
Number-of-Cited-References = {37},
Times-Cited = {30},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {DA8CT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000368032600004},
DA = {2022-05-17},
}

@inproceedings{ WOS:000591652100462,
Author = {Jang, Junwoo and Kim, Jinwhan},
Book-Group-Author = {IEEE},
Title = {Weighted Grid Partitioning for Panel-Based Bathymetric SLAM},
DOI = {10.1109/OCEANSE.2019.8867531},
Booktitle = {OCEANS 2019 - MARSEILLE},
Series = {OCEANS-IEEE},
Year = {2019},
Note = {OCEANS - Marseille Conference, Marseille, FRANCE, JUN 17-20, 2019},
Abstract = {Bathymetric navigation enables the long-term operation of autonomous
   underwater vehicles by reducing navigation drift errors with no need for
   GPS position fixes. In the case that a bathymetric map is not available,
   the simultaneous localization and mapping (SLAM) algorithm is required,
   but this increases computational complexity and memory requirement.
   Panel-based bathymetric SLAM could considerably reduce the computational
   burden. However, it may suffers from incorrect update when the vehicle
   does not belong to the updated panel. This study proposes a new update
   method, called weighted grid partitioning, which considers the
   probability distribution of a vehicle's location, and is more effective
   in terms of the map accuracy, computational burden, and memory usage
   compared to standard update methods. The feasibility of the proposed
   algorithm is verified through simulations.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Jang, J (Corresponding Author), Korea Adv Inst Sci \& Technol, Dept Mech Engn, Daejoen, South Korea.
   Jang, Junwoo; Kim, Jinwhan, Korea Adv Inst Sci \& Technol, Dept Mech Engn, Daejoen, South Korea.},
ISSN = {0197-7385},
ISBN = {978-1-7281-1450-7},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Ocean; Engineering, Electrical \&
   Electronic},
Author-Email = {garesum1@kaist.ac.kr
   jinwhan@kaist.ac.kr},
Affiliations = {Korea Advanced Institute of Science \& Technology (KAIST)},
ResearcherID-Numbers = {Kim, JinWhan/C-1807-2011},
Funding-Acknowledgement = {Agency for Defense Development, Korea},
Funding-Text = {This research was part of the project titled `Autonomous control
   technology development for antisubmarine warfare unmanned underwater
   vehicle', funded by the Agency for Defense Development, Korea.},
Cited-References = {Barkby S, 2011, J FIELD ROBOT, V28, P19, DOI 10.1002/rob.20382.
   Kim J, 2011, INT J PHOTOENERGY, V2011, DOI 10.1155/2011/359161.
   Kim T., 2017, OCEANS ANCHORAGE 201, P1.
   Melo J, 2017, OCEAN ENG, V139, P250, DOI 10.1016/j.oceaneng.2017.04.047.
   Palomer A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040560.
   Roman C, 2006, IEEE INT CONF ROBOT, P3568, DOI 10.1109/ROBOT.2006.1642247.
   Shimada N, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P268, DOI 10.1109/AFGR.1998.670960.
   Simon D, 2010, INT J SYST SCI, V41, P159, DOI 10.1080/00207720903042970.
   Stuckey R.A., 2012, IFAC P, V45, P118, DOI {[}10.3182/20120410-3-PT-4028.00021, DOI 10.3182/20120410-3-PT-4028.00021].},
Number-of-Cited-References = {9},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BQ4OM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000591652100462},
DA = {2022-05-17},
}

@article{ WOS:000722531000001,
Author = {Sung, Changki and Jeon, Seulgi and Lim, Hyungtae and Myung, Hyun},
Title = {What if there was no revisit? Large-scale graph-based SLAM with traffic
   sign detection in an HD map using LiDAR inertial odometry},
Year = {2021},
Journal = {INTELLIGENT SERVICE ROBOTICS},
Abstract = {Accurate localization and mapping in a large-scale environment is an
   essential system of an autonomous vehicle. The difficulty of the
   previous LiDAR or LiDAR-inertial simultaneous localization and mapping
   (SLAM) methods is correcting long-term drift error in a large-scale
   environment. This paper proposes a novel approach of a large-scale,
   graph-based SLAM with traffic sign data involved in a high-definition
   (HD) map. The graph of the system is structured with the inertial
   measurement unit (IMU) factor, LiDAR-inertial odometry factor,
   map-matching factor, and loop closure factor. The local sliding
   window-based optimization method is employed for real-time processing.
   As a result, the proposed method improves the accuracy of the
   localization and mapping compared with the state-of-the-art LiDAR or
   LiDAR-inertial SLAM methods. In addition, the proposed method can
   localize accurately without revisit, required for conventional
   graph-based SLAM for graph optimization, unlike previous studies. The
   proposed method is intensively validated with a data set collected in a
   city where the Global Navigation Satellite System (GNSS) signal is
   unreliable and on a university campus.},
Publisher = {SPRINGER HEIDELBERG},
Address = {TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Myung, H (Corresponding Author), KAIST Korea Adv Inst Sci \& Technol, Robot Program, KI AI, KI R, Daejeon 34141, South Korea.
   Myung, H (Corresponding Author), KAIST Korea Adv Inst Sci \& Technol, KI R, KI AI, Sch Elect Engn, Daejeon 34141, South Korea.
   Sung, Changki; Myung, Hyun, KAIST Korea Adv Inst Sci \& Technol, Robot Program, KI AI, KI R, Daejeon 34141, South Korea.
   Jeon, Seulgi; Lim, Hyungtae; Myung, Hyun, KAIST Korea Adv Inst Sci \& Technol, KI R, KI AI, Sch Elect Engn, Daejeon 34141, South Korea.},
DOI = {10.1007/s11370-021-00395-2},
EarlyAccessDate = {NOV 2021},
ISSN = {1861-2776},
EISSN = {1861-2784},
Keywords = {Autonomous vehicle; 3D LiDAR SLAM; HD map; 3D point cloud map},
Keywords-Plus = {REGISTRATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {cs1032@kaist.ac.kr
   jseulgi@kaist.ac.kr
   shapelim@kaist.ac.kr
   hmyung@kaist.ac.kr},
Affiliations = {Korea Advanced Institute of Science \& Technology (KAIST); Korea
   Advanced Institute of Science \& Technology (KAIST)},
ResearcherID-Numbers = {Myung, Hyun/C-1698-2011},
ORCID-Numbers = {Myung, Hyun/0000-0002-5799-2026},
Funding-Acknowledgement = {research project ``Development of A.I. based recognition, judgement and
   control solution for autonomous vehicle corresponding to atypical
   driving environment{''} - Ministry of Science and ICT (Republic of
   Korea) {[}2019-0-00399]; BK21 FOUR from the Ministry of Education
   (Republic of Korea); Korea Ministry of Land, Infrastructure and
   Transport (MOLIT) as ``Innovative Talent Education Program for Smart
   City{''}},
Funding-Text = {This work was supported by the research project ``Development of A.I.
   based recognition, judgement and control solution for autonomous vehicle
   corresponding to atypical driving environment,{''} which is financed
   from the Ministry of Science and ICT (Republic of Korea) Contract No.
   2019-0-00399. The students are supported by the BK21 FOUR from the
   Ministry of Education (Republic of Korea) and by Korea Ministry of Land,
   Infrastructure and Transport (MOLIT) as ``Innovative Talent Education
   Program for Smart City{''}.},
Cited-References = {Agarwal S., 2010, CERES SOLVER.
   Bahreinian SF, 2017, INTEL SERV ROBOT, V10, P271, DOI 10.1007/s11370-017-0226-9.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Ghallabi F, 2019, IEEE INT C INTELL TR, P4412, DOI 10.1109/ITSC.2019.8917057.
   Ghallabi F, 2019, IEEE INT VEH SYM, P1484, DOI 10.1109/IVS.2019.8814029.
   Ghallabi F, 2018, IEEE INT C INTELL TR, P2209, DOI 10.1109/ITSC.2018.8569951.
   Grisetti G., 2011, IEEE INT C ROB AUT I, P9.
   Haehnel D., 2009, P ROBOT SCI SYST, P435, DOI 10.15607/RSS.2009.V.021.
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331.
   Hyun J, 2019, INT CONF UBIQ ROBOT, P98, DOI 10.1109/URAI.2019.8768568.
   Jung S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12183022.
   Jung S, 2019, INT CONF UBIQ ROBOT, P208, DOI 10.1109/URAI.2019.8768677.
   Juric Andela, 2021, 2021 44th International Convention on Information, Communication and Electronic Technology (MIPRO), P1113, DOI 10.23919/MIPRO52101.2021.9596721.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kim H, 2019, IEEE ACCESS, V7, P76599, DOI 10.1109/ACCESS.2019.2921676.
   Kim H, 2017, IEEE ROBOT AUTOM LET, V2, P1518, DOI 10.1109/LRA.2017.2673868.
   Lim H, 2021, IEEE ROBOT AUTOM LET, V6, P6458, DOI 10.1109/LRA.2021.3093009.
   Lim H, 2020, IEEE INT C INT ROBOT, P10750, DOI 10.1109/IROS45743.2020.9340767.
   Lim H, 2021, IEEE ROBOT AUTOM LET, V6, P2272, DOI 10.1109/LRA.2021.3061363.
   Lim H, 2020, INT C CONTR AUTOMAT, P1155, DOI 10.23919/ICCAS50221.2020.9268266.
   Lim H, 2019, IEEE INT C INT ROBOT, P3241, DOI 10.1109/IROS40897.2019.8968551.
   Mirzaei FM, 2008, IEEE T ROBOT, V24, P1143, DOI 10.1109/TRO.2008.2004486.
   Open Source Robotics Foundation, 2018, ROBOT OPERATING SYST.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Rahman MM, 2019, INTEL SERV ROBOT, V12, P167, DOI 10.1007/s11370-018-00273-4.
   Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Thomas A, 2021, INTEL SERV ROBOT, V14, P235, DOI 10.1007/s11370-021-00359-6.
   Wei M., 1990, IEEE PLANS `90: Position Location and Navigation Symposium Record. `The 1990's - A Decade of Excellence in the Navigation Sciences' (Cat. No.90CH2811-8), P429, DOI 10.1109/PLANS.1990.66210.
   Ye HY, 2019, IEEE INT CONF ROBOT, P3144, DOI 10.1109/ICRA.2019.8793511.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.
   Zhang X, 2010, INTEL SERV ROBOT, V3, P263, DOI 10.1007/s11370-010-0071-6.},
Number-of-Cited-References = {40},
Times-Cited = {0},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {4},
Journal-ISO = {Intell. Serv. Robot.},
Doc-Delivery-Number = {XD2HN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000722531000001},
DA = {2022-05-17},
}

@inproceedings{ WOS:000375913700009,
Author = {Morrison, John G. and Galvez-Lopez, Dorian and Sibley, Gabe},
Editor = {Chong, NY and Cho, YJ},
Title = {MOARSLAM: Multiple Operator Augmented RSLAM},
Booktitle = {DISTRIBUTED AUTONOMOUS ROBOTIC SYSTEMS},
Series = {Springer Tracts in Advanced Robotics},
Year = {2016},
Volume = {112},
Pages = {119-132},
Note = {12th International Symposium on Distributed Autonomous Robotic Systems
   (DARS), Daejeon, SOUTH KOREA, NOV 02-05, 2015},
Abstract = {To effectively act on the same physical space, robots must first
   communicate to share and fuse the map of the area in which they operate.
   For long-term online operation, the merging of maps from heterogeneous
   devices must be fast and allow for scalable growth in both the number of
   clients and the size of the map. This paper presents a system which
   allows multiple clients to share and merge maps built from a
   state-of-the-art relative SLAM system. Maps can also be augmented with
   virtual elements that are consistently shared by all the clients. The
   visual-inertial mapping framework which underlies this system is
   discussed, along with the server architecture and novel integrated
   multi-session loop closure system. We show quantitative results of the
   system. The map fusion benefits are demonstrated with an example
   augmented reality application.},
Publisher = {SPRINGER JAPAN KK},
Address = {CHIYODA FIRST BLDG E, 3-8-1 NISHI-KANDA CHIYODA-KU, TOKYO, 101-0065,
   JAPAN},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Morrison, JG (Corresponding Author), Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA.
   Morrison, John G.; Galvez-Lopez, Dorian; Sibley, Gabe, Univ Colorado, Dept Comp Sci, Boulder, CO 80309 USA.},
DOI = {10.1007/978-4-431-55879-8\_9},
ISSN = {1610-7438},
ISBN = {978-4-431-55879-8; 978-4-431-55877-4},
Keywords = {Slam; Collaborative SLAM; Multi-agent mapping; Long-term autonomy},
Keywords-Plus = {NETWORKS; TIME},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {john.morrison@colorado.edu
   Dorian.GalvezLopez@colorado.edu
   gsibley@colorado.edu},
Affiliations = {University of Colorado System; University of Colorado Boulder},
ResearcherID-Numbers = {Gill, Harinderjit S/A-9808-2011
   Mellon, Stephen J/B-9744-2013},
ORCID-Numbers = {Gill, Harinderjit S/0000-0002-7740-2062
   Mellon, Stephen J/0000-0002-6375-6839},
Cited-References = {Aragues R, 2012, IEEE T ROBOT, V28, P840, DOI 10.1109/TRO.2012.2192012.
   Bryson M, 2009, J INTELL ROBOT SYST, V55, P267, DOI 10.1007/s10846-008-9303-9.
   Castle RO, 2011, COMPUT VIS IMAGE UND, V115, P854, DOI 10.1016/j.cviu.2011.02.007.
   Chang HJ, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1473.
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276.
   Forster C, 2013, IEEE INT C INT ROBOT, P3963.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Keivan N., 2014, INT S EXP ROB JUN 20.
   Klein George, 2007, P1.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Leung KYK, 2011, IEEE INT CONF ROBOT.
   McDonald J, 2013, ROBOT AUTON SYST, V61, P1144, DOI 10.1016/j.robot.2012.08.008.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Olson E, 2013, INT J ROBOT RES, V32, P826, DOI 10.1177/0278364913479413.
   Ozkucur NE, 2010, LECT NOTES ARTIF INT, V5949, P449, DOI 10.1007/978-3-642-11876-0\_39.
   Riazuelo L, 2014, ROBOT AUTON SYST, V62, P401, DOI 10.1016/j.robot.2013.11.007.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Salas-Moreno R.F., 2013, IEEE COMPUTER VISION.
   Sharma R., 2010, AIAA GUID NAV CONTR, P8334.
   Waibel M, 2011, IEEE ROBOT AUTOM MAG, V18, P69, DOI 10.1109/MRA.2011.941632.},
Number-of-Cited-References = {21},
Times-Cited = {14},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BE7UJ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000375913700009},
DA = {2022-05-17},
}

@inproceedings{ WOS:000241583101029,
Author = {Bryson, Mitch and Sukkarieh, Salah},
Book-Group-Author = {IEEE},
Title = {Active airborne localisation and exploration in unknown environments
   using inertial SLAM},
DOI = {10.1109/AERO.2006.1655801},
Booktitle = {2006 IEEE AEROSPACE CONFERENCE, VOLS 1-9},
Series = {IEEE Aerospace Conference Proceedings},
Year = {2006},
Pages = {910+},
Note = {2006 IEEE Aerospace Conference, Big Sky, MT, MAR 04-11, 2006},
Abstract = {Future Unmanned Aerial Vehicle (UAV) applications will require
   high-accuracy localisation in environments in which navigation
   infrastructure such as the Global Positioning System (GPS) and prior
   terrain maps may be unavailable or unreliable. In these applications,
   long-term operation requires the vehicle to build up a spatial map of
   the environment while simultaneously localising itself within the map, a
   task known as Simultaneous Localisation And Mapping (SLAM). In the first
   part of this paper we present an architecture for performing
   inertial-sensor based SLAM on an aerial vehicle. We demonstrate an
   on-line path planning scheme that intelligently plans the vehicle's
   trajectory while exploring unknown terrain in order to maximise the
   quality of both the resulting SLAM map and localisation estimates
   necessary for the autonomous control of the UAV. Two important
   performance properties and their relationship to the dynamic motion and
   path planning systems on-board the UAV are analysed. Firstly we analyse
   information-based measures such as Entropy. Secondly we perforin an
   observability analysis of inertial SLAM by recasting the algorithms into
   an indirect error model form. Qualitative knowledge gained from the
   observability analysis is used to assist in the design of an
   information-based trajectory planner for the UAV. Results of the online
   path planning algorithm are presented using a high-fidelity 6-DoF
   simulation of a UAV during a simulated navigation and mapping task.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bryson, M (Corresponding Author), Univ Sydney, ARC Ctr Excellence Autonomous Syst, Australian Ctr Field Robot, Sydney, NSW 2006, Australia.
   Bryson, Mitch; Sukkarieh, Salah, Univ Sydney, ARC Ctr Excellence Autonomous Syst, Australian Ctr Field Robot, Sydney, NSW 2006, Australia.},
ISSN = {1095-323X},
ISBN = {0-7803-9545-X},
Keywords = {navigation; mapping; SLAM; autonomous vehicles; observability},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Aerospace},
Author-Email = {m.bryson@cas.edu.au
   salah@cas.edu.au},
Affiliations = {University of Sydney},
Funding-Acknowledgement = {ARC; Australian Research Council; New South Wales State Government},
Funding-Text = {This work is supported in part by the ARC Centre of Excellence
   programme,funded by the Australian Research Council and the New South
   Wales State Government},
Cited-References = {Bar-Gill A., 1994, IEEE Transactions on Control Systems Technology, V2, P336, DOI 10.1109/87.338654.
   Bourgault F., 2002, IEEE INT C INT ROB S.
   BRAUN RD, 2004, IEEE AER C BIG SKY M.
   BRYSON M, 2005, IEEE RSJ INT C INT R.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   GOSHENMESKIN D, 1992, IEEE T AERO ELEC SYS, V28, P1056, DOI 10.1109/7.165367.
   Kim J., 2003, IEEE INT C ROB AUT T.
   KIM JH, 2003, INT C FIELD SERV ROB.
   MAKARENKO A, 2002, IEEE INT C INT ROB S.
   ROY N, 1999, IEEE RSJ INT C ROB A.
   SIM R, 2004, IEEE INT C ROB AUT N.
   Williams S, 2001, ADV ROBOTICS, V15, P533, DOI 10.1163/156855301317033559.
   {[}No title captured].},
Number-of-Cited-References = {13},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BFF34},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000241583101029},
DA = {2022-05-17},
}

@inproceedings{ WOS:000337617305032,
Author = {Suenderhauf, Niko and Protzel, Peter},
Book-Group-Author = {IEEE},
Title = {Switchable Constraints vs. Max-Mixture Models vs. RRR - A Comparison of
   Three Approaches to Robust Pose Graph SLAM},
DOI = {10.1109/ICRA.2013.6631320},
Booktitle = {2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2013},
Pages = {5198-5203},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Karlsruhe, GERMANY, MAY 06-10, 2013},
Abstract = {SLAM algorithms that can infer a correct map despite the presence of
   outliers have recently attracted increasing attention. In the context of
   SLAM, outlier constraints are typically caused by a failed place
   recognition due to perceptional aliasing. If not handled correctly, they
   can have catastrophic effects on the inferred map. Since robust robotic
   mapping and SLAM are among the key requirements for autonomous long-term
   operation, inference methods that can cope with such data association
   failures are a hot topic in current research. Our paper compares three
   very recently published approaches to robust pose graph SLAM, namely
   switchable constraints, max-mixture models and the RRR algorithm. All
   three methods were developed as extensions to existing factor
   graph-based SLAM back-ends and aim at improving the overall system's
   robustness to false positive loop closure constraints. Due to the
   novelty of the three proposed algorithms, no direct comparison has been
   conducted so far.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Sunderhauf, N (Corresponding Author), Tech Univ Chemnitz, Dept Elect Engn \& Informat Technol, D-09111 Chemnitz, Germany.
   Suenderhauf, Niko; Protzel, Peter, Tech Univ Chemnitz, Dept Elect Engn \& Informat Technol, D-09111 Chemnitz, Germany.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4673-5641-1; 978-1-4673-5643-5},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {niko@etit.tu-chemnitz.de},
Affiliations = {Technische Universitat Chemnitz},
ResearcherID-Numbers = {Sünderhauf, Niko/O-2192-2017},
ORCID-Numbers = {Sünderhauf, Niko/0000-0001-5286-3789},
Cited-References = {BURGARD W, 2009, P IEEE RSJ INT C INT.
   Ceriani S, 2009, AUTON ROBOT, V27, P353, DOI 10.1007/s10514-009-9156-5.
   HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503.
   Kaess M., 2012, INT J ROBOTICS RESEA.
   Kaess M., 2008, IEEE T ROBOTICS, V24.
   Kummerle R., 2011, P INT C ROB AUT ICRA.
   Latif Yasir, 2012, P ROB SCI SYST RSS S.
   Olson E., 2012, P ROB SCI SYST RSS S.
   Olson Edwin, 2013, INT J ROBOT IN PRESS.
   Olson Edwin, 2006, INT C ROB AUT ICRA 2.
   Sunderhauf Niko, 2012, P IEEE INT C INT ROB.
   Sunderhauf Niko, 2012, THESIS CHEMNITZ U TE.},
Number-of-Cited-References = {12},
Times-Cited = {27},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {6},
Doc-Delivery-Number = {BA7KQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000337617305032},
DA = {2022-05-17},
}

@article{ WOS:000554055600001,
Author = {Zeng, Taiping and Si, Bailu},
Title = {A brain-inspired compact cognitive mapping system},
Journal = {COGNITIVE NEURODYNAMICS},
Year = {2021},
Volume = {15},
Number = {1, SI},
Pages = {91-101},
Month = {FEB},
Abstract = {In many simultaneous localization and mapping (SLAM) systems, the map of
   the environment grows over time as the robot explores the environment.
   The ever-growing map prevents long-term mapping, especially in
   large-scale environments. In this paper, we develop a compact cognitive
   mapping approach inspired by neurobiological experiments. Mimicking the
   firing activities of neighborhood cells, neighborhood fields determined
   by movement information, i.e. translation and rotation, are modeled to
   describe one of the distinct segments of the explored environment. The
   vertices with low neighborhood field activities are avoided to be added
   into the cognitive map. The optimization of the cognitive map is
   formulated as a robust non-linear least squares problem constrained by
   the transitions between vertices, and is numerically solved efficiently.
   According to the cognitive decision-making of place familiarity, loop
   closure edges are clustered depending on time intervals, and then batch
   global optimization of the cognitive map is performed to satisfy the
   combined constraint of the whole cluster. After the loop closure
   process, scene integration is performed, in which revisited vertices are
   removed subsequently to further reduce the size of the cognitive map.
   The compact cognitive mapping approach is tested on a monocular visual
   SLAM system in a naturalistic maze for a biomimetic animated robot. Our
   results demonstrate that the proposed method largely restricts the
   growth of the size of the cognitive map over time, and meanwhile, the
   compact cognitive map correctly represents the overall layout of the
   environment. The compact cognitive mapping method is well suitable for
   the representation of large-scale environments to achieve long-term
   robot navigation.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Si, BL (Corresponding Author), Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.
   Zeng, Taiping, Fudan Univ, Inst Sci \& Technol Brain Inspired Intelligence, Shanghai, Peoples R China.
   Zeng, Taiping, Fudan Univ, Minist Educ, Key Lab Computat Neurosci \& Brain Inspired Intell, Shanghai, Peoples R China.
   Si, Bailu, Beijing Normal Univ, Sch Syst Sci, Beijing 100875, Peoples R China.},
DOI = {10.1007/s11571-020-09621-6},
EarlyAccessDate = {JUL 2020},
ISSN = {1871-4080},
EISSN = {1871-4099},
Keywords = {SLAM; Compact cognitive map; Long-term mapping; Neighborhood cells;
   Neighborhood fields},
Keywords-Plus = {PATH-INTEGRATION; SPATIAL MAP; TIME CELLS; INFORMATION; HIPPOCAMPUS;
   MEMORY; RATS},
Research-Areas = {Neurosciences \& Neurology},
Web-of-Science-Categories  = {Neurosciences},
Author-Email = {zengtaiping@fudan.edu.cn
   bailusi@bnu.edu.cn},
Affiliations = {Fudan University; Fudan University; Beijing Normal University},
ResearcherID-Numbers = {Si, Bailu/O-9575-2014},
ORCID-Numbers = {Si, Bailu/0000-0002-0260-3433},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2016YFC0801808]},
Funding-Text = {The authors would like to thank the support from the National Key
   Research and Development Program of China (No. 2016YFC0801808).},
Cited-References = {Ball DR, 2010, IEEE INT SOI CONF.
   Ball D, 2013, AUTON ROBOT, V34, P149, DOI 10.1007/s10514-012-9317-9.
   Bos JJ, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15602.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   Carr MF, 2011, NAT NEUROSCI, V14, P147, DOI 10.1038/nn.2732.
   Eichenbaum H, 2014, NAT REV NEUROSCI, V15, P732, DOI 10.1038/nrn3827.
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kropff E, 2015, NATURE, V523, P419, DOI 10.1038/nature14622.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Larkin MC, 2014, HIPPOCAMPUS, V24, P773, DOI 10.1002/hipo.22268.
   Lever C, 2009, J NEUROSCI, V29, P9771, DOI 10.1523/JNEUROSCI.1319-09.2009.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   MacDonald CJ, 2011, NEURON, V71, P737, DOI 10.1016/j.neuron.2011.07.012.
   Mazuran M, 2016, INT J ROBOT RES, V35, P50, DOI 10.1177/0278364915581629.
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   MITTELSTAEDT ML, 1980, NATURWISSENSCHAFTEN, V67, P566, DOI 10.1007/BF00450672.
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723.
   Moser MB, 2015, CSH PERSPECT BIOL, V7, DOI 10.1101/cshperspect.a021808.
   Naidoo R, 2016, ORYX, V50, P138, DOI 10.1017/S0030605314000222.
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1.
   TAUBE JS, 1990, J NEUROSCI, V10, P420.
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626.
   Zeng TP, 2020, NEURAL NETWORKS, V126, P21, DOI 10.1016/j.neunet.2020.02.023.
   Zeng TP, 2017, FRONT NEUROROBOTICS, V11, DOI 10.3389/fnbot.2017.00061.
   Zhao D, 2019, P 2019 INT JOINT C N.},
Number-of-Cited-References = {30},
Times-Cited = {2},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {29},
Journal-ISO = {Cogn. Neurodynamics},
Doc-Delivery-Number = {QU6QJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000554055600001},
OA = {Green Submitted, Green Published},
DA = {2022-05-17},
}

@article{ WOS:000712340600002,
Author = {Jiang, Fan and Chen, Jiagang and Ji, Shunping},
Title = {Panoramic Visual-Inertial SLAM Tightly Coupled with a Wheel Encoder},
Journal = {ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING},
Year = {2021},
Volume = {182},
Pages = {96-111},
Month = {DEC},
Abstract = {This paper presents a panoramic visual-inertial simultaneous
   localization and mapping (SLAM) system that is tightly coupled with a
   wheel encoder, which can be used in a mobile mapping system (MMS),
   robot, or driverless car. The whole SLAM system is made up of four
   modules: 1) measurement preprocessing; 2) system initialization; 3)
   tracking; and 4) local mapping. The core of the system is the combined
   adjustment we propose for the observations of the panoramic camera,
   inertial measurement unit (IMU), and wheel encoder, to optimize the
   system state, which includes the rotation, translation, velocity, IMU
   bias, and local map point coordinates in the initialization, tracking,
   and local mapping modules. In the preprocessing, the most important
   contribution is that we derive the wheel preintegration based on a
   two-wheel differential model, which combines the many wheel measurements
   between two frames into a single relative motion constraint. A novel
   initialization algorithm is also introduced, which can be divided into
   two steps: 1) the first step is to initialize the visual scale and
   parameters of the IMU; and 2) the second step is to perform the combined
   adjustment for the camera, IMU, and preintegrated wheel encoder data, to
   refine the initial parameters. The proposed panoramic camera-IMU-wheel
   SLAM (PIW-SLAM) system can achieve high-precision and robust
   localization in challenging scenes through multi-sensor fusion. We
   validated the performance of the proposed system on seven different
   challenging data sequences from the University of Michigan North Campus
   Long-Term Vision and LiDAR Dataset (NCLT) dataset. The results showed
   that the PIW-SLAM system has a higher localization accuracy than the
   other state-of-the-art SLAM systems, and it also showed a superior
   robustness in various complex environments. We also verified the
   accuracy of the scale obtained by the initialization algorithm.
   Furthermore, we confirmed the performance of the proposed PIW-SLAM
   system in a wide-baseline scene of the ground motion measurement system.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Ji, SP (Corresponding Author), Wuhan Univ, Sch Remote Sensing \& Informat Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
   Jiang, Fan; Chen, Jiagang; Ji, Shunping, Wuhan Univ, Sch Remote Sensing \& Informat Engn, 129 Luoyu Rd, Wuhan 430079, Peoples R China.},
DOI = {10.1016/j.isprsjprs.2021.10.006},
EarlyAccessDate = {OCT 2021},
ISSN = {0924-2716},
EISSN = {1872-8235},
Keywords = {SLAM; Panoramic camera; IMU; Wheel encoder; Multi-sensor fusion},
Keywords-Plus = {ODOMETRY; ROBUST; VERSATILE},
Research-Areas = {Physical Geography; Geology; Remote Sensing; Imaging Science \&
   Photographic Technology},
Web-of-Science-Categories  = {Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {jiang\_fan@whu.edu.cn
   chenjiagang2015@whu.edu.cn
   jishunping@whu.edu.cn},
Affiliations = {Wuhan University},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2018YFB0505003]; State Key Program of the National Natural Science
   Foundation of China {[}42030102]},
Funding-Text = {This work was supported by the National Key Research and Development
   Program of China (grant No. 2018YFB0505003) and the State Key Program of
   the National Natural Science Foundation of China (No. 42030102). We also
   thank the two anonymous reviewers for their constructive comments and
   suggestions.},
Cited-References = {Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389.
   Campos C., ARXIV PREPRINT ARXIV.
   Campos C, 2020, IEEE INT CONF ROBOT, P51, DOI 10.1109/ICRA40945.2020.9197334.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Caruso D, 2015, IEEE INT C INT ROBOT, P141, DOI 10.1109/IROS.2015.7353366.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335.
   Gang P., 2020, ARXIV PREPRINT ARXIV.
   Geneva P, 2020, IEEE INT CONF ROBOT, P4666, DOI 10.1109/ICRA40945.2020.9196524.
   Grupp M., 2017, EVO PYTHON PACKAGE E.
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732.
   Ji SP, 2020, ISPRS J PHOTOGRAMM, V159, P169, DOI 10.1016/j.isprsjprs.2019.11.014.
   Ji SP, 2015, ISPRS J PHOTOGRAMM, V105, P1, DOI 10.1016/j.isprsjprs.2015.03.005.
   Jung J.H., 2020, IEEE T INTELL TRANSP.
   Klein George, 2007, P1.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Liu JX, 2019, IEEE INT C INT ROBOT, P5391, DOI 10.1109/IROS40897.2019.8967607.
   Matsuki H, 2018, IEEE ROBOT AUTOM LET, V3, P3693, DOI 10.1109/LRA.2018.2855443.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Qin T., 2019, ARXIV190103638.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Qin T, 2017, IEEE INT C INT ROBOT, P4225, DOI 10.1109/IROS.2017.8206284.
   Seok H, 2020, IEEE ROBOT AUTOM LET, V5, P6225, DOI 10.1109/LRA.2020.3010457.
   Seok H, 2019, IEEE INT CONF ROBOT, P6344, DOI 10.1109/ICRA.2019.8793758.
   Shi Y, 2013, SENSORS-BASEL, V13, P119, DOI 10.3390/s130100119.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Sumikura S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2292, DOI 10.1145/3343031.3350539.
   Urban S, 2016, ARXIV161007336V1.
   Wang Y., 2018, AS C COMP VIS.
   Weiss S, 2012, IEEE INT CONF ROBOT, P957, DOI 10.1109/ICRA.2012.6225147.
   Wu Kejian J., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5155, DOI 10.1109/ICRA.2017.7989603.},
Number-of-Cited-References = {38},
Times-Cited = {0},
Usage-Count-Last-180-days = {18},
Usage-Count-Since-2013 = {18},
Journal-ISO = {ISPRS-J. Photogramm. Remote Sens.},
Doc-Delivery-Number = {WO3EF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000712340600002},
OA = {hybrid},
DA = {2022-05-17},
}

@article{ WOS:000377526400007,
Author = {Tanaka, Kanji and Chokushi, Yuuto and Ando, Masatoshi},
Title = {Mining Visual Phrases for Visual Robot Localization},
Journal = {JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT
   INFORMATICS},
DOI = {10.20965/jaciii.2016.p0057},
Year = {2016},
Volume = {20},
Number = {1},
Pages = {57-65},
Month = {JAN},
Abstract = {We propose a discriminative and compact scene descriptor for single-view
   place recognition that facilitates long-term visual SLAM in familiar,
   semidynamic, and partially changing environments. In contrast to popular
   bag-of-words scene descriptors, which rely on a library of vector
   quantized visual features, our proposed scene descriptor is based on a
   library of raw image data (such as an available visual experience,
   images shared by other colleague robots, and publicly available image
   data on the Web) and directly mine it to find visual phrases (VPs) that
   discriminatively and compactly explain an input query/database image.
   Our mining approach is motivated by recent success achieved in the field
   of common pattern discovery - specifically mining of common visual
   patterns among scenes - and requires only a single library of raw images
   that can be acquired at different times or on different days.
   Experimental results show that, although our scene descriptor is
   significantly more compact than conventional descriptors, its
   recognition performance is relatively high.},
Publisher = {FUJI TECHNOLOGY PRESS LTD},
Address = {1-15-7, UCHIKANDA, CHIYODA-KU, UNIZO UCHIKANDA 1-CHOME BLDG 2F, TOKYO,
   101-0047, JAPAN},
Type = {Article},
Language = {English},
Affiliation = {Tanaka, K (Corresponding Author), Univ Fukui, 2-7-1 Bunkyo, Fukui 9108507, Japan.
   Tanaka, Kanji; Chokushi, Yuuto; Ando, Masatoshi, Univ Fukui, 2-7-1 Bunkyo, Fukui 9108507, Japan.},
ISSN = {1343-0130},
EISSN = {1883-8014},
Keywords = {long-term visual SLAM; common pattern discovery; mining visual phrases},
Keywords-Plus = {NAVIGATION; SLAM},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Cited-References = {Ando M., 2014, IROS WORKSH PLANN PE.
   Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077.
   Bo L., 2012, ISER.
   Carlevaris-Bianco N, 2013, IEEE INT C INT ROBOT, P1034, DOI 10.1109/IROS.2013.6696478.
   Cho M, 2010, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR.2010.5539777.
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236.
   Churchill W, 2012, IEEE INT C INTELL TR, P1371, DOI 10.1109/ITSC.2012.6338716.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Cummins M., 2009, ROBOTICS SCI SYSTEMS.
   Cunningham A, 2012, IEEE INT CONF ROBOT, P1093, DOI 10.1109/ICRA.2012.6225356.
   Felzenszwalb P., 2008, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2008.4587597.
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602.
   Hanada S., 2013, IROS.
   Hongbin Zha, 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS `97 (Cat. No.97CH36108), P1729, DOI 10.1109/IROS.1997.656593.
   Huang AS, 2010, INT J ROBOT RES, V29, P1595, DOI 10.1177/0278364910384295.
   Ikeda K, 2010, IEEE INT CONF ROBOT, P4397, DOI 10.1109/ROBOT.2010.5509579.
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235.
   Jiang YN, 2012, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2012.6248042.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Kanji T, 2014, IEEE INT C INT ROBOT, P136, DOI 10.1109/IROS.2014.6942552.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Leibe B., 2004, ECCV WORKSH STAT LEA, P1732.
   Li L.-J., 2010, P NIPS, P1378.
   Masatoshi A, 2015, IEEE INT CONF ROBOT, P5455, DOI 10.1109/ICRA.2015.7139961.
   McDonald J, 2013, ROBOT AUTON SYST, V61, P1144, DOI 10.1016/j.robot.2012.08.008.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001.
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711.
   Saeki Kenichi, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P3523, DOI 10.1109/ROBOT.2009.5152201.
   Shahbazi H, 2011, IEEE INT C INT ROBOT, P1228, DOI 10.1109/IROS.2011.6048862.
   Sunderhauf N., 2013, WORKSH LONG TERM AUT.
   Taisho T, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P194, DOI 10.1109/MVA.2015.7153165.
   Tan HK, 2005, IEEE I CONF COMP VIS, P1222.
   Tanaka K, 2004, IEEE INT CONF ROBOT, P1487, DOI 10.1109/ROBOT.2004.1308034.
   Viola P., 2001, ROBUST REAL TIME OBJ.
   Yuan J., 2007, P IEEE C COMP VIS PA, P1.
   ZHENG QF, 2006, P 14 ACM INT C MULT, P00077.},
Number-of-Cited-References = {40},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Journal-ISO = {J. Adv. Comput. Intell. Inform.},
Doc-Delivery-Number = {DO1GL},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000377526400007},
DA = {2022-05-17},
}

@inproceedings{ WOS:000380472300085,
Author = {Rao, Akshay and Han, Wang},
Book-Group-Author = {IEEE},
Title = {An Adaptive Gaussian Particle Filter based Simultaneous Localization and
   Mapping with Dynamic Process Model Noise Bias Compensation},
DOI = {10.1109/ICCIS.2015.7274622},
Booktitle = {PROCEEDINGS OF THE 2015 7TH IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS
   AND INTELLIGENT SYSTEMS (CIS) AND ROBOTICS, AUTOMATION AND MECHATRONICS
   (RAM)},
Year = {2015},
Note = {Proceedings of the 2015 7th IEEE International Conference on Cybernetics
   and Intelligent Systems (CIS) And Robotics, Automation and Mechatronics
   (RAM), IEEE, Angkor Wat, CAMBODIA, JUL 15-17, 2015},
Abstract = {Simultaneous Localization and Mapping (SLAM) is a fundamental component
   of all autonomous robotics systems, which probabilisticaly fuses
   information from an exteroceptive sensor and a proprioceptive sensor to
   simultaneously estimate the robot's trajectory and the map. Inputs from
   the proprioceptive sensor are fed into the estimation algorithm via a
   process model corresponding with the vehicle kinematics, while a
   measurement model is used to process inputs from the exteroceptive
   sensor.
   Most SLAM algorithms assume known, fixed model estimate bias. This
   assumption does not hold true for systems with wrongly modeled estimate
   bias, or those affected by component fatigue due to applications
   requiring long term autonomy.
   This paper will display the adverse effects of mismodeled process model
   bias using a simulation. An adaptive algorithm employing Adaptive
   Gaussian Particle Filter based process model bias compensation will be
   deployed in tandem with a particle filter based FastSLAM algorithm. The
   algorithm will be compared favourably with existing state of the art
   SLAM algorithms in controlled simulations. Experimental data from a
   marine environment will be used to validate the efficacy of the
   algorithm.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Rao, A (Corresponding Author), Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.
   Rao, Akshay; Han, Wang, Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.},
ISBN = {978-1-4673-7338-8},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Computer Science, Cybernetics; Robotics},
Author-Email = {aksh0010@e.ntu.edu.sg
   hw@ntu.edu.sg},
Affiliations = {Nanyang Technological University \& National Institute of Education
   (NIE) Singapore; Nanyang Technological University},
ResearcherID-Numbers = {Wang, Han/A-5016-2011},
ORCID-Numbers = {Wang, Han/0000-0001-5448-9903},
Cited-References = {Dissanayake G., 2001, T ROBOTICS AUTOMATIO.
   Hahnel Dirk, 2003, INT ROB SYST 2003 IR, V1.
   JETTO L, 1999, IEEE T ROBOTICS AUTO, V0015.
   Kotecha JH, 2003, IEEE T SIGNAL PROCES, V51, P2592, DOI 10.1109/TSP.2003.816758.
   MEHRA RK, 1970, IEEE T AUTOMAT CONTR, VAC15, P175, DOI 10.1109/TAC.1970.1099422.
   Montemerlo M., IEEE INT C ROB AUT, V1, P412.
   Mullane John, 2010, P IEEE INT C AUT ROB.
   Myers K. A., 1976, IEEE T AUTOMATIC CON, V21.
   Perera LDL, 2010, IEEE T CONTR SYST T, V18, P732, DOI 10.1109/TCST.2009.2026165.
   Rao A, 2011, OCEANS-IEEE.
   Rao A., 2013, ADV ROB ITS SOC IMP, p{[}113, 118], DOI {[}10.1109/ARSO.2013.6705515, DOI 10.1109/ARSO.2013.6705515].
   SMITH R, 1990, AUTONOMOUS ROBOT VEH.
   Smith R. C., 1985, 4760 TR SRI.
   Stengel R., 1994, OPTIMAL CONTROL ESTI.},
Number-of-Cited-References = {14},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BF2JE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380472300085},
DA = {2022-05-17},
}

@inproceedings{ WOS:000392215500151,
Author = {Arroyo, Roberto and Alcantarilla, Pablo F. and Bergasa, Luis M. and
   Romera, Eduardo},
Book-Group-Author = {IEEE},
Title = {OpenABLE: An Open-source Toolbox for Application in Life-Long Visual
   Localization of Autonomous Vehicles},
DOI = {10.1109/ITSC.2016.7795672},
Booktitle = {2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION
   SYSTEMS (ITSC)},
Year = {2016},
Pages = {965-970},
Note = {19th IEEE International Conference on Intelligent Transportation Systems
   (ITSC), Rio de Janeiro, BRAZIL, NOV 01-04, 2016},
Abstract = {Visual information is a valuable asset in any perception scheme designed
   for an intelligent transportation system. In this regard, the
   camera-based recognition of locations provides a higher situational
   awareness of the environment, which is very useful for varied
   localization solutions typically needed in long-term autonomous
   navigation, such as loop closure detection and visual odometry or SLAM
   correction. In this paper we present OpenABLE, an open-source tool-box
   contributed to the community with the aim of helping researchers in the
   application of these kinds of life-long localization algorithms. The
   implementation follows the philosophy of the topological place
   recognition method named ABLE, including several new features and
   improvements. These functionalities allow to match locations using
   different global image description methods and several configuration
   options, which enable the users to control varied parameters in order to
   improve the performance of place recognition depending on their specific
   problem requisites. The applicability of our toolbox in visual
   localization purposes for intelligent vehicles is validated in the
   presented results, jointly with comparisons to the main state-of-the-art
   methods.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Arroyo, R (Corresponding Author), Univ Alcala UAH, Dept Elect, Madrid 28871, Spain.
   Arroyo, Roberto; Bergasa, Luis M.; Romera, Eduardo, Univ Alcala UAH, Dept Elect, Madrid 28871, Spain.
   Alcantarilla, Pablo F., iRobot Corp, 10 Greycoat Pl, London, England.},
ISBN = {978-1-5090-1889-5},
Keywords-Plus = {VISION; BINARY},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation Science \& Technology},
Author-Email = {roberto.arroyo@depeca.uah.es
   palcantarilla@irobot.com
   bergasa@depeca.uah.es
   eduardo.romera@depeca.uah.es},
Affiliations = {Universidad de Alcala},
ResearcherID-Numbers = {Bergasa, Luis M./H-9810-2013
   },
ORCID-Numbers = {Bergasa, Luis M./0000-0002-0087-3077
   Fernandez Alcantarilla, Pablo/0000-0001-7185-2911},
Funding-Acknowledgement = {University of Alcald (UAH); Spanish MINECO through the SmartElderlyCar
   {[}TRA2015-70501-C2-1-R]; Community of Madrid through the
   RoboCity2030-III-CM {[}S2013/MIT-2748]},
Funding-Text = {This work has been funded in part from the University of Alcald (UAH)
   through a FPI grant, the Spanish MINECO through the SmartElderlyCar
   project (TRA2015-70501-C2-1-R) and the Community of Madrid through the
   RoboCity2030-III-CM project (S2013/MIT-2748).},
Cited-References = {Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715.
   Alcantarilla P. F., 2016, ROB SCI SYST C RSS.
   Arroyo R., 2016, IEEE RSJ IROS.
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Arroyo R, 2014, IEEE INT C INT ROBOT, P3089, DOI 10.1109/IROS.2014.6942989.
   Arroyo R, 2014, IEEE INT VEH SYM, P1378, DOI 10.1109/IVS.2014.6856457.
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
   Bansal A, 2014, IEEE INT VEH SYM, P800, DOI 10.1109/IVS.2014.6856605.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Caramazana L., 2016, OP C FUT TRENDS ROB, P97.
   Churchill W, 2012, IEEE INT C INTELL TR, P1371, DOI 10.1109/ITSC.2012.6338716.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dalal N., 2005, 2005 IEEE COMPUTER S, P886, DOI {[}10.1109/CVPR.2005.177, DOI 10.1109/CVPR.2005.177].
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Kitt B, 2010, IEEE INT VEH SYM, P486, DOI 10.1109/IVS.2010.5548123.
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Maddern W, 2014, IEEE INT VEH SYM, P330, DOI 10.1109/IVS.2014.6856471.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Ros G., 2012, WORKSH IEEE 4.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Sunderhauf N., 2013, WORKSH IEEE ICRA.
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150.},
Number-of-Cited-References = {27},
Times-Cited = {13},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BG8CR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000392215500151},
DA = {2022-05-17},
}

@article{ WOS:000543394800031,
Author = {Chiang, Kai-Wei and Tsai, Guang-Je and Li, Yu-Hua and Li, You and
   El-Sheimy, Naser},
Title = {Navigation Engine Design for Automated Driving Using INS/GNSS/3D
   LiDAR-SLAM and Integrity Assessment},
Pages = {1564},
Journal = {REMOTE SENSING},
Year = {2020},
Volume = {12},
Number = {10},
Month = {MAY},
Abstract = {Automated driving has made considerable progress recently. The
   multisensor fusion system is a game changer in making self-driving cars
   possible. In the near future, multisensor fusion will be necessary to
   meet the high accuracy needs of automated driving systems. This paper
   proposes a multisensor fusion design, including an inertial navigation
   system (INS), a global navigation satellite system (GNSS), and light
   detection and ranging (LiDAR), to implement 3D simultaneous localization
   and mapping (INS/GNSS/3D LiDAR-SLAM). The proposed fusion structure
   enhances the conventional INS/GNSS/odometer by compensating for
   individual drawbacks such as INS-drift and error-contaminated GNSS.
   First, a highly integrated INS-aiding LiDAR-SLAM is presented to improve
   the performance and increase the robustness to adjust to varied
   environments using the reliable initial values from the INS. Second, the
   proposed fault detection exclusion (FDE) contributes SLAM to eliminate
   the failure solutions such as local solution or the divergence of
   algorithm. Third, the SLAM position velocity acceleration (PVA) model is
   used to deal with the high dynamic movement. Finally, an integrity
   assessment benefits the central fusion filter to avoid failure
   measurements into the update process based on the information from
   INS-aiding SLAM, which increases the reliability and accuracy.
   Consequently, our proposed multisensor design can deal with various
   situations such as long-term GNSS outage, deep urban areas, and
   highways. The results show that the proposed method can achieve an
   accuracy of under 1 meter in challenging scenarios, which has the
   potential to contribute the autonomous system.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Tsai, GJ (Corresponding Author), Natl Cheng Kung Univ, Dept Geomat Engn, 1 Daxue Rd, Tainan 701, Taiwan.
   Chiang, Kai-Wei; Tsai, Guang-Je; Li, Yu-Hua, Natl Cheng Kung Univ, Dept Geomat Engn, 1 Daxue Rd, Tainan 701, Taiwan.
   Li, You; El-Sheimy, Naser, Univ Calgary, Dept Geomat Engn, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada.},
DOI = {10.3390/rs12101564},
Article-Number = {1564},
EISSN = {2072-4292},
Keywords = {inertial navigation system and global navigation satellite system (INS;
   GNSS); light detection and ranging (LiDAR); simultaneous localization
   and mapping (SLAM)},
Keywords-Plus = {LAND-VEHICLE NAVIGATION; INTEGRATION; LOCALIZATION; SYSTEM; RADAR},
Research-Areas = {Environmental Sciences \& Ecology; Geology; Remote Sensing; Imaging
   Science \& Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {kwchiang@mail.ncku.edu.tw
   p68031050@ncku.edu.tw
   p68001013@ncku.edu.tw
   li29@ucalgary.ca
   elsheimy@ucalgary.ca},
Affiliations = {National Cheng Kung University; University of Calgary},
ORCID-Numbers = {Li, You/0000-0003-3785-0976},
Funding-Acknowledgement = {Ministry of Science and Technology {[}107-2221-E-006-125-MY3,
   108-2917-I-006-005]},
Funding-Text = {This research was funded by Ministry of Science and Technology, grant
   number 107-2221-E-006-125-MY3 and 108-2917-I-006-005.},
Cited-References = {Aggarwal P, 2010, ARTECH HSE GNSS TECH, P1.
   Brown R.G., 1992, INTRO RANDOM SIGNALS, V3.
   Chen C, 2018, IEEE INTERNET THINGS, V5, P1575, DOI 10.1109/JIOT.2017.2788848.
   Chiang KW, 2019, INFORM FUSION, V50, P181, DOI 10.1016/j.inffus.2019.01.004.
   Chiang KW, 2020, IEEE T VEH TECHNOL, V69, P2463, DOI 10.1109/TVT.2020.2966765.
   Chiang KW, 2020, IEEE SENS J, V20, P3057, DOI 10.1109/JSEN.2019.2954532.
   Cornick M, 2016, J FIELD ROBOT, V33, P82, DOI 10.1002/rob.21605.
   Cvisic I, 2018, J FIELD ROBOT, V35, P578, DOI 10.1002/rob.21762.
   Farrell J.A., 2008, AIDED NAVIGATION GPS.
   Gakne PV, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041244.
   Gao JC, 2008, J INTELL TRANSPORT S, V12, P159, DOI 10.1080/15472450802448138.
   Gebre-Egziabher D., 2009, GNSS APPL METHODS.
   GmbH, IN RQH 0018.
   Groves P.D., 2013, P 26 INT TECHN M SAT.
   GROVES PD, 2013, INSIDE GNSS MAG, V8, P40.
   Handte M, 2016, IEEE INTERNET THINGS, V3, P735, DOI 10.1109/JIOT.2016.2554146.
   Hartley R., 2003, MULTIPLE VIEW GEOMET.
   Hata AY, 2016, IEEE T INTELL TRANSP, V17, P420, DOI 10.1109/TITS.2015.2477817.
   Hening S., 2017, PROC AIAA INF SYST A, P0448.
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331.
   Julier SJ, 2003, IEEE T ROBOTIC AUTOM, V19, P1, DOI 10.1109/TRA.2002.805661.
   Kuutti S, 2018, IEEE INTERNET THINGS, V5, P829, DOI 10.1109/JIOT.2018.2812300.
   Liu H, 2010, IEEE T VEH TECHNOL, V59, P4256, DOI 10.1109/TVT.2010.2070850.
   Lu N, 2014, IEEE INTERNET THINGS, V1, P289, DOI 10.1109/JIOT.2014.2327587.
   Luo X., 2013, GPS STOCHASTIC MODEL.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Qian C, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010003.
   Shin E. H., 2005, THESIS.
   Song X, 2016, INFORM FUSION, V31, P76, DOI 10.1016/j.inffus.2016.01.003.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Stivers T, 2007, LANG CULT COGN, P1.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Tang YG, 2009, IEEE T VEH TECHNOL, V58, P1129, DOI 10.1109/TVT.2008.926213.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Vagle N, 2018, IEEE INTERNET THINGS, V5, P4816, DOI 10.1109/JIOT.2018.2822264.
   Vivet D, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56636.
   Ward E, 2016, IEEE INT VEH SYM, P864, DOI 10.1109/IVS.2016.7535489.
   Wu ZW, 2013, IEEE T INTELL TRANSP, V14, P553, DOI 10.1109/TITS.2012.2224343.
   Yang Y. F., 2008, THESIS.
   Yen SW, 2016, GPS SOLUT, V20, P885, DOI 10.1007/s10291-015-0497-6.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.
   Zhuang Y, 2018, IEEE INTERNET THINGS, V5, P4616, DOI 10.1109/JIOT.2017.2785338.},
Number-of-Cited-References = {42},
Times-Cited = {13},
Usage-Count-Last-180-days = {18},
Usage-Count-Since-2013 = {34},
Journal-ISO = {Remote Sens.},
Doc-Delivery-Number = {MC6LB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000543394800031},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000681331402130,
Author = {Tsamis, Georgios and Kostavelis, Ioannis and Giakoumis, Dimitrios and
   Tzovaras, Dimitrios},
Book-Group-Author = {IEEE COMP SOC},
Title = {Towards life-long mapping of dynamic environments using temporal
   persistence modeling},
Booktitle = {2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)},
Series = {International Conference on Pattern Recognition},
Year = {2021},
Pages = {10480-10485},
Note = {25th International Conference on Pattern Recognition (ICPR), ELECTR
   NETWORK, JAN 10-15, 2021},
Abstract = {The contemporary SLAM mapping systems assume a static environment and
   build a map that is then used for mobile robot navigation disregarding
   the dynamic changes in this environment. The paper at hand presents a
   novel solution for the problem of life-long mapping that continually
   updates a metric map represented as a 2D occupancy grid in large scale
   indoor environments with movable objects such as people, robots, objects
   etc. suitable for industrial applications. We formalize each cell's
   occupancy as a failure analysis problem and contribute temporal
   persistence modeling (TPM), an algorithm for probabilistic prediction of
   the time that a cell in an observed location is expected to be
   ``occupied{''} or ``empty{''} given sparse prior observations from a
   task specific mobile robot. Our work is evaluated in Gazebo simulation
   environment against the nominal occupancy of cells and the estimated
   obstacles persistence. We also show that robot navigation with life-long
   mapping demands less replans and leads to more efficient navigation in
   highly dynamic environments.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Tsamis, G (Corresponding Author), Informat Technol Inst CERTH ITI, Ctr Res \& Technol Hellas, 6th Km Charilaou Thermi Rd, Thessaloniki 57100, Greece.
   Tsamis, Georgios; Kostavelis, Ioannis; Giakoumis, Dimitrios; Tzovaras, Dimitrios, Informat Technol Inst CERTH ITI, Ctr Res \& Technol Hellas, 6th Km Charilaou Thermi Rd, Thessaloniki 57100, Greece.},
DOI = {10.1109/ICPR48806.2021.9413161},
ISSN = {1051-4651},
ISBN = {978-1-7281-8808-9},
Keywords-Plus = {SLAM},
Research-Areas = {Computer Science; Engineering; Imaging Science \& Photographic
   Technology},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Imaging Science \& Photographic Technology},
Author-Email = {gtsamis@iti.gr
   gkostave@iti.gr
   dgiakoum@iti.gr
   dimitrios.tzovaras@iti.gr},
Affiliations = {Centre for Research \& Technology Hellas},
ResearcherID-Numbers = {Tzovaras, Dimitrios/ABB-9576-2021
   },
ORCID-Numbers = {Tzovaras, Dimitrios/0000-0001-6915-6722
   Giakoumis, Dimitrios/0000-0003-1844-186X},
Funding-Acknowledgement = {EU {[}820742]},
Funding-Text = {This work has been supported by the EU Horizon 2020 funded project
   ``Hybrid Human-Robot RECycling plant for electriCal and eLEctRonic
   Equipment (HR-RECYCLER){''} under the grant agreement with no: 820742.},
Cited-References = {Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Dymczyk M., 2016, RSS WORKSH.
   Einhorn E, 2015, ROBOT AUTON SYST, V69, P28, DOI 10.1016/j.robot.2014.08.008.
   Hahnel D, 2003, ADV ROBOTICS, V17, P579, DOI 10.1163/156855303769156965.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kostavelis I, 2016, ENG APPL ARTIF INTEL, V48, P173, DOI 10.1016/j.engappai.2015.11.004.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Li SL, 2017, IEEE ROBOT AUTOM LET, V2, P2263, DOI 10.1109/LRA.2017.2724759.
   Montiel J.M.M., 2017, 2017 EUR C MOB ROB E, P1.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Rausand M., 2003, SYSTEM RELIABILITY T, V396.
   Rojas-Fernandez M, 2018, INT CONF ELECTR COMM, P50, DOI 10.1109/CONIELECOMP.2018.8327175.
   Santos JM, 2016, IEEE ROBOT AUTOM LET, V1, P684, DOI 10.1109/LRA.2016.2516594.
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781.
   Thrun S., 2002, EXPLOR ARTIF INTELL, V1-35, P1.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Wolf DF, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P594.},
Number-of-Cited-References = {18},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BS0DY},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000681331402130},
DA = {2022-05-17},
}

@article{ WOS:000709062700001,
Author = {Aitken, Jonathan M. and Evans, Mathew H. and Worley, Rob and Edwards, S.
   and Zhang, Rui and Dodd, Tony and Mihaylova, Lyudmila and Anderson, Sean
   R.},
Title = {Simultaneous Localization and Mapping for Inspection Robots in Water and
   Sewer Pipe Networks: A Review},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {140173-140198},
Abstract = {At the present time, water and sewer pipe networks are predominantly
   inspected manually. In the near future, smart cities will perform
   intelligent autonomous monitoring of buried pipe networks, using teams
   of small robots. These robots, equipped with all necessary computational
   facilities and sensors (optical, acoustic, inertial, thermal, pressure
   and others) will be able to inspect pipes whilst navigating,
   self-localising and communicating information about the pipe condition
   and faults such as leaks or blockages to human operators for monitoring
   and decision support. The predominantly manual inspection of pipe
   networks will be replaced with teams of autonomous inspection robots
   that can operate for long periods of time over a large spatial scale.
   Reliable autonomous navigation and reporting of faults at this scale
   requires effective localization and mapping, which is the estimation of
   the robot's position and its surrounding environment. This survey
   presents an overview of state-of-the-art works on robot simultaneous
   localization and mapping (SLAM) with a focus on water and sewer pipe
   networks. It considers various aspects of the SLAM problem in pipes,
   from the motivation, to the water industry requirements, modern SLAM
   methods, map-types and sensors suited to pipes. Future challenges such
   as robustness for long term robot operation in pipes are discussed,
   including how making use of prior knowledge, e.g. geographic information
   systems (GIS) can be used to build map estimates, and improve
   multi-robot SLAM in the pipe environment.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Review},
Language = {English},
Affiliation = {Anderson, SR (Corresponding Author), Univ Sheffield, Dept Automat Control \& Syst Engn, Sheffield S1 3JD, S Yorkshire, England.
   Aitken, Jonathan M.; Evans, Mathew H.; Worley, Rob; Edwards, S.; Zhang, Rui; Mihaylova, Lyudmila; Anderson, Sean R., Univ Sheffield, Dept Automat Control \& Syst Engn, Sheffield S1 3JD, S Yorkshire, England.
   Dodd, Tony, Staffordshire Univ, Sch Digital Technol \& Arts, Stoke On Trent ST4 2DE, Staffs, England.},
DOI = {10.1109/ACCESS.2021.3115981},
ISSN = {2169-3536},
Keywords = {Simultaneous localization and mapping; Robots; Sensors; Inspection;
   Service robots; Water resources; Location awareness; Water; sewer;
   network; pipe networks; robots; SLAM; data fusion; Bayesian estimation;
   visual odometry; laser and lidar scanning},
Keywords-Plus = {GROUND-PENETRATING RADAR; TOPOLOGICAL SIMULTANEOUS LOCALIZATION;
   FEATURE-BASED SLAM; LARGE-SCALE; KALMAN FILTER; DATA ASSOCIATION; PLACE
   RECOGNITION; MONOCULAR SLAM; MOBILE ROBOTS; RANGE DATA},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {s.anderson@sheffield.ac.uk},
Affiliations = {University of Sheffield; Staffordshire University},
ResearcherID-Numbers = {Mihaylova, L/A-3512-2008
   Aitken, Jonathan/B-8599-2016
   },
ORCID-Numbers = {Mihaylova, L/0000-0001-5856-2223
   Anderson, Sean/0000-0002-7452-5681
   Aitken, Jonathan/0000-0003-4204-4020
   Worley, Rob/0000-0002-3607-2650},
Funding-Acknowledgement = {Engineering and Physical Sciences Research Council (EPSRC), U.K. through
   the Pervasive Sensing for Buried Pipes (Pipebots) Project
   {[}EP/S016813/1]},
Funding-Text = {This work was supported by the Engineering and Physical Sciences
   Research Council (EPSRC), U.K., support through the Pervasive Sensing
   for Buried Pipes (Pipebots) Project under Grant EP/S016813/1.},
Cited-References = {Abu Bakr M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112472.
   Adria O., 2004, INT J ADV ROBOTIC SY, V1, P4.
   Agarwal P, 2013, IEEE INT CONF ROBOT, P62, DOI 10.1109/ICRA.2013.6630557.
   Ahrary A, 2006, PROCEEDINGS OF THE 2006 IEEE/SMC INTERNATIONAL CONFERENCE ON SYSTEM OF SYSTEMS ENGINEERING, P291.
   Ahrary A, 2006, IEEE INT C NETW SENS, P78.
   Al-Masri WMF, 2020, IEEE T CONTR SYST T, V28, P609, DOI 10.1109/TCST.2018.2879628.
   Alejo D, 2017, IEEE INT C INT ROBOT, P4070, DOI 10.1109/IROS.2017.8206263.
   Alejo D, 2021, J FIELD ROBOT, V38, P105, DOI 10.1002/rob.21976.
   Alejo D, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224946.
   Almalioglu Y, 2019, IEEE INT CONF ROBOT, P5474, DOI 10.1109/ICRA.2019.8793512.
   American Society of Civil Engineers, 2002, STAND GUID COLL DEP.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4\_39.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Bando Y, 2016, IEEE INT SYMP SAFE, P207, DOI 10.1109/SSRR.2016.7784300.
   Bar-Shalom Y., 2001, ESTIMATION APPL TRAC, P199.
   Bar-Shalom Y, 2009, IEEE CONTR SYST MAG, V29, P82, DOI 10.1109/MCS.2009.934469.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Behley J, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Bilal M, 2018, J APPL GEOPHYS, V150, P52, DOI 10.1016/j.jappgeo.2018.01.006.
   Blanco JL, 2007, IEEE INT CONF ROBOT, P2061, DOI 10.1109/ROBOT.2007.363625.
   Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389.
   Boal J, 2014, ROBOTICA, V32, P803, DOI 10.1017/S0263574713001070.
   Borrmann D, 2008, ROBOT AUTON SYST, V56, P130, DOI 10.1016/j.robot.2007.07.002.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203.
   Burgard W, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P730, DOI 10.1109/IROS.1998.727279.
   Butler D., 2018, URBAN DRAINAGE, DOI 10.1201/.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Cai J., 2020, J COMPUT CIVIL ENG, V34.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Cameron D, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106561.
   Carlone L, 2014, J INTELL ROBOT SYST, V75, P291, DOI 10.1007/s10846-013-9981-9.
   Carrillo H, 2012, IEEE INT CONF ROBOT, P2080, DOI 10.1109/ICRA.2012.6224890.
   Cassandra AR, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P963, DOI 10.1109/IROS.1996.571080.
   Castanedo F, 2013, SCI WORLD J, DOI 10.1155/2013/704504.
   Castellanos JA, 2004, IFAC P VOLUMES, V37, P716, DOI DOI 10.1016/S1474-6670(17)32063-3.
   Chahinian N, 2019, COMPUT ENVIRON URBAN, V78, DOI 10.1016/j.compenvurbsys.2019.101370.
   Chebrolu N, 2021, IEEE ROBOT AUTOM LET, V6, P2240, DOI 10.1109/LRA.2021.3061331.
   Chen H., 2011, P 22 INT JOINT C ART, P2411.
   Chen QJ, 2019, IEEE ACCESS, V7, P104453, DOI 10.1109/ACCESS.2019.2931748.
   Choi YH, 2008, AUTON ROBOT, V24, P13, DOI 10.1007/s10514-007-9050-y.
   Choi YS, 2017, INTEL SERV ROBOT, V10, P213, DOI 10.1007/s11370-017-0221-1.
   Choset H, 2001, IEEE T ROBOTIC AUTOM, V17, P125, DOI 10.1109/70.928558.
   Chou C, 2021, IEEE T ROBOT, V37, P67, DOI 10.1109/TRO.2020.3010640.
   Chowdhury MS, 2016, ASCE-ASME J RISK UNC, V2, DOI 10.1115/1.4030945.
   Chuang TY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12060968.
   Cieslewski T, 2018, IEEE INT CONF ROBOT, P2466.
   Clark R, 2017, THIRTY-FIRST AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3995.
   Cole DM, 2006, IEEE INT CONF ROBOT, P1556, DOI 10.1109/ROBOT.2006.1641929.
   Commandre B, 2017, INT ARCH PHOTOGRAMM, V42-1, P333, DOI 10.5194/isprs-archives-XLII-1-W1-333-2017.
   Commandre B., 2017, P INT C URB DRAIN, P2345.
   Murtra AC, 2013, IEEE INT CONF TECH.
   Costante G, 2018, IEEE ROBOT AUTOM LET, V3, P1735, DOI 10.1109/LRA.2018.2803211.
   Costello SB, 2007, TUNN UNDERGR SP TECH, V22, P524, DOI 10.1016/j.tust.2007.06.001.
   Cox I. J., 1991, 91 ICAR. Fifth International Conference on Advanced Robotics. Robots in Unstructured Environments (Cat. No.91TH0376-4), P1287, DOI 10.1109/ICAR.1991.240377.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Cunningham A, 2013, IEEE INT CONF ROBOT, P5220, DOI 10.1109/ICRA.2013.6631323.
   Cunningham A, 2012, IEEE INT CONF ROBOT, P1093, DOI 10.1109/ICRA.2012.6225356.
   Daniels D. J., 2004, GROUND PENETRATING R, V2nd.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Davison AJ, 2001, PROC CVPR IEEE, P384.
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   de Vitry MM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050706.
   Debenest P., 2014, P 3 INT C APPL ROB P, P1, DOI DOI 10.1109/CARPI.2014.7030052.
   Debeunne C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072068.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Delmerico J, 2018, IEEE INT CONF ROBOT, P2502.
   Devitt SK, 2018, STUD SYST DECIS CONT, V117, P161, DOI 10.1007/978-3-319-64816-3\_9.
   Diosi A, 2007, INT J ROBOT RES, V26, P1125, DOI 10.1177/0278364907082042.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Dou QX, 2017, IEEE T GEOSCI REMOTE, V55, P51, DOI 10.1109/TGRS.2016.2592679.
   Dou QX, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111827.
   Droeschel D, 2018, IEEE INT CONF ROBOT, P5000, DOI 10.1109/ICRA.2018.8461000.
   Duisterwinkel EHA, 2018, IEEE T INSTRUM MEAS, V67, P655, DOI 10.1109/TIM.2017.2775404.
   Duran O, 2002, IEEE SENS J, V2, P73, DOI 10.1109/JSEN.2002.1000245.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Edwards S., TOWARDS AUTONOMOUS R, P2021.
   El Kahi S., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2605, DOI 10.1109/ROBIO.2011.6181697.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Eliazar A., 2003, P 18 INT JOINT C ART, P1135.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Esquivel S, 2009, LECT NOTES COMPUT SC, V5748, P332.
   Feder HJS, 1999, INT J ROBOT RES, V18, P650, DOI 10.1177/02783649922066484.
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167.
   Fisher M., 2020, ARXIV200109124.
   Forster C, 2013, IEEE INT C INT ROBOT, P3963.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Garulli A, 2005, IEEE DECIS CONTR P, P2041.
   Georgiou C, 2017, INT J ROBOT RES, V36, P274, DOI 10.1177/0278364916687027.
   Goldberg SB, 2002, AEROSP CONF PROC, P2025.
   Gong YZ, 2015, INT J OPTOMECHATRONI, V9, P238, DOI 10.1080/15599612.2015.1059535.
   Granstrom K, 2011, INT J ROBOT RES, V30, P1728, DOI 10.1177/0278364911405086.
   Granstrom K, 2009, IEEE INT CONF ROBOT, P1990.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2020, ROBOTICS, V9, DOI 10.3390/robotics9030051.
   Guan LW, 2019, INT C COMM SIG PROC.
   Hanna P. L., 1991, KINEMATIC SYSTEMS GE, P140.
   Hansen P, 2015, INT J ROBOT RES, V34, P532, DOI 10.1177/0278364914550133.
   Hansen P, 2013, IEEE INT C INT ROBOT, P5180, DOI 10.1109/IROS.2013.6697105.
   Hansen P, 2011, IEEE INT C INT ROBOT, P4020, DOI 10.1109/IROS.2011.6048579.
   Hansen P, 2011, IEEE INT CONF ROBOT.
   Harris C. G., 1988, ALVEY VISION C, P1, DOI DOI 10.5244/C.2.23.
   Hausler S, 2019, IEEE ROBOT AUTOM LET, V4, P1924, DOI 10.1109/LRA.2019.2898427.
   He HM, 2020, 2020 THE 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTICS AND CONTROL ENGINEERING (IRCE 2020), P68, DOI 10.1109/IRCE50905.2020.9199244.
   Hertzberg J., 1996, Proceedings of the First Euromicro Workshop on Advanced Mobile Robots (EUROBOT `96), P68, DOI 10.1109/EURBOT.1996.551883.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Himstedt M, 2014, IEEE INT C INT ROBOT, P5030, DOI 10.1109/IROS.2014.6943277.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Howard A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3946, DOI 10.1109/IROS.2008.4651147.
   Howard A, 2006, INT J ROBOT RES, V25, P1243, DOI 10.1177/0278364906072250.
   Hsiao M, 2019, IEEE INT CONF ROBOT, P1274, DOI 10.1109/ICRA.2019.8793854.
   Huang GQ, 2014, IEEE INT CONF ROBOT, P4926, DOI 10.1109/ICRA.2014.6907581.
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811.
   Huang SD, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416669482.
   Jensfelt P., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2531, DOI 10.1109/ROBOT.2000.846409.
   Ji W., 2018, P 24 INT C AUT COMP, P1.
   Jia GY, 2018, IEEE INTERNET THINGS, V5, P1648, DOI 10.1109/JIOT.2017.2786349.
   Julier SJ, 2001, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ROBOT.2001.933280.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kagami S, 2020, PROC IEEE INT SYMP, P1345, DOI 10.1109/ISIE45063.2020.9152377.
   Kampffmeyer M, 2016, IEEE COMPUT SOC CONF, P680, DOI 10.1109/CVPRW.2016.90.
   Ke Ma, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2548, DOI 10.1109/ICRA.2017.7989296.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Kim JH, 2015, EURASIP J WIREL COMM, P1, DOI 10.1186/s13638-015-0495-y.
   Kim SH, 2018, IEEE SENS J, V18, P2585, DOI 10.1109/JSEN.2018.2795043.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Konda Kishore, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P486.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   KORTENKAMP D, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P979.
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006.
   Krylov VA, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050661.
   Krys Dennis, 2007, IEEE International Symposium on Computational Intelligence in Robotics and Automation, 2007, P344.
   Kuipers B, 2004, IEEE INT CONF ROBOT, P4845, DOI 10.1109/ROBOT.2004.1302485.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Kunzel J, 2018, IEEE WINT CONF APPL, P2019, DOI 10.1109/WACV.2018.00223.
   Lai WWL, 2018, NDT\&E INT, V96, P58, DOI 10.1016/j.ndteint.2017.04.002.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Lee DH, 2016, ROBOTICA, V34, P601, DOI 10.1017/S0263574714001726.
   Lee DH, 2013, INT J CONTROL AUTOM, V11, P127, DOI 10.1007/s12555-012-0049-6.
   Lee DH, 2011, IEEE INT CONF ROBOT, P1559.
   Lee DH, 2010, INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010), P611.
   Lee JS, 2009, IEEE INT CONF ROBOT, P3441.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147.
   Leung C, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5026, DOI 10.1109/IROS.2006.282530.
   Li HF, 2020, IEEE T AUTOM SCI ENG, V17, P722, DOI 10.1109/TASE.2019.2941848.
   Li HF, 2018, IEEE INT C INT ROBOT, P3145, DOI 10.1109/IROS.2018.8594006.
   Li RH, 2018, IEEE INT CONF ROBOT, P7286, DOI 10.1109/ICRA.2018.8461251.
   Li S, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000443.
   Lianwu Guan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1227, DOI 10.1109/ICMA.2018.8484439.
   Liu W, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8010049.
   Liu Z, 2013, MEASUREMENT, V46, P1, DOI 10.1016/j.measurement.2012.05.032.
   Liu Z, 2012, MECH SYST SIGNAL PR, V31, P246, DOI 10.1016/j.ymssp.2012.03.006.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Ma K, 2017, IEEE ASME INT C ADV, P1459, DOI 10.1109/AIM.2017.8014224.
   Ma K, 2015, LECT NOTES ARTIF INT, V9287, P161, DOI 10.1007/978-3-319-22416-9\_19.
   Mangelson JG, 2018, IEEE INT CONF ROBOT, P2916.
   Martin F, 2014, ROBOTICA, V32, P19, DOI 10.1017/S026357471300060X.
   Metje N, 2011, SENSORS-BASEL, V11, P7455, DOI 10.3390/s110807455.
   Milford M., 2014, 2014 IFIP NETW C, P1.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mills GH, 2017, ROBOTICS, V6, DOI 10.3390/robotics6040036.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Montemerlo M., 2003, P 18 INT JOINT C ART, P1151.
   Moravec H. P., 1989, SENSOR DEVICES SYSTE, P253, DOI {[}10.1007/978-3-642-74567-6\_19.-Text, DOI 10.1007/978-3-642-74567-6\_19].
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Muller P, 2017, IEEE WINT CONF APPL, P624, DOI 10.1109/WACV.2017.75.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer T, 2018, IEEE T ROBOT, V34, P289, DOI 10.1109/TRO.2017.2788045.
   Nassiraei AAF, 2006, IEEE IND ELEC, P3247.
   Natarajan R, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1137, DOI 10.23919/ICIF.2018.8455502.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Nettleton EW, 2000, P SOC PHOTO-OPT INS, V4051, P428, DOI 10.1117/12.381658.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Nguyen V, 2007, AUTON ROBOT, V23, P97, DOI 10.1007/s10514-007-9034-y.
   NOURBAKHSH I, 1995, AI MAG, V16, P53.
   Nuchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209.
   Nuchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001.
   Olson E, 2013, INT J ROBOT RES, V32, P826, DOI 10.1177/0278364913479413.
   Parrott C, 2020, TUNN UNDERGR SP TECH, V101, DOI 10.1016/j.tust.2020.103356.
   Payeur P, 1997, IEEE INT CONF ROBOT, P1289, DOI 10.1109/ROBOT.1997.614315.
   Pedraza L., 2007, ROBOTICS SCI SYSTEMS, V29, P1.
   Pedraza L, 2009, IEEE T ROBOT, V25, P353, DOI 10.1109/TRO.2009.2013496.
   PETERS L, 1994, P IEEE, V82, P1802, DOI 10.1109/5.338072.
   Pfister H, 2000, COMP GRAPH, P335.
   Plati C, 2015, SPR TRANS CIV ENV EN, P125, DOI 10.1007/978-3-319-04813-0\_5.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Riazuelo L, 2014, ROBOT AUTON SYST, V62, P401, DOI 10.1016/j.robot.2013.11.007.
   Rizzo C, 2021, ROBOT AUTON SYST, V136, DOI 10.1016/j.robot.2020.103702.
   Rizzo P, 2010, ADV CIV ENG, V2010, DOI 10.1155/2010/818597.
   Roh SG, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1724, DOI 10.1109/IROS.2008.4650968.
   Rome E., 1999, URBAN WATER, V1, P57.
   Rome E., 2001, P INT S INT ROB SYST, P457.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Ryde J, 2010, AUTON ROBOT, V28, P169, DOI 10.1007/s10514-009-9158-3.
   Sachedina K, 2018, PIPELINE SCI TECHNOL, V2, P187.
   Saeedi S., 2015, J FIELD ROBOT, V7, P81.
   Sahli H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040567.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Sanfourche M, 2013, IEEE INT C INT ROBOT, P2107, DOI 10.1109/IROS.2013.6696651.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Schempf H, 2010, J FIELD ROBOT, V27, P217, DOI 10.1002/rob.20330.
   Schmuck P, 2016, IFAC PAPERSONLINE, V49, P230, DOI 10.1016/j.ifacol.2016.07.738.
   Seco T, 2016, IEEE INT CONF AUTON, P28, DOI 10.1109/ICARSC.2016.22.
   Seth I, 2013, GEOSPATIAL TOOLS URB.
   Shahrdar Shervin, 2018, P SCI INF C, P368.
   Shamsi U. M, 2002, GIS TOOLS WATER WAST.
   Shin EH, 2005, J NAVIGATION, V58, P283, DOI 10.1017/S037346330500319X.
   Siam Sayem Mohammad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5702, DOI 10.1109/ICRA.2017.7989671.
   Simmons R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1080.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Steder B, 2010, IEEE INT CONF ROBOT, P1400, DOI 10.1109/ROBOT.2010.5509401.
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636.
   Strelow D, 2004, INT J ROBOT RES, V23, P1157, DOI 10.1177/0278364904045593.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2012, IEEE INT C INT ROBOT, P1879, DOI 10.1109/IROS.2012.6385590.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Tang N, 2003, 2003 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, VOLS. 1 \& 2, P1552.
   Teixeira B, 2020, IEEE ACCESS, V8, P44687, DOI 10.1109/ACCESS.2020.2978406.
   Thielemann Jens T, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563167.
   Thrun S, 2005, SPRINGER TRAC ADV RO, V15, P254.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Timofte R., 2011, P IEEE INT C COMP VI, DOI 10.1109/ICCVW.2011.6130242.
   Toreini E, 2020, FAT{*} `20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P272, DOI 10.1145/3351095.3372834.
   Tsihrintzis VA, 1996, WATER RESOUR MANAG, V10, P251, DOI 10.1007/BF00508896.
   Tur JMM, 2010, J FIELD ROBOT, V27, P491, DOI 10.1002/rob.20347.
   Twort A. C., 2009, WATER SUPPLY, V6th.
   Valencia R, 2013, IEEE T ROBOT, V29, P1050, DOI 10.1109/TRO.2013.2257577.
   Stumberg L, 2018, IEEE INT CONF ROBOT, P2510, DOI 10.1109/ICRA.2018.8462905.
   Vreeburg JHG, 2007, WATER RES, V41, P519, DOI 10.1016/j.watres.2006.09.028.
   Waltz E., 2017, HDB MULTISENSOR DATA, V2nd, DOI {[}10.1201/9781420053098, DOI 10.1201/9781420053098].
   Wang DZ, 2015, INT J ROBOT RES, V34, P1039, DOI 10.1177/0278364914562237.
   Wang JK, 2018, IEEE INT C INT ROBOT, P3537, DOI 10.1109/IROS.2018.8593753.
   Wang S, 2018, INT J ROBOT RES, V37, P513, DOI 10.1177/0278364917734298.
   Wang S, 2017, INT CONF ACOUST SPEE, P436, DOI 10.1109/ICASSP.2017.7952193.
   Wei ZY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102422.
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Wirahadikusumah R., 1998, Automation in Construction, V7, P259, DOI 10.1016/S0926-5805(97)00071-X.
   Worley Rob, 2021, 2021 European Conference on Mobile Robots (ECMR), DOI 10.1109/ECMR50962.2021.9568829.
   Worley Rob, 2020, Towards Autonomous Robotic Systems. 21st Annual Conference, TAROS 2020. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNCS 12228), P77, DOI 10.1007/978-3-030-63486-5\_11.
   Worley Rob, 2020, 2020 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI), P160, DOI 10.1109/MFI49285.2020.9235225.
   Worley R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195584.
   Wu DL, 2016, IEEE T IND INFORM, V12, P809, DOI 10.1109/TII.2015.2469636.
   Wu Y, 2019, P AMER CONTR CONF, P3180.
   Yang Y, 2020, IEEE SENS J, V20, P6331, DOI 10.1109/JSEN.2020.2976579.
   Yatim NM, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS AND SYSTEM ENGINEERING (ICEESE), P77, DOI 10.1109/ICEESE.2014.7154599.
   Yin H, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), P481, DOI 10.1109/ROBIO.2017.8324463.
   Yu YT, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2413812.
   Yu YT, 2014, IEEE GEOSCI REMOTE S, V11, P1549, DOI 10.1109/LGRS.2014.2301195.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.
   Zhang H, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881418780178.
   Zhang J., 2014, ROBOT SCI SYST, V2, P9.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.
   Zhang J, 2015, IEEE INT CONF ROBOT, P2174, DOI 10.1109/ICRA.2015.7139486.
   Zhang R., 2021, TOWARDS AUTONOMOUS R.
   Zhang XJ, 2019, WATER-SUI, V11, DOI 10.3390/w11102101.
   Zhang Y., 2011, J WSCG, V19, P49.
   Zhao C, 2018, IEEE INT C INT ROBOT, P6864, DOI 10.1109/IROS.2018.8594151.
   Zhou XR, 2019, IEEE T GEOSCI REMOTE, V57, P3967, DOI 10.1109/TGRS.2018.2889248.
   Zhou XS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1785, DOI 10.1109/IROS.2006.282219.},
Number-of-Cited-References = {278},
Times-Cited = {0},
Usage-Count-Last-180-days = {60},
Usage-Count-Since-2013 = {65},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {WJ5CN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000709062700001},
OA = {gold, Green Accepted},
DA = {2022-05-17},
}

@article{ WOS:000724215900001,
Author = {Hong, Sungchul and Bangunharcana, Antyanta and Park, Jae-Min and Choi,
   Minseong and Shin, Hyu-Soung},
Title = {Visual SLAM-Based Robotic Mapping Method for Planetary Construction},
Pages = {7715},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {22},
Month = {NOV},
Abstract = {With the recent discovery of water-ice and lava tubes on the Moon and
   Mars along with the development of in-situ resource utilization (ISRU)
   technology, the recent planetary exploration has focused on rover (or
   lander)-based surface missions toward the base construction for
   long-term human exploration and habitation. However, a 3D terrain map,
   mostly based on orbiters' terrain images, has insufficient resolutions
   for construction purposes. In this regard, this paper introduces the
   visual simultaneous localization and mapping (SLAM)-based robotic
   mapping method employing a stereo camera system on a rover. In the
   method, S-PTAM is utilized as a base framework, with which the disparity
   map from the self-supervised deep learning is combined to enhance the
   mapping capabilities under homogeneous and unstructured environments of
   planetary terrains. The overall performance of the proposed method was
   evaluated in the emulated planetary terrain and validated with potential
   results.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Hong, S (Corresponding Author), Inha Univ, Dept Geoinformat Engn, Incheon 22212, South Korea.
   Hong, Sungchul; Park, Jae-Min, Inha Univ, Dept Geoinformat Engn, Incheon 22212, South Korea.
   Bangunharcana, Antyanta; Choi, Minseong, Korea Adv Inst Sci \& Technol, Dept Mech Engn, Coll Engn, Daejeon 34141, South Korea.
   Park, Jae-Min; Shin, Hyu-Soung, Korea Inst Civil Engn \& Bldg Technol, Dept Future Technol \& Convergence Res, Goyang 10223, South Korea.},
DOI = {10.3390/s21227715},
Article-Number = {7715},
EISSN = {1424-8220},
Keywords = {planetary construction mapping; exploration rover; visual SLAM; deep
   learning; 3D terrain map},
Keywords-Plus = {SITU RESOURCE UTILIZATION; MOON; LOCALIZATION; MINERALOGY; WATER},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {schong@inha.ac.kr},
Affiliations = {Inha University; Korea Advanced Institute of Science \& Technology
   (KAIST); Korea Institute of Civil Engineering \& Building Technology
   (KICT)},
ORCID-Numbers = {Choi, Min Seong/0000-0002-5415-334X},
Funding-Acknowledgement = {research project ``Development of environmental simulator and advanced
   construction technologies over TRL6 in extreme conditions{''} - KICT},
Funding-Text = {This research was supported by the research project ``Development of
   environmental simulator and advanced construction technologies over TRL6
   in extreme conditions{''} funded by KICT.},
Cited-References = {Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13.
   Anand M, 2012, PLANET SPACE SCI, V74, P42, DOI 10.1016/j.pss.2012.08.012.
   Arney D.C., 2015, P AIAA SPAC 2015 C E, P4479.
   Arya AS, 2011, CURR SCI INDIA, V100, P524.
   Bajpai A, 2016, J FIELD ROBOT, V33, P229, DOI 10.1002/rob.21608.
   Bussey B., 2016, P 2016 IEEE AER C BI, P1, DOI 10.1109/AERO.2016.7500775.
   Cesaretti G, 2014, ACTA ASTRONAUT, V93, P430, DOI 10.1016/j.actaastro.2013.07.034.
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567.
   Di KC, 2019, GEOPHYS RES LETT, V46, P12764, DOI 10.1029/2019GL085252.
   Di KC, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081285.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Gasser M., 2018, P EUR PLAN SCI C BER.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Green R.D., 2019, P ACS NAT M EXP NASA.
   Hidalgo-Carrio J, 2018, J FIELD ROBOT, V35, P961, DOI 10.1002/rob.21790.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Hong Sungchul, 2020, {[}KSCE Journal of Civil and Environmental Engineering Research, 대한토목학회논문집(국문)], V40, P437, DOI 10.12652/Ksce.2020.40.4.0437.
   Ientile S., 2020, WIT T ENG SCI, V129, P197.
   International Space Exploration Cooperation Group (ISECG), 2020, GLOB EXPL MAP S.
   Jawin ER, 2019, EARTH SPACE SCI, V6, P2, DOI 10.1029/2018EA000490.
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17.
   Khoshnevis B, 2004, AUTOMAT CONSTR, V13, P5, DOI 10.1016/j.autcon.2003.08.012.
   Khoshnevis B, 2016, RAPID PROTOTYPING J, V22, P848, DOI 10.1108/RPJ-11-2015-0165.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Kuroda Y., 2003, P 7 INT S ART INT RO.
   Kwan C, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS \& MOBILE COMMUNICATION CONFERENCE (UEMCON), P566, DOI 10.1109/UEMCON.2018.8796542.
   Lee W.-B., 2011, CURR IND TECHNOL TRE, V9, P158.
   Li B, 2019, EARTH SPACE SCI, V6, P398, DOI 10.1029/2018EA000507.
   Loupos K, 2018, INT J INTELL ROBOT, V2, P43, DOI 10.1007/s41315-017-0031-9.
   Maki JN, 2020, SPACE SCI REV, V216, DOI 10.1007/s11214-020-00765-9.
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438.
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925.
   Merali R.S., 2012, P 2012 INT S ART INT.
   Mitrofanov IG, 2010, SCIENCE, V330, P483, DOI 10.1126/science.1185696.
   Naser MZ, 2019, PROG MATER SCI, V105, DOI 10.1016/j.pmatsci.2019.100577.
   Pajola M., 2019, PLANETARY CARTOGRAPH, P175.
   Peng M., 2018, INT ARCH PHOTOGRAMM, V42, P1369, DOI {[}10.5194/isprs-archives-XLII-3-1369-2018, DOI 10.5194/ISPRS-ARCHIVES-XLII-3-1369-2018].
   Pieters CM, 2009, CURR SCI INDIA, V96, P500.
   Pire T, 2017, ROBOT AUTON SYST, V93, P27, DOI 10.1016/j.robot.2017.03.019.
   Ralphs M, 2015, Life Sci Space Res (Amst), V7, P57, DOI 10.1016/j.lssr.2015.10.001.
   Romano M, 2021, PSYCHOTHER RES, V31, P224, DOI 10.1080/10503307.2020.1751892.
   Sanchez-Cuevas PJ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020305.
   Sanders GB, 2015, ADV SPACE RES, V55, P2381, DOI 10.1016/j.asr.2014.12.024.
   Sanders GB, 2011, ADV SPACE RES, V47, P20, DOI 10.1016/j.asr.2010.08.020.
   Schuster MJ, 2019, J INTELL ROBOT SYST, V93, P461, DOI 10.1007/s10846-017-0680-9.
   Seelos KD, 2014, GEOPHYS RES LETT, V41, P4880, DOI 10.1002/2014GL060310.
   Shaukat A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111952.
   Sherwood B, 2019, ACTA ASTRONAUT, V160, P116, DOI 10.1016/j.actaastro.2019.04.018.
   Spudis PD, 2013, J GEOPHYS RES-PLANET, V118, P2016, DOI 10.1002/jgre.20156.
   Thangavelautham J., 2017, ARXIV170107799.
   Tong CH, 2012, J FIELD ROBOT, V29, P381, DOI 10.1002/rob.21403.
   Tseng KK, 2021, ENTERP INF SYST-UK, V15, P1162, DOI 10.1080/17517575.2019.1698772.
   Wilson JT, 2018, ICARUS, V299, P148, DOI 10.1016/j.icarus.2017.07.028.
   Xiao L, 2015, SCIENCE, V347, P1226, DOI 10.1126/science.1259866.
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027.
   Zhong Y., 2017, SELF SUPERVISED LEAR.},
Number-of-Cited-References = {56},
Times-Cited = {1},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {5},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {XF6YT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000724215900001},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@article{ WOS:000722377800005,
Author = {Bresson, Guillaume and Alsayed, Zayed and Yu, Li and Glaser, Sebastien},
Title = {Simultaneous Localization and Mapping: A Survey of Current Trends in
   Autonomous Driving},
Journal = {IEEE TRANSACTIONS ON INTELLIGENT VEHICLES},
Year = {2017},
Volume = {2},
Number = {3},
Pages = {194-220},
Month = {SEP},
Abstract = {In this paper, we propose a survey of the Simultaneous Localization And
   Mapping (SLAM) field when considering the recent evolution of autonomous
   driving. The growing interest regarding self-driving cars has given new
   directions to localization and mapping techniques. In this survey, we
   give an overview of the different branches of SLAM before going into the
   details of specific trends that are of interest when considered with
   autonomous applications in mind. We first present the limits of
   classical approaches for autonomous driving and discuss the criteria
   that are essential for this kind of application. We then review the
   methods where the identified challenges are tackled. We mostly focus on
   approaches building and reusing long-term maps in various conditions
   (weather, season, etc.). We also go through the emerging domain of
   multivehicle SLAM and its link with self-driving cars. We survey the
   different paradigms of that field (centralized and distributed) and the
   existing solutions. Finally, we conclude by giving an overview of the
   various large-scale experiments that have been carried out until now and
   discuss the remaining challenges and future orientations.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Bresson, G (Corresponding Author), Inst VEDECOM, F-78000 Versailles, France.
   Bresson, Guillaume; Alsayed, Zayed; Yu, Li; Glaser, Sebastien, Inst VEDECOM, F-78000 Versailles, France.
   Alsayed, Zayed, Inria Paris Rocquencourt, F-75012 Paris, France.
   Yu, Li, Mines ParisTech, F-75006 Paris, France.
   Glaser, Sebastien, IFSTTAR, F-78000 Versailles, France.},
DOI = {10.1109/TIV.2017.2749181},
ISSN = {2379-8858},
EISSN = {2379-8904},
Keywords = {Autonomous vehicle; drift; localization; mapping; multi-vehicle; place
   recognition; SLAM; survey},
Research-Areas = {Computer Science; Engineering; Transportation},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Transportation Science \& Technology},
Author-Email = {guillaume.bresson@vedecom.fr
   zayed.alsayed@vedecom.fr
   li.yu@vedecom.fr
   sebastien.glaser@vedecom.fr},
Affiliations = {UDICE-French Research Universities; PSL Research University Paris; MINES
   ParisTech; Universite Gustave-Eiffel},
Cited-References = {Aeberhard M, 2015, IEEE INTEL TRANSP SY, V7, P42, DOI 10.1109/MITS.2014.2360306.
   Agarwal P, 2015, IEEE INT C INT ROBOT, P3111, DOI 10.1109/IROS.2015.7353807.
   Alsayed Z., 2015, P IEEE RSJ INT C INT, P13.
   Aragues R, 2010, IEEE INT CONF ROBOT, P3032, DOI 10.1109/ROBOT.2010.5509820.
   Aragues R., 2010, P ROB SCI SYST, P51.
   Arumugam R, 2010, IEEE INT CONF ROBOT, P3084, DOI 10.1109/ROBOT.2010.5509469.
   Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363.
   Baatz G, 2012, INT J COMPUT VISION, V96, P315, DOI 10.1007/s11263-011-0458-7.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615.
   BAILEY T, 2002, THESIS U SYDNEY SYDN.
   Bailey T, 2006, IEEE INT CONF ROBOT, P424, DOI 10.1109/ROBOT.2006.1641748.
   Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Bar-Shalom Y., 2001, ESTIMATION APPL TRAC.
   Bender P, 2014, IEEE INT VEH SYM, P420, DOI 10.1109/IVS.2014.6856487.
   Bernuy F, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P124, DOI 10.1109/ICCVW.2015.26.
   Bertozzi M, 2011, IEEE INT VEH SYM, P175, DOI 10.1109/IVS.2011.5940531.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Betaille D, 2010, IEEE T INTELL TRANSP, V11, P786, DOI 10.1109/TITS.2010.2050689.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Blanco JL, 2009, ROBOT AUTON SYST, V57, P64, DOI 10.1016/j.robot.2008.02.002.
   Blanco JL, 2009, AUTON ROBOT, V27, P327, DOI 10.1007/s10514-009-9138-7.
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326.
   Bojarski Mariusz, 2016, arXiv.
   Bonarini A., 2006, P IEEE RSJ INT C INT.
   Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   Brenner C, 2010, INT ARCH PHOTOGRAMM, V38, P139.
   Bresson G., 2015, ROBOT AUTON SYST, P128.
   Bresson G, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P859, DOI 10.1109/ITSC.2016.7795656.
   Bresson G, 2015, IEEE T INTELL TRANSP, V16, P1827, DOI 10.1109/TITS.2014.2376780.
   Broggi Alberto, 2014, 2014 IEEE Intelligent Vehicles Symposium Proceedings, P648, DOI 10.1109/IVS.2014.6856478.
   Broggi A, 2013, IEEE T INTELL TRANSP, V14, P1403, DOI 10.1109/TITS.2013.2262331.
   Buczko M, 2016, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2016.7535429.
   Buehler M, 2009, SPRINGER TRAC ADV RO, V56, P1, DOI 10.1007/978-3-642-03991-1.
   Burgard W, 2005, IEEE T ROBOT, V21, P376, DOI 10.1109/TRO.2004.839232.
   C. Project, 2016, CITYMOBIL2 EXP REC.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Castellanos JA, 2007, ROBOT AUTON SYST, V55, P21, DOI 10.1016/j.robot.2006.06.005.
   Castellanos JA, 2001, IEEE T ROBOTIC AUTOM, V17, P908, DOI 10.1109/70.976024.
   Castellanos JA, 2004, IFAC P VOLUMES, V37, P716, DOI DOI 10.1016/S1474-6670(17)32063-3.
   Chang HJ, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1473.
   Chatila R., 1985, POSITION REFERENCING, P138, DOI DOI 10.1109/ROBOT.1985.1087373.
   Chekhlov D, 2006, LECT NOTES COMPUT SC, V4292, P276.
   Chen ZH, 2007, ADV ROBOTICS, V21, P233, DOI 10.1163/156855307780132081.
   Chli M, 2009, IEEE INT CONF ROBOT, P2211.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Civera J, 2011, IEEE INT C INT ROBOT, P1277, DOI 10.1109/IROS.2011.6048293.
   Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345.
   Civera J, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3498, DOI 10.1109/IROS.2009.5354410.
   Clemente L.A., 2007, ROBOTICS SCI SYSTEMS, V2.
   Coast S., 2015, TESLA MAPS EXPLODING.
   Cole DM, 2006, IEEE INT CONF ROBOT, P1556, DOI 10.1109/ROBOT.2006.1641929.
   Comport A. I., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P700, DOI 10.1109/ICCVW.2011.6130316.
   Cremean LB, 2006, J FIELD ROBOT, V23, P777, DOI 10.1002/rob.20135.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Cunningham A, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P3025, DOI 10.1109/IROS.2010.5652875.
   Cunningham A, 2012, PROC SPIE, V8387, DOI 10.1117/12.919320.
   Cvisic I, 2015, 2015 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR).
   Czerwionka P., 2011, 2011 5th International Conference on Automation, Robotics and Applications (ICARA 2011), P78, DOI 10.1109/ICARA.2011.6144860.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Deaves RH, 2000, P SOC PHOTO-OPT INS, V4196, P360, DOI 10.1117/12.403747.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Delobel L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2371, DOI 10.1109/ROBIO.2015.7419693.
   Deusch H., 2014, P IEEE INT VEH S JUN, P555, DOI {[}10.1109/IVS.2014.6856413, DOI 10.1109/IVS.2014.6856413].
   DICKMANNS ED, 1990, IEEE T SYST MAN CYB, V20, P1273, DOI 10.1109/21.61200.
   Diosdado JV, 2007, OCEANS 2007 - EUROPE, VOLS 1-3, P1107.
   Dissanayake G., 2011, 2011 IEEE 6th International Conference on Industrial and Information Systems (ICIIS 2011), P477, DOI 10.1109/ICIINFS.2011.6038117.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Dissanayake MWMG, 2000, LECT NOTES CONTR INF, V250, P265.
   DMV, 2016, AUT VEH DIS REP 2016.
   DMV, 2015, AUT VEH DIS REP 2015.
   Doriya R., 2015, INT J ADV COMPUT SCI, V3, P40.
   Drummond, 2008, BRIT MACH VIS C, V13, P136.
   Dubbelman G, 2013, IEEE INT CONF ROBOT, P5190, DOI 10.1109/ICRA.2013.6631319.
   Durrant-Whyte H., 2000, BEGINNERS GUIDE DECE, P1.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eade E., 2006, P 16 C UNC ART INT S, V1, P469, DOI DOI 10.1109/CVPR.2006.263.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Eliazar A., 2003, P 18 INT JOINT C ART, P1135.
   Eliazar AI, 2004, IEEE INT CONF ROBOT, P1314, DOI 10.1109/ROBOT.2004.1308006.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   ERTRAC, 2015, AUT DRIV ROADM ERTRA.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   ETSI, 2011, 102863 ETSI TR.
   Eustice R., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3281.
   Fenwick JW, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1810, DOI 10.1109/ROBOT.2002.1014804.
   Feraud T., 2010, P 7 S INT AUT VEH, V7, P73.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Fox D., 2005, PROBABILISTIC ROBOTI, P279.
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810.
   Frese U, 2006, AUTON ROBOT, V20, P25, DOI 10.1007/s10514-006-5735-x.
   Frese U, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5032, DOI 10.1109/IROS.2006.282531.
   Fritz G, 2005, LECT NOTES COMPUT SC, V3540, P629.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Furgale P, 2013, IEEE INT VEH SYM, P809, DOI 10.1109/IVS.2013.6629566.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Geiger A, 2012, IEEE T INTELL TRANSP, V13, P1008, DOI 10.1109/TITS.2012.2189882.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Gil A, 2010, ROBOT AUTON SYST, V58, P68, DOI 10.1016/j.robot.2009.07.026.
   Goel P., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2302, DOI 10.1109/ROBOT.2000.846370.
   Grimmett H, 2015, IEEE INT CONF ROBOT, P2159, DOI 10.1109/ICRA.2015.7139484.
   Grisetti G, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3478.
   Grisetti G, 2010, IEEE INT CONF ROBOT, P273, DOI 10.1109/ROBOT.2010.5509407.
   Guivant J, 2000, J ROBOTIC SYST, V17, P565, DOI 10.1002/1097-4563(200010)17:10<565::AID-ROB4>3.0.CO;2-6.
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382.
   Guo CZ, 2016, IEEE T INTELL TRANSP, V17, P2355, DOI 10.1109/TITS.2016.2521819.
   Guo CZ, 2014, IEEE INT CONF ROBOT, P3975, DOI 10.1109/ICRA.2014.6907436.
   Gutmann J. S., 2010, ROBOTICS SCI SYSTEMS.
   Hahnel D, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P206.
   Hao Li, 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P267, DOI 10.1109/ICVES.2012.6294256.
   Hartley R, 2000, MULTIPLE VIEW GEOMET.
   Heung-Yeung Shum, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P538, DOI 10.1109/CVPR.1999.784733.
   Huang AS, 2010, INT J ROBOT RES, V29, P1595, DOI 10.1177/0278364910384295.
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811.
   Huang SD, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416669482.
   Indelman V, 2014, IEEE INT CONF ROBOT, P593, DOI 10.1109/ICRA.2014.6906915.
   Jabbari A, 2007, PROC WRLD ACAD SCI E, V22, P503.
   Jogan M, 2000, INT C PATT RECOG, P136, DOI 10.1109/ICPR.2000.902882.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Jose E., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3087, DOI 10.1109/IROS.2005.1545232.
   Joshi A, 2015, IEEE INTEL TRANSP SY, V7, P19, DOI 10.1109/MITS.2014.2364081.
   Julier S., 2001, GEN DECENTRALIZED DA.
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141.
   Julier SJ, 2001, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ROBOT.2001.933280.
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kalman R. E., 1961, J BASIC ENG, V83, P95, DOI {[}10.1115/1.3658902, DOI 10.1115/1.3658902].
   Kalman R. E., 1960, J FLUIDS ENG, V82, P34, DOI {[}https://doi.org/10.1115/1.3662552, DOI 10.1115/1.3662552].
   Kawewong A, 2011, INT J ROBOT RES, V30, P33, DOI 10.1177/0278364910371855.
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kummerle R, 2015, J FIELD ROBOT, V32, P565, DOI 10.1002/rob.21534.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Kunz F, 2015, IEEE INT VEH SYM, P666, DOI 10.1109/IVS.2015.7225761.
   Lategahn H., 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P1, DOI 10.1109/ICVES.2012.6294279.
   Lee HS, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P912, DOI 10.1109/IROS.2009.5354435.
   Lee KW, 2007, ROBOT AUTON SYST, V55, P527, DOI 10.1016/j.robot.2007.02.004.
   LEONARD J, 2003, P INT JOINT C ART IN, P1143.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   Leonard JJ, 2000, ROBOTICS RESEARCH, P169.
   Levinson J., 2007, ROBOTICS SCI SYSTEMS, V4, P1.
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li H, 2013, IEEE INTEL TRANSP SY, V5, P33, DOI 10.1109/MITS.2012.2232967.
   Li H, 2012, I C CONT AUTOMAT ROB, P632, DOI 10.1109/ICARCV.2012.6485231.
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208.
   Liu YF, 2003, IEEE INT CONF ROBOT, P1227.
   Lopez A. M., 2012, P 2012 IEEE INT VEH, V2, P1.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Luo RC, 2002, IEEE SENS J, V2, P107, DOI 10.1109/JSEN.2002.1000251.
   Mahon I, 2008, IEEE T ROBOT, V24, P1002, DOI 10.1109/TRO.2008.2004888.
   Majdik AL, 2013, IEEE INT C INT ROBOT, P3979, DOI 10.1109/IROS.2013.6696925.
   Martin A, 2010, I C CONT AUTOMAT ROB, P479, DOI 10.1109/ICARCV.2010.5707912.
   Martinelli A., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2917, DOI 10.1109/IROS.2005.1545003.
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006.
   Maybeck P.S., 1982, STOCHASTIC MODELS ES.
   McDonald J., 2011, P EUR C MOB ROB, P69.
   McLaughlin SP, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P229.
   Meilland M, 2011, IEEE INT C INT ROBOT, P4242, DOI 10.1109/IROS.2011.6048272.
   Menegatti E, 2004, ROBOT AUTON SYST, V47, P251, DOI 10.1016/j.robot.2004.03.014.
   Merriaux P, 2015, IEEE INT CONF ROBOT, P2787, DOI 10.1109/ICRA.2015.7139578.
   Michot J., 2010, P 5 S 3D DAT PROC VI, P9.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Miller I, 2011, J FIELD ROBOT, V28, P619, DOI 10.1002/rob.20395.
   Mohan M, 2010, I C CONT AUTOMAT ROB, P1000, DOI 10.1109/ICARCV.2010.5707412.
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P481, DOI 10.1109/TASE.2014.2329556.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258.
   MONTIEL J, 2006, P ROB SCI SYST, P8.
   Morales Y, 2008, IEEE INT CONF ROBOT, P449, DOI 10.1109/ROBOT.2008.4543248.
   Morales Y, 2009, J FIELD ROBOT, V26, P609, DOI 10.1002/rob.20301.
   MORAVEC HP, 1988, AI MAG, V9, P61.
   Mouragnon E., 2006, 2006 IEEE COMP SOC C, P363, DOI {[}10.1109/CVPR.2006.236, DOI 10.1109/CVPR.2006.236].
   Mu H, 2011, IEEE T AERO ELEC SYS, V47, P1433, DOI 10.1109/TAES.2011.5751268.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Muehlfellner P, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P57.
   Murphy KP, 2000, ADV NEUR IN, V12, P1015.
   Napier A, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P590, DOI 10.1109/IVS.2012.6232165.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Neira J, 2003, IEEE INT CONF ROBOT, P427.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Nettleton E, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P1425.
   Nettleton E, 2006, SPRINGER TRAC ADV RO, V24, P179.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Newman P, 2003, IEEE INT CONF ROBOT, P1921, DOI 10.1109/ROBOT.2003.1241875.
   Newman P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1802, DOI 10.1109/ROBOT.2002.1014803.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103.
   Nuchter A, 2006, LECT NOTES ARTIF INT, V4020, P335.
   Nuchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001.
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640.
   Paz LM, 2008, IEEE T ROBOT, V24, P1107, DOI 10.1109/TRO.2008.2004639.
   Pepperell E, 2016, INT J ROBOT RES, V35, DOI 10.1177/0278364915618766.
   Persson M, 2015, IEEE INT VEH SYM, P686, DOI 10.1109/IVS.2015.7225764.
   Peynot T, 2010, INT J ROBOT RES, V29, P1602, DOI 10.1177/0278364910384638.
   Pfingsthorn M, 2008, LECT NOTES COMPUT SC, V5001, P457.
   Pinies P, 2008, IEEE T ROBOT, V24, P1094, DOI 10.1109/TRO.2008.2004636.
   Pink O, 2009, IEEE INT VEH SYM, P254, DOI 10.1109/IVS.2009.5164287.
   Ploeg J, 2012, IEEE T INTELL TRANSP, V13, P989, DOI 10.1109/TITS.2012.2210636.
   Pomerleau D, 1996, IEEE EXPERT, V11, P19, DOI 10.1109/64.491277.
   Press W., 1992, NUMERICAL RECIPES C, P542.
   Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751.
   Radwan N, 2016, IEEE INT CONF ROBOT, P4837, DOI 10.1109/ICRA.2016.7487688.
   Rauskolb FW, 2008, J FIELD ROBOT, V25, P674, DOI 10.1002/rob.20254.
   Reineking T, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P789.
   Remazeilles A, 2004, IEEE INT CONF ROBOT, P4695, DOI 10.1109/ROBOT.2004.1302458.
   Riazuelo L, 2014, ROBOT AUTON SYST, V62, P401, DOI 10.1016/j.robot.2013.11.007.
   Roumeliotis SI, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1383, DOI 10.1109/IROS.1998.724781.
   Rouveure R., 2010, P ROB 2010 INT WORKS, P9.
   Royer E, 2005, PROC CVPR IEEE, P114.
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y.
   Royer E, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2248, DOI 10.1109/ITSC.2016.7795919.
   Saeedi S, 2016, J FIELD ROBOT, V33, P3, DOI 10.1002/rob.21620.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Saust F, 2011, IEEE INT VEH SYM, P169, DOI 10.1109/IVS.2011.5940568.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Schindler G., 2007, 2007 IEEE C COMP VIS, P1.
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446.
   Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509.
   Seetharaman G, 2006, COMPUTER, V39, P26, DOI 10.1109/MC.2006.447.
   Shoudong Huang, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P3011, DOI 10.1109/IROS.2010.5652603.
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Stachniss C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1153.
   Steedly D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P223, DOI 10.1109/ICCV.2001.937628.
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009.
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636.
   Sundvall P, 2006, IEEE INT CONF ROBOT, P3781, DOI 10.1109/ROBOT.2006.1642280.
   Tao T, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P2888, DOI 10.1109/WCICA.2010.5554910.
   Tao Z, 2013, IEEE INT C INT ROBOT, P406, DOI 10.1109/IROS.2013.6696383.
   Thrun S, 2005, SPRINGER TRAC ADV RO, V15, P254.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Thrun S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P321, DOI 10.1109/ROBOT.2000.844077.
   Thrun S, 2008, SPRINGER TRAC ADV RO, V38, P13.
   Thrun S, 2006, J FIELD ROBOT, V23, P661, DOI 10.1002/rob.20147.
   Toledo-Moreo R, 2010, IEEE T INTELL TRANSP, V11, P100, DOI 10.1109/TITS.2009.2031625.
   Torii A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P102, DOI 10.1109/ICCVW.2011.6130230.
   Trehard G, 2014, IEEE INT C INT ROBOT, P2699, DOI 10.1109/IROS.2014.6942931.
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298.
   Trulls E, 2011, J FIELD ROBOT, V28, P329, DOI 10.1002/rob.20386.
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255.
   Urmson C, 2006, J FIELD ROBOT, V23, P467, DOI 10.1002/rob.20126.
   Vaca-Castano G, 2012, PROC CVPR IEEE, P1186, DOI 10.1109/CVPR.2012.6247800.
   Vidal-Calleja TA, 2011, ROBOT AUTON SYST, V59, P654, DOI 10.1016/j.robot.2011.05.008.
   Vivet D, 2013, SENSORS-BASEL, V13, P4527, DOI 10.3390/s130404527.
   Vu T.-D., 2009, THESIS INPG GRENOBLE.
   Vysotska O, 2016, IEEE ROBOT AUTOM LET, V1, P213, DOI 10.1109/LRA.2015.2512936.
   Waibel M, 2011, IEEE ROBOT AUTOM MAG, V18, P69, DOI 10.1109/MRA.2011.941632.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Walter MR, 2007, INT J ROBOT RES, V26, P335, DOI 10.1177/0278364906075026.
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463.
   Wang CC, 2003, IEEE INT CONF ROBOT, P842.
   Wang CC, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P416, DOI 10.1109/IVS.2003.1212947.
   Wei LJ, 2013, IEEE T INSTRUM MEAS, V62, P3110, DOI 10.1109/TIM.2013.2265476.
   Welzel A, 2015, IEEE INT C INTELL TR, P2728, DOI 10.1109/ITSC.2015.438.
   Williams B, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2053, DOI 10.1109/IROS.2008.4650996.
   Williams B, 2010, IEEE INT CONF ROBOT, P3494, DOI 10.1109/ROBOT.2010.5509248.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Williams SB, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2743, DOI 10.1109/ROBOT.2002.1013647.
   Williams SB, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P406, DOI 10.1109/ROBOT.2002.1013394.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.
   Xie JP, 2010, I C CONT AUTOMAT ROB, P1397, DOI 10.1109/ICARCV.2010.5707329.
   Yeh T, 2004, PROC CVPR IEEE, P76.
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI {[}10.1007/S00034-009-9130-7, 10.1007/s00034-009-9130-7].
   Yu L, 2020, IEEE T CLOUD COMPUT, V8, P459, DOI 10.1109/TCC.2016.2525984.
   Yu L, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P513, DOI 10.1109/ITSC.2016.7795603.
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1\_19.
   Zender H, 2008, ROBOT AUTON SYST, V56, P493, DOI 10.1016/j.robot.2008.03.007.
   Zhang J, 2015, IEEE INT CONF ROBOT, P2174, DOI 10.1109/ICRA.2015.7139486.
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80.
   Zhang ZY, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P343.
   Zhou XS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1785, DOI 10.1109/IROS.2006.282219.
   Ziegler J, 2014, IEEE INTEL TRANSP SY, V6, P8, DOI 10.1109/MITS.2014.2306552.},
Number-of-Cited-References = {283},
Times-Cited = {241},
Usage-Count-Last-180-days = {28},
Usage-Count-Since-2013 = {35},
Journal-ISO = {IEEE T. Intell. Veh.},
Doc-Delivery-Number = {VK5KJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000722377800005},
OA = {Green Submitted},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000309406700122,
Author = {Maddern, Will and Milford, Michael and Wyeth, Gordon},
Book-Group-Author = {IEEE},
Title = {Capping Computation Time and Storage Requirements for Appearance-based
   Localization with CAT-SLAM},
DOI = {10.1109/ICRA.2012.6224622},
Booktitle = {2012 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2012},
Pages = {822-827},
Note = {IEEE International Conference on Robotics and Automation (ICRA), St
   Paul, MN, MAY 14-18, 2012},
Abstract = {Appearance-based localization is increasingly used for loop closure
   detection in metric SLAM systems. Since it relies only upon the
   appearance-based similarity between images from two locations, it can
   perform loop closure regardless of accumulated metric error. However,
   the computation time and memory requirements of current appearance-based
   methods scale linearly not only with the size of the environment but
   also with the operation time of the platform. These properties impose
   severe restrictions on long-term autonomy for mobile robots, as loop
   closure performance will inevitably degrade with increased operation
   time. We present a set of improvements to the appearance-based SLAM
   algorithm CAT-SLAM to constrain computation scaling and memory usage
   with minimal degradation in performance over time. The appearance-based
   comparison stage is accelerated by exploiting properties of the particle
   observation update, and nodes in the continuous trajectory map are
   removed according to minimal information loss criteria. We demonstrate
   constant time and space loop closure detection in a large urban
   environment with recall performance exceeding FAB-MAP by a factor of 3
   at 100\% precision, and investigate the minimum computational and memory
   requirements for maintaining mapping performance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Maddern, W (Corresponding Author), Queensland Univ Technol, Fac Sci \& Engn, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4001, Australia.
   Maddern, Will; Milford, Michael; Wyeth, Gordon, Queensland Univ Technol, Fac Sci \& Engn, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4001, Australia.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4673-1405-3},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {w.maddern@qut.edu.au
   michael.milford@qut.edu.au
   gordon.wyeth@qut.edu.au},
Affiliations = {Queensland University of Technology (QUT)},
ResearcherID-Numbers = {Milford, Michael/J-1304-2012
   },
ORCID-Numbers = {Milford, Michael/0000-0002-5162-1793
   Wyeth, Gordon/0000-0002-4996-3612},
Cited-References = {Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Cummins M., 2009, ROB SCI SYST C SEATT.
   Cummins M., 2008, IEEE INT C ROB AUT P.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Cummins M, 2010, IEEE T ROBOT, V26, P1042, DOI 10.1109/TRO.2010.2080390.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178.
   Knight J., 2001, IEEE RSJ INT C INT R.
   LEONARD J, 2003, INT JOINT C ART INT.
   Liu JS, 2001, STAT ENG IN, P225.
   Maddern W., INT J ROBOT IN PRESS.
   Maddern W., 2010, AUSTR C ROB AUT BRIS.
   Milford M., 2010, INT J ROBOTICS RES.
   Milford M., 2013, IEEE INT C ROB AUT.
   Milford M., 2004, IEEE INT C ROB AUT N.
   Nerurkar ED, 2011, INT J ROBOT RES, V30, P772, DOI 10.1177/0278364910390539.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Teynor A, 2007, LECT NOTES COMPUT SC, V4841, P610.
   Thrun S., 2002, WORKSH ALG FDN ROB N.
   Torii A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS).},
Number-of-Cited-References = {20},
Times-Cited = {31},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BCA25},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000309406700122},
DA = {2022-05-17},
}

@article{ WOS:000399558300006,
Author = {Ila, Viorela and Polok, Lukas and Solony, Marek and Svoboda, Pavel},
Title = {SLAM plus plus -A highly efficient and temporally scalable incremental
   SLAM framework},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2017},
Volume = {36},
Number = {2},
Pages = {210-230},
Month = {FEB},
Abstract = {The most common way to deal with the uncertainty present in noisy
   sensorial perception and action is to model the problem with a
   probabilistic framework. Maximum likelihood estimation is a well-known
   estimation method used in many robotic and computer vision applications.
   Under Gaussian assumption, the maximum likelihood estimation converts to
   a nonlinear least squares problem. Efficient solutions to nonlinear
   least squares exist and they are based on iteratively solving sparse
   linear systems until convergence. In general, the existing solutions
   provide only an estimation of the mean state vector, the resulting
   covariance being computationally too expensive to recover. Nevertheless,
   in many simultaneous localization and mapping (SLAM) applications,
   knowing only the mean vector is not enough. Data association, obtaining
   reduced state representations, active decisions and next best view are
   only a few of the applications that require fast state covariance
   recovery. Furthermore, computer vision and robotic applications are in
   general performed online. In this case, the state is updated and
   recomputed every step and its size is continuously growing, therefore,
   the estimation process may become highly computationally demanding. This
   paper introduces a general framework for incremental maximum likelihood
   estimation called SLAM++, which fully benefits from the incremental
   nature of the online applications, and provides efficient estimation of
   both the mean and the covariance of the estimate. Based on that, we
   propose a strategy for maintaining a sparse and scalable state
   representation for large scale mapping, which uses information theory
   measures to integrate only informative and non-redundant contributions
   to the state representation. SLAM++ differs from existing
   implementations by performing all the matrix operations by blocks. This
   led to extremely fast matrix manipulation and arithmetic operations used
   in nonlinear least squares. Even though this paper tests SLAM++
   efficiency on SLAM problems, its applicability remains general.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Ila, V (Corresponding Author), 115 North Rd, Canberra, ACT 2100, Australia.
   Ila, Viorela, Australian Natl Univ, Canberra, ACT, Australia.
   Polok, Lukas; Solony, Marek; Svoboda, Pavel, Brno Univ Technol, Fac Informat Technol, Brno, Czech Republic.},
DOI = {10.1177/0278364917691110},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Nonlinear least squares; incremental covariance recovery; long-term
   SLAM; loop closure; compact state representation},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {viorela.ila@anu.edu.au},
Affiliations = {Australian National University; Brno University of Technology},
ORCID-Numbers = {Ila, Viorela/0000-0002-8137-0833},
Funding-Acknowledgement = {ARC Centre of Excellence for Robotic Vision {[}CE140100016]; European
   Union {[}316564-IMPART]; IT4-Innovations Centre of Excellence project -
   European Regional Development Fund {[}CZ.1.05/1.1.00/02.0070]; national
   budget of the Czech Republic via the Research and Development for
   Innovations Operational Programme; Czech Ministry of Education, Youth
   and Sports via the project Large Research, Development and Innovations
   Infrastructures {[}LM2011033]},
Funding-Text = {The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Dr.
   Viorela Ila was supported by the ARC Centre of Excellence for Robotic
   Vision, project number CE140100016.; The authors from Brno University of
   Technology were supported by the European Union, 7th Framework Programme
   grant 316564-IMPART and the IT4-Innovations Centre of Excellence project
   (CZ.1.05/1.1.00/02.0070), funded by the European Regional Development
   Fund and the national budget of the Czech Republic via the Research and
   Development for Innovations Operational Programme, as well as Czech
   Ministry of Education, Youth and Sports via the project Large Research,
   Development and Innovations Infrastructures (LM2011033).},
Cited-References = {Agarwal S., 2012, CERES SOLVER.
   Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148.
   Barfoot TD, 2014, IEEE T ROBOT, V30, P679, DOI 10.1109/TRO.2014.2298059.
   Beall C, 2010, IEEE INT C INT ROBOT, P4418, DOI 10.1109/IROS.2010.5649213.
   Bjorck A, 1996, NUMERICAL METHODS LE.
   Blanco J. - L., 2010, TECHNICAL REPORT.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   Carlevaris-Bianco N, 2014, IEEE INT CONF ROBOT, P854, DOI 10.1109/ICRA.2014.6906954.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Davis T., 2006, CSPARSE.
   Davis T., 2006, DIRECT METHODS SPARS.
   Davis TA, 1999, SIAM J MATRIX ANAL A, V20, P606, DOI 10.1137/S0895479897321076.
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Dissanayake G, 2002, AUTON ROBOT, V12, P267, DOI 10.1023/A:1015217631658.
   Eustice RM, 2006, INT J ROBOT RES, V25, P1223, DOI 10.1177/0278364906072512.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   GOLUB GH, 1980, LINEAR ALGEBRA APPL, V34, P3, DOI 10.1016/0024-3795(80)90156-1.
   Grisetti G., 2007, ROBOTICS SCI SYSTEMS, P27.
   HAGER WW, 1989, SIAM REV, V31, P221, DOI 10.1137/1031049.
   Haner S, 2012, LECT NOTES COMPUT SC, V7573, P545, DOI 10.1007/978-3-642-33709-3\_39.
   Huang GQ, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P150, DOI 10.1109/ECMR.2013.6698835.
   Huang GQP, 2011, IEEE INT C INT ROBOT, P65, DOI 10.1109/IROS.2011.6048760.
   Ila V, 2015, IEEE INT CONF ROBOT, P4636, DOI 10.1109/ICRA.2015.7139841.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Indelman V, 2012, BRIT MACH VIS C BMVC, P134.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   KABSCH W, 1976, ACTA CRYSTALLOGR A, V32, P922, DOI 10.1107/S0567739476001873.
   Kaess Michael, 2011, 2011 IEEE International Conference on Robotics and Automation, P3281.
   Kaess M, 2010, INT WORKSH ALG FDN R, P150.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Klein George, 2007, P1.
   Konolige, 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.102.
   Konolige K., 2010, 2010 IEEERSJ INT C I, P22.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Kummerle R, 2009, AUTON ROBOT, V27, P387, DOI 10.1007/s10514-009-9155-6.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Polok L, 2013, ROBOTICS SCI SYSTEMS.
   Polok L., 2013, P 21 HIGH PERF COMP, P698.
   Polok L, 2013, IEEE INT CONF ROBOT, P2263, DOI 10.1109/ICRA.2013.6630883.
   Prentice S, 2010, SPRINGER TRAC ADV RO, V66, P293.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Sibley G, 2008, LECT NOTES ELECTR EN, V8, P103.
   Sim R, 2005, IEEE INT CONF ROBOT, P2411.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Tipaldi GD, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3466.
   Valencia R, 2013, IEEE T ROBOT, V29, P1050, DOI 10.1109/TRO.2013.2257577.
   Vidal-Calleja T, 2006, IEEE INT CONF ROBOT, P1930, DOI 10.1109/ROBOT.2006.1641988.},
Number-of-Cited-References = {56},
Times-Cited = {42},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {ES5DX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000399558300006},
DA = {2022-05-17},
}

@article{ WOS:000675207800014,
Author = {Meng, Qingyu and Guo, Hongyan and Zhao, Xiaoming and Cao, Dongpu and
   Chen, Hong},
Title = {Loop-Closure Detection With a Multiresolution Point Cloud Histogram Mode
   in Lidar Odometry and Mapping for Intelligent Vehicles},
Journal = {IEEE-ASME TRANSACTIONS ON MECHATRONICS},
Year = {2021},
Volume = {26},
Number = {3},
Pages = {1307-1317},
Month = {JUN},
Abstract = {Precise positioning is the basic condition for intelligent vehicles to
   complete perception, decision making and control tasks. In response to
   this challenge, in this article, lidar simultaneous localization and
   mapping (SLAM) is taken as the research object, and a SLAM system is
   designed that integrates motion compensation and ground information
   removal functions, and can construct a real-time environment map and
   determine its own position on the map while the vehicle is driving. A
   loop-closure detection method with a multiresolution point cloud
   histogram mode is proposed, which can effectively detect whether the
   vehicle passes through the same position and perform optimization to
   obtain globally consistent pose and map information in the urban
   conditions with more driving loops. We conduct experiments on the
   well-known KITTI dataset and compare the results with those of
   state-of-the-art systems. The experiments confirm that the lidar SLAM
   system designed in this article can provide accurate and effective
   positioning information for intelligent vehicles. The proposed
   loop-closure detection algorithm has an excellent real-time performance
   and accuracy, which can guarantee the long-term driving operation of
   these vehicles.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Guo, HY (Corresponding Author), Jilin Univ, State Key Lab Automot Simulat \& Control, Campus Nanling, Changchun 130025, Peoples R China.
   Guo, HY (Corresponding Author), Jilin Univ, Dept Control Sci \& Engn, Campus Nanling, Changchun 130025, Peoples R China.
   Meng, Qingyu; Guo, Hongyan; Zhao, Xiaoming, Jilin Univ, State Key Lab Automot Simulat \& Control, Campus Nanling, Changchun 130025, Peoples R China.
   Meng, Qingyu; Guo, Hongyan; Zhao, Xiaoming, Jilin Univ, Dept Control Sci \& Engn, Campus Nanling, Changchun 130025, Peoples R China.
   Cao, Dongpu, Univ Waterloo, Dept Mech \& Mechatron Engn, Waterloo, ON N2L 3G1, Canada.
   Chen, Hong, Tongji Univ, Clean Energy Automot Engn Ctr, Shanghai 201804, Peoples R China.},
DOI = {10.1109/TMECH.2021.3062647},
ISSN = {1083-4435},
EISSN = {1941-014X},
Keywords = {Three-dimensional displays; Laser radar; Intelligent vehicles;
   Simultaneous localization and mapping; Histograms; Trajectory; Feature
   extraction; KITTI dataset; lidar simultaneous localization and mapping
   (SLAM); loop-closure detection; multiresolution histogram; pose
   estimation},
Keywords-Plus = {OBJECT-DETECTION; SLAM; VISION; MAP},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Manufacturing; Engineering,
   Electrical \& Electronic; Engineering, Mechanical},
Author-Email = {qymeng19@mails.jlu.edu.cn
   guohy11@jlu.edu.cn
   zhaoxm19@mails.jlu.edu.cn
   dongpu.cao@uwaterloo.ca
   chenh@jlu.edu.cn},
Affiliations = {Jilin University; Jilin University; University of Waterloo; Tongji
   University},
ResearcherID-Numbers = {Chen, Hong/A-2851-2012},
ORCID-Numbers = {Chen, Hong/0000-0002-1724-8649},
Funding-Acknowledgement = {National Nature Science Foundation of China {[}U19A2069, 61790563];
   Project of the Science and Technology Department of Jilin Province
   {[}20200401088GX, 20200501011GX]; National Development and Reform
   Commission of Jilin Province {[}2019C0365]},
Funding-Text = {This work was supported in part by the National Nature Science
   Foundation of China under Grant U19A2069 and Grant 61790563, in part by
   the Project of the Science and Technology Department of Jilin Province
   (20200401088GX, 20200501011GX), and in part by the Project of the
   National Development and Reform Commission of Jilin Province under Grant
   2019C0365.},
Cited-References = {Agarwal S., 2019, CERES SOLVER A LARGE.
   Cadena Cesar, 2018, ARXIV180409557.
   Chen LH, 2019, IEEE SENS J, V19, P11475, DOI 10.1109/JSEN.2019.2931368.
   Chen YB, 2020, IEEE-ASME T MECH, V25, P1182, DOI 10.1109/TMECH.2019.2963439.
   Dellaert F., 2012, GTRIMCPR2012002.
   Duan JM, 2016, PROCEDIA ENGINEER, V138, P267, DOI 10.1016/j.proeng.2016.01.258.
   Dube R, 2020, INT J ROBOT RES, V39, P339, DOI 10.1177/0278364919863090.
   Eckenhoff K, 2019, INT J ROBOT RES, V38, P563, DOI 10.1177/0278364919835021.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Grisetti G., 2011, IEEE INT C ROB AUT I, P9.
   Grupp M., 2017, EVO PYTHON PACKAGE E.
   Guclu O, 2020, VISUAL COMPUT, V36, P1271, DOI 10.1007/s00371-019-01720-8.
   Handa A., 2014, SIMPLIFIED JACOBIANS SIMPLIFIED JACOBIANS, P8.
   Huang YJ, 2017, J POWER SOURCES, V341, P91, DOI 10.1016/j.jpowsour.2016.11.106.
   Jin LQ, 2020, IEEE-ASME T MECH, V25, P1803, DOI 10.1109/TMECH.2020.2997606.
   Jo H, 2018, IEEE-ASME T MECH, V23, P714, DOI 10.1109/TMECH.2018.2795252.
   Kim G, 2019, IEEE ROBOT AUTOM LET, V4, P1948, DOI 10.1109/LRA.2019.2897340.
   Kim MD, 2018, IEEE-ASME T MECH, V23, P491, DOI 10.1109/TMECH.2018.2791473.
   Li SP, 2019, ROBOT AUTON SYST, V112, P201, DOI 10.1016/j.robot.2018.11.009.
   Lin CF, 2014, IET INTELL TRANSP SY, V8, P550, DOI 10.1049/iet-its.2013.0056.
   Lin J., 2019, ARXIV190911811.
   Lin JR, 2020, IEEE INT CONF ROBOT, P3126, DOI 10.1109/ICRA40945.2020.9197440.
   Liu WL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224945.
   Magnusson M, 2009, J FIELD ROBOT, V26, P892, DOI 10.1002/rob.20314.
   McDonald J, 2013, ROBOT AUTON SYST, V61, P1144, DOI 10.1016/j.robot.2012.08.008.
   Memon AR, 2020, ROBOT AUTON SYST, V126, DOI 10.1016/j.robot.2020.103470.
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Neuhaus F., 2018, GERM C PATT REC, P60.
   Nguyen T, 2020, J ROBOT, V2020, DOI 10.1155/2020/7362952.
   Ortiz-Gonzalez A, 2020, J COMMUN TECHNOL EL+, V65, P690, DOI 10.1134/S1064226920060224.
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
   Rohling T, 2015, IEEE INT C INT ROBOT, P736, DOI 10.1109/IROS.2015.7353454.
   Schops T, 2020, IEEE T PATTERN ANAL, V42, P2494, DOI 10.1109/TPAMI.2019.2947048.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Song WJ, 2018, IEEE T INTELL TRANSP, V19, P758, DOI 10.1109/TITS.2017.2700628.
   Soualmi B, 2014, CONTROL ENG PRACT, V24, P106, DOI 10.1016/j.conengprac.2013.11.015.
   Tang DQ, 2020, IEEE-ASME T MECH, V25, P1555, DOI 10.1109/TMECH.2020.2976794.
   Tomono M, 2020, ADV ROBOTICS, V34, P1530, DOI 10.1080/01691864.2020.1824809.
   Wen WS, 2020, IEEE INTEL TRANSP SY, V12, P53, DOI 10.1109/MITS.2020.2994131.
   Wen WS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113928.
   Zhang FQ, 2020, MULTIMED TOOLS APPL, V79, P16421, DOI 10.1007/s11042-019-7438-2.
   Zhang J., 2014, ROBOT SCI SYST, V2, P9.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.},
Number-of-Cited-References = {44},
Times-Cited = {0},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {14},
Journal-ISO = {IEEE-ASME Trans. Mechatron.},
Doc-Delivery-Number = {TL9XM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000675207800014},
DA = {2022-05-17},
}

@inproceedings{ WOS:000371885405030,
Author = {Schuster, Martin J. and Brand, Christoph and Hirschmueller, Heiko and
   Suppa, Michael and Beetz, Michael},
Book-Group-Author = {IEEE},
Title = {Multi-Robot 6D Graph SLAM Connecting Decoupled Local Reference Filters},
DOI = {10.1109/IROS.2015.7354094},
Booktitle = {2015 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2015},
Pages = {5093-5100},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Hamburg, GERMANY, SEP 28-OCT 02, 2015},
Abstract = {Teams of mobile robots can be deployed in search and rescue missions to
   explore previously unknown environments. Methods for joint localization
   and mapping constitute the basis for (semi-)autonomous cooperative
   action, in particular when navigating in GPS-denied areas. As
   communication losses may occur, a decentralized solution is required.
   With these challenges in mind, we designed a submap-based SLAM system
   that relies on inertial measurements and stereo-vision to create
   multi-robot dense 3D maps. For online pose and map estimation, we
   integrate the results of keyframe-based local reference filters through
   incremental graph SLAM. To the best of our knowledge, we are the first
   to combine these two methods to benefit from their particular advantages
   for 6D multi-robot localization and mapping: Local reference filters on
   each robot provide real-time, long-term stable state estimates that are
   required for stabilization, control and fast obstacle avoidance, whereas
   online graph optimization provides global multi-robot pose and map
   estimates needed for cooperative planning. We propose a novel graph
   topology for a decoupled integration of local filter estimates from
   multiple robots into a SLAM graph according to the filters' uncertainty
   estimates and independence assumptions and evaluated its benefits on two
   different robots in indoor, outdoor and mixed scenarios. Further, we
   performed two extended experiments in a multi-robot setup to evaluate
   the full SLAM system, including visual robot detections and submap
   matches as inter-robot loop closure constraints.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Schuster, MJ (Corresponding Author), German Aerosp Ctr DLR, RMC, Dept Percept \& Cognit, Munchner Str 20, D-82234 Wessling, Germany.
   Schuster, Martin J.; Brand, Christoph; Hirschmueller, Heiko; Suppa, Michael, German Aerosp Ctr DLR, RMC, Dept Percept \& Cognit, Munchner Str 20, D-82234 Wessling, Germany.
   Beetz, Michael, Univ Bremen, Inst Artificial Intelligence, D-28359 Bremen, Germany.
   Beetz, Michael, Univ Bremen, TZI Ctr Comp Technol, D-28359 Bremen, Germany.},
ISSN = {2153-0858},
ISBN = {978-1-4799-9994-1},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {martin.schuster@dlr.de
   christoph.brand@dlr.de
   heiko.hirschmueller@dlr.de
   michael.suppa@dlr.de
   beetz@cs.uni-bremen.de},
Affiliations = {Helmholtz Association; German Aerospace Centre (DLR); University of
   Bremen; University of Bremen},
Cited-References = {Ahmad A., 2013, ICRA.
   Brand C., 2014, IROS.
   Brand C., 2015, IROS.
   Carlone L., 2010, ICRA.
   Cunningham A., 2013, ICRA.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Hirschmuller H., 2002, 2002 7th International Conference on Control, Automation, Robotics and Vision (IEEE Cat. No.02EX649), P1099.
   Howard A, 2006, INT J ROBOT RES, V25, P1243, DOI 10.1177/0278364906072250.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kim B., 2010, ICRA.
   Lee G. H., 2013, IROS.
   Leishman R. C., 2013, ICUAS.
   Mei C., 2010, IJCV, V94, P198.
   Olson E., 2011, ICRA.
   Quang P. B., 2010, FUSION.
   Reid R., 2011, RAM.
   Schmid K., 2012, IROS.
   Schmid K., 2014, FUSION.
   Tombari F., 2011, ICIP.
   Vidal-Calleja TA, 2011, ROBOT AUTON SYST, V59, P654, DOI 10.1016/j.robot.2011.05.008.
   Welle J., 2010, ICRA.
   Williams S., 2014, IJRR, V33, P1.},
Number-of-Cited-References = {24},
Times-Cited = {16},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {9},
Doc-Delivery-Number = {BE4LI},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000371885405030},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000331367401021,
Author = {Carlevaris-Bianco, Nicholas and Eustice, Ryan M.},
Editor = {Amato, N},
Title = {Long-Term Simultaneous Localization and Mapping with Generic Linear
   Constraint Node Removal},
DOI = {10.1109/IROS.2013.6696478},
Booktitle = {2013 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2013},
Pages = {1034-1041},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Tokyo, JAPAN, NOV 03-08, 2013},
Abstract = {This paper reports on the use of generic linear constraint (GLC) node
   removal as a method to control the computational complexity of long-term
   simultaneous localization and mapping. We experimentally demonstrate
   that GLC provides a principled and flexible tool enabling a wide variety
   of complexity management schemes. Specifically, we consider two main
   classes: batch multi-session node removal, in which nodes are removed in
   a batch operation between mapping sessions, and online node removal, in
   which nodes are removed as the robot operates. Results are shown for
   34.9 h of real-world indoor-outdoor data covering 147.4 km collected
   over 27 mapping sessions spanning a period of 15 months.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Carlevaris-Bianco, N (Corresponding Author), Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Carlevaris-Bianco, Nicholas, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M., Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
ISSN = {2153-0858},
ISBN = {978-1-4673-6358-7},
Keywords-Plus = {INFORMATION; FILTERS; SLAM},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Robotics},
Author-Email = {carlevar@umich.edu
   eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan},
ORCID-Numbers = {Eustice, Ryan/0000-0002-9989-4942},
Funding-Acknowledgement = {National Science Foundation {[}IIS-0746455]; Naval Sea Systems Command
   (NAVSEA) through the Naval Engineering Education Center
   {[}N65540-10-C-0003]},
Funding-Text = {This work was supported in part by the National Science Foundation under
   award IIS-0746455, and in part by the Naval Sea Systems Command (NAVSEA)
   through the Naval Engineering Education Center under award
   N65540-10-C-0003},
Cited-References = {Carlevaris-Bianco N., 2013, P IEEE INT C ROB AUT, P728.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Cunningham A., 2013, P IEEE INT C ROB AUT.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Folkesson J, 2004, IEEE INT CONF ROBOT, P383, DOI 10.1109/ROBOT.2004.1307180.
   Friedman N., 2009, PROBABILISTIC GRAPHI.
   Huang G., 2013, P EUR C MOB ROB BARC.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kaess M., 2010, OPEN SOURCE IMPLEMEN.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Magnusson M., 2009, THESIS.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Rao C., 1971, GEN INVERSE MATRICES.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Vial J, 2011, IEEE INT C INT ROBOT, P886, DOI 10.1109/IROS.2011.6048728.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Walter MR, 2007, INT J ROBOT RES, V26, P335, DOI 10.1177/0278364906075026.},
Number-of-Cited-References = {27},
Times-Cited = {12},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BA0HU},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000331367401021},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000460678700014,
Author = {Kim, Giseop and Park, Byungjae and Kim, Ayoung},
Title = {1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using
   Scan Context Image},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2019},
Volume = {4},
Number = {2},
Pages = {1948-1955},
Month = {APR},
Abstract = {In this letter, we present a long-term localization method that
   effectively exploits the structural information of an environment via an
   image format. The proposed method presents a robust year-round
   localization performance even when learned in just a single day. The
   proposed localizer learns a point cloud descriptor, named Scan Context
   Image (SCI), and performs robot localization on a grid map by
   formulating the place recognition problem as place classification using
   a convolutional neural network. Our method is faster than existing
   methods proposed for place recognition because it avoids a pairwise
   comparison between a query and scans in a database. In addition, we
   provide thorough validations using publicly available long-term
   datasets, the NCLT dataset and the Oxford RobotCar dataset, and show
   that the Scan Context Image (SCI) localization attains consistent
   performance over a year and outperforms existing methods.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Kim, A (Corresponding Author), Korea Adv Inst Sci \& Technol, Dept Civil \& Environm Engn, Daejeon 34141, South Korea.
   Kim, Giseop; Kim, Ayoung, Korea Adv Inst Sci \& Technol, Dept Civil \& Environm Engn, Daejeon 34141, South Korea.
   Park, Byungjae, ETRI, Intelligent Robot Syst Res Grp, Daejeon 34129, South Korea.},
DOI = {10.1109/LRA.2019.2897340},
ISSN = {2377-3766},
Keywords = {Localization; range sensing; SLAM},
Keywords-Plus = {PLACE RECOGNITION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {paulgkim@kaist.ac.kr
   bjp@etri.re.kr
   ayoungk@kaist.ac.kr},
Affiliations = {Korea Advanced Institute of Science \& Technology (KAIST); Electronics
   \& Telecommunications Research Institute - Korea (ETRI)},
ORCID-Numbers = {Kim, Giseop/0000-0001-6311-0686},
Funding-Acknowledgement = {Korea Agency for Infrastructure Technology Advancement (KAIA) through
   the Ministry of Land, Infrastructure and Transport of Korea
   {[}19CTAP-C142170-02]; {[}High-Definition Map Based Precise Vehicle
   Localization Using Cameras and LIDARs] project - Naver Labs Corporation},
Funding-Text = {This work was supported in part by the Korea Agency for Infrastructure
   Technology Advancement (KAIA) through the Ministry of Land,
   Infrastructure and Transport of Korea under Grant 19CTAP-C142170-02, and
   in part by the {[}High-Definition Map Based Precise Vehicle Localization
   Using Cameras and LIDARs] project funded by Naver Labs Corporation.},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   BENEDIKT ML, 1979, ENVIRON PLANN B, V6, P47, DOI 10.1068/b060047.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cop KP, 2018, IEEE INT CONF ROBOT, P3653, DOI 10.1109/ICRA.2018.8460940.
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693.
   Dube R, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Kendall A., 2017, ARXIV PREPRINT ARXIV, P571, DOI {[}10.5244/c.31.57, DOI 10.5244/C.31.57].
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Maddern W, 2015, IEEE INT CONF ROBOT, P1684, DOI 10.1109/ICRA.2015.7139414.
   Miller D, 2018, IEEE INT CONF ROBOT, P3243.
   Porav H, 2018, IEEE INT CONF ROBOT, P1011, DOI 10.1109/ICRA.2018.8462894.
   Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8\_3.
   Withers Dan, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6233, DOI 10.1109/ICRA.2017.7989738.
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760.
   Ye Y., 2017, P BRIT MACH VIS C.},
Number-of-Cited-References = {23},
Times-Cited = {38},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {9},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {HO1OR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000460678700014},
DA = {2022-05-17},
}

@inproceedings{ WOS:000659426200064,
Author = {Yu, Peidong and Wang, Mengke and Chen, Huanjian},
Editor = {Sun, J and Nawaz, M and Liu, X},
Title = {Integration and evaluation of SLAM-based backpack mobile mapping system},
Booktitle = {2020 2ND INTERNATIONAL CONFERENCE ON GEOSCIENCE AND ENVIRONMENTAL
   CHEMISTRY (ICGEC 2020)},
Series = {E3S Web of Conferences},
Year = {2020},
Volume = {206},
Pages = {03014},
Note = {2nd International Conference on Geoscience and Environmental Chemistry
   (ICGEC), Tianjin Univ Sci \& Technol, Tianjin, PEOPLES R CHINA, OCT
   09-11, 2020},
Abstract = {Mobile mapping is an efficient technology to acquire spatial data of the
   environment. As a supplement of vehicle-borne and air-borne methods,
   Backpack mobile mapping system (MMS) has a wide application prospect in
   indoor and underground space. High-precision positioning and attitude
   determination are the key to MMS. Usually, GNSS/INS integrated
   navigation system provides reliable pose information. However, in the
   GNSS-denied environments, there is no effective long-term positioning
   method. With the development of simultaneous localization and mapping
   (SLAM) algorithm, it provides a new solution for indoor mobile mapping.
   This paper develops a portable backpack mobile mapping system, which
   integrates multi-sensor such as LiDAR, IMU, GNSS and panoramic camera.
   The 3D laser SLAM algorithm is applied to the mobile mapping to realize
   the acquisition of geographic information data in various complex
   environments. The experimental results in typical indoor and outdoor
   scenes show that the system can achieve high-precision and efficient
   acquisition of 3D information, and the relative precision of point cloud
   is 2-4cm, which meets the requirements of scene mapping and
   reconstruction.},
Publisher = {E D P SCIENCES},
Address = {17 AVE DU HOGGAR PARC D ACTIVITES COUTABOEUF BP 112, F-91944 CEDEX A,
   FRANCE},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yu, PD (Corresponding Author), Shandong Univ Sci \& Technol, Coll Geodesy \& Geomat, Qingdao 266000, Shandong, Peoples R China.
   Yu, Peidong; Wang, Mengke, Shandong Univ Sci \& Technol, Coll Geodesy \& Geomat, Qingdao 266000, Shandong, Peoples R China.
   Chen, Huanjian, Wuhan Haida Cloud Technol Co LTD, Wuhan 430000, Hubei, Peoples R China.},
DOI = {10.1051/e3sconf/202020603014},
Article-Number = {03014},
ISSN = {2267-1242},
Research-Areas = {Environmental Sciences \& Ecology; Geology; Public, Environmental \&
   Occupational Health; Mining \& Mineral Processing},
Web-of-Science-Categories  = {Environmental Sciences; Geosciences, Multidisciplinary; Public,
   Environmental \& Occupational Health; Mining \& Mineral Processing},
Author-Email = {m17852327730@163.com},
Affiliations = {Shandong University of Science \& Technology},
Cited-References = {Cahalane C, 2015, ISPRS INT GEO-INF, V4, P302, DOI 10.3390/ijgi4010302.
   Chang L., 2019, REMOTE SENS-BASEL, V11.
   Gong Z, 2021, IEEE T INTELL TRANSP, V22, P734, DOI 10.1109/TITS.2019.2955734.
   Hu S., 2012, CHINESE J LASERS, V39, P161.
   Karam S, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080905.
   {[}宋凯 Song Kai], 2019, {[}测绘科学, Science of Surveying and Mapping], V44, P126.
   {[}吴波 Wu Bo], 2017, {[}测绘通报, Bulletin of Surveying and Mapping], P80.
   Yang B., 2019, SUSTAINABILITY-BASEL, V11.
   Zhang DD, 2019, INT GEOSCI REMOTE SE, P8984, DOI 10.1109/IGARSS.2019.8898669.
   Zhang S., 2019, INFRARED LASER ENG, V48, P148.},
Number-of-Cited-References = {10},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {6},
Doc-Delivery-Number = {BR6BJ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000659426200064},
OA = {gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000400048105126,
Author = {Mu, Beipeng and Giamou, Matthew and Paull, Liam and Agha-mohammadi,
   Ali-akbar and Leonard, John and How, Jonathan},
Book-Group-Author = {IEEE},
Title = {Information-based Active SLAM via Topological Feature Graphs},
DOI = {10.1109/CDC.2016.7799127},
Booktitle = {2016 IEEE 55TH CONFERENCE ON DECISION AND CONTROL (CDC)},
Series = {IEEE Conference on Decision and Control},
Year = {2016},
Pages = {5583-5590},
Note = {55th IEEE Conference on Decision and Control (CDC), Las Vegas, NV, DEC
   12-14, 2016},
Abstract = {Exploring an unknown space and building maps is a fundamental capability
   for mobile robots. For fully autonomous systems, the robot would further
   need to actively plan its paths during exploration. The problem of
   designing robot trajectories to actively explore an unknown environment
   and minimize the map error is referred to as active simultaneous
   localization and mapping (active SLAM). Existing work has focused on
   planning paths with occupancy grid maps, which do not scale well and
   suffer from long term drift. This work proposes a Topological Feature
   Graph (TFG) representation that scales well and develops an active SLAM
   algorithm with it. The TFG uses graphical models, which utilize
   independences between variables, and enables a unified quantification of
   exploration and exploitation gains with a single entropy metric. Hence,
   it facilitates a natural and principled balance between map exploration
   and refinement. A probabilistic roadmap path-planner is used to generate
   robot paths in real time. Experimental results demonstrate that the
   proposed approach achieves better accuracy than a standard grid-map
   based approach while requiring orders of magnitude less computation and
   memory resources.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Mu, B (Corresponding Author), MIT, Lab Informat \& Decis Syst, 77 Mass Ave, Cambridge, MA 02139 USA.
   Mu, Beipeng; Giamou, Matthew; How, Jonathan, MIT, Lab Informat \& Decis Syst, 77 Mass Ave, Cambridge, MA 02139 USA.
   Paull, Liam; Leonard, John, MIT, Comp Sci \& Artificial Intelligence Lab, 77 Mass Ave, Cambridge, MA USA.
   Agha-mohammadi, Ali-akbar, Qualcomm Res, 5775 Morehouse Dr, San Diego, CA USA.},
ISSN = {0743-1546},
ISBN = {978-1-5090-1837-6},
Keywords-Plus = {MOTION UNCERTAINTY},
Research-Areas = {Automation \& Control Systems; Engineering; Operations Research \&
   Management Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Operations Research \& Management Science},
Author-Email = {mubp@mit.edu
   mgiamou@mit.edu
   lpaull@mit.edu
   aliagha@qualcomm.com
   jleonard@mit.edu
   jhow@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT); Massachusetts Institute of
   Technology (MIT); Qualcomm},
Funding-Acknowledgement = {ARO MURI {[}W911NF-11-1-0391]; ONR {[}N00014-11-1-0688]; NSF
   {[}IIS-1318392]},
Funding-Text = {This research is supported in part by ARO MURI grant W911NF-11-1-0391,
   ONR grant N00014-11-1-0688 and NSF Award IIS-1318392.},
Cited-References = {Agha-Mohammadi AA, 2014, INT J ROBOT RES, V33, P268, DOI 10.1177/0278364913501564.
   Blackmore L, 2011, IEEE T ROBOT, V27, P1080, DOI 10.1109/TRO.2011.2161160.
   Bourgault E, 2002, INT ROB SYST 2002 IE, V1, P540.
   Carlone L, 2014, IEEE INT CONF ROBOT, P1140, DOI 10.1109/ICRA.2014.6906997.
   Carlone L, 2010, IEEE INT C INT ROBOT, P287, DOI 10.1109/IROS.2010.5652164.
   Carrillo H, 2012, IEEE INT CONF ROBOT, P2080, DOI 10.1109/ICRA.2012.6224890.
   Charrow B., 2015, P ROB SCI SYST ROM I.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Huang YF, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1426, DOI 10.1109/IROS.2009.5354168.
   Keidar Matan, 2011, Advanced Agent Technology. AAMAS 2011 Workshops AMPLE, AOSE, ARMS, DOCM3AS, ITMAS. Revised Selected Papers, P281.
   Leung C, 2008, IEEE INT CONF ROBOT, P1898, DOI 10.1109/ROBOT.2008.4543484.
   Martinez-Cantin R, 2009, AUTON ROBOT, V27, P93, DOI 10.1007/s10514-009-9130-2.
   Pillai  S., 2015, P ROB SCI SYST ROM I.
   Prentice S., 2009, INT J ROBOTICS RES.
   Rosen DM, 2012, IEEE INT CONF ROBOT, P1262, DOI 10.1109/ICRA.2012.6224646.
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x.
   Stachniss C., 2005, P ROB SCI SYST RSS C.
   Valencia R, 2012, IEEE INT C INT ROBOT, P1885, DOI 10.1109/IROS.2012.6385637.
   Vallv J., 2015, ROB AUT ICRA 2015 IE.
   van den Berg J, 2011, INT J ROBOT RES, V30, P895, DOI 10.1177/0278364911406562.
   Vidal-Calleja TA, 2010, IEEE T SYST MAN CY B, V40, P1567, DOI 10.1109/TSMCB.2010.2043528.
   Yamauchi B, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA `97, PROCEEDINGS, P146, DOI 10.1109/CIRA.1997.613851.},
Number-of-Cited-References = {23},
Times-Cited = {18},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {6},
Doc-Delivery-Number = {BH3UY},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000400048105126},
OA = {Green Submitted, Green Published},
DA = {2022-05-17},
}

@article{ WOS:000507505000016,
Author = {Ma, Teng and Li, Ye and Gong, Yusen and Wang, Rupeng and Sheng, Mingwei
   and Zhang, Qiang},
Title = {AUV Bathymetric Simultaneous Localisation and Mapping Using Graph Method},
Journal = {JOURNAL OF NAVIGATION},
Year = {2019},
Volume = {72},
Number = {6},
Pages = {1602-1622},
Month = {NOV},
Abstract = {Although topographic mapping missions and geological surveys carried out
   by Autonomous Underwater Vehicles (AUVs) are becoming increasingly
   prevalent, the lack of precise navigation in these scenarios still
   limits their application. This paper deals with the problems of
   long-term underwater navigation for AUVs and provides new mapping
   techniques by developing a Bathymetric Simultaneous Localisation And
   Mapping (BSLAM) method based on graph SLAM technology. To considerably
   reduce the calculation cost, the trajectory of the AUV is divided into
   various submaps based on Differences of Normals (DoN). Loop closures
   between submaps are obtained by terrain matching; meanwhile, maximum
   likelihood terrain estimation is also introduced to build weak data
   association within the submap. Assisted by one weight voting method for
   loop closures, the global and local trajectory corrections work together
   to provide an accurate navigation solution for AUVs with weak data
   association and inaccurate loop closures. The viability, accuracy and
   real-time performance of the proposed algorithm are verified with data
   collected onboard, including an 8 km planned track recorded at a speed
   of 4 knots in Qingdao, China.},
Publisher = {CAMBRIDGE UNIV PRESS},
Address = {32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA},
Type = {Article},
Language = {English},
Affiliation = {Li, Y (Corresponding Author), Harbin Engn Univ, Sci \& Technol Underwater Vehicle Lab, Harbin 150001, Peoples R China.
   Ma, Teng; Li, Ye; Gong, Yusen; Wang, Rupeng; Sheng, Mingwei; Zhang, Qiang, Harbin Engn Univ, Sci \& Technol Underwater Vehicle Lab, Harbin 150001, Peoples R China.},
DOI = {10.1017/S0373463319000286},
ISSN = {0373-4633},
EISSN = {1469-7785},
Keywords = {AUVs; Navigation; Graph SLAM; Terrain estimation.; Weight voting method},
Keywords-Plus = {TERRAIN NAVIGATION; SLAM; VEHICLE},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Marine; Oceanography},
Author-Email = {liyeheu103@163.com},
Affiliations = {Harbin Engineering University},
ResearcherID-Numbers = {MA, Teng/ABC-6356-2020},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2017YFC0305700]; open fund project
   of the Qingdao National Laboratory for Marine Science and Technology
   {[}QNLM2016ORP0406]; National Natural Science Foundation of China
   {[}51309066/E091002]},
Funding-Text = {This work was supported by the National Key R\&D Program of China
   (2017YFC0305700), open fund project of the Qingdao National Laboratory
   for Marine Science and Technology (QNLM2016ORP0406) and National Natural
   Science Foundation of China (51309066/E091002).},
Cited-References = {Anonsen KB, 2013, HUGIN AUV TERRAIN NA, P1.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Barkby S, 2012, INT J ROBOT RES, V31, P1409, DOI 10.1177/0278364912459666.
   Barkby S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P219, DOI 10.1109/IROS.2009.5354248.
   Chen P., 2016, THESIS.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Doble MJ, 2009, COLD REG SCI TECHNOL, V56, P90, DOI 10.1016/j.coldregions.2008.11.006.
   Donovan GT, 2012, IEEE J OCEANIC ENG, V37, P431, DOI 10.1109/JOE.2012.2190810.
   Feng Q. T., 2004, THESIS.
   Hagen OK, 2014, MAR TECHNOL SOC J, V48, P45, DOI 10.4031/MTSJ.48.2.6.
   Hurtos N, 2015, J FIELD ROBOT, V32, P123, DOI 10.1002/rob.21516.
   Ila V, 2017, INT J ROBOT RES, V36, P210, DOI 10.1177/0278364917691110.
   Johannsson H, 2010, P IEEE RSJ INT C INT.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kownacki C, 2016, ROBOTICA, V34, P243, DOI 10.1017/S0263574714001404.
   Li Y, 2017, J NAVIGATION, V70, P1062, DOI 10.1017/S037346331700011X.
   Mallios A, 2014, AUTON ROBOT, V36, P181, DOI 10.1007/s10514-013-9345-0.
   Nygren I, 2004, IEEE J OCEANIC ENG, V29, P906, DOI 10.1109/JOE.2004.833222.
   Nygren I., 2005, THESIS.
   Palomer A., 2013, P MTS IEEE OCEANS BE, P1.
   Palomer A, 2015, MUSEO PICTORICO ESCA, P1.
   Palomer A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040560.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Ribas D, 2008, J FIELD ROBOT, V25, P898, DOI 10.1002/rob.20249.
   Roman C., 2010, J FIELD ROBOT, V24, P23.
   Rosen DM, 2012, IEEE INT CONF ROBOT, P1262, DOI 10.1109/ICRA.2012.6224646.
   Stuckey R.A., 2012, IFAC P, V45, P118, DOI {[}10.3182/20120410-3-PT-4028.00021, DOI 10.3182/20120410-3-PT-4028.00021].
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Wang N, 2018, IEEE T FUZZY SYST, V26, P1613, DOI 10.1109/TFUZZ.2017.2737405.
   Wang N, 2017, OCEAN ENG, V145, P406, DOI 10.1016/j.oceaneng.2017.09.062.
   Zhou L, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040680.},
Number-of-Cited-References = {32},
Times-Cited = {1},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {27},
Journal-ISO = {J. Navig.},
Doc-Delivery-Number = {KC9PZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000507505000016},
DA = {2022-05-17},
}

@article{ WOS:000337363900009,
Author = {Havangi, R. and Nekoui, M. A. and Teshnehlab, M. and Taghirad, H. D.},
Title = {A SLAM based on auxiliary marginalised particle filter and differential
   evolution},
Journal = {INTERNATIONAL JOURNAL OF SYSTEMS SCIENCE},
Year = {2014},
Volume = {45},
Number = {9},
Pages = {1913-1926},
Abstract = {FastSLAM is a framework for simultaneous localisation and mapping (SLAM)
   using a Rao-Blackwellised particle filter. In FastSLAM, particle filter
   is used for the robot pose (position and orientation) estimation, and
   parametric filter (i.e. EKF and UKF) is used for the feature location's
   estimation. However, in the long term, FastSLAM is an inconsistent
   algorithm. In this paper, a new approach to SLAM based on hybrid
   auxiliary marginalised particle filter and differential evolution (DE)
   is proposed. In the proposed algorithm, the robot pose is estimated
   based on auxiliary marginal particle filter that operates directly on
   the marginal distribution, and hence avoids performing importance
   sampling on a space of growing dimension. In addition, static map is
   considered as a set of parameters that are learned using DE. Compared to
   other algorithms, the proposed algorithm can improve consistency for
   longer time periods and also, improve the estimation accuracy.
   Simulations and experimental results indicate that the proposed
   algorithm is effective.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Havangi, R (Corresponding Author), KN Toosi Univ Technol, Dept Syst \& Control, Tehran, Iran.
   Havangi, R.; Nekoui, M. A.; Teshnehlab, M.; Taghirad, H. D., KN Toosi Univ Technol, Dept Syst \& Control, Tehran, Iran.},
DOI = {10.1080/00207721.2012.759299},
ISSN = {0020-7721},
EISSN = {1464-5319},
Keywords = {FastSLAM; auxiliary marginal particle filter; differential evolution},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; PARAMETER-ESTIMATION; UNSCENTED FASTSLAM;
   CONVERGENCE; CONSISTENCY; ALGORITHM; ROBUST; STATE},
Research-Areas = {Automation \& Control Systems; Computer Science; Operations Research \&
   Management Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Theory \& Methods;
   Operations Research \& Management Science},
Author-Email = {havangi@kntu.ac.ir},
Affiliations = {K. N. Toosi University of Technology},
ResearcherID-Numbers = {Taghirad, Hamid D./AAH-2276-2019
   },
ORCID-Numbers = {Taghirad, Hamid D./0000-0002-0615-6730
   , ramazan/0000-0001-5711-3127},
Cited-References = {Bailey T, 2006, IEEE INT CONF ROBOT, P424, DOI 10.1109/ROBOT.2006.1641748.
   Chang CS, 2004, INT J SYST SCI, V35, P731, DOI 10.1080/00207720412331303624.
   Chen T, 2005, J PROCESS CONTR, V15, P665, DOI 10.1016/j.jprocont.2005.01.001.
   Crisan D, 2002, IEEE T SIGNAL PROCES, V50, P736, DOI 10.1109/78.984773.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Doucet A, 2003, ANN I STAT MATH, V55, P409, DOI 10.1007/BF02530508.
   Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123.
   Engelbrecht AP., 2007, COMPUTATIONAL INTELL.
   GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004.
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811.
   Kantas N., 2009, P 15 IFAC S SYST ID, V15, P774, DOI DOI 10.3182/20090706-3-FR-2004.00129.
   Kim C, 2008, IEEE T ROBOT, V24, P808, DOI 10.1109/TRO.2008.924946.
   Kim C, 2007, IEEE INT CONF ROBOT, P2439, DOI 10.1109/ROBOT.2007.363685.
   Kim I, 2009, ROBOTICA, V27, P853, DOI 10.1017/S0263574708005250.
   Klaas M., 2005, P 21 ANN C UNC ART I, P308.
   Kwak N, 2008, ROBOTICA, V26, P205, DOI 10.1017/S0263574707003773.
   Kwak N, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P636.
   Lee HC, 2009, IEEE SYS MAN CYBERN, P2763, DOI 10.1109/ICSMC.2009.5346572.
   Martinez-Cantin R, 2007, IEEE INT CONF ROBOT, P2415, DOI 10.1109/ROBOT.2007.363681.
   Montemerlo M., 2003, P 18 INT JOINT C ART, P1151.
   Poyiadjis G., 2005, P AM STAT ASS, P2279.
   Rodriguez-Losada D, 2009, J INTELL ROBOT SYST, V55, P109, DOI 10.1007/s10846-008-9296-4.
   Thrun S., 2004, J MACH LEARN RES, V4, P380.
   Wills A., 2008, P 17 IFAC WORLD C SE, P4012.
   Wu H, 2011, INT J SYST SCI, V42, P407, DOI 10.1080/00207720903572422.
   Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464.},
Number-of-Cited-References = {26},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {13},
Journal-ISO = {Int. J. Syst. Sci.},
Doc-Delivery-Number = {AJ0RR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000337363900009},
DA = {2022-05-17},
}

@article{ WOS:000385157300010,
Author = {Chaves, Stephen M. and Kim, Ayoung and Galceran, Enric and Eustice, Ryan
   M.},
Title = {Opportunistic sampling-based active visual SLAM for underwater
   inspection},
Journal = {AUTONOMOUS ROBOTS},
Year = {2016},
Volume = {40},
Number = {7, SI},
Pages = {1245-1265},
Month = {OCT},
Abstract = {This paper reports on an active SLAM framework for performing
   large-scale inspections with an underwater robot. We propose a path
   planning algorithm integrated with visual SLAM that plans loop-closure
   paths in order to decrease navigation uncertainty. While loop-closing
   revisit actions bound the robot's uncertainty, they also lead to
   redundant area coverage and increased path length. Our proposed
   opportunistic framework leverages sampling-based techniques and
   information filtering to plan revisit paths that are coverage efficient.
   We employ Gaussian process regression for modeling the prediction of
   camera registrations and use a two-step optimization procedure for
   selecting revisit actions. We show that the proposed method offers many
   benefits over existing solutions and good performance for bounding
   navigation uncertainty in long-term autonomous operations with hybrid
   simulation experiments and real-world field trials performed by an
   underwater inspection robot.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Chaves, SM (Corresponding Author), Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48109 USA.
   Chaves, Stephen M.; Eustice, Ryan M., Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M., Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M., Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Kim, Ayoung, Korea Adv Inst Sci \& Technol, Dept Civil \& Environm Engn, Daejeon, South Korea.
   Eustice, Ryan M., Swiss Fed Inst Technol, ASL, Zurich, Switzerland.},
DOI = {10.1007/s10514-016-9597-6},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Active SLAM; Sampling-based planning; Gaussian processes; Underwater
   robotics},
Keywords-Plus = {SHIP HULL INSPECTION; BELIEF SPACE; SIMULTANEOUS LOCALIZATION;
   NAVIGATION; ENVIRONMENTS; EXPLORATION; UNCERTAINTY; COVARIANCE;
   PERCEPTION; ALGORITHMS},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {schaves@umich.edu
   ayoungk@kaist.ac.kr
   enricg@ethz.ch
   eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan; University of Michigan System;
   University of Michigan; Korea Advanced Institute of Science \&
   Technology (KAIST); ETH Zurich},
Funding-Acknowledgement = {Office of Naval Research {[}N00014-12-1-0092]; Department of Defense},
Funding-Text = {This work was supported by the Office of Naval Research under award
   N00014-12-1-0092, monitored by Dr. T. Swean and T. Kick. We would like
   to thank J. Vaganay from Bluefin Robotics and P. Ozog for their support
   during testing. S. Chaves was supported by The SMART Scholarship for
   Service Program by the Department of Defense.},
Cited-References = {Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968.
   Barkby S, 2011, IEEE INT C INT ROBOT, P1242, DOI 10.1109/IROS.2011.6048284.
   Bourgault F, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P540, DOI 10.1109/IRDS.2002.1041446.
   Bry Adam, 2011, IEEE International Conference on Robotics and Automation, P723.
   Chaves SM, 2014, IEEE INT C INT ROBOT, P3073, DOI 10.1109/IROS.2014.6942987.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Eustice RM, 2006, INT J ROBOT RES, V25, P1223, DOI 10.1177/0278364906072512.
   Feder HJS, 1999, INT J ROBOT RES, V18, P650, DOI 10.1177/02783649922066484.
   Galceran E, 2013, IEEE INT C INT ROBOT, P6006, DOI 10.1109/IROS.2013.6697228.
   Gonzalez-Banos HH, 2002, INT J ROBOT RES, V21, P829, DOI 10.1177/0278364902021010834.
   Hand DJ, 2008, STAT VERY SHORT INTR.
   Hollinger GA, 2014, INT J ROBOT RES, V33, P1271, DOI 10.1177/0278364914533443.
   Hover FS, 2012, INT J ROBOT RES, V31, P1445, DOI 10.1177/0278364912461059.
   Indelman V, 2015, INT J ROBOT RES, V34, P849, DOI 10.1177/0278364914561102.
   Kaess M., 2013, OPEN SOURCE IMPLEMEN.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761.
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439.
   Kim A, 2015, INT J ROBOT RES, V34, P457, DOI 10.1177/0278364914547893.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   LaValle SM, 2001, INT J ROBOT RES, V20, P378, DOI 10.1177/02783640122067453.
   Melkumyan A, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1936.
   O'Callaghan ST, 2012, INT J ROBOT RES, V31, P42, DOI 10.1177/0278364911421039.
   Olson Edwin, 2011, 2011 IEEE International Conference on Robotics and Automation, P3400.
   Ozog P, 2016, J FIELD ROBOT, V33, P265, DOI 10.1002/rob.21582.
   Patil S., 2014, P INT WORKSH ALG FDN.
   Prentice S, 2009, INT J ROBOT RES, V28, P1448, DOI 10.1177/0278364909341659.
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1.
   Sim R, 2005, IEEE INT CONF ROBOT, P661.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Stachniss C., 2005, P ROB SCI SYST C CAM.
   Valencia Rafael, 2011, 2011 IEEE International Conference on Robotics and Automation, P78.
   Valencia R, 2013, IEEE T ROBOT, V29, P1050, DOI 10.1109/TRO.2013.2257577.
   Valencia R, 2012, IEEE INT C INT ROBOT, P1885, DOI 10.1109/IROS.2012.6385637.
   van den Berg J, 2012, INT J ROBOT RES, V31, P1263, DOI 10.1177/0278364912456319.
   Whaite P, 1997, IEEE T PATTERN ANAL, V19, P193, DOI 10.1109/34.584097.},
Number-of-Cited-References = {38},
Times-Cited = {9},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {42},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {DY5QT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000385157300010},
DA = {2022-05-17},
}

@article{ WOS:000400893600039,
Author = {Schmuck, Patrik and Scherer, Sebastian A. and Zell, Andreas},
Title = {Hybrid Metric-Topological 3D Occupancy Grid Maps for Large-scale Mapping},
Journal = {IFAC PAPERSONLINE},
Year = {2016},
Volume = {49},
Number = {15},
Pages = {230-235},
Note = {9th IFAC Symposium on Intelligent Autonomous Vehicles (IAV), Leipzig,
   GERMANY, JUN 29-JUL 01, 2016},
Abstract = {This paper presents a large-scale 3D environment mapping solution for
   mobile robots that is based on hybrid metric-topological maps. I a robot
   performs simultaneous localization and mapping (SLAM) while exploring an
   unknown environment, sometimes loops are closed and the whole SLAM graph
   has to he optimized. If a conventional occupancy grid mapping algorithm
   using a monolithic map is used, the whole occupancy grid map has to be
   rebuilt, after optimization, which for large maps can easily become too
   time consuming for real-time operation. In the same way, path planning
   on very large occupancy grid maps can become convutationally too
   expensive. Hybrid metric-topological maps can solve both problems. The
   global metric map is divided into sub mapsand a global topological graph
   is formed on the map. This allows recomputitig only isolated areas of
   the limp, whereas (Alters can remain Utiellatiged. The topological graph
   allows efficient path planning on the hybrid map. We show that the
   hybrid mapping approach presented here is considerably faster than
   conventional methods. Within the same time, it can generate more
   detailed maps of large environments. The computation time for maps with
   identical level of detail can he improved by up to two orders of
   magnitude. (C) 2016, IFAC (International Federation of Automatic
   Control) Hosting by Elsevier Ltd. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Schmuck, P (Corresponding Author), Eberhard Karls Univ Tubingen, Chair Cognit Syst, Tubingen, Germany.
   Schmuck, Patrik; Scherer, Sebastian A.; Zell, Andreas, Eberhard Karls Univ Tubingen, Chair Cognit Syst, Tubingen, Germany.},
DOI = {10.1016/j.ifacol.2016.07.738},
ISSN = {2405-8963},
Keywords = {Autonomous mobile robots; SLAM; Hybrid maps; Metric-topological maps;
   Large-scale mapping; Long-term autonomy},
Keywords-Plus = {SLAM},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {patrik.schmuck@uni-tuebingen.de
   sebastian.scherer@uni-tuebingen.de
   andreas.zell@uni-tuebingen.de},
Affiliations = {Eberhard Karls University of Tubingen},
ORCID-Numbers = {Schmuck, Patrik/0000-0002-5822-8441},
Cited-References = {ARUN KS, 1987, SYSTEMS MAN CYBERN A, P698.
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
   Bazeille S., 2011, EUR C MOB ROB, P303.
   Bosse M., 2004, INT J ROBOT RES, V23.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Jia S., 2012, P INT C INF AUT ICIA.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   Konolige K., 2010, INT J ROBOTICS RES.
   Lim H, 2014, IEEE INT CONF ROBOT, P1532, DOI 10.1109/ICRA.2014.6907055.
   Lim J., 2012, INT J ROBOT RES, V31.
   Maier R, 2014, LECT NOTES COMPUT SC, V8753, P54, DOI 10.1007/978-3-319-11752-2\_5.
   Parys R, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION \& TRANSMISSION (3DIMPVT 2012), P416, DOI 10.1109/3DIMPVT.2012.83.
   Paz LM, 2008, IEEE T ROBOT, V24, P1107, DOI 10.1109/TRO.2008.2004639.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Schmuck P., 2015, THESIS.
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7.
   Zivkovic Z, 2006, IEEE INT CONF ROBOT, P803.},
Number-of-Cited-References = {20},
Times-Cited = {14},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Journal-ISO = {IFAC PAPERSONLINE},
Doc-Delivery-Number = {EU2XQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)},
Unique-ID = {WOS:000400893600039},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000350047900008,
Author = {Bacca, Bladimir and Salvi, Joaquim and Cufi, Xavier},
Editor = {Sandri, S and SanchezMarre, M and Cortes, U},
Title = {Appearance-Based SLAM for Mobile Robots},
Booktitle = {ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT},
Series = {Frontiers in Artificial Intelligence and Applications},
Year = {2009},
Volume = {202},
Pages = {55-64},
Note = {12th International Conference of the
   Catalan-Association-for-Artificial-Intelligence (CCIA), Cardona, SPAIN,
   OCT 21-23, 2009},
Abstract = {This paper reviews new challenges in the area of long-term navigation,
   and new approaches to environment representation and robots capable of
   coping with dynamic environments. As a result of this review, we propose
   an appearance-based simultaneous localization and mapping (SLAM)
   solution which represents the robot environment using an
   appearance-based topological map. Dynamic environment changes are dealt
   with using human memory and fixed action pattern concepts. The former is
   used to build a histogram to register local feature stability, the
   latter for robot navigation purposes. We take omnidirectional vision and
   laser range data to extract textured 2D scans as global features, and
   textured-vertical edges as local features for map updating and robot
   localization. From the navigational point of view, we consider visual
   potential field-based behavior to adjust high level motion commands.},
Publisher = {IOS PRESS},
Address = {NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bacca, B (Corresponding Author), Univ Girona, Campus Montilivi,Bldg P-4, Girona 17071, Spain.
   Bacca, Bladimir, Univ Valle, Cali, Colombia.
   Bacca, Bladimir; Salvi, Joaquim; Cufi, Xavier, Univ Girona, Girona, Spain.},
DOI = {10.3233/978-1-60750-061-2-55},
ISSN = {0922-6389},
EISSN = {1879-8314},
ISBN = {978-1-60750-465-8; 978-1-60750-061-2},
Keywords = {Mapping; localization; computer vision},
Keywords-Plus = {MAPS; NAVIGATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods},
Author-Email = {bladimir@eia.udg.edu},
Affiliations = {Universidad del Valle; Universitat de Girona},
ResearcherID-Numbers = {Salvi, Joaquim/L-2648-2014
   },
ORCID-Numbers = {Salvi, Joaquim/0000-0002-9482-7126
   Bacca Cortes, Bladimir/0000-0003-0113-4134},
Cited-References = {Angeli A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1031, DOI 10.1109/IROS.2008.4650675.
   ARKIN RC, 1998, INTEL ROB AUTON AGEN, P1.
   Atkinson, 1968, PSYCHOL LEARNING MOT, V2, P89, DOI {[}DOI 10.1016/S0079-7421(08)60422-3, 10.1016/s0079-7421(08)60422-3.].
   BAILEY T, 2006, ROBOTICS AUTOMATION.
   Barber R, 2000, THESIS U CARLOS 3 MA.
   Blanco JL, 2009, ROBOT AUTON SYST, V57, P64, DOI 10.1016/j.robot.2008.02.002.
   Bonin-Font F, 2008, J INTELL ROBOT SYST, V53, P263, DOI 10.1007/s10846-008-9235-4.
   Booij O., 2008, DAT ASS WORKSH 28 JU.
   Booij O, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1510, DOI 10.1109/IROS.2006.281980.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Fleck S., 2006, COMP ROBOT VIS, P19.
   Folkesson J, 2007, IEEE T ROBOT, V23, P1024, DOI 10.1109/TRO.2007.903807.
   Gaspar J, 2007, STUD COMPUT INTELL, V70, P223.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Gross H, 2005, IEEE SYS MAN CYBERN, P3510.
   Jensen B., 2005, LASER RANGE IMAGING.
   Linaker F, 2006, ROBOT AUTON SYST, V54, P205, DOI 10.1016/j.robot.2005.11.003.
   Llinas R., 2001, I VORTEX NEURONS SEL.
   MARTINEZ O, 2006, P IEEE RSJ IROS WORK, P1742.
   MEI C, 2006, OMNIDIRECTIONAL CALI.
   Micusik B., 2003, P INT C COMP VIS PAT.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Nieto J, 2007, ROBOT AUTON SYST, V55, P39, DOI 10.1016/j.robot.2006.06.008.
   Nuchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001.
   Porta J. M., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3424.
   Remazeilles A, 2006, IEEE INT CONF ROBOT, P2719, DOI 10.1109/ROBOT.2006.1642112.
   Saedan M., 2006, P 2006 IEEE INT C ME, P17.
   Salvi J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1011, DOI 10.1109/IROS.2008.4650627.
   Scaramuzza D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4170, DOI 10.1109/iros.2007.4399276.
   Sim R, 2009, IMAGE VISION COMPUT, V27, P167, DOI 10.1016/j.imavis.2008.04.003.
   Weingarten J., 2006, THESIS EPFL.
   Wolf DF, 2008, IEEE T ROBOT, V24, P245, DOI 10.1109/TRO.2008.917001.
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.
   {[}No title captured].},
Number-of-Cited-References = {35},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BC1ER},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000350047900008},
DA = {2022-05-17},
}

@inproceedings{ WOS:000446394503135,
Author = {Siva, Sriram and Zhang, Hao},
Book-Group-Author = {IEEE},
Title = {Omnidirectional Multisensory Perception Fusion for Long-Term Place
   Recognition},
DOI = {10.1109/ICRA.2018.8461042},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2018},
Pages = {5175-5181},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Brisbane, AUSTRALIA, MAY 21-25, 2018},
Abstract = {Over the recent years, long-term place recognition has attracted an
   increasing attention to detect loops for largescale Simultaneous
   Localization and Mapping (SLAM) in loopy environments during long-term
   autonomy. Almost all existing methods are designed to work with
   traditional cameras with a limited field of view. Recent advances in
   omnidirectional sensors offer a robot an opportunity to perceive the
   entire surrounding environment. However, no work has existed thus far to
   research how omnidirectional sensors can help long-term place
   recognition, especially when multiple types of omnidirectional sensory
   data are available. In this paper, we propose a novel approach to
   integrate observations obtained from multiple sensors from different
   viewing angles in the omnidirectional observation in order to perform
   multi-directional place recognition in longterm autonomy. Our approach
   also answers two new questions when omnidirectional multisensory data is
   available for place recognition, including whether it is possible to
   recognize a place with long-term appearance variations when robots
   approach it from various directions, and whether observations from
   various viewing angles are the same informative. To evaluate our
   approach and hypothesis, we have collected the first largescale dataset
   that consists of omnidirectional multisensory (intensity and depth) data
   collected in urban and suburban environments across a year. Experimental
   results have shown that our approach is able to achieve
   multi-directional long-term place recognition, and identifies the most
   discriminative viewing angles from the omnidirectional observation.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Siva, S (Corresponding Author), Colorado Sch Mines, Human Ctr Robot Lab, Dept Comp Sci, Golden, CO 80401 USA.
   Siva, Sriram; Zhang, Hao, Colorado Sch Mines, Human Ctr Robot Lab, Dept Comp Sci, Golden, CO 80401 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-5386-3081-5},
Keywords-Plus = {SCENE},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {sivasriram@mines.edu
   hzhang@mines.edu},
Affiliations = {Colorado School of Mines},
ORCID-Numbers = {Zhang, Hao/0000-0001-8043-9184},
Funding-Acknowledgement = {ARO {[}W911NF-17-1-0447]},
Funding-Text = {This work was funded in part by the ARO grant W911NF-17-1-0447.},
Cited-References = {Arroyo R., 2015, INT C ROB AUT.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Chen C, 2006, INT J ROBOT RES, V25, P953, DOI 10.1177/0278364906068375.
   Chen Zetao, 2014, AUSTR C ROB AUT.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dalal Navneet, 2005, C COMP VIS PATT REC.
   Han F., 2018, LEARNING INTEGRATED.
   Han F, 2017, IEEE ROBOT AUTOM LET, V2, P1172, DOI 10.1109/LRA.2017.2662061.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Milford M. J., 2004, INT C ROB AUT.
   Milford M. J., 2012, INT C ROB AUT.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer T., 2014, C ART INT.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2.
   Salas-Moreno R. F., 2013, C COMP VIS PATT REC.
   Sunderhauf N., 2015, INTELLIGENT ROBOTS S.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Zhang H, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII.},
Number-of-Cited-References = {20},
Times-Cited = {12},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BL0QZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000446394503135},
DA = {2022-05-17},
}

@article{ WOS:000696741000004,
Author = {Chen, Mingyou and Tang, Yunchao and Zou, Xiangjun and Huang, Zhaofeng
   and Zhou, Hao and Chen, Siyu},
Title = {3D global mapping of large-scale unstructured orchard integrating
   eye-in-hand stereo vision and SLAM},
Journal = {COMPUTERS AND ELECTRONICS IN AGRICULTURE},
Year = {2021},
Volume = {187},
Pages = {106237},
Month = {AUG},
Abstract = {Large-scale, high-accuracy, and adaptive three-dimensional (3D)
   perception are the basic technical requirements for constructing a
   practical and stable fruit-picking robot. The latest vision-based
   fruit-picking robots have been able to adapt to the complex background,
   uneven lighting and low color contrast of the orchard environment.
   However, most of them have, until now, been limited to a small field of
   view or rigid sampling manners. Although the simultaneous localization
   and mapping (SLAM) methods have the potential to realize large scale
   sensing, it was critically revealed in this study that the classic SLAM
   pipeline is not completely adapted to orchard picking tasks. In this
   study, the eye-in-hand stereo vision and SLAM system were integrated to
   provide detailed global map supporting long-term, flexible and
   large-scale orchard picking. To be specific, a mobile robot based on
   eye-in-hand vision was built and an effective hand-eye calibration
   method was proposed; a state-of-theart object detection network was
   trained and used to establish a dynamic stereo matching method adapted
   well to complex orchard environments; a SLAM system was deployed and
   combined with the above eye-in-hand stereo vision system to obtain a
   detailed, wide 3D orchard map. The main contribution of this work is to
   build a new global mapping framework compatible to the nature of orchard
   picking tasks. Compared with the existing studies, this work pays more
   attention to the structural details of the orchard. Experimental results
   indicated that the constructed global map achieved both large-scale and
   high-resolution. This is an exploratory work providing theoretical and
   technical references for the future research on more stable, accurate
   and practical mobile fruit picking robots.},
Publisher = {ELSEVIER SCI LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Zou, XJ (Corresponding Author), South China Agr Univ, Coll Engn, Key Lab Key Technol Agr Machine \& Equipment, Guangzhou 510642, Peoples R China.
   Tang, YC (Corresponding Author), Zhongkai Univ Agr \& Engn, Coll Urban \& Rural Construct, Guangzhou 510006, Peoples R China.
   Tang, YC; Zou, XJ (Corresponding Author), Foshan Zhongke Innovat Res Inst Intelligent Agr \&, Guangzhou, Peoples R China.
   Chen, Mingyou; Zou, Xiangjun; Huang, Zhaofeng; Zhou, Hao; Chen, Siyu, South China Agr Univ, Coll Engn, Key Lab Key Technol Agr Machine \& Equipment, Guangzhou 510642, Peoples R China.
   Tang, Yunchao, Zhongkai Univ Agr \& Engn, Coll Urban \& Rural Construct, Guangzhou 510006, Peoples R China.
   Chen, Mingyou; Tang, Yunchao; Zou, Xiangjun, Foshan Zhongke Innovat Res Inst Intelligent Agr \&, Guangzhou, Peoples R China.},
DOI = {10.1016/j.compag.2021.106237},
EarlyAccessDate = {JUN 2021},
Article-Number = {106237},
ISSN = {0168-1699},
EISSN = {1872-7107},
Keywords = {Fruit-picking robot; 3D mapping; Stereo vision; SLAM; Stereo matching},
Keywords-Plus = {LITCHI CLUSTERS; LOCALIZATION; CALIBRATION; FUSION; CAMERA; FRUIT; LIDAR},
Research-Areas = {Agriculture; Computer Science},
Web-of-Science-Categories  = {Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications},
Author-Email = {ryan.twain@zhku.edu.cn
   xjzou1@163.com},
Affiliations = {South China Agricultural University; Zhongkai University of Agriculture
   \& Engineering},
ResearcherID-Numbers = {Tang, Yunchao/T-6632-2019},
ORCID-Numbers = {Tang, Yunchao/0000-0002-6178-4457},
Funding-Acknowledgement = {Special Funding Project of Guang-dong Enterprise Science and Technology
   Commissioner {[}GDKTP2020029500]; Key-area Research and Development
   Program of Guangdong Province {[}2019B020223003]; Major scientific
   research projects of Guangdong Province {[}2020KZDZX1037]},
Funding-Text = {This work was supported by the Special Funding Project of Guangdong
   Enterprise Science and Technology Commissioner (GDKTP2020029500) , the
   Key-area Research and Development Pro-gram of Guangdong Province
   (2019B020223003) , and the Major sci-entific research projects of
   Guangdong Province (2020KZDZX1037) .},
Cited-References = {Aguiar AS, 2020, ROBOTICS, V9, DOI 10.3390/robotics9040097.
   Andreff N., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P430, DOI 10.1109/IM.1999.805374.
   Capua F. Raverta, 2018, ARG C AUT CONTR, P1, DOI {[}10.23919/AADECA.2018.8577360, DOI 10.23919/AADECA.2018.8577360].
   Chebrolu N, 2017, INT J ROBOT RES, V36, P1045, DOI 10.1177/0278364917720510.
   Chen MY, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105508.
   Chen XY, 2018, COMPUT ELECTRON AGR, V147, P91, DOI 10.1016/j.compag.2018.02.009.
   Daniilidis K, 1999, INT J ROBOT RES, V18, P286, DOI 10.1177/02783649922066213.
   Dong WB, 2020, J FIELD ROBOT, V37, P97, DOI 10.1002/rob.21876.
   Fan YX, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111845.
   Gan H., 2017, 2017 ASABE ANN INT M, P1, DOI {[}10.13031/aim.201700164, DOI 10.13031/AIM.201700164].
   Gao XY, 2018, IEEE ACCESS, V6, P49248, DOI 10.1109/ACCESS.2018.2868848.
   Ge YY, 2020, BIOSYST ENG, V197, P188, DOI 10.1016/j.biosystemseng.2020.07.003.
   Ge YY, 2019, IEEE ACCESS, V7, P147642, DOI 10.1109/ACCESS.2019.2946369.
   Habibie N., 2018, MHS 2017, P1.
   Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56.
   HORAUD R, 1995, INT J ROBOT RES, V14, P195, DOI 10.1177/027836499501400301.
   Ivanov M, 2020, IEEE-CAA J AUTOMATIC, V7, P368, DOI 10.1109/JAS.2020.1003027.
   Jia ZY, 2015, OPT EXPRESS, V23, P15205, DOI 10.1364/OE.23.015205.
   Katikaridis D., 2019, LARGE SCALE POINT CL.
   Li JH, 2020, IEEE ACCESS, V8, P117746, DOI 10.1109/ACCESS.2020.3005386.
   Lin GC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020428.
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913.
   Nellithimaru AK, 2019, IEEE COMPUT SOC CONF, P2648, DOI 10.1109/CVPRW.2019.00321.
   PARK FC, 1994, IEEE T ROBOTIC AUTOM, V10, P717, DOI 10.1109/70.326576.
   Pierzchala M, 2018, COMPUT ELECTRON AGR, V145, P217, DOI 10.1016/j.compag.2017.12.034.
   Ramirez-Hernandez LR, 2020, INT J ADV ROBOT SYST, V17, DOI 10.1177/1729881419896717.
   Shalal N, 2015, COMPUT ELECTRON AGR, V119, P254, DOI 10.1016/j.compag.2015.09.025.
   Silwal A, 2017, J FIELD ROBOT, V34, P1140, DOI 10.1002/rob.21715.
   Tan M., 2020, P IEEE ICVF C COMOP, p10 781.
   Tan MX, 2019, PR MACH LEARN RES, V97.
   Tang YC, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00510.
   Tang YC, 2019, ROBOT CIM-INT MANUF, V59, P36, DOI 10.1016/j.rcim.2019.03.001.
   TSAI RY, 1989, IEEE T ROBOTIC AUTOM, V5, P345, DOI 10.1109/70.34770.
   Underwood JP, 2016, COMPUT ELECTRON AGR, V130, P83, DOI 10.1016/j.compag.2016.09.014.
   Wibowo TS, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P444, DOI 10.1109/ELECSYM.2016.7861047.
   Williams HAM, 2019, BIOSYST ENG, V181, P140, DOI 10.1016/j.biosystemseng.2019.03.007.
   Xiong JT, 2018, BIOSYST ENG, V166, P44, DOI 10.1016/j.biosystemseng.2017.11.005.
   Zhang T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010093.
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718.
   Zhao W, 2020, IEEE ACCESS, V8, P221975, DOI 10.1109/ACCESS.2020.3043662.},
Number-of-Cited-References = {40},
Times-Cited = {23},
Usage-Count-Last-180-days = {18},
Usage-Count-Since-2013 = {25},
Journal-ISO = {Comput. Electron. Agric.},
Doc-Delivery-Number = {UR4SL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000696741000004},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@article{ WOS:000329510300002,
Author = {Latif, Yasir and Cadena, Cesar and Neira, Jose},
Title = {Robust loop closing over time for pose graph SLAM},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1611-1626},
Month = {DEC},
Abstract = {Long-term autonomous mobile robot operation requires considering place
   recognition decisions with great caution. A single incorrect decision
   that is not detected and reconsidered can corrupt the environment model
   that the robot is trying to build and maintain. This work describes a
   consensus-based approach to robust place recognition over time, that
   takes into account all the available information to detect and remove
   past incorrect loop closures. The main novelties of our work are: (1)
   the ability of realizing that, in light of new evidence, an incorrect
   past loop closing decision has been made; the incorrect information can
   be removed thus recovering the correct estimation with a novel
   algorithm; (2) extending our proposal to incremental operation; and (3)
   handling multi-session, spatially related or unrelated scenarios in a
   unified manner. We demonstrate our proposal, the RRR algorithm, on
   different odometry systems, e.g. visual or laser, using different
   front-end loop-closing techniques. For our experiments we use the
   efficient graph optimization framework g2o as back-end. We back our
   claims up with several experiments carried out on real data, in single
   and multi-session experiments showing better results than those obtained
   by state-of-the-art methods, comparisons against whom are also
   presented.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Latif, Y (Corresponding Author), Univ Zaragoza, I3A, Zaragoza 50018, Spain.
   Latif, Yasir; Neira, Jose, Univ Zaragoza, I3A, Zaragoza 50018, Spain.
   Cadena, Cesar, George Mason Univ, Dept Comp Sci, Volgenau Sch Engn, Fairfax, VA 22030 USA.},
DOI = {10.1177/0278364913498910},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Robust place recognition; long term autonomy; pose graph SLAM;
   multi-session SLAM; consensus algorithms},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {ylatif@unizar.es},
Affiliations = {University of Zaragoza; George Mason University},
ResearcherID-Numbers = {Cadena, Cesar/AAM-4987-2020
   Neira, Jose/AAM-6571-2020
   Neira, Jose/F-8887-2013
   },
ORCID-Numbers = {Cadena, Cesar/0000-0002-2972-6011
   Neira, Jose/0000-0003-0668-977X
   Latif, Yasir/0000-0002-2529-5322},
Funding-Acknowledgement = {Direccion General de Investigacion of Spain {[}DPI2012-36070,
   DPI2009-13710, DPI2009-07130]; DGA-FSE (Group T04); US Army Research
   Office {[}W911NF-1110476]},
Funding-Text = {This research has been partially funded by the Direccion General de
   Investigacion of Spain under projects DPI2012-36070, DPI2009-13710,
   DPI2009-07130, by DGA-FSE (Group T04) and by US Army Research Office
   (grant number W911NF-1110476).},
Cited-References = {Agamennoni G, 2011, IEEE INT CONF ROBOT, P1551.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Carrillo H, 2012, IEEE INT C INT ROBOT, P2504, DOI 10.1109/IROS.2012.6385927.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Grisetti G, 2010, IEEE INT CONF ROBOT, P273, DOI 10.1109/ROBOT.2010.5509407.
   HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503.
   Johannsson H, 2012, RSS WORKSH LONG TERM.
   Kaess M, 2011, IEEE INT CONF ROBOT.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Kummerle R., 2011, P IEEE INT C ROB AUT.
   Latif Y, 2012, P IEEE RJS INT C INT.
   Latif Y, 2012, P ROB SCI SYST SYDN.
   McDonald J, 2012, ROBOTICS AU IN PRESS, DOI 10.1016/j.robot.2012.08.008.
   Olson E, 2012, P ROB SCI SYST SYDN.
   Olson E, 2012, J FIELD ROBOT, V29, P762, DOI 10.1002/rob.21426.
   Olson E, 2009, ROBOT AUTON SYST, V57, P1157, DOI 10.1016/j.robot.2009.07.021.
   Ranganathan A, 2011, INT J ROBOT RES, V30, P755, DOI 10.1177/0278364910393287.
   Rituerto A, 2012, ROBOTICS AU IN PRESS.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Sunderhauf N, 2012, P IEEE RJS INT C INT.
   Tardos JD, 2009, RAWSEEDS ROBOTICS AD.
   Valencia R, 2011, IEEE INT CONF ROBOT.
   Walcott-Bryant A, 2012, P IEEE RJS INT C INT.},
Number-of-Cited-References = {27},
Times-Cited = {106},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {69},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300002},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000361788200094,
Author = {Tang, Jian and Chen, Yuwei and Niu, Xiaoji and Wang, Li and Chen, Liang
   and Liu, Jingbin and Shi, Chuang and Hyyppa, Juha},
Title = {LiDAR Scan Matching Aided Inertial Navigation System in GNSS-Denied
   Environments},
Journal = {SENSORS},
Year = {2015},
Volume = {15},
Number = {7},
Pages = {16710-16728},
Month = {JUL},
Abstract = {A new scan that matches an aided Inertial Navigation System (INS) with a
   low-cost LiDAR is proposed as an alternative to GNSS-based navigation
   systems in GNSS-degraded or -denied environments such as indoor areas,
   dense forests, or urban canyons. In these areas, INS-based Dead
   Reckoning (DR) and Simultaneous Localization and Mapping (SLAM)
   technologies are normally used to estimate positions as separate tools.
   However, there are critical implementation problems with each standalone
   system. The drift errors of velocity, position, and heading angles in an
   INS will accumulate over time, and on-line calibration is a must for
   sustaining positioning accuracy. SLAM performance is poor in featureless
   environments where the matching errors can significantly increase. Each
   standalone positioning method cannot offer a sustainable navigation
   solution with acceptable accuracy. This paper integrates two
   complementary technologiesINS and LiDAR SLAMinto one navigation frame
   with a loosely coupled Extended Kalman Filter (EKF) to use the
   advantages and overcome the drawbacks of each system to establish a
   stable long-term navigation process. Static and dynamic field tests were
   carried out with a self-developed Unmanned Ground Vehicle (UGV)
   platformNAVIS. The results prove that the proposed approach can provide
   positioning accuracy at the centimetre level for long-term operations,
   even in a featureless indoor environment.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Chen, YW (Corresponding Author), Finnish Geospatial Inst, Dept Remote Sensing \& Photogrammetry, FI-02431 Kyrkslatt, Finland.
   Tang, Jian; Niu, Xiaoji; Wang, Li; Shi, Chuang, Wuhan Univ, GNSS Res Ctr, Wuhan 430079, Hubei, Peoples R China.
   Tang, Jian; Chen, Yuwei; Liu, Jingbin; Hyyppa, Juha, Finnish Geospatial Inst, Dept Remote Sensing \& Photogrammetry, FI-02431 Kyrkslatt, Finland.
   Chen, Liang, Finnish Geospatial Res Inst, Dept Nav \& Positioning, FI-02431 Kyrkslatt, Finland.},
DOI = {10.3390/s150716710},
ISSN = {1424-8220},
Keywords = {LiDAR; scan matching; INS; EKF; inertial navigation},
Keywords-Plus = {FUSION},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {tangjian@whu.edu.cn
   yuwei.chen@nls.fi
   xjniu@whu.edu.cn
   li.wang@whu.edu.cn
   liang.chen@nls.fi
   jingbin.liu@nls.fi
   shi@whu.edu.cn
   juha.hyyppa@nls.fi},
Affiliations = {Wuhan University; The National Land Survey of Finland; Finnish
   Geospatial Research Institute (FGI); The National Land Survey of
   Finland; Finnish Geospatial Research Institute (FGI)},
ResearcherID-Numbers = {Hyyppä, Juha M./ABH-1852-2021
   Liu, Jingbin/AAE-8803-2020
   chen, yuwei/U-9491-2017
   },
ORCID-Numbers = {chen, yuwei/0000-0003-0148-3609
   Hyyppa, Juha/0000-0001-5360-4017},
Funding-Acknowledgement = {National Nature Science Foundation of China {[}41304004]; Academy of
   Finland (project: ``Centre of Excellence in Laser Scanning Research{''})
   {[}272195]},
Funding-Text = {This study was financially supported by the National Nature Science
   Foundation of China (41304004), the Academy of Finland (project:
   ``Centre of Excellence in Laser Scanning Research{''} (272195)).},
Cited-References = {Borges GA, 2002, IEEE T ROBOTIC AUTOM, V18, P87, DOI 10.1109/70.988978.
   Fotopoulos G, 2001, GPS SOLUT, V4, P1, DOI 10.1007/PL00012849.
   Grewal M. S., 2014, KALMAN FILTERING THE, V4th.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Horn J.P., 1997, THESIS TU MUNICH MUN.
   Jekeli C., 2001, INERTIAL NAVIGATION.
   Jiang WP, 2014, SENSORS-BASEL, V14, P19371, DOI 10.3390/s141019371.
   Kim H.-S., 2012, P SOC PHOTO-OPT INS, V8387.
   Klein I, 2011, INT ARCH PHOTOGRAMM, V38-5, P231.
   Kleinert Markus, 2010, 2010 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2010), P20, DOI 10.1109/MFI.2010.5604453.
   Kneip L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P4546, DOI 10.1109/ICRA.2011.5980127.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Konolige K, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 \& 2, P1154.
   Lupton T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1547, DOI 10.1109/IROS.2009.5354267.
   Maybeck P., 1994, STOCHASTIC MODELS ES.
   Miller M. M., 2010, NAVIGATION GPS DENIE.
   Nutzi G, 2011, J INTELL ROBOT SYST, V61, P287, DOI 10.1007/s10846-010-9490-z.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Pfister S., 2006, THESIS CALTECH PASAD.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Shin E.H., 2001, ACCURACY IMPROVEMENT.
   Shin E.H., ESTIMATION TECHNIQUE.
   Simon D., 2006, OPTIMAL STATE ESTIMA.
   Soloviev Andrey, 2008, 2008 IEEE/ION Position, Location and Navigation Symposium - PLANS 2008, P511, DOI 10.1109/PLANS.2008.4570059.
   Tang J, 2015, SENSORS-BASEL, V15, P5311, DOI 10.3390/s150305311.
   Tang J, 2014, SENSORS-BASEL, V14, P11805, DOI 10.3390/s140711805.
   Titterton D., 2004, STRAPDOWN INERTIAL N, V2nd.
   Veth Major M., 2007, Navigation. Journal of the Institute of Navigation, V54, P11.
   VETH MJ, 2006, THESIS AIR FORCE I T.
   Wang XH, 2008, ECS TRANSACTIONS, V16, P3, DOI 10.1149/1.2981838.},
Number-of-Cited-References = {30},
Times-Cited = {67},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {94},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {CS0YN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000361788200094},
OA = {Green Published, Green Submitted, gold},
DA = {2022-05-17},
}

@article{ WOS:000435985000001,
Author = {Zhang, Hui and Chen, Xieyuanli and Lu, Huimin and Xiao, Junhao},
Title = {Distributed and collaborative monocular simultaneous localization and
   mapping for multi-robot systems in large-scale environments},
Journal = {INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS},
Year = {2018},
Volume = {15},
Number = {3},
Month = {JUN 18},
Abstract = {In this article, we propose a distributed and collaborative monocular
   simultaneous localization and mapping system for the multi-robot system
   in large-scale environments, where monocular vision is the only
   exteroceptive sensor. Each robot estimates its pose and reconstructs the
   environment simultaneously using the same monocular simultaneous
   localization and mapping algorithm. Meanwhile, they share the results of
   their incremental maps by streaming keyframes through the robot
   operating system messages and the wireless network. Subsequently, each
   robot in the group can obtain the global map with high efficiency. To
   build the collaborative simultaneous localization and mapping
   architecture, two novel approaches are proposed. One is a robust
   relocalization method based on active loop closure, and the other is a
   vision-based multi-robot relative pose estimating and map merging
   method. The former is used to solve the problem of tracking failures
   when robots carry out long-term monocular simultaneous localization and
   mapping in large-scale environments, while the latter uses the
   appearance-based place recognition method to determine multi-robot
   relative poses and build the large-scale global map by merging each
   robot's local map. Both KITTI data set and our own data set acquired by
   a handheld camera are used to evaluate the proposed system. Experimental
   results show that the proposed distributed multi-robot collaborative
   monocular simultaneous localization and mapping system can be used in
   both indoor small-scale and outdoor large-scale environments.},
Publisher = {SAGE PUBLICATIONS INC},
Address = {2455 TELLER RD, THOUSAND OAKS, CA 91320 USA},
Type = {Article},
Language = {English},
Affiliation = {Chen, XYL (Corresponding Author), Natl Univ Def Technol, Dept Automat, 137 Yanwachi St, Changsha 410073, Hunan, Peoples R China.
   Zhang, Hui; Chen, Xieyuanli; Lu, Huimin; Xiao, Junhao, Natl Univ Def Technol, Dept Automat, 137 Yanwachi St, Changsha 410073, Hunan, Peoples R China.},
DOI = {10.1177/1729881418780178},
Article-Number = {1729881418780178},
ISSN = {1729-8814},
Keywords = {Multi-robot collaborative SLAM; monocular SLAM; relocalization;
   large-scale SLAM},
Keywords-Plus = {SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {chenxieyuanli@hotmail.com},
Affiliations = {National University of Defense Technology - China},
ResearcherID-Numbers = {Chen, Xieyuanli/AAH-6401-2020
   },
ORCID-Numbers = {Chen, Xieyuanli/0000-0003-0955-6681
   Xiao, Junhao/0000-0002-4751-539X},
Funding-Acknowledgement = {National Science Foundation of China {[}61503401, 61773393]},
Funding-Text = {The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by National Science Foundation of China (nos 61503401 and
   61773393).},
Cited-References = {Bay H., 2006, EUR C COMP VIS, P404.
   Birk A, 2006, P IEEE, V94, P1384, DOI 10.1109/JPROC.2006.876965.
   Chebrolu  Nived, COLLABORATIVE VISUAL.
   Chen X, 8 ANN IEEE INT C CYB.
   Chen X, 2017 SPRING INT C CO, P131.
   Chen XYL, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY AND RESCUE ROBOTICS (SSRR), P41, DOI 10.1109/SSRR.2017.8088138.
   Clemente L. A., 2007, ROBOTICS SCI SYSTEMS, V2.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Doitsidis L., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P1661, DOI 10.1109/IROS.2011.6048116.
   Dong J, 2015, IEEE INT CONF ROBOT, P5807, DOI 10.1109/ICRA.2015.7140012.
   Eade E, 2008, BMVC, V136, P13.
   Eade E, 2007, IEEE I CONF COMP VIS, P2112.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel Jakob, EUR C COMP VIS, P834.
   Feder HJS, 1999, INT J ROBOT RES, V18, P650, DOI 10.1177/02783649922066484.
   Feng Y, P AS C COMP VIS, P206.
   Forster Christian, 2013, 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2013), P3962, DOI 10.1109/IROS.2013.6696923.
   Fox D, 2000, AUTON ROBOT, V8, P325, DOI 10.1023/A:1008937911390.
   Fox D, 2006, P IEEE, V94, P1325, DOI 10.1109/JPROC.2006.876927.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518.
   Howard A, 2006, INT J ROBOT RES, V25, P1243, DOI 10.1177/0278364906072250.
   Indelman V, 2014, IEEE INT CONF ROBOT, P593, DOI 10.1109/ICRA.2014.6906915.
   Kaess M, 2010, COMPUT VIS IMAGE UND, V114, P286, DOI 10.1016/j.cviu.2009.07.006.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Klein G, EUR C COMP VIS, P802.
   Ko J, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3232.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6.
   Leung KYK, 2012, J INTELL ROBOT SYST, V66, P321, DOI 10.1007/s10846-011-9620-2.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Martinelli A, 2005, IEEE INT CONF ROBOT, P2797.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Pupilli M, BMVC, DOI {[}10. 5244/C. 19. 50, DOI 10.5244/C.19.50].
   RAHIMI A, 2001, ICCV01, V1, P315.
   Reitmayr G, P 5 IEEE ACM INT S M, P109.
   Rone W, 2013, ROBOTICA, V31, P1, DOI 10.1017/S0263574712000021.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Saeedi S, 2016, J FIELD ROBOT, V33, P3, DOI 10.1002/rob.21620.
   Saeedi S, 2014, ROBOT AUTON SYST, V62, P1408, DOI 10.1016/j.robot.2014.06.002.
   Schmuck Patrik, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3863, DOI 10.1109/ICRA.2017.7989445.
   Se S, 2005, IEEE T ROBOT, V21, P364, DOI 10.1109/TRO.2004.839228.
   Sivic J, NULL, P1470.
   Sola J, 2007, IEEE INT CONF ROBOT, P4795, DOI 10.1109/ROBOT.2007.364218.
   Stachniss C., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1505.
   Strasdat H, 2012, LOCAL ACCURACY GLOBA.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Strasdat Hauke, 2010, ROBOT SCI SYST 6, V6, P2.
   Straub J, 2013, IEEE IMAGE PROC, P2548, DOI 10.1109/ICIP.2013.6738525.
   Vidal-Calleja TA, 2011, ROBOT AUTON SYST, V59, P654, DOI 10.1016/j.robot.2011.05.008.
   Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Zhou XS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1785, DOI 10.1109/IROS.2006.282219.},
Number-of-Cited-References = {59},
Times-Cited = {9},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {34},
Journal-ISO = {Int. J. Adv. Robot. Syst.},
Doc-Delivery-Number = {GK2SM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000435985000001},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000476919900002,
Author = {Valente, Michelle and Joly, Cyril and de La Fortelle, Arnaud},
Title = {Evidential SLAM Fusing 2D Laser Scanner and Stereo Camera},
Journal = {UNMANNED SYSTEMS},
Year = {2019},
Volume = {7},
Number = {3, SI},
Pages = {149-159},
Month = {JUL},
Abstract = {This work introduces a new complete Simultaneous Localization and
   Mapping (SLAM) framework that uses an enriched representation of the
   world based on sensor fusion and is able to simultaneously provide an
   accurate localization of the vehicle. A method to create an Evidential
   grid representation from two very different sensors, laser scanner and
   stereo camera, allows a better handling of the dynamic aspects of the
   urban environment and a proper management of errors to create a more
   reliable map, thus having a more precise localization. A life-long layer
   with high level states is presented, it maintains a global map of the
   entire vehicle's trajectory and distinguishes between static and dynamic
   obstacles. Finally, we propose a method that at each current map
   creation estimates the vehicle's position by a grid matching algorithm
   based on image registration techniques. Results on a real road dataset
   show that the environment mapping data can be improved by adding
   relevant information that could be missed without the proposed approach.
   Moreover, the proposed localization method is able to reduce the drift
   and improve the localization compared to other methods using similar
   configurations.},
Publisher = {WORLD SCI PUBL CO INC},
Address = {27 WARREN ST, STE 401-402, HACKENSACK, NJ 07601 USA},
Type = {Article},
Language = {English},
Affiliation = {Valente, M (Corresponding Author), PSL Res Univ, MINES ParisTech, Ctr Robot, 60 Blvd St Michel, F-75006 Paris, France.
   Valente, Michelle; Joly, Cyril; de La Fortelle, Arnaud, PSL Res Univ, MINES ParisTech, Ctr Robot, 60 Blvd St Michel, F-75006 Paris, France.},
DOI = {10.1142/S2301385019410012},
ISSN = {2301-3850},
EISSN = {2301-3869},
Keywords = {SLAM; sensor fusion; Dempster-Shafer},
Keywords-Plus = {GRIDS},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {michelle.valente@mines-paristech.fr
   cyril.joly@mines-paristech.fr
   arnaud.de\_la\_fortelle@mines-paristech.fr},
Affiliations = {UDICE-French Research Universities; PSL Research University Paris; MINES
   ParisTech},
ResearcherID-Numbers = {de La Fortelle, Arnaud/AAA-2279-2019},
Cited-References = {Baker S., 2001, COMP VIS PATT REC 20, V1, pI.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Blanco JL, 2013, ROBOTICA, V31, P687, DOI 10.1017/S0263574712000732.
   Chen C., 2006, 2006 9 INT C CONTR A, P1.
   Coue C, 2006, INT J ROBOT RES, V25, P19, DOI 10.1177/0278364906061158.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Hu ZC, 2005, Fifth International Conference on 3-D Digital Imaging and Modeling, Proceedings, P204.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Kurdej M, 2015, IEEE INTEL TRANSP SY, V7, P30, DOI 10.1109/MITS.2014.2352371.
   Labayrade R, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P646.
   Lin KH, 2012, J INF SCI ENG, V28, P131.
   Moghadam P, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS \& VISION: ICARV 2008, VOLS 1-4, P384, DOI 10.1109/ICARCV.2008.4795550.
   Moras J, 2011, IEEE INT CONF ROBOT.
   Moras J, 2015, PROC SPIE, V9474, DOI 10.1117/12.2177653.
   Mouhagir H., 2017, 2017 IEEE 20 INT C I, P1.
   Mullane J, 2006, I C CONT AUTOMAT ROB, P846.
   Oriolo G, 1997, J ROBOTIC SYST, V14, P179, DOI 10.1002/(SICI)1097-4563(199703)14:3<179::AID-ROB3>3.0.CO;2-O.
   Pagac D, 1998, IEEE T ROBOTIC AUTOM, V14, P623, DOI 10.1109/70.704234.
   Perrollaz M, 2010, IEEE INT C INT ROBOT, P2721, DOI 10.1109/IROS.2010.5649690.
   Perrollaz M, 2010, IEEE INT VEH SYM, P313, DOI 10.1109/IVS.2010.5548010.
   Shafer G., 1976, MATH THEORY EVIDENCE.
   Steyer S, 2017, IEEE INT VEH SYM, P1064, DOI 10.1109/IVS.2017.7995855.
   Tanzmeister G, 2017, IEEE T INTELL TRANSP, V18, P1454, DOI 10.1109/TITS.2016.2608919.
   Trehard G, 2015, IEEE INT VEH SYM, P814, DOI 10.1109/IVS.2015.7225785.
   Trehard G, 2014, IEEE INT C INT ROBOT, P2699, DOI 10.1109/IROS.2014.6942931.
   Yu CL, 2015, IEEE INT VEH SYM, P712, DOI 10.1109/IVS.2015.7225768.},
Number-of-Cited-References = {27},
Times-Cited = {4},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {10},
Journal-ISO = {Unmanned Syst.},
Doc-Delivery-Number = {IK9MT},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000476919900002},
DA = {2022-05-17},
}

@article{ WOS:000289844100013,
Author = {Taylor, Clark N. and Veth, Michael J. and Raquet, John F. and Miller,
   Mikel M.},
Title = {Comparison of Two Image and Inertial Sensor Fusion Techniques for
   Navigation in Unmapped Environments},
Journal = {IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS},
Year = {2011},
Volume = {47},
Number = {2},
Pages = {946-958},
Month = {APR},
Abstract = {To enable navigation of miniature aerial vehicles (MAVs) with a
   low-quality inertial measurement unit (IMU), external sensors are
   typically fused with the information generated by the low-quality IMU.
   Most commercial systems for MAVs currently fuse GPS measurements with
   IMU information to navigate the MAV. However there are many scenarios in
   which an MAV might prove useful, but GPS is not available (e. g.,
   indoors, urban terrain, etc.). Therefore several approaches have
   recently been introduced that couple information from an IMU with visual
   information (usually captured by an electro-optical camera). In general
   the methods for fusing visual information with an IMU utilizes one of
   two techniques: 1) applying rigid body constraints on where landmarks
   should appear in a set of two images (constraint-based fusion) or 2)
   simultaneously estimating the location of features that are observed by
   the camera (mapping) and the location of the camera (simultaneous
   localization and mapping-SLAM-based fusion). While each technique has
   some nuances associated with its implementation in a true MAV
   environment (i.e., computational requirements, real-time implementation,
   feature tracking, etc.), this paper focuses solely on answering the
   question ``Which fusion technique (constraint- or SLAM-based) enables
   more accurate long-term MAV navigation?{''} To answer this question,
   specific implementations of a constraint- and SLAM-based fusion
   technique, with novel modifications for improved results on MAVs, are
   described. A basic simulation environment is used to perform a
   comparison of the constraint- and SLAM-based fusion methods. We
   demonstrate the superiority of SLAM-based techniques in specific MAV
   flight scenarios and discuss the relative weaknesses and strengths of
   each fusion approach.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Taylor, CN (Corresponding Author), USAF, Sensors Directorate, Res Lab, Wright Patterson AFB, OH 45433 USA.
   Taylor, Clark N., Brigham Young Univ, Provo, UT 84602 USA.
   Veth, Michael J.; Raquet, John F., USAF, Inst Technol, Wright Patterson AFB, OH 45433 USA.
   Miller, Mikel M., USAF, Res Lab, Munit Directorate, Eglin AFB, FL USA.},
DOI = {10.1109/TAES.2011.5751236},
ISSN = {0018-9251},
EISSN = {1557-9603},
Keywords-Plus = {KALMAN FILTER},
Research-Areas = {Engineering; Telecommunications},
Web-of-Science-Categories  = {Engineering, Aerospace; Engineering, Electrical \& Electronic;
   Telecommunications},
Author-Email = {clark.n.taylor@gmail.com},
Affiliations = {Brigham Young University; United States Department of Defense; United
   States Air Force; US Air Force Research Laboratory; United States
   Department of Defense; United States Air Force},
ORCID-Numbers = {Taylor, Clark/0000-0002-6417-3715},
Funding-Acknowledgement = {AFOSR {[}FA9550-07-1-0167]; ASEE/Air Force Summer Faculty},
Funding-Text = {This work is funded by an AFOSR Young Investigator Award
   FA9550-07-1-0167 and an ASEE/Air Force Summer Faculty Fellowship.},
Cited-References = {Andersen Evan D, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3745, DOI 10.1109/IROS.2007.4399563.
   Beard Randal, 2005, J AEROS COMP INF COM, V2, P92.
   Bradley J., 2007, P AIAA C GUID NAV CO.
   Brown A., 2007, P 2007 ION GNSS C, P1111.
   Doucet A, 2001, SEQUENTIAL MONTE CAR.
   Durrant-Whyte H., 1995, 8 INT S ROB RES NEW, P613.
   Gibbens PW, 2000, IEEE DECIS CONTR P, P191, DOI 10.1109/CDC.2000.912757.
   Goodrich MA, 2008, J FIELD ROBOT, V25, P89, DOI 10.1002/rob.20226.
   Herwitz S., 2002, AIAA 1 TECHN C WORKS.
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811.
   Julier SJ, 2007, IEEE T SIGNAL PROCES, V55, P2774, DOI 10.1109/TSP.2007.893949.
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797.
   KIM J, 2004, 2004 INT S GNSS GPS.
   Kim JH, 2003, IEEE INT CONF ROBOT, P406.
   Kingston D.B., 2004, P AIAA 3 UNM UNL SYS.
   Langelaan Jacob Willem, 2006, THESIS STANFORD U.
   Maybeck P.S, 1982, STOCHASTIC MODELS ES, V1.
   Montiel JMM, 2006, ANALYSIS, V9, P1.
   Pinies P, 2007, IEEE INT CONF ROBOT, P2797, DOI 10.1109/ROBOT.2007.363895.
   Prazenica R. J., 2005, AIAA GUID NAV CONTR, P1.
   Ready Bryce B, 2007, 2007 American Control Conference, P3721, DOI 10.1109/ACC.2007.4283137.
   Rees G., 2007, P SEAS DTC TECHN C.
   Soatto S, 1996, IEEE T AUTOMAT CONTR, V41, P393, DOI 10.1109/9.486640.
   STRELOW D, 2006, P INT S EXP ROB JUL.
   Titterton D.H., 1997, STRAPDOWN INERTIAL N.
   Veth Major M., 2007, Navigation. Journal of the Institute of Navigation, V54, P11.
   Veth MM, 2006, PROCEEDINGS OF THE 2006 NATIONAL TECHNICAL MEETING OF THE INSTITUTE OF NAVIGATION - NTM 2006, P587.
   Veth M, 2006, IEEE T AERO ELEC SYS, V42, P973, DOI 10.1109/TAES.2006.4439212.},
Number-of-Cited-References = {28},
Times-Cited = {24},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {11},
Journal-ISO = {IEEE Trans. Aerosp. Electron. Syst.},
Doc-Delivery-Number = {754GW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000289844100013},
DA = {2022-05-17},
}

@inproceedings{ WOS:000418323700243,
Author = {Ravankar, Ankit A. and Ravankar, Abhijeet and Emaru, Takanori and
   Kobayashi, Yukinori},
Book-Group-Author = {IEEE},
Title = {A Hybrid Topological Mapping and Navigation Method for Large Area Robot
   Mapping},
DOI = {10.23919/SICE.2017.8105770},
Booktitle = {2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL
   ENGINEERS OF JAPAN (SICE)},
Year = {2017},
Pages = {1104-1107},
Note = {56th Annual Conference of the
   Society-of-Instrument-and-Control-Engineers-of-Japan (SICE), Kanazawa
   Univ, Kanazawa, JAPAN, SEP 19-22, 2017},
Abstract = {In this paper, we present a hybrid topological mapping and navigation
   method for mobile robots. The proposed method combines metric and
   topological information to create map and generate navigation plan for
   the robot. As compared to traditional approaches of robot mapping, the
   method is lightweight and can be used for mapping and navigation in
   large areas which is particularly useful for service robots operating in
   large buildings. The method only uses local information for navigation
   while maintaining the global topological graph nodes. The topological
   nodes are used effectively for navigation and can also be used to store
   semantic information of the scene such as robot poses, scans and scene
   properties for complete long term robot autonomy. By combining the
   information from the two maps (topological and grid map), autonomous
   navigation and mapping in large areas for robots is possible.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ravankar, AA (Corresponding Author), Hokkaido Univ, Lab Robot \& Dynam, Fac Engn, Sapporo, Hokkaido, Japan.
   Ravankar, Ankit A.; Ravankar, Abhijeet; Emaru, Takanori; Kobayashi, Yukinori, Hokkaido Univ, Lab Robot \& Dynam, Fac Engn, Sapporo, Hokkaido, Japan.},
ISBN = {978-4-9077-6457-9},
Keywords = {Robot Mapping; Topological Mapping; Navigation; Graph Theory; SLAM;
   Mobile Robot},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; SLAM},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic},
Author-Email = {ankit@eng.hokudai.ac.jp},
Affiliations = {Hokkaido University},
ResearcherID-Numbers = {Ravankar, Ankit A./L-8613-2016
   KOBAYASHI, YUKINORI/A-5738-2012
   },
ORCID-Numbers = {Ravankar, Ankit A./0000-0002-5104-9782
   Ravankar, Abhijeet/0000-0002-4057-5568},
Cited-References = {Choset H, 2001, IEEE T ROBOTIC AUTOM, V17, P125, DOI 10.1109/70.928558.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   Montemerlo M, 2003, IEEE INT CONF ROBOT, P1985, DOI 10.1109/ROBOT.2003.1241885.
   Pronobis A, 2010, INT J ROBOT RES, V29, P298, DOI 10.1177/0278364909356483.
   Pronobis A., 2012, P 2012 IEEE INT C RO.
   Ravankar A, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63458.
   Ravankar A, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63540.
   Ravankar AA, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/59992.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Thrun S, 2003, AUTON ROBOT, V15, P111, DOI 10.1023/A:1025584807625.
   Thrun S., 2005, PROBABILISTIC ROBOTI.},
Number-of-Cited-References = {15},
Times-Cited = {8},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {9},
Doc-Delivery-Number = {BJ1WS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000418323700243},
DA = {2022-05-17},
}

@article{ WOS:000446285700027,
Author = {Ma, Teng and Li, Ye and Wang, Rupeng and Cong, Zheng and Gong, Yusen},
Title = {AUV robust bathymetric simultaneous localization and mapping},
Journal = {OCEAN ENGINEERING},
Year = {2018},
Volume = {166},
Pages = {336-349},
Month = {OCT 15},
Abstract = {Bathymetric simultaneous localization and mapping (BSLAM) technique
   could provide long-term underwater navigation results for autonomous
   underwater vehicles (AUVs) and produce a self-consistent bathymetric map
   simultaneously. However, the inter-frame motion inside BSLAM is still
   difficult to estimate, and BSLAM might fail catastrophically with
   invalid loop closures caused by the measurement errors of vehicle states
   and bathymetric data. To deal with these problems, an AUV robust BSLAM
   algorithm is proposed based on graph SLAM. In this algorithm, weak data
   association is constructed via sparse pseudo-input Gaussian process
   (SPGP) regression to predict inter-frame motion, and a multi-window
   consistency method (MCM) is introduced to identify invalid loop
   closures. Various simulation experiments are conducted under different
   environments. Comparisons are made between more standard approaches, and
   our proposed algorithm is shown to be viable, accurate, and could
   robustly handle invalid loop closures.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Li, Y (Corresponding Author), Harbin Engn Univ, Sci \& Technol Underwater Vehicle Lab, Harbin 150001, Heilongjiang, Peoples R China.
   Ma, Teng; Li, Ye; Wang, Rupeng; Cong, Zheng; Gong, Yusen, Harbin Engn Univ, Sci \& Technol Underwater Vehicle Lab, Harbin 150001, Heilongjiang, Peoples R China.},
DOI = {10.1016/j.oceaneng.2018.08.029},
ISSN = {0029-8018},
Keywords = {Navigation; BSLAM; Robust; SPGP; Consistency method},
Keywords-Plus = {HULL INSPECTION; SLAM; NAVIGATION},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Civil; Engineering, Ocean;
   Oceanography},
Author-Email = {liyeheu103@163.com},
Affiliations = {Harbin Engineering University},
ResearcherID-Numbers = {MA, Teng/ABC-6356-2020
   Cong, Zheng/ABD-8325-2021
   },
ORCID-Numbers = {Cong, Zheng/0000-0002-0195-4880
   Ma, Teng/0000-0002-5609-7388},
Funding-Acknowledgement = {National Key R\&D program of China {[}2017YFC0305700]; Qingdao National
   Laboratory for Marine Science and Technology {[}QNLM2016ORP0406]},
Funding-Text = {This work was supported by the National Key R\&D program of China
   (2017YFC0305700) and open fund project of the Qingdao National
   Laboratory for Marine Science and Technology (QNLM2016ORP0406).},
Cited-References = {Agarwal P, 2014, IEEE INT CONF ROBOT, P3626, DOI 10.1109/ICRA.2014.6907383.
   Agarwal P, 2013, IEEE INT CONF ROBOT, P62, DOI 10.1109/ICRA.2013.6630557.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Barkby S, 2012, INT J ROBOT RES, V31, P1409, DOI 10.1177/0278364912459666.
   Barkby S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P219, DOI 10.1109/IROS.2009.5354248.
   Burguera A, 2010, IEEE INT C INT ROBOT, P2546, DOI 10.1109/IROS.2010.5649492.
   Carlone L, 2014, IEEE INT C INT ROBOT, P2667, DOI 10.1109/IROS.2014.6942927.
   Chen P., 2016, THESIS.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Doble MJ, 2009, COLD REG SCI TECHNOL, V56, P90, DOI 10.1016/j.coldregions.2008.11.006.
   Elibol A, 2016, INTEL SERV ROBOT, V9, P217, DOI 10.1007/s11370-016-0195-4.
   Graham MC, 2015, IEEE INT C INT ROBOT, P117, DOI 10.1109/IROS.2015.7353363.
   Hagen OK, 2014, MAR TECHNOL SOC J, V48, P45, DOI 10.4031/MTSJ.48.2.6.
   Ila V, 2017, INT J ROBOT RES, V36, P210, DOI 10.1177/0278364917691110.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kownacki C, 2016, ROBOTICA, V34, P243, DOI 10.1017/S0263574714001404.
   Latif Y, 2014, IEEE INT C INT ROBOT, P2683, DOI 10.1109/IROS.2014.6942929.
   Lee GH, 2013, IEEE INT C INT ROBOT, P556, DOI 10.1109/IROS.2013.6696406.
   Li Y, 2017, J NAVIGATION, V70, P1062, DOI 10.1017/S037346331700011X.
   Ma T, 2017, J NAVIG UNPUB, P1.
   Mallios A, 2014, AUTON ROBOT, V36, P181, DOI 10.1007/s10514-013-9345-0.
   Nieto J, 2007, ROBOT AUTON SYST, V55, P39, DOI 10.1016/j.robot.2006.06.008.
   Nygren I., 2005, THESIS.
   Ozog P, 2016, J FIELD ROBOT, V33, P265, DOI 10.1002/rob.21582.
   Palomer A, 2013, BATHYMETRY BASED SLA, P1.
   Palomer A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040560.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Ribas D, 2008, J FIELD ROBOT, V25, P898, DOI 10.1002/rob.20249.
   Roy N, 2012, P ROBOTICS SCI SYSTE, V32, P1611.
   Snelson E., 2006, ADV NEURAL INF PROCE, P1257.
   Stuckey R.A., 2012, IFAC P, V45, P118, DOI {[}10.3182/20120410-3-PT-4028.00021, DOI 10.3182/20120410-3-PT-4028.00021].
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Tan HP, 2011, OCEAN ENG, V38, P1663, DOI 10.1016/j.oceaneng.2011.07.017.
   Zhao L, 2015, IEEE SENS J, V15, P1124, DOI 10.1109/JSEN.2014.2360916.},
Number-of-Cited-References = {35},
Times-Cited = {13},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {52},
Journal-ISO = {Ocean Eng.},
Doc-Delivery-Number = {GV7EV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000446285700027},
DA = {2022-05-17},
}

@inproceedings{ WOS:000349834600021,
Author = {Kanji, Tanaka and Yuuto, Chokushi and Masatoshi, Ando},
Book-Group-Author = {IEEE},
Title = {Mining Visual Phrases for Long-Term Visual SLAM},
DOI = {10.1109/IROS.2014.6942552},
Booktitle = {2014 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2014)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2014},
Pages = {136-142},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Chicago, IL, SEP 14-18, 2014},
Abstract = {We propose a discriminative and compact scene descriptor for single-view
   place recognition that facilitates long-term visual SLAM in familiar,
   semi-dynamic and partially changing environments. In contrast to popular
   bag-ofwords scene descriptors, which rely on a library of vector
   quantized visual features, our proposed scene descriptor is based on a
   library of raw image data (such as an available visual experience,
   images shared by other colleague robots, and publicly available image
   data on the web) and directly mine it to find visual phrases (VPs) that
   discriminatively and compactly explain an input query / database image.
   Our mining approach is motivated by recent success in the field of
   common pattern discovery-specifically mining of common visual patterns
   among scenes-and requires only a single library of raw images that can
   be acquired at different time or day. Experimental results show that
   even though our scene descriptor is significantly more compact than
   conventional descriptors it has a relatively higher recognition
   performance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kanji, T (Corresponding Author), Univ Fukui, Fac Engn, Fukui, Japan.
   Kanji, Tanaka; Yuuto, Chokushi; Masatoshi, Ando, Univ Fukui, Fac Engn, Fukui, Japan.},
ISSN = {2153-0858},
ISBN = {978-1-4799-6934-0},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Cited-References = {Arbelaez P, 2012, PROC CVPR IEEE, P3378, DOI 10.1109/CVPR.2012.6248077.
   Bo L., 2012, ISER JUN.
   Carlevaris-Bianco N, 2013, IEEE INT C INT ROBOT, P1034, DOI 10.1109/IROS.2013.6696478.
   Cho M, 2010, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR.2010.5539777.
   Churchill W, 2012, IEEE INT C INTELL TR, P1371, DOI 10.1109/ITSC.2012.6338716.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Cummins M., 2009, ROBOTICS SCI SYSTEMS.
   Cunningham A, 2012, IEEE INT CONF ROBOT, P1093, DOI 10.1109/ICRA.2012.6225356.
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602.
   Hanada S., 2013, IROS.
   Hongbin Zha, 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS `97 (Cat. No.97CH36108), P1729, DOI 10.1109/IROS.1997.656593.
   Huang AS, 2010, INT J ROBOT RES, V29, P1595, DOI 10.1177/0278364910384295.
   Ikeda K, 2010, IEEE INT CONF ROBOT, P4397, DOI 10.1109/ROBOT.2010.5509579.
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235.
   Jiang YN, 2012, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2012.6248042.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Leibe B, 2004, ECCV 04 WORKSH STAT, P1, DOI DOI 10.1007/11957959\_26.
   Li L.-J., 2010, P NIPS, P1378.
   McDonald J, 2013, ROBOT AUTON SYST, V61, P1144, DOI 10.1016/j.robot.2012.08.008.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001.
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711.
   Saeki Kenichi, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P3523, DOI 10.1109/ROBOT.2009.5152201.
   Savarese S., 2006, CVPR, P2033.
   Shahbazi H, 2011, IEEE INT C INT ROBOT, P1228, DOI 10.1109/IROS.2011.6048862.
   Sunderhauf N., 2013, WORKSH LONG TERM AUT.
   Tan HK, 2005, IEEE I CONF COMP VIS, P1222.
   Tanaka K, 2004, IEEE INT CONF ROBOT, P1487, DOI 10.1109/ROBOT.2004.1308034.
   Viola P., 2001, ROBUST REAL TIME OBJ.
   ZHENG QF, 2006, P 14 ACM INT C MULT, P00077.},
Number-of-Cited-References = {34},
Times-Cited = {9},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BC0YL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000349834600021},
DA = {2022-05-17},
}

@inproceedings{ WOS:000289878100027,
Author = {Hochdorfer, Siegfried and Lutz, Matthias and Schlegel, Christian},
Book-Group-Author = {IEEE},
Title = {Lifelong Localization of a Mobile Service-Robot in Everyday Indoor
   Environments Using Omnidirectional Vision},
Booktitle = {2009 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR PRACTICAL ROBOT
   APPLICATIONS (TEPRA 2009)},
Year = {2009},
Pages = {161-166},
Note = {IEEE International Conference on Technologies for Practical Robot
   Applications, Woburn, MA, NOV 09-10, 2009},
Abstract = {SLAM (Simultaneous Localization and Mapping) mechanisms are a key
   component towards advanced service robotics applications. Currently, a
   major hurdle on the way to lifelong localization is the handling of the
   ever growing amount of landmarks over time. Therefore, the required
   resources in terms of memory and processing power are also growing over
   time.
   An approach to restrict the absolute number of landmarks by an upper
   bound was presented in {[}1]. The key was a method to specifically
   select and replace landmarks once an upper bound has been reached. In
   this paper, we extend that landmark rating and selection approach. The
   here presented extension improves the landmark rating and selection
   process. Landmarks are kept such that their visibility regions better
   approximate the robot's operational area.
   A landmark with a low information content in a sparsely known region is
   often more useful than a landmark with a higher information content in a
   well-known region. Clustering algorithms are used to identify regions in
   the environment with a high landmark density. Removing a landmark from a
   cluster with high localization support will have the smallest degradal
   ion of robot localization quality.
   Real-world experiments are used to demonstrate the performance of our
   approach. These experiments are performed on a P3DX-platform with a
   bearing-only SLAM approach. All three approaches of handling landmarks
   (the standard approach without upper bound on the number of landmarks,
   the improved and the previous landmark rating and selection process) are
   compared against each other.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Hochdorfer, S (Corresponding Author), Univ Appl Sci Ulm, Dept Comp Sci, Prittwitzstr 10, D-89075 Ulm, Germany.
   Hochdorfer, Siegfried; Lutz, Matthias; Schlegel, Christian, Univ Appl Sci Ulm, Dept Comp Sci, D-89075 Ulm, Germany.},
DOI = {10.1109/TEPRA.2009.5339626},
ISBN = {978-1-4244-4991-0},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {hochdorfer@hs-ulm.de
   lutz@hs-ulm.de
   schlegel@hs-ulm.de},
Affiliations = {Ulm University},
Cited-References = {Bailey T, 2003, IEEE INT CONF ROBOT, P1966, DOI 10.1109/ROBOT.2003.1241882.
   Bay H, 2006, 9 EUR C COMP VIS GRA.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   Ester M., 1996, KDD, V96, P226, DOI DOI 10.5555/3001460.3001507.
   HOCHDORFER S, 2007, AUTONOME MOBILE SYST, P8.
   HOCHDORFER S, 2009, IEEE RSJ INT C INT R.
   SCHLEGEL C, 2005, AUTONOME MOBILE SYST, P99.
   Seber GAF, 1984, MULTIVARIATE OBSERVA.
   Spath H, 1985, CLUSTER DISSECTION A.
   Strasdat H., 2009, IEEE INT C ROB AUT I.
   Tran TN, 2005, CHEMOMETR INTELL LAB, V77, P3, DOI 10.1016/j.chemolab.2004.07.011.
   Yip AM, 2006, IEEE T PATTERN ANAL, V28, P877, DOI 10.1109/TPAMI.2006.117.},
Number-of-Cited-References = {12},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BUO02},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000289878100027},
DA = {2022-05-17},
}

@inproceedings{ WOS:000668126802098,
Author = {Gao, Peng and Zhang, Hao},
Book-Group-Author = {Assoc Advancement Artificial Intelligence},
Title = {Long-Term Loop Closure Detection through Visual-Spatial Information
   Preserving Multi-Order Graph Matching},
DOI = {10.1609/aaai.v34i06.6604},
Booktitle = {THIRTY-FOURTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, THE
   THIRTY-SECOND INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE
   CONFERENCE AND THE TENTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN
   ARTIFICIAL INTELLIGENCE},
Series = {AAAI Conference on Artificial Intelligence},
Year = {2020},
Volume = {34},
Pages = {10369-10376},
Note = {34th AAAI Conference on Artificial Intelligence / 32nd Innovative
   Applications of Artificial Intelligence Conference / 10th AAAI Symposium
   on Educational Advances in Artificial Intelligence, New York, NY, FEB
   07-12, 2020},
Abstract = {Loop closure detection is a fundamental problem for simultaneous
   localization and mapping (SLAM) in robotics. Most of the previous
   methods only consider one type of information, based on either visual
   appearances or spatial relationships of landmarks. In this paper, we
   introduce a novel visual-spatial information preserving multi-order
   graph matching approach for long-term loop closure detection. Our
   approach constructs a graph representation of a place from an input
   image to integrate visual-spatial information, including visual
   appearances of the landmarks and the background environment, as well as
   the second and third-order spatial relationships between two and three
   landmarks, respectively. Furthermore, we introduce a new formulation
   that formulates loop closure detection as a multi-order graph matching
   problem to compute a similarity score directly from the graph
   representations of the query and template images, instead of performing
   conventional vector-based image matching. We evaluate the proposed
   multi-order graph matching approach based on two public long-term loop
   closure detection benchmark datasets, including the St. Lucia and CMU-VL
   datasets. Experimental results have shown that our approach is effective
   for long-term loop closure detection and it outperforms the previous
   state-of-the-art methods.},
Publisher = {ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
Address = {2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gao, P (Corresponding Author), Colorado Sch Mines, Human Ctr Robot Lab, Golden, CO 80401 USA.
   Gao, Peng; Zhang, Hao, Colorado Sch Mines, Human Ctr Robot Lab, Golden, CO 80401 USA.},
ISSN = {2159-5399},
EISSN = {2374-3468},
ISBN = {978-1-57735-835-0},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Computer Science; Education \& Educational Research},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Education, Scientific Disciplines},
Author-Email = {gaopeng@mines.edu
   hzhang@mines.edu},
Affiliations = {Colorado School of Mines},
ORCID-Numbers = {Zhang, Hao/0000-0001-8043-9184},
Funding-Acknowledgement = {DOT PHMSA Award {[}693JK31850005CAAP]; NSF {[}CNS-1823245, IIS-1849348,
   IIS-1849359]},
Funding-Text = {This work was partially supported by DOT PHMSA Award 693JK31850005CAAP
   and NSF grants CNS-1823245, IIS-1849348 and IIS-1849359.},
Cited-References = {Badino H., 2012, P IEEE INT C ROB AUT.
   Chen ZT, 2017, IEEE INT C INT ROBOT, P9.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Gawel Abel, 2018, IEEE Robotics and Automation Letters, V3, P1687, DOI 10.1109/LRA.2018.2801879.
   Glover A. J., 2010, ICRA, DOI 10.1109/ROBOT.2010. 5509547.
   Han F., 2018, AAAI.
   Han F, 2018, AUTON ROBOT, V42, P1323, DOI 10.1007/s10514-018-9736-3.
   Han F, 2017, IEEE ROBOT AUTOM LET, V2, P1172, DOI 10.1109/LRA.2017.2662061.
   Haveliwala T.H., 2002, P WWW, P517, DOI {[}10.1145/511446.511513, DOI 10.1145/511446.511513].
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Latif Y., 2014, RSS.
   Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387.
   Linegar C., 2016, ICRA.
   Liu K, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P8034.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R., 2014, ICRA.
   Naseer T., 2015, IROS.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   NEWMAN P, 2006, ICRA.
   Nguyen Quynh, 2015, CVPR.
   Panphattarasap P., 2016, P AS C COMP VIS, P487.
   Pronobis A, 2010, INT J ROBOT RES, V29, P298, DOI 10.1177/0278364909356483.
   Rabanser S., 2015, MACH LEARN, V98, P1.
   Ramos F. T., 2007, ROBOTICS SCI SYSTEMS, DOI {[}10.15607/RSS.2007.III.026, DOI 10.15607/RSS.2007.III.026].
   Ramos F, 2009, SPRINGER TRAC ADV RO, V54, P505.
   Schonberger J. L., 2018, CVPR.
   Stumm E., 2016, IEEE C COMP VIS PATT.
   Stumm E, 2015, IEEE INT CONF ROBOT, P5475, DOI 10.1109/ICRA.2015.7139964.
   Sunderhauf N., 2015, IROS.
   Sunderhauf N., 2011, IROS.
   Sunderhauf Niko, 2013, P WORKSH LONG TERM A, P102.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Zhang H., 2014, CVPR.},
Number-of-Cited-References = {36},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BR7JR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000668126802098},
DA = {2022-05-17},
}

@inproceedings{ WOS:000771405405115,
Author = {Zhu, Shifan and Zhang, Xinyu and Guo, Shichun and Li, Jun and Liu,
   Huaping},
Book-Group-Author = {IEEE},
Title = {Lifelong Localization in Semi-Dynamic Environment},
Booktitle = {2021 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA
   2021)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2021},
Pages = {14389-14395},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Xian,
   PEOPLES R CHINA, MAY 30-JUN 05, 2021},
Abstract = {Mapping and localization in non-static environments are fundamental
   problems in robotics. Most of previous methods mainly focus on static
   and highly dynamic objects in the environment, which may suffer from
   localization failure in semi-dynamic scenarios without considering
   objects with lower dynamics, such as parked cars and stopped
   pedestrians. In this paper, we introduce semantic mapping and lifelong
   localization approaches to recognize semi-dynamic objects in non-static
   environments. We also propose a generic framework that can integrate
   mainstream object detection algorithms with mapping and localization
   algorithms. The mapping method combines an object detection algorithm
   and a SLAM algorithm to detect semi-dynamic objects and constructs a
   semantic map that only contains semi-dynamic objects in the environment.
   During navigation, the localization method can classify observation
   corresponding to static and non-static objects respectively and evaluate
   whether those semi-dynamic objects have moved, to reduce the weight of
   invalid observation and localization fluctuation. Real-world experiments
   show that the proposed method can improve the localization accuracy of
   mobile robots in non-static scenarios.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhang, XY (Corresponding Author), Tsinghua Univ, State Key Lab Automot Safety \& Energy, Beijing 100084, Peoples R China.
   Zhang, XY (Corresponding Author), Tsinghua Univ, Sch Vehicle \& Mobil, Beijing 100084, Peoples R China.
   Zhu, Shifan; Zhang, Xinyu; Guo, Shichun; Li, Jun, Tsinghua Univ, State Key Lab Automot Safety \& Energy, Beijing 100084, Peoples R China.
   Zhu, Shifan; Zhang, Xinyu; Guo, Shichun; Li, Jun, Tsinghua Univ, Sch Vehicle \& Mobil, Beijing 100084, Peoples R China.
   Liu, Huaping, Tsinghua Univ, Dept Comp Sci \& Technol, Beijing 100084, Peoples R China.},
DOI = {10.1109/ICRA48506.2021.9561584},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-7281-9077-8},
Keywords-Plus = {MOBILE ROBOTS},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {shifzhu@gmail.com
   xyzhang@tsinghua.edu
   shichunguo@gmail.com
   lijun19580326@126.com
   hpliu@mail.tsinghua.edu.cn},
Affiliations = {Tsinghua University; Tsinghua University; Tsinghua University},
Funding-Acknowledgement = {National High Technology Research and Development Program of China
   {[}2018YFE0204300]; Beijing Science and Technology Plan Project
   {[}Z191100007419008, 2019GQG1010]; National Natural Science Foundation
   of China {[}U1964203]},
Funding-Text = {This work was supported by the National High Technology Research and
   Development Program of China under Grant No. 2018YFE0204300, and the
   Beijing Science and Technology Plan Project (Z191100007419008), and the
   Guoqiang Research Institute Project (2019GQG1010), and the National
   Natural Science Foundation of China under Grant No. U1964203.},
Cited-References = {Akai N, 2018, IEEE INT C INT ROBOT, P3159, DOI 10.1109/IROS.2018.8594146.
   Aldibaja M, 2017, IEEE T IND INFORM, V13, P2369, DOI 10.1109/TII.2017.2713836.
   Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Aycard O, 1998, IEEE INT CONF ROBOT, P3135, DOI 10.1109/ROBOT.1998.680907.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Brasch N, 2018, IEEE INT C INT ROBOT, P393, DOI 10.1109/IROS.2018.8593828.
   Burgard W, 1999, ARTIF INTELL, V114, P3, DOI 10.1016/S0004-3702(99)00070-3.
   Burgard W., 2012, 26 AAAI C ART INT, P2024.
   Chen SW, 2020, IEEE ROBOT AUTOM LET, V5, P612, DOI 10.1109/LRA.2019.2963823.
   Ding W., 2020, 2020 P IEEE INT C RO.
   Doherty K, 2019, IEEE INT CONF ROBOT, P2419, DOI 10.1109/ICRA.2019.8794244.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Egger P, 2018, IEEE INT C INT ROBOT, P3430, DOI 10.1109/IROS.2018.8593854.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Gallagher G, 2009, IEEE INT CONF ROBOT, P4322.
   Grupp M., 2017, EVO PYTHON PACKAGE E.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Hahnel D, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P496, DOI 10.1109/IRDS.2002.1041439.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Li AQ, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1902, DOI 10.1109/IROS.2016.7759301.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Montesano L, 2005, IEEE INT CONF ROBOT, P4556.
   Redmon Joseph, 2018, ARXIV ABS 180402767.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Tardos JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340.
   Thrun S, 1998, AUTON ROBOT, V5, P253, DOI 10.1023/A:1008806205438.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Valencia R, 2014, IEEE INT CONF ROBOT, P3956, DOI 10.1109/ICRA.2014.6907433.
   Vineet V, 2015, IEEE INT CONF ROBOT, P75, DOI 10.1109/ICRA.2015.7138983.
   Wan GW, 2018, IEEE INT CONF ROBOT, P4670, DOI 10.1109/ICRA.2018.8461224.
   Wang BH, 2019, IEEE ROBOT AUTOM LET, V4, P2902, DOI 10.1109/LRA.2019.2922582.
   Wang CC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2918, DOI 10.1109/ROBOT.2002.1013675.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Xiao LH, 2019, ROBOT AUTON SYST, V117, P1, DOI 10.1016/j.robot.2019.03.012.
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691.},
Number-of-Cited-References = {38},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS8DT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000771405405115},
DA = {2022-05-17},
}

@article{ WOS:000662616300001,
Author = {Sobczak, Lukasz and Filus, Katarzyna and Domanski, Adam and Domanska,
   Joanna},
Title = {LiDAR Point Cloud Generation for SLAM Algorithm Evaluation},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {10},
Pages = {3313},
Month = {MAY},
Abstract = {With the emerging interest in the autonomous driving level at 4 and 5
   comes a necessity to provide accurate and versatile frameworks to
   evaluate the algorithms used in autonomous vehicles. There is a clear
   gap in the field of autonomous driving simulators. It covers testing and
   parameter tuning of a key component of autonomous driving systems, SLAM,
   frameworks targeting off-road and safety-critical environments. It also
   includes taking into consideration the non-idealistic nature of the
   real-life sensors, associated phenomena and measurement errors. We
   created a LiDAR simulator that delivers accurate 3D point clouds in real
   time. The point clouds are generated based on the sensor placement and
   the LiDAR type that can be set using configurable parameters. We
   evaluate our solution based on comparison of the results using an actual
   device, Velodyne VLP-16, on real-life tracks and the corresponding
   simulations. We measure the error values obtained using Google
   Cartographer SLAM algorithm and the distance between the simulated and
   real point clouds to verify their accuracy. The results show that our
   simulation (which incorporates measurement errors and the rolling
   shutter effect) produces data that can successfully imitate the
   real-life point clouds. Due to dedicated mechanisms, it is compatible
   with the Robotic Operating System (ROS) and can be used interchangeably
   with data from actual sensors, which enables easy testing, SLAM
   algorithm parameter tuning and deployment.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Sobczak, L (Corresponding Author), OBRUM Sp Zoo, R\&D Ctr Mech Appliances, Toszecka 102, PL-44117 Gliwice, Poland.
   Sobczak, L (Corresponding Author), Silesian Tech Univ, Fac Automat Control Elect \& Comp Sci, Dept Distributed Syst \& Informat Devices, Akad 16, PL-44100 Gliwice, Poland.
   Sobczak, Lukasz, OBRUM Sp Zoo, R\&D Ctr Mech Appliances, Toszecka 102, PL-44117 Gliwice, Poland.
   Sobczak, Lukasz; Domanski, Adam, Silesian Tech Univ, Fac Automat Control Elect \& Comp Sci, Dept Distributed Syst \& Informat Devices, Akad 16, PL-44100 Gliwice, Poland.
   Filus, Katarzyna; Domanska, Joanna, Polish Acad Sci, Inst Theoret \& Appl Informat, Baltycka 5, PL-44100 Gliwice, Poland.},
DOI = {10.3390/s21103313},
Article-Number = {3313},
EISSN = {1424-8220},
Keywords = {autonomous vehicles; LiDAR; autonomous driving; SLAM},
Keywords-Plus = {LARGE-SCALE; LONG-TERM; SIMULTANEOUS LOCALIZATION; OPTIMIZATION; NETWORK},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {lsobczak@obrum.gliwice.pl
   kfilus@iitis.pl
   adam.domanski@polsl.pl
   joanna@iitis.pl},
Affiliations = {Silesian University of Technology; Polish Academy of Sciences; Institute
   of Theoretical \& Applied Informatics of the Polish Academy of Sciences},
ORCID-Numbers = {Filus, Katarzyna/0000-0003-1303-9230
   Domanska, Joanna/0000-0002-1935-8358
   Sobczak, Lukasz/0000-0001-9439-1812},
Funding-Acknowledgement = {National Centre for Research and Development {[}DOB-2P/02/07/2017];
   Ministry of Science and Higher Education {[}10/DW/2017/01]},
Funding-Text = {This research was partially funded by The National Centre for Research
   and Development (DOB-2P/02/07/2017) and Ministry of Science and Higher
   Education (10/DW/2017/01).},
Cited-References = {{[}Anonymous], 2019, TRENDS APPEAR GARTNE.
   {[}Anonymous], CARTOGRAPHER.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   BMW Group, 2019, SAF ASS REP SAE LEV.
   Borcs A, 2017, IEEE GEOSCI REMOTE S, V14, P992, DOI 10.1109/LGRS.2017.2674799.
   Capellier E, 2019, IEEE INT VEH SYM, P1304, DOI 10.1109/IVS.2019.8813846.
   Chan S.H., 2018, P 2018 IEEE INT C SY.
   Clough B. T., 2002, P PERF METR INT SYST.
   Dang T., 2019, P 2019 19 INT C ADV.
   Deepika N., 2017, P 2017 INT C ADV COM.
   Deloitte, 2018, AUT DRIV MOONSH PROJ.
   Dosovitskiy Alexey, 2017, P 1 ANN C ROB LEARN.
   Droeschel D, 2018, IEEE INT CONF ROBOT, P5000, DOI 10.1109/ICRA.2018.8461000.
   Dwijotomo A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010347.
   Fang J., 181107112 ARXIV.
   Ferguson D, 2006, J FIELD ROBOT, V23, P79, DOI 10.1002/rob.20109.
   Filatov A., 2017, P 2017 21 C OP INN A.
   Filipenko M, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P400, DOI 10.1109/IS.2018.8710464.
   Goodin C, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7090154.
   Hansen EA, 2007, J ARTIF INTELL RES, V28, P267, DOI 10.1613/jair.2096.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hu XM, 2018, MECH SYST SIGNAL PR, V100, P482, DOI 10.1016/j.ymssp.2017.07.019.
   Huijuan Wang, 2011, 2011 Second International Conference on Mechanic Automation and Control Engineering, P1067.
   Ji X., 2019, P 2019 IEEE INT C ME.
   Jung S.H., 2001, P 2001 IEEE COMP SOC.
   Kim P, 2018, AUTOMAT CONSTR, V89, P38, DOI 10.1016/j.autcon.2018.01.009.
   Koide K, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419841532.
   Kroger F., 2016, AUTONOMOUS DRIVING T, P41, DOI DOI 10.1007/978-3-662-48847-8\_3.
   Kummerle R, 2009, AUTON ROBOT, V27, P387, DOI 10.1007/s10514-009-9155-6.
   Labbe M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Leighty R., 1986, DARPA ALV AUTONOMOUS.
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562.
   Li MG, 2019, IEEE ACCESS, V7, P14124, DOI 10.1109/ACCESS.2018.2889304.
   Li XY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060614.
   Liang CK, 2008, IEEE T IMAGE PROCESS, V17, P1323, DOI 10.1109/TIP.2008.925384.
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752.
   Ma LF, 2021, IEEE T INTELL TRANSP, V22, P821, DOI 10.1109/TITS.2019.2961060.
   Manivasagam S., 2020, P IEEE CVF C COMP VI, P11167, DOI DOI 10.1109/CVPR42600.2020.01118.
   Milijas R., 201102306 ARXIV.
   Moras J., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P84, DOI 10.1109/ICRA.2011.5980298.
   Moravec H.P., 1980, OBSTACLE AVOIDANCE N.
   Nuchter A, 2017, INT ARCH PHOTOGRAMM, V42-2, P543, DOI 10.5194/isprs-archives-XLII-2-W3-543-2017.
   Patel K., 2019, IEEE RAD CONF.
   Pomerleau D, 1988, TECH REP.
   Proud R. W., 2003, METHODS DETERMINING.
   Ren RK, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060613.
   Ren ZL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132915.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Shah S., 2017, FIELD SERVICE ROBOTI, DOI {[}DOI 10.1007/978-3-319-67361-5, DOI 10.1007/978-3-319-67361-5\_40, 10.1007/978-3-319-67361-5\_40].
   Sheridan TB, 1992, TELEROBOTICS AUTOMAT.
   Siam M., 2017, P 2017 IEEE 20 INT C.
   Tang I, 2011, IEEE T INTELL TRANSP, V12, P476, DOI 10.1109/TITS.2010.2095499.
   Urmson C, 2009, SPRINGER TRAC ADV RO, V56, P1.
   Velas M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183944.
   Wang F, 2019, IEEE T INSTRUM MEAS, V68, P2671, DOI 10.1109/TIM.2019.2906416.
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163.
   Wen CC, 2020, ISPRS J PHOTOGRAMM, V162, P50, DOI 10.1016/j.isprsjprs.2020.02.004.
   Wen JR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113668.
   Wevolver, 2020, AUTONOMOUS VEHICLE T.
   Williams A., 2015, AUTONOMOUS SYSTEMS I.
   Williams M, 1988, PHYSL IND FUNGI.
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887.
   Yue XY, 2018, ICMR `18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P458, DOI 10.1145/3206025.3206080.},
Number-of-Cited-References = {64},
Times-Cited = {3},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {16},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {ST7JP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000662616300001},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@article{ WOS:000380936500001,
Author = {Carlevaris-Bianco, Nicholas and Ushani, Arash K. and Eustice, Ryan M.},
Title = {University of Michigan North Campus long-term vision and lidar dataset},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2016},
Volume = {35},
Number = {9},
Pages = {1023-1035},
Month = {AUG},
Abstract = {This paper documents a large scale, long-term autonomy dataset for
   robotics research collected on the University of Michigan's North
   Campus. The dataset consists of omnidirectional imagery, 3D lidar,
   planar lidar, GPS, and proprioceptive sensors for odometry collected
   using a Segway robot. The dataset was collected to facilitate research
   focusing on long-term autonomous operation in changing environments. The
   dataset is composed of 27 sessions spaced approximately biweekly over
   the course of 15 months. The sessions repeatedly explore the campus,
   both indoors and outdoors, on varying trajectories, and at different
   times of the day across all four seasons. This allows the dataset to
   capture many challenging elements including: moving obstacles (e.g.
   pedestrians, bicyclists and cars), changing lighting, varying viewpoint,
   seasonal and weather changes (e.g. falling leaves and snow), and
   long-term structural changes caused by construction projects. To further
   facilitate research, we also provide ground-truth pose for all sessions
   in a single frame of reference.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Eustice, RM (Corresponding Author), Univ Michigan, Dept Naval Architecture \& Marine Engn, 204 NAME Bldg,2600 Draper Dr, Ann Arbor, MI 48109 USA.
   Carlevaris-Bianco, Nicholas; Ushani, Arash K., Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M., Univ Michigan, Dept Naval Architecture \& Marine Engn, 204 NAME Bldg,2600 Draper Dr, Ann Arbor, MI 48109 USA.},
DOI = {10.1177/0278364915614638},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Long-term SLAM; place recognition; lidar; computer vision; field and
   service robotics},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan},
Funding-Acknowledgement = {National Science Foundation {[}IIS-0746455]; Office of Naval Research
   {[}N00014-12-1-0092]; Naval Sea Systems Command through the Naval
   Engineering Education Center {[}N65540-10-C-0003]},
Funding-Text = {This work was supported in part by the National Science Foundation under
   award IIS-0746455, by the Office of Naval Research under award
   N00014-12-1-0092, and by the Naval Sea Systems Command through the Naval
   Engineering Education Center under award N65540-10-C-0003.},
Cited-References = {Badino H., 2011, CMU VISUAL LOCALIZAT.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Barfoot T. D., 2012, 2012 Canadian Conference on Computer and Robot Vision, P388, DOI 10.1109/CRV.2012.58.
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326.
   Carlevaris-Bianco N., 2012, IROS WORKSH LIF LEAR.
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Carlevaris-Bianco N, 2013, IEEE INT C INT ROBOT, P1034, DOI 10.1109/IROS.2013.6696478.
   Ceriani S, 2009, AUTON ROBOT, V27, P353, DOI 10.1007/s10514-009-9156-5.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Eustice R, 2005, THESIS.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Fallon M, 2013, INT J ROBOT RES, V32, P1695, DOI 10.1177/0278364913509035.
   Garmin International Inc, 2011, GPS 18X TECHN SPEC R.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Hokuyo Automatic Co. Ltd., 2012, SCANN LAS RANG FIND.
   Hokuyo Automatic Company Ltd, 2005, SCANN LAS RANG FIND.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Kanji T, 2014, IEEE INT C INT ROBOT, P136, DOI 10.1109/IROS.2014.6942552.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T, 2015, EUR C MOB ROB TROIA.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Krusi P, 2015, J FIELD ROBOT, V32, P534, DOI 10.1002/rob.21524.
   KVH Industires Inc, 2009, KVH DSP 3000 FIB OPT.
   Lategahn H, 2013, IEEE INT VEH SYM, P285, DOI 10.1109/IVS.2013.6629483.
   LiDAR Velodyne, 2012, US MAN PROGR GUID HD.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowry S, 2014, P AUSTR C ROB AUT ME.
   Masatoshi A, 2015, IEEE INT CONF ROBOT, P5455, DOI 10.1109/ICRA.2015.7139961.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   MicroStrain Inc, 2012, 3DM GX3 45 THEOR OP.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mishkin D., 2015, CVPR 2015 WORKSH VIS.
   Neubert P, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P198, DOI 10.1109/ECMR.2013.6698842.
   NovAtel Inc, 2005, DL 4PLUS US MAN REV.
   Olson E, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P1059, DOI 10.1109/IROS.2010.5650579.
   Pandey G, 2015, J FIELD ROB IN PRESS.
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640.
   Point Grey Research, 2011, LADYBUG3 TECH REF MA.
   Ranganathan A, 2013, IEEE INT CONF ROBOT, P3791, DOI 10.1109/ICRA.2013.6631110.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Sunderhauf N., 2013, ICRA WORKSH LONG TER.
   Vincenty T, 1975, SURV REV, V23, P88, DOI DOI 10.1179/SRE.1975.23.176.88.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {49},
Times-Cited = {113},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {39},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {DS7BC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000380936500001},
DA = {2022-05-17},
}

@inproceedings{ WOS:000558081900003,
Author = {Banerjee, Nandan and Lisin, Dimitri and Briggs, Jimmy and Llofriu,
   Martin and Munich, Mario E.},
Book-Author = {Preucil, L
   Behnke, S
   Kulich, M},
Book-Group-Author = {IEEE},
Title = {Lifelong Mapping using Adaptive Local Maps},
DOI = {10.1109/ECMR.2019.8870347},
Booktitle = {2019 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR)},
Year = {2019},
Note = {European Conference on Mobile Robots (ECMR), Prague, CZECH REPUBLIC, SEP
   04-06, 2019},
Abstract = {Occupancy mapping enables a mobile robot to make intelligent planning
   decisions to accomplish its tasks. Adaptive local maps is an algorithm
   which represents the occupancy information as a set of overlapping local
   maps anchored to poses in the robot's trajectory. At any time, a global
   occupancy map can be rendered from the local maps to be used for path
   planning. The advantage of this approach is that the occupancy
   information stays consistent despite the changes in the pose estimates
   resulting from loop closures and localization updates. The disadvantage,
   however, is that the number of local maps grows over time. For long
   robot runs, or for multiple runs in the same space, this growth will
   result in redundant occupancy information, which will in turn increase
   the time it takes to render the global map, as well as the memory
   footprint of the system. In this paper, we propose a novel approach for
   the maintenance of an adaptive local maps system, which intelligently
   prunes redundant local maps, ensuring the robustness and stability
   required for lifelong mapping.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Banerjee, N (Corresponding Author), iRobot Corp, Bedford, MA 01730 USA.
   Banerjee, Nandan; Lisin, Dimitri; Briggs, Jimmy; Llofriu, Martin; Munich, Mario E., iRobot Corp, Bedford, MA 01730 USA.},
ISBN = {978-1-7281-3605-9},
Keywords-Plus = {SLAM},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {nbanerjee@irobot.com
   dlisin@irobot.com
   jbriggs@irobot.com
   mllofriu@irobot.com
   mmunich@irobot.com},
Cited-References = {Aulinas J, 2010, ELECTRON LETT, V46, P564, DOI 10.1049/el.2010.2271.
   Banerjee N., 2019, IEEE RSJ INT C INT R.
   Bosse M. C., 2004, THESIS.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Caccavale A., 2018, WIREFRAME MAPPING RE, P1.
   Dymczyk M., 2016, IEEE INT C INT ROB S.
   Dymczyk M, 2015, IEEE INT C INT ROBOT, P2536, DOI 10.1109/IROS.2015.7353722.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Elfes A., 1989, THESIS.
   Garrote L, 2017, IEEE INT CONF AUTON, P228, DOI 10.1109/ICARSC.2017.7964080.
   Heinemann A., 2015, 2015 EUR MICR PACK C, P1.
   Ho BJ, 2018, IEEE INT C INT ROBOT, P2175, DOI 10.1109/IROS.2018.8594234.
   Hochdorfer S., 2009, IEEE INT C TECHN PRA.
   Hornung A., 2013, AUTONOMOUS ROBOTS.
   Kakuma D, 2017, IEEE INT C SEMANT CO, P57, DOI 10.1109/ICSC.2017.38.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kwon Y, 2019, IEEE T ROBOT, V35, P482, DOI 10.1109/TRO.2018.2889262.
   Leonard JJ, 2001, IEEE J OCEANIC ENG, V26, P561, DOI 10.1109/48.972094.
   Li H, 2014, IEEE T INTELL TRANSP, V15, P2089, DOI 10.1109/TITS.2014.2309639.
   Llofriu M, 2017, IEEE INT C INT ROBOT, P1403, DOI 10.1109/IROS.2017.8202320.
   Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Pinies P, 2008, IEEE T ROBOT, V24, P1094, DOI 10.1109/TRO.2008.2004636.
   Saarinen J., 2004, IFAC P VOLUMES, V37, P388.
   Schaefer G, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P1.
   Schauer Johannes, 2018, IEEE Robotics and Automation Letters, V3, P1679, DOI 10.1109/LRA.2018.2801797.
   Schiotka A, 2017, IEEE INT C INT ROBOT, P642, DOI 10.1109/IROS.2017.8202219.
   Ta D.-N., 2018, ROB AUT ICRA 2018 IE.
   Yue YF, 2018, IEEE SENS J, V18, P8933, DOI 10.1109/JSEN.2018.2867854.},
Number-of-Cited-References = {31},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BP5RM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000558081900003},
DA = {2022-05-17},
}

@article{ WOS:000329510300005,
Author = {Tipaldi, Gian Diego and Meyer-Delius, Daniel and Burgard, Wolfram},
Title = {Lifelong localization in changing environments},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1662-1678},
Month = {DEC},
Abstract = {Robot localization systems typically assume that the environment is
   static, ignoring the dynamics inherent in most real-world settings.
   Corresponding scenarios include households, offices, warehouses and
   parking lots, where the location of certain objects such as goods,
   furniture or cars can change over time. These changes typically lead to
   inconsistent observations with respect to previously learned maps and
   thus decrease the localization accuracy or even prevent the robot from
   globally localizing itself. In this paper we present a sound
   probabilistic approach to lifelong localization in changing environments
   using a combination of a Rao-Blackwellized particle filter with a hidden
   Markov model. By exploiting several properties of this model, we obtain
   a highly efficient map management approach for dynamic environments,
   which makes it feasible to run our algorithm online. Extensive
   experiments with a real robot in a dynamically changing environment
   demonstrate that our algorithm reliably adapts to changes in the
   environment and also outperforms the popular Monte-Carlo localization
   approach.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Tipaldi, GD (Corresponding Author), Univ Freiburg, Dept Comp Sci, Hugstetter Str 55, D-79106 Freiburg, Germany.
   Tipaldi, Gian Diego; Burgard, Wolfram, Univ Freiburg, Dept Comp Sci, D-79106 Freiburg, Germany.
   Meyer-Delius, Daniel, KUKA Labs GmbH, Augsburg, Germany.},
DOI = {10.1177/0278364913502830},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Mobile and distributed robotics SLAM; localization; mapping; cognitive
   robotics; learning and adaptive systems},
Keywords-Plus = {TUTORIAL},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {tipaldi@informatik.uni-freiburg.de},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
ResearcherID-Numbers = {Burgard, Wolfram/N-2381-2019},
ORCID-Numbers = {Burgard, Wolfram/0000-0002-5680-6500},
Funding-Acknowledgement = {European Commission {[}FP7-248258-FirstMM, FP7-260026-TAPAS,
   ERC-267686-LifeNav]},
Funding-Text = {This work was supported by the European Commission (grant numbers
   FP7-248258-FirstMM, FP7-260026-TAPAS and ERC-267686-LifeNav).},
Cited-References = {Anguelov D., 2002, P C UNC AI UAI.
   Avots D., 2002, P IEEE RSJ INT C INT.
   Biber P., 2005, P ROB SCI SYST RSS.
   Blake Andrew, 1987, VISUAL RECONSTRUCTIO.
   Brechtel S., 2010, P IEEE INT C ROB AUT.
   Chen C., 2006, P IEEE INT C CONTR A.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Eliazar A. I., 2004, P IEEE INT C ROB AUT.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Fox D, 2003, INT J ROBOT RES, V22, P985, DOI 10.1177/0278364903022012001.
   Gallagher G, 2009, P IEEE INT C ROB AUT.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   HAHNEL D, 2003, P IEEE INT C ROB AUT.
   Konolige K, 2009, P IEEE RSJ INT C INT.
   Konolige K, 2010, IEEE INT C INT ROBOT.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Levin D. A., 2008, MARKOV CHAINS MIXING.
   Meyer-Delius D., 2012, P AAAI C ART INT AAA.
   Meyer-Delius D., 2010, P IEEE RSJ INT C INT.
   Montemerlo M., 2002, P IEEE INT C ROB AUT.
   MONTESANO L, 2005, P IEEE INT C ROB AUT.
   Moravec H.P., 1985, P IEEE INT C ROB AUT.
   MURPHY K, 1999, P C NEUR INF PROC SY, P1015.
   Olson E, 2005, P ROB SCI SYST.
   Olson E., 2008, THESIS MIT CAMBRIDGE.
   Petrovskaya A., 2007, P INT C ART INT IJCA.
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626.
   Rowekamper J, 2012, P IEEE RSJ INT C INT.
   Saarinen J., 2012, P IEEE RSJ INT C INT.
   Schulz D, 2003, P INT C ART INT IJCA.
   STACHNISS C, 2005, P NAT C ART INT AAAI.
   Thrun S, 2001, INT J ROBOT RES, V20, P335, DOI 10.1177/02783640122067435.
   Walcott A, 2011, THESIS MIT CAMBRIDGE.
   Walcott-Bryant A, 2012, P IEEE RSJ INT C INT.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Yang SW, 2011, IEEE INT C ROB AUT I.},
Number-of-Cited-References = {39},
Times-Cited = {50},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {18},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300005},
DA = {2022-05-17},
}

@inproceedings{ WOS:000719424500110,
Author = {Burki, Mathias and Dymczyk, Marcin and Gilitschenski, Igor and Cadena,
   Cesar and Siegwart, Roland and Nieto, Juan},
Book-Group-Author = {IEEE},
Title = {Map Management for Efficient Long-Term Visual Localization in Outdoor
   Environments},
DOI = {10.1109/IVS.2018.8500432},
Booktitle = {2018 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV)},
Series = {IEEE Intelligent Vehicles Symposium},
Year = {2018},
Pages = {682-688},
Note = {IEEE Intelligent Vehicles Symposium (IV), Changshu, PEOPLES R CHINA, JUN
   26-30, 2018},
Abstract = {We present a complete map management process for a visual localization
   system designed for multi-vehicle long-term operations in resource
   constrained outdoor environments. Outdoor visual localization generates
   large amounts of data that need to be incorporated into a lifelong
   visual map in order to allow localization at all times and under all
   appearance conditions. Processing these large quantities of data is
   non-trivial, as it is subject to limited computational and storage
   capabilities both on the vehicle and on the mapping backend. We address
   this problem with a two-fold map update paradigm capable of, either,
   adding new visual cues to the map, or updating co-observation
   statistics. The former, in combination with offline map summarization
   techniques, allows enhancing the appearance coverage of the lifelong map
   while keeping the map size limited. On the other hand, the latter is
   able to significantly boost the appearance-based landmark selection for
   efficient online localization without incurring any additional
   computational or storage burden. Our evaluation in challenging outdoor
   conditions shows that our proposed map management process allows
   building and maintaining maps for precise visual localization over long
   time spans in a tractable and scalable fashion.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Burki, M (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Burki, Mathias; Dymczyk, Marcin; Gilitschenski, Igor; Cadena, Cesar; Siegwart, Roland; Nieto, Juan, Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.},
ISSN = {1931-0587},
ISBN = {978-1-5386-4452-2},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics;
   Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics; Transportation Science \& Technology},
Author-Email = {mathias.burki@mavt.ethz.ch
   marcin.dymczyk@mavt.ethz.ch
   igor.gilitschenski@mavt.ethz.ch
   cesar.cadena@mavt.ethz.ch
   roland.siegwart@mavt.ethz.ch
   juan.nieto@mavt.ethz.ch},
Affiliations = {ETH Zurich},
Funding-Acknowledgement = {EU H2020 research project {[}688652]; Swiss State Secretariat for
   Education, Research and Innovation (SERI) {[}15.0284]},
Funding-Text = {This project has received funding from the EU H2020 research project
   under grant agreement No 688652 and from the Swiss State Secretariat for
   Education, Research and Innovation (SERI) under contract number 15.0284.},
Cited-References = {Burki M., 2016, IROS.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Dymczyk M., 2016, IROS.
   Dymczyk M, 2015, IEEE INT C INT ROBOT, P2536, DOI 10.1109/IROS.2015.7353722.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Hartmann W, 2014, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2014.9.
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9\_54.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Lategahn H., 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P1, DOI 10.1109/ICVES.2012.6294279.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Loquercio Antonio, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3170, DOI 10.1109/ICRA.2017.7989359.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Muhlfellner P., 2015, JFR.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Pirker K, 2011, IEEE INT C INT ROBOT, P3990, DOI 10.1109/IROS.2011.6048253.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {22},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS4IK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000719424500110},
DA = {2022-05-17},
}

@article{ WOS:000458335100001,
Author = {Schuster, Martin J. and Schmid, Korbinian and Brand, Christoph and
   Beetz, Michael},
Title = {Distributed stereo vision-based 6D localization and mapping for
   multi-robot teams},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2019},
Volume = {36},
Number = {2},
Pages = {305-332},
Month = {MAR},
Abstract = {Joint simultaneous localization and mapping (SLAM) constitutes the basis
   for cooperative action in multi-robot teams. We designed a stereo
   vision-based 6D SLAM system combining local and global methods to
   benefit from their particular advantages: (1) Decoupled local reference
   filters on each robot for real-time, long-term stable state estimation
   required for stabilization, control and fast obstacle avoidance; (2)
   Online graph optimization with a novel graph topology and intra- as well
   as inter-robot loop closures through an improved submap matching method
   to provide global multi-robot pose and map estimates; (3) Distribution
   of the processing of high-frequency and high-bandwidth measurements
   enabling the exchange of aggregated and thus compacted map data. As a
   result, we gain robustness with respect to communication losses between
   robots. We evaluated our improved map matcher on simulated and
   real-world datasets and present our full system in five real-world
   multi-robot experiments in areas of up 3,000 m(2) (bounding box),
   including visual robot detections and submap matches as loop-closure
   constraints. Further, we demonstrate its application to autonomous
   multi-robot exploration in a challenging rough-terrain environment at a
   Moon-analogue site located on a volcano.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Schuster, MJ (Corresponding Author), German Aerosp Ctr DLR, RMC, Dept Percept \& Cognit, Munchener Str 20, D-82234 Wessling, Germany.
   Schuster, Martin J.; Brand, Christoph, German Aerosp Ctr DLR, RMC, Dept Percept \& Cognit, Munchener Str 20, D-82234 Wessling, Germany.
   Schmid, Korbinian, Roboception GmbH, Munich, Germany.
   Beetz, Michael, Univ Bremen, Inst Artificial Intelligence, Fac Comp Sci, Bremen, Germany.
   Beetz, Michael, Univ Bremen, Ctr Comp Technol TZI, Fac Comp Sci, Bremen, Germany.},
DOI = {10.1002/rob.21812},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {graph SLAM; map matching; mobile robots; multi-robot; navigation filter},
Keywords-Plus = {REAL-TIME; NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {martin.schuster@dlr.de},
Affiliations = {Helmholtz Association; German Aerospace Centre (DLR); University of
   Bremen; University of Bremen},
ORCID-Numbers = {Schuster, Martin/0000-0002-6983-3719},
Funding-Acknowledgement = {Helmholtz-Gemeinschaft {[}HA-304, ZT-0033]; FP7 Information and
   Communication Technologies},
Funding-Text = {Helmholtz-Gemeinschaft, Grant/Award Numbers: HA-304, ZT-0033; FP7
   Information and Communication Technologies},
Cited-References = {Agarwal P, 2013, IEEE INT CONF ROBOT, P62, DOI 10.1109/ICRA.2013.6630557.
   Ahmad A., 2013, IEEE INT C ROB AUT I, DOI {[}10.1109/ICRA.2013.6631396, DOI 10.1109/ICRA.2013.6631396].
   Ahmad L. A., 2012, WORKSH COL DEPTH CAM.
   Bailey T., 2006, IEEE RSJ INT C INT R.
   Brand C., 2015, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2015.7354182, DOI 10.1109/IROS.2015.7354182].
   Brand C., 2014, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2014.6942805, DOI 10.1109/IROS.2014.6942805].
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Cunningham A., 2013, IEEE INT C ROB AUT I, DOI {[}10.1109/ICRA.2013.6631323, DOI 10.1109/ICRA.2013.6631323].
   Dellaert F., 2015, GTSAM 3 2 1.
   Dong J, 2015, IEEE INT CONF ROBOT, P5807, DOI 10.1109/ICRA.2015.7140012.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199.
   Forster C., 2013, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2013.6696924, DOI 10.1109/IROS.2013.6696924].
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hellerer M., 2016, INT S ART INT ROB AU.
   Hesch JA, 2014, INT J ROBOT RES, V33, P182, DOI 10.1177/0278364913509675.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Hirschmuller H., 2002, IEEE INT C CONTR AUT, DOI {[}10.1109/ICARCV.2002.1238577, DOI 10.1109/ICARCV.2002.1238577].
   Holz D., 2014, INT S ROB ISR GERM C.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Kaess M., 2013, APRILTAGS C LIB.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kanzog C., 2017, ROBEX ROBOTIC EXPLOR.
   Kim B., 2010, IEEE INT C ROB AUT I, DOI {[}10.1109/ROBOT.2010.5509154, DOI 10.1109/ROBOT.2010.5509154].
   Koch P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5722, DOI 10.1109/IROS.2016.7759842.
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572.
   Kummerle R, 2011, AUTON ROBOT, V30, P25, DOI 10.1007/s10514-010-9204-1.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Latif Y., 2014, IEEE RSJ INT C INT R, DOI 10.1109/IROS.2014.6942929.
   Lazaro M. T., 2013, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2013.6696483, DOI 10.1109/IROS.2013.6696483].
   Lee G. H., 2013, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2013.6696406, DOI 10.1109/IROS.2013.6696406].
   Lehner H., 2017, IEEE RSJ INT C INT R.
   Leishman RC, 2013, INT CONF UNMAN AIRCR, P343.
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251.
   Li X., 2005, EUR S GEOM PROC.
   Lupton T, 2012, IEEE T ROBOT, V28, P61, DOI 10.1109/TRO.2011.2170332.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Mendes E, 2016, IEEE INT SYMP SAFE, P195, DOI 10.1109/SSRR.2016.7784298.
   Michael N, 2012, J FIELD ROBOT, V29, P832, DOI 10.1002/rob.21436.
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P423, DOI 10.1109/TASE.2015.2408456.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Nagatani K., 2011, J FIELD ROBOT, V28, P373.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Nuchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209.
   Olson Edwin, 2011, 2011 IEEE International Conference on Robotics and Automation, P3400.
   Pinies P, 2008, IEEE T ROBOT, V24, P1094, DOI 10.1109/TRO.2008.2004636.
   Quang P. Bui, 2010, PROC 13 INT C INF FU, P1.
   Reid R., 2011, Proceedings of the 2011 IEEE 5th International Conference on Robotics, Automation and Mechatronics (RAM), P239, DOI 10.1109/RAMECH.2011.6070489.
   Roumeliotis S. I., 2002, IEEE INT C ROB AUT I, DOI {[}10.1109/ROBOT.2002.1014801, DOI 10.1109/ROBOT.2002.1014801].
   Saeedi S, 2016, J FIELD ROBOT, V33, P3, DOI 10.1002/rob.21620.
   Schadler M., 2014, DATA SET SPACEBOT AR.
   Schmid K., 2014, C INF FUS FUSION.
   Schmid K., 2012, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2012.6385969, DOI 10.1109/IROS.2012.6385969].
   Schmid K, 2014, J FIELD ROBOT, V31, P537, DOI 10.1002/rob.21506.
   Schuster M. J., 2015, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2015.7354094, DOI 10.1109/IROS.2015.7354094].
   Schuster MJ, 2019, J INTELL ROBOT SYST, V93, P461, DOI 10.1007/s10846-017-0680-9.
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252.
   Souvannavong F., 2010, INT S ART INT ROB AU.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Tombari F., 2010, 4 PAC RIM S IM VID T, P349, DOI DOI 10.1109/PSIVT.2010.65.
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679.
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1\_26.
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573.
   Vidal-Calleja TA, 2011, ROBOT AUTON SYST, V59, P654, DOI 10.1016/j.robot.2011.05.008.
   Wedler A, 2017, INT ASTR C IAC.
   Weiss S., 2012, THESIS.
   Williams S. B., 2002, IEEE INT C ROB AUT I, DOI {[}10.1109/ROBOT.2002.1013647, DOI 10.1109/ROBOT.2002.1013647].
   Williams S, 2014, INT J ROBOT RES, V33, P1544, DOI 10.1177/0278364914531056.
   Wolchover N., 2011, NASA GIVES STUCK MAR.
   Yamauchi B., 1998, Proceedings of the Second International Conference on Autonomous Agents, P47, DOI 10.1145/280765.280773.
   Yousif K., 2014, IEEE RSJ INT C INT R, DOI {[}10.1109/IROS.2014.6942925, DOI 10.1109/IROS.2014.6942925].},
Number-of-Cited-References = {74},
Times-Cited = {18},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {24},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {HK9TP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000458335100001},
OA = {hybrid, Green Accepted},
DA = {2022-05-17},
}

@article{ WOS:000624651500001,
Author = {Arshad, Saba and Kim, Gon-Woo},
Title = {Role of Deep Learning in Loop Closure Detection for Visual and Lidar
   SLAM: A Survey},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {4},
Pages = {1243},
Month = {FEB},
Abstract = {Loop closure detection is of vital importance in the process of
   simultaneous localization and mapping (SLAM), as it helps to reduce the
   cumulative error of the robot's estimated pose and generate a consistent
   global map. Many variations of this problem have been considered in the
   past and the existing methods differ in the acquisition approach of
   query and reference views, the choice of scene representation, and
   associated matching strategy. Contributions of this survey are
   many-fold. It provides a thorough study of existing literature on loop
   closure detection algorithms for visual and Lidar SLAM and discusses
   their insight along with their limitations. It presents a taxonomy of
   state-of-the-art deep learning-based loop detection algorithms with
   detailed comparison metrics. Also, the major challenges of conventional
   approaches are identified. Based on those challenges, deep
   learning-based methods were reviewed where the identified challenges are
   tackled focusing on the methods providing long-term autonomy in various
   conditions such as changing weather, light, seasons, viewpoint, and
   occlusion due to the presence of mobile objects. Furthermore, open
   challenges and future directions were also discussed.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Review},
Language = {English},
Affiliation = {Kim, GW (Corresponding Author), Chungbuk Natl Univ, Dept Control \& Robot Engn, Intelligent Robots Lab, Cheongju 28644, South Korea.
   Arshad, Saba; Kim, Gon-Woo, Chungbuk Natl Univ, Dept Control \& Robot Engn, Intelligent Robots Lab, Cheongju 28644, South Korea.},
DOI = {10.3390/s21041243},
Article-Number = {1243},
EISSN = {1424-8220},
Keywords = {simultaneous localization and mapping; loop closure detection; deep
   learning; neural networks; autonomous mobile robots},
Keywords-Plus = {REPRESENTATIONS; DISTRIBUTIONS; RECOGNITION; BAGS},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {sabarshad1000@gmail.com
   gwkim@cbnu.ac.kr},
Affiliations = {Chungbuk National University},
ORCID-Numbers = {Kim, Gon-Woo/0000-0002-4797-0464},
Funding-Acknowledgement = {Ministry of Trade, Industry and Energy (MOTIE); Korea Institute for
   Advancement of Technology (KIAT) through the International Cooperative
   RD program {[}P0004631]; MSIT (Ministry of Science and ICT), Korea,
   under the Grand Information Technology Research Center support program
   {[}IITP-2020-001462]; Institute of Information \& communications
   Technology Planning \& Evaluation (IITP) - Korea government (MSIT)
   {[}IITP-2020-0-00211]},
Funding-Text = {This research was financially supported in part by the Ministry of
   Trade, Industry and Energy (MOTIE) and Korea Institute for Advancement
   of Technology (KIAT) through the International Cooperative R\&D program
   (Project No. P0004631), in part by the MSIT (Ministry of Science and
   ICT), Korea, under the Grand Information Technology Research Center
   support program (IITP-2020-001462) supervised by the IITP (Institute for
   Information \& communications Technology Planning \& Evaluation) and in
   part by Institute of Information \& communications Technology Planning
   \& Evaluation (IITP) grant funded by the Korea government (MSIT)
   (IITP-2020-0-00211, Development of 5G based swarm autonomous logistics
   transport technology for smart post office).},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Azzam R, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-2001-3.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Bosse M, 2013, IEEE INT CONF ROBOT, P2677, DOI 10.1109/ICRA.2013.6630945.
   Bosse M, 2009, ROBOT AUTON SYST, V57, P1211, DOI 10.1016/j.robot.2009.07.009.
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324.
   Burgard W., 2008, ROBOTICS SCI SYSTEMS, P297.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Cadena C, 2010, IEEE INT C INT ROBOT, P5182, DOI 10.1109/IROS.2010.5650234.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Cascianelli S, 2017, ROBOT AUTON SYST, V92, P53, DOI 10.1016/j.robot.2017.03.004.
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625.
   Chen BF, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061120.
   Chen C, 2020, ARXIV200612567.
   Chen DM, 2010, IEEE DATA COMPR CONF, P525, DOI 10.1109/DCC.2010.53.
   Chen XYL, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Civera J., 2018, PPNIV WORKSH IROS 20.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693.
   Dalal N., 2005, 2005 IEEE COMPUTER S, P886, DOI {[}10.1109/CVPR.2005.177, DOI 10.1109/CVPR.2005.177].
   Debeunne C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072068.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Douillard B, 2011, IEEE INT CONF ROBOT.
   Douillard B, 2012, IEEE INT CONF ROBOT, P3033, DOI 10.1109/ICRA.2012.6224788.
   Douillard B., 2014, EXPT ROBOTICS, VVolume 79, P585.
   Drummond, 2008, BRIT MACH VIS C, V13, P136.
   Dube R, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Dube R, 2020, INT J ROBOT RES, V39, P339, DOI 10.1177/0278364919863090.
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Facil JM, 2019, ARXIV190209516.
   Fan YF, 2020, IEEE INT C INT ROBOT, P5158, DOI 10.1109/IROS45743.2020.9341517.
   Fernandez-Moral E, 2013, IEEE INT CONF ROBOT, P2719, DOI 10.1109/ICRA.2013.6630951.
   Fernandez-Moral E, 2016, ROBOT AUTON SYST, V75, P649, DOI 10.1016/j.robot.2015.09.009.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Galvez-Lopez D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525.
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376.
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2.
   Gao X, 2015, CHIN CONTR CONF, P5851, DOI 10.1109/ChiCC.2015.7260555.
   Garcia-Fidalgo Emilio, 2018, IEEE Robotics and Automation Letters, V3, P3051, DOI 10.1109/LRA.2018.2849609.
   Granstrom K, 2011, INT J ROBOT RES, V30, P1728, DOI 10.1177/0278364911405086.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hao Li, 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P267, DOI 10.1109/ICVES.2012.6294256.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   He Yuanlie, 2018, Computer Engineering, V44, P182, DOI 10.19678/j.issn.1000-3428.0047182.
   Himstedt M, 2014, IEEE INT C INT ROBOT, P5030, DOI 10.1109/IROS.2014.6943277.
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659.
   Hu MY, 2019, CHIN CONTR CONF, P4136, DOI 10.23919/ChiCC.2019.8866283.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003.
   Khan S, 2015, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2015.7139959.
   Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Li SP, 2019, ROBOT AUTON SYST, V112, P201, DOI 10.1016/j.robot.2018.11.009.
   Liao YY, 2017, IEEE T IMAGE PROCESS, V26, P2839, DOI 10.1109/TIP.2016.2605010.
   Likas A, 2003, PATTERN RECOGN, V36, P451.
   Lin J., 2019, ARXIV190911811.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Liu X, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19245419.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Magnusson M, 2007, J FIELD ROBOT, V24, P803, DOI 10.1002/rob.20204.
   Magnusson M, 2009, IEEE INT CONF ROBOT, P3364.
   Magnusson M, 2009, J FIELD ROBOT, V26, P892, DOI 10.1002/rob.20314.
   Memon AR, 2020, ROBOT AUTON SYST, V126, DOI 10.1016/j.robot.2020.103470.
   Merrill N, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Milioto A, 2019, IEEE INT C INT ROBOT, P4213, DOI 10.1109/IROS40897.2019.8967762.
   Muhammad N., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P333, DOI 10.1109/SSRR.2011.6106765.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Nieto J, 2006, SPRINGER TRAC ADV RO, V25, P167.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013.
   Pinies P, 2010, J FIELD ROBOT, V27, P561, DOI 10.1002/rob.20355.
   Qi C. R., 2017, ARXIV170602413.
   Qin H, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P426, DOI 10.1109/ICCAR.2018.8384713.
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690.
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91.
   Ren SQ, 2015, ADV NEUR IN, V28.
   Rohling T, 2015, IEEE INT C INT ROBOT, P736, DOI 10.1109/IROS.2015.7353454.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848.
   Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Schmiedel T, 2015, IEEE INT C INT ROBOT, P3144, DOI 10.1109/IROS.2015.7353812.
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x.
   Shin D.-W., 2018, ELECT IMAGING, V2018, P284, DOI {[}10.2352/ISSN.2470-1173.2018.17.AVM-284, DOI 10.2352/ISSN.2470-1173.2018.17.AVM-284].
   Silveira G, 2008, IEEE T ROBOT, V24, P969, DOI 10.1109/TRO.2008.2004829.
   Simonyan K, 2014, C TRACK P.
   Stuckler J, 2014, J VIS COMMUN IMAGE R, V25, P137, DOI 10.1016/j.jvcir.2013.02.008.
   Stumm E, 2016, PROC CVPR IEEE, P4535, DOI 10.1109/CVPR.2016.491.
   Sualeh M, 2019, INT J CONTROL AUTOM, V17, P729, DOI 10.1007/s12555-018-0130-x.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Tan W, 2013, INT SYM MIX AUGMENT, P209, DOI 10.1109/ISMAR.2013.6671781.
   Thrun S, 2006, KYBERNETES, V35, P1299, DOI {[}10.1108/03684920610675292, DOI 10.1108/03684920610675292].
   Tomono M, 2020, ADV ROBOTICS, V34, P1530, DOI 10.1080/01691864.2020.1824809.
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832.
   Vincent P, 2010, J MACH LEARN RES, V11, P3371.
   Walthelm A., 2004, INT C INT AUT SYST.
   Wang S, 2020, IEEE ACCESS, V8, P60552, DOI 10.1109/ACCESS.2020.2982228.
   Wang Y, 2018, 2018 IEEE THIRD INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, APPLICATIONS AND SYSTEMS (IPAS), P7, DOI 10.1109/IPAS.2018.8708875.
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207.
   Williams B, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2053, DOI 10.1109/IROS.2008.4650996.
   Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760.
   Xia YF, 2016, IEEE IJCNN, P2274, DOI 10.1109/IJCNN.2016.7727481.
   Xu H., 2018, DESTECH T COMPUT SCI, DOI {[}10.12783/dtcse/CCNT2018/24714, DOI 10.12783/DTCSE/CCNT2018/24714].
   Yang Y., 2020, ISPRS INT ARCH PHOTO, DOI {[}10.5194/isprs-archives-XLIV-M-2-2020-117-2020, DOI 10.5194/ISPRS-ARCHIVES-XLIV-M-2-2020-117-2020].
   Ye Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082299.
   Yin H, 2018, IEEE INT VEH SYM, P728.
   Yuan Liu, 2019, 2019 IEEE International Conferences on Ubiquitous Computing \& Communications (IUCC) and Data Science and Computational Intelligence (DSCI) and Smart Computing, Networking and Services (SmartCNS), P312, DOI 10.1109/IUCC/DSCI/SmartCNS.2019.00079.
   ywanowski K., 2020, ARXIV200903705.
   Zaganidis A, 2019, IEEE INT C INT ROBOT, P4562, DOI 10.1109/IROS40897.2019.8968140.
   Zhang XF, 2017, 2017 ANNUAL CONFERENCE ON SOFTWARE ANALYSIS, TESTING AND EVOLUTION (SATE 2017), P1, DOI 10.1109/SATE.2017.9.
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009.
   Zhou HY, 2019, IEEE T PATTERN ANAL, V41, P3022, DOI 10.1109/TPAMI.2018.2871832.
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6\_47.
   Zhu HW, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR), P477, DOI 10.1109/RCAR.2017.8311908.},
Number-of-Cited-References = {131},
Times-Cited = {10},
Usage-Count-Last-180-days = {64},
Usage-Count-Since-2013 = {97},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {QQ6RX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000624651500001},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@article{ WOS:000325244600003,
Author = {Kawewong, Aram and Tongprasit, Noppharit and Hasegawa, Osamu},
Title = {A speeded-up online incremental vision-based loop-closure detection for
   long-term SLAM},
Journal = {ADVANCED ROBOTICS},
Year = {2013},
Volume = {27},
Number = {17},
Pages = {1325-1336},
Month = {DEC 1},
Abstract = {An online incremental method of vision-only loop-closure detection for
   long-term robot navigation is proposed. The method is based on the
   scheme of direct feature matching which has recently become more
   efficient than the Bag-of-Words scheme in many challenging environments.
   The contributions of the paper are the application of hierarchical
   k-means to speed-up feature matching time and the improvement of the
   score calculation technique used to determine the loop-closing location.
   As a result, the presented method runs quickly in long term while
   retaining high accuracy. The searching cost has been markedly reduced.
   The proposed method requires no any off-line dictionary generation
   processes. It can start anywhere at any times. The evaluation has been
   done on standard well-known datasets being challenging in perceptual
   aliasing and dynamic changes. The results show that the proposed method
   offers high precision-recall in large-scale different environments with
   real-time computation comparing to other vision-only loop-closure
   detection methods.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Tongprasit, N (Corresponding Author), Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Imaging Sci \& Engn Lab, Midori Ku, 4259-J3 Nagatsuta, Yokohama, Kanagawa 2265803, Japan.
   Kawewong, Aram, Chiang Mai Univ, Fac Engn, Dept Comp Engn, Chiang Mai 50200, Thailand.
   Kawewong, Aram, Chiang Mai Univ, Mat Sci Res Ctr, Fac Sci, Chiang Mai 50200, Thailand.
   Tongprasit, Noppharit; Hasegawa, Osamu, Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Imaging Sci \& Engn Lab, Midori Ku, Yokohama, Kanagawa 2265803, Japan.},
DOI = {10.1080/01691864.2013.826410},
ISSN = {0169-1864},
EISSN = {1568-5535},
Keywords = {vision-based loop-closure detection; simultaneous localization and
   mapping; robotics navigation; place localization},
Keywords-Plus = {FAB-MAP},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {noppharit@gmail.com},
Affiliations = {Chiang Mai University; Chiang Mai University; Tokyo Institute of
   Technology},
Funding-Acknowledgement = {JST CREST Project of Japan; Thailand Research Fund; Thai Network
   Information Center Foundation {[}TRG5680062]; National Research
   University Project under Thailand's Office of Higher Education
   Commission},
Funding-Text = {This study was supported by a JST CREST Project of Japan, by The
   Thailand Research Fund and Thai Network Information Center Foundation
   (Grant No. TRG5680062), and by the research grant from the National
   Research University Project under Thailand's Office of Higher Education
   Commission.},
Cited-References = {Angeli A, 2009, P IEEE INTT C ROB AU.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Cummins M, 2010, IEEE T ROBOT, V26, P1042, DOI 10.1109/TRO.2010.2080390.
   Eade E., 2008, BRIT MACH VIS C BMVC.
   Filliat D, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P248, DOI 10.1109/IROS.2008.4650681.
   Kawewong A, 2011, ROBOT AUTON SYST, V59, P727, DOI 10.1016/j.robot.2011.05.007.
   Kawewong A, 2011, INT J ROBOT RES, V30, P33, DOI 10.1177/0278364910371855.
   Kawewong A, 2010, IEICE T INF SYST, VE93D, P2587, DOI 10.1587/transinf.E93.D.2587.
   KNUTH DE, 1992, AM MATH MON, V99, P403, DOI 10.2307/2325085.
   Krainin M, 2011, INT J ROBOT RES, V30, P1311, DOI 10.1177/0278364911403178.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Morioka H, 2011, P IEEE RSJ INT C INT.
   Nister D, 2006, P IEEE INT C COMP VI.
   Paul R., 2010, P IEEE INT C ROB AUT.
   Sivic J., 2003, P IEEE INT C COMP VI.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.},
Number-of-Cited-References = {19},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {17},
Journal-ISO = {Adv. Robot.},
Doc-Delivery-Number = {229EM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000325244600003},
DA = {2022-05-17},
}

@inproceedings{ WOS:000486572502069,
Author = {Liu, Kai and Wang, Hua and Han, Fei and Zhang, Hao},
Book-Group-Author = {AAAI},
Title = {Visual Place Recognition via Robust l(2)-Norm Distance Based Holism and
   Landmark Integration},
DOI = {10.1609/aaai.v33i01.33018034},
Booktitle = {THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST
   INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH
   AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE},
Year = {2019},
Pages = {8034-8041},
Note = {33rd AAAI Conference on Artificial Intelligence / 31st Innovative
   Applications of Artificial Intelligence Conference / 9th AAAI Symposium
   on Educational Advances in Artificial Intelligence, Honolulu, HI, JAN
   27-FEB 01, 2019},
Abstract = {Visual place recognition is essential for large-scale simultaneous
   localization and mapping (SLAM). Long-term robot operations across
   different time of the days, months, and seasons introduce new challenges
   from significant environment appearance variations. In this paper, we
   propose a novel method to learn a location representation that can
   integrate the semantic landmarks of a place with its holistic
   representation. To promote the robustness of our new model against the
   drastic appearance variations due to long-term visual changes, we
   formulate our objective to use non-squared l(2)-norm distances, which
   leads to a difficult optimization problem that minimizes the ratio of
   the l(2,1)-norms of matrices. To solve our objective, we derive a new
   efficient iterative algorithm, whose convergence is rigorously
   guaranteed by theory. In addition, because our solution is strictly
   orthogonal, the learned location representations can have better place
   recognition capabilities. We evaluate the proposed method using two
   large-scale benchmark data sets, the CMU-VL and Nordland data sets.
   Experimental results have validated the effectiveness of our new method
   in long-term visual place recognition applications.},
Publisher = {ASSOC ADVANCEMENT ARTIFICIAL INTELLIGENCE},
Address = {2275 E BAYSHORE RD, STE 160, PALO ALTO, CA 94303 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Liu, K (Corresponding Author), Colorado Sch Mines, Dept Comp Sci, Golden, CO 80401 USA.
   Liu, Kai; Wang, Hua; Han, Fei; Zhang, Hao, Colorado Sch Mines, Dept Comp Sci, Golden, CO 80401 USA.},
ISBN = {978-1-57735-809-1},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic},
Author-Email = {liukaizhijia@gmail.com
   huawangcs@gmail.com
   fhan@alumni.mines.edu
   hzhang@mines.edu},
Affiliations = {Colorado School of Mines},
ORCID-Numbers = {Zhang, Hao/0000-0001-8043-9184},
Funding-Acknowledgement = {National Science Foundation {[}NSF-IIS 1652943]; Army Research Office
   (ARO) {[}W911NF-17-1-0447]; U.S. Air Force Academy (USAFA)
   {[}FA7000-18-2-0016]; Distributed and Collaborative Intelligent Systems
   and Technology (DCIST) CRA {[}W911NF-17-2-0181]},
Funding-Text = {All correspondence should be addressed to: Hua Wang
   (huawangcs@gmail.com).This work was partially supported by National
   Science Foundation under Grant NSF-IIS 1652943. This research was also
   partially supported by Army Research Office (ARO) under Grant
   W911NF-17-1-0447, U.S. Air Force Academy (USAFA) under Grant
   FA7000-18-2-0016, and the Distributed and Collaborative Intelligent
   Systems and Technology (DCIST) CRA under Grant W911NF-17-2-0181.},
Cited-References = {Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016.
   CALZADA A, 2013, INT CONF MACH LEARN, P1836.
   Gao JB, 2008, NEURAL COMPUT, V20, P555, DOI 10.1162/neco.2007.11-06-397.
   Han F., 2018, AAAI.
   Han F, 2018, IEEE ROBOT AUTOM LET, V3, P3669, DOI 10.1109/LRA.2018.2856274.
   Han F, 2017, IEEE ROBOT AUTOM LET, V2, P1172, DOI 10.1109/LRA.2017.2662061.
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT, DOI {[}10.1007/b98835, DOI 10.1007/B98835].
   Latif Y, 2017, ROBOT AUTON SYST, V93, P13, DOI 10.1016/j.robot.2017.03.016.
   Lee H, 2013, INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION - 2012, VOL 9, PTS A AND B, P485.
   Liu K, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P397.
   Liu K, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2454.
   Liu K, 2018, PROC CVPR IEEE, P7727, DOI 10.1109/CVPR.2018.00806.
   Liu Y, 2017, IEEE T IMAGE PROCESS, V26, P684, DOI 10.1109/TIP.2016.2621667.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2012, IEEE INT CONF ROBOT, P822, DOI 10.1109/ICRA.2012.6224622.
   Naseer T., 2014, AAAI C ART INT.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Nie F, 2013, 23 INT JOINT C ART I.
   Nie F., 2011, IJCAI.
   Qiao YL, 2015, LECT NOTES ARTIF INT, V9414, P393, DOI 10.1007/978-3-319-27101-9\_30.
   Sunderhauf N., 2011, IEEE RSJ INT C INT R.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Sunderhauf Niko, 2013, WORKSH IEEE INT C RO.
   Wang H., 2013, P ICML, P352.
   Wang H, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1328.
   Wright John, 2009, NIPS, P116.
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224.
   Xiang SM, 2008, PATTERN RECOGN, V41, P3600, DOI 10.1016/j.patcog.2008.05.018.
   Yuan L., 2011, WORKSH IEEE RSJ INT.
   Zhang H, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII.},
Number-of-Cited-References = {31},
Times-Cited = {5},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BN6ZH},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000486572502069},
DA = {2022-05-17},
}

@inproceedings{ WOS:000297477501033,
Author = {Kretzschmar, Henrik and Stachniss, Cyrill and Grisetti, Giorgio},
Book-Group-Author = {IEEE},
Title = {Efficient Information-Theoretic Graph Pruning for Graph-Based SLAM with
   Laser Range Finders},
DOI = {10.1109/IROS.2011.6094414},
Booktitle = {2011 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2011},
Pages = {865-871},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems, San
   Francisco, CA, SEP 25-30, 2011},
Abstract = {In graph-based SLAM, the pose graph encodes the poses of the robot
   during data acquisition as well as spatial constraints between them. The
   size of the pose graph has a substantial influence on the runtime and
   the memory requirements of a SLAM system, which hinders long-term
   mapping. In this paper, we address the problem of efficient
   information-theoretic compression of pose graphs. Our approach estimates
   the expected information gain of laser measurements with respect to the
   resulting occupancy grid map. It allows for restricting the size of the
   pose graph depending on the information that the robot acquires about
   the environment or based on a given memory limit, which results in an
   any-space SLAM system. When discarding laser scans, our approach
   marginalizes out the corresponding pose nodes from the graph. To avoid a
   densely connected pose graph, which would result from exact
   marginalization, we propose an approximation to marginalization that is
   based on local Chow-Liu trees and maintains a sparse graph. Real world
   experiments suggest that our approach effectively reduces the growth of
   the pose graph while minimizing the loss of information in the resulting
   grid map.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kretzschmar, H (Corresponding Author), Univ Freiburg, Dept Comp Sci, Freiburg, Germany.
   Kretzschmar, Henrik; Stachniss, Cyrill; Grisetti, Giorgio, Univ Freiburg, Dept Comp Sci, Freiburg, Germany.},
ISSN = {2153-0858},
ISBN = {978-1-61284-455-8},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic; Robotics},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
ResearcherID-Numbers = {Stachniss, Cyrill/AAH-3034-2019
   Grisetti, Giorgio/F-3844-2011
   },
ORCID-Numbers = {Grisetti, Giorgio/0000-0002-8038-9989},
Cited-References = {CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Davison A. J., 2005, P INT C COMP VIS ICC, V1.
   Eade E, 2010, IEEE INT C INT ROBOT, P3017, DOI 10.1109/IROS.2010.5649205.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Grisetti G., 2010, P IEEE INT C ROB AUT.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Kaess M, 2009, ROBOT AUTON SYST, V57, P1198, DOI 10.1016/j.robot.2009.06.008.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   KRAUSE A, 2005, P UNC ART INT UAI.
   Kretzschmar H., 2010, KI KUNSTLICHE INTELL.
   MacKay DJ., 2003, INFORM THEORY INFERE.
   Olson E., 2008, THESIS MIT CAMBRIDGE.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Snavely N., 2008, P IEEE C COMP VIS PA, P1.},
Number-of-Cited-References = {15},
Times-Cited = {28},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BXX70},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000297477501033},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000458872703005,
Author = {Rodrigues, Romulo T. and Pedro Aguiar, A. and Pascoal, Antonio},
Editor = {Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L},
Book-Author = {Kosecka, J},
Title = {A B-spline Mapping Framework for Long-Term Autonomous Operations},
DOI = {10.1109/IROS.2018.8594456},
Booktitle = {2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2018},
Pages = {3204-3209},
Note = {25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Madrid, SPAIN, OCT 01-05, 2018},
Abstract = {This paper presents a 2D B-spline mapping framework for representing
   unstructured environments in a compact manner. While occupancy-grid and
   landmark-based maps have been successfully employed by the robotics
   community in indoor scenarios, outdoor long-term autonomous operations
   require a more compact representation of the environment. This work
   tackles this problem by interpolating the data of a high frequency
   sensor using B-spline curves. Compared to lines and circles, splines are
   more powerful in the sense that they allow for the description of more
   complex shapes in the scene. In this work, spline curves are
   continuously tracked and aligned across multiple sensor readings using
   lightweight methods, making the proposed framework suitable for robot
   navigation in outdoor missions. In particular, a Simultaneous
   Localization and Mapping (SLAM) algorithm specifically tailored for
   B-spline maps is presented here. The efficacy of the proposed framework
   is demonstrated by Software-in-the-Loop (SiL) simulations in different
   scenarios.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Rodrigues, RT (Corresponding Author), Univ Porto, Fac Engn, Porto, Portugal.
   Rodrigues, Romulo T.; Pedro Aguiar, A., Univ Porto, Fac Engn, Porto, Portugal.
   Pascoal, Antonio, Univ Lisbon, ISR IST, Lab Robot \& Engn Syst LARSyS, Lisbon, Portugal.},
ISSN = {2153-0858},
ISBN = {978-1-5386-8094-0},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {rtr@fc.up.pt
   pedro.aguiar@fe.up.pt
   antonio@isr.tecnico.ulisboa.pt},
Affiliations = {Universidade do Porto; Universidade de Lisboa},
ResearcherID-Numbers = {Rodrigues, Rômulo/AAP-7335-2021
   Aguiar, A. Pedro/L-4305-2014
   PASCOAL, ANTONIO/N-4791-2017},
ORCID-Numbers = {Rodrigues, Rômulo/0000-0003-0834-2737
   Aguiar, A. Pedro/0000-0001-7105-0505
   PASCOAL, ANTONIO/0000-0002-0657-6671},
Funding-Acknowledgement = {FEDER funds through COMPETE2020 Programa Operacional Competitividade e
   Internacionalizacao (POCI) {[}IMPROVE -POCI-01-0145-FEDER-031823];
   national funds (PIDDAC) through FCT/MCTES; Programa Operacional Regional
   do Norte (NORTE 2020) {[}PDMA -NORTE-08-5369-FSE-000061]; Portuguese FCT
   Project {[}UID/EEA/5009/2013]},
Funding-Text = {This work was supported by projects IMPROVE -POCI-01-0145-FEDER-031823 -
   funded by FEDER funds through COMPETE2020 Programa Operacional
   Competitividade e Internacionalizacao (POCI) and by national funds
   (PIDDAC) through FCT/MCTES; PDMA -NORTE-08-5369-FSE-000061, through
   Programa Operacional Regional do Norte (NORTE 2020); and the Portuguese
   FCT Project UID/EEA/5009/2013.},
Cited-References = {Bourgault F, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P540, DOI 10.1109/IRDS.2002.1041446.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   CROWLEY JL, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P674, DOI 10.1109/ROBOT.1989.100062.
   de Boor C, 1978, PRACTICAL GUIDE SPLI.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   International Organization for Standardization (ISO), 2015, 1189812015EN ISO, P1.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Liu M, 2010, IEEE INT CONF ROBOT, P4062, DOI 10.1109/ROBOT.2010.5509441.
   Lyche T., 1998, SPLINE METHODS.
   Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
   Murray D., 2007, P 6 IEEE ACM INT S M.
   Pedraza L, 2009, IEEE T ROBOT, V25, P353, DOI 10.1109/TRO.2009.2013496.
   Sack D., 2004, P 5 IFAC S INT AUT V.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Vandorpe J, 1996, IEEE INT CONF ROBOT, P901, DOI 10.1109/ROBOT.1996.503887.
   Wallgrn J. O., 2009, HIERARCHICAL VORONOI.
   Wolter D, 2004, LECT NOTES COMPUT SC, V3238, P439.},
Number-of-Cited-References = {17},
Times-Cited = {2},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BM0LT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000458872703005},
DA = {2022-05-17},
}

@inproceedings{ WOS:000227005400144,
Author = {Spero, DJ and Jarvis, RA},
Book-Group-Author = {IEEE},
Title = {Towards exteroceptive based localisation},
DOI = {10.1109/RAMECH.2004.1438024},
Booktitle = {2004 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1
   AND 2},
Year = {2004},
Pages = {822-827},
Note = {IEEE Conference on Robotics, Automation and Mechatronics, Singapore,
   SINGAPORE, DEC 01-03, 2004},
Abstract = {The intelligent application of a mobile robot, outside the experimental
   laboratory, requires a robust locomotive strategy that is rarely
   conducive to stringent kinematic modeling. Localisation methods that
   rely upon such modeling often fail, as model boundaries succumb to
   unpredictable events. This paper presents the development of a
   self-contained localisation system that purposely obviates the need for
   odometric information, and an associated kinematic model, to provide
   robot anonymity. Without odometry, the system is oblivious to the
   non-systematic vagaries of the robotic platform interacting with a
   natural domain. The proposed system hypothesises about the robot's
   absolute pose by algorithmically solving the kidnapped robot problem
   using exteroceptive based perception. Since no a priori information is
   assumed, long-term pose fixes are derived within a simultaneous
   localisation and mapping (SLAM) framework. Preliminary results were
   gathered using a skid steering mobile robot, equipped with a scanning
   laser rangefinder, in an outdoor environment. This novel localisation
   approach was found to be efficient and robust, while exhibiting the
   capacity for widespread applicability.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Spero, DJ (Corresponding Author), Monash Univ, Intelligent Robot Res Ctr, Clayton, Vic 3800, Australia.
   Monash Univ, Intelligent Robot Res Ctr, Clayton, Vic 3800, Australia.},
ISBN = {0-7803-8645-0},
Keywords = {mobile robots; autonomous navigation; localisation; kidnapped robot
   problem; SLAM},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {dorian@ieee.org},
Affiliations = {Monash University},
Cited-References = {BAILEY T, 2000, P IEEE INT C ROB AUT, P2512.
   BER M, 1992, COMPUTING EUCLIDEAN, P23.
   Borenstein J, 1997, J ROBOTIC SYST, V14, P231.
   CHAND DR, 1970, J ACM, V17, P78, DOI 10.1145/321556.321564.
   Hebert M., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P102, DOI 10.1109/ROBOT.2000.844046.
   KEMURDJIAN A, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P165, DOI 10.1109/ROBOT.1992.220318.
   LEONARD JJ, 1991, IEEE RSJ INT WORKSH, V3, P1442, DOI DOI 10.1109/IR0S.1991.174711.
   LU F, 1994, P IEEE COMP SOC C CO, P935.
   PARDALOS PM, 1994, J GLOBAL OPTIM, V4, P301, DOI 10.1007/BF01098364.
   SPERO DJ, 2002, AUSTR C ROB AUT AUCK, P228.
   Yim M, 2002, IEEE SPECTRUM, V39, P30, DOI 10.1109/6.981854.
   Zilberstein S, 1996, AUTON ROBOT, V3, P31, DOI 10.1007/BF00162466.},
Number-of-Cited-References = {12},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BBP97},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000227005400144},
DA = {2022-05-17},
}

@inproceedings{ WOS:000449748100019,
Author = {Shaik, Nayabrasul and Liebig, Thomas and Kirsch, Christopher and
   Mueller, Heinrich},
Editor = {KernIsberner, G and Furnkranz, J and Thimm, M},
Title = {Dynamic Map Update of Non-static Facility Logistics Environment with a
   Multi-robot System},
Booktitle = {KI 2017: ADVANCES IN ARTIFICIAL INTELLIGENCE},
Series = {Lecture Notes in Artificial Intelligence},
Year = {2017},
Volume = {10505},
Pages = {249-261},
Note = {40th Annual German Conference on Artificial Intelligene (KI), Dortmund,
   GERMANY, SEP 25-29, 2017},
Abstract = {Autonomous robots need to perceive and represent their environments and
   act accordingly. Using simultaneous localization and mapping (SLAM)
   methods, robots can build maps of the environment which are efficient
   for localization and path planning as long as the environment remains
   unchanged. However, facility logistics environments are not static
   because pallets and other obstacles are stored temporarily.
   This paper proposes a novel solution for updating maps of changing
   environments (i.e. environments with low-dynamic or semi-static objects)
   in real-time with multiple robots. Each robot is equipped with a laser
   range sensor and runs localization to estimate its position. Each robot
   senses the change in the environment with respect to a current map,
   initially built with a SLAM method, and constructs a temporary map which
   will be merged into the current map using localization information and
   line features of the map. This procedure enables the creation of
   long-term mapping robot systems for facility logistics.},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Shaik, N (Corresponding Author), TU Dortmund Univ, Dortmund, Germany.
   Shaik, Nayabrasul; Liebig, Thomas; Mueller, Heinrich, TU Dortmund Univ, Dortmund, Germany.
   Kirsch, Christopher, Fraunhofer Inst Mat Flow \& Logist, Dortmund, Germany.},
DOI = {10.1007/978-3-319-67190-1\_19},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-67190-1; 978-3-319-67189-5},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods},
Author-Email = {nayabrasul.shaik@tu-dortmund.de
   thomas.liebig@tu-dortmund.de
   Christopher.Kirsch@iml.fraunhofer.de
   heinrich.mueller@tu-dortmund.de},
Affiliations = {Dortmund University of Technology; Fraunhofer Gesellschaft},
Funding-Acknowledgement = {Deutsche Forschungsgemeinschaft (DFG) within the Collaborative Research
   Center {[}SFB 876]; European Union Horizon 2020 Programme
   (Horizon2020/2014-2020) {[}688380]},
Funding-Text = {The authors were partially funded by Deutsche Forschungsgemeinschaft
   (DFG) within the Collaborative Research Center SFB 876, project B2 (the
   study was also performed in collaboration with project B4) and the
   European Union Horizon 2020 Programme (Horizon2020/2014-2020), under
   grant agreement number 688380 ``VaVeL: Variety, Veracity, VaLue:
   Handling the Multiplicity of Urban Sensors{''}.},
Cited-References = {Abrate F, 2013, SPRINGER TRAC ADV RO, V83, P147.
   Carpin S, 2008, AUTON ROBOT, V25, P305, DOI 10.1007/s10514-008-9097-4.
   Clementini E., 2017, P 13 INT C SPAT INF.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Fenwick J. W., 2002, COOPERATIVE CONCURRE, P1810.
   Howard A, 2006, INT J ROBOT RES, V25, P1243, DOI 10.1177/0278364906072250.
   Jensen B., 2003, INFORMATIK AKTUELL, P21, DOI {[}10.1007/978-3-642-18986-9\_3, DOI 10.1007/978-3-642-18986-9\_3].
   Kamagaew A., 2011, 2011 5th International Conference on Automation, Robotics and Applications (ICARA 2011), P40, DOI 10.1109/ICARA.2011.6144853.
   Kleiner A, 2011, IEEE INT C INT ROBOT, P3276, DOI 10.1109/IROS.2011.6048339.
   Kohlbrecher S, 2011, P IEEE INT S SAF SEC.
   Lakaemper R., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3846.
   Lee HC, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT INTELLIGENCE (URAL), P285, DOI 10.1109/URAI.2012.6462995.
   Liebig T., 2013, CITIZEN SENSOR NETWO, P67.
   Liebig T, 2017, INFORM SYST, V64, P258, DOI 10.1016/j.is.2016.01.007.
   Liebig T, 2012, ICAART: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL. 2, P270, DOI 10.5220/0003833802700275.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Mitsou N.C., 2007, CONTR AUT 2007 MED 0, P1.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Thrun S., 2005, INTELLIGENT ROBOTICS.
   Tibaldi F., 2010, 41 INT S ROB ISR 6 G, P1.
   Trentin A, 2013, IEEE ENER CONV, P1, DOI 10.1109/ECCE.2013.6646673.
   Walcott A. N, 2011, THESIS.},
Number-of-Cited-References = {22},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {6},
Doc-Delivery-Number = {BL3JD},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000449748100019},
DA = {2022-05-17},
}

@article{ WOS:000316820200003,
Author = {Ball, David and Heath, Scott and Wiles, Janet and Wyeth, Gordon and
   Corke, Peter and Milford, Michael},
Title = {OpenRatSLAM: an open source brain-based SLAM system},
Journal = {AUTONOMOUS ROBOTS},
Year = {2013},
Volume = {34},
Number = {3},
Pages = {149-176},
Month = {APR},
Abstract = {RatSLAM is a navigation system based on the neural processes underlying
   navigation in the rodent brain, capable of operating with low resolution
   monocular image data. Seminal experiments using RatSLAM include mapping
   an entire suburb with a web camera and a long term robot delivery trial.
   This paper describes OpenRatSLAM, an open-source version of RatSLAM with
   bindings to the Robot Operating System framework to leverage advantages
   such as robot and sensor abstraction, networking, data playback, and
   visualization. OpenRatSLAM comprises connected ROS nodes to represent
   RatSLAM's pose cells, experience map, and local view cells, as well as a
   fourth node that provides visual odometry estimates. The nodes are
   described with reference to the RatSLAM model and salient details of the
   ROS implementation such as topics, messages, parameters, class diagrams,
   sequence diagrams, and parameter tuning strategies. The performance of
   the system is demonstrated on three publicly available open-source
   datasets.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Ball, D (Corresponding Author), Queensland Univ Technol, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4001, Australia.
   Ball, David; Wyeth, Gordon; Corke, Peter; Milford, Michael, Queensland Univ Technol, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4001, Australia.
   Heath, Scott; Wiles, Janet, Queensland Univ Technol, Sch Informat Technol \& Elect Engn, Brisbane, Qld 4001, Australia.},
DOI = {10.1007/s10514-012-9317-9},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {RatSLAM; OpenRatSLAM; SLAM; Navigation; Mapping; Brain-based;
   Appearance-based; ROS; Open-source; Hippocampus},
Keywords-Plus = {PROBABILISTIC LOCALIZATION; NAVIGATION; VISION; MAP},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {david.ball@qut.edu.au
   michael.milford@qut.edu.au},
Affiliations = {Queensland University of Technology (QUT); Queensland University of
   Technology (QUT)},
ResearcherID-Numbers = {Corke, Peter/C-6770-2009
   Milford, Michael/J-1304-2012
   },
ORCID-Numbers = {Corke, Peter/0000-0001-6650-367X
   Milford, Michael/0000-0002-5162-1793
   Wyeth, Gordon/0000-0002-4996-3612},
Funding-Acknowledgement = {Australian Research Council under Discovery Project {[}DP0987078,
   DP1212775]; Australian Research Council under Special Research
   Initiative on Thinking Systems {[}TS0669699]},
Funding-Text = {This work was supported in part by the Australian Research Council under
   a Discovery Project Grant DP0987078 to GW and JW, a Special Research
   Initiative on Thinking Systems TS0669699 to GW and JW and a Discovery
   Project Grant DP1212775 to MM. We would like to thank Samuel Brian for
   coding an iRat ground truth tracking system.},
Cited-References = {Andreasson H, 2008, IEEE T ROBOT, V24, P991, DOI 10.1109/TRO.2008.2004642.
   Ball D., 2009, RATSLAM.
   Ball D., 2010, AUSTR C ROB AUT BRIS.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Cummins M., 2009, ROBOTICS SCI SYSTEMS.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721.
   Heath S., 2011, AUSTR C ROB AUT MELB.
   Jacobson A., 2012, BRAIN BASED SENSOR F.
   Knuth D., 1977, INFORM PROCESSING LE, P6.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2008, SPRINGER TRAC ADV RO, V39, P179.
   Kyprou S., 2009, SIMPLE EFFECTIVE PER.
   Labbe M., 2011, IEEE RSJ INT C INT R.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Milford M., 2008, INT C ROB AUT PAS US.
   Milford M., 2013, IEEE INT C ROB AUT.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520.
   Milford MJ, 2010, PLOS COMPUT BIOL, V6, DOI 10.1371/journal.pcbi.1000995.
   Milford MJ, 2008, SPRINGER TRAC ADV RO, V41, P1.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Quigley M, 2009, IEEE INT C ROB AUT K.
   Samsonovich A, 1997, J NEUROSCI, V17, P5900.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Smith Devin, 2009, J COMPUTING SCI COLL, V24, P168.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Strasdat H., 2010, SCALE DRIFT AWARE LA.
   Sunderhauf N, 2010, IEEE INT C EMERG.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Zhang Alan M, 2009, International Journal of Robotics Research, V28, P331, DOI 10.1177/0278364908098412.
   Zoccolan D, 2009, P NATL ACAD SCI USA, V106, P8748, DOI 10.1073/pnas.0811583106.},
Number-of-Cited-References = {35},
Times-Cited = {53},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {60},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {115NX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000316820200003},
DA = {2022-05-17},
}

@article{ WOS:000368801800006,
Author = {An, Su-Yong and Lee, Lae-Kyoung and Oh, Se-Young},
Title = {Ceiling vision-based active SLAM framework for dynamic and wide-open
   environments},
Journal = {AUTONOMOUS ROBOTS},
Year = {2016},
Volume = {40},
Number = {2},
Pages = {291-324},
Month = {FEB},
Abstract = {A typical indoor environment can be divided into three categories;
   office (or room), hallway, and wide-open space such as lobby and hall.
   There have been numerous approaches for solving simultaneous
   localization and mapping (SLAM) problem in office (or room) and hallway.
   However, direct application of the existing approaches to wide-open
   space may be failed, because it has some distinguished features compared
   to other indoor places. To solve this problem, this paper proposes a new
   ceiling vision-based active SLAM framework, with an emphasis on
   practical deployment of service robot for commercial use in dynamically
   changing and wide-open environments by adopting the ceiling vision.
   First, for defining ceiling feature which can be extracted regardless of
   complexity of ceiling pattern we introduce a model-free landmark, i.e.,
   visual node descriptor, which consists of edge points and their
   orientations in image space. Second, a recursive `explore and exploit'
   is proposed for autonomous mapping. It is recursively performed by
   spreading out mapped area gradually while the robot is actively
   localized in the map. It can improve map accuracy due to frequent small
   loop closing. Third, a dynamic edge link (DEL) is proposed to cope with
   environmental changes in the map. Owing to DEL, we do not need to filter
   out corrupted sensor data and to distinguish moving object from static
   one. Also, a self-repairing map mechanism is introduced to deal with
   unexpected installation or removal of inner structures. We therefore
   achieve long-term navigation. Several simulations and real experiments
   in various places show that the proposed active SLAM framework could
   build a topologically consistent map, and demonstrated that it can be
   applied well to real environments such as wide-open space in a city hall
   and railway station.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {An, SY (Corresponding Author), Elect \& Telecommun Res Inst ETRI, Daegu 711883, South Korea.
   An, Su-Yong, Elect \& Telecommun Res Inst ETRI, Daegu 711883, South Korea.
   Lee, Lae-Kyoung; Oh, Se-Young, Pohang Univ Sci \& Technol POSTECH, Dept Elect Engn, Pohang 790784, Gyungbuk, South Korea.},
DOI = {10.1007/s10514-015-9453-0},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Ceiling vision; Mobile robot; SLAM; Dynamic environment; Wide-open area},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; ALGORITHM},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {syong.an@etri.re.kr},
Affiliations = {Electronics \& Telecommunications Research Institute - Korea (ETRI);
   Pohang University of Science \& Technology (POSTECH)},
Cited-References = {Albrecht S, 2009, THESIS.
   An SY, 2012, ADV ROBOTICS, V26, P437, DOI 10.1163/156855311X617452.
   Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389.
   Burgard W, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2089, DOI 10.1109/IROS.2009.5354691.
   Callmer J, 2008, P 2008 AUSTR C ROB A, P8.
   Choi J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4048, DOI 10.1109/IROS.2006.281866.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Delaunay Boris, 1934, B LACADEMIE SCI LURS, V6, P793.
   Dijkstra, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390.
   Diosi A., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3317.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Gaspar J, 2000, IEEE T ROBOTIC AUTOM, V16, P890, DOI 10.1109/70.897802.
   Grisetti G, 2005, IEEE INT CONF ROBOT, P2432.
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Holz D., 2010, ISR 2010 41 INT S RO, P1.
   Hwang SY, 2011, IEEE T IND ELECTRON, V58, P4804, DOI 10.1109/TIE.2011.2109333.
   Jeong WY, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2570, DOI 10.1109/IROS.2006.281708.
   Jeong-Gwan Kang, 2007, 2007 International Conference on Control, Automation and Systems - ICCAS `07, P1092, DOI 10.1109/ICCAS.2007.4407062.
   Julier SJ, 2007, ROBOT AUTON SYST, V55, P3, DOI 10.1016/j.robot.2006.06.011.
   Karlsson N, 2005, IEEE INT CONF ROBOT, P24.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kim J, 2007, ROBOT AUTON SYST, V55, P62, DOI 10.1016/j.robot.2006.06.006.
   Krose BJA, 2001, IMAGE VISION COMPUT, V19, P381, DOI 10.1016/S0262-8856(00)00086-X.
   Kundu A, 2011, IEEE I CONF COMP VIS, P2080, DOI 10.1109/ICCV.2011.6126482.
   Launay F, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P3918, DOI 10.1109/ROBOT.2002.1014338.
   Lee JS, 2010, AUTON ROBOT, V29, P1, DOI 10.1007/s10514-010-9184-1.
   Leung C, 2008, IEEE INT CONF ROBOT, P1898, DOI 10.1109/ROBOT.2008.4543484.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Martinez-Cantin R, 2009, AUTON ROBOT, V27, P93, DOI 10.1007/s10514-009-9130-2.
   Montemerlo M., 2002, AAAI IAAI, DOI DOI 10.1007/S00244-005-7058-X.
   Nieto J, 2007, ROBOT AUTON SYST, V55, P39, DOI 10.1016/j.robot.2006.06.008.
   Nieto J, 2006, SPRINGER TRAC ADV RO, V25, P167.
   Paz LM, 2008, IEEE T ROBOT, V24, P1107, DOI 10.1109/TRO.2008.2004639.
   Roda Jose Pascual, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3898, DOI 10.1109/IROS.2007.4399134.
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Seo-Yeon Hwang, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P704, DOI 10.1109/ICCAS.2008.4694592.
   Shafait F, 2008, PROC SPIE, V6815, DOI 10.1117/12.767755.
   Sim R, 2005, IEEE INT CONF ROBOT, P661.
   Su-Yong An, 2013, 2013 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), P1, DOI 10.1109/ROMAN.2013.6628522.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Tardos JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340.
   Thrun S, 2000, INT J ROBOT RES, V19, P972, DOI 10.1177/02783640022067922.
   Thrun S, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1999, DOI 10.1109/ROBOT.1999.770401.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wilson S. W., 1996, From Animals to Animats 4. Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior, P325.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   WooYeon Jeong, 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3195.
   Xu D, 2009, IEEE T IND ELECTRON, V56, P1617, DOI 10.1109/TIE.2009.2012457.},
Number-of-Cited-References = {58},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {31},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {DB8XZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000368801800006},
DA = {2022-05-17},
}

@inproceedings{ WOS:000287672000086,
Author = {Hochdorfer, Siegfried and Schlegel, Christian},
Book-Group-Author = {IEEE},
Title = {6 DoF SLAM using a ToF Camera: The challenge of a continuously growing
   number of landmarks},
Booktitle = {IEEE/RSJ 2010 INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2010)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2010},
Pages = {3981-3986},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems,
   Taipei, TAIWAN, OCT 18-22, 2010},
Abstract = {Localization and mapping are fundamental problems in service robotics
   since representations of the environment and knowledge about the own
   pose significantly simplify the implementation of a series of high-level
   applications.
   ToF (time-of-flight) cameras are a relatively new kind of sensors in
   robotics. They enable the real-time capture of the distance and the
   grayscale information of a scene. Due to the increase of the image
   resolution of ToF cameras, now high-level computer vision algorithms for
   visual feature extraction (e. g. SIFT {[}1] or SURF {[}2]) can be
   applied to the captured images. These visual features combined with the
   corresponding distance information give a full measurement of 3D
   landmarks.
   An obvious problem to be solved is the continuously growing number of
   landmarks. So far, all ever seen landmarks are just accumulated
   irrespective of their utility and the then required resources. Rather,
   one should keep only really useful landmarks, e. g. such that
   localization quality in the whole operational area is kept above a given
   threshold. In fact a lifelong running SLAM approach is dependent on
   means to select and discard landmarks. That is even more acute in case
   of feature-rich sensor data as provided with high update rates by
   sensors like a ToF camera.
   We run our SLAM approach in a real-world experiment within an indoor
   environment. The experiment was performed on a P3DX-platform equipped
   with a PMD CamCube 2.0 and a Xsens IMU.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Hochdorfer, S (Corresponding Author), Univ Appl Sci Ulm, Dept Comp Sci, Prittwitzstr 10, D-89075 Ulm, Germany.
   Hochdorfer, Siegfried; Schlegel, Christian, Univ Appl Sci Ulm, Dept Comp Sci, D-89075 Ulm, Germany.},
DOI = {10.1109/IROS.2010.5651229},
ISSN = {2153-0858},
ISBN = {978-1-4244-6675-7},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {hochdorfer@hs-ulm.de
   schlegel@hs-ulm.de},
Affiliations = {Ulm University},
Cited-References = {Bay H, 2006, 9 EUR C COMP VIS GRA.
   BEDER C, 2007, IEEE ISPRS BENCOS WO.
   BLANCO JL, 2008, DERIVATION IMPLEMENT.
   BLANCO JL, 2009, MRPT MOBILE ROBOT PR.
   Costa A, 2004, IEEE INT CONF ROBOT, P1764, DOI 10.1109/ROBOT.2004.1308079.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   Ester M., 1996, KDD, V96, P226, DOI DOI 10.5555/3001460.3001507.
   Gadeyne K., 2001, BFL BAYESIAN FILTERI.
   Hochdorfer S, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR PRACTICAL ROBOT APPLICATIONS (TEPRA 2009), P161, DOI 10.1109/TEPRA.2009.5339626.
   Lacroix S., 2002, INT J ROBOT RES, V21, P2002.
   LAMON P, 2005, THESIS ECOLE POLYTEC.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Mahalanobis P.C., 1936, P NATL I SCI INDIA, P49, DOI DOI 10.1145/1390156.1390302.
   MAY S, 2009, J FIELD ROBOTICS JFR, V26.
   May S., 2006, IEEE RSJ INT C INT R.
   Prusak A, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P355, DOI 10.1504/IJISTA.2008.021298.
   Sabeti L., 2008, J MULTIMEDIA, V3.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   SEITZ P, 2004, OPTISCHE 3D HALBLEIT.
   Smith Randall, 1988, P 4 INT S ROB RES, P467.
   STRASDAT H, 2009, IEEE INT C IN PRESS.
   Tran TN, 2005, CHEMOMETR INTELL LAB, V77, P3, DOI 10.1016/j.chemolab.2004.07.011.},
Number-of-Cited-References = {22},
Times-Cited = {16},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BTO97},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000287672000086},
DA = {2022-05-17},
}

@inproceedings{ WOS:000426978202017,
Author = {Qiu, Kejie and Shen, Shaojie},
Editor = {Bicchi, A and Okamura, A},
Title = {Model-Aided Monocular Visual-Inertial State Estimation and Dense Mapping},
DOI = {10.1109/IROS.2017.8205992},
Booktitle = {2017 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2017},
Pages = {1783-1789},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Vancouver, CANADA, SEP 24-28, 2017},
Abstract = {Robust state estimation and real-time dense mapping are two core
   capabilities for autonomous navigation of mobile robots. Global
   Navigation Satellite System (GNSS) and visual odometry/SLAM are popular
   methods for state estimation. However, when working between tall
   buildings or in indoor environments, GNSS fails due to limited sky view
   or obstruction from buildings. Visual odometry/SLAM are prone to
   long-term drifting in the absence of reliable loop closure detection. A
   state estimation method with global-consistent guarantee is desirable
   for navigation applications. As for realtime mapping, SLAM methods
   usually get a sparse map that is not good enough for obstacle avoidance
   and path-planning, and high-quality dense mapping is often
   computationally too demanding for mobile devices. Realizing the
   availability of city-scale 3D models, in this work, we improve our
   previous work on model-based global localization, and propose a
   modelaided monocular visual-inertial state estimation and dense mapping
   solution. We first develop a global-consistent state estimator by fusing
   visual-inertial odometry with the modelbased localization results.
   Utilizing depth prior from the model, we perform motion stereo with
   semi-global disparity smoothing. Our dense mapping pipeline is capable
   of online detection of obstacles that are originally not included in the
   offline 3D model. Our method runs onboard an embedded computer in
   real-time. We validate both the state estimation and mapping accuracy in
   real-world experiments.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Qiu, KJ (Corresponding Author), Hong Kong Univ Sci \& Technol, Dept Elect \& Comp Engn, Hong Kong, Hong Kong, Peoples R China.
   Qiu, Kejie; Shen, Shaojie, Hong Kong Univ Sci \& Technol, Dept Elect \& Comp Engn, Hong Kong, Hong Kong, Peoples R China.},
ISSN = {2153-0858},
ISBN = {978-1-5386-2682-5},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {kqiuaa@connect.ust.hk
   eeshaojie@ust.hk},
Affiliations = {Hong Kong University of Science \& Technology},
Funding-Acknowledgement = {WeChat-HKUST Joint Laboratory on Artificial Intelligence Technology
   (WHAT LAB)},
Funding-Text = {This work was supported by the WeChat-HKUST Joint Laboratory on
   Artificial Intelligence Technology (WHAT LAB).},
Cited-References = {Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Klein G, 2006, P BRIT MACH VIS C BM, P1119, DOI DOI 10.5244/C.20.114.
   Klingensmith M., 2015, ROBOTICS SCI SYSTEMS.
   Kuse MP, 2016, IEEE INT C ROB AUT I.
   Mok B, 2017, IEEE INT C INTELL TR.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   NEWCOMBE RA, 2011, MIX AUGM REAL ISM, DOI DOI 10.1109/ISMAR.2011.6092378.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Ok K, 2016, IEEE INT CONF ROBOT, P4522, DOI 10.1109/ICRA.2016.7487651.
   Pizzoli M, 2014, IEEE INT CONF ROBOT, P2609, DOI 10.1109/ICRA.2014.6907233.
   Qiu K., 2017, IEEE ROBOTICS AUTOMA.
   Schindler G., 2007, IEEE C COMP VIS PATT, V2007, P1.
   Shen, 2016, IEEE T AUTOM SCI ENG, V14, P1, DOI DOI 10.1109/TASE.2016.2550621.
   Teuliere C, 2015, IEEE T CYBERNETICS, V45, P869, DOI 10.1109/TCYB.2014.2337652.},
Number-of-Cited-References = {18},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BJ6YC},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000426978202017},
DA = {2022-05-17},
}

@article{ WOS:000533346400274,
Author = {Yang, Shiqiang and Fan, Guohao and Bai, Lele and Zhao, Cheng and Li,
   Dexin},
Title = {SGC-VSLAM: A Semantic and Geometric Constraints VSLAM for Dynamic Indoor
   Environments},
Journal = {SENSORS},
Year = {2020},
Volume = {20},
Number = {8},
Pages = {2432},
Month = {APR},
Abstract = {As one of the core technologies for autonomous mobile robots, Visual
   Simultaneous Localization and Mapping (VSLAM) has been widely researched
   in recent years. However, most state-of-the-art VSLAM adopts a strong
   scene rigidity assumption for analytical convenience, which limits the
   utility of these algorithms for real-world environments with independent
   dynamic objects. Hence, this paper presents a semantic and geometric
   constraints VSLAM (SGC-VSLAM), which is built on the RGB-D mode of
   ORB-SLAM2 with the addition of dynamic detection and static point cloud
   map construction modules. In detail, a novel improved quadtree-based
   method was adopted for SGC-VSLAM to enhance the performance of the
   feature extractor in ORB-SLAM (Oriented FAST and Rotated BRIEF-SLAM).
   Moreover, a new dynamic feature detection method called semantic and
   geometric constraints was proposed, which provided a robust and fast way
   to filter dynamic features. The semantic bounding box generated by YOLO
   v3 (You Only Look Once, v3) was used to calculate a more accurate
   fundamental matrix between adjacent frames, which was then used to
   filter all of the truly dynamic features. Finally, a static point cloud
   was estimated by using a new drawing key frame selection strategy.
   Experiments on the public TUM RGB-D (Red-Green-Blue Depth) dataset were
   conducted to evaluate the proposed approach. This evaluation revealed
   that the proposed SGC-VSLAM can effectively improve the positioning
   accuracy of the ORB-SLAM2 system in high-dynamic scenarios and was also
   able to build a map with the static parts of the real environment, which
   has long-term application value for autonomous mobile robots.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Yang, SQ (Corresponding Author), Xian Univ Technol, Sch Mech \& Precis Instrument Engn, Xian 710048, Shaanxi, Peoples R China.
   Yang, Shiqiang; Fan, Guohao; Bai, Lele; Zhao, Cheng; Li, Dexin, Xian Univ Technol, Sch Mech \& Precis Instrument Engn, Xian 710048, Shaanxi, Peoples R China.},
DOI = {10.3390/s20082432},
Article-Number = {2432},
EISSN = {1424-8220},
Keywords = {Visual SLAM; ORB-SLAM2; dynamic indoor environment; dynamic feature
   filtering; point cloud map},
Keywords-Plus = {RGB-D SLAM; MOTION REMOVAL; IMAGES},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {yangsq@xaut.edu.cn
   2170220051@stu.xaut.edu.cn
   2180220045@stu.xaut.edu.cn
   2190221126@stu.xaut.edu.cn
   lidexin@xaut.edu.cn},
Affiliations = {Xi'an University of Technology},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}51475365]},
Funding-Text = {This research was supported by the National Natural Science Foundation
   of China under Grant No. 51475365.},
Cited-References = {Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4.
   Fan YC, 2019, PATTERN RECOGN LETT, V127, P191, DOI 10.1016/j.patrec.2018.10.024.
   Han SQ, 2020, IEEE ACCESS, V8, P43563, DOI 10.1109/ACCESS.2020.2977684.
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322.
   Kerl C., 2013, P 2013 IEEE INT C RO.
   Kim DH, 2016, IEEE T ROBOT, V32, P1565, DOI 10.1109/TRO.2016.2609395.
   Klein George, 2007, P1.
   Kovacs A, 2013, IEEE GEOSCI REMOTE S, V10, P796, DOI 10.1109/LGRS.2012.2224315.
   Li P., 2019, P 2019 INT C ADV MEC.
   Li RH, 2018, COGN COMPUT, V10, P875, DOI 10.1007/s12559-018-9591-8.
   Li SL, 2017, IEEE ROBOT AUTOM LET, V2, P2263, DOI 10.1109/LRA.2017.2724759.
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0\_2.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Paul S, 2016, IEEE GEOSCI REMOTE S, V13, P1300, DOI 10.1109/LGRS.2016.2582528.
   Pritts J, 2013, INT CONF IMAG VIS, P106, DOI 10.1109/IVCNZ.2013.6727000.
   Redmon J., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.91.
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sedaghat A, 2011, IEEE T GEOSCI REMOTE, V49, P4516, DOI 10.1109/TGRS.2011.2144607.
   Stuhmer J, 2010, LECT NOTES COMPUT SC, V6376, P11.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Sun YX, 2018, ROBOT AUTON SYST, V108, P115, DOI 10.1016/j.robot.2018.07.002.
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Vidal AR, 2018, IEEE ROBOT AUTOM LET, V3, P994, DOI 10.1109/LRA.2018.2793357.
   Wangsiripitak Somkiat, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P375, DOI 10.1109/ROBOT.2009.5152290.
   Xie H., 2016, APPL SCI TECHNOL, V3, P23.
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001.
   Yi KM, 2013, IEEE COMPUT SOC CONF, P27, DOI 10.1109/CVPRW.2013.9.
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691.
   Zhang L, 2018, IEEE ACCESS, V6, P75545, DOI {[}10.1109/ACCESS.2018.2873617, 10.1109/TCBB.2018.2848633].
   Zhao LL, 2019, IEEE ACCESS, V7, P75604, DOI 10.1109/ACCESS.2019.2922733.
   Zhong FW, 2018, IEEE WINT CONF APPL, P1001, DOI 10.1109/WACV.2018.00115.},
Number-of-Cited-References = {38},
Times-Cited = {1},
Usage-Count-Last-180-days = {14},
Usage-Count-Since-2013 = {36},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {LO0VA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000533346400274},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@article{ WOS:000262266000007,
Author = {Blanco, J. L. and Gonzalez, J. and Fernandez-Madrigal, J. -A.},
Title = {Subjective local maps for hybrid metric-topological SLAM},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2009},
Volume = {57},
Number = {1},
Pages = {64-74},
Month = {JAN 31},
Abstract = {Hybrid maps where local metric submaps are kept in the nodes of a
   graph-based topological structure are gaining relevance as the focus of
   robot Simultaneous Localization and Mapping (SLAM) shifts towards
   spatial scalability and long-term operation. In this paper we examine
   the applicability of spectral graph partitioning techniques to the
   automatic generation of metric submaps by establishing groups in the
   sequence of observations gathered by the robot. One of the main aims of
   this work is to provide a probabilistically grounded interpretation of
   such a partitioning technique in the context of generating local maps.
   We also discuss how to apply it to different kinds of sensory data
   (landmarks extracted from stereo images and laser range scans) and how
   to consider them simultaneously. An important feature of our approach is
   that the partitioning takes into account the intrinsic characteristics
   of the sensors, such as the sensor field of view, instead of applying
   heuristics supplied by a human as in other works. Thus the robot builds
   ``subjective{''} local maps whose size will be determined by the nature
   of the sensors. The ideas presented here are supported by experimental
   results from a real mobile robot as well as simulations for statistical
   analysis. We discuss the effects of considering different combinations
   of sensors in the resulting clustering of the environment. (c) 2008
   Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Blanco, JL (Corresponding Author), Univ Malaga, Dept Syst Engn \& Automat, ETSII Campus Teatinos, E-29071 Malaga, Spain.
   Blanco, J. L.; Gonzalez, J.; Fernandez-Madrigal, J. -A., Univ Malaga, Dept Syst Engn \& Automat, E-29071 Malaga, Spain.},
DOI = {10.1016/j.robot.2008.02.002},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Graph partitioning; Hybrid maps; Map building; Simultaneous Localization
   and Mapping (SLAM)},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {jlblanco@ctima.uma.es
   jgonzalez@ctima.uma.es
   jafma@ctima.uma.es},
Affiliations = {Universidad de Malaga},
ResearcherID-Numbers = {Fernández-Madrigal, Juan-Antonio/D-5871-2011
   Gonzalez-Jimenez, Javier/D-5774-2011
   Blanco Claraco, Jose Luis/H-2388-2013},
ORCID-Numbers = {Fernández-Madrigal, Juan-Antonio/0000-0003-1376-7967
   Gonzalez-Jimenez, Javier/0000-0003-3845-3497
   Blanco Claraco, Jose Luis/0000-0002-9745-285X},
Cited-References = {Beeson P, 2005, IEEE INT CONF ROBOT, P4373.
   BLANCO JL, 2008, DERIVATION IMPLEMENT.
   BLANCO JL, 2008, IEEE T ROBO IN PRESS, V24.
   Blanco JL, 2006, IEEE INT CONF ROBOT, P818, DOI 10.1109/ROBOT.2006.1641810.
   Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Golub G. H., 1996, MATRIX COMPUTATIONS.
   Gutmann J.-S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P318, DOI 10.1109/CIRA.1999.810068.
   Lowe D. G, 1999, P 7 IEEE INT C COMP, P2.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Mohar B., 1991, GRAPH THEORY COMBINA, P871.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Moreno FA, 2007, LECT NOTES COMPUT SC, V4477, P346.
   PASKIN MA, 2002, THIN JUNCTION TREE F.
   Porta JM, 2006, ROBOT AUTON SYST, V54, P159, DOI 10.1016/j.robot.2005.09.025.
   RYBSKI PE, 2003, P IEEE RSJ INT C INT, V1, P194.
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688.
   Smith Randall, 1988, P 4 INT S ROB RES, P467.
   Sogo T, 2001, IEEE T PATTERN ANAL, V23, P268, DOI 10.1109/34.910879.
   Tardos JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340.
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479.
   Thrun S, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P944.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Veksler O, 2000, PROC CVPR IEEE, P339, DOI 10.1109/CVPR.2000.855838.
   Walter MR, 2007, INT J ROBOT RES, V26, P335, DOI 10.1177/0278364906075026.
   ZIVKOVIC Z, 2005, P IEEE RSJ INT C INT, P2480.
   Zivkovic Z, 2006, IEEE INT CONF ROBOT, P803.},
Number-of-Cited-References = {28},
Times-Cited = {38},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {10},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {391WX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000262266000007},
DA = {2022-05-17},
}

@article{ WOS:000394774300001,
Author = {Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
Title = {1 year, 1000 km: The Oxford RobotCar dataset},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2017},
Volume = {36},
Number = {1},
Pages = {3-15},
Month = {JAN},
Abstract = {We present a challenging new dataset for autonomous driving: the Oxford
   RobotCar Dataset. Over the period of May 2014 to December 2015 we
   traversed a route through central Oxford twice a week on average using
   the Oxford RobotCar platform, an autonomous Nissan LEAF. This resulted
   in over 1000 km of recorded driving with almost 20 million images
   collected from 6 cameras mounted to the vehicle, along with LIDAR, GPS
   and INS ground truth. Data was collected in all weather conditions,
   including heavy rain, night, direct sunlight and snow. Road and building
   works over the period of a year significantly changed sections of the
   route from the beginning to the end of data collection. By frequently
   traversing the same route over the period of a year we enable research
   investigating long-term localization and mapping for autonomous vehicles
   in real-world, dynamic urban environments. The full dataset is available
   for download at: http://robotcar-dataset.robots.ox.ac.uk},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article; Data Paper},
Language = {English},
Affiliation = {Maddern, W (Corresponding Author), Univ Oxford, Oxford Robot Inst, Parks Rd, Oxford OX1 3PJ, England.
   Maddern, Will; Pascoe, Geoffrey; Linegar, Chris; Newman, Paul, Univ Oxford, Oxford Robot Inst, Parks Rd, Oxford OX1 3PJ, England.},
DOI = {10.1177/0278364916679498},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Dataset; autonomous vehicles; long-term autonomy; mobile robotics;
   computer vision; cameras; LIDAR; GPS; stereo; localization; mapping;
   SLAM; RobotCar},
Keywords-Plus = {VISION; STEREO; LIDAR},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {wm@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
Funding-Acknowledgement = {EPSRC {[}EP/M019918/1]; EPSRC Leadership Fellowship {[}EP/I005021/1];
   Rhodes Scholarships; EPSRC {[}EP/I005021/1, EP/J012017/1, EP/K034472/1]
   Funding Source: UKRI; Engineering and Physical Sciences Research Council
   {[}EP/M019918/1, GR/S62215/01, EP/K034472/1, EP/J012017/1, EP/I005021/1]
   Funding Source: researchfish},
Funding-Text = {The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: Will
   Maddern is supported by EPSRC Programme Grant EP/M019918/1.; Paul Newman
   is supported by EPSRC Leadership Fellowship EP/I005021/1.; Geoffrey
   Pascoe and Chris Linegar are supported by Rhodes Scholarships.},
Cited-References = {Agarwal S., 2012, CERES SOLVER.
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5\_47.
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326.
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005.
   Churchill W., 2012, THESIS.
   Cordts M., 2016, P IEEE C COMP VIS PA.
   Dollar P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6\_3.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Harrison A., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P356, DOI 10.1109/ICRA.2011.5980112.
   Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56.
   Kassir A, 2010, P 2010 AUSTR C ROB A.
   Linegar C., 2016, P IEEE INT C ROB AUT.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Maddern W, 2014, P IEEE C ROB AUT ICR, V2, P3.
   Maddern W, 2012, P IEEE C ROB AUT ICR.
   Maddern W, 2015, P IEEE INT C ROB AUT.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103.
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640.
   Pascoe G, 2015, P IEEE INT C COMP VI.
   Pfeiffer D, 2013, PROC CVPR IEEE, P297, DOI 10.1109/CVPR.2013.45.
   Posner I, 2008, P ROB SCI SYST 4 ZUR.
   Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372.
   Schonberger J. L., 2016, P IEEE C COMP VIS PA.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8.},
Number-of-Cited-References = {29},
Times-Cited = {428},
Usage-Count-Last-180-days = {18},
Usage-Count-Since-2013 = {87},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {EL7AU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000394774300001},
OA = {Green Submitted},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000405724600096,
Author = {Taisho, Tsukamoto and Kanji, Tanaka},
Book-Group-Author = {IEEE},
Title = {Mining DCNN Landmarks for Long-term Visual SLAM},
DOI = {10.1109/ROBIO.2016.7866383},
Booktitle = {2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO)},
Year = {2016},
Pages = {570-576},
Note = {IEEE International Conference on Robotics and Biomimetics (IEEE ROBIO),
   Qingdao, PEOPLES R CHINA, DEC 03-07, 2016},
Abstract = {Long-term visual SLAM, in familiar, semidynamic, and partially changing
   environments is an important area of research in robotics. The main
   problem we faced is the question of how to describe a scene
   discriminatively and compactly-both of which are necessary in order to
   cope with changes in appearance and a large amount of visual
   information. In this study, we address the above issues by mining visual
   experience. Our strategy is to mine a library of raw visual images,
   termed visual experience, to find the relevant visual patterns to
   effectively explain the input scene. From a practical point of view, our
   work offers three main contributions over the previous work. First, it
   is the first application of discriminative visual features from deep
   convolutional neural networks (DCNN) to the task of visual landmark
   mining. Second, we show how to interpret a high-dimensional DCNN feature
   to a compact semantic representation of visual word. Third, we show that
   our approach can turn the scene description task with any feature
   (including the DCNN feature) into the task of mining visual experience.
   Experiments on a challenging cross-domain visual place recognition
   validate efficacy of the proposed approach.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kanji, T (Corresponding Author), Univ Fukui, Grad Sch Engn, Fukui, Japan.
   Taisho, Tsukamoto; Kanji, Tanaka, Univ Fukui, Grad Sch Engn, Fukui, Japan.},
ISBN = {978-1-5090-4364-4},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Funding-Acknowledgement = {JSPS KAKENHI {[}23700229, 26330297]},
Funding-Text = {Our work has been supported in part by JSPS KAKENHI Grant-in-Aid for
   Young Scientists (B) 23700229, and for Scientific Research (C) 26330297
   ({''}The realization of next-generation, discriminative and succinct
   SLAM technique: PartSLAM{''}).},
Cited-References = {Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28.
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018.
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1\_38.
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598.
   Bruce J., 2015, ICRA15 WS VPRICE.
   Carlevaris-Bianco N., 2015, I J ROBOTICS RES.
   Carrillo H, 2014, IEEE INT C INT ROBOT, P4950, DOI 10.1109/IROS.2014.6943266.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Isola P, 2013, IEEE I CONF COMP VIS, P3048, DOI 10.1109/ICCV.2013.457.
   Jegou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235.
   Kanji T, 2015, IEEE INT C INT ROBOT, P729, DOI 10.1109/IROS.2015.7353453.
   Kanji T, 2015, IEEE INT CONF ROBOT, P6359, DOI 10.1109/ICRA.2015.7140092.
   Kanji T, 2014, IEEE INT C INT ROBOT, P136, DOI 10.1109/IROS.2014.6942552.
   Kentaro Y., 2015, ICRA15 WS VPRICE.
   Krajnik T., 2015, ICRA15 WS VPRICE.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowry S., 2015, ICRA15 WS VPRICE.
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478.
   Masatoshi A., 2015, ICRA.
   Morita H., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2965.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Rematas K, 2013, ACCV, P176.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N., 2015, ICRA 2015 WORKSH VIS.
   Tanaka K., 2016, IEEE RSJ INT C IROS.
   Tommasi T, 2013, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2013.116.
   Tuytelaars T, 2011, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2011.6126449.
   Vysotska O., 2015, ICRA15 WS VPRICE.},
Number-of-Cited-References = {30},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BI1FW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000405724600096},
DA = {2022-05-17},
}

@inproceedings{ WOS:000250915304126,
Author = {Sola, Joan and Monin, Andre and Devy, Michel},
Book-Group-Author = {IEEE},
Title = {BiCamSLAM: Two times mono is more than stereo},
Booktitle = {PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND
   AUTOMATION, VOLS 1-10},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2007},
Pages = {4795+},
Note = {IEEE International Conference on Robotics and Automation, Rome, ITALY,
   APR 10-14, 2007},
Abstract = {This paper is an invitation to use mono-vision techniques on
   stereo-vision equipped robots. By using monocular algorithms on both
   cameras, the advantages of mono-vision (bearing-only, with infinity
   range but no 3D instant information) and stereo-vision (3D information
   only up to a limited range) naturally add up to provide interesting
   possibilities, that are here developed and demonstrated using an
   EKF-based monocular SLAM algorithm. Mainly we obtain: a) fast 3D mapping
   with long term, absolute angular references; b) great landmark updating
   flexibility; and c) the possibility of stereo rig extrinsic
   self-calibration, providing a much more robust and accurate sensor.
   Experimental results show the pertinence of the proposed ideas, which
   should be easily exportable (and we encourage to do so) to other, more
   performing, vision-based SLAM algorithms.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Sola, J (Corresponding Author), CNRS, LAAS, F-31077 Toulouse, France.
   Sola, Joan; Monin, Andre; Devy, Michel, CNRS, LAAS, F-31077 Toulouse, France.},
DOI = {10.1109/ROBOT.2007.364218},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4244-0601-2},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {jsola@laas.fr
   monin@laas.fr
   michel@laas.fr},
Affiliations = {Centre National de la Recherche Scientifique (CNRS)},
ResearcherID-Numbers = {Solà, Joan/AAA-4133-2020
   Solà, Joan/N-5977-2015},
ORCID-Numbers = {Solà, Joan/0000-0002-2933-3381
   Solà, Joan/0000-0002-2933-3381},
Cited-References = {BARFOOT TD, 2005, IEEE INT C INT ROB S.
   Castellanos J., 2004, 5 IFAC S INT AUT VEH.
   DAVISON A, 2003, P INT C COMP VIS NIC.
   Eade E., 2006, P 16 C UNC ART INT S, V1, P469, DOI DOI 10.1109/CVPR.2006.263.
   HARRIS C, 1988, 4 ALV VIS C MANC.
   LeCadre JP, 1997, IEEE T AERO ELEC SYS, V33, P178, DOI 10.1109/7.570737.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Montemerlo M., 2003, FASTSLAM 2 0 IMPROVE.
   Montiel J. M. M., 2006, P ROB SCI SYST.
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794.
   SOLA J, 2005, IEEE INT C INT ROB S.
   TUPYSEV VA, 1998, AIAA GUID NAV CONTR.
   WANG CC, 2004, THESIS CARNEGIE MELL.},
Number-of-Cited-References = {13},
Times-Cited = {12},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BGW23},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000250915304126},
DA = {2022-05-17},
}

@article{ WOS:000176446100001,
Author = {Davison, AJ and Murray, DW},
Title = {Simultaneous localization and map-building using active vision},
Journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE},
Year = {2002},
Volume = {24},
Number = {7},
Pages = {865-880},
Month = {JUL},
Abstract = {An active approach to sensing can provide the focused measurement
   capability over a wide field of view which allows correctly formulated
   Simultaneous Localization and Map-Building (SLAM) to be implemented with
   vision, permitting repeatable long-term localization using only
   naturally occurring, automatically-detected features. In this paper, we
   present the first example of a general system for autonomous
   localization using active vision, enabled here by a high-performance
   stereo head, addressing such issues as uncertainty-based measurement
   selection, automatic map-maintenance, and goal-directed steering. We
   present varied real-time experiments in a complex environment.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
Type = {Article},
Language = {English},
Affiliation = {Davison, AJ (Corresponding Author), Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England.
   Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England.},
DOI = {10.1109/TPAMI.2002.1017615},
ISSN = {0162-8828},
EISSN = {1939-3539},
Keywords = {active vision; simultaneous localization and map-building; mobile robots},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic},
Author-Email = {ajd@robots.ox.ac.uk
   dwm@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
Cited-References = {Ayache N., 1991, ARTIFICIAL VISION MO.
   BEARDSLEY PA, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P58, DOI 10.1109/ICCV.1995.466806.
   BOUGT JY, 1995, ICCV5, P645.
   CASTELLANOS JA, 1998, THESIS U ZARAGOZA SP.
   CHIUSO A, 2000, P 6 EUR C COMP VIS.
   Chong KS, 1999, INT J ROBOT RES, V18, P3.
   Davison AJ, 2001, ROBOT AUTON SYST, V36, P171, DOI 10.1016/S0921-8890(01)00141-5.
   DAVISON AJ, 1998, P 5 EUR C COMP VIS F, P809.
   DAVISON AJ, 2000, P IEEE RSJ C INT ROB.
   DAVISON AJ, 1998, THESIS U OXFORD.
   DURRANTWHYTE H, 1994, IND ROBOT, V21, P11, DOI 10.1108/EUM0000000004145.
   DURRANTWHYTE HF, 1999, P 9 INT S ROB RES SN, P121.
   Grossman CRS, 1999, BEHAV SOC SCI LIBR, V17, P11, DOI 10.1300/J103v17n02\_02.
   Harris C., 1992, ACTIVE VISION.
   Harris C. G., 1988, ALVEY VISION C, P1, DOI DOI 10.5244/C.2.23.
   HARRIS CG, 1987, P 3 ALV VIS C, P233.
   KNIGHT JGH, 2001, P IEEE RSJ C INT ROB.
   LAND MF, 1994, NATURE, V369, P742, DOI 10.1038/369742a0.
   LEONARD JJ, 2000, ROBOTICS RES.
   MACCORMICK J, 2000, P 6 EUR C COMP VIS.
   Murray DW, 1997, PERCEPTION, V26, P1519, DOI 10.1068/p261519.
   NAYAR S, 1997, P IEEE C COMP VIS PA.
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705.
   SANDINI G, 1990, P IEEE INT WORKSH RO.
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794.
   SMITH R, 1987, P 4 INT S ROB RES.
   Thrun S., 2000, P IEEE INT C ROB AUT.
   Thrun S., 1998, MACHINE LEARNING, V31.
   TISTARELLI M, 1992, CVGIP-IMAG UNDERSTAN, V56, P108, DOI 10.1016/1049-9660(92)90089-L.
   Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762.
   Whaite P, 1997, IEEE T PATTERN ANAL, V19, P193, DOI 10.1109/34.584097.},
Number-of-Cited-References = {31},
Times-Cited = {298},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {71},
Journal-ISO = {IEEE Trans. Pattern Anal. Mach. Intell.},
Doc-Delivery-Number = {566UF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000176446100001},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000761735106082,
Author = {Biswas, Joydeep},
Editor = {Kraus, S},
Title = {The Quest For ``Always-On{''} Autonomous Mobile Robots},
DOI = {10.24963/ijcai.2019/893},
Booktitle = {PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON
   ARTIFICIAL INTELLIGENCE},
Year = {2019},
Pages = {6388-6392},
Note = {28th International Joint Conference on Artificial Intelligence, Macao,
   PEOPLES R CHINA, AUG 10-16, 2019},
Abstract = {Building ``always-on{''} robots to be deployed over extended periods of
   time in real human environments is challenging for several reasons. Some
   fundamental questions that arise in the process include: 1) How can the
   robot reconcile unexpected differences between its observations and its
   map of the world? 2) How can we scalably test robots for long-term
   autonomy? 3) Can a robot learn to predict its own failures, and their
   corresponding causes? 4) When the robot fails and is unable to recover
   autonomously, can it utilize partially specified human corrections to
   overcome its failures? This paper summarizes our research towards
   addressing all of these questions. We present 1) Episodic non-Markov
   Localization to maintain the belief of the robot's location while
   explicitly reasoning about unmapped observations; 2) a 1, 000km
   Challenge to test for long-term autonomy; 3) feature-based and
   learning-based approaches to predicting failures; and 4)
   human-in-the-loop SLAM to overcome robot mapping errors, and SMT-based
   robot transition repair to overcome state machine failures.},
Publisher = {IJCAI-INT JOINT CONF ARTIF INTELL},
Address = {ALBERT-LUDWIGS UNIV FREIBURG GEORGES-KOHLER-ALLEE, INST INFORMATIK, GEB
   052, FREIBURG, D-79110, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Biswas, J (Corresponding Author), Univ Massachusetts, CICS, Amherst, MA 01003 USA.
   Biswas, Joydeep, Univ Massachusetts, CICS, Amherst, MA 01003 USA.},
ISBN = {978-0-9992411-4-1},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory \& Methods},
Author-Email = {joydeepb@cs.umass.edu},
Affiliations = {University of Massachusetts System; University of Massachusetts Amherst},
ORCID-Numbers = {Biswas, Joydeep/0000-0002-1211-1731},
Funding-Acknowledgement = {AFRL {[}FA8750-16-2-0042]; DARPA {[}FA8750-16-2-0042]; NSF
   {[}IIS1724101]},
Funding-Text = {I would like to thank my collaborators and mentors, including Manuela
   Veloso, Reid Simmons, Arjun Guha, and Shlomo Zilberstein -and also my
   students Samer Nashed, Jarrett Holtz, Sadegh Rabiee, Kyle Vedder,
   Spencer Lane, Sourish Ghosh, David Balaban, Alyxander Burns, and Emily
   Pruc. This work was partially supported by AFRL and DARPA under
   agreement \#FA8750-16-2-0042, and by NSF award IIS1724101.},
Cited-References = {Biswas J, 2012, IEEE INT CONF ROBOT, P1697, DOI 10.1109/icra.2012.6224766.
   Biswas J, 2017, ROBOT AUTON SYST, V87, P162, DOI 10.1016/j.robot.2016.09.005.
   Biswas J, 2016, IEEE INTELL SYST, V31, P86, DOI 10.1109/MIS.2016.53.
   Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
   Biswas J, 2011, IEEE INT C INT ROBOT, P73, DOI 10.1109/IROS.2011.6048263.
   Biswas Joydeep, 2014, ROBOCUP S ROB WORLD, P525.
   Bjorner N., 2015, LNCS, V9035, P194, DOI {[}DOI 10.1007/978-3-662-46681-0, 10.1007/978- 3- 662-46681-0].
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6\_3.
   Ghosh S, 2017, IEEE INT C INT ROBOT, P1026, DOI 10.1109/IROS.2017.8202271.
   Holtz Jarrett, IJCAI 2018, P4905.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Meyer- Delius Daniel, 2012, IROS 2012, P5750.
   Nashed S, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4643, DOI 10.1109/IROS.2016.7759683.
   Nashed SB, 2018, THIRTY-SECOND AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTIETH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / EIGHTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P1503.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Stachniss, AAAI 2005, P1324.
   Veloso M, 2012, IEEE INT C INT ROBOT, P5446, DOI 10.1109/IROS.2012.6386300.},
Number-of-Cited-References = {18},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS7HT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000761735106082},
DA = {2022-05-17},
}

@inproceedings{ WOS:000632603501023,
Author = {Kassas, Zak M. and Khalife, Joe and Abdallah, Ali and Lee, Chiawei},
Book-Group-Author = {Inst Navigat},
Title = {I am Not Afraid of the Jammer: Navigating with Signals of Opportunity in
   GPS-Denied Environments},
Booktitle = {PROCEEDINGS OF THE 33RD INTERNATIONAL TECHNICAL MEETING OF THE SATELLITE
   DIVISION OF THE INSTITUTE OF NAVIGATION (ION GNSS+ 2020)},
Series = {Institute of Navigation Satellite Division Proceedings of the
   International Technical Meeting},
Year = {2020},
Pages = {1566-1585},
Note = {33rd International Technical Meeting of the
   Satellite-Division-of-The-Institute-of-Navigation (ION GNSS), ELECTR
   NETWORK, SEP 21-25, 2020},
Abstract = {I am not afraid of the GPS jammer, as long as there are ambient signals
   of opportunity (SOPs) to exploit in the environment. In environments
   where GPS signals are challenged (e.g., indoors and deep urban canyons)
   and denied (e.g., under jamming and spoofing attacks), SOPs could serve
   as an alternative navigation source to GPS, and more generally, to
   global navigation satellite systems (GNSS). This paper presents a radio
   simultaneous localization and mapping (radio SLAM) approach that enables
   the exploitation of SOPs for resilient and accurate navigation. Radio
   SLAM estimates the states of the navigator-mounted receiver
   simultaneously with the SOPs' states. Radio SLAM could produce an
   SOP-derived navigation solution in a standalone fashion or by fusing
   SOPs with sensors (e.g., inertial measurement unit (IMU), lidar, etc.),
   digital maps, and/or other signals (e.g., GNSS). The paper also
   overviews a core component of radio SLAM: a cognitive software-defined
   radio (SDR) called MATRIX: Multichannel Adaptive TRansceiver Information
   eXtractor, which produces navigation observables from terrestrial and
   space-based SOPs. Next, the paper showcases the most accurate navigation
   results to-date with terrestrial and space-based SOPs from low Earth
   orbit (LEO) satellites in different environments and on different
   platforms: indoor pedestrian, ground vehicles in urban and deep urban
   canyons, and aerial vehicles. Finally, the paper presents the first ever
   published experimental results for navigation with SOPs in a GPS-denied
   environment. These experiments took place at Edwards Air Force Base,
   California, USA, during which GPS was intentionally jammed with
   jamming-to-signal (J/S) ratio as high as 90 dB. The results showcase a
   ground vehicle traversing a trajectory of about 5 km in 180 seconds in
   the GPS-jammed environment, during which a GPS-IMU system drifted from
   the vehicle's ground truth trajectory, resulting in a position root
   mean-squared error (RMSE) of 238 m. In contrast, the radio SLAM approach
   with a single cellular long-term evolution (LTE) SOP whose position was
   poorly known (an initial uncertainty on the order of several kilometers)
   achieved a position RMSE of 32 m.},
Publisher = {INST NAVIGATION},
Address = {815 15TH ST NW, STE 832, WASHINGTON, DC 20005 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kassas, ZM (Corresponding Author), Univ Calif Irvine, Irvine, CA 92697 USA.
   Kassas, Zak M.; Khalife, Joe, Univ Calif Irvine, Irvine, CA 92697 USA.
   Abdallah, Ali, Univ Calif Irvine, Dept Elect Engn \& Comp Sci, Irvine, CA USA.
   Lee, Chiawei, US Air Force Test Pilot Sch, Edwards AFB, CA USA.},
DOI = {10.33012/2020.17737},
ISSN = {2331-5911},
EISSN = {2331-5954},
ISBN = {0-936406-26-7},
Keywords-Plus = {TERRESTRIAL SIGNALS; MIXED SIGNALS; RADIO; GNSS; LOCALIZATION; RECEIVER;
   OBSERVABILITY; TRACKING},
Research-Areas = {Remote Sensing; Telecommunications},
Web-of-Science-Categories  = {Remote Sensing; Telecommunications},
Affiliations = {University of California System; University of California Irvine;
   University of California System; University of California Irvine},
Funding-Acknowledgement = {Office of Naval Research (ONR) {[}N00014-19-1-2511, N00014-19-1-2613];
   National Science Foundation (NSF) {[}1929965]; U.S. Department of
   Transportation (USDOT) under University Transportation Center (UTC)
   Program {[}69A3552047138]},
Funding-Text = {The authors would like to thank Edwards AFB for inviting the ASPIN
   Laboratory to conduct experiments during DT NAVFEST. The authors would
   like to thank Joshua Morales, Kimia Shamaei, Mahdi Maaref, Kyle Semelka,
   MyLinh Nguyen, and Trier Mortlock for their help with data collection.
   This work was supported in part by the Office of Naval Research (ONR)
   under Grant N00014-19-1-2511 and Grant N00014-19-1-2613; in part by the
   National Science Foundation (NSF) under Grant 1929965; and in part by
   the U.S. Department of Transportation (USDOT) under University
   Transportation Center (UTC) Program Grant 69A3552047138. DISTRIBUTION
   STATEMENT A. Approved for public release; Distribution is unlimited
   412TW-PA-20399.},
Cited-References = {3GPP2, 2014, CS0010E 3GPP2 TS.
   Abdallah A., 2020, P ION GNSS C.
   Abdallah A., 2019, P IEEE 90 VEH TECHN, P1.
   Abdallah AA, 2019, I NAVIG SAT DIV INT, P2670, DOI 10.33012/2019.17030.
   Abdallah AA, 2018, I NAVIG SAT DIV INT, P3374, DOI 10.33012/2018.16073.
   {[}Anonymous], 2013, INSIDE GNSS NEWS APR.
   {[}Anonymous], 2015, SPUTNIK NEWS     MAY.
   {[}Anonymous], 2015, GPS WORLD.
   {[}Anonymous], 2014, GPS WORLD.
   {[}Anonymous], 2017, INSIDE GNSS NEWS JUL.
   {[}Anonymous], 2019, INSIDE GNSS.
   Ardito CT, 2019, P INT TECH M I NAVIG, P306, DOI 10.33012/2019.16743.
   Bhatti J, 2017, NAVIGATION-US, V64, P51, DOI 10.1002/navi.183.
   Borio D, 2016, P IEEE, V104, P1233, DOI 10.1109/JPROC.2016.2543266.
   Chen L, 2015, IEEE T BROADCAST, V61, P625, DOI 10.1109/TBC.2015.2465155.
   del Peral-Rosado JA, 2018, IEEE COMMUN SURV TUT, V20, P1124, DOI 10.1109/COMST.2017.2785181.
   Del Peral-Rosado JA, 2018, IEEE ACCESS, V6, P25185, DOI 10.1109/ACCESS.2018.2827921.
   Divis D., 2018, DOZENS DRONES CRASH.
   Driusso M, 2017, IEEE T VEH TECHNOL, V66, P3376, DOI 10.1109/TVT.2016.2589463.
   Faragher RM, 2015, NAVIGATION-US, V62, P55, DOI 10.1002/navi.76.
   Gentner C., 2018, THESIS.
   Gill LP, 2011, IET RADAR SONAR NAV, V5, P536, DOI 10.1049/iet-rsn.2010.0065.
   Graham M., 2012, GPS USE US CRITICAL.
   GSA, 2017, GNSS MARK REP.
   Kassas Z., 2017, GPS WORLD MAGAZINE, V28, p18?25.
   Kassas Z., 2019, P INSIDEGNSS, P56.
   Kassas Z., 2020, INSIDE UNMANNED SYST, P30.
   Kassas  Z., 2014, THESIS.
   Kassas ZM, 2015, IEEE T AERO ELEC SYS, V51, P866, DOI 10.1109/TAES.2014.140022.
   Kassas ZM, 2014, IEEE T INTELL TRANSP, V15, P260, DOI 10.1109/TITS.2013.2278293.
   Kassas ZM, 2013, IEEE AERO EL SYS MAG, V28, P38, DOI 10.1109/MAES.2013.6533743.
   Kassas ZM, 2020, IEEE INTEL TRANSP SY, V12, P36, DOI 10.1109/MITS.2020.2994110.
   Kassas ZM, 2017, IEEE SIGNAL PROC MAG, V34, P111, DOI 10.1109/MSP.2017.2715363.
   Khalife Joe, 2020, 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), P1393, DOI 10.1109/PLANS46316.2020.9110199.
   Khalife J, 2020, IEEE T AERO ELEC SYS, V56, P3285, DOI 10.1109/TAES.2019.2948452.
   Khalife J, 2019, I NAVIG SAT DIV INT, P4053, DOI 10.33012/2019.17031.
   Khalife J, 2018, IEEE POSITION LOCAT, P978, DOI 10.1109/PLANS.2018.8373476.
   Khalife J, 2018, IEEE T SIGNAL PROCES, V66, P2204, DOI 10.1109/TSP.2018.2799166.
   Khalife J, 2017, IEEE INT VEH SYM, P1722, DOI 10.1109/IVS.2017.7995956.
   Khalife JJ, 2018, I NAVIG SAT DIV INT, P2321, DOI 10.33012/2018.16105.
   Khalife JJ, 2017, I NAVIG SAT DIV INT, P2554.
   Khalifeh JJ, 2015, I NAVIG SAT DIV INT, P2291.
   Lawrence D, 2017, GPS WORLD MAG, V28, P42.
   Maaref M, 2019, I NAVIG SAT DIV INT, P3045, DOI 10.33012/2019.17009.
   Maaref M, 2020, INT CONF ACOUST SPEE, P9185, DOI 10.1109/ICASSP40776.2020.9053017.
   Maaref M, 2020, IEEE T INTELL TRANSP, V21, P2723, DOI 10.1109/TITS.2019.2907851.
   Maaref M, 2019, IEEE T INTELL VEHICL, V4, P73, DOI 10.1109/TIV.2018.2886688.
   Makki A, 2015, COMPUT NETW, V88, P218, DOI 10.1016/j.comnet.2015.06.015.
   McEllroy J, 2006, I NAVIG SAT DIV INT, P126.
   Merry L., 2010, P IFAC S INT AUT VEH, P109.
   Morales J., 2019, IEEE T AEROSPACE ELE.
   Morales JJ, 2019, IEEE T AERO ELEC SYS, V55, P1021, DOI 10.1109/TAES.2018.2856318.
   Morales JJ, 2018, IEEE T AERO ELEC SYS, V54, P992, DOI 10.1109/TAES.2017.2773238.
   Morales JJ, 2016, I NAVIG SAT DIV INT, P1492.
   Pawlyk O., 2018, GEN ELECT JAMMING GR.
   PETIT J, 2015, BLACK HAT EUROPE, V111, DOI DOI 10.1209/0295-5075/111/58002.
   Popleteev A., 2011, THESIS.
   Psiaki ML, 2019, I NAVIG SAT DIV INT, P2325, DOI 10.33012/2019.17120.
   Psiaki ML, 2016, P IEEE, V104, P1258, DOI 10.1109/JPROC.2016.2526658.
   Pullen S., 2012, INSIDE GNSS, V7, P34.
   Rabinowitz M, 2005, IEEE T BROADCAST, V51, P51, DOI 10.1109/TBC.2004.837876.
   Raquet J, 2008, INT CONF ACOUST SPEE, P5308, DOI 10.1109/ICASSP.2008.4518858.
   Rasaee H, 2019, INSIDE GNSS MAGA MAR, V14, P56.
   Reid TGR, 2018, NAVIGATION-US, V65, P205, DOI 10.1002/navi.234.
   RTI International, 2019, EC BEN GLOB POS SYST.
   Sebastian C., 2016, GETTING LOST NEAR KR.
   Shamaei K, 2019, I NAVIG SAT DIV INT, P2469, DOI 10.33012/2019.17051.
   Shamaei K, 2018, NAVIGATION-US, V65, P655, DOI 10.1002/navi.272.
   Shamaei K, 2018, IEEE T WIREL COMMUN, V17, P2173, DOI 10.1109/TWC.2018.2789882.
   Shamsi K., 2019, P IEEE VEH TECHN C, P1.
   Thevenon Paul, 2011, Navigation. Journal of the Institute of Navigation, V58, P71.
   United States Executive Office of the President, 2020, EX ORD STRENGTH NAT.
   Yang C, 2015, NAVIGATION-US, V62, P291, DOI 10.1002/navi.122.
   Yang C, 2014, IEEE AERO EL SYS MAG, V29, P34, DOI 10.1109/MAES.2013.130105.
   Yang JX, 2012, IEEE T BROADCAST, V58, P347, DOI 10.1109/TBC.2012.2191693.
   Zhang ZY, 2020, IEEE T MOBILE COMPUT, V19, P1760, DOI 10.1109/TMC.2019.2915221.
   Zhuang Y, 2016, IEEE T MOBILE COMPUT, V15, P1982, DOI 10.1109/TMC.2015.2451641.},
Number-of-Cited-References = {77},
Times-Cited = {9},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BR1JY},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000632603501023},
DA = {2022-05-17},
}

@inproceedings{ WOS:000313842700012,
Author = {Courbon, Jonathan and Korrapati, Hemanth and Mezouar, Youcef},
Editor = {Lee, S and Cho, HS and Yoon, KJ and Lee, JM},
Title = {Visual Memory Update for Life-Long Mobile Robot Navigation},
DOI = {10.1007/978-3-642-33926-4_12},
Booktitle = {INTELLIGENT AUTONOMOUS SYSTEMS 12, VOL 1},
Series = {Advances in Intelligent Systems and Computing},
Year = {2013},
Volume = {193},
Pages = {133+},
Note = {12th International Conference of Intelligent Autonomous Systems, Jeju,
   SOUTH KOREA, JUN 26-29, 2012},
Abstract = {A central clue for implementation of visual memory based navigation
   strategies relies on efficient point matching between the current image
   and the key images of the memory. However, the visual memory may become
   out of date after some times because the appearance of real-world
   environments keeps changing. It is thus necessary to remove obsolete
   information and to add new data to the visual memory over time. In this
   paper, we propose a method based on short-term and long term memory
   concepts to update the visual memory of mobile robots during navigation.
   The results of our experiments show that using this method improves the
   robustness of the localization and path-following steps.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Courbon, J (Corresponding Author), Clermont Univ, Univ Blaise Pascal, Inst Pascal, BP 10448, F-63000 Clermont Ferrand, France.
   Courbon, Jonathan; Korrapati, Hemanth, Clermont Univ, Univ Blaise Pascal, Inst Pascal, BP 10448, F-63000 Clermont Ferrand, France.
   Mezouar, Youcef, CNRS, UMR 6602, F-63171 Aubiere, France.},
ISSN = {2194-5357},
ISBN = {978-3-642-33925-7; 978-3-642-33926-4},
Keywords = {Visual memory; life-long mapping; mobile robots},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems},
Affiliations = {Centre National de la Recherche Scientifique (CNRS); Universite Clermont
   Auvergne \& Associes; Universite Clermont Auvergne (UCA); Centre
   National de la Recherche Scientifique (CNRS); CNRS - Institute for
   Engineering \& Systems Sciences (INSIS); Universite Clermont Auvergne \&
   Associes; Universite Clermont Auvergne (UCA)},
ORCID-Numbers = {mezouar, youcef/0000-0001-8138-3928},
Cited-References = {Atkinson R. L, 1968, PSYCHOL LEARNING MOT.
   Bacca B, 2010, ELECTRON LETT, V46, P1120, DOI 10.1049/el.2010.1599.
   Courbon J, 2009, IEEE T INTELL TRANSP, V10, P392, DOI 10.1109/TITS.2008.2012375.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.},
Number-of-Cited-References = {6},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BDM53},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000313842700012},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921704025,
Author = {Buerki, Mathias and Gilitschenski, Igor and Stumm, Elena and Siegwart,
   Roland and Nieto, Juan},
Book-Group-Author = {IEEE},
Title = {Appearance-Based Landmark Selection for Efficient Long-Term Visual
   Localization},
DOI = {10.1109/IROS.2016.7759609},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {4137-4143},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {In this paper, we present an online landmark selection method for
   distributed long-term visual localization systems in
   bandwidth-constrained environments. Sharing a common map for online
   localization provides a fleet of autonomous vehicles with the
   possibility to maintain and access a consistent map source, and
   therefore reduce redundancy while increasing efficiency. However,
   connectivity over a mobile network imposes strict bandwidth constraints
   and thus the need to minimize the amount of exchanged data. The wide
   range of varying appearance conditions encountered during long-term
   visual localization offers the potential to reduce data usage by
   extracting only those visual cues which are relevant at the given time.
   Motivated by this, we propose an unsupervised method of adaptively
   selecting landmarks according to how likely these landmarks are to be
   observable under the prevailing appearance condition. The ranking
   function this selection is based upon exploits landmark co-observability
   statistics collected in past traversals through the mapped area.
   Evaluation is performed over different outdoor environments, large
   time-scales and varying appearance conditions, including the extreme
   transition from day-time to night-time, demonstrating that with our
   appearance-dependent selection method, we can significantly reduce the
   amount of landmarks used for localization while maintaining or even
   improving the localization performance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Burki, M (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Buerki, Mathias; Gilitschenski, Igor; Stumm, Elena; Siegwart, Roland; Nieto, Juan, Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.},
ISBN = {978-1-5090-3762-9},
Keywords-Plus = {NAVIGATION; SLAM},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {mathias.burki@mavt.ethz.ch
   igor.gilitschenski@mavt.ethz.ch
   elena.stumm@mavt.ethz.ch
   roland.siegwart@mavt.ethz.ch
   juan.nieto@mavt.ethz.ch},
Affiliations = {ETH Zurich},
ResearcherID-Numbers = {Siegwart, Roland/A-4495-2008
   },
ORCID-Numbers = {Siegwart, Roland/0000-0002-2760-7983
   Gilitschenski, Igor/0000-0001-6426-365X},
Funding-Acknowledgement = {EU H project UP-Drive {[}688652]},
Funding-Text = {This work was supported by the EU H2020 project UP-Drive under grant nr.
   688652.},
Cited-References = {Carlevaris-Bianco N., 2012, IROS WORKSH LIF LEAR.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cieslewski T., 2015, ICRA.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dayoub F, 2008, IROS.
   Dymczyk Marcin, 2015, ICRA.
   Johns E., 2013, ICRA.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Konolige K., 2009, IROS.
   Lategahn H., 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P1, DOI 10.1109/ICVES.2012.6294279.
   Li Y., 2010, EUR C COMP VIS.
   Linegar C, 2015, ICRA.
   Lynen Simon, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P303, DOI 10.1109/3DV.2014.36.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Mohan M., 2015, ICRA.
   Mu BP, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Muhlfellner P., 2015, J SOFTWARE ENG UNPUB.
   Muhlfellner P., 2015, J FIELD ROBOTICS.
   Stumm E., 2015, ICRA.},
Number-of-Cited-References = {19},
Times-Cited = {17},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921704025},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000570976500043,
Author = {Zhang, Hao and Han, Fei and Wang, Hua},
Editor = {Hsu, D and Amato, N and Berman, S and Jacobs, S},
Title = {Robust Multimodal Sequence-Based Loop Closure Detection via Structured
   Sparsity},
DOI = {10.15607/RSS.2016.XII.043},
Booktitle = {ROBOTICS: SCIENCE AND SYSTEMS XII},
Year = {2016},
Note = {Workshop on Are the Skeptics Right Limits and Potentials of Deep
   Learning in Robotics at the 12th Conference on Robotics - Science and
   Systems (RSS), Univ Michigan, Ann Arbor, MI, JUN 18-22, 2016},
Abstract = {Loop closure detection is an essential component for simultaneously
   localization and mapping in a variety of robotics applications. One of
   the most challenging problems is to perform long-term place recognition
   with strong perceptual aliasing and appearance variations due to changes
   of illumination, vegetation, weather, etc. To address this challenge, we
   propose a novel Robust Multimodal Sequence-based (ROMS) method for
   long-term loop closure detection, by formulating image sequence matching
   as an optimization problem regularized by structured sparsity-inducing
   norms. Our method is able to model the sparsity nature of place
   recognition, i.e., the current location should match only a small subset
   of previously visited places, as well as to model underlying structures
   of image sequences and incorporate multiple feature modalities to
   construct a discriminative scene representation. In addition, a new
   optimization algorithm is developed to efficiently solve the formulated
   problem, which has a theoretical guarantee to converge to the global
   optimal solution. To evaluate the ROMS algorithm, extensive experiments
   are performed using large-scale benchmark datasets, including St Lucia,
   CMU-VL, and Nordland datasets. Experimental results have validated that
   our algorithm outperforms previous loop closure detection methods, and
   obtains the state-of-the-art performance on long-term place recognition.},
Publisher = {MIT PRESS},
Address = {ONE ROGERS ST, CAMBRIDGE, MA 02142 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhang, H (Corresponding Author), Colorado Sch Mines, Dept Elect Engn \& Comp Sci, Golden, CO 80401 USA.
   Zhang, Hao; Han, Fei; Wang, Hua, Colorado Sch Mines, Dept Elect Engn \& Comp Sci, Golden, CO 80401 USA.},
ISBN = {978-0-9923747-2-3},
Keywords-Plus = {PLACE RECOGNITION; LOCALIZATION; TIME; SLAM; BAGS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {hzhang@mines.edu
   fhan@mines.edu
   huawangcs@gmail.com},
Affiliations = {Colorado School of Mines},
ORCID-Numbers = {Zhang, Hao/0000-0001-8043-9184},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Chen C, 2006, INT J ROBOT RES, V25, P953, DOI 10.1177/0278364906068375.
   Cummins M., 2009, ROBOTICS SCI SYSTEMS.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Goldberg SB, 2002, AEROSP CONF PROC, P2025.
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475.
   Gutmann Jens-Steffen, 1999, IEEE INT S COMP INT.
   Hansen Paul, 2014, IEEE RSJ INT C INT R.
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Kleiner A, 2007, J FIELD ROBOT, V24, P723, DOI 10.1002/rob.20208.
   Klopschitz Manfred, 2008, 3D DATA PROCESSING V.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Latif Yasir, 2014, ROB SCI SYST C.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2012, IEEE INT CONF ROBOT, P822, DOI 10.1109/ICRA.2012.6224622.
   Milford MJ, 2004, IEEE INT CONF ROBOT, P403, DOI 10.1109/ROBOT.2004.1307183.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Naseer Tayyab, 2015, IEEE RSJ INT C INT R.
   Nie F., 2010, ADV NEURAL INFORM PR, V23, P1813, DOI DOI 10.1007/978-3-319-10690-8\_12.
   Pepperell E, 2014, IEEE INT CONF ROBOT, P1612, DOI 10.1109/ICRA.2014.6907067.
   Ren SQ, 2015, ADV NEUR IN, V28.
   Santos JM, 2015, J INTELL ROBOT SYST, V80, P401, DOI 10.1007/s10846-015-0180-8.
   Stumm ES, 2016, INT J ROBOT RES, V35, P334, DOI 10.1177/0278364915570140.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Sunderhauf Niko, 2013, WORKSH IEEE INT C RO.
   Teichman A, 2011, IEEE INT CONF ROBOT.
   Thrun S, 2008, SPRINGER TRAC ADV RO, V38, P13.
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x.
   Wang H., 2013, P ICML, P352.
   Zhang H, 2013, IEEE T CYBERNETICS, V43, P1429, DOI 10.1109/TCYB.2013.2275291.},
Number-of-Cited-References = {44},
Times-Cited = {24},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP9YF},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000570976500043},
DA = {2022-05-17},
}

@inproceedings{ WOS:000300178300022,
Author = {Lang, Dagmar and Winkens, Christian and Haeselich, Marcel and Paulus,
   Dietrich},
Editor = {Roning, J and Casasent, DP},
Title = {Hierarchical Loop Detection for Mobile Outdoor Robots},
Pages = {83010P},
Booktitle = {INTELLIGENT ROBOTS AND COMPUTER VISION XXIX: ALGORITHMS AND TECHNIQUES},
Series = {Proceedings of SPIE},
Year = {2012},
Volume = {8301},
Note = {Conference on Intelligent Robots and Computer Vision XXIX - Algorithms
   and Techniques, Burlingame, CA, JAN 23-24, 2012},
Abstract = {Loop closing is a fundamental part of 3D simultaneous localization and
   mapping (SLAM) that can greatly enhance the quality of long-term
   mapping. It is essential for the creation of globally consistent maps.
   Conceptually, loop closing is divided into detection and optimization.
   Recent approaches depend on a single sensor to recognize previously
   visited places in the loop detection stage. In this study, we combine
   data of multiple sensors such as GPS, vision, and laser range data to
   enhance detection results in repetitively changing environments that are
   not sufficiently explained by a single sensor. We present a fast and
   robust hierarchical loop detection algorithm for outdoor robots to
   achieve a reliable environment representation even if one or more
   sensors fail.},
Publisher = {SPIE-INT SOC OPTICAL ENGINEERING},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Lang, D (Corresponding Author), Univ Koblenz Landau, AGAS Robot, Act Vis Grp, Univ Str 1, D-56070 Koblenz, Germany.
   Lang, Dagmar; Winkens, Christian; Haeselich, Marcel; Paulus, Dietrich, Univ Koblenz Landau, AGAS Robot, Act Vis Grp, D-56070 Koblenz, Germany.},
DOI = {10.1117/12.908277},
Article-Number = {83010P},
ISSN = {0277-786X},
EISSN = {1996-756X},
ISBN = {978-0-81948-948-7},
Research-Areas = {Computer Science; Engineering; Robotics; Optics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics; Optics},
Author-Email = {robots@uni-koblenz.de},
Affiliations = {University of Koblenz \& Landau},
Cited-References = {Andreasson H, 2010, ROBOT AUTON SYST, V58, P157, DOI 10.1016/j.robot.2009.09.011.
   Angeli A, 2008, IEEE INT CONF ROBOT, P1842, DOI 10.1109/ROBOT.2008.4543475.
   Bay H., 2006, EUR C COMP VIS, P404.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Dijkstra, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390.
   Ebrahimi Mosalam, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P9, DOI 10.1109/CVPR.2009.5204313.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Granstrom K, 2010, IEEE INT C INT ROBOT, P2089, DOI 10.1109/IROS.2010.5651013.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246.
   Haselich M., 2012, P IEEE INT IN PRESS.
   Hertzberg J, 2009, COMPUTER, P1.
   Kunze L., 2007, P WORKSH COMP ATT AP.
   LAMON P, 2006, IEEE RSJ IROS WORKSH.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   MAGNUSSON M, 2009, P IEEE INT C ROB AUT, P23.
   NEUHAUS F, 2009, P 2009 IEEE C EM TEC, P00001.
   Newman P, 2009, P ROB SCI SYST.
   Nuchter A, 2009, SPRINGER TRAC ADV RO, V52, P1.
   Olson E., 2008, THESIS MIT CAMBRIDGE.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Pellenz J., 2010, P IEEE INT WORKSH SA.
   Pfaff P, 2007, INT J ROBOT RES, V26, P217, DOI 10.1177/0278364906075165.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O.},
Number-of-Cited-References = {26},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BYT58},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000300178300022},
DA = {2022-05-17},
}

@inproceedings{ WOS:000270919300120,
Author = {Fu, Siyao and Yang, Guosheng},
Book-Group-Author = {IEEE},
Title = {Uncalibrated Monocular based Simultaneous Localization and Mapping for
   Indoor Autonomous Mobile Robot Navigation},
DOI = {10.1109/ICNSC.2009.4919356},
Booktitle = {2009 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, SENSING AND CONTROL,
   VOLS 1 AND 2},
Series = {IEEE International Conference on Networking Sensing and Control},
Year = {2009},
Pages = {653-658},
Note = {International Conference on Networking, Sensing and Control, Okayama,
   JAPAN, MAR 26-29, 2009},
Abstract = {This paper describes a an SLAM algorithm for the navigation for an
   indoor autonomous mobile robot. The main emphasis of this paper is on
   the ability of line extraction. A recognition method based on straight
   line extraction is proposed for extracting the key features on the
   office ceiling, in an effort to estimate the pose of mobile robot.
   Random Sample Consensus (RANSAC) paradigm is used to group the line
   segments. During the navigation, onboard odometry is used at the
   beginning stage to estimate the information of environment for visual
   reckoning, while lamps on the ceiling act as beacons for positioning to
   eliminate accumulation of errors after a long-term run. The data
   captured from infrared sensors is used for constructing a map. The
   proposed method scales well with respect to the size of the input image
   and the number and size of the shapes within the data. Moreover the
   algorithm is conceptually simple and easy to implement. Simulation and
   experimental results show that good recognition and localization can be
   achieved using the proposed method, allowing for the interested region
   correspondence matching and mapping between images from different
   sensors or the same sensor indifferent time phrase.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Fu, SY (Corresponding Author), Cent Univ Nationalities, Sch Informat \& Engn, Beijing 100081, Peoples R China.
   Fu, Siyao; Yang, Guosheng, Cent Univ Nationalities, Sch Informat \& Engn, Beijing 100081, Peoples R China.},
ISSN = {1810-7869},
ISBN = {978-1-4244-3491-6},
Keywords-Plus = {SLAM},
Research-Areas = {Automation \& Control Systems; Computer Science; Remote Sensing;
   Telecommunications},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Hardware \&
   Architecture; Remote Sensing; Telecommunications},
Author-Email = {siyao.fu@ieee.org},
Affiliations = {Minzu University of China},
Cited-References = {Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   BURNS, 1986, IEEE T PATTERN ANAL, P425.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Eliazar Austin, 2003, P 18 INT JOINT C ART, P1135.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   FITZGIBBON AW, 1998, P EUR C COMP VIS, P311.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2007, ROBOT AUTON SYST, V55, P30, DOI 10.1016/j.robot.2006.06.007.
   Hough PVC, 1962, US patent, Patent No. {[}3069654, 3,069,654].
   Jung IK, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P946.
   Kim JH, 2003, IEEE INT CONF ROBOT, P406.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   MURPHY K, 1999, P C NEUR INF PROC SY, P1015.
   Neira J., 1997, P 5 INT S INT PROB S, P275.
   Newman P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1802, DOI 10.1109/ROBOT.2002.1014803.
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705.
   Sim R., 2005, IJCAI WORKSH REAS UN, P9.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   SMITH R, 1987, P 4 INT S ROB RES, P467.
   2D3 WEB BASED LIT.},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BLS20},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000270919300120},
DA = {2022-05-17},
}

@inproceedings{ WOS:000712319500114,
Author = {Gao, Peng and Zhang, Hao},
Book-Group-Author = {IEEE},
Title = {Long-term Place Recognition through Worst-case Graph Matching to
   Integrate Landmark Appearances and Spatial Relationships},
DOI = {10.1109/ICRA40945.2020.9196906},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2020},
Pages = {1070-1076},
Note = {IEEE International Conference on Robotics and Automation (ICRA), ELECTR
   NETWORK, MAY 31-JUN 15, 2020},
Abstract = {Place recognition is an important component for simultaneously
   localization and mapping in a variety of robotics applications.
   Recently, several approaches using landmark information to represent a
   place showed promising performance to address long-term environment
   changes. However, previous approaches do not explicitly consider changes
   of the landmarks, i,e., old landmarks may disappear and new ones often
   appear over time. In addition, representations used in these approaches
   to represent landmarks are limited, based upon visual or spatial cues
   only. In this paper, we introduce a novel worst-case graph matching
   approach that integrates spatial relationships of landmarks with their
   appearances for long-term place recognition. Our method designs a graph
   representation to encode distance and angular spatial relationships as
   well as visual appearances of landmarks in order to represent a place.
   Then, we formulate place recognition as a graph matching problem under
   the worst-case scenario. Our approach matches places by computing the
   similarities of distance and angular spatial relationships of the
   landmarks that have the least similar appearances (i.e., worst-case). If
   the worst appearance similarity of landmarks is small, two places are
   identified to be not the same, even though their graph representations
   have high spatial relationship similarities. We evaluate our approach
   over two public benchmark datasets for long-term place recognition,
   including St. Lucia and CMU-VL. The experimental results have validated
   that our approach obtains the state-of-the-art place recognition
   performance, with a changing number of landmarks.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gao, P (Corresponding Author), Colorado Sch Mines, Dept Comp Sci, Human Ctr Robot Lab, Golden, CO 80401 USA.
   Gao, Peng; Zhang, Hao, Colorado Sch Mines, Dept Comp Sci, Human Ctr Robot Lab, Golden, CO 80401 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-7281-7395-5},
Keywords-Plus = {LOOP CLOSURE DETECTION; VISUAL SLAM; FEATURES},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {gaopeng@mines.edu
   hzhang@mines.edu},
Affiliations = {Colorado School of Mines},
Funding-Acknowledgement = {DOT PHMSA {[}693JK31850005CAAP]; DOE {[}DE-FE0031650];  {[}IIS-1942056];
    {[}IIS-1849348];  {[}IIS1849359]},
Funding-Text = {This work was partially supported by IIS-1942056, IIS-1849348,
   IIS1849359, DOT PHMSA 693JK31850005CAAP, and DOE DE-FE0031650.},
Cited-References = {Arandjelovic R., 2016, IEEE C COMPUTER VISI.
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Han F, 2018, IEEE ROBOT AUTOM LET, V3, P3669, DOI 10.1109/LRA.2018.2856274.
   Han F, 2018, AUTON ROBOT, V42, P1323, DOI 10.1007/s10514-018-9736-3.
   Han F, 2017, IEEE ROBOT AUTOM LET, V2, P1172, DOI 10.1109/LRA.2017.2662061.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Hou Y, 2018, J INTELL ROBOT SYST, V92, P505, DOI 10.1007/s10846-017-0735-y.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Kitt B. M., 2011, MONOCULAR VISUAL ODO.
   Lategahn H, 2011, IEEE INT CONF ROBOT, P1732.
   Latif Y., 2014, ROBOTICS SCI SYSTEMS.
   Lee D, 2013, ROBOT INTELLIGENCE T.
   Liu K, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P8034.
   Lowry S, 2016, IEEE T ROBOT, V32, P600, DOI 10.1109/TRO.2016.2545711.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Milford MJ, 2004, IEEE INT CONF ROBOT, P403, DOI 10.1109/ROBOT.2004.1307183.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Panphattarasap P., 2016, P AS C COMP VIS, P487.
   Pronobis A, 2010, INT J ROBOT RES, V29, P298, DOI 10.1177/0278364909356483.
   Rabanser S., 2015, MACH LEARN, V98, P1.
   Romeijn HE, 2000, DISCRETE APPL MATH, V103, P209, DOI 10.1016/S0166-218X(99)00224-3.
   Siam Sayem Mohammad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5702, DOI 10.1109/ICRA.2017.7989671.
   Siva S, 2018, IEEE INT CONF ROBOT, P5175.
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Yang SW, 2017, ROBOT AUTON SYST, V93, P116, DOI 10.1016/j.robot.2017.03.018.
   Zetao Chen, 2017, 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P9, DOI 10.1109/IROS.2017.8202131.
   Zhang H, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII.
   Zhou HZ, 2015, IEEE T VEH TECHNOL, V64, P1364, DOI 10.1109/TVT.2015.2388780.
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1\_26.},
Number-of-Cited-References = {48},
Times-Cited = {3},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS3LB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000712319500114},
DA = {2022-05-17},
}

@article{ WOS:000494823200196,
Author = {Pan, Zhichen and Chen, Haoyao and Li, Silin and Liu, Yunhui},
Title = {ClusterMap Building and Relocalization in Urban Environments for
   Unmanned Vehicles},
Journal = {SENSORS},
Year = {2019},
Volume = {19},
Number = {19},
Pages = {4252},
Month = {OCT},
Abstract = {Map building and map-based relocalization techniques are important for
   unmanned vehicles operating in urban environments. The existing
   approaches require expensive high-density laser range finders and suffer
   from relocalization problems in long-term applications. This study
   proposes a novel map format called the ClusterMap, on the basis of which
   an approach to achieving relocalization is developed. The ClusterMap is
   generated by segmenting the perceived point clouds into different point
   clusters and filtering out clusters belonging to dynamic objects. A
   location descriptor associated with each cluster is designed for
   differentiation. The relocalization in the global map is achieved by
   matching cluster descriptors between local and global maps. The solution
   does not require high-density point clouds and high-precision
   segmentation algorithms. In addition, it prevents the effects of
   environmental changes on illumination intensity, object appearance, and
   observation direction. A consistent ClusterMap without any scale problem
   is built by utilizing a 3D visual-LIDAR simultaneous localization and
   mapping solution by fusing LIDAR and visual information. Experiments on
   the KITTI dataset and our mobile vehicle illustrates the effectiveness
   of the proposed approach.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Chen, HY (Corresponding Author), Harbin Inst Technol Shenzhen, Sch Mech Engn \& Automat, Shenzhen 518055, Peoples R China.
   Chen, HY (Corresponding Author), Shenzhen Univ Town, Bldg G1011, Shenzhen 518055, Peoples R China.
   Pan, Zhichen; Chen, Haoyao; Li, Silin, Harbin Inst Technol Shenzhen, Sch Mech Engn \& Automat, Shenzhen 518055, Peoples R China.
   Liu, Yunhui, Chinese Univ Hong Kong, Dept Mech \& Automat Engn, Hong Kong, Peoples R China.
   Pan, Zhichen; Chen, Haoyao; Li, Silin, Shenzhen Univ Town, Bldg G1011, Shenzhen 518055, Peoples R China.
   Liu, Yunhui, Chinese Univ Hong Kong, Shatin, Room 208,William MW Mong Engn Bldg, Hong Kong, Peoples R China.},
DOI = {10.3390/s19194252},
Article-Number = {4252},
EISSN = {1424-8220},
Keywords = {relocalization; SLAM; Localization; Map Descriptor; LIDAR-based Map
   Building; ClusterMap},
Keywords-Plus = {SLAM; LOCALIZATION; ODOMETRY; VISION},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {zhchpan@163.com
   hychen5@hit.edu.cn
   lisilin013@163.com
   yhliu@mae.cuhk.edu.hk},
Affiliations = {Harbin Institute of Technology; Chinese University of Hong Kong;
   University Town of Shenzhen; Chinese University of Hong Kong},
ORCID-Numbers = {Chen, Haoyao/0000-0003-1652-9681},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61673131, U1713206,
   U1613218]; Bureau of Industry and Information Technology of Shenzhen
   {[}20170505160946600]},
Funding-Text = {This work was partially supported by grants from the National Natural
   Science Foundation of China (Reference No. 61673131, U1713206 and
   U1613218) and the Bureau of Industry and Information Technology of
   Shenzhen (Reference No. 20170505160946600).},
Cited-References = {Bogoslavskyi I, 2017, PFG-J PHOTOGRAMM REM, V85, P41, DOI 10.1007/s41064-016-0003-y.
   Bosse M, 2013, IEEE INT CONF ROBOT, P2677, DOI 10.1109/ICRA.2013.6630945.
   Brenneke C, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P188.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Dhall A., 2017, ARXIV170509785.
   Dube R., 2016, ARXIV160907720.
   Dube R., 2018, P ROB SCI SYST RSS P.
   Engel J., 2017, EUR C COMP VIS ECCV, P834.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Finman R., 2015, P ICRA WORKSH VIS PL.
   Gawel A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P182, DOI 10.1109/IROS.2016.7759053.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Haoyao Chen, 2019, Assembly Automation, V39, P297, DOI 10.1108/AA-04-2018-065.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Lenac K, 2017, ROBOT AUTON SYST, V92, P197, DOI 10.1016/j.robot.2017.03.013.
   Li H., 2017, ARXIV171105805.
   Lin LS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153410.
   Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Opromolla R, 2016, INT CONF UNMAN AIRCR, P649, DOI 10.1109/ICUAS.2016.7502580.
   Pfrunder A, 2017, IEEE INT C INT ROBOT, P2601, DOI 10.1109/IROS.2017.8206083.
   Rusu R.B., 2009, IEEE INT C ROB AUT I, P3212, DOI DOI 10.1109/R0B0T.2009.5152473.
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Schauwecker K, 2014, IEEE INT CONF ROBOT, P6102, DOI 10.1109/ICRA.2014.6907758.
   Shehata, 2017, ARXIV PREPRINT ARXIV.
   Wang HS, 2017, IEEE T IND ELECTRON, V64, P2893, DOI 10.1109/TIE.2016.2631514.
   Wang L, 2017, IFAC PAPERSONLINE, V50, P276, DOI 10.1016/j.ifacol.2017.08.046.
   Zhang J, 2018, J FIELD ROBOT, V35, P1242, DOI 10.1002/rob.21809.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.
   Zhang J, 2017, AUTON ROBOT, V41, P31, DOI {[}10.1007/s10514-015-9525-1, 10.1109/MWSYM.2015.7167049].
   Zhu ZL, 2015, PROCEEDINGS OF THE 31ST INTERNATIONAL CONFERENCE ON COMPUTER ANIMATION AND SOCIAL AGENTS (CASA 2016), P53, DOI 10.1145/3205326.3205357.},
Number-of-Cited-References = {34},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {6},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {JK4OO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000494823200196},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@article{ WOS:000403987300020,
Author = {Melo, Jose and Matos, Anibal},
Title = {Survey on advances on terrain based navigation for autonomous underwater
   vehicles},
Journal = {OCEAN ENGINEERING},
Year = {2017},
Volume = {139},
Pages = {250-264},
Month = {JUL 15},
Abstract = {The autonomy of robotic underwater vehicles is dependent on the ability
   to perform long-term and long-range missions without need of human
   intervention. While current state-of-the-art underwater navigation
   techniques are able to provide sufficient levels of precision in
   positioning, they require the use of support vessels or acoustic
   beacons. This can pose limitations on the size of the survey area, but
   also on the whole cost of the operations.
   Terrain Based Navigation is a sensor-based navigation technique that
   bounds the error growth of dead reckoning using a map with terrain
   information, provided that there is enough terrain variability. An
   obvious advantage of Terrain Based Navigation is the fact that no
   external aiding signals or devices are required. Because of this unique
   feature, terrain navigation has the potential to dramatically improve
   the autonomy of Autonomous Underwater Vehicles (AUVs).
   This paper consists on a comprehensive survey on the recent developments
   for Terrain Based Navigation methods proposed for AUVs. The survey
   includes a brief introduction to the original Terrain Based Navigation
   formulations, as well as a description of the algorithms, and a list of
   the different implementation alternatives found in the literature.
   Additionally, and due to the relevance, Bathymetric SLAM techniques will
   also be discussed.},
Publisher = {PERGAMON-ELSEVIER SCIENCE LTD},
Address = {THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Melo, J (Corresponding Author), Univ Porto, FEUP Fac Engn, Rua Dr Roberto Frias S-N, P-4200465 Oporto, Portugal.
   Melo, Jose; Matos, Anibal, Univ Porto, FEUP Fac Engn, Rua Dr Roberto Frias S-N, P-4200465 Oporto, Portugal.
   Melo, Jose; Matos, Anibal, INESC TEC INESC Technol \& Sci, Rua Dr Roberto Frias 378, P-4200465 Oporto, Portugal.},
DOI = {10.1016/j.oceaneng.2017.04.047},
ISSN = {0029-8018},
Keywords = {AUV navigation; AUV autonomy; Terrain based navigation for AUVs},
Keywords-Plus = {PARTICLE FILTER; AUV NAVIGATION; SLAM; LOCALIZATION},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Civil; Engineering, Ocean;
   Oceanography},
Author-Email = {jose.melo@fe.up.pt
   anibal@fe.up.pt},
Affiliations = {Universidade do Porto; INESC TEC; Universidade do Porto},
ResearcherID-Numbers = {Melo, José/I-5411-2019
   Matos, Aníbal/N-4350-2013},
ORCID-Numbers = {Melo, José/0000-0001-5190-9730
   Matos, Aníbal/0000-0002-9771-002X},
Funding-Acknowledgement = {ERDF-European Regional Development Fund through the Operational
   Programme for Competitiveness and Internationalisation - COMPETE
   Programme {[}POCI-01-0145-FEDER-006961]; National Funds through the
   FCT-Fundacao para a Ciencia e a Tecnologia (Portuguese Foundation for
   Science and Technology) {[}UID/EEA/50014/2013]; Portuguese Foundation
   for Science and Technology {[}SFRH/BD/70727/2010]},
Funding-Text = {This work is financed by the ERDF-European Regional Development Fund
   through the Operational Programme for Competitiveness and
   Internationalisation - COMPETE 2020 Programme within project
   ``POCI-01-0145-FEDER-006961{''}, and by National Funds through the
   FCT-Fundacao para a Ciencia e a Tecnologia (Portuguese Foundation for
   Science and Technology) as part of project UID/EEA/50014/2013. The first
   author was supported by the Portuguese Foundation for Science and
   Technology through the Ph.D. grant SFRH/BD/70727/2010.},
Cited-References = {Anonsen K. B., 2011, P MTS IEEE OC 11 C K, P1, DOI DOI 10.23919/OCEANS.2011.6107235.
   Anonsen K.B., 2010, THESIS.
   Anonsen KB, 2007, 2007 SYMPOSIUM ON UNDERWATER TECHNOLOGY AND WORKSHOP ON SCIENTIFIC USE OF SUBMARINE CABLES AND RELATED TECHNOLOGIES, VOLS 1 AND 2, P499, DOI 10.1109/UT.2007.370773.
   Anonsen KB, 2006, IEEE POSITION LOCAT, P1027, DOI 10.1109/PLANS.2006.1650705.
   Anonsen Kjetil Bergh, 2007, P IFAC C CONTR APPL, V40, P106, DOI {[}10.3182/20070919-3-HR-3904.00020, DOI 10.3182/20070919-3-HR-3904.00020].
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374.
   Aulinas J., 2011, P OCEANS JUN, P1.
   Aulinas J, 2010, OCEANS-IEEE.
   Bachmann A., 2003, P AUSTR C ROB AUT, P1.
   Bahr A, 2009, INT J ROBOT RES, V28, P714, DOI 10.1177/0278364908100561.
   BARKBY S, 2009, P OCEANS 09 C BIL MS, P1.
   Barkby S, 2011, IEEE INT C INT ROBOT, P1242, DOI 10.1109/IROS.2011.6048284.
   Barkby S, 2011, J FIELD ROBOT, V28, P19, DOI 10.1002/rob.20382.
   Barkby S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P219, DOI 10.1109/IROS.2009.5354248.
   Bartmanski D, 2012, CULT SOCIOL-SER, P1.
   Bergem O., 1993, THESIS.
   Bergman N, 1999, IEEE CONTR SYST MAG, V19, P33, DOI 10.1109/37.768538.
   Bergman N., 1999, THESIS.
   Bergman N., 1997, CRAMER RAO BOUND TER.
   Burguera A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146396.
   Burguera A, 2010, IEEE INT C INT ROBOT, P2546, DOI 10.1109/IROS.2010.5649492.
   Carlstrom J., 2007, P 15 INT S UNM UNT S, P250.
   Carr SC, 2010, INT CULT PSYCHOL, P1, DOI 10.1007/978-1-4419-6208-9\_1.
   Censi A, 2006, IEEE INT CONF ROBOT, P2291, DOI 10.1109/ROBOT.2006.1642044.
   CHEN Z, 2003, BAYESIAN FILTERING K.
   Claus B, 2015, J FIELD ROBOT, V32, P935, DOI 10.1002/rob.21563.
   Cowie M., 2008, P IEEE ION POS LOC N, P1219.
   CSORBA M, 1997, SIMULTANEOUS LOCALIS.
   Dektor S., 2012, AUTONOMOUS UNDERWATE, P1.
   Dektor S., 2014, OCEANS ST JOHNS 2014, P1, DOI DOI 10.1109/OCEANS.2014.7003195.
   DiMassa DE, 1997, OCEANS `97 MTS/IEEE CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P541, DOI 10.1109/OCEANS.1997.634423.
   Donovan G.T., 2011, OCEANS 2011, P1.
   Donovan GT, 2012, IEEE J OCEANIC ENG, V37, P431, DOI 10.1109/JOE.2012.2190810.
   Eliazar A., 2003, P 18 INT JOINT C ART, P1135.
   Eliazar AI, 2004, IEEE INT CONF ROBOT, P1314, DOI 10.1109/ROBOT.2004.1308006.
   ENNS R, 1995, J GUID CONTROL DYNAM, V18, P1444, DOI 10.2514/3.21566.
   Fairfield N., 2008, OCEANS 2008, P1, DOI DOI 10.1109/OCEANS.2008.5151853.
   Fairfield N, 2007, J FIELD ROBOT, V24, P3, DOI 10.1002/rob.20165.
   Fairfield N, 2010, J FIELD ROBOT, V27, P85, DOI 10.1002/rob.20320.
   Fallon MF, 2010, IEEE INT CONF ROBOT, P4256, DOI 10.1109/ROBOT.2010.5509869.
   Ferreira B., 2010, OCEANS 2010 MTS IEEE, P1, DOI 10.1109/OCEANS.2010.5664518 ..
   Fofonoff N. P., 1983, ALGORITHMS COMPUTATI.
   Gannan Yuan, 2012, Proceedings of the 2012 International Conference on Measurement, Information and Control (MIC), P922, DOI 10.1109/MIC.2012.6273436.
   Groves PD, 2013, ARTECH HSE GNSS TECH, P1.
   Hagen O.K., 2008, PRESSURE DEPTH ESTIM.
   Hagen O.K., 2011, OCEANS 2011, P1.
   Hagen P. E., 2009, UNDERWATER VEHICLES, P129.
   Hansen RE, 2003, OCEANS 2003 MTS/IEEE: CELEBRATING THE PAST...TEAMING TOWARD THE FUTURE, P2438, DOI 10.1109/OCEANS.2003.178294.
   HANSEN RE, 2011, SONAR SYSTEMS, P3.
   Hansen RE, 2011, IEEE T GEOSCI REMOTE, V49, P3677, DOI 10.1109/TGRS.2011.2155071.
   Hausler A. J., 2013, P MTS IEEE OC, P1.
   Hernandez E., 2009, J PHYS AGENTS, V3, P1.
   Hernandez E, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P255, DOI 10.1109/IROS.2009.5354656.
   Hollowell J., 1990, IEEE PLANS `90: Position Location and Navigation Symposium Record. `The 1990's - A Decade of Excellence in the Navigation Sciences' (Cat. No.90CH2811-8), P616, DOI 10.1109/PLANS.1990.66236.
   Hostetler L., 1978, P AIAA GUID CONTR C, P20.
   HOSTETLER LD, 1983, IEEE T AUTOMAT CONTR, V28, P315, DOI 10.1109/TAC.1983.1103232.
   Houts SE, 2012, IEEE AUTO UNDER VEH.
   Jalving B., 2004, P UDT EUR NIC FRANC, P1.
   Jian S., 2012, J CHINESE INERTIAL T.
   Jing ZQ, 2009, 2009 INTERNATIONAL CONFERENCE ON ENERGY AND ENVIRONMENT TECHNOLOGY, VOL 3, PROCEEDINGS, P3, DOI 10.1109/ICEET.2009.467.
   Johnston A. E., 2008, Proceedings - International Fertiliser Society, P1.
   Karabork A., 2010, THESIS.
   Karlsson R., 2003, P IEEE INT C AC SPEE.
   Kim J, 2011, OCEANS 2011.
   Kinsey J., 2006, P C MAN CONTR MAR CR, P1.
   Koh A. C. T., 2009, OCEANS 2009, P1.
   Krupinski S, 2009, OCEANS-IEEE, P500.
   Kullander L., 1989, Proceedings of the 6th International Symposium on Unmanned Untethered Submersible Technology (IEEE Cat. No.89CH2782-1), P494, DOI 10.1109/UUST.1989.754741.
   LaPointe C. E., 2006, THESIS.
   Larsen MB, 2000, OCEANS 2000 MTS/IEEE - WHERE MARINE SCIENCE AND TECHNOLOGY MEET, VOLS 1-3, CONFERENCE PROCEEDINGS, P2043, DOI 10.1109/OCEANS.2000.882240.
   Leonard J.J., 1998, MIT MARINE ROBOTICS, V1, P1.
   Lucido L, 1998, INT J SYST SCI, V29, P1157, DOI 10.1080/00207729808929605.
   Lucido L., 2004, P MTS IEEE OC 96 C F, P417.
   Makumder S., 2001, THESIS.
   Mallios A, 2014, AUTON ROBOT, V36, P181, DOI 10.1007/s10514-013-9345-0.
   Mallios A, 2010, IEEE INT C INT ROBOT, P4404, DOI 10.1109/IROS.2010.5649246.
   Manual on Hydrography, 2011, 4 QUAI ANT 1ER BP 44.
   Massa D.D., 1997, THESIS.
   Meduna D, 2010, AUTONOMOUS UNDERWATE, V2010, P1.
   Meduna D. K., 2008, OCEANS 2008, P1, DOI 10.1109/OCEANS.2008.5152043.
   Meduna DK., 2011, TERRAIN RELATIVE NAV.
   Melo J., 2013, P MTS IEEE OC 13 C, P1.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Morice C., 2009, OCEANS 2009 EUROPE, P1.
   Mu H, 2007, C IND ELECT APPL, P2821.
   Multibeam Sonar Theory of Operation, 2000, MULT SON THEOR OP L.
   Murangira A, 2011, P 14 INT C INF FUS F, P1.
   Nakaya T., 2009, P GEOC 2009, P1.
   Nordlund PJ, 2009, IEEE T AERO ELEC SYS, V45, P1385, DOI 10.1109/TAES.2009.5310306.
   Nygren I, 2004, IEEE J OCEANIC ENG, V29, P906, DOI 10.1109/JOE.2004.833222.
   Nygren Ingemar, 2008, 2008 IEEE/ION Position, Location and Navigation Symposium - PLANS 2008, P923, DOI 10.1109/PLANS.2008.4570034.
   Nygren I., 2005, THESIS.
   Padial J, 2014, OCEANS-IEEE.
   Padilla J., 2014, P 15 INT HEAT T C, P1.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Ren ZX, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P1025, DOI 10.1109/ICINFA.2008.4608149.
   Ribas D, 2008, J FIELD ROBOT, V25, P898, DOI 10.1002/rob.20249.
   Roman C., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3662.
   Schon T.B., 2006, IEEE AER C, P1.
   Stalder S, 2008, OCEANS-IEEE, P51.
   Strauss O, 1999, OCEANS `99 MTS/IEEE : RIDING THE CREST INTO THE 21ST CENTURY, VOLS 1-3, P882, DOI 10.1109/OCEANS.1999.804990.
   Stuckey R.A, 2012, IFAC WORKSH NAV GUID, P1.
   Stutters L, 2008, IEEE T SYST MAN CY C, V38, P581, DOI 10.1109/TSMCC.2008.919147.
   Taejin K., 2014, P ICPHM INT C PROGN, P1, DOI DOI 10.1155/2014/193401.
   Teixeira F. C., 2012, IFAC P VOLUMES, V45, P132, DOI DOI 10.3182/20120410-3-PT-4028.00023.
   Thrun S., 2005, INTELLIGENT ROBOTICS.
   Vaman D, 2012, IEEE AIAA 31 DIG AV.
   Vickery K, 1998, PROCEEDINGS OF THE 1998 WORKSHOP ON AUTONOMOUS UNDERWATER VEHICLES, (AUV `98), P5, DOI 10.1109/AUV.1998.744434.
   Wang KD, 2006, LECT NOTES COMPUT SC, V4109, P252.
   Wang KD, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P391, DOI 10.1109/WCICA.2010.5555067.
   Wang S., 2010, P IEEE INFOCOM, P1, DOI {[}10.1109/INFCOM.2010.5461943, DOI 10.1109/INFCOM.2010.5461943].
   Wilby AD, 1999, OCEANS `99 MTS/IEEE : RIDING THE CREST INTO THE 21ST CENTURY, VOLS 1-3, P23, DOI 10.1109/OCEANS.1999.799702.
   Williams S.B., 2001, EFFICIENT SOLUTIONS.
   Williams S, 2006, SPRINGER TRAC ADV RO, V24, P93.
   Willumsen Are B, 2007, OCEANS 2007 - Europe, P1.
   Woock P, 2010, OCEANS 10 IEEE SYDNE, P1.
   Woock P., 2012, P MTS IEEE OC 12 C Y, P1.
   Zandara S, 2013, IEEE INT CONF ROBOT, P40, DOI 10.1109/ICRA.2013.6630554.
   Zert B, 2005, Oceans 2005 - Europe, Vols 1 and 2, P124.},
Number-of-Cited-References = {119},
Times-Cited = {92},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {102},
Journal-ISO = {Ocean Eng.},
Doc-Delivery-Number = {EY4ZP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000403987300020},
OA = {Green Published},
DA = {2022-05-17},
}

@article{ WOS:000429978600023,
Author = {Fu, Changhong and Sarabakha, Andriy and Kayacan, Erdal and Wagner,
   Christian and John, Robert and Garibaldi, Jonathan M.},
Title = {Input Uncertainty Sensitivity Enhanced Nonsingleton Fuzzy Logic
   Controllers for Long-Term Navigation of Quadrotor UAVs},
Journal = {IEEE-ASME TRANSACTIONS ON MECHATRONICS},
Year = {2018},
Volume = {23},
Number = {2},
Pages = {725-734},
Month = {APR},
Abstract = {Input uncertainty, e.g., noise on the on-board camera and inertial
   measurement unit, in vision-based control of unmanned aerial vehicles
   (UAVs) is an inevitable problem. In order to handle input uncertainties
   as well as further analyze the interaction between the input and the
   antecedent fuzzy sets (FSs) of nonsingleton fuzzy logic controllers
   (NSFLCs), an input uncertainty sensitivity enhanced NSFLC has been
   developed in robot operating system using the C++ programming language.
   Based on recent advances in nonsingleton inference, the centroid of the
   intersection of the input and antecedent FSs (Cen-NSFLC) is utilized to
   calculate the firing strength of each rule instead of the maximum of the
   intersection used in traditional NSFLC (Tra-NSFLC). An 8-shaped
   trajectory, consisting of straight and curved lines, is used for the
   real-time validation of the proposed controllers for a trajectory
   following problem. An accurate monocular keyframe-based visual-inertial
   simultaneous localization and mapping (SLAM) approach is used to
   estimate the position of the quadrotor UAV in GPS-denied unknown
   environments. The performance of the Cen-NSFLC is compared with a
   conventional proportional-integral derivative (PID) controller, a
   singleton FLC and a Tra-NSFLC. All controllers are evaluated for
   different flight speeds, thus introducing different levels of
   uncertainty into the control problem. Visualinertial SLAM-based
   real-time quadrotor UAV flight tests demonstrate that not only does the
   Cen-NSFLC achieve the best control performance among the four
   controllers, but it also shows better control performance when compared
   to their singleton counterparts. Considering the bias in the use of
   model-based controllers, e.g., PID, for the control of UAVs, this paper
   advocates an alternative method, namely Cen-NSFLCs, in uncertain working
   environments.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Kayacan, E (Corresponding Author), Nanyang Technol Univ, Sch Mech \& Aerosp Engn, Singapore 639798, Singapore.
   Fu, Changhong; Sarabakha, Andriy; Kayacan, Erdal, Nanyang Technol Univ, Sch Mech \& Aerosp Engn, Singapore 639798, Singapore.
   Fu, Changhong; Sarabakha, Andriy, NTU Corp Lab, ST Engn, Singapore 639798, Singapore.
   Wagner, Christian; John, Robert; Garibaldi, Jonathan M., Univ Nottingham, Sch Comp Sci, Lab Uncertainty Data \& Decis Making, Nottingham NG7 2RD, England.
   Wagner, Christian, Michigan Technol Univ, Inst Comp \& Cyber Syst, Houghton, MI 49931 USA.},
DOI = {10.1109/TMECH.2018.2810947},
ISSN = {1083-4435},
EISSN = {1941-014X},
Keywords = {Fuzzy logic controller (FLC); input uncertainty sensitivity enhanced
   nonsingleton FLC (NSFLC); monocular visual-inertial simultaneous
   localization and mapping (SLAM); NSFLC; unmanned aerial vehicle (UAV)},
Keywords-Plus = {TRACKING; ROUTINES; SYSTEM},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Manufacturing; Engineering,
   Electrical \& Electronic; Engineering, Mechanical},
Author-Email = {changhongfu@ntu.edu.sg
   andriy001@e.ntu.edu.sg
   erdal@ntu.edu.sg
   christian.wagner@nottingham.ac.uk
   robert.john@nottingham.ac.uk
   jon.garibaldi@nottingham.ac.uk},
Affiliations = {Nanyang Technological University \& National Institute of Education
   (NIE) Singapore; Nanyang Technological University; University of
   Nottingham; Michigan Technological University},
ResearcherID-Numbers = {Kayacan, Erdal/D-6256-2014
   Fu, Changhong/AAN-2859-2020
   John, Robert/A-4073-2009
   },
ORCID-Numbers = {Kayacan, Erdal/0000-0002-4873-2513
   Fu, Changhong/0000-0002-9897-6022
   John, Robert/0000-0002-2341-9993
   Sarabakha, Andriy/0000-0002-3629-0674
   Kayacan, Erdal/0000-0002-7143-8777
   Wagner, Christian/0000-0002-6121-9722},
Funding-Acknowledgement = {ST Engineering-NTU Corporate Laboratory through the NRF corporate
   lab@university scheme; RCUK's From Human Data to Personal Experience
   Grant {[}EP/M02315X/1]},
Funding-Text = {This work was supported in part by the ST Engineering-NTU Corporate
   Laboratory through the NRF corporate lab@university scheme and in part
   by the RCUK's EP/M02315X/1 From Human Data to Personal Experience Grant.},
Cited-References = {Cara A. B., 2011, Proceedings 2011 IEEE Symposium on Advances in Type-2 Fuzzy Logic Systems (T2FUZZ), P126, DOI 10.1109/T2FUZZ.2011.5949560.
   Chen FY, 2016, IEEE T IND ELECTRON, V63, P5044, DOI 10.1109/TIE.2016.2552151.
   Doyle CE, 2013, IEEE-ASME T MECH, V18, P506, DOI 10.1109/TMECH.2012.2211081.
   Dryanovski I, 2013, AUTON ROBOT, V34, P177, DOI 10.1007/s10514-012-9318-8.
   Erginer B, 2012, INT J CONTROL AUTOM, V10, P61, DOI 10.1007/s12555-012-0107-0.
   Fu CH, 2016, IEEE INT FUZZY SYST, P1023, DOI 10.1109/FUZZ-IEEE.2016.7737800.
   Fu CH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16091406.
   Fu CH, 2015, INT CONF UNMAN AIRCR, P957, DOI 10.1109/ICUAS.2015.7152384.
   Fu CH, 2014, J INTELL ROBOT SYST, V73, P513, DOI 10.1007/s10846-013-9918-3.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Kayacan E, 2017, IEEE-ASME T MECH, V22, P339, DOI 10.1109/TMECH.2016.2614672.
   Klein George, 2007, P1.
   Mahony R, 2012, IEEE ROBOT AUTOM MAG, V19, P20, DOI 10.1109/MRA.2012.2206474.
   Mellinger D, 2011, IEEE INT CONF ROBOT, P2520.
   Mendel J., 2001, UNCERTAIN RULE BASED.
   Michael N, 2012, J FIELD ROBOT, V29, P832, DOI 10.1002/rob.21436.
   Mouzouris GC, 1997, IEEE T FUZZY SYST, V5, P199, DOI 10.1109/91.580795.
   Mullner D, 2013, J STAT SOFTW, V53, P1.
   Olivares-Mendez MA, 2015, SENSORS-BASEL, V15, P31362, DOI 10.3390/s151229861.
   Olivares-Mendez MA, 2014, MED C CONTR AUTOMAT, P1183, DOI 10.1109/MED.2014.6961536.
   Pestana J, 2014, J INTELL ROBOT SYST, V73, P387, DOI 10.1007/s10846-013-9953-0.
   Pourabdollah A, 2016, IEEE T FUZZY SYST, V24, P1513, DOI 10.1109/TFUZZ.2016.2540065.
   Pourkazemi A., 2015, P IEEE 15 MED MICR S, P1.
   Puls T, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3374, DOI 10.1109/IROS.2009.5354646.
   Rinaldi F, 2013, J INTELL ROBOT SYST, V70, P203, DOI 10.1007/s10846-012-9708-3.
   Santos M, 2010, Proceedings 2010 IEEE International Conference on Intelligent Systems and Knowledge Engineering (ISKE 2010), P141, DOI 10.1109/ISKE.2010.5680812.
   Shen S., 2013, P ROBOT SCI SYST, V1, P1.
   Tauro F, 2015, IEEE-ASME T MECH, V20, P3269, DOI 10.1109/TMECH.2015.2408112.
   Tomic T, 2012, IEEE ROBOT AUTOM MAG, V19, P46, DOI 10.1109/MRA.2012.2206473.
   Valente J, 2011, SENSORS-BASEL, V11, P6088, DOI 10.3390/s110606088.
   Wallace L, 2014, IEEE T GEOSCI REMOTE, V52, P7619, DOI 10.1109/TGRS.2014.2315649.
   Weiss S, 2011, J FIELD ROBOT, V28, P854, DOI 10.1002/rob.20412.
   Zhou DJ, 2016, IEEE INT CONF ROBOT, P1249, DOI 10.1109/ICRA.2016.7487256.
   Zhou HL, 2015, IEEE T INTELL TRANSP, V16, P297, DOI 10.1109/TITS.2014.2331353.},
Number-of-Cited-References = {34},
Times-Cited = {32},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {40},
Journal-ISO = {IEEE-ASME Trans. Mechatron.},
Doc-Delivery-Number = {GC7MY},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000429978600023},
OA = {Green Submitted, Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000712319501101,
Author = {Peng, Cheng and Weikersdorfer, David},
Book-Group-Author = {IEEE},
Title = {Map As the Hidden Sensor: Fast Odometry-Based Global Localization},
DOI = {10.1109/ICRA40945.2020.9197225},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2020},
Pages = {2317-2323},
Note = {IEEE International Conference on Robotics and Automation (ICRA), ELECTR
   NETWORK, MAY 31-JUN 15, 2020},
Abstract = {Accurate and robust global localization is essential to robotics
   applications. We propose a novel global localization method that employs
   the map traversability as a hidden observation. The resulting
   map-corrected odometry localization is able to provide an accurate
   belief tensor of the robot state. Our method can be used for blind
   robots in dark or highly reflective areas. In contrast to odometry drift
   in the long-term, our method using only odometry and the map converges
   in long-term. Our method can also be integrated with other sensors to
   boost the localization performance. The algorithm does not have any
   initial state assumption and tracks all possible robot states at all
   times. Therefore, our method is global and is robust in the event of
   ambiguous observations. We parallel each step of our algorithm such that
   it can be performed in real-time (up to similar to 300 Hz) using GPU. We
   validate our algorithm in different publicly available floor-plans and
   show that it is able to converge to the ground truth fast while being
   robust to ambiguities.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Peng, C (Corresponding Author), NVIDIA Corperat, ISAAC SDK Team, Santa Clara, CA 95051 USA.
   Peng, C (Corresponding Author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
   Peng, Cheng; Weikersdorfer, David, NVIDIA Corperat, ISAAC SDK Team, Santa Clara, CA 95051 USA.
   Peng, Cheng, Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-7281-7395-5},
Keywords-Plus = {SLAM},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {peng0175@umn.edu},
Affiliations = {University of Minnesota System; University of Minnesota Twin Cities},
Funding-Acknowledgement = {NVIDIA},
Funding-Text = {This work was supported by NVIDIA},
Cited-References = {Alsayed Z, 2017, IEEE INT C INTELL TR.
   AULINAS J, 2008, CCIA, V184, P363, DOI DOI 10.3233/978-1-58603-925-7-363.
   Brubaker MA, 2016, IEEE T PATTERN ANAL, V38, P652, DOI 10.1109/TPAMI.2015.2453975.
   Burgard W, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P896.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Chen D., 2011, P 13 WORKSH ALG ENG, P75.
   DAVIES PJ, 2010, PLANT HORMONES, P1, DOI {[}DOI 10.1007/978-1-4020-2686-7, 10.1007/978-1-4020-2686-7\_1].
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038.
   FLOYD RW, 1976, P SID, V17, P75.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Grisetti G, 2005, IEEE INT CONF ROBOT, P2432.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisetti G, 2007, ROBOT AUTON SYST, V55, P30, DOI 10.1016/j.robot.2006.06.007.
   Gustafsson F, 2010, IEEE AERO EL SYS MAG, V25, P53, DOI 10.1109/MAES.2010.5546308.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Howard A., 2003, ROBOTICS DATA SET RE.
   Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4\_59.
   Klepal, 2008, P IEEE ION POS LOC N, P141, DOI DOI 10.1109/PLANS.2008.4570050.
   Kwak N, 2007, 2007 RO-MAN: 16TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1-3, P200.
   Luo A, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6110327.
   Maybeck Peter S., 1982, STOCHASTIC MODELS ES, V3.
   Montemerlo M., 2003, P 18 INT JOINT C ART, P1151.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   NVIDIA Cooperation, IS SDK.
   O'Kane JM, 2006, IEEE INT CONF ROBOT, P37, DOI 10.1109/ROBOT.2006.1641158.
   Ochieng Y., 2003, BRAZILIAN J CARTOGRA, V55.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Romero AR, 2018, IEEE INT CONF ROBOT, P2940, DOI 10.1109/ICRA.2018.8460707.
   Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721.
   Se S, 2005, IEEE T ROBOT, V21, P364, DOI 10.1109/TRO.2004.839228.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Widyawan, 2007, 4th IEEE International Symposium on Wireless Communication Systems 2007, P133.
   Yang JQ, 2016, INFORM SCIENCES, V346, P163, DOI 10.1016/j.ins.2016.01.095.
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319.},
Number-of-Cited-References = {37},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS3LB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000712319501101},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000441444700010,
Author = {Sun, Li and Yan, Zhi and Zaganidis, Anestis and Zhao, Cheng and Duckett,
   Tom},
Title = {Recurrent-OctoMap: Learning State-Based Map Refinement for Long-Term
   Semantic Mapping With 3-D-Lidar Data},
DOI = {10.1109/LRA.2018.2856268},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {3749-3756},
Month = {OCT},
Abstract = {This letter presents a novel semantic mapping approach,
   Recurrent-OctoMap, learned from long-term three-dimensional (3-D) Lidar
   data. Most existing semantic mapping approaches focus on improving
   semantic understanding of single frames, rather than 3-D refinement of
   semantic maps (i.e. fusing semantic observations). The most widely used
   approach for the 3-D semantic map refinement is ``Bayes update,{''}
   which fuses the consecutive predictive probabilities following a
   Markov-chain model. Instead, we propose a learning approach to fuse the
   semantic features, rather than simply fusing predictions from a
   classifier. In our approach, we represent and maintain our 3-D map as an
   OctoMap, and model each cell as a recurrent neural network, to obtain a
   Recurrent-OctoMap. In this case, the semantic mapping process can he
   formulated as a sequence-to-sequence encoding-decoding problem.
   Moreover, in order to extend the duration of observations in our
   Recurrent-OctoMap, we developed a robust 3-D localization and mapping
   system for successively mapping a dynamic environment using more than
   two weeks of data, and the system can he trained and deployed with
   arbitrary memory length. We validate our approach on the ETH long-term
   3-D Lidar dataset. The experimental results show that our proposed
   approach outperforms the conventional ``Bayes update{''} approach.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Sun, L (Corresponding Author), Univ Lincoln, L CAS, Lincoln LN6 7TS, England.
   Sun, Li; Zaganidis, Anestis; Zhao, Cheng; Duckett, Tom, Univ Lincoln, L CAS, Lincoln LN6 7TS, England.
   Yan, Zhi, UTBM, Lab Elect Informat \& Image, CNRS, F-90010 Belfort, France.},
DOI = {10.1109/LRA.2018.2856268},
ISSN = {2377-3766},
Keywords = {Mapping; simultaneous localization and mapping (SLAM); deep learning in
   robotics and automation; object detection; segmentation and
   categorization},
Keywords-Plus = {SEGMENTATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {lsun@lincoln.ac.uk
   zhi.yan@utbm.fr
   azaganidis@lincoln.ac.uk
   czhao@lincoln.ac.uk
   tduckett@lincoln.ac.uk},
Affiliations = {University of Lincoln; Centre National de la Recherche Scientifique
   (CNRS); Universite de Bourgogne; Universite de Technologie de
   Belfort-Montbeliard (UTBM)},
ResearcherID-Numbers = {Yan, Zhi/W-5265-2019
   },
ORCID-Numbers = {Yan, Zhi/0000-0001-8251-9786
   Sun, Li/0000-0002-0393-8665
   Zhao, Cheng/0000-0001-8502-3233},
Funding-Acknowledgement = {European Union {[}732737, 645376]},
Funding-Text = {This work was supported by the European Union's Horizon 2020 research
   and innovation programme under Grant 732737 (ILIAD) and 645376 (FLOBOT).},
Cited-References = {Bogoslavskyi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P163, DOI 10.1109/IROS.2016.7759050.
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691.
   Cho Kyunghyun, 2014, COMPUT SCI, DOI DOI 10.3115/V1/D14-1179.
   De Deuge M., 2013, P AUSTR C ROB AUT, V2, P1.
   Dewan A, 2016, IEEE INT CONF ROBOT, P4508, DOI 10.1109/ICRA.2016.7487649.
   Einhorn E, 2015, ROBOT AUTON SYST, V69, P28, DOI 10.1016/j.robot.2014.08.008.
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402\_1.
   Engelmann F, 2017, IEEE INT CONF COMP V, P716, DOI 10.1109/ICCVW.2017.90.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hermans A, 2014, IEEE INT CONF ROBOT, P2631, DOI 10.1109/ICRA.2014.6907236.
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI 10.1162/neco.1997.9.8.1735.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Kidono K, 2011, IEEE INT VEH SYM, P405, DOI 10.1109/IVS.2011.5940433.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955.
   Ma LN, 2017, IEEE INT C INT ROBOT, P598, DOI 10.1109/IROS.2017.8202213.
   Maturana Daniel, 2018, FIELD SERVICE ROBOTI, P335, DOI DOI 10.1007/978-3-319-67361-5.
   McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Navarro-Serment L. E., 2009, P C FIELD SERV ROB, P1516.
   Pomerleau F, 2014, IEEE INT CONF ROBOT, P3712, DOI 10.1109/ICRA.2014.6907397.
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16.
   Sebastian T., PROBABILISTIC ROBOTI.
   Sengupta S, 2013, IEEE INT CONF ROBOT, P580, DOI 10.1109/ICRA.2013.6630632.
   Sengupta S, 2012, IEEE INT C INT ROBOT, P857, DOI 10.1109/IROS.2012.6385958.
   Spinello L, 2011, IEEE INT CONF ROBOT, P1304, DOI 10.1109/ICRA.2011.5980085.
   Sun L, 2018, IEEE INT CONF ROBOT, P5942, DOI 10.1109/ICRA.2018.8461228.
   Sun L, 2016, IEEE INT CONF ROBOT, P2464, DOI 10.1109/ICRA.2016.7487399.
   Sun L, 2015, IEEE INT CONF ROBOT, P185, DOI 10.1109/ICRA.2015.7138998.
   Tateno K, 2016, IEEE INT CONF ROBOT, P2295, DOI 10.1109/ICRA.2016.7487378.
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887.
   Xiang Y., 2017, P ROB SCI SYST RSS.
   Xiong T, 2014, BIOMED CIRC SYST C, P9, DOI 10.1109/BioCAS.2014.6981632.
   Yan Z, 2017, IEEE INT C INT ROBOT, P864, DOI 10.1109/IROS.2017.8202247.
   Zaganidis A, 2018, IEEE ROBOT AUTOM LET, V3, P2942, DOI 10.1109/LRA.2018.2848308.
   Zhao C., ARXIV171000132.
   Zhao C, 2017, 2017 18TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P75, DOI 10.1109/ICAR.2017.8023499.},
Number-of-Cited-References = {37},
Times-Cited = {28},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {29},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GQ1ZW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000441444700010},
OA = {Green Accepted, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000329510300010,
Author = {Paul, Rohan and Newman, Paul},
Title = {Self-help: Seeking out perplexing images for ever improving topological
   mapping},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1742-1766},
Month = {DEC},
Abstract = {In this work, we present a novel approach that allows a robot to improve
   its own navigation performance through introspection and then targeted
   data retrieval. It is a step in the direction of life-long learning and
   adaptation and is motivated by the desire to build robots that have
   plastic competencies which are not baked in. They should react to and
   benefit from use. We consider a particular instantiation of this problem
   in the context of place recognition. Based on a topic-based
   probabilistic representation for images, we use a measure of perplexity
   to evaluate how well a working set of background images explain the
   robot's online view of the world. Offline, the robot then searches an
   external resource to seek out additional background images that bolster
   its ability to localize in its environment when used next. In this way
   the robot adapts and improves performance through use. We demonstrate
   this approach using data collected from a mobile robot operating in
   outdoor workspaces.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Paul, R (Corresponding Author), Univ Oxford, Dept Engn Sci, Robot Res Grp, Oxford OX1 3PJ, England.
   Paul, Rohan; Newman, Paul, Univ Oxford, Mobile Robot Res Grp, Oxford OX1 3PJ, England.},
DOI = {10.1177/0278364913509859},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Life-long learning; topological mapping; topic models; perplexity},
Keywords-Plus = {PROBABILISTIC LOCALIZATION; SURPRISING EVENTS; LOOP-CLOSURE; FAB-MAP;
   SLAM; NAVIGATION; MODEL},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {rohanp@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
Funding-Acknowledgement = {Rhodes Trust, Oxford, UK; EPSRC {[}EP/I005021/1]; Engineering and
   Physical Sciences Research Council {[}EP/I005021/1] Funding Source:
   researchfish},
Funding-Text = {This work was supported by the Rhodes Trust, Oxford, UK, and by the
   EPSRC (grant number EP/I005021/1) and an EPSRC Leadership Fellowship.},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Banerjee A, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P431.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114.
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993.
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9.
   Boyd-Graber J, 2010, ARXIV10024665.
   Chengxiang Zhai, 2001, SIGIR Forum, P334.
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI {[}10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800].
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2007, IEEE INT CONF ROBOT, P2042, DOI 10.1109/ROBOT.2007.363622.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Cussens J., 1993, Machine Learning: ECML-93. European Conference on Machine Learning Proceedings, P136.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Endres F, 2009, P ROB SCI SYST SEATT, P34.
   Fei-Fei L, 2005, PROC CVPR IEEE, P524.
   Girdhar Y, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P746, DOI 10.1109/IROS.2010.5650315.
   Girdhar Y, 2012, INT S EXP ROB QUEB C.
   Girdhar Y, 2010, IEEE INT CONF ROBOT, P5035, DOI 10.1109/ROBOT.2010.5509464.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101.
   Heinrich G, 2005, PARAMETER ESTIMATION.
   Hendel A, 2011, LECT NOTES COMPUT SC, V6494, P448, DOI 10.1007/978-3-642-19318-7\_35.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Hoffman M., 2010, ADV NEURAL INFORM PR, P856, DOI DOI 10.1073/PNAS.0307750100.
   Hoi S. C. H., 2006, P 23 INT C MACH LEAR, P417, DOI DOI 10.1145/1143844.1143897.
   Holub A, 2008, PROC CVPR IEEE, P885.
   Horster E., 2007, CIVR 07, P17.
   Hospedales T, 2011, IEEE T KNOWL DATA EN, P1.
   Itti L, 2005, PROC CVPR IEEE, P631.
   Joho D, 2012, P ROB SCI SYST RSS S.
   Joshi Ajay J., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2372, DOI 10.1109/CVPRW.2009.5206627.
   Kapoor A, 2010, INT J COMPUT VISION, V88, P169, DOI 10.1007/s11263-009-0268-3.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Lavrenko V, 2009, INFORM RETRIEVAL SER, V26, P1.
   Lawrence N. D., 2002, ADV NEURAL INF PROCE, P609.
   Levin A, 2004, PROC CVPR IEEE, P611.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   MacKay D. J. C., 1995, NAT LANG ENG, V1, P1.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Manning C.D., 2008, INTRO INFORM RETRIEV.
   Mei C, 2010, IEEE INT C INT ROBOT, P3738, DOI 10.1109/IROS.2010.5652266.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Murillo A C, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552.
   Paul R, 2011, 2011 IEEE INT C ROB, P445.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Philbin J, 2008, P BRIT MACH VIS C BM.
   Ranganathan Ananth, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P2017, DOI 10.1109/ROBOT.2009.5152376.
   Seeger M, 2003, 9 INT WORKSH AI STAT.
   SETTLES B, 2010, 1648 U WISC.
   Silpa - Anan C., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587638.
   Silpa-Anan C, 2004, P AUSTR C ROB AUT CA.
   Singh G, 2010, OMN ROB VIS WORKSH I.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950.
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302.
   Tellex S., 2012, P ROB SCI SYST SYDN.
   Valgren C., 2007, EUR C MOB ROB.
   Varadarajan Jagannadan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1338, DOI 10.1109/ICCVW.2009.5457456.
   Wallach MH, 2006, INT C MACHINE LEARNI, P977, DOI DOI 10.1145/1143844.1143967.
   Wang C, 2011, P 14 INT C ART INT S.
   Wang X., 2007, ADV NEURAL INFORM PR, P1577.
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87.
   Xiaoyong Liu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P186.
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178.
   Yi Zhang, 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P81.
   Zhu Jun, 2010, P 27 INT C MACH LEAR, P1239.},
Number-of-Cited-References = {70},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300010},
DA = {2022-05-17},
}

@inproceedings{ WOS:000365180000014,
Author = {Yokozuka, Masashi and Hashimoto, Naohisa and Tomita, Kohji and
   Matsumoto, Osamu},
Editor = {Giaffreda, R and Caganova, D and Li, Y and Riggio, R and Voisard, A},
Title = {Development of Autonomous Wheelchair for Indoor and Outdoor Traveling},
Booktitle = {INTERNET OF THINGS: IOT INFRASTRUCTURES, PT II},
Series = {Lecture Notes of the Institute for Computer Sciences Social Informatics
   and Telecommunications Engineering},
Year = {2015},
Volume = {151},
Pages = {91-96},
Note = {1st International Summit on Internet of Things (IoT), Rome, ITALY, OCT
   27-28, 2014},
Abstract = {In order to assist elderly people and disabled people, this paper
   describes development of autonomous wheelchair to travel in indoor and
   outdoor environments for providing traveling ability to any where. For
   this aim, the autonomous wheelchairs should have traveling-capability
   without choosing indoor and outdoor environments. Position detection is
   a key technology for autonomous driving since people decides a traveling
   direction from a current position and a destination. GPS is a
   fundamental technology for position detection. However GPS is not
   available in indoor cases, and GPS is not always available in outdoor
   cases when tall buildings occlude satellites. In these cases autonomous
   wheelchair has to detect a self-position by other sensor systems. In
   this study we have adopted a localization system utilizing 3D maps and a
   3D laser range finder. By the 3D localization system our wheelchair
   system can detect a self-position robustly if the wheelchair is
   surrounded by obstacles such as pedestrians. To avoid collision our
   wheelchair system uses short and long term planning. The short planning
   finds a safe motion-pattern from every conceivable pattern by the
   simulation on a map. The long term planning generates a feasible route
   to destination. If the route generated by the long-term planner collides
   to some obstacles our wheelchair avoids collision by the short term
   planning. By the localization system and the planning system our
   wheelchair could operate in public spaces.},
Publisher = {SPRINGER},
Address = {233 SPRING STREET, NEW YORK, NY 10013, UNITED STATES},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yokozuka, M (Corresponding Author), Natl Inst Adv Ind Sci \& Technol, 1-1-1 Umezono, Tsukuba, Ibaraki 3058568, Japan.
   Yokozuka, Masashi; Hashimoto, Naohisa; Tomita, Kohji; Matsumoto, Osamu, Natl Inst Adv Ind Sci \& Technol, Tsukuba, Ibaraki 3058568, Japan.},
DOI = {10.1007/978-3-319-19743-2\_14},
ISSN = {1867-8211},
ISBN = {978-3-319-19743-2; 978-3-319-19742-5},
Keywords = {Autonomous vehicle; Wheelchair; SLAM},
Research-Areas = {Computer Science; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Telecommunications},
Author-Email = {yokotsuka-masashi@aist.go.jp},
Affiliations = {National Institute of Advanced Industrial Science \& Technology (AIST)},
ResearcherID-Numbers = {Tomita, Kohji/M-6333-2016
   Hashimoto, Naohisa/K-3270-2012
   Matsumoto, Osamu/B-9311-2017},
ORCID-Numbers = {Tomita, Kohji/0000-0001-9796-0443
   Hashimoto, Naohisa/0000-0003-2236-8116
   },
Cited-References = {Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977.
   Yokozuka M., 2012, P IEEE RSJ INT C INT, P3838.
   Yokozuka M., 2012, ADV ROBOTICS, V26, P3838.
   Yokozuka M, 2010, J ROBOT MECHATRON, V22, P758, DOI 10.20965/jrm.2010.p0758.
   Yokozuka M, 2014, J ROBOT MECHATRON, V26, P236, DOI 10.20965/jrm.2014.p0236.},
Number-of-Cited-References = {5},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BD9SA},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000365180000014},
DA = {2022-05-17},
}

@inproceedings{ WOS:000380550000210,
Author = {Li, Jie and Eustice, Ryan M. and Johnson-Roberson, Matthew},
Book-Group-Author = {IEEE},
Title = {Underwater Robot Visual Place Recognition in the Presence of Dramatic
   Appearance Change},
DOI = {10.23919/OCEANS.2015.7404369},
Pages = {1-6},
Booktitle = {OCEANS 2015 - MTS/IEEE WASHINGTON},
Series = {OCEANS-IEEE},
Year = {2015},
Note = {OCEANS MTS/IEEE Conference, Washington, DC, OCT 19-22, 2015},
Abstract = {This paper reports on an algorithm for underwater visual place
   recognition in the presence of dramatic appearance change. Long-term
   visual place recognition is challenging underwater due to biofouling,
   corrosion, and other effects that lead to dramatic visual appearance
   change, which often causes traditional point-based feature methods to
   perform poorly. Building upon the authors' earlier work, this paper
   presents an algorithm for underwater vehicle place recognition and
   relocalization that enables an autonomous underwater vehicle (AUV) to
   relocalize itself to a previously-built simultaneous localization and
   mapping (SLAM) graph. High-level structural features are learned using a
   supervised learning framework that retains features that have a high
   potential to persist in the underwater environment. Combined with a
   particle filtering framework, these features are used to provide a
   probabilistic representation of localization confidence. The algorithm
   is evaluated on real data, from multiple years, collected by a Hovering
   Autonomous Underwater Vehicle (HAUV) for ship hull inspection.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Li, J (Corresponding Author), Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Li, Jie, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M.; Johnson-Roberson, Matthew, Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
ISSN = {0197-7385},
ISBN = {978-0-933957-43-5},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Electrical \& Electronic; Oceanography},
Author-Email = {ljlijie@umich.edu
   eustice@umich.edu
   mattjr@umich.edu},
Affiliations = {University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan},
Cited-References = {Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Li J, 2015, IEEE INT CONF ROBOT, P3652, DOI 10.1109/ICRA.2015.7139706.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   McManus C., 2014, P ROB SCI SYST C.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Ozog P, 2014, IEEE INT CONF ROBOT, P3832, DOI 10.1109/ICRA.2014.6907415.},
Number-of-Cited-References = {8},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BF3JW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380550000210},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370974900012,
Author = {Linegar, Chris and Churchill, Winston and Newman, Paul},
Book-Group-Author = {IEEE},
Title = {Work Smart, Not Hard: Recalling Relevant Experiences for Vast-Scale but
   Time-Constrained Localisation},
DOI = {10.1109/ICRA.2015.7138985},
Booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2015},
Pages = {90-97},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Seattle, WA, MAY 26-30, 2015},
Abstract = {This paper is about life-long vast-scale localisation in spite of
   changes in weather, lighting and scene structure. Building upon our
   previous work in Experience-based Navigation {[}1], we continually grow
   and curate a visual map of the world that explicitly supports multiple
   representations of the same place. We refer to these representations as
   experiences, where a single experience captures the appearance of an
   environment under certain conditions. Pedagogically, an experience can
   be thought of as a visual memory. By accumulating experiences we are
   able to handle cyclic appearance change (diurnal lighting, seasonal
   changes, and extreme weather conditions) and also adapt to slow
   structural change. This strategy, although elegant and effective, poses
   a new challenge: In a region with many stored representations - which
   one(s) should we try to localise against given finite computational
   resources?
   By learning from our previous use of the experience-map, we can make
   predictions about which memories we should consider next, conditioned on
   how the robot is currently localised in the experience-map. During
   localisation, we prioritise the loading of past experiences in order to
   minimise the expected computation required. We do this in a
   probabilistic way and show that this memory policy significantly
   improves localisation efficiency, enabling long-term autonomy on robots
   with limited computational resources. We demonstrate and evaluate our
   system over three challenging datasets, totalling 206km of outdoor
   travel. We demonstrate the system in a diverse range of lighting and
   weather conditions, scene clutter, camera occlusions, and permanent
   structural change in the environment.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Linegar, C (Corresponding Author), Univ Oxford, Mobile Robot Grp, Oxford, England.
   Linegar, Chris; Churchill, Winston; Newman, Paul, Univ Oxford, Mobile Robot Grp, Oxford, England.},
ISSN = {1050-4729},
ISBN = {978-1-4799-6923-4},
Keywords-Plus = {VISUAL ODOMETRY; NAVIGATION; SLAM},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {chrisl@robots.ox.ac.uk
   winston@robots.ox.ac.uk
   pnewman@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
Funding-Acknowledgement = {EPSRC {[}EP/J012017/1, EP/J013501/1] Funding Source: UKRI},
Cited-References = {Bishop C. M., 2006, PATTERN RECOGNITION, V1.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Konolige K., 2010, INT J ROBOTICS RES.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Maddern W, 2012, IEEE INT CONF ROBOT, P822, DOI 10.1109/ICRA.2012.6224622.
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184.
   McManus C., 2014, ROB AUT ICRA 2014 IE.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Murphy Kevin P., 2012, MACHINE LEARNING PRO.
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103.
   Scaramuzza D., 2011, IEEE ROBOTICS AUTOMA.
   Sibley G, 2010, IEEE INT CONF ROBOT, P285, DOI 10.1109/ROBOT.2010.5509527.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5.},
Number-of-Cited-References = {19},
Times-Cited = {38},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE3MR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370974900012},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391656500076,
Author = {Wang, Yue and Xiong, Rong and Huang, Shoudong and wu, Jun},
Editor = {Su, H and Wang, T and Tokhi, MO and Virk, GS},
Title = {MULTI-SESSION SLAM OVER LOW DYNAMIC WORKSPACE USING RGBD SENSOR},
DOI = {10.1142/9789814725248_0076},
Booktitle = {ASSISTIVE ROBOTICS},
Year = {2016},
Pages = {633-640},
Note = {18th Climbing and Walking Robots Conference (CLAWAR), Hangzhou, PEOPLES
   R CHINA, SEP 06-09, 2015},
Abstract = {Climbing robot, flying robot or human wearable devices usually execute
   daily tasks in a pre-defined workspace sharing with humans. Long-term
   operation for these robots posts three challenge: 3D pose estimation,
   cost limitation and unexpected low dynamics. To address these
   challenges, we propose a solution for performing multi-session SLAM
   using a RGBD sensor. The main model is a multi-session pose graph, which
   evolves over the multiple visits of the workspace. When the robot
   explores the new areas, its poses will be added to the graph. The poses
   in the graph will be pruned if their corresponding 3D point scans are
   out of date. Thus the scans corresponding to the poses kept in the
   current graph will always give a map of the latest environment. To
   detect the changes of the environment, an out-of-dated scans
   identification module is proposed. Pruning of the poses also decreases
   the computational burden in graph optimization. Experimental results
   using real world data acquired by a Kinect sensor show that the proposed
   framework is able to manage the map in date for low dynamic environments
   with a reduction in complexity and an acceptable error level compared to
   the method saving all poses.},
Publisher = {WORLD SCIENTIFIC PUBL CO PTE LTD},
Address = {PO BOX 128 FARRER RD, SINGAPORE 9128, SINGAPORE},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Xiong, R (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Zhejiang, Peoples R China.
   Wang, Yue; Xiong, Rong; wu, Jun, Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Zhejiang, Peoples R China.
   Huang, Shoudong, Univ Technol, Sch Elect Mech \& Mechatron Syst, Ctr Autonomous Syst, Sydney, NSW, Australia.},
ISBN = {978-981-4725-23-1},
Keywords = {SLAM; low dynamic environment; RGBD sensor},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {rxiong@iipc.zju.edu.cn},
Affiliations = {Zhejiang University; University of Technology Sydney},
ResearcherID-Numbers = {Huang, Shoudong/B-4255-2013
   },
ORCID-Numbers = {Huang, Shoudong/0000-0002-6124-4178},
Cited-References = {Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Huang G. P., 2009, EXPT ROBOTICS.
   Huang G. P., 2011, INT ROB SYST IEEE RS.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Saarinen J., 2012, INT ROB SYST IEEE RS.
   Sturm J., 2012, INT ROB SYST IEEE RS.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Walcott-Bryant A., 2012, INT ROB SYST IEEE RS.
   Wang Y, 2015, SPRINGER THESES-RECO, P1, DOI 10.1007/978-3-662-47175-3.
   Wang Y., 2013, INT J ROBOTICS AUTOM, V28.},
Number-of-Cited-References = {11},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BG7SL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391656500076},
DA = {2022-05-17},
}

@inproceedings{ WOS:000653645300024,
Author = {Yang Guihua and Liu Zhiyi and Tang Weiwei},
Book-Group-Author = {ACM},
Title = {Simultaneous Positioning And Map Construction of Mobile Robots Based on
   The Cartographer Algorithm},
Booktitle = {2019 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION PROCESSING
   (ICIIP 2019)},
Year = {2019},
Pages = {122-126},
Note = {4th International Conference on Intelligent Information Processing
   (ICIIP), Guilin, PEOPLES R CHINA, NOV 16-17, 2019},
Abstract = {At present, mobile robots have been more and more widely used, in order
   to enable mobile robots to achieve autonomous localization and mapping
   (SLAM), and to solve the problem of cumulative errors caused by
   long-term movement of robots; The current mainstream filtering method
   does not solve the accumulated error caused by the mileage meter. In
   order to correct the accumulated error caused by the mileage meter, this
   design uses Cartographer algorithm to build the map, and correct the
   accumulated error of mileage to achieve the accurate positioning of the
   robot. Taking ROS system as the operating platform, the experimental
   results show that the mobile robot corrects the accumulated error of
   mileage very well, and achieves more accurate positioning and better
   environmental map construction.},
Publisher = {ASSOC COMPUTING MACHINERY},
Address = {1515 BROADWAY, NEW YORK, NY 10036-9998 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Liu, ZY (Corresponding Author), Guangxi Zhuang Autonomous Reg Guilin Univ Technol, Coll Mech \& Control Engn, Guilin, Peoples R China.
   Yang Guihua; Liu Zhiyi; Tang Weiwei, Guangxi Zhuang Autonomous Reg Guilin Univ Technol, Coll Mech \& Control Engn, Guilin, Peoples R China.},
DOI = {10.1145/3378065.3378089},
ISBN = {978-1-4503-6191-0},
Keywords = {Cartographer Algorithms; Mapping; Independent Positioning},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods},
Author-Email = {954991219@qq.com
   2275376732@qq.com
   1421583518@qq.com},
Cited-References = {{[}Anonymous], 2018, SENSORS MICROSYSTEMS, V37, P50.
   {[}Anonymous], 2018, J HIGH TECHNOLOGY CO, V28, P48.
   chengding wu, 2008, CABLE TECHNOLOGY, V25, P20.
   D'alfonso L, 2013, INT C ADV ROB IEEE, P1.
   kiliang Ding, 2010, J LIAONING U ENG TEC, V29, P44.
   Ningshan Meng Qingqiang, 2007, J HEILONGJIANG U SCI, V17, P452.
   Turner R, 2012, NEUROCOMPUTING, V80, P47, DOI 10.1016/j.neucom.2011.07.029.
   {[}王耀南 WANG Yaonan], 2008, {[}控制理论与应用, Control Theory \& Applications], V25, P57.
   Xian jun, 2013, COMPUTER OPTICAL DIS, P129.
   Zhang qian, 2018, LASER J, V39.
   zhu kai, 2018, COMPUTER APPL RES, V35.
   Zunhe Hu, 2017, VISION LOCATION MAPP.},
Number-of-Cited-References = {12},
Times-Cited = {0},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {6},
Doc-Delivery-Number = {BR4XF},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000653645300024},
DA = {2022-05-17},
}

@article{ WOS:000430999700038,
Author = {Cao, Fengkui and Zhuang, Yan and Zhang, Hong and Wang, Wei},
Title = {Robust Place Recognition and Loop Closing in Laser-Based SLAM for UGVs
   in Urban Environments},
Journal = {IEEE SENSORS JOURNAL},
Year = {2018},
Volume = {18},
Number = {10},
Pages = {4242-4252},
Month = {MAY 15},
Abstract = {Robust place recognition plays a key role for the long-term autonomy of
   unmanned ground vehicles (UGVs) working in indoor or outdoor
   environments. Although most of the state-of-the-art that approaches for
   place recognition are vision-based, visual sensors lack adaptability in
   environments with poor or dynamically changing illumination. In this
   paper, a 3-D-laser-based place recognition algorithm is proposed to
   accomplish loop closure detection for simultaneous localization and
   mapping. An image model named bearing angle (BA) is adopted to convert
   3-D laser points to 2-D images, and then ORB features extracted from BA
   images are utilized to perform scene matching. Since the computational
   cost for matching a query BA image with all the BA images in a database
   is too high to meet the requirement of performing real-time place
   recognition, a visual bag of words approach is used to improve search
   efficiency. Furthermore, a speed normalization algorithm and a 3-D
   geometry-based verification algorithm are proposed to complete the
   proposed place recognition algorithm. Experiments were conducted on two
   self-developed UGV platforms to verify the performance of the proposed
   method.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhuang, Y (Corresponding Author), Dalian Univ Technol, Sch Control Sci \& Engn, Dalian 116024, Peoples R China.
   Cao, Fengkui; Zhuang, Yan, Dalian Univ Technol, Sch Control Sci \& Engn, Dalian 116024, Peoples R China.
   Zhang, Hong, Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2R3, Canada.
   Wang, Wei, Dalian Univ Technol, Res Ctr Informat \& Control, Dalian 116024, Peoples R China.},
DOI = {10.1109/JSEN.2018.2815956},
ISSN = {1530-437X},
EISSN = {1558-1748},
Keywords = {Laser scanning; place recognition; simultaneous localization and mapping
   (SLAM); unmanned ground vehicles (UGVs)},
Keywords-Plus = {CLOSURE DETECTION; NAVIGATION; SCENE; BAGS},
Research-Areas = {Engineering; Instruments \& Instrumentation; Physics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Instruments \& Instrumentation;
   Physics, Applied},
Author-Email = {cfkybfq@mail.dlut.edu.cn
   zhuang@dlut.edu.cn
   hzhang@ualberta.ca
   wangwei@dlut.edu.cn},
Affiliations = {Dalian University of Technology; University of Alberta; Dalian
   University of Technology},
ResearcherID-Numbers = {Cao, Fengkui/X-3624-2019},
ORCID-Numbers = {Cao, Fengkui/0000-0002-5869-7352},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61375088, U1608253]},
Funding-Text = {This work was supported by the National Natural Science Foundation of
   China under Grant 61375088 and Grant U1608253. The associate editor
   coordinating the review of this paper and approving it for publication
   was Dr. Rosario Morello. (Corresponding author: Yan Zhuang.)},
Cited-References = {Aliakbarpour H, 2017, IEEE SENS J, V17, P2640, DOI 10.1109/JSEN.2017.2679187.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arandjelovic R, 2016, PROC CVPR IEEE, P5297, DOI 10.1109/CVPR.2016.572.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2007, IEEE INT CONF ROBOT, P2042, DOI 10.1109/ROBOT.2007.363622.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   De Silva O, 2015, IEEE SENS J, V15, P1716, DOI 10.1109/JSEN.2014.2364684.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Granstrom K, 2009, IEEE INT CONF ROBOT, P1990.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Hou Y, 2018, AUTON ROBOT, V42, P1169, DOI 10.1007/s10514-017-9684-3.
   Korrapati H, 2017, AUTON ROBOT, V41, P967, DOI 10.1007/s10514-016-9560-6.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Magnusson M, 2009, IEEE INT CONF ROBOT, P3364.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muhammad N., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P333, DOI 10.1109/SSRR.2011.6106765.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Newman P, 2005, IEEE INT CONF ROBOT, P635.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280.
   Scaramuzza D, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4170, DOI 10.1109/iros.2007.4399276.
   Siam Sayem Mohammad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5702, DOI 10.1109/ICRA.2017.7989671.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Steder B, 2010, IEEE INT CONF ROBOT, P1400, DOI 10.1109/ROBOT.2010.5509401.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Zhao L, 2015, IEEE SENS J, V15, P1124, DOI 10.1109/JSEN.2014.2360916.
   Zhuang Y, 2013, IEEE T INSTRUM MEAS, V62, P438, DOI 10.1109/TIM.2012.2216475.},
Number-of-Cited-References = {31},
Times-Cited = {18},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {26},
Journal-ISO = {IEEE Sens. J.},
Doc-Delivery-Number = {GE1TM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000430999700038},
DA = {2022-05-17},
}

@article{ WOS:000666730300001,
Author = {Oh, Junghyun and Han, Changwan and Lee, Seunghwan},
Title = {Condition-Invariant Robot Localization Using Global Sequence Alignment
   of Deep Features},
Pages = {4103},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {12},
Month = {JUN},
Abstract = {Localization is one of the essential process in robotics, as it plays an
   important role in autonomous navigation, simultaneous localization, and
   mapping for mobile robots. As robots perform large-scale and long-term
   operations, identifying the same locations in a changing environment has
   become an important problem. In this paper, we describe a robust visual
   localization system under severe appearance changes. First, a robust
   feature extraction method based on a deep variational autoencoder is
   described to calculate the similarity between images. Then, a global
   sequence alignment is proposed to find the actual trajectory of the
   robot. To align sequences, local fragments are detected from the
   similarity matrix and connected using a rectangle chaining algorithm
   considering the robot's motion constraint. Since the chained fragments
   provide reliable clues to find the global path, false matches on
   featureless structures or partial failures during the alignment could be
   recovered and perform accurate robot localization in changing
   environments. The presented experimental results demonstrated the
   benefits of the proposed method, which outperformed existing algorithms
   in long-term conditions.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Lee, S (Corresponding Author), Kumoh Natl Inst Technol, Dept Elect Engn, Gumi 39177, Gyeongbuk, South Korea.
   Oh, Junghyun; Han, Changwan, Kwangwoon Univ, Dept Robot, Seoul 01897, South Korea.
   Lee, Seunghwan, Kumoh Natl Inst Technol, Dept Elect Engn, Gumi 39177, Gyeongbuk, South Korea.},
DOI = {10.3390/s21124103},
Article-Number = {4103},
EISSN = {1424-8220},
Keywords = {robotics; localization; sequence alignment; place recognition; deep
   learning},
Keywords-Plus = {LOOP-CLOSURE DETECTION; PLACE RECOGNITION; FAB-MAP; SLAM; SCALE},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {jhyunoh@kw.ac.kr
   hcw511@naver.com
   leesh@kumoh.ac.kr},
Affiliations = {Kwangwoon University; Kumoh National University Technology},
ORCID-Numbers = {Han, ChangWan/0000-0002-1025-2055
   Oh, Junghyun/0000-0003-0502-7600},
Funding-Acknowledgement = {National Research Foundation of Korea(NRF) grant - Korea
   government(MSIT) {[}2020R1F1A1076667]; Korea Institute of Energy
   Technology Evaluation and Planning (KETEP); Ministry of Trade, Industry
   \& Energy (MOTIE) of the Republic of Korea {[}20174010201620]; Kwangwoon
   University},
Funding-Text = {This work has supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIT)(No.
   2020R1F1A1076667), Korea Institute of Energy Technology Evaluation and
   Planning (KETEP) and the Ministry of Trade, Industry \& Energy (MOTIE)
   of the Republic of Korea (No. 20174010201620). Also, this work was
   supported by Research Resettlement Fund for the new faculty of Kwangwoon
   University in 2019.},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arandjelovic R., 2016, IEEE T PATTERN ANAL, P5297, DOI DOI 10.1109/TPAMI.2017.2711011.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Brudno M, 2003, BIOINFORMATICS, V19, pi54, DOI 10.1093/bioinformatics/btg1005.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Chancan M., ARXIV201108518.
   Chen Z., P IEEE INT C ROB AUT, P3223.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Gadd Matthew, 2020, 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), P270, DOI 10.1109/PLANS46316.2020.9109951.
   Garg S, 2021, IEEE ROBOT AUTOM LET, V6, P4305, DOI 10.1109/LRA.2021.3067633.
   Garg S, 2018, IEEE INT CONF ROBOT, P3645, DOI 10.1109/ICRA.2018.8461051.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Kingma D.P., 2013, ARXIV.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Latif Y, 2018, IEEE INT CONF ROBOT, P2349, DOI 10.1109/ICRA.2018.8461081.
   Liu Y, 2012, IEEE INT C INT ROBOT, P1051, DOI 10.1109/IROS.2012.6386145.
   Lopez E, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040802.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S.M., 2014, THESIS QUEENSLAND U.
   Lowry S, 2016, IEEE T ROBOT, V32, P600, DOI 10.1109/TRO.2016.2545711.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Mao J, 2019, IEEE ACCESS, V7, P5723, DOI 10.1109/ACCESS.2018.2889030.
   Marchel L, 2020, J NAVIGATION, V73, P282, DOI 10.1017/S0373463319000584.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Murillo A., 2009, P PRESENTED IEEE INT.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Neubert P, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P198, DOI 10.1109/ECMR.2013.6698842.
   Oh JH, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.0037.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424.
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N., 2013, P WORKSHOP LONG TERM.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Szegedy C., P IEEE INT C COMPUTE, P1.
   Yuan X, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051174.
   Zeng ZQ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112257.},
Number-of-Cited-References = {43},
Times-Cited = {1},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {SZ7HA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000666730300001},
OA = {gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000380550000269,
Author = {Bichucher, Vittorio and Walls, Jeffrey M. and Ozog, Paul and Skinner,
   Katherine A. and Eustice, Ryan M.},
Book-Group-Author = {IEEE},
Title = {Bathymetric Factor Graph SLAM with Sparse Point Cloud Alignment},
Pages = {1-7},
DOI = {10.23919/OCEANS.2015.7404433},
Booktitle = {OCEANS 2015 - MTS/IEEE WASHINGTON},
Series = {OCEANS-IEEE},
Year = {2015},
Note = {OCEANS MTS/IEEE Conference, Washington, DC, OCT 19-22, 2015},
Abstract = {This paper reports on a factor graph simultaneous localization and
   mapping framework for autonomous underwater vehicle localization based
   on terrain-aided navigation. The method requires no prior bathymetric
   map and only assumes that the autonomous underwater vehicle has the
   ability to sparsely sense the local water column depth, such as with a
   bottom-looking Doppler velocity log. Since dead-reckoned navigation is
   accurate in short time windows, the vehicle accumulates several water
   column depth point clouds-or submaps-during the course of its survey. We
   propose an xy-alignment procedure between these submaps in order to
   enforce consistent bathymetric structure over time, and therefore
   attempt to bound long-term navigation drift. We evaluate the submap
   alignment method in simulation and present performance results from
   multiple autonomous underwater vehicle field trials.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bichucher, V (Corresponding Author), Univ Michigan, Ann Arbor, MI 48109 USA.
   Bichucher, Vittorio; Walls, Jeffrey M.; Ozog, Paul; Skinner, Katherine A.; Eustice, Ryan M., Univ Michigan, Ann Arbor, MI 48109 USA.},
ISSN = {0197-7385},
ISBN = {978-0-933957-43-5},
Keywords-Plus = {TERRAIN NAVIGATION; UNDERWATER; LOCALIZATION},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Electrical \& Electronic; Oceanography},
Author-Email = {vittbich@umich.edu
   jmwalls@umich.edu
   paulozog@umich.edu
   kskin@umich.edu
   eustice@umich.edu},
Affiliations = {University of Michigan System; University of Michigan},
Cited-References = {Agarwal P, 2013, P IEEE INT C ROB AUT.
   Barkby S, 2011, IEEE INT C INT ROBOT, P1242, DOI 10.1109/IROS.2011.6048284.
   Bergman N, 1999, IEEE CONTR SYST MAG, V19, P33, DOI 10.1109/37.768538.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Brown HC, 2009, MAR TECHNOL SOC J, V43, P33, DOI 10.4031/MTSJ.43.2.4.
   CHEN Y, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2724, DOI 10.1109/ROBOT.1991.132043.
   Claus B., 2015, J FIELD ROBOT.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   DiMassa DE, 1997, OCEANS `97 MTS/IEEE CONFERENCE PROCEEDINGS, VOLS 1 AND 2, P541, DOI 10.1109/OCEANS.1997.634423.
   Eustice R., 2005, P IEEE MTS OCEANS C.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Eustice RM, 2006, INT J ROBOT RES, V25, P1223, DOI 10.1177/0278364906072512.
   Eustice RM, 2011, J FIELD ROBOT, V28, P121, DOI 10.1002/rob.20365.
   Fallon MF, 2011, IEEE INT CONF ROBOT, P2398, DOI 10.1109/ICRA.2011.5980302.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Karlsson R, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P65.
   Kim A, 2015, INT J ROBOT RES, V34, P457, DOI 10.1177/0278364914547893.
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Kimball P, 2008, IEEE AUTO UNDER VEH, P20.
   Kimball PW, 2015, IEEE J OCEANIC ENG, V40, P196, DOI 10.1109/JOE.2014.2300396.
   Kinsey J. C., 2006, IFAC C MAN CONT MAR.
   Kullander L., 1989, Proceedings of the 6th International Symposium on Unmanned Untethered Submersible Technology (IEEE Cat. No.89CH2782-1), P494, DOI 10.1109/UUST.1989.754741.
   Nygren I, 2004, IEEE J OCEANIC ENG, V29, P906, DOI 10.1109/JOE.2004.833222.
   Ozog P., 2015, J FIELD ROB IN PRESS.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Roman C, 2007, J FIELD ROBOT, V24, P23, DOI 10.1002/rob.20164.
   Segal A., 2009, P ROB SCI SYST C JUN.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   VanMiddlesworth M, 2015, SPRINGER TRAC ADV RO, V105, P17, DOI 10.1007/978-3-319-07488-7\_2.
   Whitcomb L., 1999, P 11 INT S UNM UNT S, P1.
   Williams S, 2006, SPRINGER TRAC ADV RO, V24, P93.},
Number-of-Cited-References = {31},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BF3JW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380550000269},
DA = {2022-05-17},
}

@article{ WOS:000390027900022,
Author = {Chudoba, Jan and Kulich, Miroslav and Saska, Martin and Baca, Tomas and
   Preucil, Libor},
Title = {Exploration and Mapping Technique Suited for Visual-features Based
   Localization of MAVs},
Journal = {JOURNAL OF INTELLIGENT \& ROBOTIC SYSTEMS},
Year = {2016},
Volume = {84},
Number = {1-4, SI},
Pages = {351-369},
Month = {DEC},
Abstract = {An approach for long term localization, stabilization, and navigation of
   micro-aerial vehicles (MAVs) in unknown environment is presented in this
   paper. The proposed method relies strictly on onboard sensors of
   employed MAVs and does not require any external positioning system. The
   core of the method consists in extraction of information from pictures
   consequently captured using a camera carried by the particular MAV.
   Visual features are obtained from images of the surface under the MAV,
   and stored into a map that is represented by these features. The
   position of the MAV is then obtained through matching with previously
   stored features. An important part of the proposed system is a novel
   approach for exploration and mapping of the workspace of robots. This
   method enables efficient exploring of the unknown environment, while
   keeping the iteratively built map of features consistent. The proposed
   algorithm is suitable for mapping of surfaces, both outdoor and indoor,
   with various density of the image features. The sufficient precision and
   long term persistence of the method allows its utilization for
   stabilization of large MAV groups that work in formations with small
   relative distances between particular vehicles. Numerous experiments
   with quadrotor helicopters and various numerical simulations have been
   realized for verification of the entire system and its components.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Saska, M (Corresponding Author), Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Prague, Czech Republic.
   Saska, Martin; Baca, Tomas, Czech Tech Univ, Dept Cybernet, Fac Elect Engn, Prague, Czech Republic.
   Chudoba, Jan; Kulich, Miroslav; Preucil, Libor, Czech Tech Univ, Czech Inst Informat Robot \& Cybernet, Prague, Czech Republic.},
DOI = {10.1007/s10846-016-0358-8},
ISSN = {0921-0296},
EISSN = {1573-0409},
Keywords = {MAVs; Visual-features; MAV localization; MAV stabilization; Exploration;
   Mapping},
Keywords-Plus = {NAVIGATION; SLAM},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {chudoba@labe.felk.cvut.cz
   kulich@labe.felk.cvut.cz
   saskam1@fel.cvut.cz
   bacatoma@fel.cvut.cz
   preucil@labe.felk.cvut.cz},
Affiliations = {Czech Technical University Prague; Czech Technical University Prague},
ResearcherID-Numbers = {Saska, Martin/L-3669-2013
   Preucil, Libor/G-9530-2014
   Báča, Tomáš/W-2903-2018
   Kulich, Miroslav/L-3465-2013},
ORCID-Numbers = {Báča, Tomáš/0000-0001-9649-8277
   Kulich, Miroslav/0000-0002-0997-5889},
Cited-References = {Amidi O., 1996, THESIS.
   Amigoni F, 2010, ROBOT AUTON SYST, V58, P684, DOI 10.1016/j.robot.2009.11.005.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Caballero F, 2009, J INTELL ROBOT SYST, V54, P137, DOI 10.1007/s10846-008-9257-y.
   Caron F, 2006, INFORM FUSION, V7, P221, DOI 10.1016/j.inffus.2004.07.002.
   Carrillo LRG, 2012, J INTELL ROBOT SYST, V65, P373, DOI 10.1007/s10846-011-9571-7.
   Conte G., 2008, INTEGRATED UAV NAVIG.
   Conte G, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/387308.
   Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390.
   Fowers SG, 2008, STABILIZATION CONTRO.
   Gonzalez-Banos HH, 2002, INT J ROBOT RES, V21, P829, DOI 10.1177/0278364902021010834.
   Grabe V, 2012, IEEE INT C INT ROBOT, P2153, DOI 10.1109/IROS.2012.6386234.
   Guizilini V, 2011, IEEE INT CONF ROBOT.
   Holz D., 2010, EVALUATING EFFICIENC.
   Honegger D, 2013, IEEE INT CONF ROBOT, P1736, DOI 10.1109/ICRA.2013.6630805.
   Kelly J, 2008, SPRINGER TRAC ADV RO, V42, P255.
   Koenig S, 2001, IEEE INT CONF ROBOT, P3594, DOI 10.1109/ROBOT.2001.933175.
   Krajn T., 2012, INT MULT SYST SIGN D, P34.
   Krajn ` ik T., 2013, P INT C ADV ROB IEEE.
   Krajn ` ik T., 2013, J INTELL ROBOT SYST.
   Lemaire T, 2007, INT J COMPUT VISION, V74, P343, DOI 10.1007/s11263-007-0042-3.
   Makarenko AA, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P534, DOI 10.1109/IRDS.2002.1041445.
   Newman P., 2003, IEEE INT C ROB AUT.
   Ronnback S, 2000, THESIS.
   Stachniss C., 2005, P ROB SCI SYST CAMBR.
   Tovey C, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3251.
   Wang CL, 2013, INT J AUTOM COMPUT, V10, P387, DOI 10.1007/s11633-013-0735-8.
   Wendel J, 2006, AEROSP SCI TECHNOL, V10, P527, DOI 10.1016/j.ast.2006.04.002.
   Yamauchi B, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA `97, PROCEEDINGS, P146, DOI 10.1109/CIRA.1997.613851.
   Zingg S, 2010, IEEE INT CONF ROBOT, P3361, DOI 10.1109/ROBOT.2010.5509777.
   {[}No title captured].},
Number-of-Cited-References = {32},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {10},
Journal-ISO = {J. Intell. Robot. Syst.},
Doc-Delivery-Number = {EF0PJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000390027900022},
DA = {2022-05-17},
}

@inproceedings{ WOS:000371885405129,
Author = {Limosani, R. and Morales, L. Yoichi and Even, J. and Ferreri, F. and
   Watanabe, A. and Cavallo, F. and Dario, P. and Hagita, N.},
Book-Group-Author = {IEEE},
Title = {Long-Term Human Affordance Maps},
DOI = {10.1109/IROS.2015.7354193},
Booktitle = {2015 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2015},
Pages = {5748-5754},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Hamburg, GERMANY, SEP 28-OCT 02, 2015},
Abstract = {This paper presents a work on mapping the use of space by humans in long
   periods of time. Daily geometric maps with the same coordinate frame
   were generated with SLAM, and in a similar manner, daily affordance
   density maps (places people use) were generated with the output of a
   human tracker running on the robot. The contribution of the paper is
   two-fold: an approach to detect geometric changes to cluster them in
   similar geometric configurations and the building of geometric and
   affordance composite maps on each cluster. This approach avoids the loss
   of long term retrieved information. Geometric similarity was computed
   using a normal distance approach on the maps. The analysis was performed
   on data collected by a mobile robot for a period of 4 months
   accumulating data equivalent to 7 0 days. Experimental results show that
   the system is capable of detecting geometric changes in the environment
   and clustering similar geometric configurations.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Limosani, R (Corresponding Author), Scuola Super Sant Anna, BioRobot Inst, Rome, Italy.
   Limosani, R., Scuola Super Sant Anna, BioRobot Inst, Rome, Italy.
   Morales, L. Yoichi, Adv Telecommun Res Inst Int, Intelligent Robot \& Commun Labs, Kyoto, Japan.},
ISSN = {2153-0858},
ISBN = {978-1-4799-9994-1},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {r.limosani@sssup.it
   yoichims@atr.jp},
Affiliations = {Scuola Superiore Sant'Anna; Advanced Telecommunications Research
   Institute International},
ResearcherID-Numbers = {Cavallo, Filippo/J-8246-2015},
ORCID-Numbers = {Cavallo, Filippo/0000-0001-7432-5033},
Cited-References = {Anguelov D., 2002, P 18 C UNC ART INT, P10.
   Bacca B, 2013, ROBOT AUTON SYST, V61, P1539, DOI 10.1016/j.robot.2013.07.003.
   BURGARD W, 1998, P 15 NAT C ART INT A.
   Carlevaris-Bianco N, 2013, IEEE INT C INT ROBOT, P1034, DOI 10.1109/IROS.2013.6696478.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   HAHNEL D, 2003, P IEEE INT C ROB AUT.
   Hall E., 1990, DOUBLEDAY ANCHOR BOO.
   Kiimmerle R., 2014, J FIELD ROBOTICS.
   Lu D., 2013, IROS.
   Luber M, 2012, IEEE INT C INT ROBOT, P902, DOI 10.1109/IROS.2012.6385716.
   Marder-Eppstein E., 2010, INT C ROB AUT 05 201.
   Meeussen W, 2011, ICRA 2011 WORKSH LON.
   Meyer-Delius D., 2012, AAAI.
   Morales Y, 2009, J FIELD ROBOT, V26, P609, DOI 10.1002/rob.20301.
   Norman D.A., 2002, DESIGN EVERYDAY THIN.
   Pacchierotti E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4965, DOI 10.1109/IROS.2006.282519.
   Pomerleau F, 2014, IEEE INT CONF ROBOT, P3712, DOI 10.1109/ICRA.2014.6907397.
   Sisbot E. A., 2005, IEEE RAS INT C HUM R.
   Stachniss C, 2008, 2008 INT C COGN SYST, P85.
   Tipaldi G. D., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P1968, DOI 10.1109/IROS.2011.6048551.
   Tipaldi GD, 2011, IEEE INT CONF ROBOT, P1217.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   WANG CC, 2002, P IEEE INT C ROB AUT.
   WANG CC, 2003, P IEEE INT C ROB AUT.
   {[}No title captured].},
Number-of-Cited-References = {26},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BE4LI},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000371885405129},
OA = {Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370974906040,
Author = {Arroyo, Roberto and Alcantarilla, Pablo F. and Bergasa, Luis M. and
   Romera, Eduardo},
Book-Group-Author = {IEEE},
Title = {Towards Life-Long Visual Localization using an Efficient Matching of
   Binary Sequences from Images},
DOI = {10.1109/ICRA.2015.7140088},
Booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2015},
Pages = {6328-6335},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Seattle, WA, MAY 26-30, 2015},
Abstract = {Life-long visual localization is one of the most challenging topics in
   robotics over the last few years. The difficulty of this task is in the
   strong appearance changes that a place suffers due to dynamic elements,
   illumination, weather or seasons. In this paper, we propose a novel
   method (ABLE-M) to cope with the main problems of carrying out a robust
   visual topological localization along time. The novelty of our approach
   resides in the description of sequences of monocular images as binary
   codes, which are extracted from a global LDB descriptor and efficiently
   matched using FLANN for fast nearest neighbor search. Besides, an
   illumination invariant technique is applied. The usage of the proposed
   binary description and matching method provides a reduction of memory
   and computational costs, which is necessary for long-term performance.
   Our proposal is evaluated in different life-long navigation scenarios,
   where ABLE-M outperforms some of the main state-of-the-art algorithms,
   such as WI-SURF, BRIEF-Gist, FAB-MAP or SeqSLAM. Tests are presented for
   four public datasets where a same route is traversed at different times
   of day or night, along the months or across all four seasons.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Arroyo, R (Corresponding Author), Univ Alcala UAH, Dept Elect, Madrid 28871, Spain.
   Arroyo, Roberto; Bergasa, Luis M.; Romera, Eduardo, Univ Alcala UAH, Dept Elect, Madrid 28871, Spain.
   Alcantarilla, Pablo F., Toshiba Res Europe Ltd, Comp Vis Grp, Cambridge CB4 0GZ, England.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-6923-4},
Keywords-Plus = {LOOP CLOSURE DETECTION; NAVIGATION; MAP},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {roberto.arroyo@depeca.uah.es
   pablo.alcantarilla@crl.toshiba.co.uk
   bergasa@depeca.uah.es
   eduardo.romera@depeca.uah.es},
Affiliations = {Universidad de Alcala; Toshiba Corporation},
ResearcherID-Numbers = {Bergasa, Luis M./H-9810-2013},
ORCID-Numbers = {Bergasa, Luis M./0000-0002-0087-3077},
Cited-References = {Arroyo R, 2014, IEEE INT C INT ROBOT, P3089, DOI 10.1109/IROS.2014.6942989.
   Arroyo R, 2014, IEEE INT VEH SYM, P1378, DOI 10.1109/IVS.2014.6856457.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Bansal A, 2014, IEEE INT VEH SYM, P800, DOI 10.1109/IVS.2014.6856605.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Bradski G, 2000, DR DOBBS J, V25, P120.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M., 2009, ROB SCI SYST C RSS J.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Johns E, 2013, IEEE INT CONF ROBOT, P2731, DOI 10.1109/ICRA.2013.6630953.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Lee GH, 2014, IEEE INT CONF ROBOT, P1510, DOI 10.1109/ICRA.2014.6907052.
   Liu Y, 2012, IEEE INT C INT ROBOT, P1051, DOI 10.1109/IROS.2012.6386145.
   Lv Q, 2007, VLDB, DOI DOI 10.1145/1143844.1143857.
   Maddern W, 2014, IEEE INT VEH SYM, P330, DOI 10.1109/IVS.2014.6856471.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   Milford M., 2012, ROB SCI SYST C RSS J.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376.
   Neubert P, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P198, DOI 10.1109/ECMR.2013.6698842.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N., 2013, WORKSH LONG TERM AUT.
   Valgren C, 2008, IEEE INT CONF ROBOT, P1856, DOI 10.1109/ROBOT.2008.4543477.
   Wu JJ, 2014, IEEE INT CONF ROBOT, P861.
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150.},
Number-of-Cited-References = {29},
Times-Cited = {60},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE3MR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370974906040},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000458872703031,
Author = {Egger, Philipp and Borges, Paulo V. K. and Catt, Gavin and Pfrunder,
   Andreas and Siegwart, Roland and Dube, Renaud},
Editor = {Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L},
Book-Author = {Kosecka, J},
Title = {PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization},
DOI = {10.1109/IROS.2018.8593854},
Booktitle = {2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2018},
Pages = {3430-3437},
Note = {25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Madrid, SPAIN, OCT 01-05, 2018},
Abstract = {Reliable long-term localization is key for robotic systems in dynamic
   environments. In this paper, we propose a novel approach for long-term
   localization using 3D LiDARs, coined PoseMap. In essence, we extract
   distinctive features from range measurements and bundle these into local
   views along with observation poses. The sensor's trajectory is then
   estimated in a sliding window fashion by matching current and old
   features and minimizing the distances in-between. The map representation
   facilitates finding a suitable set of old features, by selecting the
   closest local map(s) for matching. Similarly to a visibility analysis,
   this procedure provides a suitable set of features for localization but
   at a fraction of the computational cost. PoseMap also allows for updates
   and extensions of the map at any time by replacing and adding local maps
   when necessary. We evaluate our approach using two platforms both
   equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz
   and robustness to changes in the environment such as moving vehicles and
   changing vegetation. PoseMap was implemented on an autonomous vehicle
   allowing it to drive autonomously over a period of 18 months through a
   mix of industrial and unstructured off-road environments, covering more
   than 100 kms without a single localization failure.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Egger, P (Corresponding Author), CSIRO, Data61, Robot \& Autonomous Syst Grp, Canberra, ACT, Australia.
   Egger, P (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Egger, Philipp; Borges, Paulo V. K.; Catt, Gavin, CSIRO, Data61, Robot \& Autonomous Syst Grp, Canberra, ACT, Australia.
   Egger, Philipp; Pfrunder, Andreas; Siegwart, Roland; Dube, Renaud, Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.},
ISSN = {2153-0858},
ISBN = {978-1-5386-8094-0},
Keywords-Plus = {MAPS},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {philipp-egger@outlook.com
   paulo.borges@csiro.au
   gavin.catt@csiro.au
   andrepfr@ethz.ch
   rdube@ethz.ch},
Affiliations = {Commonwealth Scientific \& Industrial Research Organisation (CSIRO); ETH
   Zurich},
Cited-References = {Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Bosse M., 2009, 2009 IEEE INT C ROBO, P4312, DOI {[}10.1109/ROBOT.2009.5152851, DOI 10.1109/ROBOT.2009.5152851].
   Bosse M., 2013, IEEE INT C ROB AUT I.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Bosse M, 2012, IEEE T ROBOT, V28, P1104, DOI 10.1109/TRO.2012.2200990.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Dube R., 2017, IEEE RSJ INT C INT R.
   Dube R, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Maddern W, 2015, IEEE INT CONF ROBOT, P1684, DOI 10.1109/ICRA.2015.7139414.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   Meyer-Delius D., 2012, AAAI.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Pfrunder A, 2017, IEEE INT C INT ROBOT, P2601, DOI 10.1109/IROS.2017.8206083.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Zhang J., 2014, ROBOTICS SCI SYSTEMS, V2.},
Number-of-Cited-References = {21},
Times-Cited = {23},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BM0LT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000458872703031},
DA = {2022-05-17},
}

@article{ WOS:000457667300008,
Author = {Boniardi, Federico and Caselitz, Tim and Kuemmerle, Rainer and Burgard,
   Wolfram},
Title = {A pose graph-based localization system for long-term navigation in CAD
   floor plans},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2019},
Volume = {112},
Pages = {84-97},
Month = {FEB},
Abstract = {Accurate localization is an essential technology for flexible
   automation. Industrial applications require mobile platforms to be
   precisely localized in complex environments, often subject to continuous
   changes and reconfiguration. Most of the approaches use precomputed maps
   both for localization and for interfacing robots with workers and
   operators. This results in increased deployment time and costs as
   mapping experts are required to setup the robotic systems in factory
   facilities. Moreover, such maps need to be updated whenever significant
   changes in the environment occur in order to be usable within commanding
   tools. To overcome those limitations, in this work we present a robust
   and highly accurate method for long-term LiDAR-based indoor localization
   that uses CAD-based architectural floor plans. The system leverages a
   combination of graph-based mapping techniques and Bayes filtering to
   maintain a sparse and up-to-date globally consistent map that represents
   the latest configuration of the environment. This map is aligned to the
   CAD drawing using prior constraints and is exploited for relative
   localization, thus allowing the robot to estimate its current pose with
   respect to the global reference frame of the floor plan. Furthermore,
   the map helps in limiting the disturbances caused by structures and
   clutter not represented in the drawing. Several long-term experiments in
   changing real-world environments show that our system outperforms common
   state-of-the-art localization methods in terms of accuracy and
   robustness while remaining memory and computationally efficient. (C)
   2018 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Boniardi, F (Corresponding Author), Univ Freiburg, Georges Kohler Allee 80, D-79110 Freiburg, Germany.
   Boniardi, Federico; Caselitz, Tim; Burgard, Wolfram, Univ Freiburg, Georges Kohler Allee 80, D-79110 Freiburg, Germany.
   Kuemmerle, Rainer, KUKA, Zugspitzstr 140, D-86165 Augsburg, Germany.},
DOI = {10.1016/j.robot.2018.11.003},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Mobile robotics; Localization; Mapping; SLAM; Adaptive systems},
Keywords-Plus = {ROBOT; TRACKING},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {boniardi@informatik.uni-freiburg.de
   caselitz@informatik.uni-freiburg.de
   rainer.kuemmerle@kuka.com
   burgard@informatik.uni-freiburg.de},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
ORCID-Numbers = {Burgard, Wolfram/0000-0002-5680-6500},
Cited-References = {Agarwal P, 2013, P IEEE INT C ROB AUT.
   Biber P., 2005, P ROB SCI SYST.
   Boniardi F., 2017, P IEEE RSJ INT C INT.
   Bowen-Biggs L, 2016, P INT C SOC ROB ICSR.
   Burgard W., 1996, P NAT C ART INT.
   Carlevaris-Bianco N., 2013, P IEEE INT C ROB AUT.
   Censi A., 2007, P IEEE INT C ROB AUT.
   Censi A., 2008, P IEEE INT C ROB AUT.
   Donnelly William, 2005, GPU GEMS, V2, P3.
   ELFES A, 1987, IEEE T ROBOTIC AUTOM, V3, P249, DOI 10.1109/JRA.1987.1087096.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Fox D, 2001, STAT ENG IN, P401.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hart JC, 1996, VISUAL COMPUT, V12, P527, DOI 10.1007/s003710050084.
   Hile H., 2008, IEEE COMPUT GRAPHICS, V28.
   HOPCROFT J, 1973, COMMUN ACM, V16, P372, DOI 10.1145/362248.362272.
   Huang G., 2013, P IEEE EUR C MOB ROB.
   International Organization for Standardization (ISO), 2015, 1189812015EN ISO, P1.
   Ito S, 2014, INT CONF ACOUST SPEE.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kummerle R, 2015, J FIELD ROBOT, V32, P565, DOI 10.1002/rob.21534.
   Kummerle R, 2011, AUTON ROBOT, V30, P25, DOI 10.1007/s10514-010-9204-1.
   Kummerle R., 2011, P IEEE INT C ROB AUT.
   LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Lu F, 1997, J INTELL ROBOT SYST, V18, P249, DOI 10.1023/A:1007957421070.
   Luo R. C., 2010, P IEEE C MULT FUS IN.
   Mazuran M, 2018, SPR PROC ADV ROBOT, V3, P435, DOI 10.1007/978-3-319-60916-4\_25.
   Mazuran M, 2016, INT J ROBOT RES, V35, P50, DOI 10.1177/0278364915581629.
   Mendez O., ARXIV170901500.
   Meyer-Delius D., 2010, P IEEE RSJ INT C INT.
   Meyer-Delius D., 2012, P AAAI C ART INT.
   Olson E., 2008, THESIS.
   Rosen D., 2016, P IEEE INT C ROB AUT.
   Rowekamper J, 2012, P IEEE RSJ INT C INT.
   Scharr H, 2000, THESIS.
   Schiotka A., 2017, P IEEE RSJ INT C INT.
   Segal A., 2009, P ROB SCI SYST.
   Siddiqi S., 2003, P INT C ADV ROB ICAR.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Sprunk C., 2013, P IEEE RSJ INT C INT.
   Sunderhauf N., 2012, P IEEE RSJ INT C INT.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   VANDEVEN J, 2010, P IEEE INT C ROB AUT.
   Vysotska O., 2016, P IEEE RSJ INT C INT.
   Walcott A. N., 2011, THESIS.
   Walcott-Bryant A, 2012, P IEEE RSJ INT C INT.
   Wang DZ, 2015, INT J ROBOT RES, V34, P1039, DOI 10.1177/0278364914562237.
   Winterhalter W., 2015, P IEEE RSJ INT C INT.
   Yilmaz S., 2011, P INT C EL EL ENG EL.},
Number-of-Cited-References = {52},
Times-Cited = {16},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {23},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {HK1LV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000457667300008},
DA = {2022-05-17},
}

@article{ WOS:000442595800006,
Author = {Pire, Taihu and Baravalle, Rodrigo and D'Alessandro, Ariel and Civera,
   Javier},
Title = {Real-time dense map fusion for stereo SLAM},
Journal = {ROBOTICA},
Year = {2018},
Volume = {36},
Number = {10},
Pages = {1510-1526},
Month = {OCT},
Abstract = {A robot should be able to estimate an accurate and dense 3D model of its
   environment (a map), along with its pose relative to it, all of it in
   real time, in order to be able to navigate autonomously without
   collisions.
   As the robot moves from its starting position and the estimated map
   grows, the computational and memory footprint of a dense 3D map
   increases and might exceed the robot capabilities in a short time.
   However, a global map is still needed to maintain its consistency and
   plan for distant goals, possibly out of the robot field of view.
   In this work, we address such problem by proposing a real-time stereo
   mapping pipeline, feasible for standard CPUs, which is locally dense and
   globally sparse and accurate. Our algorithm is based on a graph relating
   poses and salient visual points, in order to maintain a long-term
   accuracy with a small cost. Within such framework, we propose an
   efficient dense fusion of several stereo depths in the locality of the
   current robot pose.
   We evaluate the performance and the accuracy of our algorithm in the
   public datasets of Tsukuba and KITTI, and demonstrate that it
   outperforms single-view stereo depth. We release the code as
   open-source, in order to facilitate the system use and comparisons.},
Publisher = {CAMBRIDGE UNIV PRESS},
Address = {32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA},
Type = {Article},
Language = {English},
Affiliation = {Pire, T (Corresponding Author), CONICET UNR, French Argentine Int Ctr Informat \& Syst Sci, CIFASIS, Buenos Aires, DF, Argentina.
   Pire, Taihu; Baravalle, Rodrigo; D'Alessandro, Ariel, CONICET UNR, French Argentine Int Ctr Informat \& Syst Sci, CIFASIS, Buenos Aires, DF, Argentina.
   Civera, Javier, Univ Zaragoza, I3A, Zaragoza, Spain.},
DOI = {10.1017/S0263574718000528},
ISSN = {0263-5747},
EISSN = {1469-8668},
Keywords = {Dense Mapping; Visual SLAM; Stereo Vision},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {pire@cifasis-conicet.gov.ar
   baravalle@cifasis-conicet.gov.ar
   ariel.dalessandro@gmail.com
   jcivera@unizar.es},
Affiliations = {University of Zaragoza},
ResearcherID-Numbers = {Civera, Javier/I-3651-2015},
ORCID-Numbers = {Civera, Javier/0000-0003-1368-1151},
Funding-Acknowledgement = {Spanish government {[}DPI2015-67275]; Aragon regional government
   {[}DGA-T45\_17R/FSE]},
Funding-Text = {This work is part of the Development of a weed remotion mobile robot
   project at CIFASIS (CONICET-UNR). It was also partially supported by the
   Spanish government (project DPI2015-67275) and the Aragon regional
   government (Grupo DGA-T45\_17R/FSE).},
Cited-References = {Alcantarilla P., 2013, P 5 WORKSH PLANN PER.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Bao SY, 2013, PROC CVPR IEEE, P1264, DOI 10.1109/CVPR.2013.167.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Cole DM, 2006, IEEE INT CONF ROBOT, P1556, DOI 10.1109/ROBOT.2006.1641929.
   Concha A., 2014, P ROB SCI SYST BERK.
   Concha A, 2016, IEEE INT CONF ROBOT, P1331, DOI 10.1109/ICRA.2016.7487266.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Engel J., 2017, IEEE T PATTERN ANAL.
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Geiger Andreas, 2011, EFFICIENT LARGE SCAL, P25.
   Graber G., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P708, DOI 10.1109/ICCVW.2011.6130318.
   Klingensmith M., 2015, P ROBOTICS SCI SYSTE, V4.
   Kuschk G, 2017, IEEE INT VEH SYM, P1348, DOI 10.1109/IVS.2017.7995899.
   Ladicky L, 2012, INT J COMPUT VISION, V100, P122, DOI 10.1007/s11263-011-0489-0.
   Maddern W, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2181, DOI 10.1109/IROS.2016.7759342.
   Miksik O, 2015, IEEE INT C INT ROBOT, P908, DOI 10.1109/IROS.2015.7353479.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Oleynikova H, 2017, IEEE INT C INT ROBOT, P1366, DOI 10.1109/IROS.2017.8202315.
   Peris M, 2012, INT C PATT RECOG, P1038.
   Pire T, 2017, ROBOT AUTON SYST, V93, P27, DOI 10.1016/j.robot.2017.03.019.
   Pire T, 2015, IEEE INT C INT ROBOT, P1373, DOI 10.1109/IROS.2015.7353546.
   Pizzoli M, 2014, IEEE INT CONF ROBOT, P2609, DOI 10.1109/ICRA.2014.6907233.
   Schops T, 2017, COMPUT VIS IMAGE UND, V157, P151, DOI 10.1016/j.cviu.2016.09.007.
   Sengupta S, 2013, IEEE INT CONF ROBOT, P580, DOI 10.1109/ICRA.2013.6630632.
   Stuhmer J., 2010, REAL TIME DENSE GEOM, P11.
   Tanner M., 2016, ARXIV160403734.
   Tippetts B, 2016, J REAL-TIME IMAGE PR, V11, P5, DOI 10.1007/s11554-012-0313-2.
   Vineet V, 2015, IEEE INT CONF ROBOT, P75, DOI 10.1109/ICRA.2015.7138983.
   Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421.},
Number-of-Cited-References = {34},
Times-Cited = {8},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {40},
Journal-ISO = {Robotica},
Doc-Delivery-Number = {GR4PH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000442595800006},
DA = {2022-05-17},
}

@inproceedings{ WOS:000312876800013,
Author = {Abrate, Fabrizio and Bona, Basilio and Indri, Marina and Rosa, Stefano
   and Tibaldi, Federico},
Editor = {Martinoli, A and Mondada, F and Correll, N and Mermoud, G and Egerstedt, M and Hsieh, MA and Parker, LE and Stoy, K},
Title = {Multi-robot Map Updating in Dynamic Environments},
DOI = {10.1007/978-3-642-32723-0_11},
Booktitle = {DISTRIBUTED AUTONOMOUS ROBOTIC SYSTEMS},
Series = {Springer Tracts in Advanced Robotics},
Year = {2013},
Volume = {83},
Pages = {147+},
Note = {10th International Symposium on Distributed Autonomous Robotic Systems,
   Ecole Polytechn Fed Lausanne, Lausanne, SWITZERLAND, NOV 01-03, 2010},
Abstract = {Multi-robot systems play an important role in many robotic applications.
   A prerequisite for a team of robots is the capability of building and
   maintaining updated maps of the environment. The simultaneous estimation
   of the trajectory and the map of the environment (known as SLAM)
   requires many computational resources. Moreover, SLAM is generally
   performed in environments that do not vary over time (called static
   environments), whereas real applications commonly require navigation
   services in dynamic environments. This paper focuses on long-term
   mapping operativity in presence of variations in the map, as in the case
   of robotic applications in logistic spaces, where rovers have to track
   the presence of goods in given areas. In this context classical SLAM
   approaches are generally not directly applicable, since they usually
   apply in static environments or in dynamic environments where it is
   possible to model the environment dynamics. This paper proposes a
   methodology that allows the robots to detect variations in the
   environment, generate maps containing only the persistent variations,
   propagate thiem to the team and finally merge the received information
   in a consistent way. The team of robots is also exploited to assure the
   coverage of areas not visited for long time, thus improving the
   knowledge on the present status of the map. The map updating process is
   demonstrated to be computationally light, in order to be performed in
   parallel with other tasks (e.g., team coordination and planning,
   surveillance).},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Abrate, F (Corresponding Author), Ist Super Mario Boella, Via PC Boggio 61, I-10129 Turin, Italy.
   Abrate, Fabrizio, Ist Super Mario Boella, Via PC Boggio 61, I-10129 Turin, Italy.
   Bona, Basilio; Indri, Marina; Rosa, Stefano; Tibaldi, Federico, Politecn Torino, Dipartimento Automat Informat, I-10129 Turin, Italy.},
ISSN = {1610-7438},
EISSN = {1610-742X},
ISBN = {978-3-642-32722-3},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods},
Author-Email = {fabrizio.abrate@ismb.it
   basilio.bona@polito.it
   marina.indri@polito.it
   stefano.rosa@polito.it
   federico.tibaldi@polito.it},
Affiliations = {Polytechnic University of Turin},
ORCID-Numbers = {INDRI, Marina/0000-0002-2740-9514},
Cited-References = {Abrate F., 2008, IEEE INT C INT ROB S.
   Abrate F., 2009, P 9 C AUT ROB SYST C, P1.
   Abrate F., 2010, P 41 INT S ROB, P296.
   Birk A, 2006, P IEEE, V94, P1384, DOI 10.1109/JPROC.2006.876965.
   Carlone L., 2010, P IEEE INT C ROB AUT.
   Carpin S, 2008, AUTON ROBOT, V25, P305, DOI 10.1007/s10514-008-9097-4.
   Fabrizi E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2972, DOI 10.1109/ROBOT.2000.846479.
   Fenwick JW, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1810, DOI 10.1109/ROBOT.2002.1014804.
   HOWARD A, 2005, ROBOTICS SCI SYSTEMS, P201.
   Howard A, 2006, P IEEE, V94, P1360, DOI 10.1109/JPROC.2006.876922.
   LaValle S. M., 2004, PLANNING ALGORITHMS.
   Maragos P., 1986, IEEE T ACOUSTICS SPE.
   Siciliano B., 2008, SPRINGER HDB ROBOTIC, DOI {[}10.1007/978-3-540-30301-5, DOI 10.1007/978-3-540-30301-5].
   SMITH RG, 1980, IEEE T COMPUT, V29, P1104.
   Thrun S., 1996, P NAT C ART INT.
   Williams S., 2002, MULTIVEHICLE SIMULTA, P2743, DOI DOI 10.1109/ROBOT.2002.1013647.
   Zhou X. S., P IEEE INT C INT ROB, P1785.},
Number-of-Cited-References = {17},
Times-Cited = {8},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BDD84},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000312876800013},
DA = {2022-05-17},
}

@inproceedings{ WOS:000446394504073,
Author = {Sun, Li and Yan, Zhi and Mellado, Sergi Molina and Hanheide, Marc and
   Duckett, Tom},
Book-Group-Author = {IEEE},
Title = {3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous
   Mobile Robot Deployment Data},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2018},
Pages = {5942-5948},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Brisbane, AUSTRALIA, MAY 21-25, 2018},
Abstract = {This paper presents a novel 3DOF pedestrian trajectory prediction
   approach for autonomous mobile service robots. While most previously
   reported methods are based on learning of 2D positions in monocular
   camera images, our approach uses range-finder sensors to learn and
   predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within
   the world coordinate system). Our approach, T-Pose-LSTM (Temporal
   3DOF-Pose Long-Short-Term Memory), is trained using long-term data from
   real-world robot deployments and aims to learn context-dependent
   (environment-and time-specific) human activities. Our approach
   incorporates long-term temporal information (i.e. date and time) with
   short-term pose observations as input. A sequence-to-sequence LSTM
   encoder-decoder is trained, which encodes observations into LSTM and
   then decodes the resulting predictions. On deployment, the approach can
   perform on-the-fly prediction in real-time. Instead of using manually
   annotated data, we rely on a robust human detection, tracking and SLAM
   system, providing us with examples in a global coordinate system. We
   validate the approach using more than 15 km of pedestrian trajectories
   recorded in a care home environment over a period of three months. The
   experiments show that the proposed T-Pose-LSTM model outperforms the
   state-of-the-art 2D-based method for human trajectory prediction in
   long-term mobile robot deployments.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Sun, L (Corresponding Author), Univ Lincoln, Lincoln Ctr Autonomous Syst L CAS, Lincoln, England.
   Sun, Li; Mellado, Sergi Molina; Hanheide, Marc; Duckett, Tom, Univ Lincoln, Lincoln Ctr Autonomous Syst L CAS, Lincoln, England.
   Yan, Zhi, UTBM, Lab Elect Informat Image Le2i, Belfort, France.},
ISSN = {1050-4729},
ISBN = {978-1-5386-3081-5},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {lsun@lincoln.ac.uk
   zhi.yan@utbm.fr
   smolinamellado@lincoln.ac.uk
   mhanheide@lincoln.ac.uk
   tduckett@lincoln.ac.uk},
Affiliations = {University of Lincoln; Universite de Bourgogne; Universite de
   Technologie de Belfort-Montbeliard (UTBM)},
ResearcherID-Numbers = {Yan, Zhi/W-5265-2019},
ORCID-Numbers = {Yan, Zhi/0000-0001-8251-9786},
Funding-Acknowledgement = {European Union's Horizon 2020 research and innovation programme
   {[}732737]},
Funding-Text = {We thank NVIDIA Corporation for generously donating a high-power GPU on
   which this work was performed. This project has received funding from
   the European Union's Horizon 2020 research and innovation programme
   under grant agreement No 732737 (ILIAD).},
Cited-References = {Alahi A., 2016, CVPR.
   Alahi A., 2014, CVPR.
   Arras K. O., 2007, ICRA.
   Bartoli F., 2017, ARXIV170502503.
   Bengio Y, RMSPROP EQUILIBRATED.
   Biswas J, 2016, IEEE INTELL SYST, V31, P86, DOI 10.1109/MIS.2016.53.
   Dondrup C., 2015, WORKSH MACH LEARN SO.
   Endres F., 2014, IEEE T ROBOTICS.
   Grisetti G., 2005, ICRA.
   Hanheide M., 2017, P HRI.
   Hawes N., 2017, ROBOTICS AUTOMATION, V4.
   Helbing D., 1995, PHYS REV.
   Hochreiter S., 1997, NEURAL COMPUTATION.
   Jafari O. H., 2014, ICRA.
   Krajnik Tomas, 2017, IEEE T ROBOTICS.
   Lerner A., 2007, COMPUTER GRAPHICS FO.
   Linder  T., 2016, ICRA.
   Linder T., 2014, INT C INF FUS FUSION.
   Lovric, 2011, INT ENCY STAT SCI.
   Marder-Eppstein E., 2010, ICRA.
   Mur-Artal R., 2015, IEEE T ROBOTICS.
   Pellegrini S., ICCV 2009.
   Robicquet A., 2016, ECCV.
   Thrun S., 1999, ICRA.
   Trautman P., 2017, ARXIV170503639.
   Trautman P., 2010, IROS.
   Varshneya D., 2017, ARXIV170509436.
   Yamaguchi K., 2011, CVPR.
   Yan Z., 2017, IROS.
   Yi S., 2016, IEEE T IMAGE PROCESS.
   Yi S., 2015, ICCV.},
Number-of-Cited-References = {31},
Times-Cited = {28},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {7},
Doc-Delivery-Number = {BL0QZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000446394504073},
OA = {Green Accepted, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000764815300031,
Author = {Toft, Carl and Maddern, Will and Torii, Akihiko and Hammarstrand, Lars
   and Stenborg, Erik and Safari, Daniel and Okutomi, Masatoshi and
   Pollefeys, Marc and Sivic, Josef and Pajdla, Tomas and Kahl, Fredrik and
   Sattler, Torsten},
Title = {Long-Term Visual Localization Revisited},
Journal = {IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE},
Year = {2022},
Volume = {44},
Number = {4},
Pages = {2074-2088},
Month = {APR 1},
Abstract = {Visual localization enables autonomous vehicles to navigate in their
   surroundings and augmented reality applications to link virtual to real
   worlds. Practical visual localization approaches need to be robust to a
   wide variety of viewing conditions, including day-night changes, as well
   as weather and seasonal variations, while providing highly accurate six
   degree-of-freedom (6DOF) camera pose estimates. In this paper, we extend
   three publicly available datasets containing images captured under a
   wide variety of viewing conditions, but lacking camera pose information,
   with ground truth pose information, making evaluation of the impact of
   various factors on 6DOF camera pose estimation accuracy possible. We
   also discuss the performance of state-of-the-art localization approaches
   on these datasets. Additionally, we release around half of the poses for
   all conditions, and keep the remaining half private as a test set, in
   the hopes that this will stimulate research on long-term visual
   localization, learned local image features, and related research areas.
   Our datasets are available at visuallocalization.net, where we are also
   hosting a benchmarking server for automatic evaluation of results on the
   test set. The presented state-of-the-art results are to a large degree
   based on submissions to our server.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA},
Type = {Article},
Language = {English},
Affiliation = {Toft, C (Corresponding Author), Chalmers Univ Technol, S-41296 Gothenburg, Sweden.
   Toft, Carl; Hammarstrand, Lars; Stenborg, Erik; Kahl, Fredrik; Sattler, Torsten, Chalmers Univ Technol, S-41296 Gothenburg, Sweden.
   Maddern, Will, Univ Nuro, Nuro Robot Inst, Nuro OX1 2JD, England.
   Torii, Akihiko; Safari, Daniel; Okutomi, Masatoshi, Tokyo Inst Technol, Tokyo 1528550, Japan.
   Safari, Daniel, Tech Univ Denmark, DK-2800 Lyngby, Denmark.
   Pollefeys, Marc, Swiss Fed Inst Technol, Dept Comp Sci, CH-8092 Zurich, Switzerland.
   Pollefeys, Marc, Microsoft, Redmond, WA 98052 USA.
   Sivic, Josef, PSL Res Univ, Dept Informat, CNRS, Ecole Normale Super, F-75006 Paris, France.
   Sivic, Josef; Pajdla, Tomas; Sattler, Torsten, Czech Tech Univ, Czech Inst Informat Robot \& Cybernet, Prague 16636 6, Czech Republic.},
DOI = {10.1109/TPAMI.2020.3032010},
ISSN = {0162-8828},
EISSN = {1939-3539},
Keywords = {Benchmark testing; Visualization; Cameras; Three-dimensional displays;
   Robots; Solid modeling; Trajectory; Visual localization; relocalization;
   6DOF pose estimation; benchmark; long-term localization},
Keywords-Plus = {PROBABILISTIC LOCALIZATION; PLACE RECOGNITION; IMAGE; SLAM},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic},
Author-Email = {carltoft@gmail.com
   will@nuro.ai
   torii@sc.e.titech.ac.jp
   lars.hammarstrand@chalmers.se
   erik.stenborg@chalmers.se
   daniel.safari@yahoo.dk
   mxo@ok.sc.e.titech.ac.jp
   marc.pollefeys@inf.ethz.ch
   josef.sivic@inria.fr
   pajdla@cvut.cz
   fredrik.kahl@chalmers.se
   torsten.sattler@cvut.cz},
Affiliations = {Chalmers University of Technology; Tokyo Institute of Technology;
   Technical University of Denmark; ETH Zurich; Microsoft; Centre National
   de la Recherche Scientifique (CNRS); UDICE-French Research Universities;
   PSL Research University Paris; Ecole Normale Superieure (ENS);
   Universite de Paris; Czech Technical University Prague},
ResearcherID-Numbers = {/C-1291-2019},
ORCID-Numbers = {/0000-0001-5676-1392},
Funding-Acknowledgement = {European Regional Development Fund under the project IMPACT
   {[}CZ.02.1.01/0.0/0.0/15\_003/0000468]; JSPS KAKENHI {[}15H05313]; EPSRC
   {[}EP/M019918/1]; Swedish Research Council {[}2016-04445]; Swedish
   Foundation for Strategic Research (Semantic Mapping and Visual
   Navigation for Smart Robots)},
Funding-Text = {This work was supported in part by the European Regional Development
   Fund under the project IMPACT (reg. no.
   CZ.02.1.01/0.0/0.0/15\_003/0000468), JSPS KAKENHI Grant Number 15H05313,
   EPSRC Programme Grant EP/M019918/1, the Swedish Research Council (grant
   no. 2016-04445), and the Swedish Foundation for Strategic Research
   (Semantic Mapping and Visual Navigation for Smart Robots).},
Cited-References = {Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018.
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326.
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863.
   Brachmann E, 2017, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2017.267.
   Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366.
   Camposeco F, 2017, PROC CVPR IEEE, P6700, DOI 10.1109/CVPR.2017.709.
   Camposeco F, 2016, LECT NOTES COMPUT SC, V9909, P202, DOI 10.1007/978-3-319-46454-1\_13.
   Cao S, 2014, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2014.66.
   Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610.
   Choudhary S, 2012, LECT NOTES COMPUT SC, V7576, P130, DOI 10.1007/978-3-642-33715-4\_10.
   Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060.
   Donoser M, 2014, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2014.73.
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828.
   Enqvist O., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P264, DOI 10.1109/ICCVW.2011.6130252.
   Enqvist O, 2008, LECT NOTES COMPUT SC, V5302, P141, DOI 10.1007/978-3-540-88682-2\_12.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Germain H, 2019, INT CONF 3D VISION, P513, DOI 10.1109/3DV.2019.00063.
   Gronat P, 2016, INT J COMPUT VISION, V118, P319, DOI 10.1007/s11263-015-0878-x.
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0.
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/cvpr.2009.5206587.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Jenicek T, 2019, IEEE I CONF COMP VIS, P9695, DOI 10.1109/ICCV.2019.00979.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kneip L, 2011, PROC CVPR IEEE.
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9\_54.
   Larsson M, 2019, IEEE I CONF COMP VIS, P31, DOI 10.1109/ICCV.2019.00012.
   Larsson M, 2019, PROC CVPR IEEE, P9524, DOI 10.1109/CVPR.2019.00976.
   Larsson V., 2016, P BRIT MACH VIS C.
   Lee GH, 2015, INT J ROBOT RES, V34, P837, DOI 10.1177/0278364914557969.
   Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5\_2.
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791.
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218.
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208.
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7\_3.
   Liu L, 2017, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2017.260.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lynen S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Melekhov I., 2018, ARXIV181008393.
   Milford Michael, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P18, DOI 10.1109/CVPRW.2015.7301395.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Neubert P., 2013, INT C ROB AUT ICRA W, DOI 10.1016/j.cell.2007.12.011.
   Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520.
   Radenovic F, 2016, PROC CVPR IEEE, P5488, DOI 10.1109/CVPR.2016.592.
   Revaud J., 2019, P ADV NEUR INF PROC, P405.
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474.
   Sarlin P.-E, 2019, P IEEE C COMP VIS PA, p12 716.
   Sattler T., 2016, P IEEE C COMP VIS PA, P2102.
   Sattler T., 2015, P IEEE INT C COMP VI.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76.
   Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721.
   Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445.
   Shi T., ARXIV190403803, V2019.
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377.
   Simonyan K, 2015, INT C LEARN REPR ICL.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sun X, 2017, PROC CVPR IEEE, P5641, DOI 10.1109/CVPR.2017.598.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331.
   Svarm L, 2014, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2014.75.
   Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752.
   Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8\_24.
   Toft C, 2017, IEEE INT CONF COMP V, P650, DOI 10.1109/ICCVW.2017.83.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Torii A, 2015, IEEE T PATTERN ANAL, V37, P2346, DOI 10.1109/TPAMI.2015.2409868.
   uhlfellner P. M\_, 2016, J FIELD ROBOTICS, V35.
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165.
   Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75.
   Wang SL, 2017, IEEE I CONF COMP VIS, P3028, DOI 10.1109/ICCV.2017.327.
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8\_3.
   Xin Z, 2019, IEEE INT CONF ROBOT, P5979, DOI 10.1109/ICRA.2019.8794383.
   Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.
   Zhou H., 2016, P EUR C COMP VIS WOR.},
Number-of-Cited-References = {95},
Times-Cited = {3},
Usage-Count-Last-180-days = {14},
Usage-Count-Since-2013 = {14},
Journal-ISO = {IEEE Trans. Pattern Anal. Mach. Intell.},
Doc-Delivery-Number = {ZN1PQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000764815300031},
OA = {Green Submitted, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000655487600012,
Author = {Zhao, Lijun and Liu, Yu and Jiang, Xinkai and Wang, Ke and Zhou, Zigeng},
Editor = {Yu, H and Liu, J and Liu, L and Ju, Z and Liu, Y and Zhou, D},
Title = {Indoor Environment RGB-DT Mapping for Security Mobile Robots},
Booktitle = {INTELLIGENT ROBOTICS AND APPLICATIONS, ICIRA 2019, PT IV},
Series = {Lecture Notes in Artificial Intelligence},
Year = {2019},
Volume = {11743},
Pages = {131-141},
Note = {12th International Conference on Intelligent Robotics and Applications
   (ICIRA), Shenyang, PEOPLES R CHINA, AUG 08-11, 2019},
Abstract = {Many robot applications, such as environmental monitoring, security and
   surveillance help people to do tasks in day-to-day scenarios. However,
   the growing security demand for environment perception is a key issue of
   mapping or frequent updating in the long term, such as fire detection in
   early stage. A hybrid mapping method is proposed based on fusing RGB,
   depth and thermal (DT) information from Kinect and infrared sensors
   equipped in the mobile robot. Firstly, the proposed pipeline will
   estimate the robot's pose by extracting and matching ORB features in RGB
   images successively. Then Poses corresponding to each depth and
   thermal-Infrared image are estimated through a combination of timestamp
   synchronization and the result of the extrinsic calibration of the
   system, and the map with both appearance and the temperature of
   environment is generated by the combination of The RGB and temperature
   information. Finally, the depth information is used to project the pixel
   points to the world coordinate system to generate the RGB-DT map.
   Extensive results verify the effectiveness of the proposed RGB-DT
   mapping for environments perception},
Publisher = {SPRINGER INTERNATIONAL PUBLISHING AG},
Address = {GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhao, LJ (Corresponding Author), Harbin Inst Technol, State Key Lab Robot \& Syst, Harbin, Peoples R China.
   Zhao, Lijun; Liu, Yu; Jiang, Xinkai; Wang, Ke, Harbin Inst Technol, State Key Lab Robot \& Syst, Harbin, Peoples R China.
   Zhou, Zigeng, Kunming Power Supply Bur, Kunming, Yunnan, Peoples R China.},
DOI = {10.1007/978-3-030-27538-9\_12},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-030-27538-9; 978-3-030-27537-2},
Keywords = {SLAM; Environment mapping; ORB-SLAM; Multi-sensor fusing},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {zhaolj@hit.edu.cn},
Affiliations = {Harbin Institute of Technology},
Cited-References = {Borrmann D, 2012, SYROCO, V45, P31.
   Chang H., 2007, COMPUT ENG DES, V28, P5682.
   Dai A., 2017, ACM T GRAPHIC, V36, p76a.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Ge P., 2018, INFRARED TECHNOL, V40, P45.
   Hwang S, 2015, INT CONF UBIQ ROBOT, P435, DOI 10.1109/URAI.2015.7358897.
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6.
   Moghadam P, 2013, IEEE INT CONF ROBOT, P3685, DOI 10.1109/ICRA.2013.6631095.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Nagatani K., 2013, FIELD SERVICE ROBOTI, P49, DOI {[}10.1007/978-3-642-40686-7\_4, DOI 10.1007/978-3-642-40686-7\_4].
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Tan Y., 2018, J MIANYANG TEACH COL, V2, P40.
   van Baar J, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION \& TRANSMISSION (3DIMPVT 2012), P472, DOI 10.1109/3DIMPVT.2012.69.
   Vidas S, 2013, IEEE INT CONF ROBOT, P2311, DOI 10.1109/ICRA.2013.6630890.
   Zhang Q., 2005, IEEE RSJ INT C INT R.
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718.},
Number-of-Cited-References = {16},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BR5IE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000655487600012},
DA = {2022-05-17},
}

@inproceedings{ WOS:000405519500048,
Author = {Zhang, Yu and Chao, Ainong and Zhao, Boxin and Liu, Huawei and Zhao,
   Xiaolin},
Book-Group-Author = {IEEE},
Title = {Migratory Birds-Inspired Navigation System for Unmanned Aerial Vehicles},
DOI = {10.1109/ICInfA.2016.7831835},
Booktitle = {2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA)},
Year = {2016},
Pages = {276-281},
Note = {IEEE International Conference on Information and Automation (ICIA),
   Ningbo, PEOPLES R CHINA, AUG 01-03, 2016},
Abstract = {Migration birds are able to navigate themselves during a long-distance
   journey without getting lost. They actually achieve just what is being
   sought for in the field of Unmanned Aerial Vehicles (UAVs): long-term
   autonomous navigation. This paper proposes an approach that combines the
   migration birds' sense principles with Micro-Electro-Mechanical System
   (MEMS) sensors to estimate UAVs position within GPS-denied environments.
   Camera, orientation and web-based maps (such as Google/Baidu Maps) are
   chosen to simulate the birds' localization cues: vision, earth magnetic
   field and mental maps. The visual odometry, Particle Filter theories are
   used in the proposed approach to integrate multiple sensor measurements.
   Real flying experiments are conducted both in indoor and outdoor
   environments. The results validate that the proposed migration-inspired
   visual odometry system can estimate the UAV localization effectively.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhao, BX (Corresponding Author), Air Force Engn Univ, Coll Aerosp Engn, Xian 710000, Peoples R China.
   Zhang, Yu; Chao, Ainong; Zhao, Boxin; Liu, Huawei; Zhao, Xiaolin, Air Force Engn Univ, Coll Aerosp Engn, Xian 710000, Peoples R China.},
ISBN = {978-1-5090-4102-2},
Keywords = {Migration birds; Unmanned Aerial Vehicles; Navigation},
Keywords-Plus = {VISUAL ODOMETRY; SLAM},
Research-Areas = {Automation \& Control Systems; Computer Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Information Systems},
Author-Email = {boxin.zhao@nudt.edu.cn},
Affiliations = {Air Force Engineering University},
Funding-Acknowledgement = {National University of Defense Technology; National Natural Science
   Foundation of China {[}61503405]},
Funding-Text = {Grateful to supports from National University of Defense Technology and
   National Natural Science Foundation of China No. 61503405.},
Cited-References = {Caballero F, 2009, J INTELL ROBOT SYST, V54, P137, DOI 10.1007/s10846-008-9257-y.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810.
   Gerdes J, 2014, SOFT ROBOT, V1, P275, DOI 10.1089/soro.2014.0019.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Grabe V, 2012, IEEE INT C INT ROBOT, P2153, DOI 10.1109/IROS.2012.6386234.
   Holland RA, 2014, J ZOOL, V293, P1, DOI 10.1111/jzo.12107.
   Hu JS, 2014, IEEE INT CONF ROBOT, P3963, DOI 10.1109/ICRA.2014.6907434.
   Kendoul F, 2009, ROBOT AUTON SYST, V57, P591, DOI 10.1016/j.robot.2009.02.001.
   Kitt B, 2010, IEEE INT VEH SYM, P486, DOI 10.1109/IVS.2010.5548123.
   Klein George, 2007, P1.
   Ma Y., 2004, INVITATION 3 D VISIO, P121.
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184.
   Martinelli A, 2012, HANDBOOK OF INTELLIGENT VEHICLES, VOLS 1 AND 2, P1335, DOI 10.1007/978-0-85729-085-4\_52.
   Pete AE, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2015.0508.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Shen S, 2014, IEEE INT CONF ROBOT, P4974, DOI 10.1109/ICRA.2014.6907588.
   Soloviev A., 2009, P SPIE, V7332.
   Srinivasan MV, 2009, FLYING INSECTS AND ROBOTS, P15, DOI 10.1007/978-3-540-89393-6\_2.
   Weiss S, 2011, J FIELD ROBOT, V28, P854, DOI 10.1002/rob.20412.
   Zhao B, 2015, CONTR C CCC 2015 34.},
Number-of-Cited-References = {22},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BI1CE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000405519500048},
DA = {2022-05-17},
}

@inproceedings{ WOS:000647641800013,
Author = {Oh, Jung H. and Lee, Heung-Jae},
Book-Group-Author = {IEEE Comp Soc},
Title = {Global Alignment of Deep Features for Robot Localization in Changing
   Environment},
Booktitle = {2019 3RD EUROPEAN CONFERENCE ON ELECTRICAL ENGINEERING AND COMPUTER
   SCIENCE (EECS 2019)},
Year = {2019},
Pages = {72-75},
Note = {3rd European Conference on Electrical Engineering and Computer Science
   (EECS), Athens, GREECE, DEC 28-30, 2019},
Abstract = {Localization is an elemental requirement for autonomous navigation,
   simultaneous localization and mapping for mobile robots. As robots can
   perform long-term and large-scale tasks, finding locations in changing
   environment is a crucial problem. To resolve the problem, we present a
   robust localization system under severe appearance changes. The system
   consists of two stages. First, a robust feature extraction method using
   a deep convolutional auto-encoder is proposed. Then, global alignment of
   extracted feature sequences is proposed to find the actual robot's
   locations. Since the proposed method not only uses the condition-robust
   features but also considers the actual trajectory of the robot by
   aligning features sequences, it can show accurate localization
   performances in changing environments. Experiments were conducted to
   prove the effective of the proposed method, and the results showed that
   our method outperformed than existing methods.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Oh, JH (Corresponding Author), Kwangwoon Univ, Sch Robot, Seoul, South Korea.
   Oh, Jung H., Kwangwoon Univ, Sch Robot, Seoul, South Korea.
   Lee, Heung-Jae, Kwangwoon Univ, Dept Elect Engn, Seoul, South Korea.},
DOI = {10.1109/EECS49779.2019.00026},
ISBN = {978-1-7281-6109-9},
Keywords = {robotics; localization; sequence alignment; place recognition; deep
   learning; auto-encoder},
Keywords-Plus = {FAB-MAP; SCALE; SLAM},
Research-Areas = {Computer Science; Engineering; Mathematics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Engineering,
   Electrical \& Electronic; Mathematics, Applied},
Author-Email = {jhyunoh@kw.ac.kr
   hjlee@kw.ac.kr},
Affiliations = {Kwangwoon University; Kwangwoon University},
Funding-Acknowledgement = {Korea Electric Power Corporation {[}R17XA05-20]; Korea Institute of
   Energy Technology Evaluation and Planning (KETEP); Ministry of Trade,
   Industry \& Energy (MOTIE) of the Republic of Korea {[}20174010201620];
   Research Resettlement Fund for the new faculty of Kwangwoon University
   in 2019},
Funding-Text = {The research was supported by Korea Electric Power Corporation
   (R17XA05-20), Korea Institute of Energy Technology Evaluation and
   Planning (KETEP) and the Ministry of Trade, Industry \& Energy (MOTIE)
   of the Republic of Korea (No. 20174010201620). Also, this work was
   supported by Research Resettlement Fund for the new faculty of Kwangwoon
   University in 2019.},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7\_7.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Oh JH, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.0037.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Vincent P, 2010, J MACH LEARN RES, V11, P3371.
   Zeng ZQ, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8112257.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.},
Number-of-Cited-References = {20},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BR3LQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000647641800013},
DA = {2022-05-17},
}

@article{ WOS:000525390100048,
Author = {Nie, Fuyu and Zhang, Weimin and Yao, Zhuo and Shi, Yongliang and Li,
   Fangxing and Huang, Qiang},
Title = {LCPF: A Particle Filter Lidar SLAM System With Loop Detection and
   Correction},
Journal = {IEEE ACCESS},
Year = {2020},
Volume = {8},
Pages = {20401-20412},
Abstract = {A globally consistent map is the basis of indoor robot localization and
   navigation. However, map built by Rao-Blackwellized Particle Filter
   (RBPF) doesn;t have high global consistency which is not suitable for
   long-term application in large scene. To address the problem, we present
   an improved RBPF Lidar SLAM system with loop detection and correction
   named LCPF. The efficiency and accuracy of loop detection depend on the
   segmentation of submaps. Instead of dividing the submap at fixed number
   of laser scan like existing method, Dynamic Submap Segmentation is
   proposed in LCPF. This segmentation algorithm decreases the error inside
   the submap by splitting the submap where there is high scan match error
   and later rectifies the error by an improved pose graph optimization
   between submaps. In order to segment the submap at appropriate point,
   when to create a new submap is determined by both the accumulation of
   scan match error and the particle distribution. Furthermore, LCPF uses
   branch and bound algorithm as basic detector for loop detection and
   multiple criteria to judge the reliability of a loop. In the criteria, a
   novel parameter called usable ratio was proposed to measure the useful
   information that a laser scan containing. Finally, comparisons to
   existing 2D-Lidar mapping algorithm are performed with a series of open
   dataset simulations and real robot experiments to demonstrate the
   effectiveness of LCPF.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhang, WM (Corresponding Author), Beijing Inst Technol, Sch Mechatron Engn, Beijing 100811, Peoples R China.
   Nie, Fuyu; Zhang, Weimin; Yao, Zhuo; Shi, Yongliang; Li, Fangxing; Huang, Qiang, Beijing Inst Technol, Sch Mechatron Engn, Beijing 100811, Peoples R China.
   Nie, Fuyu; Zhang, Weimin; Yao, Zhuo; Shi, Yongliang; Li, Fangxing; Huang, Qiang, Beijing Inst Technol, Key Lab Biomimet Robots \& Syst, Minist Educ, Beijing 100081, Peoples R China.
   Nie, Fuyu; Zhang, Weimin; Yao, Zhuo; Shi, Yongliang; Li, Fangxing; Huang, Qiang, Beijing Adv Innovat Ctr Intelligent Robots \& Syst, Beijing 100081, Peoples R China.},
DOI = {10.1109/ACCESS.2020.2968353},
ISSN = {2169-3536},
Keywords = {Simultaneous localization and mapping; mobile robots; indoor navigation;
   particle filter; loop detection; dynamic submap segementation},
Keywords-Plus = {CONSISTENCY; TIME},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {zhwm@bit.edu.cn},
Affiliations = {Beijing Institute of Technology; Beijing Institute of Technology},
ORCID-Numbers = {Yao, Zhuo/0000-0001-7532-4200},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2017YFB1302200]},
Funding-Text = {This work was supported by the National Key Research and Development
   Program of China under Grant 2017YFB1302200.},
Cited-References = {Aldibaja M, 2017, IEEE T IND INFORM, V13, P2369, DOI 10.1109/TII.2017.2713836.
   Bailey T, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3562, DOI 10.1109/IROS.2006.281644.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Carlone L, 2010, IEEE INT CONF ROBOT, P243, DOI 10.1109/ROBOT.2010.5509307.
   de la Puente P, 2014, AUTON ROBOT, V37, P243, DOI 10.1007/s10514-014-9386-z.
   Elinas P., 2006, P IEEE INT C ROB AUT, P1.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Grisettiyz G., 2006, P IEEE INT C ROB AUT, P2432.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Huang GP, 2008, IEEE INT CONF ROBOT, P473, DOI 10.1109/ROBOT.2008.4543252.
   Huang SD, 2007, IEEE T ROBOT, V23, P1036, DOI 10.1109/TRO.2007.903811.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Li MG, 2019, IEEE ACCESS, V7, P14124, DOI 10.1109/ACCESS.2018.2889304.
   Montemerlo M., 2004, P IEEE INT C ROB AUT, V2, P1985.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Paz LM, 2008, IEEE T ROBOT, V24, P1107, DOI 10.1109/TRO.2008.2004639.
   Sim R, 2007, INT J COMPUT VISION, V74, P303, DOI 10.1007/s11263-006-0021-0.
   Stasse O, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P348, DOI 10.1109/IROS.2006.281645.
   Teslic L, 2011, J INTELL ROBOT SYST, V62, P187, DOI 10.1007/s10846-010-9441-8.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Wang XP, 2017, IEEE IND ELEC, P5685, DOI 10.1109/IECON.2017.8216986.
   Weingarten J., 2005, IEEE RSJ INT C INT R, P3834.
   Wen JR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113668.},
Number-of-Cited-References = {25},
Times-Cited = {3},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {14},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {LC5SJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000525390100048},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000286183800003,
Author = {Kawewong, Aram and Tongprasit, Noppharit and Tangruamsub, Sirinart and
   Hasegawa, Osamu},
Title = {Online and Incremental Appearance-based SLAM in Highly Dynamic
   Environments},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2011},
Volume = {30},
Number = {1},
Pages = {33-55},
Month = {JAN},
Abstract = {In this paper we present a novel method for online and incremental
   appearance-based localization and mapping in a highly dynamic
   environment. Using position-invariant robust features (PIRFs), the
   method can achieve a high rate of recall with 100\% precision. It can
   handle both strong perceptual aliasing and dynamic changes of places
   efficiently. Its performance also extends beyond conventional images; it
   is applicable to omnidirectional images for which the major portions of
   scenes are similar for most places. The proposed PIRF-based Navigation
   method named PIRF-Nav is evaluated by testing it on two standard
   datasets in a similar manner as in FAB-MAP and on an additional
   omnidirectional image dataset that we collected. This extra dataset was
   collected on 2 days with different specific events, i.e. an open-campus
   event, to present challenges related to illumination variance and strong
   dynamic changes, and to test assessment of dynamic scene changes.
   Results show that PIRF-Nav outperforms FAB-MAP; PIRF-Nav at precision-1
   yields a recall rate about twice as high (approximately 80\% increase)
   than that of FAB-MAP. Its computation time is sufficiently short for
   real-time applications. The method is fully incremental, and requires no
   offline process for dictionary creation. Additional testing using
   combined datasets proves that PIRF-Nav can function over the long term
   and can solve the kidnapped robot problem.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Kawewong, A (Corresponding Author), Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Midori Ku, 4259-R2-52 Nagatsuta, Yokohama, Kanagawa 2268503, Japan.
   Kawewong, Aram, Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Midori Ku, Yokohama, Kanagawa 2268503, Japan.},
DOI = {10.1177/0278364910371855},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Appearance-based localization and mapping; invariant robust feature;
   topological SLAM},
Keywords-Plus = {VISION-BASED LOCALIZATION; LOOP-CLOSURE},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {kawewong.a.aa@m.titech.ac.jp},
Affiliations = {Tokyo Institute of Technology},
Funding-Acknowledgement = {New Energy and Industrial Technology Development Organization (NEDO) of
   Japan},
Funding-Text = {This study was supported by an Industrial Technology Research Grant
   Program received in 2004 from the New Energy and Industrial Technology
   Development Organization (NEDO) of Japan. Also, the authors gratefully
   acknowledge Oxford Robotics Research Group for their provided database
   and binary source codes.},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Bay H., 2006, P EUR C COMP VIS ECC.
   Bowling M., 2005, P INT S ROB RES ISRR.
   Chen C, 2006, INT J ROBOT RES, V25, P953, DOI 10.1177/0278364906068375.
   Cummins M., 2009, P ROB SCI SYST RSS.
   CUMMINS M, 2008, P IEEE INT C ROB AUT.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Filliat D., 2003, COGN SYST RES, V4, P243, DOI DOI 10.1016/S1389-0417(03)00008-1.
   FILLIAT D, 2007, P IEEE INT C ROB AUT.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   KAWEWONG A, 2009, P INT C COMP AN IM P.
   Kosecka J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008.
   Krose BJA, 2001, IMAGE VISION COMPUT, V19, P381, DOI 10.1016/S0262-8856(00)00086-X.
   Lamon P., 2001, P IEEE INT C ROB AUT.
   LEVIN A, 2004, P IEEE INT C COMP VI.
   LI F, 2006, P INT C ROB AUT ICRA.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Meyer J.-A., 2003, COGN SYST RES, V4, P283, DOI {[}DOI 10.1016/S1389-0417(03)00007-X, 10.1016/S1389-0417(03)00007-X].
   Newman P., 2006, P IEEE INT C ROB AUT.
   Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17.
   Nister D, 2006, P IEEE INT C COMP VI.
   Schindler G, 2007, P IEEE C COMP VIS PA.
   Silpa-Anan C., 2004, P AUSTR C ROB AUT.
   Sivic J., 2003, P IEEE INT C COMP VI.
   Torralba A., 2003, P IEEE INT C COMP VI.
   ULRICH I, 2003, P IEEE INT C ROB AUT.
   Wang JQ, 2006, IEEE T SYST MAN CY B, V36, P413, DOI 10.1109/TSMCB.2005.859085.
   Wolf J, 2005, IEEE T ROBOT, V21, P208, DOI 10.1109/TRO.2004.835453.
   Zivkovic Z., 2005, P IEEE RSJ INT C INT.
   {[}No title captured].},
Number-of-Cited-References = {31},
Times-Cited = {39},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {23},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {706AO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000286183800003},
DA = {2022-05-17},
}

@article{ WOS:000412132800001,
Author = {Perez-Grau, Francisco J. and Caballero, Fernando and Viguria, Antidio
   and Ollero, Anibal},
Title = {Multi-sensor three-dimensional Monte Carlo localization for long-term
   aerial robot navigation},
Journal = {INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS},
Year = {2017},
Volume = {14},
Number = {5},
Month = {SEP 27},
Abstract = {This article presents an enhanced version of the Monte Carlo
   localization algorithm, commonly used for robot navigation in indoor
   environments, which is suitable for aerial robots moving in a
   three-dimentional environment and makes use of a combination of
   measurements from an Red,Green,Blue-Depth (RGB-D) sensor, distances to
   several radio-tags placed in the environment, and an inertial
   measurement unit. The approach is demonstrated with an unmanned aerial
   vehicle flying for 10 min indoors and validated with a very precise
   motion tracking system. The approach has been implemented using the
   robot operating system framework and works smoothly on a regular i7
   computer, leaving plenty of computational capacity for other navigation
   tasks such as motion planning or control.},
Publisher = {SAGE PUBLICATIONS INC},
Address = {2455 TELLER RD, THOUSAND OAKS, CA 91320 USA},
Type = {Article},
Language = {English},
Affiliation = {Perez-Grau, FJ (Corresponding Author), Ctr Adv Aerosp Technol CATEC, Aerosp Technol Pk Andalusia, Seville 41309, Spain.
   Perez-Grau, Francisco J.; Viguria, Antidio, Ctr Adv Aerosp Technol CATEC, Aerosp Technol Pk Andalusia, Seville 41309, Spain.
   Caballero, Fernando; Ollero, Anibal, Univ Seville, Dept Syst Engn \& Automat, Seville, Spain.},
DOI = {10.1177/1729881417732757},
Article-Number = {1729881417732757},
ISSN = {1729-8814},
Keywords = {Aerial robotics; localization; autonomous vehicle navigation},
Keywords-Plus = {SLAM; VISION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {fjperez@catec.aero},
Affiliations = {University of Sevilla},
ResearcherID-Numbers = {Perez Grau, Francisco Javier/P-3596-2018
   Caballero, Fernando/E-6297-2010
   },
ORCID-Numbers = {Perez Grau, Francisco Javier/0000-0003-3372-7348
   Caballero, Fernando/0000-0001-8869-2846
   Viguria, Antidio/0000-0003-4193-9965},
Funding-Acknowledgement = {EuRoC project - EU FP7 {[}CPIP 608849]; OCELLIMAV project - Spanish
   Government {[}TEC2014-61708-EXP]},
Funding-Text = {The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   has been partially supported by EuRoC project funded by the EU FP7 under
   grant agreement CPIP 608849 and OCELLIMAV project funded by the Spanish
   Government, grant TEC2014-61708-EXP.},
Cited-References = {Achtelik MW, 2012, IEEE INT C INT ROBOT, P2651, DOI 10.1109/IROS.2012.6386270.
   Bolognesi M, 2015, INT ARCH PHOTOGRAMM, V40-5, P229, DOI 10.5194/isprsarchives-XL-5-W4-229-2015.
   Bouabdallah S, 2007, DESIGN CONTROL MINIA, V33.
   Caballero F, 2008, IEEE INT CONF ROBOT, P596, DOI 10.1109/ROBOT.2008.4543271.
   Chen ZC, 2006, IEEE INT CONF ROBOT, P2686, DOI 10.1109/ROBOT.2006.1642107.
   COX IJ, 1991, IEEE T ROBOTIC AUTOM, V7, P193, DOI 10.1109/70.75902.
   Cui JQ, 2016, UNMANNED SYST, V4, P83, DOI 10.1142/S2301385016400094.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dryanovski I, 2013, IEEE INT CONF ROBOT, P2305, DOI 10.1109/ICRA.2013.6630889.
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412.
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199.
   Fabresse FR, 2016, J INTELL ROBOT SYST, V84, P297, DOI 10.1007/s10846-015-0322-z.
   Fallon MF, 2012, IEEE INT CONF ROBOT, P1663, DOI 10.1109/ICRA.2012.6224951.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Gholami M, 2013, ROBOT CIM-INT MANUF, V29, P96, DOI 10.1016/j.rcim.2012.07.006.
   Gonzalez J, 2009, ROBOT AUTON SYST, V57, P496, DOI 10.1016/j.robot.2008.10.022.
   Guo KX, 2016, UNMANNED SYST, V4, P23, DOI 10.1142/S2301385016400033.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Hornung A, 2010, IEEE INT C INT ROBOT, P1690, DOI 10.1109/IROS.2010.5649751.
   Mesas-Carrascosa FJ, 2014, INT J APPL EARTH OBS, V33, P270, DOI 10.1016/j.jag.2014.06.009.
   Kanai S, INT ARCH PHOTOGRAMME, V40, P61.
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104.
   Kitt B, 2010, IEEE INT VEH SYM, P486, DOI 10.1109/IVS.2010.5548123.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Lee KS, 2015 IEEE 15 INT C E, P1291, DOI {[}10.1109/EEEIC.2015.7165356, DOI 10.1109/EEEIC.2015.7165356].
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258.
   Pagliari D, 2015, INT ARCH PHOTOGRAMM, V44, P113, DOI 10.5194/isprsarchives-XL-4-W5-113-2015.
   Perez-Grau FJ, 2016, INT CONF UNMAN AIRCR, P608, DOI 10.1109/ICUAS.2016.7502653.
   Pinies P, 2007, IEEE INT CONF ROBOT, P2797, DOI 10.1109/ROBOT.2007.363895.
   Raja AK, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P2010, DOI 10.1109/ICIT.2016.7475076.
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y.
   Schmid K, 2013, IEEE INT C INT ROBOT, P3955, DOI 10.1109/IROS.2013.6696922.
   Siebert S, 2014, AUTOMAT CONSTR, V41, P1, DOI 10.1016/j.autcon.2014.01.004.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   Thrun S., COMMUNICATIONS ACM, V45, P52.
   Thrun S., 2011, COMMUNICATION.
   Tiemann J, 2015, P INT C IND PS IND O, P1.
   Weiss S, 2011, J FIELD ROBOT, V28, P854, DOI 10.1002/rob.20412.},
Number-of-Cited-References = {41},
Times-Cited = {7},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {21},
Journal-ISO = {Int. J. Adv. Robot. Syst.},
Doc-Delivery-Number = {FI6UR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000412132800001},
OA = {gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000538328100056,
Author = {Butterworth, James and Savani, Rahul and Tuyls, Karl},
Book-Group-Author = {ACM},
Title = {Evolving Indoor Navigational Strategies Using Gated Recurrent Units In
   NEAT},
Booktitle = {PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE
   COMPANION (GECCCO'19 COMPANION)},
Year = {2019},
Pages = {111-112},
Note = {Genetic and Evolutionary Computation Conference (GECCO), Prague, CZECH
   REPUBLIC, JUL 13-17, 2019},
Abstract = {Simultaneous Localisation and Mapping (SLAM) algorithms are expensive to
   run on smaller robotic platforms such as Micro-Aerial Vehicles. Bug
   algorithms are an alternative that use relatively little processing
   power, and avoid high memory consumption by not building an explicit map
   of the environment. In this work we explore the performance of
   Neuroevolution - specifically NEAT - at evolving control policies for
   simulated differential drive robots carrying out generalised maze
   navigation. We compare this performance with respect to one particular
   bug algorithm known as I-Bug. We extend NEAT to include Gated Recurrent
   Units (GRUs) to help deal with long term dependencies. We show that both
   NEAT and our NEAT-GRU can repeatably generate controllers that
   outperform I-Bug on a test set of 209 indoor maze like environments. We
   show that NEAT-GRU is superior to NEAT in this task. Moreover, we show
   that out of the 2 systems, only NEAT-GRU can continuously evolve
   successful controllers for a much harder task in which no bearing
   information about the target is provided to the agent.},
Publisher = {ASSOC COMPUTING MACHINERY},
Address = {1515 BROADWAY, NEW YORK, NY 10036-9998 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Butterworth, J (Corresponding Author), Univ Liverpool, Liverpool, Merseyside, England.
   Butterworth, James; Savani, Rahul; Tuyls, Karl, Univ Liverpool, Liverpool, Merseyside, England.},
DOI = {10.1145/3319619.3321995},
ISBN = {978-1-4503-6748-6},
Keywords = {genetic algorithms; neuroevolution; NEAT; navigation; maze solving;
   gated recurrent units; memory},
Research-Areas = {Mathematics},
Web-of-Science-Categories  = {Mathematics, Interdisciplinary Applications},
Author-Email = {j.butterworth2@liverpool.ac.uk
   rahul.savani@liverpool.ac.uk
   k.tuyls@liverpool.ac.uk},
Affiliations = {University of Liverpool},
ORCID-Numbers = {Butterworth, James/0000-0002-6446-6577},
Cited-References = {Butterworth J, 2019, CORR.
   Dorigo Marco, 2013, IEEE Robotics \& Automation Magazine, V20, P60, DOI 10.1109/MRA.2013.2252996.
   McGuire K, 2018, CORR.
   Pinciroli C, 2012, SWARM INTELL-US, V6, P271, DOI 10.1007/s11721-012-0072-5.
   Rawal A, 2016, GECCO'16: PROCEEDINGS OF THE 2016 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P501, DOI 10.1145/2908812.2908941.
   Shorten D, 2015, LECT NOTES COMPUTER, P783.},
Number-of-Cited-References = {6},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP0XM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000538328100056},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000309167700143,
Author = {Courbon, Jonathan and Korrapati, Hemanth and Mezouar, Youcef},
Book-Group-Author = {IEEE},
Title = {Adaptive Visual Memory For Mobile Robot Navigation In Dynamic
   Environment},
DOI = {10.1109/IVS.2012.6232166},
Booktitle = {2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV)},
Year = {2012},
Pages = {873-878},
Note = {IEEE Intelligent Vehicles Symposium (IV), Alcala de Henares, SPAIN, JUN
   03-07, 2012},
Abstract = {A central clue for implementation of visual memory based navigation
   strategies relies on efficient point matching between the current image
   and the key images of the memory. However, the visual memory may become
   out of date after some times because the appearance of real-world
   environments keeps changing. It is thus necessary to remove obsolete
   information and to add new data to the visual memory over time. In this
   paper, we propose a method based on short-term and long term memory
   concepts to update the visual memory of mobile robots during navigation.
   The results of our experiments show that using this method improves the
   robustness of the localization and path-following steps.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Courbon, J (Corresponding Author), Inst Pascal, 24 Ave Landais, F-63171 Aubiere, France.
   Courbon, Jonathan; Korrapati, Hemanth; Mezouar, Youcef, Inst Pascal, F-63171 Aubiere, France.},
ISBN = {978-1-4673-2118-1},
Keywords-Plus = {LOCALIZATION; VISION; SLAM},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering;
   Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Transportation
   Science \& Technology},
Author-Email = {jonathan.courbon@lasmea.univ-bpclermont.fr
   hemanth.korrapati@lasmea.univ-bpclermont.fr
   youcef.mezouar@lasmea.univ-bpclermont.fr},
ORCID-Numbers = {mezouar, youcef/0000-0001-8138-3928},
Cited-References = {Andreasson H, 2007, ROBOT AUTON SYST, V55, P541, DOI 10.1016/j.robot.2007.02.002.
   Atkinson R. L, 1968, PSYCHOL LEARNING MOT.
   Bacca B, 2010, ELECTRON LETT, V46, P1120, DOI 10.1049/el.2010.1599.
   Courbon J, 2009, IEEE T INTELL TRANSP, V10, P392, DOI 10.1109/TITS.2008.2012375.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   GOEDEME T, 2005, IEEE RSJ INT C INT R, P1806.
   Hochdorfer S, 2009, 14 INT C ADV ROB MUN.
   Lemaire T, 2007, INT J COMPUT VISION, V74, P343, DOI 10.1007/s11263-007-0042-3.
   Li HD, 2006, INT C PATT RECOG, P630.
   Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084.
   Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17.
   Reid I., 2007, ROBOTICS SCI SYSTEMS.
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y.
   Wangsiripitak S, 2009, IEEE INT CONF ROBOT, P705.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.},
Number-of-Cited-References = {15},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BBZ39},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000309167700143},
DA = {2022-05-17},
}

@inproceedings{ WOS:000379864100065,
Author = {Popp, Manuel and Atman, Jamal and Scholz, Georg and Ruppelt, Jan and
   Trommer, Gert F.},
Book-Group-Author = {Inst Navigat},
Title = {A Reduced Camera SLAM Approach for Indoor and Outdoor Navigation Using
   Laser Information for Landmark Initialization and Relative Motion
   Information},
DOI = {10.33012/2016.13452},
Booktitle = {PROCEEDINGS OF THE 2016 INTERNATIONAL TECHNICAL MEETING OF THE INSTITUTE
   OF NAVIGATION},
Series = {Proceedings of the International Technical Meeting of the Institute of
   Navigation},
Year = {2016},
Pages = {647-656},
Note = {47th Annual Precise Time and Time Interval Systems and Applications
   Meeting (PTTI) / International Technical Meeting of
   the-Institute-of-Navigation, Monterey, CA, JAN 25-28, 2016},
Abstract = {In order to allow Micro Areal Vehicles (MAVs) to autonomously explore
   urban areas a precise knowledge of the MAV's kinematic state is
   essential. Thus, an integrated navigation system is presented in this
   paper. It provides a precise self-localization in both; indoor and
   outdoor areas. In order to circumvent the disadvantages of common image
   or laser based navigation systems, the information from both sensors are
   fused together on an early stage. That means, laser rangefinder's
   distance measurements are referred to image pixels. This results in
   2.5-D images. But in order to do so, the pose between both sensors has
   to be known. Therefore a process that allows a calibration of the
   sensors' extrinsic parameters is presented in this paper. Our navigation
   filter bases on a reduced SLAM approach combined with relative motion
   measurements. Both elements benefit from the 2.5-D images. The scale
   factor of the relative translational motion can be simply measured,
   while the landmarks can be initialized instantaneously with precisely
   known depth. This results in a navigation system that provides precise
   and long-term stable navigation solutions, independently from structure
   and condition of the environment.},
Publisher = {INST NAVIGATION},
Address = {815 15TH ST NW, STE 832, WASHINGTON, DC 20005 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Popp, M (Corresponding Author), Karlsruhe Inst Technol, Inst Syst Optimizat ITE, Karlsruhe, Germany.
   Popp, Manuel; Atman, Jamal; Scholz, Georg; Ruppelt, Jan; Trommer, Gert F., Karlsruhe Inst Technol, Inst Syst Optimizat ITE, Karlsruhe, Germany.
   Trommer, Gert F., ITMO Univ, St Petersburg, Russia.},
ISSN = {2330-3646},
EISSN = {2330-3662},
Research-Areas = {Paleontology},
Web-of-Science-Categories  = {Paleontology},
Affiliations = {Helmholtz Association; Karlsruhe Institute of Technology; ITMO
   University},
Cited-References = {Bachrach Abraham, 2010, 2010 IEEE International Conference on Robotics and Automation (ICRA 2010), P1096, DOI 10.1109/ROBOT.2010.5509990.
   Bachrach A., 2011, J FIELD ROBOT, P1096.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bouguet J-Y., 2001, PYRAMIDAL IMPLEMENTA.
   Carrillo LRG, 2012, J INTELL ROBOT SYST, V65, P373, DOI 10.1007/s10846-011-9571-7.
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276.
   Crocoll P., 2013, P EUR NAV C, V11.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Fraundorfer F, 2012, IEEE INT C INT ROBOT, P4557, DOI 10.1109/IROS.2012.6385934.
   Frietsch N., 2012, THESIS.
   Ganhua Li, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3854, DOI 10.1109/IROS.2007.4399041.
   Grzonka S, 2009, IEEE INT CONF ROBOT, P1679.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Hoang VD, 2014, LECT NOTES COMPUT SC, V8397, P561, DOI 10.1007/978-3-319-05476-6\_57.
   Honegger D, 2013, IEEE INT CONF ROBOT, P1736, DOI 10.1109/ICRA.2013.6630805.
   Kneip L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P4546, DOI 10.1109/ICRA.2011.5980127.
   Kneip L., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2235, DOI 10.1109/IROS.2011.6048267.
   Lippiello V, 2011, IEEE DECIS CONTR P, P3566, DOI 10.1109/CDC.2011.6160577.
   Ma Y., 2003, INVITATION 3 D VISIO.
   Mourikis AI, 2007, IEEE T ROBOT, V23, P717, DOI 10.1109/TRO.2007.900610.
   Mourikis AI, 2006, IEEE INT CONF ROBOT, P2277, DOI 10.1109/ROBOT.2006.1642042.
   Popp M., 2014, P ION GNSS, P1784.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Roumeliotis S. I., 2006, TECHNICAL REPORT.
   Schauwecker K, 2014, J INTELL ROBOT SYST, V74, P1, DOI 10.1007/s10846-013-9907-6.
   Schmid K, 2014, J FIELD ROBOT, V31, P537, DOI 10.1002/rob.21506.
   Schmid K, 2013, IEEE INT C INT ROBOT, P3955, DOI 10.1109/IROS.2013.6696922.
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7.
   Tomic T, 2012, IEEE ROBOT AUTOM MAG, V19, P46, DOI 10.1109/MRA.2012.2206473.
   Yaghobi M, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P1850, DOI 10.1109/ROBIO.2009.4913283.
   Zhang Q., 2004, 2004 IEEERSJ INT C I, V3, P2301, DOI {[}10.1109/IROS.2004.1389752, DOI 10.1109/IROS.2004.1389752].},
Number-of-Cited-References = {31},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BF0XR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000379864100065},
DA = {2022-05-17},
}

@inproceedings{ WOS:000434349200108,
Author = {Van Opdenbosch, Dominik and Aykut, Tamay and Oelsch, Martin and Alt,
   Nicolas and Steinbach, Eckehard},
Book-Group-Author = {IEEE},
Title = {Efficient Map Compression for Collaborative Visual SLAM},
Booktitle = {2018 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION (WACV
   2018)},
Series = {IEEE Winter Conference on Applications of Computer Vision},
Year = {2018},
Pages = {992-1000},
Note = {18th IEEE Winter Conference on Applications of Computer Vision (WACV),
   NV, MAR 12-15, 2018},
Abstract = {Swarm robotics is receiving increasing interest, because the
   collaborative completion of tasks, such as the exploration of unknown
   environments, leads to improved performance and reduced effort. The
   ability to exchange map information is an essential requirement for
   collaborative exploration. When moving to large-scale environments,
   where the communication data rate between the swarm participants is
   typically limited, efficient compression algorithms and an approach for
   discarding less informative parts of the map are key for a successful
   long-term operation. In this paper, we present a novel compression
   approach for environment maps obtained from a visual SLAM system. We
   apply feature coding to the visual information to compress the map
   efficiently. We make use of a minimum spanning tree to connect all
   features that serve as observations of a single map point. Thereby, we
   can exploit inter-feature dependencies and obtain an optimal coding
   order. Additionally, we add a map sparsification step to keep only
   useful map points by solving a linear integer programming problem, which
   preserves the map points that exhibit both good compression properties
   and high observability. We evaluate the proposed method on a standard
   dataset and show that our approach outperforms state-of-the-art
   techniques.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Van Opdenbosch, D (Corresponding Author), Tech Univ Munich, Chair Media Technol, Munich, Germany.
   Van Opdenbosch, Dominik; Aykut, Tamay; Oelsch, Martin; Alt, Nicolas; Steinbach, Eckehard, Tech Univ Munich, Chair Media Technol, Munich, Germany.},
DOI = {10.1109/WACV.2018.00114},
ISSN = {2472-6737},
ISBN = {978-1-5386-4886-5},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic},
Author-Email = {dominik.van-opdenbosch@tum.de
   eckehard.steinbach@tum.de},
Affiliations = {Technical University of Munich},
ResearcherID-Numbers = {Aykut, Tamay/E-8936-2017},
ORCID-Numbers = {Aykut, Tamay/0000-0002-8497-9521},
Funding-Acknowledgement = {space agency of the German Aerospace Center; Federal Ministry of
   Economics and Technology of the German Bundestag {[}50NA1515]},
Funding-Text = {This work is supported by the space agency of the German Aerospace
   Center with funds from the Federal Ministry of Economics and Technology
   on the basis of a resolution of the German Bundestag under the reference
   50NA1515.},
Cited-References = {Baroffio L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2445294.
   Baroffio L, 2014, IEEE T IMAGE PROCESS, V23, P2262, DOI 10.1109/TIP.2014.2312617.
   Burri M., 2016, INT J ROBOT RES, V35, P1.
   Cheng WT, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2623488.
   Cieslewski T, 2015, IEEE INT CONF ROBOT, P6241, DOI 10.1109/ICRA.2015.7140075.
   Contreras Luis, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4509, DOI 10.1109/ICRA.2017.7989523.
   Contreras L, 2015, IEEE INT C INT ROBOT, P133, DOI 10.1109/IROS.2015.7353365.
   Duan LY, 2016, IEEE T IMAGE PROCESS, V25, P179, DOI 10.1109/TIP.2015.2500034.
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673.
   Dymczyk M, 2015, IEEE INT C INT ROBOT, P2536, DOI 10.1109/IROS.2015.7353722.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   G. O. Inc, 2017, GUROBI OPTIMIZER REF.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Huiskes M. J., 2008, P 1 INT ACM C MULT I, P39, DOI DOI 10.1145/1460096.1460104.
   Karp R.M., 1972, COMPLEXITY COMPUTER, P85, DOI DOI 10.1007/978-1-4684-2001-2\_9.
   Klein George, 2007, P1.
   Kruskal JB., 1956, AM MATH SOC, V7, P48, DOI {[}10.1090/s0002-9939-1956-0078686-7, 10.1090/S0002-9939-1956-0078686-7].
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lynen Simon, 2015, ROBOTICS SCI SYSTEMS, VXI.
   Merzic Hamza, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3200, DOI 10.1109/ICRA.2017.7989363.
   MURARTAL R, 2017, IEEE T ROBOTICS, P1, DOI DOI 10.1109/TR0.2017.2705103.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Opdenbosch D. V., 2017, IEEE C VIS COMM IM P.
   Park HS, 2013, IEEE COMPUT SOC CONF, P229, DOI 10.1109/CVPRW.2013.41.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.},
Number-of-Cited-References = {28},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BK2ZI},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000434349200108},
DA = {2022-05-17},
}

@article{ WOS:000733469200001,
Author = {Zhang, Kaining and Jiang, Xingyu and Ma, Jiayi},
Title = {Appearance-Based Loop Closure Detection via Locality-Driven Accurate
   Motion Field Learning},
Journal = {IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS},
Year = {2022},
Volume = {23},
Number = {3},
Pages = {2350-2365},
Month = {MAR},
Abstract = {Loop closure detection (LCD) is of significant importance in
   simultaneous localization and mapping. It represents the robot's ability
   to recognize whether the current surrounding corresponds to a previously
   observed one. In this paper, we conduct this task in a two-step
   strategy: candidate frame selection and loop closure verification. The
   first step aims to search semantically similar images for the query one
   using features obtained by Key.Net with HardNet. Instead of adopting the
   traditional Bag-of-Words strategy, we utilize the aggregated selective
   match kernel to calculate the similarity between images. Subsequently,
   based on the potential property of motion field in the LCD scene, we
   propose a novel feature matching method, i.e., exploiting the smoothness
   prior and learning the motion field for an image pair in a reproducing
   kernel Hilbert space (RKHS), to implement loop closure verification.
   Concretely, we formulate the learning problem into a Bayesian framework
   with latent variables indicating the true/false correspondences and a
   mixture model accounting for the distribution of data. Furthermore, we
   propose a locality-driven mechanism to enhance the local relevance of
   motion vectors and term the algorithm as locality-driven accurate motion
   field learning (LAL). To satisfy the requirement of efficiency in the
   LCD task, we use a sparse approximation and search a suboptimal solution
   for the motion field in the RKHS, termed as LAL{*}. Extensive
   experiments are conducted on public datasets for feature matching and
   LCD tasks. The quantitative results demonstrate the effectiveness of our
   method over the current state-of-the-art, meanwhile showing its
   potential for long-term visual localization. The codes of LAL and LAL{*}
   are publicly available at https://github.com/KN-Zhang/LAL.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Ma, JY (Corresponding Author), Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.
   Zhang, Kaining; Jiang, Xingyu; Ma, Jiayi, Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.},
DOI = {10.1109/TITS.2021.3086822},
EarlyAccessDate = {JUN 2021},
ISSN = {1524-9050},
EISSN = {1558-0016},
Keywords = {Feature extraction; Liquid crystal displays; Visualization; Task
   analysis; Robots; Simultaneous localization and mapping; Kernel; SLAM;
   loop closure detection; place recognition; feature matching; autonomous
   vehicle},
Keywords-Plus = {PLACE RECOGNITION; FAB-MAP; IMAGE; LOCALIZATION; KERNELS; VISION;
   SEARCH; SCALE; SLAM},
Research-Areas = {Engineering; Transportation},
Web-of-Science-Categories  = {Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology},
Author-Email = {zkn19961212@whu.edu.cn
   jiangx.y@whu.edu.cn
   jyma2010@gmail.com},
Affiliations = {Wuhan University},
ORCID-Numbers = {Zhang, Kaining/0000-0002-2033-2307
   Jiang, Xingyu/0000-0001-9790-8856
   Ma, Jiayi/0000-0003-3264-3265},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61773295]; Key Research
   and Development Program of Hubei Province {[}2020BAB113]; Natural
   Science Foundation of Hubei Province {[}2019CFA037]},
Funding-Text = {This work was supported in part by the National Natural Science
   Foundation of China under Grant 61773295, in part by the Key Research
   and Development Program of Hubei Province under Grant 2020BAB113, and in
   part by the Natural Science Foundation of Hubei Province under Grant
   2019CFA037. The Associate Editor for this article was T.-H. Kim.},
Cited-References = {An S., 2020, ARXIV201011703.
   An S, 2019, IEEE INT C INT ROBOT, P378, DOI 10.1109/IROS40897.2019.8968043.
   Andrew AM, 2001, KYBERNETES.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Bampis L, 2018, INT J ROBOT RES, V37, P62, DOI 10.1177/0278364917740639.
   Barroso-Laguna A, 2019, IEEE I CONF COMP VIS, P5835, DOI 10.1109/ICCV.2019.00593.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302.
   Bingyi Cao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P726, DOI 10.1007/978-3-030-58565-5\_43.
   Blanco JL, 2009, AUTON ROBOT, V27, P327, DOI 10.1007/s10514-009-9138-7.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Choy CB, 2016, ADV NEUR IN, V29.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Nguyen DD, 2019, IEEE T INTELL TRANSP, V20, P4103, DOI 10.1109/TITS.2018.2881556.
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Garcia-Fidalgo Emilio, 2018, IEEE Robotics and Automation Letters, V3, P3051, DOI 10.1109/LRA.2018.2849609.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Han J, 2019, IEEE T INTELL TRANSP, V20, P4415, DOI 10.1109/TITS.2018.2885341.
   Jegou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57.
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9.
   Jiang XY, 2020, IEEE T IMAGE PROCESS, V29, P736, DOI 10.1109/TIP.2019.2934572.
   Kazmi SMAM, 2019, IEEE T ROBOT, V35, P1352, DOI 10.1109/TRO.2019.2926475.
   Khan S, 2015, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2015.7139959.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Li XR, 2010, INT J COMPUT VISION, V89, P1, DOI 10.1007/s11263-010-0318-x.
   Liu HR, 2010, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2010.5539780.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Luo ZX, 2020, PROC CVPR IEEE, P6588, DOI 10.1109/CVPR42600.2020.00662.
   Ma JY, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01359-2.
   Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI 10.1007/s11263-018-1117-z.
   Ma JY, 2019, IEEE T NEUR NET LEAR, V30, P3584, DOI 10.1109/TNNLS.2018.2872528.
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478.
   MacQueen J.B., 1967, P 5 BERKELEY S MATH, P281.
   Mishchuk A., 2017, ADV NEURAL INFORM PR, P4826.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374.
   Perronnin F, 2007, PROC CVPR IEEE, P2272.
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300.
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649.
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77.
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4.
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832.
   Tsintotas KA, 2019, IEEE ROBOT AUTOM LET, V4, P1737, DOI 10.1109/LRA.2019.2897151.
   Tsintotas KA, 2018, IEEE INT CONF ROBOT, P5979, DOI 10.1109/ICRA.2018.8461146.
   Wang TH, 2018, IEEE INT CONF ROBOT, P2341.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Xia YF, 2016, IEEE IJCNN, P2274, DOI 10.1109/IJCNN.2016.7727481.
   Yan JC, 2016, IEEE T PATTERN ANAL, V38, P1228, DOI 10.1109/TPAMI.2015.2477832.
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4\_28.
   Yu J, 2020, IEEE T NEUR NET LEAR, V31, P661, DOI 10.1109/TNNLS.2019.2908982.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.
   Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81.
   Zhou B., 2014, P ADV NEUR INF PROC, P487, DOI DOI 10.1162/153244303322533223.},
Number-of-Cited-References = {64},
Times-Cited = {3},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {8},
Journal-ISO = {IEEE Trans. Intell. Transp. Syst.},
Doc-Delivery-Number = {ZR6BI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000733469200001},
DA = {2022-05-17},
}

@article{ WOS:000329510300004,
Author = {Churchill, Winston and Newman, Paul},
Title = {Experience-based navigation for long-term localisation},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1645-1661},
Month = {DEC},
Abstract = {This paper is about long-term navigation in environments whose
   appearance changes over time, suddenly or gradually. We describe,
   implement and validate an approach which allows us to incrementally
   learn a model whose complexity varies naturally in accordance with
   variation of scene appearance. It allows us to leverage the state of the
   art in pose estimation to build over many runs, a world model of
   sufficient richness to allow simple localisation despite a large
   variation in conditions. As our robot repeatedly traverses its
   workspace, it accumulates distinct visual experiences that in concert,
   implicitly represent the scene variation: each experience captures a
   visual mode. When operating in a previously visited area, we continually
   try to localise in these previous experiences while simultaneously
   running an independent vision-based pose estimation system. Failure to
   localise in a sufficient number of prior experiences indicates an
   insufficient model of the workspace and instigates the laying down of
   the live image sequence as a new distinct experience. In this way, over
   time we can capture the typical time-varying appearance of an
   environment and the number of experiences required tends to a constant.
   Although we focus on vision as a primary sensor throughout, the ideas we
   present here are equally applicable to other sensor modalities. We
   demonstrate our approach working on a road vehicle operating over a
   3-month period at different times of day, in different weather and
   lighting conditions. We present extensive results analysing different
   aspects of the system and approach, in total processing over 136,000
   frames captured from 37 km of driving.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Churchill, W (Corresponding Author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.
   Churchill, Winston; Newman, Paul, Univ Oxford, Mobile Robot Grp, Oxford OX1 3PJ, England.},
DOI = {10.1177/0278364913499193},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Localisation; mobile and distributed robotics; SLAM; mapping; field
   robots; field and service robotics},
Keywords-Plus = {TRACKING},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {winston.churchill@eng.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
Funding-Acknowledgement = {EPSRC {[}EP/I005021/1]; Oxford Technologies Ltd.; BAE SYSTEMS;
   Engineering and Physical Sciences Research Council {[}EP/J012017/1,
   EP/I005021/1] Funding Source: researchfish; EPSRC {[}EP/J012017/1]
   Funding Source: UKRI},
Funding-Text = {Winston Churchill is supported by an EPSRC Case Studentship with Oxford
   Technologies Ltd. Paul Newman is supported by an EPSRC Leadership
   Fellowship (number EP/I005021/1). This work has also been supported by
   BAE SYSTEMS.},
Cited-References = {Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Biber P, 2005, P IEEE ROB SCI SYST.
   Borrmann D, 2010, IEEE INT C INT ROB S.
   Burgard W, 2007, SPRINGER TRACTS ADV, V35, P27.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Cummins M., 2009, ROBOTICS SCI SYSTEMS.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Konolige K, 2007, INT S RES ROB ISRR.
   Lategahn H, 2012, P IEEE INT C VEH EL.
   McManus C., 2012, P IEEE INT C ROB AUT.
   Mei C, 2008, IEEE T ROBOT, V24, P1352, DOI 10.1109/TRO.2008.2007941.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275.
   Schindler K, 2010, ISPRS J PHOTOGRAMM, V65, P523, DOI 10.1016/j.isprsjprs.2010.06.006.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Taneja A, 2011, P IEEE INT C COMP VI.
   Wolf D, 2004, P IEEE INT C ROB AUT.},
Number-of-Cited-References = {22},
Times-Cited = {121},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300004},
DA = {2022-05-17},
}

@inproceedings{ WOS:000224151200036,
Author = {Pacis, EB and Everett, HR and Farrington, N and Bruemmer, D},
Editor = {Gerhart, GR and Shoemaker, CM and Gage, DW},
Title = {Enhancing functionality and autonomy in man-portable robots},
Booktitle = {UNMANNED GROUND VEHICLE TECHNOLOGY VI},
Series = {PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)},
Year = {2004},
Volume = {5422},
Pages = {355-366},
Note = {Conference on Unmanned Ground Vehicle Technology VI, Orlando, FL, APR
   13-15, 2004},
Abstract = {Current man-portable robotic systems are too heavy for troops to pack
   during extended missions in rugged terrain and typically require more
   user support than can be justified by their limited return in force
   multiplication or improved effectiveness. As a consequence, today's
   systems appear organically attractive only in life-threatening
   scenarios, such as detection of chemical/biological/radiation hazards,
   mines, or improvised explosive devices. For the long term, significant
   improvements in both functionality (i.e., perform more useful tasks) and
   autonomy (i.e., with less human intervention) are required to increase
   the level of general acceptance and, hence, the number of units deployed
   by the user. In the near term, however, the focus must remain on robust
   and reliable solutions that reduce risk and save lives. Ibis paper
   describes ongoing efforts to address these needs through a spiral
   development process that capitalizes on technology transfer to harvest
   applicable results of prior and ongoing activities throughout the
   technical community.},
Publisher = {SPIE-INT SOC OPTICAL ENGINEERING},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pacis, EB (Corresponding Author), Space \& Naval Warfare Syst Ctr, San Diego, CA USA.
   Space \& Naval Warfare Syst Ctr, San Diego, CA USA.},
DOI = {10.1117/12.553020},
ISSN = {0277-786X},
ISBN = {0-8194-5345-5},
Keywords = {robotics; sensors; autonomy; localization; mapping; SLAM;
   communications; technology transfer},
Research-Areas = {Automation \& Control Systems; Robotics; Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics; Transportation Science \&
   Technology},
Affiliations = {Naval Information Warfare Center Pacific},
Cited-References = {BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032.
   BRUCH MH, 2002, AUVSI UNMANNED SYSTE.
   BURGARD W, 1996, 13 NAT C ART INT, P896.
   CARROLL DM, 2004, 3039 SPAC NAV WARF S.
   Dellaert Frank, 1999, IEEE INT C ROB AUT I.
   Everett HR, 2003, IEEE INSTRU MEAS MAG, V6, P30, DOI 10.1109/MIM.2003.1251480.
   EVERETT HR, WARFIGHTERS ASS ELIM.
   FOX D, 1999, 16 NAT C ART INT AAA.
   FOX D, 2003, MULTIROBOT SYSTEMS S, V2.
   FOX D, 2001, ADV NEURAL INFORMATI.
   Gerkey B., 2003, 11 INT C ADV ROB ICA.
   Gilbert DR, 2001, BUS ETHICS Q, V11, P1, DOI 10.2307/3857865.
   GUTMAN JS, 1999, CIRCA 99.
   HANDSCHIN JE, 1970, AUTOMATICA, V6.
   KOGUT G, 2003, AUVSI UNM SYST INT S.
   Konolige K, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 \& 2, P1154.
   KONOLIGE K, UNPUB AAAAI04.
   LAIRD RT, 1990, 17 ANN TECHN S EXH A, P280.
   Lu F., 1997, AUTONOMOUS ROBOTS, V4.
   MORAVEC HP, 1985, 1985 IEEE INT C ROB, P116.
   MULLENS K, 2004, ROBOTICS UPDATE, V4.
   {*}OFF SECR DEF ACQ, JOINT ARCH UNM SYST.
   Ojeda L, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P317, DOI 10.1109/ROBOT.2002.1013380.
   OJEDA L, 2003, 0301 U MICH DEP MECH.
   SIMMONS R, OBSTACLE AVOIDANCE S.
   {*}SPAC NAV WARF SYS, AUT MOB COMM REL PRO.
   {*}SPAC NAV WARF SYS, MOB DET ASS RESP SYS.
   {*}SPAC NAV WARF SYS, MAN PORT ROB SYST PR.
   STEWART B, 2003, REVISITING PROBLEM M.
   Thrun S, 2001, INT J ROBOT RES, V20, P335, DOI 10.1177/02783640122067435.
   ULRICH I, 1998, IEEE INT C ROB AUT I.
   JOINT ROBOTICS PROGR.
   ROBOTICS INTELLIGENT.},
Number-of-Cited-References = {33},
Times-Cited = {5},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BAX98},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000224151200036},
DA = {2022-05-17},
}

@article{ WOS:000509509300001,
Author = {Giubilato, Riccardo and Vayugundla, Mallikarjuna and Schuster, Martin J.
   and Stuerzl, Wolfgang and Wedler, Armin and Triebel, Rudolph and Debei,
   Stefano},
Title = {Relocalization With Submaps: Multi-Session Mapping for Planetary Rovers
   Equipped With Stereo Cameras},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2020},
Volume = {5},
Number = {2},
Pages = {580-587},
Month = {APR},
Abstract = {To enable long term exploration of extreme environments such as
   planetary surfaces, heterogeneous robotic teams need the ability to
   localize themselves on previously built maps. While the Localization and
   Mapping problem for single sessions can be efficiently solved with many
   state of the art solutions, place recognition in natural environments
   still poses great challenges for the perception system of a robotic
   agent. In this paper we propose a relocalization pipeline which exploits
   both 3D and visual information from stereo cameras to detect matches
   across local point clouds of multiple SLAM sessions. Our solution is
   based on a Bag of Binary Words scheme where binarized SHOT descriptors
   are enriched with visual cues to recall in a fast and efficient way
   previously visited places. The proposed relocalization scheme is
   validated on challenging datasets captured using a planetary rover
   prototype on Mount Etna, designated as a Moon analogue environment.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Giubilato, R (Corresponding Author), Univ Padua, CISAS Giuseppe Colombo, Via Venezia 15, I-35131 Padua, Italy.
   Giubilato, Riccardo; Debei, Stefano, Univ Padua, CISAS Giuseppe Colombo, Via Venezia 15, I-35131 Padua, Italy.
   Giubilato, Riccardo; Vayugundla, Mallikarjuna; Schuster, Martin J.; Stuerzl, Wolfgang; Wedler, Armin; Triebel, Rudolph, German Aerosp Ctr DLR, Inst Robot \& Mechatron, Munchener Str 20, D-82234 Wessling, Germany.},
DOI = {10.1109/LRA.2020.2964157},
ISSN = {2377-3766},
Keywords = {Localization; space robotics and automation; mapping},
Keywords-Plus = {PLACE RECOGNITION; LOCALIZATION; DESCRIPTOR},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {riccardo.giubilato@gmail.com
   Mallikarjuna.Vayugundla@dlr.de
   martin.schuster@dlr.de
   wolfgang.stuerzl@dlr.de
   armin.wedler@dlr.de
   rudolph.triebel@dlr.de
   stefano.debei@unipd.it},
Affiliations = {University of Padua; Helmholtz Association; German Aerospace Centre
   (DLR)},
ResearcherID-Numbers = {Triebel, Rudolph/ABG-8692-2020
   },
ORCID-Numbers = {Triebel, Rudolph/0000-0002-7975-036X
   Debei, Stefano/0000-0002-6757-6616
   Schuster, Martin/0000-0002-6983-3719
   GIUBILATO, Riccardo/0000-0002-3161-3171
   Vayugundla, Mallikarjuna/0000-0002-9277-0461},
Funding-Acknowledgement = {Helmholtz Association, project alliance ROBEX {[}HA-304]; Helmholtz
   Association, project ARCHES {[}ZT-0033]},
Funding-Text = {This work was supported by Helmholtz Association, project alliance ROBEX
   (contract number HA-304) and project ARCHES (contract number ZT-0033).},
Cited-References = {Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244.
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207.
   Brand C, 2014, IEEE INT C INT ROBOT, P1846, DOI 10.1109/IROS.2014.6942805.
   Burki M., 2019, ARXIV190204343.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Chiodini S, 2018, IEEE INT CONF ROBOT, P897, DOI 10.1109/ICRA.2018.8462865.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dewan A, 2018, IEEE INT C INT ROBOT, P4774, DOI 10.1109/IROS.2018.8594420.
   Dube Renaud, 2018, IEEE Robotics and Automation Letters, V3, P1832, DOI 10.1109/LRA.2018.2803213.
   Dube  R., 2018, P ROB SCI SYST.
   Forster C, 2013, IEEE INT C INT ROBOT, P3971, DOI 10.1109/IROS.2013.6696924.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376.
   Gawel A, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY AND RESCUE ROBOTICS (SSRR), P27, DOI 10.1109/SSRR.2017.8088136.
   Gojcic Z., 2018, ARXIV181106879.
   Guo JD, 2019, IEEE ROBOT AUTOM LET, V4, P1470, DOI 10.1109/LRA.2019.2893887.
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y.
   Lehner H, 2017, IEEE INT C INT ROBOT, P6191, DOI 10.1109/IROS.2017.8206521.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maffra F, 2019, IEEE ROBOT AUTOM LET, V4, P1525, DOI 10.1109/LRA.2019.2895826.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Petrelli A, 2011, IEEE I CONF COMP VIS, P2244, DOI 10.1109/ICCV.2011.6126503.
   Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013.
   Prakhya SM, 2017, AUTON ROBOT, V41, P1501, DOI 10.1007/s10514-016-9612-y.
   Schlegel D, 2019, IEEE INT CONF ROBOT, P5488, DOI 10.1109/ICRA.2019.8793753.
   Schlegel D, 2018, IEEE ROBOT AUTOM LET, V3, P3741, DOI 10.1109/LRA.2018.2856542.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   Schuster MJ, 2019, J INTELL ROBOT SYST, V93, P461, DOI 10.1007/s10846-017-0680-9.
   Schuster MJ, 2019, J FIELD ROBOT, V36, P305, DOI 10.1002/rob.21812.
   Steder B, 2011, IEEE INT C INT ROBOT, P1249, DOI 10.1109/IROS.2011.6048325.
   Surmann H, 2017, IEEE INT C INT ROBOT, P626, DOI 10.1109/IROS.2017.8202217.
   Tombari F., 2010, 4 PAC RIM S IM VID T, P349, DOI DOI 10.1109/PSIVT.2010.65.
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679.
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1\_26.
   Wedler A., 2018, P 69 INT ASTR C.
   Wedler A., 2017, P 68 INT ASTR C.
   Yew ZJ, 2018, LECT NOTES COMPUT SC, V11219, P630, DOI 10.1007/978-3-030-01267-0\_37.},
Number-of-Cited-References = {37},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {30},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {KF8TL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000509509300001},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000671855400017,
Author = {Bouaziz, Youssef and Royer, Eric and Bresson, Guillaume and Dhome,
   Michel},
Book-Group-Author = {IEEE},
Title = {Keyframes retrieval for robust long-term visual localization in changing
   conditions},
Booktitle = {2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND
   INFORMATICS (SAMI 2021)},
Year = {2021},
Pages = {93-100},
Note = {19th IEEE World Symposium on Applied Machine Intelligence and
   Informatics (SAMI), SLOVAKIA, JAN 21-23, 2021},
Abstract = {Appearance changes are a challenge for visual localization in outdoor
   environments. Revisiting familiar places but retrieving keyframes that
   were taken under different environmental condition can result in
   inaccurate localization. To overcome this difficulty, we propose a
   localization approach able to take advantage of a visual landmark map
   composed of N sequences gathered at different times and conditions.
   During this localization process, we exploit information collected in
   the beginning of the trajectory to compute a ranking function which will
   be used in the rest of the trajectory to retrieve from the map the
   keyframes that maximise the number of matched points. The retrieval
   depends on the geometric distance between the pose of the keyframe and
   the current pose of the vehicle, and the similarity of this keyframe
   with the current environmental condition. The results demonstrate that
   our approach has significantly improved localization performance in
   challenging conditions (snow, rain, change of season . . .).},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bouaziz, Y (Corresponding Author), Clermont Auvergne Univ, Inst Pascal, Clermont Ferrand, France.
   Bouaziz, Youssef; Royer, Eric; Dhome, Michel, Clermont Auvergne Univ, Inst Pascal, Clermont Ferrand, France.
   Bresson, Guillaume, Inst VEDECOM, Versailles, France.},
DOI = {10.1109/SAMI50585.2021.9378614},
ISBN = {978-1-7281-8053-3},
Keywords = {Visual-Based Navigation; Computer Vision for Transportation; SLAM},
Keywords-Plus = {EXPERIENCE},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications},
Author-Email = {youssef.bouaziz@etu.uca.fr
   eric.royer@uca.fr
   guillaume.bresson@vedecom.fr
   michel.dhome@uca.fr},
Funding-Acknowledgement = {French government research program ``Investissements d'Avenir{''}
   through the IMobS3 Laboratory of Excellence {[}ANR-10-LABX-16-01];
   European Union through the Regional Competitiveness and Employment
   program 2014-2020 (ERDF - AURA region); AURA region},
Funding-Text = {This work has been sponsored by the French government research program
   ``Investissements d'Avenir{''} through the IMobS3 Laboratory of
   Excellence (ANR-10-LABX-16-01), by the European Union through the
   Regional Competitiveness and Employment program 2014-2020 (ERDF - AURA
   region) and by the AURA region.},
Cited-References = {Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Burki Mathias, 2018, 2018 IEEE Intelligent Vehicles Symposium (IV), P682, DOI 10.1109/IVS.2018.8500432.
   Burki M, 2019, J FIELD ROBOT, V36, P1041, DOI 10.1002/rob.21870.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Diaz-Escobar J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3758102.
   Harris C. G., 1988, ALVEY VISION C, P1, DOI DOI 10.5244/C.2.23.
   Lebraly Pierre, 2011, 2011 IEEE International Conference on Robotics and Automation, P221.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   MacTavish K, 2018, J FIELD ROBOT, V35, P1265, DOI 10.1002/rob.21838.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murillo A C, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552.
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305.
   Pepperell E, 2016, INT J ROBOT RES, V35, DOI 10.1177/0278364915618766.
   Piasco N, 2019, IEEE INT CONF ROBOT, P9094, DOI 10.1109/ICRA.2019.8794221.
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127.
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4\_28.},
Number-of-Cited-References = {24},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BR8FY},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000671855400017},
DA = {2022-05-17},
}

@inproceedings{ WOS:000771405405079,
Author = {Thomas, Hugues and Agro, Ben and Gridseth, Mona and Zhang, Jian and
   Barfoot, Timothy D.},
Book-Group-Author = {IEEE},
Title = {Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor
   Navigation},
Booktitle = {2021 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA
   2021)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2021},
Pages = {14047-14053},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Xian,
   PEOPLES R CHINA, MAY 30-JUN 05, 2021},
Abstract = {We present a self-supervised learning approach for the semantic
   segmentation of lidar frames. Our method is used to train a deep point
   cloud segmentation architecture without any human annotation. The
   annotation process is automated with the combination of simultaneous
   localization and mapping (SLAM) and ray-tracing algorithms. By
   performing multiple navigation sessions in the same environment, we are
   able to identify permanent structures, such as walls, and disentangle
   short-term and long-term movable objects, such as people and tables,
   respectively. New sessions can then be performed using a network trained
   to predict these semantic labels. We demonstrate the ability of our
   approach to improve itself over time, from one session to the next. With
   semantically filtered point clouds, our robot can navigate through more
   complex scenarios, which, when added to the training pool, help to
   improve our network predictions. We provide insights into our network
   predictions and show that our approach can also improve the performances
   of common localization techniques.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Thomas, H (Corresponding Author), Univ Toronto, Inst Aerosp Studies UTIAS, 4925 Dufferin St, Toronto, ON, Canada.
   Thomas, Hugues; Agro, Ben; Gridseth, Mona; Barfoot, Timothy D., Univ Toronto, Inst Aerosp Studies UTIAS, 4925 Dufferin St, Toronto, ON, Canada.
   Zhang, Jian, Apple Inc, Cupertino, CA 95014 USA.},
DOI = {10.1109/ICRA48506.2021.9561701},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-7281-9077-8},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {hugues.thomas@robotics.utias.utoronto.ca
   ben.agro@robotics.utias.utoronto.ca
   mona.gridseth@robotics.utias.utoronto.ca
   jianz@apple.com
   tim.barfoot@utoronto.ca},
Affiliations = {University of Toronto; Apple Inc},
Cited-References = {Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
   Brooks CA, 2012, J FIELD ROBOT, V29, P445, DOI 10.1002/rob.21408.
   Chen XYL, 2019, IEEE INT C INT ROBOT, P4530, DOI 10.1109/IROS40897.2019.8967704.
   Deschaud JE, 2018, IEEE INT CONF ROBOT, P2480.
   Dewan A, 2017, IEEE INT C INT ROBOT, P3544, DOI 10.1109/IROS.2017.8206198.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Fox D, 2003, INT J ROBOT RES, V22, P985, DOI 10.1177/0278364903022012001.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hadsell R, 2009, J FIELD ROBOT, V26, P120, DOI 10.1002/rob.20276.
   Hornung A., 2003, AUTON ROBOT, V34, P189.
   Lookingbill A, 2007, INT J COMPUT VISION, V74, P287, DOI 10.1007/s11263-006-0024-x.
   Mendes E, 2016, IEEE INT SYMP SAFE, P195, DOI 10.1109/SSRR.2016.7784298.
   Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
   Nava M, 2019, IEEE ROBOT AUTOM LET, V4, P1279, DOI 10.1109/LRA.2019.2894849.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Pomerleau F, 2014, IEEE INT CONF ROBOT, P3712, DOI 10.1109/ICRA.2014.6907397.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Ridge B, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/59654.
   Sofman B, 2006, J FIELD ROBOT, V23, P1059, DOI 10.1002/rob.20169.
   Sun L, 2018, IEEE ROBOT AUTOM LET, V3, P3749, DOI 10.1109/LRA.2018.2856268.
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651.
   Wang K, 2019, IEEE INT CONF ROBOT, P5224, DOI 10.1109/ICRA.2019.8793499.
   Zhang J., 2014, ROBOT SCI SYST, V2, P9.
   Zhang L, 2018, IEEE ACCESS, V6, P75545, DOI {[}10.1109/ACCESS.2018.2873617, 10.1109/TCBB.2018.2848633].},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS8DT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000771405405079},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000276080401050,
Author = {Lidoris, Georgios and Rohrmueller, Florian and Wollherr, Dirk and Buss,
   Martin},
Book-Group-Author = {IEEE},
Title = {The Autonomous City Explorer (ACE) Project - Mobile Robot Navigation in
   Highly Populated Urban Environments},
DOI = {10.1109/ROBOT.2009.5152534},
Booktitle = {ICRA: 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION,
   VOLS 1-7},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2009},
Pages = {2238-2244},
Note = {IEEE International Conference on Robotics and Automation, Kobe, JAPAN,
   MAY 12-17, 2009},
Abstract = {One of the greatest challenges nowadays in robotics is the advancement
   of robots from industrial tools to companions and helpers of humans,
   operating in natural, populated environments. In this respect, the
   Autonomous City Explorer (ACE) project aims to combine the research
   fields of autonomous mobile robot navigation and human robot
   interaction. A robot has been created that is capable of navigating in
   an unknown, highly populated, urban environment, based only on
   information extracted through interaction with passers-by and its local
   perception capabilities.
   This paper describes the algorithms and architecture that make up the
   navigation subsystem of ACE. More specifically, the algorithms used for
   Simultaneous Localization and Mapping (SLAM), path planning in dynamic
   environments and behavior selection are presented, as well as the system
   architecture that integrates them to a complete working system. Results
   from an extended field experiment, where the robot navigated
   autonomously through the downtown city area of Munich, are analyzed and
   show that the robot is capable of long-term, safe navigation in
   real-world settings.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Lidoris, G (Corresponding Author), Tech Univ Munich, Fac Elect Engn, Inst Automat Control Engn LSR, D-80290 Munich, Germany.
   Lidoris, Georgios; Rohrmueller, Florian; Wollherr, Dirk; Buss, Martin, Tech Univ Munich, Fac Elect Engn, Inst Automat Control Engn LSR, D-80290 Munich, Germany.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4244-2788-8},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {georgios.lidoris@tum.de
   rohrmueller@tum.de
   dw@tum.de
   mb@tum.de},
Affiliations = {Technical University of Munich},
ResearcherID-Numbers = {Wollherr, Dirk/C-3925-2011},
ORCID-Numbers = {Wollherr, Dirk/0000-0003-2810-6790},
Cited-References = {BAUER A, 2009, P INT C ROB AUT.
   BEESON P, 2005, P INT C ROB AUT.
   Casals A, 1989, SENSOR DEVICES SYSTE.
   GRISETTI G, 2005, P INT C ROB AUT.
   GROSS HM, 2008, P INT C SYST MAN CYB.
   HAEHNEL D, 2003, P INT C INT ROB SYST.
   LIDORIS G, 2008, P INT C INT ROB SYST.
   LIDORIS G, 2007, P INT C INT ROB SYST.
   Muhlbauer Q., 2009, P INT C ROB AUT.
   PHILIPPSEN R, 2003, INT C ROB AUT.
   ROHRMULLER F, 2008, P INT C INT ROB SYST.
   Stachniss C., 2005, ROBOTICS SCI SYSTEMS.
   THRUN S, 2000, INT J ROBOTICS RES, V19.
   Thrun S., 2006, J ROBOT SYST, V23.
   Urmson C., 2008, J FIELD ROBOTICS, V25.
   YAMAUCHI B, 1998, INT C AUT AG.},
Number-of-Cited-References = {16},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BOB06},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000276080401050},
DA = {2022-05-17},
}

@inproceedings{ WOS:000284917000010,
Author = {Ascher, C. and Kessler, C. and Wankerl, M. and Trommer, G. F.},
Editor = {Trommer, GF},
Title = {Combining Laser Range Measurements and a Dual-IMU IPNS for Precise
   Indoor SLAM},
Pages = {10.1-10.17},
Booktitle = {SYMPOSIUM GYRO TECHNOLOGY 2009},
Series = {SYMPOSIUM GYRO TECHNOLOGY},
Year = {2009},
Note = {Symposium Gyro Technology 2009, Karlsruhe, GERMANY, SEP 22-23, 2009},
Abstract = {In this paper an Integrated Pedestrian Navigation System (IPNS) for
   indoor applications with mapping capabilities based on inertial sensors
   and laser measurements is presented. Our proposal is a Dual-IMU IPNS
   comprising two inertial measurement units (MEMS IMUs), mounted at the
   foot and the torso, a magnetometer, a barometer and a two-dimensional
   laser scanner. First results indicate that the combined
   Dual-IMU/magnetometer/barometer/laser system can meet the challenging
   requirements of pedestrian indoor navigation. With our approach
   centimetre accurate maps and a long-term stable navigation solution can
   be obtained while performing indoor missions. The capabilities of our
   approach are demonstrated using post-processed data obtained in
   real-world test scenarios.},
Publisher = {UNIV STUTTGART INST A FUR MECHANIK},
Address = {PFAFFENWALDRING 9, 70550 STUTTGART, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ascher, C (Corresponding Author), Univ Karlsruhe, Inst Syst Optimizat ITE, Kaiserstr 12, D-76128 Karlsruhe, Germany.
   Ascher, C.; Kessler, C.; Wankerl, M.; Trommer, G. F., Univ Karlsruhe, Inst Syst Optimizat ITE, D-76128 Karlsruhe, Germany.},
ISSN = {1439-4502},
Keywords-Plus = {SAFE NAVIGATION; MOBILE ROBOTS},
Research-Areas = {Automation \& Control Systems; Engineering; Instruments \&
   Instrumentation},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Affiliations = {Helmholtz Association; Karlsruhe Institute of Technology},
Cited-References = {Borges GA, 2000, INT C PATT RECOG, P441, DOI 10.1109/ICPR.2000.905371.
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903.
   Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140.
   Nguyen V, 2005, 2005 2nd IEEE International Conference on Group IV Photonics, P195.
   Nguyen V, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P664.
   Nguyen V, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5007, DOI 10.1109/IROS.2006.282527.
   OJEDA L, 2007, IEEE P INT WORKSH SA.
   SHIN SH, 2007, SAS 2007 IEEE SENS A.
   Victorino AC, 2003, INT J ROBOT RES, V22, P1019, DOI 10.1177/0278364903022012003.
   Victorino AC, 2003, INT J ROBOT RES, V22, P1005, DOI 10.1177/0278364903022012002.
   Wendel J., 2007, INTEGRIERTE NAVIGATI.},
Number-of-Cited-References = {11},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BSM38},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000284917000010},
DA = {2022-05-17},
}

@inproceedings{ WOS:000279793700080,
Author = {Farley, Greg and Chapman, Mark},
Book-Group-Author = {ION},
Title = {An Alternate Approach to GPS Denied Navigation based on Monocular SLAM
   Techniques},
Url = {https://www.ion.org/publications/abstract.cfm?articleID=7741},
Booktitle = {PROCEEDINGS OF THE 2008 NATIONAL TECHNICAL MEETING OF THE INSTITUTE OF
   NAVIGATION - NTM 2008},
Year = {2008},
Pages = {810-818},
Note = {2008 National Technical Meeting of the Institute-of-Navigation, San
   Diego, CA, JAN 28-30, 2008},
Abstract = {GPS denied navigation indoors, underground, on moving reference frames,
   and in urban canyons can be achieved in a practical approach suitable
   for use by the war fighter or emergency responder. Rockwell Collins is
   working to successfully advance the state of the art in robotic vision
   algorithms and coupled MEMS based dead reckoning modules to demonstrate
   accurate long term navigation in GPS denied environments. Significant
   efforts continue across the navigation industry to improve methods of
   correcting MEMS based dead reckoning modules to allow short term GPS
   denied navigation accuracy. The general approach of correcting or aiding
   the MEMS to create a navigation solution is hampered by several
   practical issues:
   Magnetic anomalies induce significant error conditions and distortions
   that cannot be predicted without a priori knowledge of the environment
   to be traversed.
   Angular rotation error propagates creating a linearly increasing
   navigation error. Correction of the heading errors requires extremely
   precise aiding in order to achieve practical navigation accuracy for
   more than a few minutes.
   Body stride estimation routines fail to accurately compensate for
   changing body postures and stride lengths that result from combat
   operations and intricate search and rescue activities.
   Rockwell Collins has addressed these issues by challenging the
   fundamental assumption that MEMS aiding will provide an acceptable
   solution. Instead, robotic vision algorithm based navigation is aided by
   the MEMS. Current robotic vision algorithms such as Simultaneous
   Location and Mapping (SLAM) are throughput intensive and are not
   practical for the dismounted user. The use of the MEMS provides
   excellent instantaneous sensor pointing information that reduces the
   SLAM processing requirements significantly. The use of Feature
   Constellation Tracking (FCT) algorithm improvements further reduce the
   processing requirements by allowing intelligent thinning of the features
   tracked. This paper will summarize the results of recent testing of a
   GPS denied brass board. The brass board was developed utilizing a single
   camera and inverse depth parameterization to allow accurate passive
   ranging to local landmarks. FCT software dynamically tracks up to 64
   features aided by a MEMS module. Monocular SLAM routines are used to
   compute real time navigation solutions. The test bed was evaluated both
   indoors and outdoors against known truth courses and provides startling
   results.},
Publisher = {INST NAVIGATION},
Address = {815 15TH ST NW, STE 832, WASHINGTON, DC 20005 USA},
Type = {Proceedings Paper},
Language = {English},
Research-Areas = {Computer Science; Remote Sensing; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Remote Sensing;
   Telecommunications},
Cited-References = {DAVISON A, P 9 INT C COMP VIS 2.
   DAVISON A, 2004, P IFAC S INT AUT VEH.
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615.
   LUCAS BD, 1981, P 7 INT JOINT C ART, P674.
   Montiel J.M.M., 2006, P ROB SCI SYST C PHI.
   Shi J., 1994, P IEEE C COMP VIS PA, P593, DOI DOI 10.1109/CVPR.1994.323794.
   Tomasi Carlo, 1991, CMUCS91132.},
Number-of-Cited-References = {7},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BPS62},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000279793700080},
DA = {2022-05-17},
}

@article{ WOS:000295437000013,
Author = {Bacca, B. and Salvi, J. and Cufi, X.},
Title = {Appearance-based mapping and localization for mobile robots using a
   feature stability histogram},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2011},
Volume = {59},
Number = {10},
Pages = {840-857},
Month = {OCT},
Abstract = {The strength of appearance-based mapping models for mobile robots lies
   in their ability to represent the environment through high-level image
   features and to provide human-readable information. However, developing
   a mapping and a localization method using these kinds of models is very
   challenging, especially if robots must deal with long-term mapping,
   localization, navigation, occlusions, and dynamic environments. In other
   words, the mobile robot has to deal with environmental appearance
   change, which modifies its representation of the environment. This paper
   proposes an indoor appearance-based mapping and a localization method
   for mobile robots based on the human memory model, which was used to
   build a Feature Stability Histogram (FSH) at each node in the robot
   topological map. This FSH registers local feature stability over time
   through a voting scheme, and the most stable features were considered
   for mapping, for Bayesian localization and for incrementally updating
   the current appearance reference view in the topological map. The
   experimental results are presented using an omnidirectional images
   dataset acquired over the long-term and considering: illumination
   changes (time of day, different seasons), occlusions, random removal of
   features, and perceptual aliasing. The results include a comparison with
   the approach proposed by Dayoub and Duckett (2008) {[}19] and the
   popular Bag-of-Words (Bazeille and Filliat, 2010) {[}35] approach. The
   obtained results confirm the viability of our method and indicate that
   it can adapt the internal map representation over time to localize the
   robot both globally and locally. (C) 2011 Elsevier B.V. All rights
   reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Bacca, B (Corresponding Author), Univ Girona, Campus Montilivi,Bldg PIV,Off 009, Girona 17071, Spain.
   Bacca, B.; Salvi, J.; Cufi, X., Univ Girona, Girona 17071, Spain.
   Bacca, B., Univ Valle, Cali 25360, Colombia.},
DOI = {10.1016/j.robot.2011.06.008},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Appearance-based; Localization and mapping; Topological maps;
   Omnidirectional vision},
Keywords-Plus = {IMAGES; SLAM},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {bladimir@eia.udg.edu
   qsalvi@eia.udg.edu
   xcuf@eia.udg.edu},
Affiliations = {Universitat de Girona; Universidad del Valle},
ResearcherID-Numbers = {Salvi, Joaquim/L-2648-2014
   },
ORCID-Numbers = {Salvi, Joaquim/0000-0002-9482-7126
   Bacca Cortes, Bladimir/0000-0003-0113-4134},
Funding-Acknowledgement = {Spanish project {[}DPI-2007-66796-C03-02]; LASPAU-COLCIENCIAS
   {[}136-2008]; University of Valle {[}644-19-04-95];  {[}SGR2005-01008]},
Funding-Text = {This work has been supported by the publicly funded Spanish project
   DPI-2007-66796-C03-02, the LASPAU-COLCIENCIAS grant 136-2008, the
   University of Valle contract 644-19-04-95, and the consolidated research
   group's grant SGR2005-01008.},
Cited-References = {ALY M, {[}No title captured].
   Andreasson H, 2008, IEEE T ROBOT, V24, P991, DOI 10.1109/TRO.2008.2004642.
   ANGELI A, 2008, INT ROB SYST IEEE RS, V1, P1031.
   Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI {[}10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3].
   Bacca B, 2010, ELECTRON LETT, V46, P1120, DOI 10.1049/el.2010.1599.
   BACCA B, 2010, IEEE RSJ INT C INT R, V1, P2053.
   Bacca B, 2009, FRONT ARTIF INTEL AP, V202, P55, DOI 10.3233/978-1-60750-061-2-55.
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Barber R, 2000, THESIS U CARLOS 3 MA.
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   BAZEILLE S, 2010, RAIRO OPERATIONS RES, P1.
   DAYOUB F, 2008, INT ROB SYST 2008 IR, V1, P3364.
   DURRANTWHYTE H, 2006, ROBOTICS AUTOMATION, V20, P99.
   GALLEGOS G, 2010, ROB AUT ICRA IEEE IN, V7, P3519.
   GALLEGOS G, 2010, ROB AUT ICRA IEEE IN, V3, P3519.
   Gaspar J, 2007, STUD COMPUT INTELL, V70, P223.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   GROSS HM, 2005, SYST MAN CYB 2005 IE, V4, P3510.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Linaker F, 2006, ROBOT AUTON SYST, V54, P205, DOI 10.1016/j.robot.2005.11.003.
   Llinas R., 2001, 1 VORTEX NEURONS SEL.
   MAGNUSSON M, 2009, ROB AUT ICRA IEEE IN, V1, P23.
   MARTINEZ O, 2006, P IEEE RSJ IROS WORK, P1742.
   Matsumoto Y., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P317, DOI 10.1109/IROS.1999.813023.
   Murillo AC, 2007, ROBOT AUTON SYST, V55, P372, DOI 10.1016/j.robot.2006.12.004.
   NEWMAN P, 2006, ROB AUT ICRA P IEEE, V1, P1180.
   Nieto J, 2007, ROBOT AUTON SYST, V55, P39, DOI 10.1016/j.robot.2006.06.008.
   Nilsback ME, 2006, P IEEE COMP SOC C CO, Vvol2, P1447.
   Nuchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001.
   Porta J. M., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3424.
   Porta JM, 2005, AUTON ROBOT, V18, P59, DOI 10.1023/B:AURO.0000047287.00119.b6.
   REMAZEILLES A, 2006, ROB AUT ICRA P IEEE, V1, P2719.
   SCARAMUZZA D, 2009, P IEEE INT C ROB AUT, V1, P4293.
   Segvic S, 2009, COMPUT VIS IMAGE UND, V113, P172, DOI 10.1016/j.cviu.2008.08.005.
   Sujan VA, 2006, AUTON ROBOT, V21, P15, DOI 10.1007/s10514-005-6066-z.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   ZHOU C, 2003, ROB AUT P ICRA IEEE, V1, P1271.
   ZIVKOVIC Z, 2006, ROB AUT 2006 ICRA 20, V1, P803.
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.},
Number-of-Cited-References = {41},
Times-Cited = {20},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {14},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {827OE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000295437000013},
DA = {2022-05-17},
}

@inproceedings{ WOS:000552238603077,
Author = {Zhang, Shengkai and Wang, Wei and Tang, Sheyang and Jin, Shi and Jiang,
   Tao},
Book-Group-Author = {IEEE},
Title = {Localizing Backscatters by a Single Robot With Zero Start-up Cost},
DOI = {10.1109/GLOBECOM38437.2019.9013768},
Pages = {1-6},
Booktitle = {2019 IEEE GLOBAL COMMUNICATIONS CONFERENCE (GLOBECOM)},
Series = {IEEE Global Communications Conference},
Year = {2019},
Note = {IEEE Global Communications Conference (GLOBECOM), Waikoloa, HI, DEC
   09-13, 2019},
Abstract = {Recent years have witnessed the rapid proliferation of low-power
   backscatter technologies that realize the ubiquitous and long-term
   connectivity to empower smart cities and smart homes. Localizing such
   low-power backscatter tags is crucial for IoT-based smart services.
   However, current backscatter localization systems require prior
   knowledge of the site, either a map or landmarks with known positions,
   increasing the deployment cost. To empower universal localization
   service, this paper presents Rover, an indoor localization system that
   simultaneously localizes multiple backscatter tags with zero start-up
   cost using a robot equipped with inertial sensors. Rover runs in a joint
   optimization framework, fusing WiFi-based positioning measurements with
   inertial measurements to simultaneously estimate the locations of both
   the robot and the connected tags. Our design addresses practical issues
   such as the interference among multiple tags and the real-time
   processing for solving the SLAM problem. We prototype Rover using
   off-the-shelf WiFi chips and customized backscatter tags. Our
   experiments show that Rover achieves localization accuracies of 39:3 cm
   for the robot and 74:6 cm for the tags.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhang, SK (Corresponding Author), Huazhong Univ Sci \& Technol, Sch Elect Informat \& Commun, Wuhan, Peoples R China.
   Zhang, Shengkai; Wang, Wei; Tang, Sheyang; Jiang, Tao, Huazhong Univ Sci \& Technol, Sch Elect Informat \& Commun, Wuhan, Peoples R China.
   Jin, Shi, Southeast Univ, Sch Informat Sci \& Engn, Nanjing, Peoples R China.},
ISSN = {2334-0983},
ISBN = {978-1-7281-0962-6},
Keywords = {Backscatter; localization; inertial sensor; channel state information},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {szhangk@hust.edu.cn
   weiwangw@hust.edu.cn
   sheyangtang@hust.edu.cn
   jinshi@seu.edu.cn
   taojiang@hust.edu.cn},
Affiliations = {Huazhong University of Science \& Technology; Southeast University -
   China},
ResearcherID-Numbers = {Jin, Shi/ABG-5416-2021},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2017YFE0121500]; NSFC {[}61871441,
   91738202, 61631015]; Young Elite Scientists Sponsorship Program by CAST
   {[}2018QNRC001]; Major Program of National Natural Science Foundation of
   Hubei in China {[}2016CFA009]; Key Laboratory of Dynamic Cognitive
   System of Electromagnetic Spectrum Space (Nanjing Univ. Aeronaut.
   Astronaut.), MIIT; Fundamental Research Funds for the Central
   Universities {[}2015ZDTD012]; Graduates' Innovation Fund of HUST
   {[}2019YGSCXCY009]},
Funding-Text = {The work was supported in part by National Key R\&D Program of China
   under Grant 2017YFE0121500, NSFC under Grant 61871441, 91738202,
   61631015, Young Elite Scientists Sponsorship Program by CAST with Grant
   2018QNRC001, Major Program of National Natural Science Foundation of
   Hubei in China with Grant 2016CFA009, Key Laboratory of Dynamic
   Cognitive System of Electromagnetic Spectrum Space (Nanjing Univ.
   Aeronaut. Astronaut.), MIIT, Fundamental Research Funds for the Central
   Universities with Grant number 2015ZDTD012, and Graduates' Innovation
   Fund of HUST with Grant 2019YGSCXCY009.},
Cited-References = {ElMossallamy MA, 2018, IEEE GLOB COMM CONF.
   Forster C, 2015, P ROB SCI SYST.
   Halperin D., 2011, ACM SIGCOMM COMPUT C.
   He YA, 2017, IEEE J SEL AREA COMM, V35, P1132, DOI 10.1109/JSAC.2017.2679659.
   Hessar M., 2019, USENIX P NSDI.
   Kellogg B, 2014, ACM SIGCOMM COMP COM, V44, P607, DOI {[}10.1145/2619239.2626319, 10.1145/2740070.2626319].
   Kotaru M., 2015, ACM P SIGCOMM.
   Kotaru M., 2017, ACM P CONEXT.
   Li J., 2018, IEEE P GLOBECOM.
   Lin Y, 2018, J FIELD ROBOT, V35, P23, DOI 10.1002/rob.21732.
   Lupton T, 2012, IEEE T ROBOT, V28, P61, DOI 10.1109/TRO.2011.2170332.
   Ma Y., 2017, ACM P SIGCOMM.
   Peng Y., 2018, ACM P SIGCOMM.
   Shen SJ, 2016, SPRINGER TRAC ADV RO, V109, P211, DOI 10.1007/978-3-319-23778-7\_15.
   Tang F, 2016, J SENSORS, V2016, DOI 10.1155/2016/3251632.
   Vasisht D., 2016, USENIX P NSDI.},
Number-of-Cited-References = {16},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP4GG},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000552238603077},
DA = {2022-05-17},
}

@article{ WOS:000781124000002,
Author = {Bouaziz, Youssef and Royer, Eric and Bresson, Guillaume and Dhome,
   Michel},
Title = {Map management for robust long-term visual localization of an autonomous
   shuttle in changing conditions},
Year = {2022},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Abstract = {Changes in appearance present a tremendous problem for the visual
   localization of an autonomous vehicle in outdoor environments. Data
   association between the current image and the landmarks in the map can
   be challenging in cases where the map was built with different
   environmental conditions. This paper introduces a solution to build and
   use multi-session maps incorporating sequences recorded in different
   conditions (day, night, fog, snow, rain, change of season, etc.). During
   visual localization, we exploit a ranking function to extract the most
   relevant keyframes from the map. This ranking function is designed to
   take into account the pose of the vehicle as well as the current
   environmental condition. In the mapping phase, covering all conditions
   by constantly adding data to the map leads to a continuous growth in the
   map size which in turn deteriorates the localization speed and
   performance. Our map management strategy is an incremental approach that
   aims to limit the size of the map while keeping it as diverse as
   possible. Our experiments were performed on real data collected with our
   autonomous shuttle as well as on a widely used public dataset. The
   results demonstrate that our keyframe-based ranking function is suitable
   for long-term scenarios. Our map management algorithm aims to build a
   map with as much diversity as possible whereas some state of the art
   approaches tend to filter out the less observed landmarks. This strategy
   shows a reduction of localization failures while maintaining real-time
   performance.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Bouaziz, Y (Corresponding Author), Inst VEDECOM, Inst Pascal, CNRS, Versailles, France.
   Bouaziz, Youssef, Inst VEDECOM, Inst Pascal, CNRS, Versailles, France.
   Royer, Eric; Dhome, Michel, Inst Pascal, SIGMA Clermont, CNRS, Clermont Ferrand, France.
   Bresson, Guillaume, Inst VEDECOM, Versailles, France.},
DOI = {10.1007/s11042-021-11870-4},
EarlyAccessDate = {APR 2022},
ISSN = {1380-7501},
EISSN = {1573-7721},
Keywords = {Visual-based navigation; Computer vision for transportation; SLAM},
Keywords-Plus = {EXPERIENCE},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic},
Author-Email = {youssef.bouaziz@etu.uca.fr
   eric.royer@uca.fr
   guillaume.bresson@vedecom.fr
   michel.dhome@uca.fr},
Affiliations = {Centre National de la Recherche Scientifique (CNRS); Centre National de
   la Recherche Scientifique (CNRS); Universite Clermont Auvergne (UCA)},
Funding-Acknowledgement = {French government research program ``Investissements d'Avenir{''}
   through the IMobS3 Laboratory of Excellence {[}ANR-10-LABX-16-01];
   French government research program ``Investissements d'Avenir{''}
   through the RobotEx Equipment of Excellence {[}ANR-10-EQPX-44]; European
   Union through the Regional Competitiveness and Employment program
   2014-2020 (ERDF - AURA region); AURA region},
Funding-Text = {This work has been sponsored by the French government research program
   ``Investissements d'Avenir{''} through the IMobS3 Laboratory of
   Excellence (ANR-10-LABX-16-01) and the RobotEx Equipment of Excellence
   (ANR-10-EQPX-44), by the European Union through the Regional
   Competitiveness and Employment program 2014-2020 (ERDF - AURA region)
   and by the AURA region.},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Berrio JS, 2019, IEEE INT VEH SYM, P1166, DOI 10.1109/IVS.2019.8814289.
   Bouaziz Y, 2021, 18 INT C INF CONTR A.
   Bouaziz Y, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), P93, DOI 10.1109/SAMI50585.2021.9378614.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Burki M, 2018, IEEE INT VEH SYM, P682.
   Burki M, 2019, J FIELD ROBOT, V36, P1041, DOI 10.1002/rob.21870.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Chen C, 2020, ARXIV200612567.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Clark R, 2017, PROC CVPR IEEE, P2652, DOI 10.1109/CVPR.2017.284.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Diaz-Escobar J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3758102.
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828.
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Gridseth M, 2020, IEEE INT CONF ROBOT, P1674, DOI 10.1109/ICRA40945.2020.9197362.
   Halodova L, 2019, IEEE INT C INT ROBOT, P7033, DOI 10.1109/IROS40897.2019.8967994.
   Harris C. G., 1988, ALVEY VISION C, P1, DOI DOI 10.5244/C.2.23.
   Jatzkowski I, 2018, IEEE INT C INTELL TR, P2030, DOI 10.1109/ITSC.2018.8569692.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Krajnik T, 2019, IEEE ROBOT AUTOM LET, V4, P3310, DOI 10.1109/LRA.2019.2926682.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Laskar Z, 2017, IEEE INT CONF COMP V, P920, DOI 10.1109/ICCVW.2017.113.
   Lebraly Pierre, 2011, 2011 IEEE International Conference on Robotics and Automation, P221.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   MacTavish K, 2018, J FIELD ROBOT, V35, P1265, DOI 10.1002/rob.21838.
   Maddern W, 2020, ARXIV200210152.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Magnago V, 2019, IEEE T INSTRUM MEAS, V68, P4443, DOI 10.1109/TIM.2018.2887071.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murillo A C, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552.
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305.
   Pascoe G, 2017, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2017.158.
   Pepperell E, 2016, INT J ROBOT RES, V35, DOI 10.1177/0278364915618766.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Royer E, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2248, DOI 10.1109/ITSC.2016.7795919.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721.
   Stenborg E, 2020, INT CONF 3D VISION, P938, DOI 10.1109/3DV50981.2020.00104.
   Tian YR, 2019, PROC CVPR IEEE, P11008, DOI 10.1109/CVPR.2019.01127.
   Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75.
   Yan Z, 2020, IEEE INT C INT ROBOT, P10697, DOI 10.1109/IROS45743.2020.9341406.
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4\_28.},
Number-of-Cited-References = {50},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Multimed. Tools Appl.},
Doc-Delivery-Number = {0K9RK},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000781124000002},
DA = {2022-05-17},
}

@inproceedings{ WOS:000714033803090,
Author = {Qin, Tong and Chen, Tongqing and Chen, Yilun and Su, Qing},
Book-Group-Author = {IEEE},
Title = {AVP-SLAM: Semantic Visual Mapping and Localization for Autonomous
   Vehicles in the Parking Lot},
Booktitle = {2020 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2020},
Pages = {5939-5945},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, OCT 24-JAN 24, 2020-2021},
Abstract = {Autonomous valet parking is a specific application for autonomous
   vehicles. In this task, vehicles need to navigate in narrow, crowded and
   GPS-denied parking lots. Accurate localization ability is of great
   importance. Traditional visual-based methods suffer from tracking lost
   due to texture-less regions, repeated structures, and appearance
   changes. In this paper, we exploit robust semantic features to build the
   map and localize vehicles in parking lots. Semantic features contain
   guide signs, parking lines, speed bumps, etc, which typically appear in
   parking lots. Compared with traditional features, these semantic
   features are long-term stable and robust to the perspective and
   illumination change. We adopt four surround-view cameras to increase the
   perception range. Assisting by an IMU (Inertial Measurement Unit) and
   wheel encoders, the proposed system generates a global visual semantic
   map. This map is further used to localize vehicles at the centimeter
   level. We analyze the accuracy and recall of our system and compare it
   against other methods in real experiments. Furthermore, we demonstrate
   the practicability of the proposed system by the autonomous parking
   application.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Qin, T (Corresponding Author), Huawei Technol, IAS BU, Shanghai, Peoples R China.
   Qin, Tong; Chen, Tongqing; Chen, Yilun; Su, Qing, Huawei Technol, IAS BU, Shanghai, Peoples R China.},
DOI = {10.1109/IROS45743.2020.9340939},
ISSN = {2153-0858},
ISBN = {978-1-7281-6212-6},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {qintong@huawei.com
   chentongqing@huawei.com
   chengyilun@huawei.com
   suqing@huawei.com},
Affiliations = {Huawei Technologies},
Cited-References = {Badrinarayanan V., 2015, ARXIV150507293.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Jeong J, 2017, IEEE INT VEH SYM, P1736, DOI 10.1109/IVS.2017.7995958.
   Kitt B, 2010, IEEE INT VEH SYM, P486, DOI 10.1109/IVS.2010.5548123.
   Klein George, 2007, P1.
   Le Gentil C, 2019, IEEE INT CONF ROBOT, P6388, DOI 10.1109/ICRA.2019.8794429.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Lu Y, 2017, IEEE INT VEH SYM, P468, DOI 10.1109/IVS.2017.7995762.
   Lynen S., GET OUT MY LAB LARGE.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Qin T, 2018, IEEE INT CONF ROBOT, P1197.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Ranganathan A, 2013, IEEE INT C INT ROBOT, P921, DOI 10.1109/IROS.2013.6696460.
   Rehder E, 2015, IEEE INT VEH SYM, P1393, DOI 10.1109/IVS.2015.7225910.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509.
   Yin H, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE-RCAR 2020), P1, DOI 10.1109/RCAR49640.2020.9303291.
   Zhang J., 2014, ROBOT SCI SYST, V2, P9.},
Number-of-Cited-References = {25},
Times-Cited = {6},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BS3PB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000714033803090},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000494942303113,
Author = {Wang, Kai and Lin, Yimin and Wang, Luowei and Han, Liming and Hua,
   Minjie and Wang, Xiang and Lian, Shiguo and Huang, Bill},
Editor = {Howard, A and Althoefer, K and Arai, F and Arrichiello, F and Caputo, B and Castellanos, J and Hauser, K and Isler, V and Kim, J and Liu, H and Oh, P and Santos, V and Scaramuzza, D and Ude, A and Voyles, R and Yamane, K and Okamura, A},
Book-Group-Author = {IEEE},
Title = {A Unified Framework for Mutual Improvement of SLAM and Semantic
   Segmentation},
DOI = {10.1109/ICRA.2019.8793499},
Booktitle = {2019 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2019},
Pages = {5224-5230},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Montreal, CANADA, MAY 20-24, 2019},
Abstract = {This paper presents a novel framework for simultaneously implementing
   localization and segmentation, which are two of the most important
   vision-based tasks for robotics. While the goals and techniques used for
   them were considered to be different previously, we show that by making
   use of the intermediate results of the two modules, their performance
   can be enhanced at the same time. Our framework is able to handle both
   the instantaneous motion and long-term changes of instances in
   localization with the help of the segmentation result, which also
   benefits from the refined 3D pose information. We conduct experiments on
   various datasets, and prove that our framework works effectively on
   improving the precision and robustness of the two tasks and outperforms
   existing localization and segmentation algorithms.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wang, K (Corresponding Author), CloudMinds Technol Inc, Beijing 100102, Peoples R China.
   Wang, Kai; Lin, Yimin; Wang, Luowei; Han, Liming; Hua, Minjie; Wang, Xiang; Lian, Shiguo; Huang, Bill, CloudMinds Technol Inc, Beijing 100102, Peoples R China.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-5386-6026-3},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {kai.wang@cloudminds.com
   anson.lin@cloudminds.com
   luowei.wang@cloudminds.com
   liming.han@cloudminds.com
   michael.hua@cloudminds.com
   xiang.wang@cloudminds.com
   scott.lian@cloudminds.com
   bill@cloudminds.com},
Cited-References = {Badrinarayanan V., 2015, ARXIV151100561.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Chen L.C., 2018, ARXIV180202611.
   Chen L.C., 2017, ARXIV170605587.
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184.
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261.
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343.
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510.
   GIRSHICK R, 2014, PROC CVPR IEEE, P580, DOI DOI 10.1109/CVPR.2014.81.
   Guo YM, 2018, INT J MULTIMED INF R, V7, P87, DOI 10.1007/s13735-017-0141-z.
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0\_20.
   He Kaiming, 2018, IEEE T PATTERN ANAL.
   Kaneko M., 2018, P IEEE C COMP VIS PA, P258.
   Klappstein J, 2009, LECT NOTES COMPUT SC, V5414, P611.
   Klein George, 2007, P1.
   Li Y., 2016, ARXIV161107709.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Liu Peidong, 2018, P IEEE INT C ROB AUT.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Qiu ZF, 2018, IEEE T MULTIMEDIA, V20, P939, DOI 10.1109/TMM.2017.2759504.
   Reddy ND, 2015, IEEE INT C INT ROBOT, P1897, DOI 10.1109/IROS.2015.7353626.
   Ren SQ, 2015, ADV NEUR IN, V28.
   Saputra MRU, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3177853.
   Shah S., 2017, ARXIV.
   Shi XS, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P802, DOI 10.1109/IAEAC.2015.7428667.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Wu T, 2018, IEEE SIGNAL PROC LET, V25, P1196, DOI 10.1109/LSP.2018.2849590.
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660.
   Zhong FW, 2018, IEEE WINT CONF APPL, P1001, DOI 10.1109/WACV.2018.00115.},
Number-of-Cited-References = {31},
Times-Cited = {7},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BO1CN},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000494942303113},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000766269000035,
Author = {Dexheimer, Eric and Peluse, Patrick and Chen, Jianhui and Pritts, James
   and Kaess, Michael},
Title = {Information-Theoretic Online Multi-Camera Extrinsic Calibration},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2022},
Volume = {7},
Number = {2},
Pages = {4757-4764},
Month = {APR},
Abstract = {Calibration of multi-camera systems is essential for lifelong use of
   vision-based headsets and autonomous robots. In this work, we present an
   information-based framework for online extrinsic calibration of
   multi-camera systems. While previous work largely focuses on monocular,
   stereo, or strictly non-overlapping field-of-view (FoV) setups, we allow
   arbitrary configurations while also exploiting overlapping pairwise FoV
   when possible. In order to efficiently solve for the extrinsic
   calibration parameters, which increase linearly with the number of
   cameras, we propose a novel entropy-based keyframe measure and bound the
   backend optimization complexity by selecting informative motion segments
   that minimize the maximum entropy across all extrinsic parameter
   partitions. We validate the pipeline on three distinct platforms to
   demonstrate the generality of the method for resolving the extrinsics
   and performing downstream tasks. Our code is available at
   https://github.com/edexheim/info\_ext\_calib.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Dexheimer, E (Corresponding Author), Carnegie Mellon Univ CMU, Inst Robot, Pittsburgh, PA 15213 USA.
   Dexheimer, Eric; Kaess, Michael, Carnegie Mellon Univ CMU, Inst Robot, Pittsburgh, PA 15213 USA.
   Peluse, Patrick; Chen, Jianhui, Facebook Real Labs FRL, Pittsburgh, PA 15222 USA.
   Pritts, James, Chalmers Univ Technol, SE-41296 Gothenburg, Sweden.},
DOI = {10.1109/LRA.2022.3145061},
ISSN = {2377-3766},
Keywords = {SLAM; calibration and identification},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {edex99@gmail.com
   ppeluse@fb.com
   jchen2020@fb.com
   jbpritts@gmail.com
   kaess@cmu.edu},
Affiliations = {Chalmers University of Technology},
ORCID-Numbers = {Kaess, Michael/0000-0002-7590-3357},
Funding-Acknowledgement = {Facebook Reality Labs (Pittsburgh, PA); U.S. Army Research Office; U.S.
   Army Futures Command {[}W911NF-20-D-0002]},
Funding-Text = {This work was supported by Facebook Reality Labs (Pittsburgh, PA). The
   CMU authors were partly supported by the U.S. Army Research Office and
   in part by the U.S. Army Futures Command under Contract
   W911NF-20-D-0002.},
Cited-References = {Bishop C.M., 2006, PATTERN RECOGN.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Carrera G, 2011, IEEE INT CONF ROBOT, P2652, DOI 10.1109/ICRA.2011.5980294.
   Dang T, 2009, IEEE T IMAGE PROCESS, V18, P1536, DOI 10.1109/TIP.2009.2017824.
   Das A, 2015, IEEE INT C INT ROBOT, P3676, DOI 10.1109/IROS.2015.7353891.
   Eckenhoff K, 2019, IEEE INT CONF ROBOT, P3158, DOI 10.1109/ICRA.2019.8793886.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Hartley R., 2003, MULTIPLE VIEW GEOMET.
   Heng L, 2015, AUTON ROBOT, V39, P259, DOI 10.1007/s10514-015-9466-8.
   Heng L, 2013, IEEE INT C INT ROBOT, P1793, DOI 10.1109/IROS.2013.6696592.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Jaekel J, 2020, IEEE INT C INT ROBOT, P4623, DOI 10.1109/IROS45743.2020.9341604.
   Keivan N, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1590, DOI 10.1109/ROBIO.2014.7090561.
   Keivan N, 2015, IEEE INT CONF ROBOT, P5775, DOI 10.1109/ICRA.2015.7140008.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Kuo JC, 2020, IEEE INT CONF ROBOT, P2116.
   Lee GH, 2014, PROC CVPR IEEE, P540, DOI 10.1109/CVPR.2014.76.
   Ling YG, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1771, DOI 10.1109/IROS.2016.7759283.
   Liu PD, 2018, IEEE INT C INT ROBOT, P1154, DOI 10.1109/IROS.2018.8593561.
   Lucas B. D, 1981, P 7 INT JOINT C ART, V2.
   Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17.
   Nobre Fernando, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6525, DOI 10.1109/ICRA.2017.7989771.
   Nobre F, 2018, P INT S EXP ROB, P737.
   Ouyang ZP, 2020, IEEE INT CONF ROBOT, P4990, DOI 10.1109/ICRA40945.2020.9197127.
   Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520.
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Schneider Thomas, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6487, DOI 10.1109/ICRA.2017.7989766.
   Schneider T, 2019, IEEE SENS J, V19, P3846, DOI 10.1109/JSEN.2019.2893809.
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718.},
Number-of-Cited-References = {31},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {ZP2QI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000766269000035},
DA = {2022-05-17},
}

@article{ WOS:000479244400001,
Author = {Burki, Mathias and Cadena, Cesar and Gilitschenski, Igor and Siegwart,
   Roland and Nieto, Juan},
Title = {Appearance-based landmark selection for visual localization},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2019},
Volume = {36},
Number = {6},
Pages = {1041-1073},
Month = {SEP},
Abstract = {Visual localization in outdoor environments is subject to varying
   appearance conditions rendering it difficult to match current camera
   images against a previously recorded map. Although it is possible to
   extend the respective maps to allow precise localization across a wide
   range of differing appearance conditions, these maps quickly grow in
   size and become impractical to handle on a mobile robotic platform. To
   address this problem, we present a landmark selection algorithm that
   exploits appearance co-observability for efficient visual localization
   in outdoor environments. Based on the appearance condition inferred from
   recently observed landmarks, a small fraction of landmarks useful under
   the current appearance condition is selected and used for localization.
   This allows to greatly reduce the bandwidth consumption between the
   mobile platform and a map backend in a shared-map scenario, and
   significantly lowers the demands on the computational resources on said
   mobile platform. We derive a landmark ranking function that exhibits
   high performance under vastly changing appearance conditions and is
   agnostic to the distribution of landmarks across the different map
   sessions. Furthermore, we relate and compare our proposed
   appearance-based landmark ranking function to popular ranking schemes
   from information retrieval, and validate our results on the challenging
   University of Michigan North Campus long-term vision and LIDAR data sets
   (NCLT), including an evaluation of the localization accuracy using
   ground-truth poses. In addition to that, we investigate the
   computational and bandwidth resource demands. Our results show that by
   selecting 20-30\% of landmarks using our proposed approach, a similar
   localization performance as the baseline strategy using all landmarks is
   achieved.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Burki, M (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Burki, Mathias; Cadena, Cesar; Siegwart, Roland; Nieto, Juan, Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Gilitschenski, Igor, MIT, Comp Sci \& Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.},
DOI = {10.1002/rob.21870},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {landmark selection; long-term localization; multisession mapping; visual
   localization; wheeled robots},
Keywords-Plus = {RECOGNITION; NAVIGATION; SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mathias.buerki@mavt.ethz.ch},
Affiliations = {ETH Zurich; Massachusetts Institute of Technology (MIT)},
ResearcherID-Numbers = {Cadena, Cesar/AAM-4987-2020
   },
ORCID-Numbers = {Cadena, Cesar/0000-0002-2972-6011
   Burki, Mathias/0000-0002-6988-9990},
Cited-References = {Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3.
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715.
   Bay H., 2006, EUR C COMP VIS, P404.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Burgard W, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2089, DOI 10.1109/IROS.2009.5354691.
   Burki Mathias, 2018, 2018 IEEE Intelligent Vehicles Symposium (IV), P682, DOI 10.1109/IVS.2018.8500432.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Clement L, 2017, J FIELD ROBOT, V34, P74, DOI 10.1002/rob.21655.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Dymczyk M, 2015, IEEE INT C INT ROBOT, P2536, DOI 10.1109/IROS.2015.7353722.
   Hochdorfer S., 2009, INTENSIVMED, P1.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Lategahn H, 2014, IEEE INT VEH SYM, P756, DOI 10.1109/IVS.2014.6856421.
   Li FY, 2006, IEEE INT CONF ROBOT, P3405, DOI 10.1109/ROBOT.2006.1642222.
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   MacTavish Kirk, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2065, DOI 10.1109/ICRA.2017.7989238.
   Maddern W., 2014, P VIS PLAC REC CHANG, V2, P5.
   McManus C., 2014, SCENE SIGNATURES LOC.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   Milford M., 2005, P AUSTR C ROB AUT 20, P1.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2004, IEEE INT CONF ROBOT, P403, DOI 10.1109/ROBOT.2004.1307183.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Muhlfellner P., 2015, DESIGNING RELATIONAL.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Paton M, 2015, IEEE INT CONF ROBOT, P1519, DOI 10.1109/ICRA.2015.7139391.
   Prasser D, 2006, SPRINGER TRAC ADV RO, V25, P143.
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0.
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302.
   Schindler G., 2007, 2007 IEEE C COMP VIS, P1.
   Stumm E, 2015, IEEE INT CONF ROBOT, P5475, DOI 10.1109/ICRA.2015.7139964.},
Number-of-Cited-References = {38},
Times-Cited = {6},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {31},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {IO2XF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000479244400001},
DA = {2022-05-17},
}

@article{ WOS:000629028400047,
Author = {Oelsch, Martin and Karimi, Mojtaba and Steinbach, Eckehard},
Title = {R-LOAM: Improving LiDAR Odometry and Mapping With Point-to-Mesh Features
   of a Known 3D Reference Object},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {2},
Pages = {2068-2075},
Month = {APR},
Abstract = {LiDAR-based odometry and mapping is used in many robotic applications to
   retrieve the robot's position in an unknown environment and allows for
   autonomous operation in GPS-denied (e.g., indoor) environments. With a
   3D LiDAR sensor, highly accurate localization becomes possible, which
   enables high quality 3D reconstruction of the environment. In this
   letter we extend the well-known LOAM framework by leveraging prior
   knowledge about a reference object in the environment to further improve
   the localization accuracy. This requires a known 3D model of the
   reference object and its known position in a global coordinate frame.
   Instead of only relying on the point features in the mapping module of
   LOAM, we also include mesh features extracted from the 3D triangular
   mesh of the reference object in the optimization problem. For fast
   correspondence computation of mesh features, we use the
   Axis-Aligned-Bounding-Box-Tree (AABB) structure. Essentially, our
   approach not only makes use of the previously built map for absolute
   localization in the environment, but also takes the relative position to
   the reference object into account, effectively reducing long-term drift.
   To validate the proposed concept, we generated datasets using the Gazebo
   simulation environment in exemplary visual inspection scenarios of an
   airplane inside a hangar and the Eiffel Tower. An actuated 3D LiDAR
   sensor is mounted via a 1-DoF gimbal on a UAV capturing 360 degrees
   scans. We benchmark our approach against the state-of-the-art
   open-source LOAM framework. The results show that the proposed joint
   optimization using both point and mesh features yields a significant
   reduction in Absolute Pose Error (APE) and therefore improves the map
   and 3D reconstruction quality during long-term operations.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Oelsch, M (Corresponding Author), Tech Univ Munich, Dept Elect \& Comp Engn, Chair Media Technol, D-80333 Munich, Germany.
   Oelsch, Martin; Karimi, Mojtaba; Steinbach, Eckehard, Tech Univ Munich, Dept Elect \& Comp Engn, Chair Media Technol, D-80333 Munich, Germany.},
DOI = {10.1109/LRA.2021.3060413},
ISSN = {2377-3766},
Keywords = {SLAM; localization; mapping; range sensing},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {martin.oelsch@tum.de
   mojtaba.karimi@tum.de
   Eckehard.Steinbach@tum.de},
Affiliations = {Technical University of Munich},
ResearcherID-Numbers = {cao, xiaoxiang/AAR-9291-2021
   },
ORCID-Numbers = {Steinbach, Eckehard/0000-0001-8853-2703
   Karimi, Mojtaba/0000-0003-1358-4431},
Funding-Acknowledgement = {space agency of the German Aerospace Center; Federal Ministry of
   Economics, and Technology of theGerman Bundestag {[}20X1707 C]},
Funding-Text = {This work was supported by the space agency of the German Aerospace
   Center with funds from the Federal Ministry of Economics, and Technology
   on the basis of a resolution of theGerman Bundestag under the reference
   20X1707 C.},
Cited-References = {Boniardi F, 2019, ROBOT AUTON SYST, V112, P84, DOI 10.1016/j.robot.2018.11.003.
   Boniardi F, 2017, IEEE INT C INT ROBOT, P3318, DOI 10.1109/IROS.2017.8206168.
   Conte G, 2008, AEROSP CONF PROC, P3142.
   Debeunne C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072068.
   Deschaud JE, 2018, IEEE INT CONF ROBOT, P2480.
   Droeschel D, 2018, IEEE INT CONF ROBOT, P5000, DOI 10.1109/ICRA.2018.8461000.
   Gawel A, 2019, IEEE INT C INT ROBOT, P2300, DOI 10.1109/IROS40897.2019.8967733.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Graeter J, 2018, IEEE INT C INT ROBOT, P7872, DOI 10.1109/IROS.2018.8594394.
   Herbers P, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204260.
   Hery E., 2018, LIDAR BASED RELATIVE.
   Hery E, 2019, IEEE INT VEH SYM, P1219, DOI 10.1109/IVS.2019.8813880.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Ito S, 2014, IEEE INT CONF ROBOT, P417, DOI 10.1109/ICRA.2014.6906890.
   Jacobson A., 2018, LIBIGL ASIMPLEC GEOM.
   Korah T, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P710.
   Kummerle R, 2011, AUTON ROBOT, V30, P25, DOI 10.1007/s10514-010-9204-1.
   Kumar GA, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061268.
   Leung KYK, 2008, IEEE INT CONF ROBOT, P551, DOI 10.1002/9780470696712.ch27.
   Mielle M, 2019, ROBOTICS, V8, DOI 10.3390/robotics8020040.
   Opromolla R, 2016, INT CONF UNMAN AIRCR, P649, DOI 10.1109/ICUAS.2016.7502580.
   Parsley MP, 2011, IEEE INT CONF ROBOT, P2638.
   Sandy T, 2016, IEEE INT CONF ROBOT, P2852, DOI 10.1109/ICRA.2016.7487449.
   Seo Y, 2019, IEEE INT VEH SYM, P1118, DOI 10.1109/IVS.2019.8814164.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Winterhalter W, 2015, IEEE INT C INT ROBOT, P3138, DOI 10.1109/IROS.2015.7353811.
   Xiong T, 2014, BIOMED CIRC SYST C, P9, DOI 10.1109/BioCAS.2014.6981632.
   Zhang J, 2015, IEEE INT CONF ROBOT, P2174, DOI 10.1109/ICRA.2015.7139486.},
Number-of-Cited-References = {28},
Times-Cited = {4},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {27},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {QX0GT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000629028400047},
DA = {2022-05-17},
}

@article{ WOS:000342795200003,
Author = {Williams, Stephen and Indelman, Vadim and Kaess, Michael and Roberts,
   Richard and Leonard, John J. and Dellaert, Frank},
Title = {Concurrent filtering and smoothing: A parallel architecture for
   real-time navigation and full smoothing},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2014},
Volume = {33},
Number = {12},
Pages = {1544-1568},
Month = {OCT},
Abstract = {We present a parallelized navigation architecture that is capable of
   running in real-time and incorporating long-term loop closure
   constraints while producing the optimal Bayesian solution. This
   architecture splits the inference problem into a low-latency update that
   incorporates new measurements using just the most recent states
   (filter), and a high-latency update that is capable of closing long
   loops and smooths using all past states (smoother). This architecture
   employs the probabilistic graphical models of factor graphs, which
   allows the low-latency inference and high-latency inference to be viewed
   as sub-operations of a single optimization performed within a single
   graphical model. A specific factorization of the full joint density is
   employed that allows the different inference operations to be performed
   asynchronously while still recovering the optimal solution produced by a
   full batch optimization. Due to the real-time, asynchronous nature of
   this algorithm, updates to the state estimates from the high-latency
   smoother will naturally be delayed until the smoother calculations have
   completed. This architecture has been tested within a simulated aerial
   environment and on real data collected from an autonomous ground
   vehicle. In all cases, the concurrent architecture is shown to recover
   the full batch solution, even while updated state estimates are produced
   in real-time.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Indelman, V (Corresponding Author), Coll Comp, Inst Robot \& Intelligent Machines, 801 Atlantic Dr, Atlanta, GA 30309 USA.
   Williams, Stephen; Indelman, Vadim; Roberts, Richard; Dellaert, Frank, Georgia Inst Technol, Inst Robot \& Intelligent Machines, Atlanta, GA 30332 USA.
   Kaess, Michael, Carnegie Mellon Univ, Sch Comp Sci, Field Robot Ctr, Inst Robot, Pittsburgh, PA 15213 USA.
   Leonard, John J., MIT, Comp Sci \& Artificial Intelligence Lab, Cambridge, MA 02139 USA.},
DOI = {10.1177/0278364914531056},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Information fusion; smoothing; filtering; real time navigation; SLAM;
   probabilistic graphical models},
Keywords-Plus = {TRACKING; FUSION; SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {indelman@cc.gatech.edu},
Affiliations = {University System of Georgia; Georgia Institute of Technology; Carnegie
   Mellon University; Massachusetts Institute of Technology (MIT)},
ORCID-Numbers = {Kaess, Michael/0000-0002-7590-3357
   Dellaert, Frank/0000-0002-5532-3566},
Funding-Acknowledgement = {All Source Positioning and Navigation (ASPN) program of the Air Force
   Research Laboratory (AFRL) {[}FA8650-11-C-7137]},
Funding-Text = {This work was supported by the All Source Positioning and Navigation
   (ASPN) program of the Air Force Research Laboratory (AFRL) (contract
   number FA8650-11-C-7137). The views expressed in this work have not been
   endorsed by the sponsors.},
Cited-References = {Aharoni R, 2009, INVENT MATH, V176, P1, DOI 10.1007/s00222-008-0157-3.
   Bar-Shalom Y, 2002, IEEE T AERO ELEC SYS, V38, P769, DOI 10.1109/TAES.2002.1039398.
   Bar-Shalom Y., 1995, MULTITARGET MULTISEN.
   Davis TA, 2004, ACM T MATH SOFTWARE, V30, P353, DOI 10.1145/1024074.1024079.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Eustice RM, 2006, IEEE T ROBOT, V22, P1100, DOI 10.1109/TRO.2006.886264.
   Farrell J.A., 2008, AIDED NAVIGATION GPS.
   Folkesson J, 2004, IEEE INT CONF ROBOT, P383, DOI 10.1109/ROBOT.2004.1307180.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Grisetti G, 2007, P ROB SCI SYST RSS.
   GTSAM, GTSAM 2 3 1.
   Heggernes P, 1996, P 2 SIAM C SPARS MAT.
   Indelman V., 2012, 2012 15th International Conference on Information Fusion (FUSION 2012), P2154.
   Indelman V, 2013, IEEE INT C INT ROBOT, P1952, DOI 10.1109/IROS.2013.6696615.
   Indelman V, 2013, ROBOT AUTON SYST, V61, P721, DOI 10.1016/j.robot.2013.05.001.
   Jones ES, 2011, INT J ROBOT RES, V30, P407, DOI 10.1177/0278364910388963.
   Kaess Michael, 2011, 2011 IEEE International Conference on Robotics and Automation, P3281.
   Kaess M, 2010, P INT WORKSH ALG FDN.
   Kaess M, 2012, P INT C INF FUS FUS, P2154.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kaess M, 2010, SPRINGER TRAC ADV RO, V68, P157.
   Klein George, 2007, P1.
   Konolige K., 2010, 2010 IEEERSJ INT C I, P22.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572.
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Lupton T, 2012, IEEE T ROBOT, V28, P61, DOI 10.1109/TRO.2011.2170332.
   Mahon I, 2008, IEEE T ROBOT, V24, P1002, DOI 10.1109/TRO.2008.2004888.
   Maybeck P. S., 1979, STOCHASTIC MODELS ES, V1.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Menger K., 1927, FUND MATH, V10, P96, DOI DOI 10.4064/FM-10-1-96-115.
   Mourikis Anastasios I, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563131.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Moutarlier P., 1989, EXPT ROBOTICS 1, P327.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Ranganathan A, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2492.
   Shen XJ, 2009, IEEE T AUTOMAT CONTR, V54, P1928, DOI 10.1109/TAC.2009.2023777.
   SIBLEY G, 2009, P ROB SCI SYST RSS S.
   Smith D, 2006, IEEE T KNOWL DATA EN, V18, P1696, DOI 10.1109/TKDE.2006.183.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   Smith Randall, 1988, P 4 INT S ROB RES, P467.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Triggs Bill, 1999, LECT NOTES COMPUTER, P298, DOI DOI 10.1007/3-540-44480-7\_21.
   Vial J, 2011, IEEE INT C INT ROBOT, P886, DOI 10.1109/IROS.2011.6048728.
   Zahng S, 2011, P SPIE.
   Zhu Z., 2007, IEEE C COMP VIS PATT, P1.},
Number-of-Cited-References = {49},
Times-Cited = {11},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {20},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {AQ4UM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000342795200003},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000649552900010,
Author = {Tsintotas, Konstantinos A. and Bampis, Loukas and Gasteratos, Antonios},
Title = {Modest-vocabulary loop-closure detection with incremental bag of tracked
   words},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2021},
Volume = {141},
Pages = {103782},
Month = {JUL},
Abstract = {A key feature in the context of simultaneous localization and mapping is
   loop-closure detection, a process determining whether the current
   robot's environment perception coincides with previous observation.
   However, in long-term operations, both computational efficiency and
   memory requirements involved in an autonomous robot operation in
   uncontrolled environments, are of particular importance. The majority of
   approaches scale linearly with the environment's size in terms of
   storage and query time. The article at hand presents an efficient
   appearance-based loop-closure detection pipeline, which encodes the
   traversed trajectory by a low amount of unique visual words generated
   on-line through feature tracking. The incrementally constructed visual
   vocabulary is referred to as the ``Bag of Tracked Words.{''} A
   nearest-neighbor voting scheme is utilized to query the database and
   assign probabilistic scores to all visited locations. Exploiting the
   inherent temporal coherency in the loop-closure task, the produced
   scores are processed through a Bayesian filter to estimate the belief
   state about the robot's location on the map. Also, a geometrical
   verification step ensures consistency between image matches. Management
   is also applied to the resulting vocabulary to reduce its growth rate
   and constraint the system's computational complexity while improving its
   voting distinctiveness. The proposed approach's performance is
   experimentally evaluated on several publicly available and challenging
   datasets, including hand-held, car-mounted, aerial, and ground
   trajectories. Results demonstrate the method's adaptability, which
   retains high operational frequency in environments of up to 13 km and
   high recall rates for perfect precision, outperforming other
   state-of-the-art techniques. The system's effectiveness is owed to the
   reduced vocabulary size, which is at least one order of magnitude
   smaller than other contemporary approaches. An open research-oriented
   source code has been made publicly available, which is dubbed as
   ``BoTW-LCD.{''} (C) 2021 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Tsintotas, KA (Corresponding Author), Democritus Univ Thrace, Sch Engn, Dept Prod \& Management Engn, Lab Robot \& Automat, GR-67132 Xanthi, Greece.
   Tsintotas, Konstantinos A.; Bampis, Loukas; Gasteratos, Antonios, Democritus Univ Thrace, Sch Engn, Dept Prod \& Management Engn, Lab Robot \& Automat, GR-67132 Xanthi, Greece.},
DOI = {10.1016/j.robot.2021.103782},
EarlyAccessDate = {APR 2021},
Article-Number = {103782},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Loop-closure detection; Mapping; Recognition; SLAM; Visual-based
   navigation},
Keywords-Plus = {PLACE RECOGNITION; PROBABILISTIC LOCALIZATION; LARGE-SCALE; FAB-MAP;
   SLAM; ONLINE; VISION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {ktsintot@pme.duth.gr
   lbampis@pme.duth.gr
   agaster@pme.duth.gr},
Affiliations = {Democritus University of Thrace},
ResearcherID-Numbers = {Tsintotas, Konstantinos A./ACG-1650-2022
   Gasteratos, Antonios/AAI-4740-2021
   Tsintotas, Konstantinos A./AAG-2765-2022
   },
ORCID-Numbers = {Tsintotas, Konstantinos A./0000-0002-1808-2601
   Gasteratos, Antonios/0000-0002-5421-0332
   Tsintotas, Konstantinos A./0000-0002-1808-2601
   Bampis, Loukas/0000-0001-7764-4646},
Cited-References = {Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732.
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3\_16.
   An S., 2020, ARXIV PREPRINT ARXIV.
   An S, 2019, IEEE INT C INT ROBOT, P378, DOI 10.1109/IROS40897.2019.8968043.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Arroyo R, 2014, IEEE INT C INT ROBOT, P3089, DOI 10.1109/IROS.2014.6942989.
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027.
   Babenko A, 2015, IEEE T PATTERN ANAL, V37, P1247, DOI 10.1109/TPAMI.2014.2361319.
   BAEZA-YATES R., 1999, MODERN INFORM RETRIE.
   Balaska V, 2021, ROBOT AUTON SYST, V139, DOI 10.1016/j.robot.2021.103760.
   Balaska V, 2020, ROBOT AUTON SYST, V131, DOI 10.1016/j.robot.2020.103567.
   Bampis L, 2018, INT J ROBOT RES, V37, P62, DOI 10.1177/0278364917740639.
   Bampis L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4530, DOI 10.1109/IROS.2016.7759667.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007.
   Blanco JL, 2009, AUTON ROBOT, V27, P327, DOI 10.1007/s10514-009-9138-7.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Company-Corcoles Joan P., 2020, 2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA), P1313, DOI 10.1109/ETFA46521.2020.9212133.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2007, IEEE INT CONF ROBOT, P2042, DOI 10.1109/ROBOT.2007.363622.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Durbin R., 1998, BIOL SEQUENCE ANAL P.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Fritzke B., 1995, Advances in Neural Information Processing Systems 7, P625.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Garcia-Fidalgo Emilio, 2018, IEEE Robotics and Automation Letters, V3, P3051, DOI 10.1109/LRA.2018.2849609.
   Garcia-Fidalgo E, 2017, IEEE T ROBOT, V33, P1061, DOI 10.1109/TRO.2017.2704598.
   Garcia-Fidalgo E, 2015, ROBOT AUTON SYST, V64, P1, DOI 10.1016/j.robot.2014.11.009.
   Gehrig Mathias, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3192, DOI 10.1109/ICRA.2017.7989362.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Hiemstra D., 2000, International Journal on Digital Libraries, V3, P131, DOI 10.1007/s007999900025.
   Ho KL, 2006, ROBOT AUTON SYST, V54, P740, DOI 10.1016/j.robot.2006.04.016.
   Kansizoglou I., 2020, ARXIV PREPRINT ARXIV.
   Kawewong A, 2011, INT J ROBOT RES, V30, P33, DOI 10.1177/0278364910371855.
   Kazmi SMAM, 2019, IEEE T ROBOT, V35, P1352, DOI 10.1109/TRO.2019.2926475.
   Khan S, 2015, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2015.7139959.
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Liu Y, 2012, IEEE INT CONF ROBOT, P3613, DOI 10.1109/ICRA.2012.6224741.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   LUCAS BD, 1981, P 7 INT JOINT C ART, P674.
   Lynen Simon, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P303, DOI 10.1109/3DV.2014.36.
   MacQueen J.B., 1967, P 5 BERKELEY S MATH, P281.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Maffra F, 2019, IEEE ROBOT AUTOM LET, V4, P1525, DOI 10.1109/LRA.2019.2895826.
   Maffra F, 2018, IEEE INT CONF ROBOT, P2542.
   Mei C, 2010, IEEE INT C INT ROBOT, P3738, DOI 10.1109/IROS.2010.5652266.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Murillo AC, 2013, IEEE T ROBOT, V29, P146, DOI 10.1109/TRO.2012.2220211.
   Neubert P, 2019, IEEE ROBOT AUTOM LET, V4, P3200, DOI 10.1109/LRA.2019.2927096.
   Nicosevici T, 2012, IEEE T ROBOT, V28, P886, DOI 10.1109/TRO.2012.2192013.
   Papapetros IT, 2020, INT CONF UNMAN AIRCR, P1206, DOI 10.1109/ICUAS48674.2020.9213923.
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0\_1.
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Schlegel D, 2018, IEEE ROBOT AUTOM LET, V3, P3741, DOI 10.1109/LRA.2018.2856542.
   Senst T, 2012, IEEE T CIRC SYST VID, V22, P1377, DOI 10.1109/TCSVT.2012.2202070.
   Shahbazi H, 2011, IEEE INT C INT ROBOT, P1228, DOI 10.1109/IROS.2011.6048862.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Stumm ES, 2016, INT J ROBOT RES, V35, P334, DOI 10.1177/0278364915570140.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Talbot B, 2018, IEEE INT C INT ROBOT, P7758, DOI 10.1109/IROS.2018.8593761.
   Tsintotas K.A., 2021, IET COMPUT VIS.
   Tsintotas K.A., 2018, P INT C ROB ALP ADR, P580, DOI DOI 10.1007/978-3-030-00232-9\_61.
   Tsintotas KA, 2019, LECT NOTES COMPUT SC, V11754, P75, DOI 10.1007/978-3-030-34995-0\_7.
   Tsintotas KA, 2019, IEEE ROBOT AUTOM LET, V4, P1737, DOI 10.1109/LRA.2019.2897151.
   Tsintotas KA, 2018, IEEE INT CONF ROBOT, P5979, DOI 10.1109/ICRA.2018.8461146.
   Yue HS, 2019, IEEE INT C INT ROBOT, P3787, DOI 10.1109/IROS40897.2019.8967726.
   Zhang G, 2016, IEEE INT CONF ROBOT, P765, DOI 10.1109/ICRA.2016.7487205.
   Zhang GF, 2016, IEEE T IMAGE PROCESS, V25, P5957, DOI 10.1109/TIP.2016.2607425.
   Zobel J, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1132956.1132959.},
Number-of-Cited-References = {84},
Times-Cited = {5},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {16},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {SA8KW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000649552900010},
DA = {2022-05-17},
}

@inproceedings{ WOS:000461361000242,
Author = {Zhang, Zhongyuan and Wang, Hesheng and Chen, Weidong},
Book-Group-Author = {IEEE},
Title = {A real-time visual-inertial mapping and localization method by fusing
   unstable GPS},
DOI = {10.1109/WCICA.2018.8630513},
Booktitle = {2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA)},
Year = {2018},
Pages = {1397-1402},
Note = {13th World Congress on Intelligent Control and Automation (WCICA),
   Changsha, PEOPLES R CHINA, JUL 04-08, 2018},
Abstract = {This paper presents a novel method which fuse visual, IMU and GPS
   tightly to realize high-precision real-time localization and mapping
   simultaneously (SLAM). Our method is based on the bundle adjustment
   (BA). The confidence of the GPS signal is used to determine the window
   size in the local mapping thread and judge w hether the keyframe is
   reliable. The long-term unreliable key frame linking with large
   uncertainty of GPS which called GPS-restricted or GPS-denied situation
   will cause the drift when mapping. To eliminate the drift, in contrast
   to use the closed-loop detection and global optimization which will
   increase the computational burden extremely with the size of the map
   enlarged, a semi-global optimization method is proposed to relieve the
   burden, which make the localization estimated by this method possible to
   be used to navigate for unmanned vehicles. In our method, the confidence
   of the GPS signal is significantly important, however, the covariance
   supplied by the GPS receiver may not be trustworthy sometimes, which
   cause some unnecessary mistake when optimizing, thus a semi-supervised
   clustering method taking the information of GPS and IMU into account
   synthetically is introduced to get that confidence more robustly.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wang, HS (Corresponding Author), Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   Wang, HS (Corresponding Author), Minist Educ China, Key Lab Syst Control \& Informat Proc, Beijing, Peoples R China.
   Zhang, Zhongyuan; Wang, Hesheng; Chen, Weidong, Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   Zhang, Zhongyuan; Wang, Hesheng; Chen, Weidong, Minist Educ China, Key Lab Syst Control \& Informat Proc, Beijing, Peoples R China.
   Wang, Hesheng, Harbin Inst Technol, State Key Lab Robot \& Syst, Harbin 150001, Heilongjiang, Peoples R China.},
ISBN = {978-1-5386-7345-4},
Research-Areas = {Automation \& Control Systems; Computer Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial Intelligence},
Author-Email = {wanghesheng@sjtu.edu.cn},
Affiliations = {Shanghai Jiao Tong University; Ministry of Education, China; Harbin
   Institute of Technology},
Cited-References = {Bala Chayan, 1983, IEEE T COMMUN, V36, P41.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Lategahn H, 2013, IEEE INT VEH SYM, P719, DOI 10.1109/IVS.2013.6629552.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal Raul, IEEE ROBOTICS AUTOMA.
   Qin Tong, 2017, VINS MONO ROBUST VER.
   Schleicher D, 2009, IEEE T INTELL TRANSP, V10, P440, DOI 10.1109/TITS.2009.2026317.
   Shen SJ, 2015, IEEE INT CONF ROBOT, P5303, DOI 10.1109/ICRA.2015.7139939.
   Shepard DP, 2014, IEEE POSITION LOCAT, P1309, DOI 10.1109/PLANS.2014.6851506.
   Surber Julian, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6300, DOI 10.1109/ICRA.2017.7989745.
   Ziegler J, 2014, IEEE INTEL TRANSP SY, V6, P8, DOI 10.1109/MITS.2014.2306552.},
Number-of-Cited-References = {12},
Times-Cited = {3},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BM2RI},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000461361000242},
DA = {2022-05-17},
}

@article{ WOS:000710778700001,
Author = {Wang, Jibo and Li, Chengpeng and Li, Bangyu and Pang, Chenglin and Fang,
   Zheng},
Title = {High-precision and robust localization system for mobile robots in
   complex and large-scale indoor scenes},
Journal = {INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS},
Year = {2021},
Volume = {18},
Number = {5},
Month = {SEP},
Abstract = {High-precision and robust localization is the key issue for long-term
   and autonomous navigation of mobile robots in industrial scenes. In this
   article, we propose a high-precision and robust localization system
   based on laser and artificial landmarks. The proposed localization
   system is mainly composed of three modules, namely scoring
   mechanism-based global localization module, laser and artificial
   landmark-based localization module, and relocalization trigger module.
   Global localization module processes the global map to obtain the map
   pyramid, thus improve the global localization speed and accuracy when
   robots are powered on or kidnapped. Laser and artificial landmark-based
   localization module is employed to achieve robust localization in highly
   dynamic scenes and high-precision localization in target areas. The
   relocalization trigger module is used to monitor the current
   localization quality in real time by matching the current laser scan
   with the global map and feeds it back to the global localization module
   to improve the robustness of the system. Experimental results show that
   our method can achieve robust robot localization and real-time detection
   of the current localization quality in indoor scenes and industrial
   environment. In the target area, the position error is less than 0.004 m
   and the angle error is less than 0.01 rad.},
Publisher = {SAGE PUBLICATIONS INC},
Address = {2455 TELLER RD, THOUSAND OAKS, CA 91320 USA},
Type = {Article},
Language = {English},
Affiliation = {Fang, Z (Corresponding Author), Northeastern Univ, Fac Robot Sci \& Engn, Shenyang 110819, Liaoning, Peoples R China.
   Wang, Jibo; Pang, Chenglin; Fang, Zheng, Northeastern Univ, Fac Robot Sci \& Engn, Shenyang 110819, Liaoning, Peoples R China.
   Li, Chengpeng; Li, Bangyu, SIASUN Robot \& Automat Co Ltd, Shenyang, Peoples R China.},
DOI = {10.1177/17298814211047690},
Article-Number = {17298814211047690},
ISSN = {1729-8814},
Keywords = {AGV; automated guided vehicle; global localization; high-precision
   localization; relocalization trigger mechanism; landmark},
Keywords-Plus = {RGB-D SLAM; GLOBAL LOCALIZATION; MOTION REMOVAL; LASER; LIDAR},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {fangzheng@mail.neu.edu.cn},
Affiliations = {Northeastern University - China},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}62073066, U20A20197];
   Science and Technology on Near-Surface Detection Laboratory
   {[}6142414200208]; Fundamental Research Funds for the Central
   Universities {[}N182608003]; Major Special Science and Technology
   Project of Liaoning Province {[}2019JH1/10100026]; Major Scientific and
   Technological Innovation Project of Shandong Province {[}2019JZZY010128]},
Funding-Text = {The author(s) disclosed receipt of the following financial support for
   the research, authorship, and/or publication of this article: This work
   was supported by the National Natural Science Foundation of China
   (62073066, U20A20197), the Science and Technology on Near-Surface
   Detection Laboratory (6142414200208), the Fundamental Research Funds for
   the Central Universities (N182608003), and the Major Special Science and
   Technology Project of Liaoning Province (No. 2019JH1/10100026), and the
   Major Scientific and Technological Innovation Project of Shandong
   Province (2019JZZY010128).},
Cited-References = {Adelson EH., 1984, RCA ENG, V29, P33.
   Arandjelovic R., 2016, IEEE T PATTERN ANAL, P5297, DOI DOI 10.1109/TPAMI.2017.2711011.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Censi A, 2008, IEEE INT CONF ROBOT, P19, DOI 10.1109/ROBOT.2008.4543181.
   Esfahani MA, 2018, IEEE INT CONF CON AU, P81, DOI 10.1109/ICCA.2018.8444299.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Fox D, 2002, ADV NEUR IN, V14, P713.
   Gallagher G, 2009, IEEE INT CONF ROBOT, P4322.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Glocker B, 2015, IEEE T VIS COMPUT GR, V21, P571, DOI 10.1109/TVCG.2014.2360403.
   Goeddel R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1932, DOI 10.1109/IROS.2016.7759305.
   Grisetti G, 2005, IEEE INT CONF ROBOT, P2432.
   Guo S, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419862985.
   Huan Yin, 2018, 2018 IEEE Intelligent Vehicles Symposium (IV), P728, DOI 10.1109/IVS.2018.8500682.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Latif Y, 2018, IEEE INT CONF ROBOT, P2349, DOI 10.1109/ICRA.2018.8461081.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Milford M., 2014, 2014 IFIP NETW C, P1.
   Millane A, 2019, IEEE INT C INT ROBOT, P1271, DOI 10.1109/IROS40897.2019.8967683.
   Olson Edwin, 2011, 2011 IEEE International Conference on Robotics and Automation, P3400.
   Ratz S, 2020, IEEE INT CONF ROBOT, P5415, DOI 10.1109/ICRA40945.2020.9197458.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Saarinen J, 2013, IEEE INT C INT ROBOT, P382, DOI 10.1109/IROS.2013.6696380.
   Sobreira H, 2016, IND ROBOT, V43, P596, DOI 10.1108/IR-01-2016-0026.
   Su ZR, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), P2377, DOI 10.1109/ROBIO.2017.8324775.
   Sun DL, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4517, DOI 10.1109/IROS.2016.7759665.
   Sun L, 2020, IEEE INT CONF ROBOT, P4386, DOI 10.1109/ICRA40945.2020.9196708.
   Sun YX, 2018, ROBOT AUTON SYST, V108, P115, DOI 10.1016/j.robot.2018.07.002.
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012.
   Valencia R, 2014, IEEE INT CONF ROBOT, P3956, DOI 10.1109/ICRA.2014.6907433.
   Wang Z, 2021, IEEE SENS J, V21, P11497, DOI 10.1109/JSEN.2020.3021049.
   Yao EL, 2018, ROBOT AUTON SYST, V107, P209, DOI 10.1016/j.robot.2018.06.009.
   Zhang M., 2019 AM CONTR C ACC, P1997.},
Number-of-Cited-References = {35},
Times-Cited = {0},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Int. J. Adv. Robot. Syst.},
Doc-Delivery-Number = {WM0IJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000710778700001},
DA = {2022-05-17},
}

@article{ WOS:000724477700005,
Author = {Xiao, Hongru and Han, Yanqun and Zhao, Junqiao and Cui, Jiafeng and
   Xiong, Lu and Yu, Zhuoping},
Title = {LIO-Vehicle: A Tightly-Coupled Vehicle Dynamics Extension of LiDAR
   Inertial Odometry},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2022},
Volume = {7},
Number = {1},
Pages = {446-453},
Month = {JAN},
Abstract = {We propose LIO-Vehicle, a new tightly-coupled vehicle dynamics extension
   of LiDAR inertial odometry (LIO) method that provides highly accurate,
   robust, and real-time vehicle trajectory estimation. Since most existing
   LiDAR-based localization methods are not specifically proposed for
   vehicles, they do not take the motion constraints of ground robots into
   account. And they may not work well in structure-less areas, such as
   tunnels and narrow corridors. For LIO in these LiDAR-degraded
   circumstances, inertial sensors alone are unable to sustain reliable
   long-term accuracy due to the accumulation of errors without external
   periodic corrections. Therefore, it is necessary to introduce other
   low-cost sensors and vehicle motion constraints to build a more accurate
   and robust odometry algorithm. In this letter, we use wheel speedometer
   and steering angle sensor measurements to establish a
   two-degree-of-freedom vehicle dynamics model and then construct a
   preintegration factor based on the model's output. At the backend, we
   add the vehicle dynamics preintegration results, IMU preintegration
   measurements, and LiDAR odometry results to a factor graph and get the
   optimized result with the help of sliding window optimization. The
   experiments show that the proposed method can achieve higher positioning
   accuracy compared with the existing LiDAR inertial odometry methods and
   it can significantly mitigate navigation error in harsh areas where
   environmental features are insufficient for LiDAR odometry.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Zhao, JQ (Corresponding Author), Tongji Univ, Dept Comp Sci \& Technol, Shanghai 201804, Peoples R China.
   Xiao, Hongru; Han, Yanqun; Cui, Jiafeng; Xiong, Lu; Yu, Zhuoping, Tongji Univ, Sch Automot Studies, Shanghai 201804, Peoples R China.
   Zhao, Junqiao, Tongji Univ, Dept Comp Sci \& Technol, Shanghai 201804, Peoples R China.},
DOI = {10.1109/LRA.2021.3126336},
ISSN = {2377-3766},
Keywords = {SLAM; localization; mapping; vehicle dynamics},
Keywords-Plus = {COMPLEXITY; MOTION; ROBUST},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {2031620@tongji.edu.cn
   yanqun\_han@163.com
   zhaojunqiao@tongji.edu.cn
   1933444@tongji.edu.cn
   xiong\_lu@tongji.edu.cn
   yuzhuoping@tongji.edu.cn},
Affiliations = {Tongji University; Tongji University},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2020YFA0711402]; National Natural Science Foundation of China
   {[}U1764261, 41801335, 41871370]},
Funding-Text = {This work was supported by the National Key Research and Development
   Program of China under Grant 2020YFA0711402, and in part by the National
   Natural Science Foundation of China under Grants U1764261, 41801335, and
   41871370.},
Cited-References = {Aboutaleb A. M., 2020, THESIS QUEENS U CANA.
   Bekir E., 2007, INTRO MODERN NAVIGAT.
   Bento LC, 2005, 2005 IEEE Intelligent Transportation Systems Conference (ITSC), P245.
   Demir M, 2019, IEEE INT C INTELL TR, P3288, DOI 10.1109/ITSC.2019.8916995.
   Gezici S, 2005, IEEE SIGNAL PROC MAG, V22, P70, DOI 10.1109/MSP.2005.1458289.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Huang GQP, 2013, IEEE T ROBOT, V29, P1226, DOI 10.1109/TRO.2013.2267991.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kang R, 2019, IEEE INT C INTELL TR, P3593, DOI 10.1109/ITSC.2019.8916940.
   Li M, 2013, IEEE INT CONF ROBOT, P4712, DOI 10.1109/ICRA.2013.6631248.
   Liu JX, 2019, IEEE INT C INT ROBOT, P5391, DOI 10.1109/IROS40897.2019.8967607.
   Lupton T, 2012, IEEE T ROBOT, V28, P61, DOI 10.1109/TRO.2011.2170332.
   Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917.
   Mikov A, 2019, INT SYMP INERT SENSO.
   Qin C, 2019, ADV NEUR IN, V32.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   SMITH DE, 1995, VEHICLE SYST DYN, V24, P163, DOI 10.1080/00423119508969086.
   Tomizuka M., 2020, ARXIV PREPRINT ARXIV.
   Xu W., ARXIV210706829, V2021.
   Xu W, 2021, IEEE ROBOT AUTOM LET, V6, P3317, DOI 10.1109/LRA.2021.3064227.
   Yang S, 2018, IEEE INT C INT ROBOT, P1175, DOI 10.1109/IROS.2018.8593754.
   Ye H., 2017, ARXIV PREPRINT ARXIV.
   Ye HY, 2019, IEEE INT CONF ROBOT, P3144, DOI 10.1109/ICRA.2019.8793511.
   Yu JX, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1930, DOI 10.1109/ICMLC.2008.4620722.
   Zhang HL, 2007, PROCEEDINGS OF THE 26TH CHINESE CONTROL CONFERENCE, VOL 3, P115.
   Zhang J., 2014, ROBOT SCI SYST, V41, P401.
   Zhang SJ, 2019, CHIN CONT DECIS CONF, P4950, DOI 10.1109/CCDC.2019.8832695.},
Number-of-Cited-References = {29},
Times-Cited = {1},
Usage-Count-Last-180-days = {25},
Usage-Count-Since-2013 = {25},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {XG0UW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000724477700005},
DA = {2022-05-17},
}

@inproceedings{ WOS:000465234300004,
Author = {Wilbers, Daniel and Rumberg, Lars and Stachniss, Cyrill},
Book-Group-Author = {IEEE},
Title = {Approximating Marginalization with Sparse Global Priors for Sliding
   Window SLAM-Graphs},
Booktitle = {2019 THIRD IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC 2019)},
Year = {2019},
Pages = {25-31},
Note = {3rd IEEE International Conference on Robotic Computing (IRC), Naples,
   ITALY, FEB 25-27, 2019},
Abstract = {Most autonomous vehicles rely on some kind of map for localization or
   navigation. Outdated maps however are a risk to the performance of any
   map-based localization system applied in autonomous vehicles. It is
   necessary to update the used maps to ensure stable and long-term
   operation. We address the problem of computing landmark updates live in
   the vehicle, which requires efficient use of the computational
   resources. In particular, we employ a graph-based sliding window
   approach for simultaneous localization and incremental map refinement.
   We propose a novel method that approximates sliding window
   marginalization without inducing fill-in. Our method maintains the exact
   same sparsity pattern as without performing marginalization, but
   simultaneously improves the landmark estimates. The main novelty of this
   work is the derivation of sparse global priors that approximate dense
   marginalization. In comparison to state-of-the-art work, our approach
   utilizes global instead of local linearization points, but still
   minimizes linearization errors. We first approximate marginalization via
   Kullback-Leibler divergence and then recalculate the mean to compensate
   linearization errors. We evaluate our approach on simulated and real
   data from a prototype vehicle and compare our approach to
   state-of-the-art sliding window marginalization.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wilbers, D (Corresponding Author), Volkswagen Grp Res, Wolfsburg, Germany.
   Wilbers, D (Corresponding Author), Univ Bonn, Inst Geodesy \& Geoinformat, Bonn, Germany.
   Wilbers, Daniel; Rumberg, Lars, Volkswagen Grp Res, Wolfsburg, Germany.
   Wilbers, Daniel; Stachniss, Cyrill, Univ Bonn, Inst Geodesy \& Geoinformat, Bonn, Germany.},
DOI = {10.1109/IRC.2019.00013},
ISBN = {978-1-5386-9245-5},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Cybernetics; Robotics},
Affiliations = {Volkswagen; Volkswagen Germany; University of Bonn},
ResearcherID-Numbers = {Stachniss, Cyrill/AAH-3034-2019},
Cited-References = {Brenner C., 2009, LECT NOTES COMPUTER, V5748.
   Bresson G., 2017, IEEE T INTELL VEHICL.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Carlevaris-Bianco N, 2014, IEEE T ROBOT, V30, P1371, DOI 10.1109/TRO.2014.2347571.
   Carlevaris-Bianco N, 2014, IEEE INT CONF ROBOT, P854, DOI 10.1109/ICRA.2014.6906954.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   Choudhary S, 2015, IEEE INT CONF ROBOT, P4620, DOI 10.1109/ICRA.2015.7139839.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eckenhoff K, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3275, DOI 10.1109/IROS.2016.7759505.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Hsiung J., 2018, P IEEE RSJ INT C INT.
   Kretzschmar H, 2011, IEEE INT C INT ROBOT, P865, DOI 10.1109/IROS.2011.6048060.
   Kummerle R, 2011, AUTON ROBOT, V30, P25, DOI 10.1007/s10514-010-9204-1.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Mazuran M., 2014, ROBOTICS SCI SYSTEMS, P1.
   Merfels C, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P3116, DOI 10.1109/IROS.2016.7759482.
   Roh H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081315.
   Sibley G, 2010, J FIELD ROBOT, V27, P587, DOI 10.1002/rob.20360.
   Stachniss C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1153.
   Ta D.-N., 2018, P IEEE INT C ROB AUT.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Vallve J., 2018, IEEE ROBOTICS AUTOMA, V3.
   Vallve J., 2017, P EUR C MOB ROB ECMR.
   Vial J, 2011, IEEE INT C INT ROBOT, P886, DOI 10.1109/IROS.2011.6048728.
   Vysotska O, 2017, PFG-J PHOTOGRAMM REM, V85, P53, DOI 10.1007/s41064-017-0006-3.
   Vysotska O, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4511, DOI 10.1109/IROS.2016.7759664.
   Wilbers D., 2019, P IEEE INT C ROB COM.
   2016, INT J ROBOT RES, V35, P50, DOI DOI 10.1177/0278364915581629.},
Number-of-Cited-References = {28},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BM5LZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000465234300004},
DA = {2022-05-17},
}

@article{ WOS:000478965200001,
Author = {Quan, Meixiang and Piao, Songhao and Tan, Minglang and Huang, Shi-Sheng},
Title = {Tightly-Coupled Monocular Visual-Odometric SLAM Using Wheels and a MEMS
   Gyroscope},
Journal = {IEEE ACCESS},
Year = {2019},
Volume = {7},
Pages = {97374-97389},
Abstract = {In this paper, we present a novel tightly coupled probabilistic
   monocular visual-odometric simultaneous localization and mapping
   (VOSLAM) algorithm using wheels and a MEMS gyroscope, which can provide
   accurate, robust, and long-term localization for ground robots. First,
   we present a novel odometer preintegration theory on manifold; it
   integrates the wheel encoder measurements and gyroscope measurements to
   a relative motion constraint that is independent of the linearization
   point and carefully addresses the uncertainty propagation and gyroscope
   bias correction. Based on the preintegrated odometer measurement model,
   we also introduce the odometer error term and tightly integrate it into
   the visual optimization framework. Then, in order to bootstrap the
   VOSLAM system, we propose a simple map initialization method. Finally,
   we present a complete localization mechanism to maximally exploit both
   sensing cues, which provides different strategies for motion tracking
   when: 1) both measurements are available; 2) visual measurements are not
   available; and 3) wheel encoders experience slippage, thereby ensuring
   the accurate and robust motion tracking. The proposed algorithm is
   evaluated by performing extensive experiments, and the experimental
   results demonstrate the superiority of the proposed system.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Piao, SH (Corresponding Author), Harbin Inst Technol, Sch Comp Sci \& Technol, Harbin 150001, Heilongjiang, Peoples R China.
   Huang, SS (Corresponding Author), Hypercept Inc, Beijing 100083, Peoples R China.
   Quan, Meixiang; Piao, Songhao, Harbin Inst Technol, Sch Comp Sci \& Technol, Harbin 150001, Heilongjiang, Peoples R China.
   Tan, Minglang; Huang, Shi-Sheng, Hypercept Inc, Beijing 100083, Peoples R China.},
DOI = {10.1109/ACCESS.2019.2930201},
ISSN = {2169-3536},
Keywords = {Motion estimation; sensor fusion; simultaneous localization and mapping},
Keywords-Plus = {VERSATILE},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {piaosh@hit.edu.cn
   shishenghuang.net@gmail.com},
Affiliations = {Harbin Institute of Technology},
ORCID-Numbers = {Piao, Songhao/0000-0003-3153-3646},
Funding-Acknowledgement = {National Science Foundation of China {[}61375081]; Special Fund Project
   of Harbin Science and Technology Innovation Talents Research
   {[}RC2013XK010002]},
Funding-Text = {This work was supported in part by the National Science Foundation of
   China under Grant 61375081, and in part by the Special Fund Project of
   Harbin Science and Technology Innovation Talents Research under Grant
   RC2013XK010002.},
Cited-References = {Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Eudes Alexandre, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P290, DOI 10.1109/ICPR.2010.80.
   Forster C, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Hesch J. A., 2012, P IEEE C COMP VIS PA, P15.
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629.
   Huang G., 2008, P 11 INT S EXP ROB A.
   Jones ES, 2011, INT J ROBOT RES, V30, P407, DOI 10.1177/0278364910388963.
   Klein George, 2007, P1.
   Kleinert Markus, 2010, 2010 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2010), P20, DOI 10.1109/MFI.2010.5604453.
   Lategahn H, 2011, IEEE INT CONF ROBOT, P1732.
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251.
   Li PL, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P11, DOI 10.1109/ISMAR.2017.18.
   Michot J., 2010, P 5 S 3D DAT PROC VI, P9.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17.
   Pinies P, 2007, IEEE INT CONF ROBOT, P2797, DOI 10.1109/ROBOT.2007.363895.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Strasdat H., 2010, P ROB SCI SYST.
   Wu Kejian J., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5155, DOI 10.1109/ICRA.2017.7989603.},
Number-of-Cited-References = {30},
Times-Cited = {15},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {16},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {IN8YH},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000478965200001},
OA = {gold, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000543397000175,
Author = {Li, Qingqing and Nevalainen, Paavo and Queralta, Jorge Pena and
   Heikkonen, Jukka and Westerlund, Tomi},
Title = {Localization in Unstructured Environments: Towards Autonomous Robots in
   Forests with Delaunay Triangulation},
Journal = {REMOTE SENSING},
Year = {2020},
Volume = {12},
Number = {11},
Pages = {1870},
Month = {JUN},
Abstract = {Autonomous harvesting and transportation is a long-term goal of the
   forest industry. One of the main challenges is the accurate localization
   of both vehicles and trees in a forest. Forests are unstructured
   environments where it is difficult to find a group of significant
   landmarks for current fast feature-based place recognition algorithms.
   This paper proposes a novel approach where local point clouds are
   matched to a global tree map using the Delaunay triangularization as the
   representation format. Instead of point cloud based matching methods, we
   utilize a topology-based method. First, tree trunk positions are
   registered at a prior run done by a forest harvester. Second, the
   resulting map is Delaunay triangularized. Third, a local submap of the
   autonomous robot is registered, triangularized and matched using
   triangular similarity maximization to estimate the position of the
   robot. We test our method on a dataset accumulated from a forestry site
   at Lieksa, Finland. A total length of 200 m of harvester path was
   recorded by an industrial harvester with a 3D laser scanner and a
   geolocation unit fixed to the frame. Our experiments show a 12 cm s.t.d.
   in the location accuracy and with real-time data processing for speeds
   not exceeding 0.5 m/s. The accuracy and speed limit are realistic during
   forest operations.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Li, QQ (Corresponding Author), Univ Turku, Turku Intelligent Embedded \& Robot Syst, Turku 20500, Finland.
   Li, Qingqing; Nevalainen, Paavo; Queralta, Jorge Pena; Heikkonen, Jukka; Westerlund, Tomi, Univ Turku, Turku Intelligent Embedded \& Robot Syst, Turku 20500, Finland.},
DOI = {10.3390/rs12111870},
Article-Number = {1870},
EISSN = {2072-4292},
Keywords = {robotics; localization; delaunay triangulation; SLAM; forest
   localization},
Keywords-Plus = {RECOGNITION; EFFICIENT; LIDAR},
Research-Areas = {Environmental Sciences \& Ecology; Geology; Remote Sensing; Imaging
   Science \& Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {qingq1i@utu.fi
   ptneva@utu.fi
   jopequ@utu.fi
   jukhei@utu.fi
   tovewe@utu.fi},
Affiliations = {University of Turku},
ResearcherID-Numbers = {Westerlund, Tomi/I-2167-2019
   Queralta, Jorge Peña/ABA-5310-2020
   Li, Qingqing/AAV-2263-2021
   Li, Qingqing/AAM-8348-2021
   },
ORCID-Numbers = {Westerlund, Tomi/0000-0002-1793-2694
   Queralta, Jorge Peña/0000-0003-3091-3217
   Li, Qingqing/0000-0001-6556-2213
   Li, Qingqing/0000-0001-6556-2213
   Nevalainen, Paavo/0000-0002-7646-929X},
Funding-Acknowledgement = {Business Finland {[}26004155]; Academy of Finland {[}328755]},
Funding-Text = {This research are funded by Business Finland grant number 26004155 and
   Academy of Finland grant number 328755.},
Cited-References = {Arzoumanian Z, 2005, J APPL ECOL, V42, P999, DOI 10.1111/j.1365-2664.2005.01117.x.
   Badue C., 2019, ARXIV190104407.
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007.
   Biber P., 2003, P 2003 IEEE RSJ INT, V3.
   Bosse M, 2013, IEEE INT CONF ROBOT, P2677, DOI 10.1109/ICRA.2013.6630945.
   Bosse M, 2009, ROBOT AUTON SYST, V57, P1211, DOI 10.1016/j.robot.2009.07.009.
   Boukouvala F, 2016, EUR J OPER RES, V252, P701, DOI 10.1016/j.ejor.2015.12.018.
   Chakareski J, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P9.
   Chen SW, 2020, IEEE ROBOT AUTOM LET, V5, P612, DOI 10.1109/LRA.2019.2963823.
   Chen Y, 2003, THIRD IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING - BIBE 2003, PROCEEDINGS, P18.
   Edelsbrunner H, 2001, ACT NUMERIC, V9, P133.
   Hellstrom T., 2009, International Journal of Forest Engineering, V20, P31.
   Himstedt M, 2014, IEEE INT C INT ROBOT, P5030, DOI 10.1109/IROS.2014.6943277.
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331.
   Kankare V, 2014, ISPRS J PHOTOGRAMM, V97, P89, DOI 10.1016/j.isprsjprs.2014.08.008.
   Lauer M., 2005, ROBOT SOCCER WORLD C.
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785.
   Liang XL, 2016, ISPRS J PHOTOGRAMM, V115, P63, DOI 10.1016/j.isprsjprs.2016.01.006.
   Liao F, 2016, IEEE INT VEH SYM, P246, DOI 10.1109/IVS.2016.7535393.
   Liu YF, 2003, IEEE INT CONF ROBOT, P1227.
   Lynen S, 2017, INT J COMPUT VISION, V124, P49, DOI 10.1007/s11263-016-0947-9.
   Magnusson Martin, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P3907, DOI 10.1109/ROBOT.2009.5152538.
   Miettinen M, 2007, IEEE INT CONF ROBOT, P517, DOI 10.1109/ROBOT.2007.363838.
   Nunez P, 2006, IEEE INT CONF ROBOT, P1167, DOI 10.1109/ROBOT.2006.1641867.
   Pierzchala M, 2018, COMPUT ELECTRON AGR, V145, P217, DOI 10.1016/j.compag.2017.12.034.
   Qian C, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010003.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Qingqing L., 2019, P 9 IEEE CIS RAM C B.
   Resindra Widya A., 2018, ARXIV180503879.
   Ringdahl O, 2011, SCAND J FOREST RES, V26, P350, DOI 10.1080/02827581.2011.566889.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Rusu RB, 2010, KUNSTL INTELL, V24, P345, DOI 10.1007/s13218-010-0059-6.
   Sampath A., 2006, P AM SOC PHOT REM SE, P1.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Segal A., 2009, ROBOTICS SCI SYSTEMS, V2, P435.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Sinclair D., 2016, ARXIV160401428.
   Tang J, 2015, FORESTS, V6, P4588, DOI 10.3390/f6124390.
   Thakur R, 2016, IEEE CONSUM ELECTR M, V5, P48, DOI 10.1109/MCE.2016.2556878.
   Thrun S., 2002, P WORKSH ALG FDN ROB, P1.
   Tian Y., 2018, P INT S EXP ROB, P140.
   Tomastik J, 2017, FORESTRY, V90, P187, DOI 10.1093/forestry/cpw031.
   Tominaga A, 2018, JOINT INT CONF SOFT, P1142, DOI 10.1109/SCIS-ISIS.2018.00180.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405.
   Yoneda K, 2019, IATSS RES, V43, P253, DOI 10.1016/j.iatssr.2019.11.005.
   Zhang J, 2014, P ROB SCI SYST BERK.
   Zhang WM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020211.
   Zhu X., 2017, AUTONOMOUS MOBILE RO.
   Zimbelman EG, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191017.},
Number-of-Cited-References = {50},
Times-Cited = {13},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Remote Sens.},
Doc-Delivery-Number = {MC6LX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000543397000175},
OA = {gold, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000385157300007,
Author = {Tan, Yew Teck and Chitre, Mandar and Hover, Franz S.},
Title = {Cooperative bathymetry-based localization using low-cost autonomous
   underwater vehicles},
Journal = {AUTONOMOUS ROBOTS},
Year = {2016},
Volume = {40},
Number = {7, SI},
Pages = {1187-1205},
Month = {OCT},
Abstract = {We present a cooperative bathymetry-based localization approach for a
   team of low-cost autonomous underwater vehicles (AUVs), each equipped
   only with a single-beam altimeter, a depth sensor and an acoustic modem.
   The localization of the individual AUV is achieved via fully
   decentralized particle filtering, with the local filter's measurement
   model driven by the AUV's altimeter measurements and ranging information
   obtained through inter-vehicle communication. We perform empirical
   analysis on the factors that affect the filter performance. Simulation
   studies using randomly generated trajectories as well as trajectories
   executed by the AUVs during field experiments successfully demonstrate
   the feasibility of the technique. The proposed cooperative localization
   technique has the potential to prolong AUV mission time, and thus open
   the door for long-term autonomy underwater.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Tan, YT (Corresponding Author), Natl Univ Singapore, Trop Marine Sci Inst, Acoust Res Lab, Singapore, Singapore.
   Tan, YT (Corresponding Author), Natl Univ Singapore, Dept Elect \& Comp Engn, Singapore, Singapore.
   Tan, Yew Teck; Chitre, Mandar, Natl Univ Singapore, Trop Marine Sci Inst, Acoust Res Lab, Singapore, Singapore.
   Tan, Yew Teck; Chitre, Mandar, Natl Univ Singapore, Dept Elect \& Comp Engn, Singapore, Singapore.
   Hover, Franz S., MIT, Dept Mech Engn, Cambridge, MA 02139 USA.},
DOI = {10.1007/s10514-015-9508-2},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Cooperative localization; Autonomous underwater vehicle;
   Rao-Blackwellized particle filter; Acoustic ranging},
Keywords-Plus = {ACOUSTIC NAVIGATION; FILTER; SLAM},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {tanyt81@gmail.com
   mandar@arl.nus.edu.sg
   hover@mit.edu},
Affiliations = {National University of Singapore; National University of Singapore;
   Massachusetts Institute of Technology (MIT)},
ResearcherID-Numbers = {Chitre, Mandar/B-1675-2016
   },
ORCID-Numbers = {Chitre, Mandar/0000-0001-6243-7871
   Tan, Yew Teck/0000-0003-2158-9910},
Funding-Acknowledgement = {Singapore-MIT Alliance for Research and Technology (SMART) graduate
   fellowship},
Funding-Text = {This work was supported by Singapore-MIT Alliance for Research and
   Technology (SMART) graduate fellowship. The authors wish to thank the
   Hovergroup, WAVES lab and STARFISH team for obtaining the experimental
   data, and Dr. Bharath Kaylan for providing bathymetric maps.},
Cited-References = {Anonsen KB, 2006, IEEE POSITION LOCAT, P1027, DOI 10.1109/PLANS.2006.1650705.
   Arrichiello F, 2011, IEEE INT C INT ROBOT, P3166, DOI 10.1109/IROS.2011.6048075.
   Bahr A., 2009, IEEE INT C ROB AUT I, DOI {[}10.1109/ROBOT.2009.5152859, DOI 10.1109/R0B0T.2009.5152859].
   Bahr A, 2009, INT J ROBOT RES, V28, P714, DOI 10.1177/0278364908100561.
   Barkby S, 2011, J FIELD ROBOT, V28, P19, DOI 10.1002/rob.20382.
   Bo Jiang, 2011, Proceedings of the 25th IEEE International Parallel \& Distributed Processing Symposium (IPDPS 2011), P334, DOI 10.1109/IPDPS.2011.40.
   Carreno S, 2010, OCEANS-IEEE.
   Chitre M., 2010, P OCEANS SYDN C MAY, P1, DOI DOI 10.1109/OCEANSSYD.2010.5603615.
   Cover T. M., 2006, THEORY.
   Curcio J, 2005, OCEANS-IEEE, P725.
   Donovan GT, 2012, IEEE J OCEANIC ENG, V37, P431, DOI 10.1109/JOE.2012.2190810.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Fairfield N., 2008, OCEANS 2008, P1, DOI DOI 10.1109/OCEANS.2008.5151853.
   Fairfield N, 2006, IEEE INT CONF ROBOT, P3575, DOI 10.1109/ROBOT.2006.1642248.
   Fallon M. F., 2011, IEEE INT C ROB AUT I.
   Fearnhead P., 1998, THESIS.
   Gadre A. S., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1420, DOI 10.1109/IROS.2005.1545230.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Jakuba MV, 2008, J FIELD ROBOT, V25, P861, DOI 10.1002/rob.20250.
   Kalyan B., 2013, P 28 ANN ACM S APPL, P229, DOI DOI 10.1145/2480362.2480411.
   Karlsson R, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P526.
   Koay TB, 2011, INDIAN J GEO-MAR SCI, V40, P157.
   Lanz O, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P317, DOI 10.1109/ICIAP.2007.4362798.
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847.
   Maczka D. K., 2007, P MTS IEEE C OC 2000, P1, DOI DOI 10.1109/0CEANS.2007.4449404.
   Maurya P., 2012, P IFAC WORKSH NAV GU, P10.
   Meduna D.K., 2010, AUTONOMOUS UNDERWATE, DOI {[}10.1109/AUV.2010.5779659, DOI 10.1109/AUV.2010.5779659].
   Nordlund P.-J., 2002, THESIS.
   Nordlund PJ, 2001, P AMER CONTR CONF, P4375, DOI 10.1109/ACC.2001.945666.
   Nygren I, 2004, IEEE J OCEANIC ENG, V29, P906, DOI 10.1109/JOE.2004.833222.
   Roman C., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3662.
   ROSENCRANTZ M, 2003, P UAI, P493.
   Schon T, 2005, IEEE T SIGNAL PROCES, V53, P2279, DOI 10.1109/TSP.2005.849151.
   Sheng XH, 2005, 2005 FOURTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P181.
   Smith RN, 2010, INT J ROBOT RES, V29, P1475, DOI 10.1177/0278364910377243.
   Song TL, 1999, IEEE J OCEANIC ENG, V24, P383, DOI 10.1109/48.775299.
   Tan YT, 2014, IEEE J OCEANIC ENG, V39, P371, DOI 10.1109/JOE.2013.2296361.
   Tan YT., 2012, INT S DISTR AUT ROB.
   Teixeira F., 2012, P IFAC WORKSH NAV GU, P10.
   Teixeira F. C., 2007, THESIS.
   Teixeira F. C., 2012, P IFAC C MAN CONTR M.
   Vickery K, 1998, PROCEEDINGS OF THE 1998 WORKSHOP ON AUTONOMOUS UNDERWATER VEHICLES, (AUV `98), P5, DOI 10.1109/AUV.1998.744434.
   Webster SE, 2013, IEEE T ROBOT, V29, P957, DOI 10.1109/TRO.2013.2252857.
   Webster SE, 2012, INT J ROBOT RES, V31, P935, DOI 10.1177/0278364912446166.},
Number-of-Cited-References = {44},
Times-Cited = {14},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {42},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {DY5QT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000385157300007},
OA = {Green Published},
DA = {2022-05-17},
}

@article{ WOS:000704051800001,
Author = {Liu, Zhe and Qiao, Zhijian and Suo, Chuanzhe and Liu, Yingtian and Jin,
   Kefan},
Title = {Map-less long-term localization in complex industrial environments},
Journal = {ASSEMBLY AUTOMATION},
Year = {2021},
Volume = {41},
Number = {6},
Pages = {714-724},
Month = {NOV 24},
Abstract = {Purpose This paper aims to study the localization problem for autonomous
   industrial vehicles in the complex industrial environments. Aiming for
   practical applications, the pursuit is to build a map-less localization
   system which can be used in the presence of dynamic obstacles,
   short-term and long-term environment changes.
   Design/methodology/approach The proposed system contains four main
   modules, including long-term place graph updating, global localization
   and re-localization, location tracking and pose registration. The first
   two modules fully exploit the deep-learning based three-dimensional
   point cloud learning techniques to achieve the map-less global
   localization task in large-scale environment. The location tracking
   module implements the particle filter framework with a newly designed
   perception model to track the vehicle location during movements.
   Finally, the pose registration module uses visual information to exclude
   the influence of dynamic obstacles and short-term changes and further
   introduces point cloud registration network to estimate the accurate
   vehicle pose. Findings Comprehensive experiments in real industrial
   environments demonstrate the effectiveness, robustness and practical
   applicability of the map-less localization approach. Practical
   implications This paper provides comprehensive experiments in real
   industrial environments. Originality/value The system can be used in the
   practical automated industrial vehicles for long-term localization
   tasks. The dynamic objects, short-/long-term environment changes and
   hardware limitations of industrial vehicles are all considered in the
   system design. Thus, this work moves a big step toward achieving real
   implementations of the autonomous localization in practical industrial
   scenarios.},
Publisher = {EMERALD GROUP PUBLISHING LTD},
Address = {HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Liu, Z (Corresponding Author), Univ Cambridge, Dept Comp Sci \& Technol, Cambridge, England.
   Liu, Zhe, Univ Cambridge, Dept Comp Sci \& Technol, Cambridge, England.
   Qiao, Zhijian, Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.
   Suo, Chuanzhe; Liu, Yingtian, Chinese Univ Hong Kong, Dept Mech \& Automat Engn, Hong Kong, Peoples R China.
   Jin, Kefan, Shanghai Jiao Tong Univ, MOE Key Lab Marine Intelligent Equipment \& Syst, Shanghai, Peoples R China.
   Jin, Kefan, Shanghai Jiao Tong Univ, State Key Lab Ocean Engn, Shanghai, Peoples R China.},
DOI = {10.1108/AA-06-2021-0088},
EarlyAccessDate = {OCT 2021},
ISSN = {0144-5154},
EISSN = {1758-4078},
Keywords = {Autonomous robots; Automated vehicles; Localization in industrial
   environments; Long-term localization; Map-less localization},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Manufacturing},
Author-Email = {zl457@cam.ac.uk
   qiaozhijian@sjtu.edu.cn
   suo\_ivy@foxmail.com
   liuyingtian@stu.hit.edu.cn
   jinkefan@sjtu.edu.cn},
Affiliations = {League of European Research Universities - LERU; University of
   Cambridge; Shanghai Jiao Tong University; Chinese University of Hong
   Kong; Shanghai Jiao Tong University; Shanghai Jiao Tong University},
Cited-References = {Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Chen HY, 2019, ASSEMBLY AUTOM, V39, P297, DOI 10.1108/AA-04-2018-065.
   Chen XYL, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
   Cheng J, 2015, INT CON DISTR COMP S, P527, DOI 10.1109/ICDCS.2015.60.
   Dhall A., 2017, ARXIV170509785.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Kato S, 2018, ACM IEEE INT CONF CY, P287, DOI 10.1109/ICCPS.2018.00035.
   Koltun V, 2018, ARXIV PREPRINT ARXIV.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Liu YX, 2019, J PHYS CONF SER, V1176, DOI 10.1088/1742-6596/1176/2/022019.
   Liu Z, 2019, IEEE I CONF COMP VIS, P2831, DOI 10.1109/ICCV.2019.00292.
   Liu Z, 2020, IEEE ROBOT AUTOM MAG, V27, P139, DOI 10.1109/MRA.2020.2977290.
   Liu Z, 2019, IEEE INT C INT ROBOT, P1218, DOI 10.1109/IROS40897.2019.8967875.
   Liu Z, 2016, IEEE T CONTR SYST T, V24, P2125, DOI 10.1109/TCST.2016.2518618.
   Liu Z, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P1012, DOI 10.1109/ROBIO.2014.7090465.
   Liu Z, 2021, IEEE ROBOT AUTOM LET, V6, P3184, DOI 10.1109/LRA.2021.3062815.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Schaupp L, 2019, IEEE INT C INT ROBOT, P3255, DOI 10.1109/IROS40897.2019.8968094.
   Schindler K., 2021, 2021 IEEE CVF C COMP, P4267.
   Shamsfakhr F, 2020, ASSEMBLY AUTOM, V40, P801, DOI 10.1108/AA-09-2017-119.
   Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Sons M, 2018, IEEE INT C INTELL TR, P2671, DOI 10.1109/ITSC.2018.8570011.
   Stachniss C., 2021, 2021 IEEE INT C ROB.
   Suo CZ, 2020, IEEE ACCESS, V8, P108402, DOI 10.1109/ACCESS.2020.2999727.
   Tai, 2021, 2021 IEEE CVF C COMP, P869.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Vizzo Ignacio, 2021, 2021 IEEE International Conference on Robotics and Automation (ICRA), P5624, DOI 10.1109/ICRA48506.2021.9562069.
   Wang, 2019, ARXIV190513315V2.
   Wang H., 2021, 2021 IEEE CVF C COMP, P15910.
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362.
   Wei HS, 2020, IEEE INT C INT ROBOT, P2678, DOI 10.1109/IROS45743.2020.9341249.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.
   Xia Y., 2021, P IEEE CVF C COMP VI, P11348.
   Xie, 2020, ARXIV201013072.
   Xu W, 2021, IEEE ROBOT AUTOM LET, V6, P3317, DOI 10.1109/LRA.2021.3064227.
   Ying Wang, 2020, 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), P5769, DOI 10.1109/IROS45743.2020.9341010.
   Zhe Liu, 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P46, DOI 10.1109/MFI.2012.6343051.
   Zhou Z, 2021, ASSEMBLY AUTOM, V41, P71, DOI 10.1108/AA-01-2020-0002.
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184.},
Number-of-Cited-References = {40},
Times-Cited = {2},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Assem. Autom.},
Doc-Delivery-Number = {XB9CP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000704051800001},
DA = {2022-05-17},
}

@article{ WOS:000706876000001,
Author = {Oh, Junghyun and Eoh, Gyuho},
Title = {Variational Bayesian Approach to Condition-Invariant Feature Extraction
   for Visual Place Recognition},
Journal = {APPLIED SCIENCES-BASEL},
Year = {2021},
Volume = {11},
Number = {19},
Pages = {8976},
Month = {OCT},
Abstract = {As mobile robots perform long-term operations in large-scale
   environments, coping with perceptual changes becomes an important issue
   recently. This paper introduces a stochastic variational inference and
   learning architecture that can extract condition-invariant features for
   visual place recognition in a changing environment. Under the assumption
   that a latent representation of the variational autoencoder can be
   divided into condition-invariant and condition-sensitive features, a new
   structure of the variation autoencoder is proposed and a variational
   lower bound is derived to train the model. After training the model,
   condition-invariant features are extracted from test images to calculate
   the similarity matrix, and the places can be recognized even in severe
   environmental changes. Experiments were conducted to verify the proposed
   method, and the experimental results showed that our assumption was
   reasonable and effective in recognizing places in changing environments.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Eoh, G (Corresponding Author), Chungbuk Natl Univ, Ind AI Res Ctr, Cheongju 28116, South Korea.
   Oh, Junghyun, Kwangwoon Univ, Dept Robot, Seoul 01897, South Korea.
   Eoh, Gyuho, Chungbuk Natl Univ, Ind AI Res Ctr, Cheongju 28116, South Korea.},
DOI = {10.3390/app11198976},
Article-Number = {8976},
EISSN = {2076-3417},
Keywords = {place recognition; localization; deep learning; mobile robots;
   auto-encoder; SLAM},
Keywords-Plus = {SCALE},
Research-Areas = {Chemistry; Engineering; Materials Science; Physics},
Web-of-Science-Categories  = {Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied},
Author-Email = {jhyunoh@kw.ac.kr
   gyuho.eoh@cbnu.ac.kr},
Affiliations = {Kwangwoon University; Chungbuk National University},
ORCID-Numbers = {Eoh, Gyuho/0000-0003-4931-4396
   Oh, Junghyun/0000-0003-0502-7600},
Funding-Acknowledgement = {National Research Foundation of Korea (NRF) - Korea government (MSIT)
   {[}2020R1F1A1076667]; Korea Institute of Energy Technology Evaluation
   and Planning (KETEP); Ministry of Trade, Industry \& Energy (MOTIE) of
   the Republic of Korea {[}20174010201620]; Kwangwoon University},
Funding-Text = {This work has supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government(MSIT) (No. 2020R1F1A1076667),
   Korea Institute of Energy Technology Evaluation and Planning (KETEP) and
   the Ministry of Trade, Industry \& Energy (MOTIE) of the Republic of
   Korea (No. 20174010201620). This work was also supported by Research
   Resettlement Fund for the new faculty of Kwangwoon University in 2019.},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Chancan M, 2020, IEEE ROBOT AUTOM LET, V5, P993, DOI 10.1109/LRA.2020.2967324.
   Choi Y., 2015, P IEEE INT C COMP VI.
   Civera J., 2018, PPNIV WORKSH IROS 20.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Garg S, 2018, IEEE INT CONF ROBOT, P3645, DOI 10.1109/ICRA.2018.8461051.
   Kingma D.P., 2014, AUTOENCODING VARIATI.
   Krizhevsky A., P INT C ADV NEUR INF, P1097.
   Liu Y, 2012, IEEE INT C INT ROBOT, P1051, DOI 10.1109/IROS.2012.6386145.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Naseer T, 2015, IEEE INT C INT ROBOT, P2529, DOI 10.1109/IROS.2015.7353721.
   Neubert P., 2013, INT C ROB AUT ICRA W, DOI 10.1016/j.cell.2007.12.011.
   Oh JH, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.0037.
   Oh J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124103.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Park C, 2020, INT J CONTROL AUTOM, V18, P2699, DOI 10.1007/s12555-019-0891-x.
   Pu Y, 2016, ADV NEURAL INFORM PR.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Simonyan K, 2015, P CVPR.
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.},
Number-of-Cited-References = {26},
Times-Cited = {0},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Appl. Sci.-Basel},
Doc-Delivery-Number = {WG3DI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000706876000001},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000324383405006,
Author = {Wendel, Andreas and Irschara, Arnold and Bischof, Horst},
Book-Group-Author = {IEEE},
Title = {Natural Landmark-based Monocular Localization for MAVs},
Pages = {5792-5799},
DOI = {10.1109/ICRA.2011.5980317},
Booktitle = {2011 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2011},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Shanghai, PEOPLES R CHINA, MAY 09-13, 2011},
Abstract = {Highly accurate localization of a micro aerial vehicle (MAV) with
   respect to a scene is important for a wide range of applications, in
   particular surveillance and inspection. Most existing approaches to
   visual localization focus on indoor environments, while such tasks
   require outdoor navigation. Within this work, we introduce a novel
   algorithm for monocular visual localization for MAVs based on the
   concept of virtual views in 3D space. Under the assumption that
   significant parts of the scene do not alter their geometry and serve as
   natural landmarks, the accuracy of our visual approach outperforms
   consumer grade GPS systems. In an experimental setup we compare our
   approach to a state-of-the-art visual SLAM algorithm and evaluate the
   performance by geometric validation from an observer's view. As our
   method directly allows global registration, it is neither prone to drift
   nor bias. This makes it well suited for long-term autonomous navigation.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wendel, A (Corresponding Author), Graz Univ Technol, Inst Comp Graph \& Vis, A-8010 Graz, Austria.
   Wendel, Andreas; Irschara, Arnold; Bischof, Horst, Graz Univ Technol, Inst Comp Graph \& Vis, A-8010 Graz, Austria.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-61284-385-8},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {wendel@icg.tugraz.at
   irschara@icg.tugraz.at
   bischof@icg.tugraz.at},
Affiliations = {Graz University of Technology},
Cited-References = {Ahrens S., 2009, INT C ROB AUT ICRA.
   Altug E., 2002, INT C ROB AUT ICRA.
   Beder C, 2006, LECT NOTES COMPUT SC, V4174, P657.
   Bloesch M., 2010, INT C ROB AUT ICRA.
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577.
   Everingham M., 2007, PASCAL VISUAL OBJECT.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Frahm J.-M., 2010, EUR C COMP VIS ECCV.
   Furukawa Y., 2009, IEEE T PATTERN ANAL.
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67.
   Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759.
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547.
   Irschara Arnold, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2599, DOI 10.1109/CVPRW.2009.5206587.
   Irschara A., 2007, WORKSH VIRT REPR MOD.
   Klein George, 2007, P1.
   Klopschitz M, 2010, INT S 3D DAT PROC VI.
   Li Y., 2010, EUR C COMP VIS ECCV.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x.
   Mondragon I. F., 2010, INT C ROB AUT ICRA.
   Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Robertson D., 2004, BRIT MACH VIS C BMVC.
   Rudol P., 2010, INT C ROB AUT ICRA.
   Saripalli S., 2002, INT C ROB AUT ICRA.
   Schindler G., 2007, IEEE C COMP VIS PATT.
   Snavely N., 2006, P SIGGRAPH 2006.
   Triggs B., 2000, VISION ALGORITHMS TH, V1883, DOI {[}DOI 10.1007/3-540-44480-7\_21, 10.1007/3-540-44480-7\_21].
   Zhu Z. W., 2008, IEEE C COMP VIS PATT.
   Zufferey J.-C., 2010, INT C ROB AUT ICRA.},
Number-of-Cited-References = {30},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BGW51},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000324383405006},
DA = {2022-05-17},
}

@inproceedings{ WOS:000558081900024,
Author = {Schaefer, Alexander and Buescher, Daniel and Vertens, Johan and Luft,
   Lukas and Burgard, Wolfram},
Book-Author = {Preucil, L
   Behnke, S
   Kulich, M},
Book-Group-Author = {IEEE},
Title = {Long-Term Urban Vehicle Localization Using Pole Landmarks Extracted from
   3-D Lidar Scans},
DOI = {10.1109/ECMR.2019.8870928},
Booktitle = {2019 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR)},
Year = {2019},
Note = {European Conference on Mobile Robots (ECMR), Prague, CZECH REPUBLIC, SEP
   04-06, 2019},
Abstract = {Due to their ubiquity and long-term stability, pole-like objects are
   well suited to serve as landmarks for vehicle localization in urban
   environments. In this work, we present a complete mapping and long-term
   localization system based on pole landmarks extracted from 3-D lidar
   data. Our approach features a novel pole detector, a mapping module, and
   an online localization module, each of which are described in detail,
   and for which we provide an open-source implementation {[}1]. In
   extensive experiments, we demonstrate that our method improves on the
   state of the art with respect to long-term reliability and accuracy:
   First, we prove reliability by tasking the system with localizing a
   mobile robot over the course of 15 months in an urban area based on an
   initial map, confronting it with constantly varying routes, differing
   weather conditions, seasonal changes, and construction sites. Second, we
   show that the proposed approach clearly outperforms a recently published
   method in terms of accuracy.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Schaefer, A (Corresponding Author), Univ Freiburg, Dept Comp Sci, Freiburg, Germany.
   Schaefer, Alexander; Buescher, Daniel; Vertens, Johan; Luft, Lukas; Burgard, Wolfram, Univ Freiburg, Dept Comp Sci, Freiburg, Germany.},
ISBN = {978-1-7281-3605-9},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {aschaef@cs.uni-freiburg.de
   buescher@cs.uni-freiburg.de
   vertensj@cs.uni-freiburg.de
   luft@cs.uni-freiburg.de
   burgard@cs.uni-freiburg.de},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
ORCID-Numbers = {Burgard, Wolfram/0000-0002-5680-6500
   Schaefer, Alexander/0000-0002-5207-8403},
Funding-Acknowledgement = {Samsung Electronics Co. Ltd.},
Funding-Text = {This work has been partially supported by Samsung Electronics Co. Ltd.
   under the GRO program.},
Cited-References = {Brenner C, 2009, LECT NOTES COMPUT SC, V5748, P61.
   Buscher, LONG TERM URBAN VEHI.
   Cabo C, 2014, ISPRS J PHOTOGRAMM, V87, P47, DOI 10.1016/j.isprsjprs.2013.10.008.
   Carlevaris-Bianco N., 2012, INT J ROBOT RES, V35, P1023.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/tit.1975.1055330.
   Geiger A., 2013, INT J ROBOTICS RES.
   Hata AY, 2016, IEEE T INTELL TRANSP, V17, P420, DOI 10.1109/TITS.2015.2477817.
   Im JH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081268.
   Kummerle J., 2019, 2019 IEEE INT C ROB.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li F, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091442.
   Luft L, 2017, IEEE INT C INT ROBOT, P6678, DOI 10.1109/IROS.2017.8206583.
   Modsching M., 2006, P 3 WORKSH POS NAV C.
   Ordonez C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071465.
   Qin B, 2012, IEEE INT CONF ROBOT, P2640, DOI 10.1109/ICRA.2012.6224913.
   Rodriguez-Cuenca B, 2015, REMOTE SENS-BASEL, V7, P12680, DOI 10.3390/rs71012680.
   Schindler A, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P134, DOI 10.1109/IVWorkshops.2013.6615239.
   Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509.
   Sefati M, 2017, IEEE INT VEH SYM, P13, DOI 10.1109/IVS.2017.7995692.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Tombari F, 2014, IEEE INT C INT ROBOT, P4922, DOI 10.1109/IROS.2014.6943262.
   Welzel A, 2015, IEEE INT C INTELL TR, P2728, DOI 10.1109/ITSC.2015.438.
   Weng LH, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P96, DOI 10.1109/RCAR.2018.8621688.
   Wu F, 2017, IEEE T INTELL TRANSP, V18, P292, DOI 10.1109/TITS.2016.2565698.
   Yokoyama H., 2013, INT J CADCAM, V13, P31.
   Yu YT, 2015, IEEE T GEOSCI REMOTE, V53, P1374, DOI 10.1109/TGRS.2014.2338915.
   Zheng H., 2016, INT ARCH PHOTOGRAMME, V41.},
Number-of-Cited-References = {29},
Times-Cited = {8},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BP5RM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000558081900024},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921705114,
Author = {Gadd, Matthew and Newman, Paul},
Book-Group-Author = {IEEE},
Title = {Checkout My Map: Version Control for Fleetwide Visual Localisation},
DOI = {10.1109/IROS.2016.7759843},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {5729-5736},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {This paper is about underpinning long-term operations of fleets of
   vehicles using visual localisation. In particular it examines ways in
   which vehicles, considered as independent agents, can share, update and
   leverage each others' visual experiences in a mutually beneficial way.
   We draw on our previous work in Experience-based Navigation (EBN) {[}1],
   in which a visual map supporting multiple representations of the same
   place is built, yielding real-time localisation capability for a
   solitary vehicle. We now consider how any number of such agents might
   operate in concert via data sharing policies that are germane to the
   shared task of lifelong localisation. We rapidly construct considerable
   maps by the conjoining of work distributed to asynchronous processes,
   and share expertise amongst the team by the selective dispensing of
   mission-specific map contents. We demonstrate and evaluate our system
   against 100 km of data collected in North Oxford over a period of a
   month featuring diverse deviation in appearance due to atmospheric,
   lighting, and structural dynamics. We show that our framework is capable
   of creating maps in a fraction of the time required by single-agent EBN,
   with no significant loss in localisation robustness, and is able to
   furnish robots on real-world forays with maps which require much less
   storage.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gadd, M (Corresponding Author), Univ Oxford, Mobile Robot Grp, Oxford, England.
   Gadd, Matthew; Newman, Paul, Univ Oxford, Mobile Robot Grp, Oxford, England.},
ISBN = {978-1-5090-3762-9},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {mattgadd@robots.ox.ac.uk
   pnewman@robots.ox.ac.uk},
Affiliations = {University of Oxford},
ResearcherID-Numbers = {Gadd, Matthew/AAS-4274-2020},
ORCID-Numbers = {Gadd, Matthew/0000-0001-9447-8619},
Funding-Acknowledgement = {FirstRand Laurie Dip penar; Oppenheimer Memorial Trust; Keble Ian Palmer
   scholarships; EPSRC Leadership Fellowship {[}EP/J012017/1]; EPSRC
   Programme {[}EP/M019918/1]; European Community's Seventh Framework
   Programme {[}FP7-610603]; EPSRC {[}EP/I005021/1, EP/M019918/1] Funding
   Source: UKRI},
Funding-Text = {Matthew Gadd is supported by the FirstRand Laurie Dip penar, Oppenheimer
   Memorial Trust, and Keble Ian Palmer scholarships. Paul Newman is
   supported by EPSRC Leadership Fellowship Grant EP/J012017/1 and EPSRC
   Programme Grant EP/M019918/1. Additionally, the authors acknowledge the
   support of this work by the European Community's Seventh Framework
   Programme under grant agreement FP7-610603 (EUROPA2). The authors thank
   Chris Linegar for his support in interfacing with core EBN software, as
   well as Winston Churchill for his valuable suggestions.},
Cited-References = {Aragues R, 2012, IEEE T ROBOT, V28, P840, DOI 10.1109/TRO.2012.2192012.
   Bahr A, 2009, IEEE INT CONF ROBOT, P4295.
   Bailey Tim, 2011, IEEE International Conference on Robotics and Automation, P2859.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Churchill W, 2012, IEEE INT C INTELL TR, P1371, DOI 10.1109/ITSC.2012.6338716.
   Cieslewski T, 2015, IEEE INT CONF ROBOT, P6241, DOI 10.1109/ICRA.2015.7140075.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cunningham A, 2012, IEEE INT CONF ROBOT, P1093, DOI 10.1109/ICRA.2012.6225356.
   Dymczyk M., 2015, P IEEE INT C ROB AUT.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Leach P., 2005, UNIVERSALLY UNIQUE I.
   Linegar C., 2015, P IEEE INT C ROB AUT.
   Maddern W, 2015, P IEEE INT C ROB AUT.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Nagel W., 2005, SUBVERSION VERSION C.
   Nister D., 2004, COMP VIS PATT REC 20, V1, pI, DOI DOI 10.1109/CVPR.2004.1315094.
   Paul R, 2012, IEEE INT CONF ROBOT, P4058, DOI 10.1109/ICRA.2012.6224762.
   Pepperell E., 2015, AUTOMATIC IMAGE SCAL.
   STORMO GD, 1982, NUCLEIC ACIDS RES, V10, P2997, DOI 10.1093/nar/10.9.2997.
   Wingerd L., 2005, PRACTICAL PERFORCE.},
Number-of-Cited-References = {23},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921705114},
OA = {Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370974903096,
Author = {Li, Jie and Eustice, Ryan M. and Johnson-Roberson, Matthew},
Book-Group-Author = {IEEE},
Title = {High-Level Visual Features for Underwater Place Recognition},
DOI = {10.1109/ICRA.2015.7139706},
Booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2015},
Pages = {3652-3659},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Seattle, WA, MAY 26-30, 2015},
Abstract = {This paper reports on a method to perform robust visual relocalization
   between temporally separated sets of underwater images gathered by a
   robot. The place recognition and relocalization problem is more
   challenging in the underwater environment mainly due to three factors:
   1) changes in illumination; 2) long-term changes in the visual
   appearance of features because of phenomena like biofouling on man-made
   structures and growth or movement in natural features; and 3) low
   density of visually salient features for image matching. To address
   these challenges, a patch-based feature matching approach is proposed,
   which uses image segmentation and local intensity contrast to locate
   salient patches and HOG description to make correspondences between
   patches. Compared to traditional point-based features that are sensitive
   to dramatic appearance changes underwater, patch-based features are able
   to encode higher level information such as shape or structure which
   tends to persist across years in underwater environments. The algorithm
   is evaluated on real data, from multiple years, collected by a Hovering
   Autonomous Underwater Vehicle for ship hull inspection. Results in
   relocalization performance across missions from different years are
   compared to other traditional methods.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Li, J (Corresponding Author), Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Li, Jie, Univ Michigan, Dept Elect Engn \& Comp Sci, Ann Arbor, MI 48109 USA.
   Eustice, Ryan M.; Johnson-Roberson, Matthew, Univ Michigan, Dept Naval Architecture \& Marine Engn, Ann Arbor, MI 48109 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-6923-4},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; NAVIGATION; SLAM},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {ljlijie@umich.edu
   eustice@umich.edu
   mattjr@umich.Gdu},
Affiliations = {University of Michigan System; University of Michigan; University of
   Michigan System; University of Michigan},
Cited-References = {Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66.
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Carlevaris-Bianco Nicholas, 2011, IEEE International Conference on Robotics and Automation, P423.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dalal N., 2005, 2005 IEEE COMPUTER S, P886, DOI {[}10.1109/CVPR.2005.177, DOI 10.1109/CVPR.2005.177].
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eustice RM, 2008, IEEE J OCEANIC ENG, V33, P103, DOI 10.1109/JOE.2008.923547.
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77.
   Harel J., 2007, NIPS C ADV NEUR INF, P545, DOI {[}10.7551/mitpress/7503.0 01.0 0 01, DOI 10.7551/MITPRESS/7503.003.0073].
   Hartley R., 2003, MULTIPLE VIEW GEOMET.
   Jiang H., 2011, BMVC, V6, P7, DOI DOI 10.5244/C.25.110.(4).
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   McManus C., 2014, P ROB SCI SYST C BER.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Ozog P, 2014, IEEE INT CONF ROBOT, P3832, DOI 10.1109/ICRA.2014.6907415.
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743.},
Number-of-Cited-References = {20},
Times-Cited = {13},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BE3MR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370974903096},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000354931600028,
Author = {Qiao, Yongliang and Cappelle, Cindy and Ruichek, Yassine},
Editor = {Gelbukh, A and Espinoza, FC and GaliciaHaro, SN},
Title = {Image Based Place Recognition and Lidar Validation for Vehicle
   Localization},
DOI = {10.1007/978-3-319-13647-9_28},
Booktitle = {HUMAN-INSPIRED COMPUTING AND ITS APPLICATIONS, PT I},
Series = {Lecture Notes in Artificial Intelligence},
Year = {2014},
Volume = {8856},
Pages = {304-315},
Note = {13th Mexican International Conference on Artificial Intelligence
   (MICAI), Tuxtla Gutierrez, MEXICO, NOV 16-22, 2014},
Abstract = {In this paper, we propose a system for vehicle localization that
   combines two sensors: a camera and a lidar. An image based place
   recognition approach is used to determine the vehicle localization when
   the vehicle revisited a previously visited location. Unlike systems that
   only rely on visual appearance recognition for localization, we also
   integrate lidar measurements information in order to validate the vision
   based place recognition results. Effectively, false positives
   recognition can be detected and rejected by checking the coherency of
   the image based recognition results with the results of lidar
   measurements matching with ICP (iterative closest point) algorithm. In
   case of false image based recognized places, vehicle position can be
   computed using only lidar based ICP method. The vehicle position is
   effectively estimated using the last known position and the
   transformation between the corresponding lidar measurement and the
   current one obtained by applying ICP. By employing the camera and lidar
   sensors, the deficiencies of each individual sensor can be overcome.
   Experiments were conducted in two different surrounding areas. The
   obtained results show that the proposed method permit to avoid the
   well-known long-term accumulated error of deadreckoning localization and
   lidar data can help to reject false positives of place recognition.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Qiao, YL (Corresponding Author), UTBM, IRTES SET, F-90010 Belfort, France.
   Qiao, Yongliang; Cappelle, Cindy; Ruichek, Yassine, UTBM, IRTES SET, F-90010 Belfort, France.},
ISSN = {0302-9743},
EISSN = {1611-3349},
ISBN = {978-3-319-13647-9; 978-3-319-13646-2},
Keywords = {Vehicle localization; Place recognition; Multi-sensor approach; ICP},
Keywords-Plus = {LARGE-SCALE; FAB-MAP; APPEARANCE; SLAM},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Theory \&
   Methods},
Author-Email = {yongliang.qiao@utbm.fr
   cindy.cappelle@utbm.fr
   yassine.ruichek@utbm.fr},
Affiliations = {Universite de Technologie de Belfort-Montbeliard (UTBM)},
ResearcherID-Numbers = {Qiao, Yongliang/AAW-3433-2020
   },
ORCID-Numbers = {Qiao, Yongliang/0000-0003-2142-0154},
Cited-References = {Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Bosse M, 2009, ROBOT AUTON SYST, V57, P1211, DOI 10.1016/j.robot.2009.07.009.
   Chong ZJ, 2013, IEEE INT CONF ROBOT, P1554, DOI 10.1109/ICRA.2013.6630777.
   Collier J, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P128, DOI 10.1109/CRV.2013.35.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Eade E. D., 2008, BRIT MACH VIS C BMVC, P61.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Granstrom K, 2011, INT J ROBOT RES, V30, P1728, DOI 10.1177/0278364911405086.
   Granstrom K, 2009, IEEE INT CONF ROBOT, P1990.
   Hahnel D, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P206.
   Ho K., 2005, EUR C MOB ROB ECMR.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Latecki LJ, 2003, LECT NOTES COMPUT SC, V2886, P34.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Nieto J, 2007, ROBOT AUTON SYST, V55, P39, DOI 10.1016/j.robot.2006.06.008.
   Saito T, 2012, 2012 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P43, DOI 10.1109/SII.2012.6426958.
   Tipaldi GD, 2010, IEEE INT CONF ROBOT, P3616, DOI 10.1109/ROBOT.2010.5509864.},
Number-of-Cited-References = {21},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BC7JE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000354931600028},
DA = {2022-05-17},
}

@article{ WOS:000272605900006,
Author = {Bosse, Michael and Zlot, Robert},
Title = {Keypoint design and evaluation for place recognition in 2D lidar maps},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2009},
Volume = {57},
Number = {12, SI},
Pages = {1211-1224},
Month = {DEC 31},
Note = {Workshop of the Inside-Data-Association, Zurich, SWITZERLAND, JUN 28,
   2008},
Abstract = {We address the place recognition problem, which we define as the problem
   of establishing whether an observed location has been previously seen,
   and if so, determining the transformation aligning the current
   observations to an existing map. In the contexts of robot navigation and
   mapping, place recognition amounts to globally localizing a robot or map
   segment without being given any prior estimate. An efficient method of
   solving this problem involves first selecting a set of keypoints in the
   scene which store an encoding of their local region, and then utilizing
   a sublinear-time search into a database of keypoints previously
   generated from the global map to identify places with common features.
   We present an algorithm to embed arbitrary keypoint descriptors in a
   reduced-dimension metric space, in order to frame the problem as an
   efficient nearest neighbor search. Given that there are a multitude of
   possibilities for keypoint design, we propose a general methodology for
   comparing keypoint location selection heuristics and descriptor models
   that describe the region around the keypoint. With respect to selecting
   keypoint locations, we introduce a metric that encodes how likely it is
   that the keypoint will be found in the presence of noise and occlusions
   during mapping passes. Metrics for keypoint descriptors are used to
   assess the distinguishability between the distributions of matches and
   non-matches and the probability the correct match will be found in an
   approximate k-nearest neighbors search. Verification of the test
   outcomes is done by comparing the various keypoint designs on a
   kilometers-scale place recognition problem. We apply our design
   evaluation methodology to three keypoint selection heuristics and six
   keypoint descriptor models. A full place recognition system is
   presented, including a series of match verification algorithms which
   effectively filter out false positives. Results from city-scale and
   long-term mapping problems illustrate our approach for both offline and
   online SLAM, map merging, and global localization and demonstrate that
   our algorithm is able to produce accurate maps over trajectories of
   hundreds of kilometers. Crown Copyright (C) 2009 Published by Elsevier
   B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Bosse, M (Corresponding Author), CSIRO, ICT Ctr, Autonomous Syst Lab, POB 883, Kenmore, Qld 4069, Australia.
   Bosse, Michael; Zlot, Robert, CSIRO, ICT Ctr, Autonomous Syst Lab, Kenmore, Qld 4069, Australia.},
DOI = {10.1016/j.robot.2009.07.009},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Place recognition; Data association; SLAM; Mapping; Localization;
   Dimension reduction; Regional point descriptor},
Keywords-Plus = {APPROXIMATE NEAREST-NEIGHBOR; LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {mike.bosse@csiro.au
   robert.zlot@csiro.au},
Affiliations = {Commonwealth Scientific \& Industrial Research Organisation (CSIRO)},
ResearcherID-Numbers = {Zlot, Robert/B-7546-2011
   Bosse, Michael/B-7719-2011},
ORCID-Numbers = {Zlot, Robert/0000-0002-1672-552X
   },
Cited-References = {Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494.
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348.
   Bailey T., 2002, THESIS U SYDNEY SYDN.
   BAY H, 2006, SURF SPEEDED UP ROBU.
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Bosse M., 2009, INT C FIELD SERV ROB.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/tit.1975.1055330.
   HO K, 2005, EUR C MOB ROB.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Howard A., 2003, ROBOTICS DATA SET RE.
   LIN KI, 2005, INT DAT ENG APPL S.
   LIU T, 2004, NEUR INF PROC SYST C.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   LU F, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P935, DOI 10.1109/CVPR.1994.323928.
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9.
   Neyman J, 1933, PHILOS T R SOC LOND, V231, P289, DOI 10.1098/rsta.1933.0009.
   PROCOPIUC O, 2003, INT S SPAT TEMP DAT.
   Schindler G, 2007, IEEE COMP SOC C COMP.
   TOMONO M, 2004, IEEE INT C ROB AUT.
   Walthelm A., 2004, INT C INT AUT SYST.
   WEISS G, 1994, IEEE RSJ INT C INT R.
   Zlot R., 2008, INT S EXP ROB.},
Number-of-Cited-References = {26},
Times-Cited = {61},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {26},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {530PX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000272605900006},
DA = {2022-05-17},
}

@article{ WOS:000441935900005,
Author = {Kunze, Lars and Hawes, Nick and Duckett, Tom and Hanheide, Marc and
   Krajnik, Tomas},
Title = {Artificial Intelligence for Long-Term Robot Autonomy: A Survey},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {4023-4030},
Month = {OCT},
Abstract = {Autonomous systems will play an essential role in many applications
   across diverse domains including space, marine, air, field, road, and
   service robotics. They will assist us in our daily routines and perform
   dangerous, dirty, and dull tasks. However, enabling robotic systems to
   perform autonomously in complex, real-world scenarios over extended time
   periods (i.e., weeks, months, or years) poses many challenges. Some of
   these have been investigated by subdisciplines of Artificial
   Intelligence (AI) including navigation and mapping, perception,
   knowledge representation and reasoning, planning, interaction, and
   learning. The different subdisciplines have developed techniques that,
   when re-integrated within an autonomous system, can enable robots to
   operate effectively in complex, long-term scenarios. In this letter, we
   survey and discuss AI techniques as ``enablers{''} for long-term robot
   autonomy, current progress in integrating these techniques within
   long-running robotic systems, and the future challenges and
   opportunities for AI in long-term autonomy.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Kunze, L (Corresponding Author), Univ Oxford, Dept Engn Sci, Oxford Robot Inst, Oxford OX1 2JD, England.
   Kunze, Lars; Hawes, Nick, Univ Oxford, Dept Engn Sci, Oxford Robot Inst, Oxford OX1 2JD, England.
   Duckett, Tom; Hanheide, Marc, Univ Lincoln, Sch Comp Sci, Lincoln LN6 7TS, England.
   Krajnik, Tomas, Czech Tech Univ, Fac Elect Engn, Dept Comp Sci, Prague 16636, Czech Republic.},
DOI = {10.1109/LRA.2018.2860628},
ISSN = {2377-3766},
Keywords = {Autonomous agents; AI-based methods; long-term autonomy},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; SPECIAL-ISSUE; VISUAL TEACH; NAVIGATION;
   INFORMATION; EXPLORATION; PERCEPTION; REPEAT; HRI},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {lars@robots.ox.ac.uk
   nickh@robots.ox.ac.uk
   tduckett@lincoln.ac.uk
   mhanheide@lincoln.ac.uk
   tomas.krajnik@fel.cvut.cz},
Affiliations = {League of European Research Universities - LERU; University of Oxford;
   University of Lincoln; Czech Technical University Prague},
ResearcherID-Numbers = {Hanheide, Marc/AAO-9299-2021
   Krajnik, Tomas/P-9137-2014
   },
ORCID-Numbers = {Hanheide, Marc/0000-0001-7728-1849
   Kunze, Lars/0000-0001-5302-1938
   Krajnik, Tomas/0000-0002-4408-7916
   Hawes, Nick/0000-0002-7556-6098},
Funding-Acknowledgement = {EPSRC {[}EP/M019918/1, EP/R02572X/1]; EU {[}732737]; CZ {[}17-27006Y,
   CZ.02.1.01/0.0/0.0/16\_019/0000765]},
Funding-Text = {This work was supported in part by EPSRC under Grants EP/M019918/1 and
   EP/R02572X/1 (NCNR), in part by EU project No. 732737 (ILIAD), and in
   part by CZ projects 17-27006Y and CZ.02.1.01/0.0/0.0/16\_019/0000765.},
Cited-References = {Ambrus R, 2014, IEEE INT C INT ROBOT, P1854, DOI 10.1109/IROS.2014.6942806.
   Balint-Benczedi F, 2017, 2017 18TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P25, DOI 10.1109/ICAR.2017.8023492.
   Barfoot T, 2013, INT J ROBOT RES, V32, P1609, DOI 10.1177/0278364913511182.
   Baxter P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178126.
   Bechar A, 2016, BIOSYST ENG, V149, P94, DOI 10.1016/j.biosystemseng.2016.06.014.
   Beetz M, 2015, IEEE INT CONF ROBOT, P1549, DOI 10.1109/ICRA.2015.7139395.
   Beetz M, 2015, IEEE INT CONF ROBOT, P1983, DOI 10.1109/ICRA.2015.7139458.
   Beyer L, 2017, IEEE COMPUT SOC CONF, P1444, DOI 10.1109/CVPRW.2017.187.
   Biswas J, 2016, IEEE INTELL SYST, V31, P86, DOI 10.1109/MIS.2016.53.
   Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
   Bresina J. L., 2005, ICAPS, P40.
   Broggi Alberto, 2012, International Journal of Vehicle Autonomous Systems, V10, P147.
   Broggi A., 1999, International Journal of Intelligent Control and Systems, V3, P409.
   Brugali D, 2009, IEEE ROBOT AUTOM MAG, V16, P9, DOI 10.1109/MRA.2009.932127.
   Burgard W, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P11.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Cashmore M, 2015, P I C AUTOMAT PLAN S, P333.
   Chien S, 2017, J AEROSP INFORM SYST, V14, P307, DOI 10.2514/1.I010386.
   Chrpa L, 2015, IEEE INT C INT ROBOT, P1685, DOI 10.1109/IROS.2015.7353594.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Coppola C., 2016, P 22 EUR C ART INT, P85.
   Dayoubm F., 2011, ROBOTICS AUTONOMOUS, V5, P285.
   de Graaf MMA, 2016, INTERACT STUD, V17, P461, DOI 10.1075/is.17.3.08deg.
   Dickmanns E. D., 2007, DYNAMIC VISION PERCE.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Duckworth P, 2016, AAMAS'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS \& MULTIAGENT SYSTEMS, P1043.
   Eriksen C, 2018, 2018 SECOND IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING (IRC), P282, DOI 10.1109/IRC.2018.00060.
   Fentanes JP, 2015, IEEE INT CONF ROBOT, P1112, DOI 10.1109/ICRA.2015.7139315.
   Folkesson, 2018, ARXIV PREPRINT ARXIV.
   Foster ME, 2016, LECT NOTES ARTIF INT, V9979, P753, DOI 10.1007/978-3-319-47437-3\_74.
   Furgale P, 2015, J FIELD ROBOT, V32, P629, DOI 10.1002/rob.21619.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Gadd M, 2015, IEEE INT CONF ROBOT, P3271, DOI 10.1109/ICRA.2015.7139650.
   Goldberg S., 2002, P IEEE AER C BIG SKY.
   Griffith S, 2017, J FIELD ROBOT, V34, P188, DOI 10.1002/rob.21664.
   Gross HM, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2005, DOI 10.1109/IROS.2009.5354497.
   Kasaei SH, 2018, NEUROCOMPUTING, V291, P151, DOI 10.1016/j.neucom.2018.02.066.
   Hanheide M, 2017, ACMIEEE INT CONF HUM, P341, DOI 10.1145/2909824.3020228.
   Hawes N, 2017, IEEE ROBOT AUTOM MAG, V24, P146, DOI 10.1109/MRA.2016.2636359.
   Ingrand F, 2017, ARTIF INTELL, V247, P10, DOI 10.1016/j.artint.2014.11.003.
   Iocchi L, 2016, P I C AUTOMAT PLAN S, P486.
   Jacq A, 2016, ACMIEEE INT CONF HUM, P239, DOI 10.1109/HRI.2016.7451758.
   Jing Dong, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3878, DOI 10.1109/ICRA.2017.7989447.
   Jochem T., 1995, Proceedings of the Intelligent Vehicles `95. Symposium (Cat. No.95TH8132), P107, DOI 10.1109/IVS.1995.528266.
   Jones C. P., 2012, 2012 IEEE OES AUTONO, P1, DOI DOI 10.1109/AUV.2012.6380738.
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239.
   Kanda T, 2007, IEEE T ROBOT, V23, P962, DOI 10.1109/TRO.2007.904904.
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Korein M, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS \& MULTIAGENT SYSTEMS, P429.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Krajnik T, 2017, ROBOT AUTON SYST, V88, P127, DOI 10.1016/j.robot.2016.11.011.
   Krajnik T, 2015, IEEE INT CONF ROBOT, P2140, DOI 10.1109/ICRA.2015.7139481.
   Krajnik T, 2010, J FIELD ROBOT, V27, P511, DOI 10.1002/rob.20354.
   Kucner T, 2013, IEEE INT C INT ROBOT, P1196, DOI 10.1109/IROS.2013.6696502.
   Kunz C, 2009, J FIELD ROBOT, V26, P411, DOI 10.1002/rob.20288.
   Lacerda B, 2014, IEEE INT C INT ROBOT, P1511, DOI 10.1109/IROS.2014.6942756.
   Latif Y., 2018, P INT C ROB AUT.
   Leite I, 2013, INT J SOC ROBOT, V5, P291, DOI 10.1007/s12369-013-0178-y.
   Lowry S, 2016, IEEE T ROBOT, V32, P600, DOI 10.1109/TRO.2016.2545711.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   Mason J, 2012, IEEE INT C INT ROBOT, P3851, DOI 10.1109/IROS.2012.6385729.
   Meeussen W., 2011, P INT C ROB AUT LTAW, P300.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Miller Justin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1402, DOI 10.1109/ICRA.2017.7989167.
   Molina Sergi, 2018, Towards Autonomous Robotic Systems. 19th Annual Conference, TAROS 2018 Proceedings: Lecture Notes in Artificial Intelligence (LNAI 10965), P135, DOI 10.1007/978-3-319-96728-8\_12.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Neubert P, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P198, DOI 10.1109/ECMR.2013.6698842.
   Nourbakhsh IR, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3636.
   Oettershagen P, 2017, J FIELD ROBOT, V34, P1352, DOI 10.1002/rob.21717.
   Olsen D.R., 2004, HUMAN FACTORS COMPUT, P231.
   Palomeras N, 2016, AUTON ROBOT, V40, P1279, DOI 10.1007/s10514-015-9511-7.
   Paton M., 2018, FIELD SERVICE ROBOTI, P415.
   Paton M, 2017, J FIELD ROBOT, V34, P98, DOI 10.1002/rob.21669.
   Peloquin RA, 2017, IEEE ROBOT AUTOM LET, V2, P381, DOI 10.1109/LRA.2016.2633623.
   Pinillos R, 2016, ROBOT AUTON SYST, V79, P40, DOI 10.1016/j.robot.2016.01.014.
   Porav H., 2018, P IEEE INT C ROB AUT.
   Pratama F, 2017, J EXP THEOR ARTIF IN, V29, P313, DOI 10.1080/0952813X.2015.1134679.
   Quigley M., 2009, P ICRA WORKSH OP SOU.
   Rajan K, 2017, ARTIF INTELL, V247, P1, DOI 10.1016/j.artint.2017.03.003.
   Riazuelo L, 2015, IEEE T AUTOM SCI ENG, V12, P432, DOI 10.1109/TASE.2014.2377791.
   Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek.
   Rosenthal S, 2012, J INTELL ROBOT SYST, V66, P205, DOI 10.1007/s10846-011-9610-4.
   Rossi S, 2017, PATTERN RECOGN LETT, V99, P3, DOI 10.1016/j.patrec.2017.06.002.
   Santos JM, 2016, IEEE ROBOT AUTOM LET, V1, P684, DOI 10.1109/LRA.2016.2516594.
   Schlegel C, 2015, IT-INF TECHNOL, V57, P85, DOI 10.1515/itit-2014-1069.
   Seshia S. A., 2016, ARXIV160608514.
   Stachniss C., 2005, P C ART INT, P1324.
   Sun L., 2018, P INT C ROB AUT.
   Thrun S, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1999, DOI 10.1109/ROBOT.1999.770401.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Toris Russell, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3215, DOI 10.1109/ICRA.2017.7989365.
   Tran TT, 2017, J ARTIF INTELL RES, V58, P523, DOI 10.1613/jair.5306.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Veloso M, 2012, IEEE INT C INT ROBOT, P5446, DOI 10.1109/IROS.2012.6386300.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Winder J., 2016, P 25 INT JOINT C ART, P4040.
   Withers Dan, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6233, DOI 10.1109/ICRA.2017.7989738.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Wurman PR, 2008, AI MAG, V29, P9.
   Yan Z, 2017, IEEE INT C INT ROBOT, P864, DOI 10.1109/IROS.2017.8202247.
   Young J, 2016, FRONT ARTIF INTEL AP, V285, P1458, DOI 10.3233/978-1-61499-672-9-1458.},
Number-of-Cited-References = {103},
Times-Cited = {43},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {104},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GQ7PI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000441935900005},
OA = {Green Submitted, Green Accepted},
DA = {2022-05-17},
}

@article{ WOS:000450077900005,
Author = {MacTavish, Kirk and Paton, Michael and Barfoot, Timothy D.},
Title = {Selective memory: Recalling relevant experience for long-term visual
   localization},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2018},
Volume = {35},
Number = {8, SI},
Pages = {1265-1292},
Month = {DEC},
Abstract = {Visual navigation is a key enabling technology for autonomous mobile
   vehicles. The ability to provide large-scale, long-term navigation using
   low-cost, low-power vision sensors is appealing for industrial
   applications. A crucial requirement for long-term navigation systems is
   the ability to localize in environments whose appearance is constantly
   changing over time-due to lighting, weather, seasons, and physical
   changes. This paper presents a multiexperience localization (MEL) system
   that uses a powerful map representation-storing every visual experience
   in layers-that does not make assumptions about underlying appearance
   modalities and generators. Our localization system provides real-time
   performance by selecting online, a subset of experiences against which
   to localize. We achieve this task through a novel experience-triage
   algorithm based on collaborative filtering, which selects experiences
   relevant to the live view, outperforming competing techniques. Based on
   classical memory-based recommender systems, this technique also enables
   landmark-level recommendations, is entirely online, and requires no
   training data. We demonstrate the capabilities of the MEL system in the
   context of long-term autonomous path following in unstructured outdoor
   environments with a challenging 100-day field experiment through day,
   night, snow, spring, and summer. We furthermore provide offline analysis
   comparing our system to several state-of-the-art alternatives. We show
   that the combination of the novel methods presented in this paper enable
   full use of incredibly rich multiexperience maps, opening the door to
   robust long-term visual localization.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {MacTavish, K (Corresponding Author), Univ Toronto, Inst Aerosp Studies, 4925 Dufferin St, N York, ON M3H 5T6, Canada.
   MacTavish, Kirk; Paton, Michael; Barfoot, Timothy D., Univ Toronto, Inst Aerosp Studies, Fac Appl Sci \& Engn, Toronto, ON, Canada.},
DOI = {10.1002/rob.21838},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords = {mapping; position estimation; terrestrial robotics},
Keywords-Plus = {NAVIGATION; REPEAT; TEACH},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {kirk.mactavish@mail.utoronto.ca},
Affiliations = {University of Toronto},
Funding-Acknowledgement = {Clearpath Robotics; NSERC Canadian Field Robotics Network (NCFRN);
   Natural Sciences and Engineering Research Council (NSERC)},
Funding-Text = {Clearpath Robotics; NSERC Canadian Field Robotics Network (NCFRN);
   Natural Sciences and Engineering Research Council (NSERC)},
Cited-References = {Agarwal P, 2013, IEEE INT CONF ROBOT, P62, DOI 10.1109/ICRA.2013.6630557.
   Anderson S, 2015, IEEE INT C INT ROBOT, P157, DOI 10.1109/IROS.2015.7353368.
   Barfoot, 2014, ICRA WORKSH VIS PLAC, P1.
   Barfoot T., 2017, STATE ESTIMATION ROB.
   Barfoot TD, 2016, SPRINGER TRAC ADV RO, V114, P487, DOI 10.1007/978-3-319-28872-7\_28.
   Barfoot TD, 2014, IEEE T ROBOT, V30, P679, DOI 10.1109/TRO.2014.2298059.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Clement L, 2018, IEEE ROBOT AUTOM LET, V3, P2447, DOI 10.1109/LRA.2018.2799741.
   Costante G, 2016, IEEE ROBOT AUTOM LET, V1, P18, DOI 10.1109/LRA.2015.2505717.
   Csurka G., 2004, WORKSH STAT LEARN CO, V1, P1, DOI DOI 10.1234/12345678.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   GALLER BA, 1964, COMMUN ACM, V7, P301, DOI 10.1145/364099.364331.
   Girdhar Y., 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P191, DOI 10.1109/CRV.2011.32.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Klein George, 2007, P1.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Liu N, 2010, APPL MECH MATER, V29-32, P95, DOI 10.4028/www.scientific.net/AMM.29-32.95.
   Lowry SM, 2014, IEEE INT CONF ROBOT, P3950, DOI 10.1109/ICRA.2014.6907432.
   MacTavish Kirk, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2065, DOI 10.1109/ICRA.2017.7989238.
   MacTavish K, 2016, SPRINGER TRAC ADV RO, V113, P187, DOI 10.1007/978-3-319-27702-8\_13.
   MacTavish K, 2015, 2015 12TH CONFERENCE ON COMPUTER AND ROBOT VISION CRV 2015, P62, DOI 10.1109/CRV.2015.52.
   Maddern W, 2015, IEEE INT CONF ROBOT, P1684, DOI 10.1109/ICRA.2015.7139414.
   McManus C., 2014, ROBOTICS SCI SYSTEMS.
   McManus C, 2013, J FIELD ROBOT, V30, P254, DOI 10.1002/rob.21444.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Ostafew CJ, 2016, J FIELD ROBOT, V33, P133, DOI 10.1002/rob.21587.
   Pascoe G, 2015, IEEE INT CONF ROBOT, P6366, DOI 10.1109/ICRA.2015.7140093.
   Paton M., 2018, FIELD SERVICE ROBOTI, P415.
   Paton M, 2017, J FIELD ROBOT, V34, P98, DOI 10.1002/rob.21669.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   POWELL MJD, 1964, COMPUT J, V7, P155, DOI 10.1093/comjnl/7.2.155.
   Sunderhauf N, 2012, IEEE INT C INT ROBOT, P1879, DOI 10.1109/IROS.2012.6385590.
   Sunderhauf N., 2015, P ROB SCI SYST 12.
   Teynor A, 2007, LECT NOTES COMPUT SC, V4841, P610.
   TRAHANIAS P, 1989, PATTERN RECOGN, V22, P449, DOI 10.1016/0031-3203(89)90053-8.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.},
Number-of-Cited-References = {45},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {12},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {HA2OG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000450077900005},
DA = {2022-05-17},
}

@article{ WOS:000210740700009,
Author = {Bazeille, Stephane and Battesti, Emmanuel and Filliat, David},
Title = {A Light Visual Mapping and Navigation Framework for Low-Cost Robots},
Journal = {JOURNAL OF INTELLIGENT SYSTEMS},
Year = {2015},
Volume = {24},
Number = {4},
Pages = {505-524},
Month = {DEC},
Abstract = {We address the problems of localization, mapping, and guidance for
   robots with limited computational resources by combining vision with the
   metrical information given by the robot odometry. We propose in this
   article a novel light and robust topometric simultaneous localization
   and mapping framework using appearance-based visual loop-closure
   detection enhanced with the odometry. The main advantage of this
   combination is that the odometry makes the loop-closure detection more
   accurate and reactive, while the loop-closure detection enables the
   long-term use of odometry for guidance by correcting the drift. The
   guidance approach is based on qualitative localization using vision and
   odometry, and is robust to visual sensor occlusions or changes in the
   scene. The resulting framework is incremental, real-time, and based on
   cheap sensors provided on many robots (a camera and odometry encoders).
   This approach is, moreover, particularly well suited for low-power
   robots as it is not dependent on the image processing frequency and
   latency, and thus it can be applied using remote processing. The
   algorithm has been validated on a Pioneer P3DX mobile robot in indoor
   environments, and its robustness is demonstrated experimentally for a
   large range of odometry noise levels.},
Publisher = {WALTER DE GRUYTER GMBH},
Address = {GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY},
Type = {Article},
Language = {English},
Affiliation = {Bazeille, S (Corresponding Author), IIT, Dept Adv Robot, Via Morego 30, I-16163 Genoa, Italy.
   Bazeille, Stephane, IIT, Dept Adv Robot, Via Morego 30, I-16163 Genoa, Italy.
   Battesti, Emmanuel; Filliat, David, ENSTA ParisTech, INRIA FLOWERS Team, F-91762 Palaiseau, France.},
DOI = {10.1515/jisys-2014-0116},
ISSN = {0334-1860},
EISSN = {2191-026X},
Keywords = {Visual loop-closure detection; topological SLAM; path following},
Keywords-Plus = {LOOP-CLOSURE DETECTION; LOCALIZATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {stephane.bazeille@gmail.com},
Affiliations = {Istituto Italiano di Tecnologia - IIT; Institut Polytechnique de Paris},
ResearcherID-Numbers = {FILLIAT, David/ABD-6165-2020
   Bazeille, Stéphane/AAF-3158-2020},
ORCID-Numbers = {FILLIAT, David/0000-0002-5739-1618
   Bazeille, Stéphane/0000-0001-9670-9863},
Cited-References = {Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8\_8.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Angeli A, 2008, IEEE INT CONF ROBOT, P1842, DOI 10.1109/ROBOT.2008.4543475.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Bazeille S., 2011, EUR C MOB ROB, P303.
   Bazeille S., 2011, P INT C ROB AUT.
   Blanco JL, 2009, ROBOT AUTON SYST, V57, P64, DOI 10.1016/j.robot.2008.02.002.
   Booij O, 2007, IEEE INT CONF ROBOT, P3927, DOI 10.1109/ROBOT.2007.364081.
   Burschka D., 2001, P INT C ROB AUT.
   Chen ZC, 2009, IEEE T ROBOT, V25, P749, DOI 10.1109/TRO.2009.2017140.
   Correa J, 2010, J INTELL ROBOT SYST, V58, P339, DOI 10.1007/s10846-009-9348-4.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dijkstra EW, 1959, NUMER MATH, V1, P269, DOI 10.1007/BF01386390.
   Diosi A, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4271.
   Duckett T, 2002, AUTON ROBOT, V12, P287, DOI 10.1023/A:1015269615729.
   Eade E, 2007, IEEE I CONF COMP VIS, P2112.
   Filliat D., 2002, P 7 INT C SIM AD BEH, P131.
   Fraundorfer F, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3878.
   Frese U, 2005, IEEE T ROBOT, V21, P196, DOI 10.1109/TRO.2004.839220.
   Galvez-Lopez D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Grisetti G., 2007, ROBOTICS SCI SYSTEMS, V3, P65.
   Howard A, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1055, DOI 10.1109/IROS.2001.976308.
   Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972.
   Kaess Michael, 2011, 2011 IEEE International Conference on Robotics and Automation, P3281.
   Kawewong A, 2011, ROBOT AUTON SYST, V59, P727, DOI 10.1016/j.robot.2011.05.007.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Kosecka J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Rybski P., 2003, IEEE INT C ROB AUT.
   Saedan M., 2007, P IEEE ASME INT C AD, P1.
   Sagues C, 2005, ROBOT AUTON SYST, V50, P41, DOI 10.1016/j.robot.2004.08.005.
   Sibley G., 2009, ROBOTICS SCI SYSTEMS.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Siyao Fu, 2009, 2009 International Conference on Networking, Sensing and Control, P663, DOI 10.1109/ICNSC.2009.4919356.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Valgren C, 2007, IEEE INT CONF ROBOT, P4283, DOI 10.1109/ROBOT.2007.364138.
   Zivkovic Z., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2480.},
Number-of-Cited-References = {44},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {J. Intell. Syst.},
Doc-Delivery-Number = {V59CI},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000210740700009},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921704099,
Author = {Nashed, Samer and Biswas, Joydeep},
Book-Group-Author = {IEEE},
Title = {Curating Long-Term Vector Maps},
DOI = {10.1109/IROS.2016.7759683},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {4643-4648},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {Autonomous service mobile robots need to consistently, accurately, and
   robustly localize in human environments despite changes to such
   environments over time. Episodic non-Markov Localization addresses the
   challenge of localization in such changing environments by classifying
   observations as arising from Long-Term, Short-Term, or Dynamic Features.
   However, in order to do so, EnML relies on an estimate of the Long-Term
   Vector Map (LTVM) that does not change over time. In this paper, we
   introduce a recursive algorithm to build and update the LTVM over time
   by reasoning about visibility constraints of objects observed over
   multiple robot deployments. We use a signed distance function (SDF) to
   filter out observations of short-term and dynamic features from multiple
   deployments of the robot. The remaining long-term observations are used
   to build a vector map by robust local linear regression. The uncertainty
   in the resulting LTVM is computed via Monte Carlo resampling the
   observations arising from long-term features. By combining
   occupancy-grid based SDF filtering of observations with continuous space
   regression of the filtered observations, our proposed approach builds,
   updates, and amends LTVMs over time, reasoning about all observations
   from all robot deployments in an environment. We present experimental
   results demonstrating the accuracy, robustness, and compact nature of
   the extracted LTVMs from several long-term robot datasets.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Nashed, S (Corresponding Author), Univ Massachusetts, Coll Informat \& Comp Sci, Amherst, MA 01003 USA.
   Nashed, Samer; Biswas, Joydeep, Univ Massachusetts, Coll Informat \& Comp Sci, Amherst, MA 01003 USA.},
ISBN = {978-1-5090-3762-9},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {snashed@cs.umass.edu
   joydeepb@cs.umass.edu},
Affiliations = {University of Massachusetts System; University of Massachusetts Amherst},
ORCID-Numbers = {Biswas, Joydeep/0000-0002-1211-1731},
Cited-References = {Arbuckle D., 2002, IROS.
   Biber P, 2005, RSS.
   Biswas J., 2014, ICRA.
   Biswas J., 2012, IROS.
   Biswas R., 2002, IROS.
   Burgard W., 2007, AUTONOMOUS NAVIGATIO, P3, DOI 10.1007/978-3-540-73422- 2\_1.
   Bylow E., 2013, RSS.
   Chatila R., 1985, ROBOTICS AUTOMATION.
   Curless B., 1996, ACM.
   Elfes Alberto, 1989, USING OCCUPANCY GRID.
   Fischler M A, 1981, RANDOM SAMPLE CONSEN.
   Hahnel D., 2002, IROS.
   Krajnik T., 2014, ICRA.
   Moravec H. P., 1989, AAAI SPRING S ROB NA.
   PFISTER ST, 2003, ICRA.
   Saarinen J., 2012, IROS.
   Tipaldi G. D., 2013, IJRR.
   Walcott-Bryant A., 2012, IROS.
   Wolf D., 2005, AUTONOMOUS ROBOTS.
   Zhang L., 2000, ICRA.},
Number-of-Cited-References = {20},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921704099},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000609454000004,
Author = {Schaefer, Alexander and Buescher, Daniel and Vertens, Johan and Luft,
   Lukas and Burgard, Wolfram},
Title = {Long-term vehicle localization in urban environments based on pole
   landmarks extracted from 3-D lidar scans},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Pages = {103709},
Year = {2021},
Volume = {136},
Month = {FEB},
Abstract = {Due to their ubiquity and long-term stability, pole-like objects are
   well suited to serve as landmarks for vehicle localization in urban
   environments. In this work, we present a complete mapping and long-term
   localization system based on pole landmarks extracted from 3-D lidar
   data. Our approach features a novel pole detector, a mapping module, and
   an online localization module, each of which are described in detail,
   and for which we provide an open-source implementation (Schaefer and
   Buscher, 0000). In extensive experiments, we demonstrate that our method
   improves on the state of the art with respect to long-term reliability
   and accuracy: First, we prove reliability by tasking the system with
   localizing a mobile robot over the course of 15 months in an urban area
   based on an initial map, confronting it with constantly varying routes,
   differing weather conditions, seasonal changes, and construction sites.
   Second, we show that the proposed approach clearly outperforms a
   recently published method in terms of accuracy. (C) 2020 Elsevier B.V.
   All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Buscher, D (Corresponding Author), Univ Freiburg, Dept Comp Sci, Freiburg, Germany.
   Schaefer, Alexander; Buescher, Daniel; Vertens, Johan; Luft, Lukas; Burgard, Wolfram, Univ Freiburg, Dept Comp Sci, Freiburg, Germany.},
DOI = {10.1016/j.robot.2020.103709},
Article-Number = {103709},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Mapping; Localization; Lidar; Pole; Landmark; Feature extraction;
   Autonomous driving},
Keywords-Plus = {AUTOMATIC DETECTION; LIGHT POLES; OBJECTS; CLASSIFICATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {aschaef@cs.uni-freiburg.de
   buescher@cs.uni-freiburg.de
   vertensj@cs.uni-freiburg.de
   luft@cs.uni-freiburg.de
   burgard@cs.uni-freiburg.de},
Affiliations = {League of European Research Universities - LERU; University of Freiburg},
Funding-Acknowledgement = {Samsung Electronics Co. Ltd. under the GRO program},
Funding-Text = {This work has been partially supported by Samsung Electronics Co. Ltd.
   under the GRO program.},
Cited-References = {Brenner C, 2009, LECT NOTES COMPUT SC, V5748, P61.
   Buscher, LONG TERM URBAN VEHI.
   Cabo C, 2014, ISPRS J PHOTOGRAMM, V87, P47, DOI 10.1016/j.isprsjprs.2013.10.008.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Deusch H., 2014, P IEEE INT VEH S JUN, P555, DOI {[}10.1109/IVS.2014.6856413, DOI 10.1109/IVS.2014.6856413].
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/tit.1975.1055330.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Hata AY, 2016, IEEE T INTELL TRANSP, V17, P420, DOI 10.1109/TITS.2015.2477817.
   Huang J, 2015, IEEE INT CONF ROBOT, P3032, DOI 10.1109/ICRA.2015.7139615.
   Im JH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081268.
   Kummerle J, 2019, IEEE INT CONF ROBOT, P5965, DOI 10.1109/ICRA.2019.8793497.
   Lehtomaki M, 2010, REMOTE SENS-BASEL, V2, P641, DOI 10.3390/rs2030641.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li FS, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10040531.
   Luft L, 2017, IEEE INT C INT ROBOT, P6678, DOI 10.1109/IROS.2017.8206583.
   Blanco-Claraco JL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143155.
   Modsching M., 2006, P 3 WORKSH POS NAV C.
   Ordonez C, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071465.
   Qin B, 2012, IEEE INT CONF ROBOT, P2640, DOI 10.1109/ICRA.2012.6224913.
   Rodriguez-Cuenca B, 2015, REMOTE SENS-BASEL, V7, P12680, DOI 10.3390/rs71012680.
   Schindler A, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P134, DOI 10.1109/IVWorkshops.2013.6615239.
   Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509.
   Sefati M, 2017, IEEE INT VEH SYM, P13, DOI 10.1109/IVS.2017.7995692.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Tombari F, 2014, IEEE INT C INT ROBOT, P4922, DOI 10.1109/IROS.2014.6943262.
   Tombari F, 2009, ICINCO 2009: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL 2, P5.
   Wang R., 2016, INT ARCH PHOTOGRAMM, V41.
   Welzel A, 2015, IEEE INT C INTELL TR, P2728, DOI 10.1109/ITSC.2015.438.
   Weng LH, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P96, DOI 10.1109/RCAR.2018.8621688.
   Wu F, 2017, IEEE T INTELL TRANSP, V18, P292, DOI 10.1109/TITS.2016.2565698.
   Yan WY, 2016, OPT LASER TECHNOL, V77, P162, DOI 10.1016/j.optlastec.2015.09.017.
   Yokoyama H., 2013, INT J CADCAM, V13, P31.
   Yu YT, 2015, IEEE T GEOSCI REMOTE, V53, P1374, DOI 10.1109/TGRS.2014.2338915.},
Number-of-Cited-References = {35},
Times-Cited = {3},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {9},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {PU7BC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000609454000004},
DA = {2022-05-17},
}

@article{ WOS:000733501100001,
Author = {Nguyen, Thien-Minh and Cao, Muqing and Yuan, Shenghai and Lyu, Yang and
   Nguyen, Thien Hoang and Xie, Lihua},
Title = {VIRAL-Fusion: A Visual-Inertial-Ranging-Lidar Sensor Fusion Approach},
Journal = {IEEE TRANSACTIONS ON ROBOTICS},
Year = {2022},
Volume = {38},
Number = {2},
Pages = {958-977},
Month = {APR},
Abstract = {In recent years, onboard self-localization (OSL) methods based on
   cameras or lidar have achieved many significant progresses. However,
   some issues such as estimation drift and robustness in low-texture
   environment still remain inherent challenges for OSL methods. On the
   other hand, infrastructure-based methods can generally overcome these
   issues, but at the expense of some installation cost. This poses an
   interesting problem of how to effectively combine these methods, so as
   to achieve localization with long-term consistency as well as
   flexibility compared to any single method. To this end, we propose a
   comprehensive optimization-based estimator for the 15-D state of an
   unmanned aerial vehicle (UAV), fusing data from an extensive set of
   sensors: inertial measurement unit (IMU), ultrawideband (UWB) ranging
   sensors, and multiple onboard visual-inertial and lidar odometry
   subsystems. In essence, a sliding window is used to formulate a sequence
   of robot poses, where relative rotational and translational constraints
   between these poses are observed in the IMU preintegration and OSL
   observations, while orientation and position are coupled in the
   body-offset UWB range observations. An optimization-based approach is
   developed to estimate the trajectory of the robot in this sliding
   window. We evaluate the performance of the proposed scheme in multiple
   scenarios, including experiments on public datasets, high-fidelity
   graphical-physical simulation, and field-collected data from UAV flight
   tests. The result demonstrates that our integrated localization method
   can effectively resolve the drift issue, while incurring minimal
   installation requirements.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Nguyen, TM (Corresponding Author), Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.
   Nguyen, Thien-Minh; Cao, Muqing; Yuan, Shenghai; Lyu, Yang; Nguyen, Thien Hoang; Xie, Lihua, Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.},
DOI = {10.1109/TRO.2021.3094157},
EarlyAccessDate = {JUL 2021},
ISSN = {1552-3098},
EISSN = {1941-0468},
Keywords = {Quaternions; Location awareness; Matrix converters; Visualization;
   Simultaneous localization and mapping; Laser radar; Distance
   measurement; Aerial robots; localization; optimization},
Keywords-Plus = {LOCALIZATION; VERSATILE; ODOMETRY; SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {thienminh.npn@gmail.com
   mqcao@ntu.edu.sg
   shyuan@ntu.edu.sg
   lyu.yang@ntu.edu.sg
   e180071@e.ntu.edu.sg
   elhxie@ntu.edu.sg},
Affiliations = {Nanyang Technological University \& National Institute of Education
   (NIE) Singapore; Nanyang Technological University},
ORCID-Numbers = {Nguyen, Thien/0000-0003-1218-0910
   Nguyen, Thien-Minh/0000-0003-1315-0967
   Xie, Lihua/0000-0002-7137-4136},
Funding-Acknowledgement = {Autonomous Systems and Software Program (WASP) - Knut and Alice
   Wallenberg Foundation, under the Wallenberg-NTU Presidential
   Postdoctoral Fellowship Program},
Funding-Text = {This work was supported by theWallenberg AI, Autonomous Systems and
   Software Program (WASP), funded by the Knut and Alice Wallenberg
   Foundation, under the Wallenberg-NTU Presidential Postdoctoral
   Fellowship Program. This paper was recommended for publication by
   Associate Editor R. Tron and Editor F. Chaumette upon evaluation of the
   reviewers' comments.},
Cited-References = {Agarwal S., 2018, CERES SOLVER TUTORIA.
   Bloesch M, 2015, IEEE INT C INT ROBOT, P298, DOI 10.1109/IROS.2015.7353389.
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033.
   Campos Carlos, 2021, IEEE Transactions on Robotics, V37, P1874, DOI 10.1109/TRO.2021.3075644.
   Cao MQ, 2020, IEEE INT CONF CON AU, P1149, DOI 10.1109/ICCA51439.2020.9264577.
   Cao YJ, 2020, VIR SLAM VISUAL INER.
   Chirikjian GS, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-4944-9.
   Dellaert F, 2017, FDN TRENDS ROBOT, V6, P1.
   Djugash J, 2012, INT J ROBOT RES, V31, P604, DOI 10.1177/0278364912441039.
   Eckenhoff K, 2019, INT J ROBOT RES, V38, P563, DOI 10.1177/0278364919835021.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Fang X, 2021, IEEE T SYST MAN CY-S, V51, P6830, DOI 10.1109/TSMC.2020.2964713.
   Fang X, 2018, I C CONT AUTOMAT ROB, P1973, DOI 10.1109/ICARCV.2018.8581124.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Guo KX, 2016, UNMANNED SYST, V4, P23, DOI 10.1142/S2301385016400033.
   Huang WB, 2020, IEEE T ROBOT, V36, P1153, DOI 10.1109/TRO.2019.2959161.
   Karrer M., 2020, DISTRIBUTED VARIABLE.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Li JX, 2018, IEEE INT CONF CON AU, P100, DOI 10.1109/ICCA.2018.8444329.
   Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917.
   Mautz R., 2012, THESIS, DOI {[}10.3929/ethz-a-007313554, DOI 10.3929/ETHZ-A-007313554].
   Mueller MW, 2015, IEEE INT CONF ROBOT, P1730, DOI 10.1109/ICRA.2015.7139421.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Nguyen T.-M., INT J ROBOT RES, V2021.
   Nguyen T.-M., 2016, 2016 INT MICR VEH C, P56.
   Nguyen TM, 2020, IEEE T ROBOT, V36, P553, DOI 10.1109/TRO.2019.2954677.
   Nguyen TM, 2020, IEEE T CONTR SYST T, V28, P2021, DOI 10.1109/TCST.2019.2916089.
   Oleynikova H, 2020, J FIELD ROBOT, V37, P642, DOI 10.1002/rob.21950.
   Paredes JA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010089.
   Qin T, 2018, IEEE INT C INT ROBOT, P3662, DOI 10.1109/IROS.2018.8593603.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Queralta J. P., 2020, VIO UWBBASED COLLABO.
   Shah S., 2017, FIELD SERVICE ROBOTI, P621, DOI DOI 10.1007/978-3-319-67361-5.
   Shan TX, 2020, IEEE INT C INT ROBOT, P5135, DOI 10.1109/IROS45743.2020.9341176.
   Sola J., 2018, ARXIV PREPRINT ARXIV.
   Song Y, 2019, IEEE INT CONF ROBOT, P6568, DOI 10.1109/ICRA.2019.8794222.
   Nguyen TH, 2020, IEEE INT CONF ROBOT, P665, DOI 10.1109/ICRA40945.2020.9196794.
   Nguyen TH, 2020, AUTON ROBOT, V44, P1519, DOI 10.1007/s10514-020-09944-7.
   Nguyen TH, 2020, UNMANNED SYST, V8, P179, DOI 10.1142/S2301385020500119.
   Nguyen TM, 2019, IEEE ROBOT AUTOM LET, V4, P3641, DOI 10.1109/LRA.2019.2926671.
   Tiemann J, 2017, INT C INDOOR POSIT, DOI 10.1109/ipin.2017.8115937.
   Wang C, 2017, IEEE INT C INT ROBOT, P1602, DOI 10.1109/IROS.2017.8205968.
   Weinstein Aaron, 2018, IEEE Robotics and Automation Letters, V3, P1801, DOI 10.1109/LRA.2018.2800119.
   Xu H, 2020, IEEE INT CONF ROBOT, P8776, DOI 10.1109/ICRA40945.2020.9196944.
   Ye HY, 2019, IEEE INT CONF ROBOT, P3144, DOI 10.1109/ICRA.2019.8793511.
   Yuan SH, 2021, UNMANNED SYST, V9, P129, DOI 10.1142/S230138502150014X.
   Zhang J, 2018, J FIELD ROBOT, V35, P1242, DOI 10.1002/rob.21809.
   Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941.},
Number-of-Cited-References = {50},
Times-Cited = {4},
Usage-Count-Last-180-days = {10},
Usage-Count-Since-2013 = {10},
Journal-ISO = {IEEE Trans. Robot.},
Doc-Delivery-Number = {0H8BQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000733501100001},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000389436600309,
Author = {Gao, Enyang and Chen, Zhaohua and Gao, Qizhuhui},
Editor = {Jing, W and Guiran, C and Huiyu, Z},
Title = {Particle Filter Based Robot Self-localization Using RGBD Cues and Wheel
   Odometry Measurements},
DOI = {10.2991/emim-16.2016.309},
Booktitle = {PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON ELECTRONIC,
   MECHANICAL, INFORMATION AND MANAGEMENT SOCIETY (EMIM)},
Series = {ACSR-Advances in Comptuer Science Research},
Year = {2016},
Volume = {40},
Pages = {1523-1529},
Note = {6th International Conference on Electronic, Mechanical, Information and
   Management Society (EMIM), Shenyang, PEOPLES R CHINA, APR 01-03, 2016},
Abstract = {Mobile robot localization in the GPS denied environments is increasingly
   exerting fundamental roles in a wide range of applications such as SFM
   and SLAM. However, the traditional single sensor based positioning
   methods are either unreliable or inaccurate in the long term. This paper
   presents a novel moving agent localizing approach that combines both
   RGBD cues and wheel odometry measurements within the particle filter
   based probabilistic framework. Unlike the traditional RGBD localization
   methods which are computationally expensive and non-robust, we took
   advantage of wheel odomery measurements as the prior information or say
   the initial values during the RBGD pose optimization process.
   Additionally, the optimal pose derived from visual sensor is, in turn,
   able to determine the reliability of the wheel odometry inputs. This
   verifying process is considerably useful in the presence of wheel slip.
   Experimental results validate that our approach is effective and
   reliable in wheel robot localization.},
Publisher = {ATLANTIS PRESS},
Address = {29 AVENUE LAVMIERE, PARIS, 75019, FRANCE},
Type = {Proceedings Paper},
Language = {English},
ISSN = {2352-538X},
ISBN = {978-94-6252-176-6},
Keywords = {Mobile robot; Self-localization; RGBD; Wheel odometry; Particle filter},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Theory \&
   Methods; Engineering, Electrical \& Electronic; Engineering, Mechanical},
Author-Email = {arnold0110@sina.com},
Cited-References = {Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684.
   Chen Z L, 2013, DEPTH CAMERA ASSISTE.
   Chi WZ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2703, DOI 10.1109/ROBIO.2013.6739882.
   Li J, 2012, IEEE T DIELECT EL IN, V19, P543, DOI 10.1109/TDEI.2012.6180248.
   Luo F, 2014, INT CONTR AUT WCICA, P3089.
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001.
   Stefan W, 2012, J SCI COMPUT, V50, P665, DOI 10.1007/s10915-011-9529-8.
   Tsai G-J, 2015, ISPRS INT ARCH PHOTO, VXL, P183, DOI {[}10.5194/isprsarchives-XL-1-W4-183-2015, DOI 10.5194/ISPRSARCHIVES-XL-1-W4-183-2015].
   Wang ZG, 2015, ADV MECH ENG, V7, DOI 10.1155/2014/305981.
   Zhu R, 2004, IEEE T NEUR SYS REH, V12, P295, DOI 10.1109/TNSRE.2004.827825.},
Number-of-Cited-References = {10},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BG5ED},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000389436600309},
DA = {2022-05-17},
}

@article{ WOS:000629731200026,
Author = {Yin, Peng and Xu, Lingyun and Zhang, Ji and Choset, Howie},
Title = {FusionVLAD: A Multi-View Deep Fusion Networks for Viewpoint-Free 3D
   Place Recognition},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {2},
Pages = {2304-2310},
Month = {APR},
Abstract = {Real-time 3D place recognition is a crucial technology to recover from
   localization failure in applications like autonomous driving, last-mile
   delivery, and service robots. However, it is challenging for 3D place
   retrieval methods to be accurate, efficient, and robust to the variant
   viewpoints differences. In this letter, we propose FusionVLAD, a
   fusion-based network that encodes a multiview representation of sparse
   3D point clouds into viewpoint-free global descriptors. The system
   consists of two parallel branches: a spherical-view branch for
   orientation-invariant feature extraction, and the top-down view branch
   for translation-insensitive feature extraction. Furthermore, we design a
   parallel fusion module to enhance the combination of region-wise feature
   connection between the two branches. Experiments on two public datasets
   and two generated datasets show that our method outperforms
   state-of-the-art with robust place recognition accuracy and efficient
   inference time. Besides, FusionVLAD requires limited computation
   resources and makes it extremely suitable for low-cost robots' long-term
   place recognition task.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Xu, LY (Corresponding Author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Yin, Peng; Xu, Lingyun; Zhang, Ji; Choset, Howie, Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.},
DOI = {10.1109/LRA.2021.3061375},
ISSN = {2377-3766},
Keywords = {Recognition; SLAM; visual learning},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {pyin2@andrew.cmu.edu
   hitmaxtom@gmail.com
   zhangji@cmu.edu
   choset@cs.cmu.edu},
Affiliations = {Carnegie Mellon University},
ResearcherID-Numbers = {Yin, Peng/AEY-2004-2022},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693.
   Esteves C, 2018, LECT NOTES COMPUT SC, V11217, P54, DOI 10.1007/978-3-030-01261-8\_4.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Liu Z, 2019, IEEE I CONF COMP VIS, P2831, DOI 10.1109/ICCV.2019.00292.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Qi CR, 2017, NEURIPS.
   Rho E., 2018, P 6 INT C BRAIN COMP, P1.
   Rohling T, 2015, IEEE INT C INT ROBOT, P736, DOI 10.1109/IROS.2015.7353454.
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x.
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1\_26.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760.
   Xiong T, 2014, BIOMED CIRC SYST C, P9, DOI 10.1109/BioCAS.2014.6981632.
   Zhang W., 2019, P IEEE C COMP VIS PA, P12436.},
Number-of-Cited-References = {19},
Times-Cited = {3},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {11},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {QY0LG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000629731200026},
DA = {2022-05-17},
}

@inproceedings{ WOS:000457843608080,
Author = {Sattler, Torsten and Maddern, Will and Toft, Carl and Torii, Akihiko and
   Hammarstrand, Lars and Stenborg, Erik and Safari, Daniel and Okutomi,
   Masatoshi and Pollefeys, Marc and Sivic, Josef and Kahl, Fredrik and
   Pajdla, Tomas},
Book-Group-Author = {IEEE},
Title = {Benchmarking 6DOF Outdoor Visual Localization in Changing Conditions},
Booktitle = {2018 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION
   (CVPR)},
Series = {IEEE Conference on Computer Vision and Pattern Recognition},
Year = {2018},
Pages = {8601-8610},
Note = {31st IEEE/CVF Conference on Computer Vision and Pattern Recognition
   (CVPR), Salt Lake City, UT, JUN 18-23, 2018},
Abstract = {Visual localization enables autonomous vehicles to navigate in their
   surroundings and augmented reality applications to link virtual to real
   worlds. Practical visual localization approaches need to be robust to a
   wide variety of viewing condition, including day-night changes, as well
   as weather and seasonal variations, while providing highly accurate 6
   degree-of-freedom (6DOF) camera pose estimates. In this paper, we
   introduce the first benchmark datasets specifically designed for
   analyzinp, the impact of such factors on-visual localization. Using
   carefully created ground truth poses Jr query images taken under a wide
   variety of conditions, we evaluate the impact of various factors on 6DOF
   camera pose estimation accuracy through extensive experiments with
   state-of-the-art localization approaches. Based on our results, we draw
   conclusions about the difficulty of different conditions, showing that
   long-term localization is far from solved, and propose promising avenues
   for future work, including sequence-based localization approaches and
   the need for better local features. Our benchmark is available at
   visuallocalization.net},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Sattler, T (Corresponding Author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   Sattler, Torsten; Pollefeys, Marc, Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   Maddern, Will, Univ Oxford, Oxford Robot Inst, Oxford, England.
   Toft, Carl; Hammarstrand, Lars; Stenborg, Erik; Kahl, Fredrik, Chalmers Univ Technol, Dept Elect Engn, Gothenburg, Sweden.
   Safari, Daniel; Okutomi, Masatoshi, Tokyo Inst Technol, Tokyo, Japan.
   Safari, Daniel, Tech Univ Denmark, Lyngby, Denmark.
   Pollefeys, Marc, Microsoft, Zurich, Switzerland.
   Sivic, Josef, PSL Res Univ, INRIA, WILLOW Project, Dept Informat,ENS,CNRS,UMR 8548, Paris, France.
   Sivic, Josef; Pajdla, Tomas, Czech Tech Univ, CIIRC, Prague, Czech Republic.
   Kahl, Fredrik, Lund Univ, Ctr Math Sci, Lund, Sweden.},
DOI = {10.1109/CVPR.2018.00897},
ISSN = {1063-6919},
ISBN = {978-1-5386-6420-9},
Keywords-Plus = {PROBABILISTIC LOCALIZATION; SLAM},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Affiliations = {ETH Zurich; League of European Research Universities - LERU; University
   of Oxford; Chalmers University of Technology; Tokyo Institute of
   Technology; Technical University of Denmark; Centre National de la
   Recherche Scientifique (CNRS); Inria; UDICE-French Research
   Universities; PSL Research University Paris; Ecole Normale Superieure
   (ENS); Universite de Paris; Czech Technical University Prague; League of
   European Research Universities - LERU; Lund University},
ResearcherID-Numbers = {Sattler, Torsten/AAM-3155-2021
   Pollefeys, Marc/I-7607-2013
   /C-1291-2019
   },
ORCID-Numbers = {/0000-0001-5676-1392
   Pajdla, Tomas/0000-0001-6325-0072
   Okutomi, Masatoshi/0000-0001-5787-0742},
Funding-Acknowledgement = {ERC grant LEAP {[}336845]; CIFAR Learning in Machines Brains program;
   EU-H2020 project {[}LADIO 731970]; European Regional Development Fund
   under the project IMPACT {[}CZ.02.1.01/0.0/0.0/15\_003/0000468]; JSPS
   KAKENHI {[}15H05313]; EPSRC Programme {[}EP/M019918/1]; Swedish Research
   Council {[}2016-04445]; Swedish Foundation for Strategic Research;
   Vinnova / FFI {[}2017-01942]},
Funding-Text = {This work was partially supported by ERC grant LEAP No. 336845, CIFAR
   Learning in Machines \& Brains program, EU-H2020 project LADIO 731970,
   the European Regional Development Fund under the project IMPACT (reg.
   no. (CZ.02.1.01/0.0/0.0/15\_003/0000468), JSPS KAKENHI Grant Number
   15H05313, EPSRC Programme Grant EP/M019918/1, the Swedish Research
   Council (grant no. 2016-04445), the Swedish Foundation for Strategic
   Research (Semantic Mapping and Visual Navigation for Smart. Robots), and
   Vinnova / FFI (Perceptron, grant no. 2017-01942).},
Cited-References = {Arandjelovic R., 2014, P ACCV.
   Arandjelovic R., 2012, P CVPR.
   Arandjelovic R., 2016, P CVPR.
   Badino H., 2011, P IV.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326.
   Brachmann E., 2016, P CVPR.
   Brachmann E., 2017, P CVPR.
   Camposeco F., 2017, P CVPR.
   Camposeco F., 2016, P ECCV.
   Cao S., 2013, P CVPR.
   Cao S., 2014, P CVPR.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Chen D. M., 2011, P CVPR.
   Chen Z., 2017, P ICRA.
   Choudhary S., 2012, P ECCV.
   Clark R., 2017, P CVPR.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Donoser M., 2014, P CVPR.
   Engel J., 2014, P ECCV.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Gronat P, 2016, INT J COMPUT VISION, V118, P319, DOI 10.1007/s11263-015-0878-x.
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0.
   Irschara A., 2009, P CVPR.
   Jegou H., 2010, P CVPR.
   Kendall A., 2015, P ICCV.
   Kneip L., 2011, P CVPR.
   Larsson V., 2016, P BMVC.
   Lee GH, 2015, INT J ROBOT RES, V34, P837, DOI 10.1177/0278364914557969.
   Li Y., 2012, P ECCV.
   Li Y., 2010, P ECCV.
   Linegar C., 2016, P ICRA.
   Linegar C., 2015, P ICRA.
   Liu L., 2017, P ICCV.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lynen S., 2015, P RSS.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Milford M., 2015, P CVPR WORKSH.
   Milford M. J., 2012, P ICRA.
   Muhlfellner P., 2015, J FIELD ROBOTICS.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer T., 2014, P AAAI.
   Naseer T., 2017, ICRA.
   Pless R., 2003, P CVPR.
   Radenovic F., 2016, P CVPR.
   Sattler T., 2012, P BMVC.
   Sattler T., 2018, ARXIV170709092.
   Sattler T., 2016, P CVPR.
   Sattler T., 2015, P ICCV.
   Sattler T., 2017, P CVPR.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Schonberger J. L., 2018, P CVPR.
   Schonberger J.L., 2016, P CVPR.
   Shotton J., 2013, P CVPR.
   Simonyan K., 2015, 3 INT C LEARNING REP.
   Sivic J., 2003, P ICCV.
   Sun X., 2017, P CVPR.
   Sunderhauf N., 2015, P IROS.
   Sunderhauf N., 2015, P RSS.
   Sunderhauf N., 2013, P ICRA WORKSH.
   Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331.
   Taira H., 2018, P CVPR.
   Torii A., 2015, IEEE PAMI.
   Torii A., 2015, P CVPR.
   Walch F., 2017, P ICCV.
   Wang S., 2017, P ICCV.
   Weyand T., 2016, P ECCV.
   Zeisl B., 2015, P ICCV.},
Number-of-Cited-References = {72},
Times-Cited = {144},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {14},
Doc-Delivery-Number = {BL9NZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000457843608080},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000633637000021,
Author = {Xu, Xuecheng and Yin, Huan and Chen, Zexi and Li, Yuehua and Wang, Yue
   and Xiong, Rong},
Title = {DiSCO: Differentiable Scan Context With Orientation},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {2},
Pages = {2791-2798},
Month = {APR},
Abstract = {Global localization is essential for robot navigation, of which the
   first step is to retrieve a query from the map database. This problem is
   called place recognition. In recent years, LiDAR scan based place
   recognition has drawn attention as it is robust against the appearance
   change. In this letter, we propose a LiDAR-based place recognition
   method, named Differentiable Scan Context with Orientation (DiSCO),
   which simultaneously finds the scan at a similar place and estimates
   their relative orientation. The orientation can further be used as the
   initial value for the down-stream local optimal metric pose estimation,
   improving the pose estimation especially when a large orientation
   between the current scan and retrieved scan exists. Our key idea is to
   transform the feature into the frequency domain. We utilize the
   magnitude of the spectrum as the place descriptor, which is
   theoretically rotation-invariant. In addition, based on the
   differentiable phase correlation, we can efficiently estimate the global
   optimal relative orientation using the spectrum. With such structural
   constraints, the network can be learned in an end-to-end manner, and the
   backbone is fully shared by the two tasks, achieving better
   interpretability and lightweight. Finally, DiSCO is validated on three
   datasets with long-term outdoor conditions, showing better performance
   than the compared methods. Codes are released at
   https://github.com/MaverickPeter/DiSCO-pytorch.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   Wang, Y (Corresponding Author), Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310027, Zhejiang, Peoples R China.
   Xu, Xuecheng; Yin, Huan; Chen, Zexi; Wang, Yue; Xiong, Rong, Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   Xu, Xuecheng; Yin, Huan; Chen, Zexi; Wang, Yue; Xiong, Rong, Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310027, Zhejiang, Peoples R China.
   Li, Yuehua, Zhejiang Lab, Hangzhou 310014, Zhejiang, Peoples R China.},
DOI = {10.1109/LRA.2021.3060741},
ISSN = {2377-3766},
Keywords = {Localization; range sensing; SLAM},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {xuechengxu@zju.edu.cn
   zjuyinhuan@gmail.com
   chenzexi@zju.edu.cn
   liyh@zhejianglab.com
   ywang24@zju.edu.cn
   rxiong\_zju@hotmail.com},
Affiliations = {Zhejiang University; Zhejiang University},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020
   },
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202
   Chen, Zexi/0000-0002-9782-6022
   Xu, Xuecheng/0000-0002-0762-6714},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018AAA0102700]; State
   Administration of Science, Technology and Industry for National Defence
   Grant, PRC {[}HTKJ2019KL502005]},
Funding-Text = {This work was supported in part by the National Key R\&D Program of
   China underGrant 2018AAA0102700 and in part by the stable support
   project of State Administration of Science, Technology and Industry for
   National Defence Grant, PRC under Grant HTKJ2019KL502005. (Corresponding
   author: Yue Wang.)},
Cited-References = {Andrei I., 2018, P C ROB LEARN, P605.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Barnes D., 2020, C ROB LEARN, P303.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Bulow H, 2020, IEEE INT CONF ROBOT, P8594, DOI 10.1109/ICRA40945.2020.9197453.
   Bulow H, 2018, INT J COMPUT VISION, V126, P731, DOI 10.1007/s11263-018-1067-5.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Chen XYL, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693.
   Dube Renaud, 2018, IEEE Robotics and Automation Letters, V3, P1832, DOI 10.1109/LRA.2018.2803213.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Kim G, 2020, IEEE INT CONF ROBOT, P6246.
   Kim G, 2019, IEEE ROBOT AUTOM LET, V4, P1948, DOI 10.1109/LRA.2019.2897340.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Kingma D. P., 2015, P INT C LEARN REPR.
   Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3\_43.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280.
   Schaupp L, 2019, IEEE INT C INT ROBOT, P3255, DOI 10.1109/IROS40897.2019.8968094.
   Steder B, 2011, IEEE INT C INT ROBOT, P1249, DOI 10.1109/IROS.2011.6048325.
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P1198, DOI 10.1109/34.177385.
   Tang L, 2020, IEEE INT CONF ROBOT, P1301, DOI 10.1109/ICRA40945.2020.9196518.
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Wang J, 2015, SOIL USE MANAGE, V31, P375, DOI 10.1111/sum.12202.
   Wang Y., 2020, ARXIV200809474.
   Yin H, 2018, IEEE INT VEH SYM, P728.
   Yin H, 2020, IEEE T INTELL TRANSP, V21, P1380, DOI 10.1109/TITS.2019.2905046.},
Number-of-Cited-References = {31},
Times-Cited = {5},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {11},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {RD7ET},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000633637000021},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000385157300006,
Author = {Ganesan, Varadarajan and Chitre, Mandar and Brekke, Edmund},
Title = {Robust underwater obstacle detection and collision avoidance},
Journal = {AUTONOMOUS ROBOTS},
Year = {2016},
Volume = {40},
Number = {7, SI},
Pages = {1165-1185},
Month = {OCT},
Abstract = {A robust obstacle detection and avoidance system is essential for long
   term autonomy of autonomous underwater vehicles (AUVs). Forward looking
   sonars are usually used to detect and localize obstacles. However, high
   amounts of background noise and clutter present in underwater
   environments makes it difficult to detect obstacles reliably. Moreover,
   lack of GPS signals in underwater environments leads to poor
   localization of the AUV. This translates to uncertainty in the position
   of the obstacle relative to a global frame of reference. We propose an
   obstacle detection and avoidance algorithm for AUVs which differs from
   existing techniques in two aspects. First, we use a local occupancy grid
   that is attached to the body frame of the AUV, and not to the global
   frame in order to localize the obstacle accurately with respect to the
   AUV alone. Second, our technique adopts a probabilistic framework which
   makes use of probabilities of detection and false alarm to deal with the
   high amounts of noise and clutter present in the sonar data. This local
   probabilistic occupancy grid is used to extract potential obstacles
   which are then sent to the command and control (C2) system of the AUV.
   The C2 system checks for possible collision and carries out an evasive
   maneuver accordingly. Experiments are carried out to show the viability
   of the proposed algorithm.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Ganesan, V (Corresponding Author), Natl Univ Singapore, Trop Marine Sci Inst, Dept Elect \& Comp Engn, Acoust Res Lab, Singapore, Singapore.
   Ganesan, Varadarajan; Chitre, Mandar, Natl Univ Singapore, Trop Marine Sci Inst, Dept Elect \& Comp Engn, Acoust Res Lab, Singapore, Singapore.
   Brekke, Edmund, Norwegian Univ Sci \& Technol, Dept Engn Cybernet, Trondheim, Norway.},
DOI = {10.1007/s10514-015-9532-2},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Obstacle Detection; Collision Avoidance; Local Occupancy Grids},
Keywords-Plus = {OCCUPANCY GRIDS; LOCALIZATION; ENVIRONMENTS; SLAM; MAP; NAVIGATION;
   SONAR},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {varadarajan@arl.nus.edu.sg
   mandar@arl.nus.edu.sg
   edmund.brekke@itk.ntnu.no},
Affiliations = {National University of Singapore; Norwegian University of Science \&
   Technology (NTNU)},
ResearcherID-Numbers = {Chitre, Mandar/B-1675-2016},
ORCID-Numbers = {Chitre, Mandar/0000-0001-6243-7871},
Cited-References = {Brekke E., 2013, P OCEANS 13, P1.
   Brekke E., 2010, OCEANS 2010 IEEE SYD, P1.
   Brekke E, 2011, IEEE T AERO ELEC SYS, V47, P2874, DOI 10.1109/TAES.2011.6034670.
   Burguera A, 2012, SENSORS-BASEL, V12, P7855, DOI 10.3390/s120607855.
   Castellanos JA, 2007, ROBOT AUTON SYST, V55, P21, DOI 10.1016/j.robot.2006.06.005.
   Chew J.L., 2013, 2013 OCEANS SAN DIEG, P1.
   Chitre MA, 2006, IEEE J OCEANIC ENG, V31, P497, DOI 10.1109/JOE.2006.875272.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Eliazar A., 2005, THESIS.
   Eliazar AI, 2004, IEEE INT CONF ROBOT, P1314, DOI 10.1109/ROBOT.2004.1308006.
   Fairfield N, 2007, J FIELD ROBOT, V24, P3, DOI 10.1002/rob.20165.
   Fulgenzi C, 2007, IEEE INT CONF ROBOT, P1610, DOI 10.1109/ROBOT.2007.363554.
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136.
   Hernandez E., 2009, IFAC P VOLUMES, V42, P286.
   Hidalgo F, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P306, DOI 10.1109/ICARA.2015.7081165.
   Horner DP, 2005, OCEANS-IEEE, P1464.
   Horner D. P., 2009, P INT S UNM UNT SUBM, P1464.
   Hurtos N, 2015, J FIELD ROBOT, V32, P123, DOI 10.1002/rob.21516.
   Jakuba M., 2008, P 2008 AUSTR C ROB A.
   Koay TB, 2011, INDIAN J GEO-MAR SCI, V40, P157.
   Konolige K, 1997, AUTON ROBOT, V4, P351, DOI 10.1023/A:1008806422571.
   Leedekerken J.-C., 2006, P 7 INT MIN WARF S M.
   Majumder S, 2001, LECT NOTES CONTR INF, V271, P511.
   Marlow S.Q., 2010, AIAA GUID NAV CONTR.
   Martin A, 2000, OCEANS 2000 MTS/IEEE - WHERE MARINE SCIENCE AND TECHNOLOGY MEET, VOLS 1-3, CONFERENCE PROCEEDINGS, P337, DOI 10.1109/OCEANS.2000.881281.
   Montemerlo M, 2003, IEEE INT CONF ROBOT, P1985, DOI 10.1109/ROBOT.2003.1241885.
   Moutarlier P., 1989, FIFTH INT S ROBOTICS, P85.
   Nerurkar Esha D, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P636, DOI 10.1109/IROS.2007.4399179.
   Nolan J., 1997, COMMUN STAT STOCHAST, V13, P759, DOI DOI 10.1080/15326349708807450.
   Quidu I, 2007, OCEANS 2007 - Europe, P1, DOI 10.1109/OCEANSE.2007.4302304.
   Ribas D, 2008, J FIELD ROBOT, V25, P898, DOI 10.1002/rob.20249.
   Richards M., 2005, FUNDAMENTALS RADAR S, P304.
   Shi Zhao, 2009, 2009 4th IEEE Conference on Industrial Electronics and Applications, P3648, DOI 10.1109/ICIEA.2009.5138887.
   STENTZ A, 1994, IEEE INT CONF ROBOT, P3310, DOI 10.1109/ROBOT.1994.351061.
   Teck TY, 2014, SPRINGER TRAC ADV RO, V104, P321, DOI 10.1007/978-3-642-55146-8\_23.
   Teck TY, 2012, AUT UND VEH AUV 2012, P1.
   Tena R. I., 1999, IEEE C MOT AN TRACK, p11/1.
   Teo K., 2009, OCEANS 2009 MTS IEEE, P1.
   Thrun S., 2005, PROBABILISTIC ROBOTI.},
Number-of-Cited-References = {39},
Times-Cited = {10},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {47},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {DY5QT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000385157300006},
DA = {2022-05-17},
}

@article{ WOS:000634833600001,
Author = {Azpurua, Hector and Rezende, Adriano and Potje, Guilherme and da Cruz
   Junior, Gilmar Pereira and Fernandes, Rafael and Miranda, Victor and de
   Resende Filho, Levi Welington and Domingues, Jaco and Rocha, Filipe and
   Martins de Sousa, Frederico Luiz and Dias de Barros, Luiz Guilherme and
   Nascinnento, Erickson R. and Macharet, Douglas G. and Pessin, Gustavo
   and Freitas, Gustavo M.},
Title = {Towards Semi-autonomous Robotic Inspection and Mapping in Confined
   Spaces with the EspeleoRobo},
Journal = {JOURNAL OF INTELLIGENT \& ROBOTIC SYSTEMS},
Year = {2021},
Volume = {101},
Number = {4},
Month = {MAR 25},
Abstract = {Autonomous mobile devices operating in confined environments, such as
   pipes, underground tunnel systems, and cave networks, face multiple open
   challenges from the robotics perspective. Those challenges, such as
   mobility, localization, and mapping in GPS denied scenarios, are
   receiving particular attention from the academy and industry. One
   example is the Brazilian mining company Vale S.A., which is employing a
   robot - EspeleoRobo (SpeleoRobot) - to access restricted and dangerous
   areas for human workers. The EspeleoRobo is a robot initially designed
   for natural cave inspection during teleoperated missions. It is now
   being used to monitor other types of confined environments, such as dam
   galleries and other restrained or dangerous areas. This paper describes
   the platform in its current version and the pipeline used for
   semi-autonomous inspection in confined environments. The pipeline
   includes photorealistic mapping techniques, Simultaneous Localization
   and Mapping (SLAM) with LiDAR, path planning based on mobility
   optimization, and navigation control using vector fields to reduce
   operator dependency of the robot operation. The proposed concept was
   validated in simulations with a realistic underground tunnel system and
   in representative real-world scenarios. The results endorse the
   viability of using the proposed concept for real deployments.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Azpurua, H (Corresponding Author), Univ Fed Minas Gerais, Comp Sci Dept, BR-31270901 Belo Horizonte, MG, Brazil.
   Azpurua, H (Corresponding Author), Inst Tecnol Vale ITV, BR-35400000 Ouro Preto, Brazil.
   Azpurua, Hector; Potje, Guilherme; Nascinnento, Erickson R.; Macharet, Douglas G., Univ Fed Minas Gerais, Comp Sci Dept, BR-31270901 Belo Horizonte, MG, Brazil.
   Azpurua, Hector; de Resende Filho, Levi Welington; Domingues, Jaco; Rocha, Filipe; Martins de Sousa, Frederico Luiz; Dias de Barros, Luiz Guilherme; Pessin, Gustavo, Inst Tecnol Vale ITV, BR-35400000 Ouro Preto, Brazil.
   Rezende, Adriano; da Cruz Junior, Gilmar Pereira; Fernandes, Rafael; Miranda, Victor; Freitas, Gustavo M., Univ Fed Minas Gerais, Elect Engn Dept, BR-31270901 Belo Horizonte, MG, Brazil.},
DOI = {10.1007/s10846-021-01321-5},
Article-Number = {69},
ISSN = {0921-0296},
EISSN = {1573-0409},
Keywords = {Subterranean exploration with mobile robots; 3D reconstruction and
   mapping; GPS-denied localization; path planning in rugged terrains;
   Vector field control},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; LONG-TERM; LARGE-SCALE; ALGORITHMS;
   NAVIGATION; LIDAR},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {hector.azpurua@dcc.ufmg.br
   adrianomcr@ufmg.br
   guipotje@dcc.ufmg.br
   gilmarpcjunior@ufmg.br
   rafaelfgs@ufmg.br
   victormrfm@ufmg.br
   levi.filho@pq.itv.org
   jaco.domingues@itv.org
   filipe.rocha@itv.org
   frederico.sousa@pq.itv.org
   luiz.barros@pq.itv.org
   erickson@dcc.ufmg.br
   doug@dcc.ufmg.br
   gustavo.pessin@itv.org
   gustavomfreitas@ufmg.br},
Affiliations = {Universidade Federal de Minas Gerais; Instituto Tecnologico Vale
   Desenvolvimento Sustentavel; Universidade Federal de Minas Gerais},
ORCID-Numbers = {Dias de Barros, Luiz Guilherme/0000-0003-3842-2906},
Funding-Acknowledgement = {Instituto Tecnologico Vale (ITV); Vale S.A.; Conselho Nacional de
   Desenvolvimento Cientiifico e Tecnologico (CNPq); Fundacao de Amparo a
   Pesquisa do Estado de Minas Gerais (FAPEMIG); Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES)},
Funding-Text = {- Instituto Tecnologico Vale (ITV);; - Vale S.A.;; - Conselho Nacional
   de Desenvolvimento Cientiifico e Tecnologico (CNPq);; - Fundacao de
   Amparo a Pesquisa do Estado de Minas Gerais (FAPEMIG);; - Coordenacao de
   Aperfeicoamento de Pessoal de Nivel Superior (CAPES).},
Cited-References = {AliceVision, 2018, MESHROOM 3D RECONSTR.
   {[}Anonymous], 2015, ROCKETM DATASHEET.
   {[}Anonymous], 2017, WIFI IND INTERNET TH.
   Azpurua H., 2019, 2019 19 INT C ADV RO.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Booz A, 2018, UNEARTHING SUBTERRAN.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   CARR JC, 2003, P 1 INT C COMP GRAPH, P119.
   Carrillo H, 2018, AUTON ROBOT, V42, P235, DOI 10.1007/s10514-017-9662-9.
   Chaimowicz L, 2005, IEEE INT CONF ROBOT, P2487.
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552.
   Cho N, 2015, J GUID CONTROL DYNAM, V38, P2366, DOI 10.2514/1.G001060.
   Droeschel D, 2018, IEEE INT CONF ROBOT, P5000, DOI 10.1109/ICRA.2018.8461000.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Fabri A., 2009, P 17 ACM SIGSPATIAL, P538, DOI DOI 10.1145/1653771.1653865.
   Filipenko M, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P400, DOI 10.1109/IS.2018.8710464.
   Freitas G.M., 2018, MULTITERRAIN INSPECT.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Goncalves VM, 2010, IEEE T ROBOT, V26, P647, DOI 10.1109/TRO.2010.2053077.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56.
   HOPPE H, 1992, COMP GRAPH, V26, P71.
   Jancosek Michal, 2014, Int Sch Res Notices, V2014, P798595, DOI 10.1155/2014/798595.
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761.
   Kazhdan M., 2007, SYMP, V7, P256.
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237.
   Koide K, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419841532.
   Labbe M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Levy B, 2002, ACM T GRAPHIC, V21, P362.
   Liepa P., 2003, Symposium on Geometry Processing, P200.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Macenski S., 2020, 2020 IEEE RSJ INT C.
   Miranda V.R.F., 2019 19 INT C ADV RO, P320.
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0\_20.
   Moulon P, 2013, IEEE I CONF COMP VIS, P3248, DOI 10.1109/ICCV.2013.403.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murphy RR, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1577.
   Murphy RR, 2014, INTELL ROBOT AUTON, P1.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839.
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
   Rezende AMC, 2020, IEEE INT CON AUTO SC, P1427, DOI 10.1109/CASE48305.2020.9217005.
   Santos AS, 2018, 15TH LATIN AMERICAN ROBOTICS SYMPOSIUM 6TH BRAZILIAN ROBOTICS SYMPOSIUM 9TH WORKSHOP ON ROBOTICS IN EDUCATION (LARS/SBR/WRE 2018), P265, DOI 10.1109/LARS/SBR/WRE.2018.00056.
   Saranli U, 2001, INT J ROBOT RES, V20, P616, DOI 10.1177/02783640122067570.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Shekhar R, 1996, IEEE VISUAL, P335, DOI 10.1109/VISUAL.1996.568127.
   Shepard D, 1968, P 1968 23 ACM NATL C, DOI DOI 10.1145/800186.810616.
   Shewchuk JR, 2002, COMP GEOM-THEOR APPL, V22, P21, DOI 10.1016/S0925-7721(01)00047-5.
   Siciliano B, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1, DOI 10.1007/978-3-319-32552-1.
   Siciliano B, 2009, ADV TXB CONTR SIG PR, P1.
   Sousa R.L.S., 2016, IEEE BIENN C ARG ARG, P1.
   Wolf P.R., 2014, ELEMENTS PHOTOGRAMME.
   Yagfarov R, 2018, I C CONT AUTOMAT ROB, P1979, DOI 10.1109/ICARCV.2018.8581131.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.},
Number-of-Cited-References = {56},
Times-Cited = {0},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {24},
Journal-ISO = {J. Intell. Robot. Syst.},
Doc-Delivery-Number = {RF4TV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000634833600001},
DA = {2022-05-17},
}

@article{ WOS:000663515000002,
Author = {Potokar, Easton and Norman, Kalin and Mangelson, Joshua},
Title = {Invariant Extended Kalman Filtering for Underwater Navigation},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {3},
Pages = {5792-5799},
Month = {JUL},
Abstract = {Recent advances in the utilization of Lie Groups for robotic
   localization have led to dramatic increases in the accuracy of
   estimation and uncertainty characterization. One of the novel methods,
   the Invariant Extended Kalman Filter (InEKF) extends the Extended Kalman
   Filter (EKF) by leveraging the fact that some error dynamics defined on
   matrix Lie Groups satisfy a log-linear differential equation.
   Utilization of these observations result in linearization with minimal
   approximation error, no dependence on current state estimates, and
   excellent convergence and accuracy properties. In this letter we show
   that the primary sensors used for underwater localization, inertial
   measurement units (IMUs) and doppler velocity logs (DVLs) meet the
   requirements of the InEKF. Furthermore, we show that singleton
   measurements, such as depth, can also be used in the InEKF update with
   minor modifications, thus expanding the set of measurements usable in an
   InEKF. We compare convergence, accuracy and timing results of the InEKF
   to a quaternion-based EKF using a Monte Carlo simulation and show
   notable improvements in long-term localization and much faster
   convergence with negligible difference in computation time.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Potokar, E (Corresponding Author), Brigham Young Univ BYU, Dept Elect \& Comp Engn, Coll Phys \& Math Sci, Provo, UT 84606 USA.
   Potokar, Easton; Norman, Kalin; Mangelson, Joshua, Brigham Young Univ BYU, Dept Elect \& Comp Engn, Coll Phys \& Math Sci, Provo, UT 84606 USA.},
DOI = {10.1109/LRA.2021.3085167},
ISSN = {2377-3766},
Keywords = {Unmanned underwater vehicles; filtering algorithms; state estimation;
   computational geometry},
Keywords-Plus = {AUV NAVIGATION; SLAM; LOCALIZATION; SYSTEM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {eastonpots@byu.edu
   kalinnorman@byu.edu
   joshua\_mangelson@byu.edu},
ORCID-Numbers = {Mangelson, Joshua/0000-0002-0550-0368
   Potokar, Easton/0000-0001-9756-1661
   Norman, Kalin/0000-0002-1310-8729},
Funding-Acknowledgement = {Office of Naval Research {[}N00014-21-1-2435]},
Funding-Text = {This work was supported by the Office of Naval Research under Award
   Number N00014-21-1-2435.},
Cited-References = {Aghannan N, 2002, IEEE DECIS CONTR P, P1479, DOI 10.1109/CDC.2002.1184728.
   Barczyk M, 2013, IEEE T CONTR SYST T, V21, P791, DOI 10.1109/TCST.2012.2195495.
   Barczyk M, 2011, IEEE DECIS CONTR P, P5389.
   Barrau A., 2015, THESIS MINES PARISTE.
   Barrau A, 2018, ANNU REV CONTR ROBOT, V1, P237, DOI 10.1146/annurev-control-060117-105010.
   Barrau A, 2017, IEEE T AUTOMAT CONTR, V62, P1797, DOI 10.1109/TAC.2016.2594085.
   Bonnabel S, 2007, IEEE DECIS CONTR P, P4007.
   Bonnabel S, 2009, IEEE T AUTOMAT CONTR, V54, P1709, DOI 10.1109/TAC.2009.2020646.
   Brossard M, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P2021, DOI 10.23919/ICIF.2018.8455807.
   Carr SC, 2010, INT CULT PSYCHOL, P1, DOI 10.1007/978-1-4419-6208-9\_1.
   Donovan GT, 2012, IEEE J OCEANIC ENG, V37, P431, DOI 10.1109/JOE.2012.2190810.
   Greaves J., 2018, GITHUB.
   Hall B.C., 2015, LIE ALGEBRAS REPRESE.
   Hartley R, 2020, INT J ROBOT RES, V39, P402, DOI 10.1177/0278364919894385.
   Kalman R. E., 1960, J FLUIDS ENG, V82, P34, DOI {[}https://doi.org/10.1115/1.3662552, DOI 10.1115/1.3662552].
   Kim A, 2013, IEEE T ROBOT, V29, P719, DOI 10.1109/TRO.2012.2235699.
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P2330, DOI 10.1109/LRA.2018.2809510.
   Mallios A, 2010, IEEE INT C INT ROBOT, P4404, DOI 10.1109/IROS.2010.5649246.
   Mangelson JG, 2020, IEEE T ROBOT, V36, P1371, DOI 10.1109/TRO.2020.2994457.
   Murray R., 1994, MATH INTRO ROBOTIC M.
   Olson E, 2006, IEEE J OCEANIC ENG, V31, P949, DOI 10.1109/JOE.2006.880386.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Sabet MT, 2018, IEEE J OCEANIC ENG, V43, P927, DOI 10.1109/JOE.2017.2769838.
   Sola J., 2015, ARXIV171102508.
   Ullah I, 2019, IEEE ACCESS, V7, P45693, DOI 10.1109/ACCESS.2019.2909133.
   Woodbury M. A., 1950, MEMORANDUM REPORT ST.
   Wu KZ, 2017, IEEE INT C INT ROBOT, P1578, DOI 10.1109/IROS.2017.8205965.},
Number-of-Cited-References = {27},
Times-Cited = {0},
Usage-Count-Last-180-days = {13},
Usage-Count-Since-2013 = {21},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {SV0JX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000663515000002},
DA = {2022-05-17},
}

@inproceedings{ WOS:000544658405093,
Author = {Halodova, Lucie and Dvorakova, Eliska and Majer, Filip and Vintr, Tomas
   and Mozos, Oscar Martinez and Dayoub, Feras and Krajnik, Tomas},
Book-Group-Author = {IEEE},
Title = {Predictive and adaptive maps for long-term visual navigation in changing
   environments},
DOI = {10.1109/IROS40897.2019.8967994},
Booktitle = {2019 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2019},
Pages = {7033-7039},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Macau, PEOPLES R CHINA, NOV 04-08, 2019},
Abstract = {In this paper, we compare different map management techniques for
   long-term visual navigation in changing environments. In this scenario,
   the navigation system needs to continuously update and refine its
   feature map in order to adapt to the environment appearance change. To
   achieve reliable long-term navigation, the map management techniques
   have to (i) select features useful for the current navigation task, (ii)
   remove features that are obsolete, (iii) and add new features from the
   current camera view to the map. We propose several map management
   strategies and evaluate their performance with regard to the robot
   localisation accuracy in long-term teach-and-repeat navigation. Our
   experiments, performed over three months, indicate that strategies which
   model cyclic changes of the environment appearance and predict which
   features are going to be visible at a particular time and location,
   outperform strategies which do not explicitly model the temporal
   evolution of the changes.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Halodova, L (Corresponding Author), Czech Tech Univ, Artificial Intelligence Ctr, Prague, Czech Republic.
   Halodova, Lucie; Dvorakova, Eliska; Majer, Filip; Vintr, Tomas; Krajnik, Tomas, Czech Tech Univ, Artificial Intelligence Ctr, Prague, Czech Republic.
   Mozos, Oscar Martinez, Tech Univ Cartagena, Cartagena, Spain.
   Dayoub, Feras, QUT, Australian Ctr Robot Vis, Brisbane, Qld, Australia.},
ISSN = {2153-0858},
ISBN = {978-1-7281-4004-9},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods; Robotics},
Author-Email = {halodluc@fel.cvut.cz
   krajnt1@fel.cvut.cz},
Affiliations = {Czech Technical University Prague; Universidad Politecnica de Cartagena;
   Australian Centre for Robotic Vision; Queensland University of
   Technology (QUT)},
ResearcherID-Numbers = {Majer, Filip/AAA-2941-2022
   },
ORCID-Numbers = {Dayoub, Feras/0000-0002-4234-7374},
Funding-Acknowledgement = {Czech Science Foundation {[}17-27006Y]; Spanish Ramon y Cajal Programme
   {[}RYC-2014-15029]},
Funding-Text = {The work was funded by the Czech Science Foundation project 17-27006Y
   and by Spanish Ramon y Cajal Programme (ref. RYC-2014-15029)},
Cited-References = {Austin D., 2001, IEEE RSJ INT C INT R.
   Bay H., 2008, COMPUTER VISION IMAG.
   Biber P, 2005, RSS.
   Burki Mathias, 2018, 2018 IEEE Intelligent Vehicles Symposium (IV), P682, DOI 10.1109/IVS.2018.8500432.
   Calonder M., 2010, P ICCV.
   Churchill Winston, 2013, INT J ROBOTICS RES.
   Dayoub F., 2008, P INT C INT ROB SYST.
   Dosovitskiy A., 2017, C ROBOT LEARNING, P1.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Gadd M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5729, DOI 10.1109/IROS.2016.7759843.
   Julier SJ, 2001, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ROBOT.2001.933280.
   Krajnik T., 2018, IEEE RSJ INT C INT R.
   Krajnik T., 2010, J FIELD ROBOTICS.
   Krajnik T., 2013, INT C ADV ROB ICAR.
   Krajnik T., 2017, ROBOTICS AUTONOMOUS.
   Krajnik T., 2014, J INTELLIGENT ROBOTI.
   Krajnik T, 2010, J FIELD ROBOT, V27, P511, DOI 10.1002/rob.20354.
   Krajnik Tomas, 2017, IEEE T ROBOTICS.
   Kunze L., 2018, IEEE ROBOTICS AUTOMA, P1.
   Latif Y, 2018, ICRA.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowry S., 2016, T ROBOTICS.
   Lowry Stephanie, 2016, IEEE T ROBOTICS.
   MacTavish K, 2018, J FIELD ROBOT, V35, P1265, DOI 10.1002/rob.21838.
   Maddern W., 2017, ACTA POLYTECH HUNG, V36, P3, DOI {[}10.1177/0278364916679498, DOI 10.1177/0278364916679498].
   Majer F, 2018, MODELING SIMULATION.
   Majer F, SOURCE CODES BEARING.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Neubert P., 2013, EUR C MOB ROB.
   Paton M., 2018, FIELD SERVICE ROBOTI.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Paton M, 2016, SPRINGER TRAC ADV RO, V113, P563, DOI 10.1007/978-3-319-27702-8\_37.
   Porav Horia, 2018, ICRA.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Szucsova H., 2011, THESIS.
   Thrun S, 2002, COMMUN ACM, V45, P52.
   Valgren C., 2010, ROBOTICS AUTONOMOUS, V58, P157.
   YAN Z, EU LONG TERM DATASET.},
Number-of-Cited-References = {38},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BP2QS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000544658405093},
DA = {2022-05-17},
}

@inproceedings{ WOS:000176593900097,
Author = {Austin, D and Fletcher, L and Zelinsky, A},
Book-Group-Author = {IEEE
   IEEE},
Title = {Mobile robotics in the long term - Exploring the fourth dimension},
DOI = {10.1109/IROS.2001.976237},
Booktitle = {IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON
   INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4: EXPANDING THE SOCIETAL ROLE OF
   ROBOTICS IN THE NEXT MILLENNIUM},
Year = {2001},
Pages = {613-618},
Note = {IEEE Conference on Intelligent Robots and Systems (IROS 2001), MAUI, HI,
   OCT 29-NOV 03, 2001},
Abstract = {This paper explores the issues involved in deployment of mobile robots
   in real-world situations and presents solutions and approaches under
   development at the Australian National University. For deployment of
   mobile robots outside of the laboratory, long-term operation is
   required. Hence, we have developed an automatic recharging system. In
   addition, a web-based tele-operation system is used to provide missions
   to test the long-term reliability of the robot. The final aspect of
   real-world operation that is explored here is operations in dynamic
   environments. To date, researchers have assumed static environments for
   mapping and localisation. Here we propose methods to avoid this
   restriction.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Austin, D (Corresponding Author), Australian Natl Univ, Robot Syst Lab, Res Sch Informat Sci \& Engn, Canberra, ACT 0200, Australia.
   Australian Natl Univ, Robot Syst Lab, Res Sch Informat Sci \& Engn, Canberra, ACT 0200, Australia.},
ISBN = {0-7803-6612-3},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {david@syseng.anu.edu.au
   luke@syseng.anu.edu.au
   alex@syseng.anu.edu.au},
Affiliations = {Australian National University},
Cited-References = {AUSTIN DJ, 2000, P IEEE INT C ROB AUT.
   AUSTIN DJ, 2001, IN PRESS J ROBOTICS.
   AUSTIN DJ, 2000, P IAS 00 VEN JUL, P628.
   AUSTIN DJ, DAVES ROBOTIC OPERAT.
   AUSTIN DJ, DROBOT.
   Beetz M, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2280, DOI 10.1109/ROBOT.1999.770445.
   BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P535, DOI 10.1109/70.86083.
   Burgard W., 2000, ARTIFICIAL INTELLIGE, V114.
   Burgard W., 1998, P NAT C ART INT.
   Dar T, 1998, IEEE INT CONF ROBOT, P3552.
   Fox D., 1999, J ARTIFICIAL INTELLI, V11.
   HADA Y, 1999, 9 INT C ADV ROB 99 I, P297.
   JENSFELT P, 2000, IN PRESS IEEE INT C.
   KAGAMI S, 2000, P IEEE INT C ROB AUT.
   KAGAMI S, 1999, P IEEE INT C MULT FU.
   LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402.
   SIMMONS RG, IN PRESS ACM MAGAZIN.
   SUTHERLAND O, 2000, P INT S EXP REOB ISE.
   THOMPSON S, UNPUB 2001 IEEE RSJ.
   Thrun S, 2000, INT J ROBOT RES, V19, P972, DOI 10.1177/02783640022067922.
   Thrun S, 1998, IEEE INT CONF ROBOT, P1546, DOI 10.1109/ROBOT.1998.677346.
   Thrun S., 1999, P IEEE INT C ROB AUT.
   Yuta S, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1871, DOI 10.1109/IROS.1998.724869.},
Number-of-Cited-References = {23},
Times-Cited = {7},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BU64S},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000176593900097},
DA = {2022-05-17},
}

@inproceedings{ WOS:000459239500073,
Author = {Hu, Xiaowei and Wang, Jingchuan and Chen, Weidong},
Book-Group-Author = {IEEE},
Title = {Long-term `Localization of Mobile Robots in Dynamic Changing
   Environments},
DOI = {10.1109/CAC.2018.8623046},
Booktitle = {2018 CHINESE AUTOMATION CONGRESS (CAC)},
Series = {Chinese Automation Congress},
Year = {2018},
Pages = {384-389},
Note = {Chinese Automation Congress (CAC), Xian, PEOPLES R CHINA, NOV 30-DEC 02,
   2018},
Abstract = {Long-term localization in dynamic changing environments is still a
   challenge in robotics. Traditional localization algorithms typically
   assume that the environment is static. However, in many real-world
   applications, such as parking lots and industrial plants, there are
   always dynamic objects (e.g. moving people) and semi-dynamic objects
   (e.g. parked cars and placed goods). In this paper we address this
   challenge by introducing a long-term localization algorithm in the
   environments which combine dynamic objects and semi-dynamic objects.
   Localizability-based-updating particle filter (LU-PF) algorithm is
   proposed here Not only we use localizability matric to build an updating
   mechanism, but also it is used for localization system Besides. we
   propose the dynamic factor as long-memory information to serve as prior
   knowledge, which improves the robustness of updating process.
   Experiments in parking lots demonstrate that our approach has better
   localization results with a more accurate up-to-date map compared to
   other methods.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wang, JC (Corresponding Author), Shanghai Jiao Tong Univ, Dept Automat, Key Lab Syst Control \& Informat Proc, Minist Educ China, Shanghai, Peoples R China.
   Wang, JC (Corresponding Author), Shanghai Key Lab Nav \& Locat Based Serv, Shanghai, Peoples R China.
   Hu, Xiaowei; Wang, Jingchuan; Chen, Weidong, Shanghai Jiao Tong Univ, Dept Automat, Key Lab Syst Control \& Informat Proc, Minist Educ China, Shanghai, Peoples R China.
   Hu, Xiaowei; Wang, Jingchuan; Chen, Weidong, Shanghai Key Lab Nav \& Locat Based Serv, Shanghai, Peoples R China.},
ISSN = {2688-092X},
EISSN = {2688-0938},
ISBN = {978-1-7281-1312-8},
Keywords = {long-term localization; map updating mechanism; localizability; dynamic
   factor},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {kobe4545@sjtu.edu.cn
   jchwang@sjtu.edu.cn
   wdchen@sjtu.edu.cn},
Affiliations = {Ministry of Education, China; Shanghai Jiao Tong University},
Funding-Acknowledgement = {Natural Science Foundation of China {[}61773261]; National Key R\&D
   Program of China {[}2017YFC0806501]},
Funding-Text = {This work is partly supported by the Natural Science Foundation of China
   (Grant 61773261), and the National Key R\&D Program of China (Grant No.
   2017YFC0806501).},
Cited-References = {Biber P., 2005, ROBOTICS SCI SYSTEMS.
   Burgard W, 1999, ARTIF INTELL, V114, P3, DOI 10.1016/S0004-3702(99)00070-3.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Kleeman L, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P699.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Krajnik Tomas, 2017, IEEE T ROBOTICS.
   Krajnik Tomas, 2016, P IEEE INT C INT ROB.
   Liu Li, 2015, P IEEE INT C ADV INT.
   Meyer-Delius D., 2012, AAAI.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Montemerlo M, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P695, DOI 10.1109/ROBOT.2002.1013439.
   Olson E, 2015, IEEE INT CONF ROBOT, P5815, DOI 10.1109/ICRA.2015.7140013.
   Sun DL, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4517, DOI 10.1109/IROS.2016.7759665.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Valencia R., 2014, P IEEE INT C ROB AUT.
   Wang Y, 2014, IND ROBOT, V41, P241, DOI 10.1108/IR-06-2013-371.
   Willner D., 1976, Proceedings of the 1976 IEEE Conference on Decision and Control including the 15th Symposium on Adaptive Processes, P570.},
Number-of-Cited-References = {18},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BM0WI},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000459239500073},
DA = {2022-05-17},
}

@article{ WOS:000407395200015,
Author = {Krajnik, Tomas and Fentanes, Jaime P. and Santos, Joao M. and Duckett,
   Tom},
Title = {FreMEn: Frequency Map Enhancement for Long-Term Mobile Robot Autonomy in
   Changing Environments},
Journal = {IEEE TRANSACTIONS ON ROBOTICS},
Year = {2017},
Volume = {33},
Number = {4},
Pages = {964-977},
Month = {AUG},
Abstract = {We present a new approach to long-term mobile robot mapping in dynamic
   indoor environments. Unlike traditional world models that are tailored
   to represent static scenes, our approach explicitly models environmental
   dynamics. We assume that some of the hidden processes that influence the
   dynamic environment states are periodic and model the uncertainty of the
   estimated state variables by their frequency spectra. The spectral model
   can represent arbitrary timescales of environment dynamics with low
   memory requirements. Transformation of the spectral model to the time
   domain allows for the prediction of the future environment states, which
   improves the robot's long-term performance in changing environments.
   Experiments performed over time periods of months to years demonstrate
   that the approach can efficiently represent large numbers of
   observations and reliably predict future environment states. The
   experiments indicate that the model's predictive capabilities improve
   mobile robot localization and navigation in changing environments.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Krajnik, T (Corresponding Author), Univ Lincoln, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.
   Krajnik, Tomas; Fentanes, Jaime P.; Santos, Joao M.; Duckett, Tom, Univ Lincoln, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.
   Krajnik, Tomas, Czech Tech Univ, Fac Elect Engn, Prague 16636, Czech Republic.},
DOI = {10.1109/TRO.2017.2665664},
ISSN = {1552-3098},
EISSN = {1941-0468},
Keywords = {Localization; long-term autonomy; mapping},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {tkrajnik@lincoln.ac.uk
   jpulidofentanes@lincoln.ac.uk
   jsantos@lincoln.ac.uk
   tduckett@lincoln.ac.uk},
Affiliations = {University of Lincoln; Czech Technical University Prague},
ResearcherID-Numbers = {Krajník, Tomáš/O-2339-2013},
ORCID-Numbers = {Krajník, Tomáš/0000-0002-4408-7916},
Funding-Acknowledgement = {EU ICT {[}600623]; Czech Science Foundation {[}17-27006Y]},
Funding-Text = {This work was supported by the EU ICT Project 600623 ``STRANDS{''} and
   the Czech Science Foundation under Project 17-27006Y.},
Cited-References = {Ambrus R, 2014, IEEE INT C INT ROBOT, P1854, DOI 10.1109/IROS.2014.6942806.
   {[}Anonymous], 2017, STROMOVKA DATASET.
   {[}Anonymous], 2016, THE FFTW C LIB.
   Arbuckle D, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P409, DOI 10.1109/IRDS.2002.1041424.
   Austin D, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P613, DOI 10.1109/IROS.2001.976237.
   Bracewell R.N., 1986, FOURIER TRANSFORM IT.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Calonder Michael, 2010, Computer Vision - ECCV 2010. Proceedings 11th European Conference on Computer Vision, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Fentanes JP, 2015, IEEE INT CONF ROBOT, P1112, DOI 10.1109/ICRA.2015.7139315.
   Hahnel D, 2003, ADV ROBOTICS, V17, P579, DOI 10.1163/156855303769156965.
   Hawes N., 2017, IEEE ROBOT IN PRESS.
   Hochdorfer S., 2009, P INT C ADV ROB, P1.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T., 2015, P AAAI C ART INT VID.
   Krajnik T., 2014, ADV AUTONOMOUS ROBOT, P281.
   Krajnik T., 2016, P ICRA 2016 WORKSH A.
   Krajnik T., 2013, 2013 16 INT C ADV RO, P1, DOI {[}10.1109/icar.2013.6766520, DOI 10.1109/ICAR.2013.6766520].
   Krajnik T., 2015, P 2015 EUR C MOB ROB, P1.
   Krajnik T, 2017, ROBOT AUTON SYST, V88, P127, DOI 10.1016/j.robot.2016.11.011.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Krajnik T, 2015, IEEE INT CONF ROBOT, P2140, DOI 10.1109/ICRA.2015.7139481.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Krajnik T, 2010, J FIELD ROBOT, V27, P511, DOI 10.1002/rob.20354.
   Kucner T., 2013, P IEEE RSJ INT C INT, P1.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Migliore D., 2009, P ICRA WORKSH SAF NA.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Mishkin D., 2015, P CVPR WORKSH VIS PL.
   Mitsou N.C., 2007, CONTR AUT 2007 MED 0, P1.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Santos JM, 2016, IEEE ROBOT AUTOM LET, V1, P684, DOI 10.1109/LRA.2016.2516594.
   Santos M. J., 2016, ROBOT AUTON SYST.
   Stachniss C., 2005, P C ART INT, P1324.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Thrun S. a. o., 2002, EXPLORING ARTIFICIAL, V1, P1.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Yguel M, 2006, SPRINGER TRAC ADV RO, V25, P219.},
Number-of-Cited-References = {47},
Times-Cited = {48},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {19},
Journal-ISO = {IEEE Trans. Robot.},
Doc-Delivery-Number = {FD2WJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000407395200015},
OA = {Green Submitted, Green Accepted},
DA = {2022-05-17},
}

@article{ WOS:000295437000004,
Author = {Kawewong, Aram and Tongprasit, Noppharit and Hasegawa, Osamu},
Title = {PIRF-Nav 2.0: Fast and online incremental appearance-based loop-closure
   detection in an indoor environment},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2011},
Volume = {59},
Number = {10},
Pages = {727-739},
Month = {OCT},
Abstract = {This paper presents a fast and online incremental solution for an
   appearance-based loop-closure detection problem in a dynamic indoor
   environment. Closing the loop in a dynamic environment has been an
   important topic in robotics for decades. Recently, PIRF-Nav has been
   reported as being successful in achieving high recall rate at precision
   1. However, PIRF-Nav has three main disadvantages: (i) the computational
   expense of PIRF-Nav is beyond real-time, (ii) it utilizes a large amount
   of memory in the redundant process of keeping signatures of places, and
   (iii) it is ill-suited to an indoor environment. These factors hinder
   the use of PIRF-Nav in a general environment for long-term, high-speed
   mobile robotic applications. Therefore, this paper proposes two
   techniques: (i) new modified PIRF extraction that makes the system more
   suitable for an indoor environment and (ii) new dictionary management
   that can eliminate redundant searching and conserve memory consumption.
   The results show that our proposed method can complete tasks up to 12
   times faster than PIRF-Nav with only a slight percentage decline in
   recall. In addition, we collected additional data from a university
   canteen crowded during lunch time. Even in this crowded indoor
   environment, our proposed method has better real-time processing
   performance compared with other methods. (C) 2011 Elsevier B.V. All
   rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Kawewong, A (Corresponding Author), Tokyo Inst Technol, Imaging Sci \& Engn Lab, Midori Ku, 4259-R2-52 Nagatsuta, Yokohama, Kanagawa 2268503, Japan.
   Kawewong, Aram; Hasegawa, Osamu, Tokyo Inst Technol, Imaging Sci \& Engn Lab, Midori Ku, Yokohama, Kanagawa 2268503, Japan.
   Tongprasit, Noppharit, Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Midori Ku, Yokohama, Kanagawa 2268503, Japan.},
DOI = {10.1016/j.robot.2011.05.007},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Vision-based loop-closure detection; Simultaneous localization and
   mapping; Robotics navigation; Place localization},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; SLAM; MAP},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {kawewong.a.aa@m.titech.ac.jp
   tongprasit.n.aa@m.titech.ac.jp
   hasegawa.o.aa@m.titech.ac.jp},
Affiliations = {Tokyo Institute of Technology; Tokyo Institute of Technology},
Funding-Acknowledgement = {New Energy and Industrial Technology Development Organization (NEDO) of
   Japan},
Funding-Text = {This study was supported by an Industrial Technology Research Grant
   Program received in 2004 from the New Energy and Industrial Technology
   Development Organization (NEDO) of Japan. Also, the authors gratefully
   acknowledge Oxford Robotics Research Group for their provided database
   and source codes.},
Cited-References = {Angeli A., 2009, P IEEE INT C ROB AUT.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   AYACHE N, 1989, IEEE T ROBOTIC AUTOM, V5, P804, DOI 10.1109/70.88101.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Blanco J., 2008, IEEE T ROBOTICS, V24.
   Chang H.J., 2007, IEEE T ROBOTICS, V23.
   Choset H, 2001, IEEE T ROBOTIC AUTOM, V17, P125, DOI 10.1109/70.928558.
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276.
   Cummins M., 2009, P ROB SCI SYST RSS.
   CUMMINS M, 2008, P IEEE INT C ROB AUT.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Eade E., 2008, P BRIT MACH VIS C BM.
   Filliat D., 2008, P IEEE RSJ INT C INT.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Gutmann J.-S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P318, DOI 10.1109/CIRA.1999.810068.
   Kawewong A., 2010, INT J ROBOT RES.
   Kawewong A, 2010, IEICE T INF SYST, VE93D, P2587, DOI 10.1587/transinf.E93.D.2587.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Kosecka J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Kuipers B., 2004, P IEEE INT C ROB AUT.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
   Nister D, 2006, P IEEE INT C COMP VI.
   Reid A. Davison. I.D., 2007, PAMI, V29, P1.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Tardos JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340.
   Tongprasit N, 2009, LECT NOTES COMPUT SC, V5863, P769, DOI 10.1007/978-3-642-10677-4\_88.
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541.
   Valgren C., 2008, P IEEE INT C ROB AUT.},
Number-of-Cited-References = {33},
Times-Cited = {14},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {827OE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000295437000004},
DA = {2022-05-17},
}

@inproceedings{ WOS:000381625900086,
Author = {Ravari, Alireza Norouzzadeh and Taghirad, Hamid D.},
Book-Group-Author = {IEEE},
Title = {Loop Closure Detection by Compressed Sensing for Exploration of Mobile
   Robots in Outdoor Environments},
DOI = {10.1109/ICRoM.2015.7367836},
Booktitle = {2015 3RD RSI INTERNATIONAL CONFERENCE ON ROBOTICS AND MECHATRONICS
   (ICROM)},
Series = {RSI International Conference on Robotics and Mechatronics ICRoM},
Year = {2015},
Pages = {511-516},
Note = {3rd RSI/ISM International Conference on Robotics and Mechatronics
   (ICROM), Tarbiat Modares Univ, Tehran, IRAN, OCT 07-09, 2015},
Abstract = {In the problem of simultaneously localization and mapping (SLAM) for a
   mobile robot, it is required to detect previously visited locations so
   the estimation error shall be reduced. Sensor observations are compared
   by a similarity metric to detect loops. In long term navigation or
   exploration, the number of observations increases and so the complexity
   of the loop closure detection. Several techniques are proposed in order
   to reduce the complexity of loop closure detection. Few algorithms have
   considered the loop closure detection from a subset of sensor
   observations. In this paper, the compressed sensing approach is
   exploited to detect loops from few sensor measurements. In the basic
   compressed sensing it is assumed that a signal has a sparse
   representation is a basis which means that only a few elements of the
   signal are non-zero. Based on the compressed sensing approach a sparse
   signal can be recovered from few linear noisy projections by l(1)
   minimization. The difference matrix which is widely used for loop
   detection has a sparse structure, where similar observations are shown
   by zero distance and different locations are indicated by ones. Based on
   the multiple measurement vector technique which is an extension of the
   basic compressed sensing, the loop closure detection is performed by
   comparison of few sensor observations. The applicability of the proposed
   algorithm is investigated in some outdoor environments through some
   publicly available data sets. It has been shown by some experiments that
   the proposed method can detect loops effectively.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ravari, AN (Corresponding Author), KN Toosi Univ Technol, Fac Elect \& Comp Engn, Adv Robot \& Automated Syst, Ind Control Ctr Excellence, Tehran, Iran.
   Ravari, Alireza Norouzzadeh; Taghirad, Hamid D., KN Toosi Univ Technol, Fac Elect \& Comp Engn, Adv Robot \& Automated Syst, Ind Control Ctr Excellence, Tehran, Iran.},
ISSN = {2377-679X},
EISSN = {2572-6889},
ISBN = {978-1-4673-7234-3},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {a.norouzzadeh@ee.kntu.ac.ir
   taghirad@kntu.ac.ir},
Affiliations = {K. N. Toosi University of Technology},
ResearcherID-Numbers = {Taghirad, Hamid D./AAH-2276-2019},
ORCID-Numbers = {Taghirad, Hamid D./0000-0002-0615-6730},
Cited-References = {Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663.
   BARON D, 2005, DISTRIBUTED COMPRESS.
   Cerra D., 2011, J VISUAL COMMUNICATI.
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653.
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A., 2012, COMPUTER VISION PATT.
   Granstrom K., 2011, INT J ROBOTICS RES.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Indelman V., 2015, INT J ROBOT RES.
   Kokiopoulou E, 2011, IEEE T IMAGE PROCESS, V20, P1543, DOI 10.1109/TIP.2010.2102044.
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101.
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728.
   Magnusson M, 2009, J FIELD ROBOT, V26, P892, DOI 10.1002/rob.20314.
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082.
   Meilland M, 2015, J FIELD ROBOT, V32, P474, DOI 10.1002/rob.21531.
   Needell D, 2010, COMMUN ACM, V53, P93, DOI 10.1145/1859204.1859229.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159.
   Rahmoune A, 2012, IEEE T IMAGE PROCESS, V21, P1950, DOI 10.1109/TIP.2011.2181525.
   Ravari AN, 2014, IEEE T CYBERNETICS, V44, P1938, DOI 10.1109/TCYB.2014.2300180.
   Siciliano B., 2008, SPRINGER HDB ROBOTIC.
   Stumm E. S., 2015, INT J ROBOT RES.
   Tan AH, 2002, IEEE T INSTRUM MEAS, V51, P583, DOI 10.1109/TIM.2002.802243.
   Trautman P, 2015, INT J ROBOT RES, V34, P335, DOI 10.1177/0278364914557874.
   van den Berg E, 2008, SIAM J SCI COMPUT, V31, P890, DOI 10.1137/080714488.},
Number-of-Cited-References = {29},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BF4RL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000381625900086},
DA = {2022-05-17},
}

@article{ WOS:000615477700001,
Author = {Lin, Xiaohu and Wang, Fuhong and Yang, Bisheng and Zhang, Wanwei},
Title = {Autonomous Vehicle Localization with Prior Visual Point Cloud Map
   Constraints in GNSS-Challenged Environments},
Journal = {REMOTE SENSING},
Year = {2021},
Volume = {13},
Number = {3},
Pages = {506},
Month = {FEB},
Abstract = {Accurate vehicle ego-localization is key for autonomous vehicles to
   complete high-level navigation tasks. The state-of-the-art localization
   methods adopt visual and light detection and ranging (LiDAR)
   simultaneous localization and mapping (SLAM) to estimate the position of
   the vehicle. However, both of them may suffer from error accumulation
   due to long-term running without loop optimization or prior constraints.
   Actually, the vehicle cannot always return to the revisited location,
   which will cause errors to accumulate in Global Navigation Satellite
   System (GNSS)-challenged environments. To solve this problem, we
   proposed a novel localization method with prior dense visual point cloud
   map constraints generated by a stereo camera. Firstly, the
   semi-global-block-matching (SGBM) algorithm is adopted to estimate the
   visual point cloud of each frame and stereo visual odometry is used to
   provide the initial position for the current visual point cloud.
   Secondly, multiple filtering and adaptive prior map segmentation are
   performed on the prior dense visual point cloud map for fast matching
   and localization. Then, the current visual point cloud is matched with
   the candidate sub-map by normal distribution transformation (NDT).
   Finally, the matching result is used to update pose prediction based on
   the last frame for accurate localization. Comprehensive experiments were
   undertaken to validate the proposed method, showing that the root mean
   square errors (RMSEs) of translation and rotation are less than 5.59 m
   and 0.08 degrees, respectively.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Wang, FH (Corresponding Author), Wuhan Univ, Sch Geodesy \& Geomat, Wuhan 430079, Peoples R China.
   Lin, Xiaohu; Wang, Fuhong; Zhang, Wanwei, Wuhan Univ, Sch Geodesy \& Geomat, Wuhan 430079, Peoples R China.
   Yang, Bisheng, Wuhan Univ, State Key Lab Informat Engn Surveying Mapping \& R, Wuhan 430079, Peoples R China.},
DOI = {10.3390/rs13030506},
Article-Number = {506},
EISSN = {2072-4292},
Keywords = {autonomous vehicle; stereo visual odometry; pose prediction; accurate
   vehicle localization},
Keywords-Plus = {ODOMETRY},
Research-Areas = {Environmental Sciences \& Ecology; Geology; Remote Sensing; Imaging
   Science \& Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {xhlin214@whu.edu.cn
   fhwang@sgg.whu.edu.cn
   bshyang@whu.edu.cn
   wwzhang@sgg.whu.edu.cn},
Affiliations = {Wuhan University; Wuhan University},
ResearcherID-Numbers = {Yang, Bisheng/A-4642-2013},
ORCID-Numbers = {Yang, Bisheng/0000-0001-7736-0803},
Funding-Acknowledgement = {National Natural Science Foundation of China for Distinguished Young
   Scholars {[}41725005]; Key Project of the National Natural Science
   Foundation of China {[}41531177]; National Key Research and Development
   Program of China {[}2016YFB0501803]},
Funding-Text = {This research was funded by the National Natural Science Foundation of
   China for Distinguished Young Scholars (grant no. 41725005), the Key
   Project of the National Natural Science Foundation of China (grant no.
   41531177) and the National Key Research and Development Program of China
   (grant no. 2016YFB0501803).},
Cited-References = {Bosse M, 2012, IEEE T ROBOT, V28, P1104, DOI 10.1109/TRO.2012.2200990.
   Brubaker MA, 2016, IEEE T PATTERN ANAL, V38, P652, DOI 10.1109/TPAMI.2015.2453975.
   Carvalho H, 1997, IEEE T AERO ELEC SYS, V33, P835, DOI 10.1109/7.599254.
   Caselitz T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1926, DOI 10.1109/IROS.2016.7759304.
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567.
   Choi J, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P3082, DOI 10.1109/ITSC.2014.6958185.
   Forster C, 2013, IEEE INT C INT ROBOT, P3971, DOI 10.1109/IROS.2013.6696924.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Huhle B, 2008, IEEE INT CONF ROBOT, P4025, DOI 10.1109/ROBOT.2008.4543829.
   Im JH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081268.
   Kim D, 2015, IEEE INT VEH SYM, P680, DOI 10.1109/IVS.2015.7225763.
   Kim H, 2017, IEEE ROBOT AUTOM LET, V2, P1518, DOI 10.1109/LRA.2017.2673868.
   Kim Y, 2019, PFLUG ARCH EUR J PHY, V471, P431, DOI 10.1007/s00424-018-2225-x.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Levinson J., 2007, ROBOTICS SCI SYSTEMS, V4, P1.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li Q, 2020, ISPRS J PHOTOGRAMM, V161, P13, DOI 10.1016/j.isprsjprs.2020.01.008.
   Lin XH, 2021, INT J DIGIT EARTH, V14, P619, DOI 10.1080/17538947.2020.1862318.
   Lin XH, 2019, IEEE ACCESS, V7, P70742, DOI 10.1109/ACCESS.2019.2916901.
   Liu H, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111348.
   Lyrio LJ, 2015, IEEE INT CONF ROBOT, P3603, DOI 10.1109/ICRA.2015.7139699.
   Magnusson M, 2013, THESIS OREBRO U OREB.
   Magnusson M, 2009, IEEE INT CONF ROBOT, P2263.
   Mohamed AH, 1999, J GEODESY, V73, P193, DOI 10.1007/s001900050236.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Neubert P, 2017, IEEE INT C INT ROBOT, P2492, DOI 10.1109/IROS.2017.8206067.
   Nuchter A, 2007, J FIELD ROBOT, V24, P699, DOI 10.1002/rob.20209.
   Oliveira G.L., 2017, ARXIV170608775.
   Qin B, 2012, IEEE INT CONF ROBOT, P2640, DOI 10.1109/ICRA.2012.6224913.
   Radwan N, 2016, IEEE INT CONF ROBOT, P4837, DOI 10.1109/ICRA.2016.7487688.
   Ruchti P, 2015, IEEE INT CONF ROBOT, P5260, DOI 10.1109/ICRA.2015.7139932.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Stewart AD, 2012, IEEE INT CONF ROBOT, P2625, DOI 10.1109/ICRA.2012.6224750.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Suzuki T, 2010, IEEE INT C INT ROBOT, P5737, DOI 10.1109/IROS.2010.5652983.
   Wang D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113863.
   Wen WS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113928.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.
   Xu YQ, 2017, IEEE INT VEH SYM, P487, DOI 10.1109/IVS.2017.7995765.
   Yoneda K, 2014, IEEE INT VEH SYM, P1345, DOI 10.1109/IVS.2014.6856596.
   Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941.
   Ziegler J, 2014, IEEE INT VEH SYM, P1231, DOI 10.1109/IVS.2014.6856560.},
Number-of-Cited-References = {46},
Times-Cited = {4},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {13},
Journal-ISO = {Remote Sens.},
Doc-Delivery-Number = {QD4GB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000615477700001},
OA = {gold, Green Published},
DA = {2022-05-17},
}

@article{ WOS:000587709700015,
Author = {Ding, Xiaqing and Wang, Yue and Xiong, Rong and Li, Dongxuan and Tang,
   Li and Yin, Huan and Zhao, Liang},
Title = {Persistent Stereo Visual Localization on Cross-Modal Invariant Map},
Journal = {IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS},
Year = {2020},
Volume = {21},
Number = {11},
Pages = {4646-4658},
Month = {NOV},
Abstract = {Autonomous mobile vehicles are expected to perform persistent and
   accurate localization with low-cost equipment. To achieve this goal, we
   propose a stereo camera based visual localization method using a
   modified laser map, which takes the advantage of both the low cost of
   camera, and high geometric precision of laser data to achieve long-term
   performance. Considering that LiDAR and camera give measurements of the
   same environment in different modalities, the cross-modal invariance is
   investigated to modify the laser map for visual localization.
   Specifically, a map learning algorithm is introduced to sample the
   robust subsets in laser maps that are useful for visual localization
   using multi-session visual and laser data. Further, a generative map
   model is derived to describe this crossmodal invariance, based on which
   two types of measurements are defined to model the laser map points as
   appropriate visual observations. Tightly coupling these measurements
   within the local bundle adjustment during online sliding-window based
   visual odometry, the vehicle can achieve robust localization even one
   year after the map was built. The effectiveness of the proposed method
   is evaluated on both the public KITTI datasets and self-collected
   datasets in our campus, which include seasonal, illumination and object
   variations. On all experimental localization sessions, our method
   provides satisfactory results, even when the direction is opposite to
   that in the mapping session, verifying the superior performance of the
   laser map based visual localization method.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y; Xiong, R (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou 310007, Peoples R China.
   Ding, Xiaqing; Wang, Yue; Xiong, Rong; Li, Dongxuan; Tang, Li; Yin, Huan, Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou 310007, Peoples R China.
   Zhao, Liang, Univ Technol Sydney, Ctr Autonomous Syst CAS, Sydney, NSW 2007, Australia.},
DOI = {10.1109/TITS.2019.2942760},
ISSN = {1524-9050},
EISSN = {1558-0016},
Keywords = {Visual localization; persistent autonomy; map maintenance; map
   incorporated bundle adjustment},
Keywords-Plus = {SLAM; NAVIGATION; FRAMEWORK},
Research-Areas = {Engineering; Transportation},
Web-of-Science-Categories  = {Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology},
Author-Email = {wangyue@iipc.zju.edu.cn
   rxiong@zju.edu.cn},
Affiliations = {Zhejiang University; University of Technology Sydney},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020
   },
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202
   Zhao, Liang/0000-0003-4063-8183},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2017YFC0806501]; Key Research and Development Program of Zhejiang
   Province, China {[}2019C01043]; National Nature Science Foundation of
   China {[}61903332]},
Funding-Text = {This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFC0806501, in part by the
   Key Research and Development Program of Zhejiang Province, China, Grant
   2019C01043, and in part by the National Nature Science Foundation of
   China under Grant 61903332.},
Cited-References = {ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965.
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
   Bay H., 2006, EUR C COMP VIS, P404.
   BESAG J, 1986, J R STAT SOC B, V48, P259.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   Caselitz T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1926, DOI 10.1109/IROS.2016.7759304.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Hata AY, 2018, IEEE T INTELL TRANSP, V19, P2893, DOI 10.1109/TITS.2017.2761774.
   Heyde ChristopherC., 2008, QUASI LIKELIHOOD ITS.
   Hu F, 2010, ENVIRON TOXICOL CHEM, V29, P683, DOI 10.1002/etc.73.
   Klein G, 2007, ADV CANCER RES, V98, P1, DOI 10.1016/S0065-230X(06)98001-4.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Labbe M, 2018, AUTON ROBOT, V42, P1133, DOI 10.1007/s10514-017-9682-5.
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li DX, 2017, P AMER CONTR CONF, P3579, DOI 10.23919/ACC.2017.7963501.
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   McManus C., 2014, ROBOTICS SCI SYSTEMS.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   McManus C, 2013, J FIELD ROBOT, V30, P254, DOI 10.1002/rob.21444.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Ozog P, 2017, ROBOT AUTON SYST, V87, P329, DOI 10.1016/j.robot.2016.09.006.
   Pascoe G., 2015, P BRIT MACH VIS C.
   Pomerleau F, 2014, IEEE INT CONF ROBOT, P3712, DOI 10.1109/ICRA.2014.6907397.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Santoso F, 2017, IEEE T AUTOM SCI ENG, V14, P260, DOI 10.1109/TASE.2016.2582752.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   Sons M, 2017, IEEE INT VEH SYM, P1158, DOI 10.1109/IVS.2017.7995869.
   Sturm J., 2012, P WORKSH COL DEPTH C.
   Surber Julian, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6300, DOI 10.1109/ICRA.2017.7989745.
   Tang L., 2018, IEEE INT C ROB BIOM, P787.
   Tang L, 2019, AUTON ROBOT, V43, P197, DOI 10.1007/s10514-018-9724-7.
   Torii A., 2017, P IEEE C COMP VIS PA, P1637.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421.
   Wang Y, 2016, CAAI T INTELL TECHNO, V1, P90, DOI 10.1016/j.trit.2016.03.009.
   Wang Y, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P32, DOI 10.1109/ECMR.2013.6698816.
   Wang Y, 2013, INT J ROBOT AUTOM, V28, P234, DOI 10.2316/Journal.206.2013.3.206-3806.
   Withers Dan, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6233, DOI 10.1109/ICRA.2017.7989738.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.
   Xu YQ, 2017, IEEE INT VEH SYM, P487, DOI 10.1109/IVS.2017.7995765.
   Yang ZF, 2017, IEEE T AUTOM SCI ENG, V14, P39, DOI 10.1109/TASE.2016.2550621.},
Number-of-Cited-References = {57},
Times-Cited = {5},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {13},
Journal-ISO = {IEEE Trans. Intell. Transp. Syst.},
Doc-Delivery-Number = {OO9QU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000587709700015},
DA = {2022-05-17},
}

@article{ WOS:000502153400003,
Author = {Reijgwart, Victor and Millane, Alexander and Oleynikova, Helen and
   Siegwart, Roland and Cadena, Cesar and Nieto, Juan},
Title = {Voxgraph: Globally Consistent, Volumetric Mapping Using Signed Distance
   Function Submaps},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2020},
Volume = {5},
Number = {1},
Pages = {227-234},
Month = {JAN},
Abstract = {Globally consistent dense maps are a key requirement for long-term robot
   navigation in complex environments. While previous works have addressed
   the challenges of dense mapping and global consistency, most require
   more computational resources than may be available on-board small
   robots. We propose a framework that creates globally consistent
   volumetric maps on a CPU and is lightweight enough to run on
   computationally constrained platforms. Our approach represents the
   environment as a collection of overlapping signed distance function
   (SDF) submaps and maintains global consistency by computing an optimal
   alignment of the submap collection. By exploiting the underlying SDF
   representation, we generate correspondence-free constraints between
   submap pairs that are computationally efficient enough to optimize the
   global problem each time a new submap is added. We deploy the proposed
   system on a hexacopter micro aerial vehicle (MAV) with an Inteli7-8650 U
   CPU in two realistic scenarios: mapping a large-scale area using a
   3DLiDARandmapping an industrial space using an RGB-D camera. In the
   large-scale outdoor experiments, the system optimizes a 120x80mmap in
   less than 4 s and produces absolute trajectoryRMSEs of less than 1mover
   400mtrajectories. Our complete system, called voxgraph, is available as
   open source.(1)},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Reijgwart, V (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Reijgwart, Victor; Millane, Alexander; Oleynikova, Helen; Siegwart, Roland; Cadena, Cesar; Nieto, Juan, Swiss Fed Inst Technol, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.},
DOI = {10.1109/LRA.2019.2953859},
ISSN = {2377-3766},
Keywords = {Mapping; SLAM; aerial systems; perception and autonomy},
Keywords-Plus = {VERSATILE; ROBUST},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {victorr@ethz.ch
   millanea@ethz.ch
   helenol@ethz.ch
   rsiegwart@ethz.ch
   cesarc@ethz.ch
   nietoj@ethz.ch},
Affiliations = {ETH Zurich},
ResearcherID-Numbers = {Cadena, Cesar/AAM-4987-2020
   Siegwart, Roland/A-4495-2008
   },
ORCID-Numbers = {Cadena, Cesar/0000-0002-2972-6011
   Nieto, Juan/0000-0003-4808-0831
   Oleynikova, Helen/0000-0002-1831-2315
   Siegwart, Roland/0000-0002-2760-7983
   Reijgwart, Victor/0000-0002-7605-8490},
Funding-Acknowledgement = {National Center of Competence in Research (NCCR) Robotics through the
   Swiss National Science Foundation; DefenseAdvanced Research Projects
   Agency (DARPA) {[}HR00111820045]; Armasuisse},
Funding-Text = {This work was supported by the National Center of Competence in Research
   (NCCR) Robotics through the Swiss National Science Foundation, as well
   as theDefenseAdvanced Research Projects Agency (DARPA) under Agreement
   HR00111820045 and Armasuisse.},
Cited-References = {Bloesch M, 2017, INT J ROBOT RES, V36, P1053, DOI 10.1177/0278364917728574.
   Burri M, 2015, IEEE INT C INT ROBOT, P1872, DOI 10.1109/IROS.2015.7353622.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Choi S, 2015, PROC CVPR IEEE, P5556, DOI 10.1109/CVPR.2015.7299195.
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH `96, P303.
   Dai A., 2017, TOG, V36, P24.
   Dellaert F, 2017, FDN TRENDS ROBOT, V6, P1.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Ericson C., 1996, SERIES M KAUFMANN SE.
   Fioraio N, 2015, PROC CVPR IEEE, P4475, DOI 10.1109/CVPR.2015.7299077.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Henry P, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P398, DOI 10.1109/3DV.2013.59.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Izadi Shahram, 2011, P 24 ANN ACM S US IN, P559, DOI DOI 10.1145/2047196.2047270.
   Kahler O, 2016, LECT NOTES COMPUT SC, V9912, P500, DOI 10.1007/978-3-319-46484-8\_30.
   Kang H. R., 2006, COMPUTATIONAL COLOR.
   Lei H., 2013, P ROB SCI SYST C.
   Lin Y, 2018, J FIELD ROBOT, V35, P23, DOI 10.1002/rob.21732.
   Lorensen W.E., 1987, SIGGRAPH COMPUTER GR, V21, P163, DOI {[}DOI 10.1145/37402.37422, 10.1145/37401.37422].
   Maier R., 2013, P BRIT MACH VIS C.
   Millane A, 2018, IEEE INT C INT ROBOT, P995, DOI 10.1109/IROS.2018.8593427.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487234.
   Nikolic J, 2014, IEEE INT CONF ROBOT, P431, DOI 10.1109/ICRA.2014.6906892.
   Oleynikova Helen, 2018, IEEE Robotics and Automation Letters, V3, P1474, DOI 10.1109/LRA.2018.2800109.
   Oleynikova H, 2017, IEEE INT C INT ROBOT, P1366, DOI 10.1109/IROS.2017.8202315.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Ratliff N, 2009, IEEE INT CONF ROBOT, P4030.
   Schneider Thomas, 2018, IEEE Robotics and Automation Letters, V3, P1418, DOI 10.1109/LRA.2018.2800113.
   Wagner R, 2014, IEEE INT C INT ROBOT, P2691, DOI 10.1109/IROS.2014.6942930.
   Whelan T., 2015, P ROB SCI SYST C.
   Whelan T., 2012, P AAAI C.
   Zhang J, 2017, AUTON ROBOT, V41, P401, DOI 10.1007/s10514-016-9548-2.
   Zhang ZC, 2018, IEEE INT C INT ROBOT, P7244, DOI 10.1109/IROS.2018.8593941.},
Number-of-Cited-References = {36},
Times-Cited = {15},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {JV1UD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000502153400003},
OA = {Green Accepted, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000538946800001,
Author = {Yan, Zhi and Schreiberhuber, Simon and Halmetschlager, Georg and
   Duckett, Tom and Vincze, Markus and Bellotto, Nicola},
Title = {Robot perception of static and dynamic objects with an autonomous floor
   scrubber},
Journal = {INTELLIGENT SERVICE ROBOTICS},
Year = {2020},
Volume = {13},
Number = {3},
Pages = {403-417},
Month = {JUL},
Abstract = {This paper presents the perception system of a new professional cleaning
   robot for large public places. The proposed system is based on multiple
   sensors including 3D and 2D lidars, two RGB-D cameras and a stereo
   camera. The two lidars together with an RGB-D camera are used for
   dynamic object (human) detection and tracking, while the second RGB-D
   and stereo camera are used for detection of static objects (dirt and
   ground objects). A learning and reasoning module for spatial-temporal
   representation of the environment based on the perception pipeline is
   also introduced. Furthermore, a new dataset collected with the robot in
   several public places, including a supermarket, a warehouse and an
   airport, is released. Baseline results on this dataset for further
   research and comparison are provided. The proposed system has been fully
   implemented into the Robot Operating System (ROS) with high modularity,
   also publicly available to the community.},
Publisher = {SPRINGER HEIDELBERG},
Address = {TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY},
Type = {Article},
Language = {English},
Affiliation = {Yan, Z (Corresponding Author), Univ Bourgogne Franche Comte, UTBM, CIAD UMR7533, F-90010 Belfort, France.
   Schreiberhuber, S (Corresponding Author), TU Wien, Vienna, Austria.
   Yan, Zhi, Univ Bourgogne Franche Comte, UTBM, CIAD UMR7533, F-90010 Belfort, France.
   Schreiberhuber, Simon; Halmetschlager, Georg; Vincze, Markus, TU Wien, Vienna, Austria.
   Duckett, Tom; Bellotto, Nicola, Univ Lincoln, Lincoln Ctr Autonomous Syst L CAS, Lincoln, England.},
DOI = {10.1007/s11370-020-00324-9},
EarlyAccessDate = {JUN 2020},
ISSN = {1861-2776},
EISSN = {1861-2784},
Keywords = {Robot perception; Human detection and tracking; Object and dirt
   detection; Spatial-temporal representation; Dataset; ROS},
Keywords-Plus = {LONG-TERM AUTONOMY; RGB-D SLAM; MOTION REMOVAL; TRACKING; PEOPLE},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {zhi.yan@utbm.fr
   schreiberhuber@acin.tuwien.ac.at
   halmetschlager@acin.tuwien.ac.at
   tduckett@lincoln.ac.uk
   vincze@acin.tuwien.ac.at
   nbellotto@lincoln.ac.uk},
Affiliations = {Universite de Bourgogne; Universite de Technologie de
   Belfort-Montbeliard (UTBM); Technische Universitat Wien; University of
   Lincoln},
ResearcherID-Numbers = {Yan, Zhi/W-5265-2019
   },
ORCID-Numbers = {Yan, Zhi/0000-0001-8251-9786
   Schreiberhuber, Simon/0000-0002-1138-7576
   Bellotto, Nicola/0000-0001-7950-9608
   Vincze, Markus/0000-0002-2799-491X
   Halmetschlager-Funek, Georg/0000-0002-8936-0824},
Funding-Acknowledgement = {European Union {[}645376]},
Funding-Text = {This work has received funding from the European Union's Horizon 2020
   research and innovation programme under Grant Agreement No. 645376
   (FLOBOT).},
Cited-References = {Ali W., 2018, P EUR C COMP VIS ECC, P0.
   Arras KO, 2007, IEEE INT CONF ROBOT, P3402, DOI 10.1109/ROBOT.2007.363998.
   Bellotto N, 2018, ENCY ROBOTICS, P1.
   Bellotto N, 2010, AUTON ROBOT, V28, P425, DOI 10.1007/s10514-009-9167-2.
   Bellotto N, 2009, IEEE T SYST MAN CY B, V39, P167, DOI 10.1109/TSMCB.2008.2004050.
   Bogoslavskyi I, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P163, DOI 10.1109/IROS.2016.7759050.
   Bormann R, 2013, IEEE INT CONF ROBOT, P1260, DOI 10.1109/ICRA.2013.6630733.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Dai YR, 2013, IEEE INT VEH SYM, P1137, DOI 10.1109/IVS.2013.6629619.
   Dewan A, 2016, IEEE INT CONF ROBOT, P4508, DOI 10.1109/ICRA.2016.7487649.
   Drews P, 2013, ROBOT AUTON SYST, V61, P1696, DOI 10.1016/j.robot.2013.06.004.
   Duda Richard O., 2001, PATTERN CLASSIFICATI, Vsecond.
   Grunauer A, 2017, LECT NOTES COMPUT SC, V10454, P436, DOI 10.1007/978-3-319-64107-2\_34.
   Grunwald M, 2018, PROC SPIE, V10752, DOI 10.1117/12.2320657.
   Halmetschlager-Funek G, 2019, IEEE ROBOT AUTOM MAG, V26, P67, DOI 10.1109/MRA.2018.2852795.
   Hawes N, 2017, IEEE ROBOT AUTOM MAG, V24, P146, DOI 10.1109/MRA.2016.2636359.
   Held D, 2013, IEEE INT CONF ROBOT, P1138, DOI 10.1109/ICRA.2013.6630715.
   Howard A., 2019, ABS190502244 CORR.
   Jafari OH, 2014, IEEE INT CONF ROBOT, P5636, DOI 10.1109/ICRA.2014.6907688.
   Jia SM, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012170.
   Kidono K, 2011, IEEE INT VEH SYM, P405, DOI 10.1109/IVS.2011.5940433.
   Kobilarov M, 2006, IEEE INT CONF ROBOT, P557, DOI 10.1109/ROBOT.2006.1641769.
   Krajnik T, 2019, IEEE ROBOT AUTOM LET, V4, P3310, DOI 10.1109/LRA.2019.2926682.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Kunze L, 2018, IEEE ROBOT AUTOM LET, V3, P4431, DOI 10.1109/LRA.2018.2870466.
   Linder T, 2016, IEEE INT CONF ROBOT, P5512, DOI 10.1109/ICRA.2016.7487766.
   Liu K, 2013, EUR INT J SCI TECHNO, V2, P199.
   Navarro-Serment LE, 2009, P 7 C FIELD SERV ROB, P103.
   Pimentel MAF, 2014, SIGNAL PROCESS, V99, P215, DOI 10.1016/j.sigpro.2013.12.026.
   Prassler E, 2000, AUTON ROBOT, V9, P211, DOI 10.1023/A:1008974515925.
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
   Schreiberhuber S, 2017, 2017 AUSTRIAN ASS PA.
   Shackleton J, 2010, P 7 IEEE INT C ADV V, P420, DOI DOI 10.1109/AVSS.2010.52.
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835.
   Spinello L, 2010, INT J ROBOT RES, V29, P1498, DOI 10.1177/0278364910377533.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Sun L, 2018, P 2018 IEEE INT C RO.
   Sun YX, 2018, ROBOT AUTON SYST, V108, P115, DOI 10.1016/j.robot.2018.07.002.
   Sun YX, 2017, ROBOT AUTON SYST, V89, P110, DOI 10.1016/j.robot.2016.11.012.
   Tarsha-Kurdi F., 2008, PHOTOGRAMM J FINL, V21, P97.
   Vintr T, 2019, P 2018 IEEE INT C RO.
   Yan Z, 2018, 2018 3RD INTERNATIONAL SOCIAL SCIENCES AND EDUCATION CONFERENCE (ISSEC 2018), P1.
   Yan Z, 2020, AUTON ROBOT, V44, P147, DOI 10.1007/s10514-019-09883-y.
   Yan Z, 2017, IEEE INT C INT ROBOT, P864, DOI 10.1109/IROS.2017.8202247.
   Yang MY, 2010, P 2ND INT C MACH CON.
   Zermas Dimitris, 2017, ICRA.
   Zhao J, 2007, IEEE INT CONF ROBOT, P529, DOI 10.1109/ROBOT.2007.363041.
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472.},
Number-of-Cited-References = {49},
Times-Cited = {1},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {19},
Journal-ISO = {Intell. Serv. Robot.},
Doc-Delivery-Number = {ME5MZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000538946800001},
OA = {Green Submitted, Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000570976900079,
Author = {Rosinol, Antoni and Gupta, Arjun and Abate, Marcus and Shi, Jingnan and
   Carlone, Luca},
Editor = {Toussaint, M and Bicchi, A and Hermans, T},
Title = {3D Dynamic Scene Graphs: Actionable Spatial Perception with Places,
   Objects, and Humans},
Url = {https://roboticsconference.org/2020/program/papers/79.html},
Booktitle = {ROBOTICS: SCIENCE AND SYSTEMS XVI},
Year = {2020},
Note = {16th Conference on Robotics - Science and Systems (RSS), ELECTR NETWORK,
   JUL 12-16, 2020},
Abstract = {We present a unified representation for actionable spatial perception:
   3D Dynamic Scene Graphs. Scene graphs are directed graphs where nodes
   represent entities in the scene (e.g. objects, walls, rooms), and edges
   represent relations (e.g. inclusion, adjacency) among nodes. Dynamic
   scene graphs (DSGs) extend this notion to represent dynamic scenes with
   moving agents (e.g. humans, robots), and to include actionable
   information that supports planning and decision-making (e.g.
   spatio-temporal relations, topology at different levels of abstraction).
   Our second contribution is to provide the first fully automatic Spatial
   PerceptIon eNgine(SPIN) to build a DSG from visual-inertial data. We
   integrate state-of-the-art techniques for object and human detection and
   pose estimation, and we describe how to robustly infer object, robot,
   and human nodes in crowded scenes. To the best of our knowledge, this is
   the first paper that reconciles visual-inertial SLAM and dense human
   mesh tracking. Moreover, we provide algorithms to obtain hierarchical
   representations of indoor environments (e.g. places, structures, rooms)
   and their relations. Our third contribution is to demonstrate the
   proposed spatial perception engine in a photo-realistic Unity-based
   simulator, where we assess its robustness and expressiveness. Finally,
   we discuss the implications of our proposal on modern robotics
   applications. 3D Dynamic Scene Graphs can have a profound impact on
   planning and decision-making, human-robot interaction, long-term
   autonomy, and scene prediction.},
Publisher = {MIT PRESS},
Address = {ONE ROGERS ST, CAMBRIDGE, MA 02142 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Rosinol, A (Corresponding Author), MIT, Lab Informat \& Decis Syst LIDS, Cambridge, MA 02139 USA.
   Rosinol, Antoni; Gupta, Arjun; Abate, Marcus; Shi, Jingnan; Carlone, Luca, MIT, Lab Informat \& Decis Syst LIDS, Cambridge, MA 02139 USA.},
ISBN = {978-0-9923747-6-1},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; MOTION; TRACKING; RECONSTRUCTION;
   RECOGNITION; MAPS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {arosinol@mit.edu
   agupta@mit.edu
   mabate@mit.edu
   jnshi@mit.edu
   lcarlone@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT)},
ResearcherID-Numbers = {Vidal, Antoni Rosinol/AAO-4321-2021},
ORCID-Numbers = {Vidal, Antoni Rosinol/0000-0001-5244-0882},
Funding-Acknowledgement = {ARL DCIST CRA {[}W911NF-17-2-0181]; ONR RAIDER {[}N00014-18-1-2828]; MIT
   Lincoln Laboratory; ``la Caixa{''} Foundation {[}100010434,
   LCF/BQ/AA18/11680088]},
Funding-Text = {This work was partially funded by ARL DCIST CRA W911NF-17-2-0181, ONR
   RAIDER N00014-18-1-2828, MIT Lincoln Laboratory, and ``la Caixa{''}
   Foundation (ID 100010434), LCF/BQ/AA18/11680088 (A. Rosinol).},
Cited-References = {Aldoma A, 2013, IEEE INT CONF ROBOT, P2104, DOI 10.1109/ICRA.2013.6630859.
   Alzantot M., 2012, P 20 INT C ADV GEOGR, P99.
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1\_24.
   ARMENI I, 2016, PROC CVPR IEEE, P1534, DOI DOI 10.1109/CVPR.2016.170.
   Armeni I, 2019, IEEE I CONF COMP VIS, P5663, DOI 10.1109/ICCV.2019.00576.
   Azim A, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P802, DOI 10.1109/IVS.2012.6232303.
   Bao S. Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2025, DOI 10.1109/CVPR.2011.5995462.
   Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939.
   BENNEWITZ M, 2003, EXPLORING ARTIFICIAL, P2000.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Blanco JL, 2009, ROBOT AUTON SYST, V57, P64, DOI 10.1016/j.robot.2008.02.002.
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1\_34.
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203.
   Brasch N, 2018, IEEE INT C INT ROBOT, P393, DOI 10.1109/IROS.2018.8593828.
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2\_5.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Chatila R., 1985, POSITION REFERENCING, P138, DOI DOI 10.1109/ROBOT.1985.1087373.
   Choi HJ, 2008, NANO, V3, P1, DOI 10.1142/S1793292008000848.
   Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12.
   Chojnacki M, 2018, INT J MICRO AIR VEH, V10, P157, DOI 10.1177/1756829318756354.
   Cui LY, 2019, IEEE ACCESS, V7, P166528, DOI 10.1109/ACCESS.2019.2952161.
   Dellaert F, 2017, FDN TRENDS ROBOT, V6, P1.
   Dong J., 2017, VISUAL INERTIAL SEMA.
   Dube R, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Eckenhoff K, 2019, IEEE ROBOT AUTOM LET, V4, P1541, DOI 10.1109/LRA.2019.2896472.
   Everett M., 2018, MOTION PLANNING DYNA.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Friedman S, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2109.
   Fukui A., 2016, PROC C EMPIRICAL MET, P457.
   Galindo C., 2005, IEEE RSJ INT C INT R, P3492.
   Geneva P., 2019, 19030863 ARXIV.
   Grinvald M, 2019, IEEE ROBOT AUTOM LET, V4, P3037, DOI 10.1109/LRA.2019.2923960.
   Hassan M, 2019, IEEE I CONF COMP VIS, P2282, DOI 10.1109/ICCV.2019.00237.
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411.
   Hwangbo M, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1909, DOI 10.1109/IROS.2009.5354093.
   Jiang CFF, 2018, INT J COMPUT VISION, V126, P920, DOI 10.1007/s11263-018-1103-5.
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215.
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990.
   Joho D, 2011, ROBOT AUTON SYST, V59, P319, DOI 10.1016/j.robot.2011.02.012.
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744.
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761.
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656.
   Kneip L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.16.
   Kollar T., 2017, 171201097 ARXIV.
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234.
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463.
   Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356.
   Krishna R., 2016, VISUAL GENOME CONNEC.
   Krishna S., 1992, INTRO DATABASE KNOWL.
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5.
   Kuipers B, 1978, COGNITIVE SCI, V2, P129, DOI {[}DOI 10.1207/S15516709COG0202\_3, 10.1207/s15516709cog0202\_3].
   Larsson D. T., 2019, Q SEARCH TREES INFOR.
   Larsson T, 2006, COMPUT GRAPH-UK, V30, P450, DOI 10.1016/j.cag.2006.02.011.
   Lassner C., 2017, PROC CVPR IEEE, P6050, DOI DOI 10.1109/CVPR.2017.500.
   Li C, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P574, DOI 10.1109/IROS.2016.7759111.
   Li J., 2020, ARXIV200105422.
   Li J., 2018, ABS181201192 ARXIV.
   Li PL, 2018, LECT NOTES COMPUT SC, V11206, P664, DOI 10.1007/978-3-030-01216-8\_40.
   Li Y, 2017, CHIN INSIGHT, P3, DOI 10.1007/978-981-10-4385-7\_1.
   Liang XD, 2017, PROC CVPR IEEE, P4408, DOI 10.1109/CVPR.2017.469.
   Lianos KN, 2018, LECT NOTES COMPUT SC, V11208, P246, DOI 10.1007/978-3-030-01225-0\_15.
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179.
   Liu C, 2018, LECT NOTES COMPUT SC, V11210, P203, DOI 10.1007/978-3-030-01231-1\_13.
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013.
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0\_51.
   Lukierski Robert, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6315, DOI 10.1109/ICRA.2017.7989747.
   Mangelson JG, 2018, IEEE INT CONF ROBOT, P2916.
   McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538.
   McCormac J, 2018, INT CONF 3D VISION, P32, DOI 10.1109/3DV.2018.00015.
   Monszpart A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322961.
   Mura C, 2014, COMPUT GRAPH-UK, V44, P20, DOI 10.1016/j.cag.2014.07.005.
   Narita G, 2019, IEEE INT C INT ROBOT, P4205, DOI 10.1109/IROS40897.2019.8967890.
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631.
   Nicholson L, 2019, IEEE ROBOT AUTOM LET, V4, P1, DOI 10.1109/LRA.2018.2866205.
   Nuchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001.
   Ochmann S, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P120.
   Oleynikova H., 2018, IEEE RSJ INT C INT R.
   Oleynikova H, 2017, IEEE INT C INT ROBOT, P1366, DOI 10.1109/IROS.2017.8202315.
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062.
   Pangercic D, 2012, IEEE INT C INT ROBOT, P4644, DOI 10.1109/IROS.2012.6385603.
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055.
   Pirk S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130814.
   Pronobis A., 2012, IEEE INT C ROB AUT I.
   Qiu KJ, 2019, IEEE T ROBOT, V35, P799, DOI 10.1109/TRO.2019.2909085.
   Ranganathan A., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P1518.
   Remolina E, 2004, ARTIF INTELL, V152, P47, DOI 10.1016/S0004-3702(03)00114-0.
   Rogers JG, 2012, IEEE INT CONF ROBOT, P1766, DOI 10.1109/ICRA.2012.6225298.
   Rosinol A., 2020, UHUMANS DATASET.
   Rosinol A., 2019, IEEE INT C ROB AUT I.
   Rosinol A., 2019, ARXIV191002490CS.
   Rosu R., 2019, INT J COMPUTER VISIO.
   Ruiz-Sarmiento JR, 2017, KNOWL-BASED SYST, V119, P257, DOI 10.1016/j.knosys.2016.12.016.
   Runz Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4471, DOI 10.1109/ICRA.2017.7989518.
   Runz M, 2018, INT SYM MIX AUGMENT, P10, DOI 10.1109/ISMAR.2018.00024.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Schleich D, 2019, ROBOTICS: SCIENCE AND SYSTEMS XV.
   Shan M., 2019, TECHNICAL REPORT.
   Shi XH, 2018, INT C DIGITAL HOME, P187, DOI 10.1109/ICDH.2018.00041.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Tan V., 2017, BMVC.
   Tateno K, 2015, IEEE INT C INT ROBOT, P4465, DOI 10.1109/IROS.2015.7354011.
   Turner E, 2014, 2014 PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS (GRAPP 2014), P22.
   Vasudevan S., 2006, P IROS WORKSH SENS H.
   Wald J, 2018, IEEE ROBOT AUTOM LET, V3, P3402, DOI 10.1109/LRA.2018.2852782.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wang R., 2010, OPENSCENEGRAPH 3 0 B.
   Whelan T, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI 10.1109/ICRA.2019.8794371.
   Xu D., 2017, INT C COMP VIS ICCV.
   Yang B, 2019, R RES LANDSCAPE ENV, P3.
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695.
   Zanfir A, 2018, PROC CVPR IEEE, P2148, DOI 10.1109/CVPR.2018.00229.
   Zender H, 2008, ROBOT AUTON SYST, V56, P493, DOI 10.1016/j.robot.2008.03.007.
   Zhang HH, 2017, IEEE ACM INT WORKS M, P5, DOI 10.1109/MiSE.2017.9.
   Zhang Y., 2019, ARXIV191202923.
   Zhao YB, 2013, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2013.401.
   Zheng K., 2019, P 2019 IEEE RSJ INT.
   Zheng K., 2018, P 32 AAAI C ART INT.
   Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291.
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540.},
Number-of-Cited-References = {120},
Times-Cited = {16},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BP9YJ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000570976900079},
DA = {2022-05-17},
}

@inproceedings{ WOS:000724145802112,
Author = {Wang, Lisai and Chen, Weidong and Wang, Jingchuan},
Book-Group-Author = {IEEE},
Title = {Long-Term Localization With Time Series Map Prediction for Mobile Robots
   in Dynamic Environments},
Booktitle = {2020 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2020},
Pages = {8587-8593},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, OCT 24-JAN 24, 2020-2021},
Abstract = {In many applications of mobile robot, the environment is constantly
   changing. How to use historical information to analysis environmental
   changes and generate a map corresponding with current environment is
   important to achieve high-precision localization. Inspired by predictive
   mechanism of brain, this paper presents a long-term localization
   approach named ArmMPU (ARMA-based Map Prediction and Update) based on
   time series modeling and prediction. Autoregressive moving average model
   (ARMA), a kind of time series modeling method, is employed for
   environmental map modeling and prediction, then predicted map and
   filtered observation are fused to fix the prediction error. The
   simulation and experiment results show that the proposed method improves
   long-term localization performance in dynamic environments.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Chen, WD (Corresponding Author), Shanghai Jiao Tong Univ, Inst Med Robot \& Dept Automat, Shanghai, Peoples R China.
   Chen, WD (Corresponding Author), Minist Educ, Key Lab Syst Control \& Informat Proc, Shanghai, Peoples R China.
   Wang, Lisai; Chen, Weidong; Wang, Jingchuan, Shanghai Jiao Tong Univ, Inst Med Robot \& Dept Automat, Shanghai, Peoples R China.
   Wang, Lisai; Chen, Weidong; Wang, Jingchuan, Minist Educ, Key Lab Syst Control \& Informat Proc, Shanghai, Peoples R China.},
DOI = {10.1109/IROS45743.2020.9468884},
ISSN = {2153-0858},
ISBN = {978-1-7281-6212-6},
Keywords-Plus = {MODELS},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {lisaiw@sjtu.edu.cn
   wdchen@sjtu.edu.cn
   jchwang@sjtu.edu.cn},
Affiliations = {Shanghai Jiao Tong University},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}U1813206, 61773261]},
Funding-Text = {This work is supported by the National Natural Science Foundation of
   China (Grant U1813206 and 61773261).},
Cited-References = {AKAIKE H, 1969, ANN I STAT MATH, V21, P243, DOI 10.1007/BF02532251.
   AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705.
   Apruzzi F, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2016)045.
   Boateng P, 2017, MEGAPROJECT RISK ANALYSIS AND SIMULATION: A DYNAMIC SYSTEMS APPROACH, P223.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Dodge Y., 2008, CONCISE ENCY STAT.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hu XW, 2018, CHIN AUTOM CONGR, P384, DOI 10.1109/CAC.2018.8623046.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Morris T, 2014, IEEE INT CONF ROBOT, P2765, DOI 10.1109/ICRA.2014.6907255.
   Olson E, 2015, IEEE INT CONF ROBOT, P5815, DOI 10.1109/ICRA.2015.7140013.
   Potter MC, 2014, ATTEN PERCEPT PSYCHO, V76, P270, DOI 10.3758/s13414-013-0605-z.
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626.
   Saarinen JP, 2013, INT J ROBOT RES, V32, P1627, DOI 10.1177/0278364913499415.
   Schreiber M, 2019, IEEE INT CONF ROBOT, P9299, DOI 10.1109/ICRA.2019.8793582.
   Song BW, 2019, IEEE INT C INT ROBOT, P5364, DOI 10.1109/IROS40897.2019.8968017.
   Sun DL, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4517, DOI 10.1109/IROS.2016.7759665.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Wang Y, 2014, IND ROBOT, V41, P241, DOI 10.1108/IR-06-2013-371.},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS4YL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000724145802112},
DA = {2022-05-17},
}

@article{ WOS:000516001900001,
Author = {Taniguchi, Akira and Hagiwara, Yoshinobu and Taniguchi, Tadahiro and
   Inamura, Tetsunari},
Title = {Improved and scalable online learning of spatial concepts and language
   models with mapping},
Journal = {AUTONOMOUS ROBOTS},
Year = {2020},
Volume = {44},
Number = {6},
Pages = {927-946},
Month = {JUL},
Abstract = {We propose a novel online learning algorithm, called SpCoSLAM 2.0, for
   spatial concepts and lexical acquisition with high accuracy and
   scalability. Previously, we proposed SpCoSLAM as an online learning
   algorithm based on unsupervised Bayesian probabilistic model that
   integrates multimodal place categorization, lexical acquisition, and
   SLAM. However, our original algorithm had limited estimation accuracy
   owing to the influence of the early stages of learning, and increased
   computational complexity with added training data. Therefore, we
   introduce techniques such as fixed-lag rejuvenation to reduce the
   calculation time while maintaining an accuracy higher than that of the
   original algorithm. The results show that, in terms of estimation
   accuracy, the proposed algorithm exceeds the original algorithm and is
   comparable to batch learning. In addition, the calculation time of the
   proposed algorithm does not depend on the amount of training data and
   becomes constant for each step of the scalable algorithm. Our approach
   will contribute to the realization of long-term spatial language
   interactions between humans and robots.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Taniguchi, A (Corresponding Author), Ritsumeikan Univ, 1-1-1 Noji Higashi, Kusatsu, Shiga 5258577, Japan.
   Taniguchi, Akira; Hagiwara, Yoshinobu; Taniguchi, Tadahiro, Ritsumeikan Univ, 1-1-1 Noji Higashi, Kusatsu, Shiga 5258577, Japan.
   Inamura, Tetsunari, SOKENDAI Grad Univ Adv Studies, Natl Inst Informat, Chiyoda Ku, 2-1-2 Hitotsubashi, Tokyo 1018430, Japan.},
DOI = {10.1007/s10514-020-09905-0},
EarlyAccessDate = {FEB 2020},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Online learning; Place categorization; Scalability; Semantic mapping;
   Lexical acquisition; Unsupervised Bayesian probabilistic model},
Keywords-Plus = {ACQUISITION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {a.taniguchi@em.ci.ritsumei.ac.jp
   yhagiwara@em.ci.ritsumei.ac.jp
   taniguchi@em.ci.ritsumei.ac.jp
   inamura@nii.ac.jp},
Affiliations = {Ritsumeikan University; Graduate University for Advanced Studies -
   Japan; Research Organization of Information \& Systems (ROIS); National
   Institute of Informatics (NII) - Japan},
ResearcherID-Numbers = {Inamura, Tetsunari/ADW-8458-2022},
Funding-Acknowledgement = {JST CREST {[}JPMJCR15E3]; JSPS KAKENHI {[}JP17J07842, JP16H06561,
   JP16K12497]},
Funding-Text = {This work was partially supported by JST CREST Grant Number JPMJCR15E3,
   and JSPS KAKENHI Grant Numbers JP17J07842, JP16H06561, and JP16K12497.},
Cited-References = {Aldous D. J., 1985, ECOLE ETE PROBABILTI, P1.
   Aoki T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2636, DOI 10.1109/IROS.2016.7759410.
   Araki T, 2012, IEEE INT C INT ROBOT, P1623, DOI 10.1109/IROS.2012.6385812.
   Araki T, 2012, ADV ROBOTICS, V26, P1995, DOI 10.1080/01691864.2012.728693.
   Ball D, 2013, AUTON ROBOT, V34, P149, DOI 10.1007/s10514-012-9317-9.
   Beevers KR, 2007, IEEE INT CONF ROBOT, P2433, DOI 10.1109/ROBOT.2007.363684.
   Borschinger B., 2012, P 50 ANN M ASS COMP, P85.
   Borschinger Benjamin, 2011, P AUSTR LANG TECHN A, P10.
   Cangelosi A, 2015, INTELL ROBOT AUTON, P1.
   Canini Kevin, 2009, P ARTIFICIAL INTELLI, P65.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Fox EB, 2011, ANN APPL STAT, V5, P1020, DOI 10.1214/10-AOAS395.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Gu ZX, 2016, IFAC PAPERSONLINE, V49, P150, DOI 10.1016/j.ifacol.2016.10.477.
   Hagiwara Y, 2018, FRONT NEUROROBOTICS, V12, DOI 10.3389/fnbot.2018.00011.
   Han F, 2018, AUTON ROBOT, V42, P1323, DOI 10.1007/s10514-018-9736-3.
   Heath S, 2016, IEEE T COGN DEV SYST, V8, P3, DOI 10.1109/TAMD.2015.2442619.
   Hemachandra S, 2014, IEEE INT CONF ROBOT, P2623, DOI 10.1109/ICRA.2014.6907235.
   Howard A., 2003, ROBOTICS DATA SET RE.
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075.
   Inamura T, 2010, Proceedings of the 2010 IEEE/SICE International Symposium on System Integration (SII 2010), P212, DOI 10.1109/SII.2010.5708327.
   Isobe S, 2017, LECT NOTES ARTIF INT, V10652, P115, DOI 10.1007/978-3-319-70022-9\_12.
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889.
   Kantas N, 2015, STAT SCI, V30, P328, DOI 10.1214/14-STS511.
   Karaoguz H, 2016, AUTON ROBOT, V40, P1379, DOI 10.1007/s10514-015-9514-4.
   Kitagawa G, 2014, ANN I STAT MATH, V66, P443, DOI 10.1007/s10463-014-0446-0.
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Kudo T., 2006, MECAB YET ANOTHER PA.
   Landsiedel C, 2017, ADV ROBOTICS, V31, P222, DOI 10.1080/01691864.2016.1277554.
   Lee A., 2009, P AS PAC SIGN INF PR, P131.
   Luperto M, 2019, AUTON ROBOT, V43, P813, DOI 10.1007/s10514-018-9732-7.
   Mochihashi D., 2009, P JOINT C 47 ANN M A, V1, P100.
   Montemerlo M., 2003, P 18 INT JOINT C ART, P1151.
   Nakamura T, 2018, FRONT NEUROROBOTICS, V12, DOI 10.3389/fnbot.2018.00025.
   Neubig G, 2012, IEICE T INF SYST, VE95D, P614, DOI 10.1587/transinf.E95.D.614.
   Nishihara J, 2017, IEEE T COGN DEV SYST, V9, P255, DOI 10.1109/TCDS.2016.2552579.
   Pronobis A, 2012, IEEE INT CONF ROBOT, P3515, DOI 10.1109/ICRA.2012.6224637.
   Rangel JC, 2019, AUTON ROBOT, V43, P697, DOI 10.1007/s10514-018-9723-8.
   SETHURAMAN J, 1994, STAT SINICA, V4, P639.
   Sunderhauf N, 2016, IEEE INT CONF ROBOT, P5729, DOI 10.1109/ICRA.2016.7487796.
   Taguchi R, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1336.
   Taniguchi A, 2017, IEEE INT C INT ROBOT, P811, DOI 10.1109/IROS.2017.8202243.
   Taniguchi A, 2018, ROBOT AUTON SYST, V99, P166, DOI 10.1016/j.robot.2017.10.013.
   Taniguchi A, 2016, IEEE T COGN DEV SYST, V8, P285, DOI 10.1109/TCDS.2016.2565542.
   Taniguchi T, 2019, IEEE T COGN DEV SYST, V11, P494, DOI 10.1109/TCDS.2018.2867772.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Ueda R., 2016, P INT C INT AUT SYST, P737.
   Walter M. R., 2013, P ROB SCI SYST RSS.
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009.},
Number-of-Cited-References = {50},
Times-Cited = {7},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {5},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {MI1DC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000516001900001},
OA = {Green Submitted, hybrid},
DA = {2022-05-17},
}

@inproceedings{ WOS:000269197301274,
Author = {Gross, H. -M. and Boehme, H. -J. and Schroeter, C. and Mueller, S. and
   Koenig, A. and Martin, Ch. and Merten, M. and Bley, A.},
Book-Group-Author = {IEEE},
Title = {ShopBot: Progress in Developing an Interactive Mobile Shopping Assistant
   for Everyday Use},
DOI = {10.1109/ICSMC.2008.4811835},
Booktitle = {2008 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN AND CYBERNETICS
   (SMC), VOLS 1-6},
Series = {IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings},
Year = {2008},
Pages = {3470+},
Note = {IEEE International Conference on System, Man, and Cybernetic, Singapore,
   SINGAPORE, OCT 12-15, 2008},
Abstract = {The paper describes progress achieved in our longterm research project
   SHOPBOT, which aims at the development of an intelligent and interactive
   mobile shopping assistant for everyday use in shopping centers or home
   improvement stores. It is focusing on recent progress concerning two
   important methodological aspects: (i) the on-line building of maps of
   the operation area by means of advanced Rao-Blackwellized SLAM
   approaches using both sonar-based gridmaps as well as vision-based graph
   maps as representations, and (ii) a probabilistic approach to
   multi-modal user detection and tracking during the guidance tour.
   Experimental results of both the map building characteristics and the
   person tracking behavior achieved in an ordinary home improvement store
   demonstrate the reliability of both approaches. Moreover, we present
   first very encouraging results of long-term field trials which have been
   executed with three robotic shopping assistants in another home
   improvement store in Bavaria since March 2008. In this field test, the
   robots could demonstrate their suitability for this challenging
   real-world application, as well as the necessary user acceptance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gross, HM (Corresponding Author), Ilmenau Univ Technol, Neuroinformat \& Cognit Robot Lab, D-98693 Ilmenau, Germany.
   Gross, H. -M.; Boehme, H. -J.; Schroeter, C.; Mueller, S.; Koenig, A., Ilmenau Univ Technol, Neuroinformat \& Cognit Robot Lab, D-98693 Ilmenau, Germany.
   Martin, Ch.; Merten, M.; Bley, A., MetraLabs Robot GmbH, D-98693 Ilmenau, Germany.},
ISSN = {1062-922X},
ISBN = {978-1-4244-2383-5},
Keywords-Plus = {SENSOR FUSION; ROBOTS; TRACKING},
Research-Areas = {Computer Science; Engineering; Imaging Science \& Photographic
   Technology},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Engineering, Electrical \& Electronic; Imaging Science \&
   Photographic Technology},
Author-Email = {Horst-Michael.Gross@tu-ilmenau.de},
Affiliations = {Technische Universitat Ilmenau},
Funding-Acknowledgement = {State Thuringia {[}2006-FE-0154]; AiF/BMWI {[}KF0555101DF]},
Funding-Text = {The research leading to these results has received funding from the
   State Thuringia (TAB-Grant \#2006-FE-0154) and the AiF/BMWI
   (ALRob-Project Grant \#KF0555101DF)},
Cited-References = {ANDREASSON H, P ICRA 07, P4096.
   ELIAZAR AI, P IJCAI 03, P1135.
   FOX D, P AAAI 99, P5398.
   FRITSCH J, P ICRA 04, P898.
   GROSS HM, P IROS 03, P1505.
   GROSS HM, P IEEE SMC 00, P80.
   GROSS HM, P IROS 02, P265.
   HAEHNEL D, P IROS 03, P206.
   Jensen B, 2005, IEEE T IND ELECTRON, V52, P1530, DOI 10.1109/TIE.2005.858730.
   KOENIG A, P IROS 08.
   KULYUKIN V, P IROS 05, P2845.
   Lowe D. G., P ICCV 99, P1150.
   Martin C, 2006, ROBOT AUTON SYST, V54, P721, DOI 10.1016/j.robot.2006.04.012.
   MENEGATTI E, P ECMR 03, P13.
   MONTEMERLO M, P AAAI 02, P593.
   MORAVEC HP, 1988, AI MAG, V9, P61.
   MURPHY KP, P NIPS 99, P1015.
   RANGANATHAN A, P ICRA 06, P810.
   SCHEIDIG A, P ROMAN 06, P747.
   SCHROETER C, P IROS 08.
   SCHROETER C, P ECMR07, P138.
   SCHULZ D, P CVPR 01, P371.
   SHIEH M, P SMC 06, P4493.
   Siegwart R, 2003, ROBOT AUTON SYST, V42, P203, DOI 10.1016/S0921-8890(02)00376-7.
   Simmons R, 2003, AI MAG, V24, P51.
   STMUELLER, P ECMR 07, P211.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   TOMIZAWA T, P IROS 06, P4953.
   VIOLA P, P NIPS 01, P1311.
   Wilhelm T, 2004, ROBOT AUTON SYST, V48, P31, DOI 10.1016/j.robot.2004.05.004.},
Number-of-Cited-References = {30},
Times-Cited = {52},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BKT54},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000269197301274},
DA = {2022-05-17},
}

@article{ WOS:000626509300002,
Author = {Thien Hoang Nguyen and Thien-Minh Nguyen and Xie, Lihua},
Title = {Range-Focused Fusion of Camera-IMU-UWB for Accurate and Drift-Reduced
   Localization},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {2},
Pages = {1678-1685},
Month = {APR},
Abstract = {In this work, we present a tightly-coupled fusion scheme of a monocular
   camera, a 6-DoF IMU, and a single unknown Ultra-wideband (UWB) anchor to
   achieve accurate and drift-reduced localization. Specifically, this
   letter focuses on incorporating the UWB sensor into an existing
   state-of-the-art visual-inertial system. Previous works toward this goal
   use a single nearest UWB range data to update robot positions in the
   sliding window ({''}position-focused{''}) and have demonstrated
   encouraging results. However, these approaches ignore 1) the time-offset
   between UWB and camera sensors, and 2) all other ranges between two
   consecutive keyframes. Our approach shifts the perspective to the UWB
   measurements ({''}range-focused{''}) by leveraging the propagated
   information readily available from the visual-inertial odometry
   pipeline. This allows the UWB data to be used in a more effective
   manner: the time-offset of each range data is addressed and all
   available measurements can be utilized. Experimental results show that
   the proposed method consistently outperforms previous methods in both
   estimating the anchor position and reducing the drift in long-term
   trajectories.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Nguyen, TH (Corresponding Author), Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.
   Thien Hoang Nguyen; Thien-Minh Nguyen; Xie, Lihua, Nanyang Technol Univ, Sch Elect \& Elect Engn, Singapore 639798, Singapore.},
DOI = {10.1109/LRA.2021.3057838},
ISSN = {2377-3766},
Keywords = {Sensor fusion; localization; SLAM},
Keywords-Plus = {OPTIMIZATION; NAVIGATION; ROBUST},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {e180071@e.ntu.edu.sg
   thienminh.npn@gmail.com
   ELHXIE@ntu.edu.sg},
Affiliations = {Nanyang Technological University \& National Institute of Education
   (NIE) Singapore; Nanyang Technological University},
ResearcherID-Numbers = {Xie, Lihua/D-2236-2009
   },
ORCID-Numbers = {Xie, Lihua/0000-0002-7137-4136
   Nguyen, Thien-Minh/0000-0003-1315-0967
   Nguyen, Thien/0000-0003-1218-0910},
Funding-Acknowledgement = {Delta-NTU Corporate Lab through the National Research Foundation
   Corporate Lab@UniversityScheme},
Funding-Text = {This work was supported by the Delta-NTU Corporate Lab through the
   National Research Foundation Corporate Lab@UniversityScheme.},
Cited-References = {AGARWAL S, CERES SOLVER TUTORIA.
   Alarifi A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050707.
   Benini A, 2013, J INTELL ROBOT SYST, V70, P461, DOI 10.1007/s10846-012-9742-1.
   Cao S., 2019, GEN OPTIMIZATION BAS.
   Cioffi G, 2020, IEEE INT C INT ROBOT, P5089, DOI 10.1109/IROS45743.2020.9341697.
   FANG BT, 1990, IEEE T AERO ELEC SYS, V26, P748, DOI 10.1109/7.102710.
   Fernando E, 2019, IEEE INT C INT ROBOT, P2783, DOI 10.1109/IROS40897.2019.8968057.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Geneva P, 2020, IEEE INT CONF ROBOT, P4666, DOI 10.1109/ICRA40945.2020.9196524.
   Hausman K, 2016, IEEE INT CONF ROBOT, P4289, DOI 10.1109/ICRA.2016.7487626.
   Hoeller D, 2017, IFAC PAPERSONLINE, V50, P12734, DOI 10.1016/j.ifacol.2017.08.1826.
   HUBER PJ, 1964, ANN MATH STAT, V35, P73, DOI 10.1214/aoms/1177703732.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164.
   Li JX, 2018, IEEE INT CONF CON AU, P100, DOI 10.1109/ICCA.2018.8444329.
   Lu Y, 2017, INT J ADV ROBOT SYST, V14, P1, DOI 10.1177/1729881417716816.
   Mahfouz MR, 2008, IEEE T MICROW THEORY, V56, P1316, DOI 10.1109/TMTT.2008.923351.
   Martel FM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204366.
   Mueller MW, 2015, IEEE INT CONF ROBOT, P1730, DOI 10.1109/ICRA.2015.7139421.
   Nguyen P. N. T. M., 2020, THESIS NANYANG TU.
   Nguyen TM, 2020, IEEE T ROBOT, V36, P553, DOI 10.1109/TRO.2019.2954677.
   Nguyen TM, 2020, IEEE T CONTR SYST T, V28, P2021, DOI 10.1109/TCST.2019.2916089.
   Nyqvist H.E., 2015, P IEEE IPIN, P13, DOI 10.1109/IPIN.2015.7346940.
   Perez-Grau FJ, 2017, IEEE INT C INT ROBOT, P3495, DOI 10.1109/IROS.2017.8206191.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Shi Q, 2018, I NAVIG SAT DIV INT, P3111, DOI 10.33012/2018.15962.
   Song Y, 2019, IEEE INT CONF ROBOT, P6568, DOI 10.1109/ICRA.2019.8794222.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Nguyen TH, 2020, IEEE INT CONF ROBOT, P665, DOI 10.1109/ICRA40945.2020.9196794.
   Nguyen TH, 2020, AUTON ROBOT, V44, P1519, DOI 10.1007/s10514-020-09944-7.
   Nguyen TM, 2019, IEEE INT CONF ROBOT, P9603, DOI 10.1109/ICRA.2019.8793851.
   Tiemann J, 2018, IEEE INT CONF COMM.
   Usenko V, 2020, IEEE ROBOT AUTOM LET, V5, P422, DOI 10.1109/LRA.2019.2961227.
   van der Helm S, 2020, AUTON ROBOT, V44, P415, DOI 10.1007/s10514-019-09843-6.
   Wang C, 2017, IEEE INT C INT ROBOT, P1602, DOI 10.1109/IROS.2017.8205968.
   Xu H, 2020, IEEE INT CONF ROBOT, P8776, DOI 10.1109/ICRA40945.2020.9196944.},
Number-of-Cited-References = {36},
Times-Cited = {9},
Usage-Count-Last-180-days = {18},
Usage-Count-Since-2013 = {38},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {QT3SF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000626509300002},
DA = {2022-05-17},
}

@inproceedings{ WOS:000259998202092,
Author = {Dayoub, Feras and Duckett, Tom},
Editor = {Chatila, R and Kelly, A and Merlet, JP},
Title = {An Adaptive Appearance-based Map for Long-Term Topological Localization
   of Mobile Robots},
Booktitle = {2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT
   SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS},
Year = {2008},
Pages = {3364-3369},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems,
   Nice, FRANCE, SEP 22-26, 2008},
Abstract = {This work considers a mobile service robot which uses an
   appearance-based representation of its workplace as a map, where the
   current view and the map are used to estimate the current position in
   the environment. Due to the nature of real-world environments such as
   houses and offices, where the appearance keeps changing, the internal
   representation may become out of date after some time. To solve this
   problem the robot needs to be able to adapt its internal representation
   continually to the changes in the environment. This paper presents a
   method for creating an adaptive map for long-term appearance-based
   localization of a mobile robot using long-term and short-term memory
   concepts, with omni-directional vision as the external sensor.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dayoub, F (Corresponding Author), Lincoln Univ, Dept Comp \& Informat, Lincoln LN6 7TS, England.
   Dayoub, Feras; Duckett, Tom, Lincoln Univ, Dept Comp \& Informat, Lincoln LN6 7TS, England.},
DOI = {10.1109/IROS.2008.4650701},
ISBN = {978-1-4244-2057-5},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic; Robotics},
Author-Email = {fdayoub@lincoln.ac.uk
   tduckett@lincoln.ac.uk},
Affiliations = {University of Lincoln},
ResearcherID-Numbers = {Dayoub, Iyad/ABB-1565-2021
   },
ORCID-Numbers = {Dayoub, Iyad/0000-0003-0910-4722
   Dayoub, Feras/0000-0002-4234-7374},
Cited-References = {Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI {[}10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3].
   Bay H., 2006, P EUR C COMP VIS ECC.
   FRAUNDORFER C, 2007, P IEEE INT C INT ROB.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   GROSS H, 2003, P IEEE INT C INT ROB.
   KOSECKA J, 2004, P IEEE INT C ROB AUT.
   KUIPERS B, 1993, LEARNING ROBOTS, P4763.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006.
   Menegatti E, 2004, ROBOT AUTON SYST, V48, P17, DOI 10.1016/j.robot.2004.05.003.
   Nister D., 2006, P IEEE C COMP VIS PA.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   Sivic J., 2003, P IEEE INT C COMP VI.
   TAMIMI H., 2005, P EUR C MOB ROB ECMR.
   Ulrich I., 2000, P IEEE INT C ROB AUT.
   VALGREN C, 2006, P IEEE INT C INT ROB.
   VLASSIS N, 2002, P IEEE INT C ROB AUT.
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.},
Number-of-Cited-References = {18},
Times-Cited = {36},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BIJ26},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000259998202092},
OA = {Green Accepted},
DA = {2022-05-17},
}

@article{ WOS:000565043900001,
Author = {Piasco, Nathan and Sidibe, Desire and Gouet-Brunet, Valerie and
   Demonceaux, Cedric},
Title = {Improving Image Description with Auxiliary Modality for Visual
   Localization in Challenging Conditions},
Journal = {INTERNATIONAL JOURNAL OF COMPUTER VISION},
Year = {2021},
Volume = {129},
Pages = {185-202},
Number = {1},
Month = {JAN},
Abstract = {Image indexing for lifelong localization is a key component for a large
   panel of applications, including robot navigation, autonomous driving or
   cultural heritage valorization. The principal difficulty in long-term
   localization arises from the dynamic changes that affect outdoor
   environments. In this work, we propose a new approach for outdoor large
   scale image-based localization that can deal with challenging scenarios
   like cross-season, cross-weather and day/night localization. The key
   component of our method is a new learned global image descriptor, that
   can effectively benefit from scene geometry information during training.
   At test time, our system is capable of inferring the depth map related
   to the query image and use it to increase localization accuracy. We show
   through extensive evaluation that our method can improve localization
   performances, especially in challenging scenarios when the visual
   appearance of the scene has changed. Our method is able to leverage both
   visual and geometric clues from monocular images to create
   discriminative descriptors for cross-season localization and effective
   matching of images acquired at different time periods. Our method can
   also use weakly annotated data to localize night images across a
   reference dataset of daytime images. Finally we extended our method to
   reflectance modality and we compare multi-modal descriptors respectively
   based on geometry, material reflectance and a combination of both.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Piasco, N (Corresponding Author), Univ Bourgogne Franche Comte, ImViA, VIBOT ERL CNRS 6000, Dijon, France.
   Piasco, N (Corresponding Author), Univ Paris Est, ENSG, IGN, LaSTIG, F-94160 St Mande, France.
   Piasco, Nathan; Demonceaux, Cedric, Univ Bourgogne Franche Comte, ImViA, VIBOT ERL CNRS 6000, Dijon, France.
   Piasco, Nathan; Gouet-Brunet, Valerie, Univ Paris Est, ENSG, IGN, LaSTIG, F-94160 St Mande, France.
   Sidibe, Desire, Univ Evry, Univ Paris Saclay, IBISC, F-91020 Evry, France.},
DOI = {10.1007/s11263-020-01363-6},
EarlyAccessDate = {AUG 2020},
ISSN = {0920-5691},
EISSN = {1573-1405},
Keywords = {Localization; Image retrieval; Side modality learning; Depth from
   monocular; Global image descriptor},
Keywords-Plus = {REPRESENTATIONS; RECOGNITION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {nathan.piasco@gmail.com},
Affiliations = {Universite de Bourgogne; Universite Gustave-Eiffel; UDICE-French
   Research Universities; League of European Research Universities - LERU;
   Universite Paris Saclay; Universite d'Evry-Val-d'Essonne},
ResearcherID-Numbers = {SIDIBE, DESIRE/AFQ-8070-2022
   Demonceaux, Cedric/S-5643-2017},
ORCID-Numbers = {SIDIBE, DESIRE/0000-0002-5843-7139
   Demonceaux, Cedric/0000-0001-6916-1273},
Funding-Acknowledgement = {French ANR project pLaTINUM {[}ANR-15-CE23-0010]; NVIDIA Corporation},
Funding-Text = {We would like to acknowledge the French ANR project pLaTINUM
   (ANR-15-CE23-0010) for its financial support and Marco Bevilacqua for
   kindly sharing the code of his inpainting algorithm used in this
   research. We also gratefully acknowledge the support of NVIDIA
   Corporation with the donation of the Titan Xp GPU used for this
   research.},
Cited-References = {Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387.
   Anoosheh A, 2018, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2018.00122.
   Arandjelovi R., 2014, AS C COMP VIS ACCV.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Ardeshir S, 2014, LECT NOTES COMPUT SC, V8694, P602, DOI 10.1007/978-3-319-10599-4\_39.
   Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591009.
   Azzi C., 2016, BRIT MACH VIS C BMVC, V2, P1.
   Bansal A, 2014, IEEE INT VEH SYM, P800, DOI 10.1109/IVS.2014.6856605.
   Bevilacqua M, 2017, ISPRS J PHOTOGRAMM, V125, P16, DOI 10.1016/j.isprsjprs.2017.01.005.
   Bhowmik N, 2017, JOINT URB REMOTE SEN.
   Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489.
   Cao Y, 2016, THIRTIETH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3457.
   Cao ZJ, 2017, IEEE I CONF COMP VIS, P5609, DOI 10.1109/ICCV.2017.598.
   Chevalier M, 2018, PATTERN RECOGN LETT, V116, P29, DOI 10.1016/j.patrec.2018.09.007.
   Christie G., 2016, ARXIV160904794.
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172.
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601.
   Cord, 2018, ADV NEURAL INFORM PR, P1310.
   Croissant JG, 2016, FRONT MOL BIOSCI, V3, DOI 10.3389/fmolb.2016.00001.
   Deng C, 2018, IEEE T IMAGE PROCESS, V27, P3893, DOI 10.1109/TIP.2018.2821921.
   Eigen D., 2014, ADV NEURAL INFORM PR.
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446.
   Garg S, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Garg S, 2018, IEEE INT CONF ROBOT, P3645, DOI 10.1109/ICRA.2018.8461051.
   Germain H., 2018, ARXIV181203707.
   Germain H, 2019, INT CONF 3D VISION, P513, DOI 10.1109/3DV.2019.00063.
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699.
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8.
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4\_15.
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0\_23.
   Hays J., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587784.
   Hinton G., 2015, ARXIV150302531, V14, P38.
   Hoffman J, 2016, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2016.96.
   Iscen A., 2018, MINING MANIFOLDS MET.
   Jegou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609.
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348.
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6\_43.
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572.
   Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346.
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947.
   Li W, 2018, IEEE T PATTERN ANAL, V40, P2030, DOI 10.1109/TPAMI.2017.2734890.
   Liu L, 2019, IEEE I CONF COMP VIS, P2570, DOI 10.1109/ICCV.2019.00266.
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685.
   Loo SY, 2019, IEEE INT CONF ROBOT, P5218, DOI 10.1109/ICRA.2019.8794425.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Morago B, 2016, IEEE T IMAGE PROCESS, V7149, P12.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305.
   Naseer T, 2018, IEEE T ROBOT, V34, P289, DOI 10.1109/TRO.2017.2788045.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Paulin M, 2017, INT J COMPUT VISION, V121, P149, DOI 10.1007/s11263-016-0924-3.
   Piasco N., 2019, BRIT MACH VIS C BMVC.
   Piasco N, 2019, IEEE IMAGE PROC, P2561, DOI 10.1109/ICIP.2019.8803014.
   Piasco N, 2019, IEEE INT CONF ROBOT, P9094, DOI 10.1109/ICRA.2019.8794221.
   Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013.
   Porav H, 2019, IEEE INT CONF ROBOT, P7087, DOI 10.1109/ICRA.2019.8793486.
   Porav H, 2018, IEEE INT CONF ROBOT, P1011, DOI 10.1109/ICRA.2018.8462894.
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566.
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0\_1.
   Riba E., 2016, BRIT MACH VIS C.
   Russell BC, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS).
   Sarlin P.-E., 2018, P 2 C ROB LEARN CORL, P1.
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175.
   Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721.
   Seymour M, 2019, COMMUN BIOL, V2, DOI 10.1038/s42003-019-0330-9.
   Sharmanska V, 2013, IEEE I CONF COMP VIS, P825, DOI 10.1109/ICCV.2013.107.
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377.
   Sizikova E., 2016, EUR C COMP VIS WORKS, P1.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695.
   Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8\_24.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Torii A, 2015, IEEE T PATTERN ANAL, V37, P2346, DOI 10.1109/TPAMI.2015.2409868.
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Vapnik V, 2009, NEURAL NETWORKS, V22, P544, DOI 10.1016/j.neunet.2009.06.042.
   Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451.
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799.
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1\_19.
   Zhou T., 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632.
   Zwald Laurent, 2012, ARXIV12076868.},
Number-of-Cited-References = {87},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {9},
Journal-ISO = {Int. J. Comput. Vis.},
Doc-Delivery-Number = {PU0KV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000565043900001},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000376668802123,
Author = {Dominguez, S. and Khomutenko, B. and Garcia, G. and Martinet, P.},
Book-Group-Author = {IEEE},
Title = {An optimization technique for positioning multiple maps for self-driving
   car's autonomous navigation},
Booktitle = {2015 IEEE 18TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION
   SYSTEMS},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2015},
Pages = {2694-2699},
Note = {18th IEEE International Conference on Intelligent Transportation
   Systems, SPAIN, SEP 15-18, 2015},
Abstract = {Self-driving car's navigation requires a very precise localization
   covering wide areas and long distances. Moreover, they have to do it at
   faster speeds than conventional mobile robots. This paper reports on an
   efficient technique to optimize the position of a sequence of maps along
   a journey. We take advantage of the short-term precision and reduced
   space on disk of the localization using 2D occupancy grid maps, from now
   on called sub-maps, as well as, the long-term global consistency of a
   Kalman filter that fuses odometry and GPS measurements. In our approach,
   horizontal planar LiDARs and odometry measurements are used to perform
   2D-SLAM generating the sub-maps, and the EKF to generate the trajectory
   followed by the car in global coordinates. During the trip, after
   finishing each sub-map, a relaxation process is applied to a set of the
   last sub-maps to position them globally using both, global and map's
   local path. The importance of this method lies on its performance,
   expending low computing resources, so it can work in real time on a
   computer with conventional characteristics and on its robustness which
   makes it suitable for being used on a selfdriving car as it doesn't
   depend excessively on the availability of GPS signal or the eventual
   appearance of moving objects around the car. Extensive testing has been
   performed in the suburbs and in the down-town of Nantes (France)
   covering a distance of 25 kilometers with different traffic conditions
   obtaining satisfactory results for autonomous driving.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dominguez, S (Corresponding Author), Ecole Cent Nantes, IRCCyN, 1 Rue Noe, F-44321 Nantes, France.
   Dominguez, S.; Khomutenko, B.; Garcia, G.; Martinet, P., Ecole Cent Nantes, IRCCyN, 1 Rue Noe, F-44321 Nantes, France.},
DOI = {10.1109/ITSC.2015.433},
ISSN = {2153-0009},
ISBN = {978-1-4673-6596-3},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation Science \& Technology},
Author-Email = {Salvador.Dominguez@irccyn.ec-nantes.fr
   khomutenko.bogdan@irccyn.ec-nantes.fr
   Gaetan.Garcia@ec-nantes.fr
   Philippe.Martinet@irccyn.ec-nantes.fr},
Affiliations = {Nantes Universite; Ecole Centrale de Nantes},
ResearcherID-Numbers = {Martinet, Philippe/E-1714-2015},
ORCID-Numbers = {Martinet, Philippe/0000-0001-5827-0431},
Cited-References = {Beall C., 2014, 6 WORKSH PLANN PERC.
   Biber P., 2005, P ROB SCI SYST RSS.
   Chanier Francois, 2008, 2008 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2008), P533, DOI 10.1109/MFI.2008.4648050.
   Churchill W, 2012, IEEE INT C INTELL TR, P1371, DOI 10.1109/ITSC.2012.6338716.
   Engel J., 2014, P EUR C COMP VIS ECC.
   Herath DC, 2008, IEEE INT CONF ROBOT, P1892, DOI 10.1109/ROBOT.2008.4543483.
   Karlsson N, 2005, IEEE INT CONF ROBOT, P24.
   Suger B, 2014, IEEE INT CONF ROBOT, P3632, DOI 10.1109/ICRA.2014.6907384.
   Zhao HJ, 2008, IEEE INT CONF ROBOT, P1455, DOI 10.1109/ROBOT.2008.4543407.},
Number-of-Cited-References = {9},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {9},
Doc-Delivery-Number = {BE8OT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000376668802123},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000447734200016,
Author = {Tanaka, Kanji},
Title = {Deformable Map Matching to Handle Uncertain Loop-Less Maps},
Journal = {JOURNAL OF ADVANCED COMPUTATIONAL INTELLIGENCE AND INTELLIGENT
   INFORMATICS},
Year = {2018},
Volume = {22},
Number = {6},
Pages = {915-923},
Month = {OCT},
Abstract = {In the classical context of map relative localization, map-matching (MM)
   is typically defined as the task of finding a rigid transformation
   (i.e., 3DOF rotation/translation on the 2D moving plane) that aligns two
   maps, the query and reference maps built by mobile robots. This
   definition is valid in loop-rich trajectories that enable a mapper robot
   to close many loops, for which precise maps can be assumed. The same
   cannot be said about the newly emerging vision only autonomous
   navigation systems, which typically operate in loop-less trajectories
   that have no loop (e.g., straight paths). In this paper, we address this
   limitation by merging the two maps. Our study is motivated by the
   observation that even when there is no loop in either the query or
   reference map, many loops can often be obtained in the merged map. We
   add two new aspects to MM: (1) map retrieval with compact and
   discriminative binary features powered by deep convolutional neural
   network (DCNN), which efficiently generates a small number of good
   initial alignment hypotheses; and (2) map merge, which jointly deforms
   the two maps to minimize differences in shape between them. A preemption
   scheme is introduced to avoid excessive evaluation of useless MM
   hypotheses. For experimental investigation, we created a novel
   collection of uncertain loop-less maps by utilizing the recently
   published North Campus Long-Term (NCLT) dataset and its ground-truth GPS
   data. The results obtained using these map collections confirm that our
   approach improves on previous MM approaches.},
Publisher = {FUJI TECHNOLOGY PRESS LTD},
Address = {1-15-7, UCHIKANDA, CHIYODA-KU, UNIZO UCHIKANDA 1-CHOME BLDG 2F, TOKYO,
   101-0047, JAPAN},
Type = {Article},
Language = {English},
Affiliation = {Tanaka, K (Corresponding Author), Univ Fukui, 3-9-1 Bunkyo, Fukui, Fukui 9108507, Japan.
   Tanaka, Kanji, Univ Fukui, 3-9-1 Bunkyo, Fukui, Fukui 9108507, Japan.},
DOI = {10.20965/jaciii.2018.p0915},
ISSN = {1343-0130},
EISSN = {1883-8014},
Keywords = {loop closing; deformable map matching; deep convolutional features},
Keywords-Plus = {LARGE-SCALE; RELOCATION; SLAM},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Funding-Acknowledgement = {JSPS KAKENHI {[}26330297, 17K00361]},
Funding-Text = {Our work has been supported in part by JSPS KAKENHI Grant-in-Aid for
   Scientific Research (C) 26330297, and (C) 17K00361.},
Cited-References = {Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1\_38.
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Clemente L. A., 2007, ROBOTICS SCI SYSTEMS, V3.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Ikeda K, 2010, IEEE INT CONF ROBOT, P4397, DOI 10.1109/ROBOT.2010.5509579.
   Koenig A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1576, DOI 10.1109/IROS.2008.4650878.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Neira J, 2003, IEEE INT CONF ROBOT, P427.
   Ni K, 2007, IEEE INT CONF ROBOT, P1678, DOI 10.1109/ROBOT.2007.363564.
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257.
   Sumner RW, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239531.
   Tanaka K., 2016, 2016 IEEE RSJ INT C.
   Tanaka K, 2008, IEEE INT CONF ROBOT, P2784, DOI 10.1109/ROBOT.2008.4543632.
   Tanaka K, 2006, IEEE INT CONF ROBOT, P68, DOI 10.1109/ROBOT.2006.1641163.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Tomomi N, 2011, IEEE INT C INT ROBOT, P872, DOI 10.1109/IROS.2011.6048283.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.},
Number-of-Cited-References = {22},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Journal-ISO = {J. Adv. Comput. Intell. Inform.},
Doc-Delivery-Number = {GX4VA},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000447734200016},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000629731200025,
Author = {Chen, Runjian and Yin, Huan and Jiao, Yanmei and Dissanayake, Gamini and
   Wang, Yue and Xiong, Rong},
Title = {Deep Samplable Observation Model for Global Localization and Kidnapping},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {2},
Pages = {2296-2303},
Month = {APR},
Abstract = {Global localization and kidnapping are two challenging problems in robot
   localization. The popular method, Monte Carlo Localization (MCL)
   addresses the problem by iteratively updating a set of particles with a
   ``sampling-weighting{''} loop. Sampling is decisive to the performance
   of MCL {[}1]. However, traditional MCL can only sample from a uniform
   distribution over the state space. Although variants of MCL propose
   different sampling models, they fail to provide an accurate distribution
   or generalize across scenes. To better deal with these problems, we
   present a distribution proposal model named Deep Samplable Observation
   Model (DSOM). DSOM takes a map and a 2D laser scan as inputs and outputs
   a conditional multimodal probability distribution of the pose, making
   the samples more focusing on the regions with higher likelihood. With
   such samples, the convergence is expected to be more effective and
   efficient. Considering that the learning-based sampling model may fail
   to capture the accurate pose sometimes, we furthermore propose the
   Adaptive Mixture MCL (AdaM MCL), which deploys a trusty mechanism to
   adaptively select updating mode for each particle to tolerate this
   situation. Equipped with DSOM, AdaM MCL can achieve more accurate
   estimation, faster convergence and better scalability than previous
   methods in both synthetic and real scenes. Even in real environments
   with long-term changes, AdaM MCL is able to localize the robot using
   DSOM trained only by simulation observations from a SLAM map or a
   blueprint map. Source code for this paper is available here:
   https://github.com/Runjian-Chen/AdaM\_MCL.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   Wang, Y (Corresponding Author), Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310027, Zhejiang, Peoples R China.
   Chen, Runjian; Yin, Huan; Jiao, Yanmei; Wang, Yue; Xiong, Rong, Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou 310027, Zhejiang, Peoples R China.
   Chen, Runjian; Yin, Huan; Jiao, Yanmei; Wang, Yue; Xiong, Rong, Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310027, Zhejiang, Peoples R China.
   Dissanayake, Gamini, Univ Technol Sydney, Ctr Autonomous Syst, Ultimo, NSW 2007, Australia.},
DOI = {10.1109/LRA.2021.3061339},
ISSN = {2377-3766},
Keywords = {Global localization; multimodal; samplable observation model},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {rjchen@zju.edu.cn
   zjuyinhuan@gmail.com
   11732026@zju.edu.cn
   gamini.dissanayake@uts.edu.au
   ywang24@zju.edu.cn
   rxiong\_zju@hotmail.com},
Affiliations = {Zhejiang University; Zhejiang University; University of Technology
   Sydney},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020
   },
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202
   Chen, Runjian/0000-0003-0519-496X},
Funding-Acknowledgement = {National Nature Science Foundation of China {[}61903332]; Zhejiang
   PublicWelfareTechnology Research Program {[}LGG21F030012]},
Funding-Text = {This work was supported in part by the National Nature Science
   Foundation of China under Grant 61903332 and in part by the Zhejiang
   PublicWelfareTechnology Research Program under Grant LGG21F030012.},
Cited-References = {Ceriani S, 2009, AUTON ROBOT, V27, P353, DOI 10.1007/s10514-009-9156-5.
   COX IJ, 1991, IEEE T ROBOTIC AUTOM, V7, P193, DOI 10.1109/70.75902.
   Fox D, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P343.
   FUKUDA T, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1466, DOI 10.1109/IECON.1993.339287.
   Hinkel R., 1989, Robot Control 1988 (SYROCO'88) Selected Papers from the 2nd IFAC Symposium, P271.
   Jonschkowski R, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797.
   Karkus P., 2018, P C ROB LEARN, P169.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kim G, 2019, IEEE ROBOT AUTOM LET, V4, P1948, DOI 10.1109/LRA.2019.2897340.
   LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402.
   Ma X., 2019, P AAAI C ART INT APR, V34, P5101.
   Matteucci M., 2006, INT C INT ROB SYTS, V6, P93.
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4.
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1\_3.
   Qi CR, 2017, NEURIPS.
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
   Ramon-Vigo R., 2014, P WORKSH ROB CLUTT P.
   Stachniss Cyrill, 2014, Foundations and Trends in Robotics, V3, P211, DOI 10.1561/2300000013.
   Thrun S, 2002, COMMUN ACM, V45, P52.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   van Erven T, 2014, IEEE T INFORM THEORY, V60, P3797, DOI 10.1109/TIT.2014.2320500.
   Welch G., 1995, INTRO KALMAN FILTER.
   Xu S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020249.
   Yin H, 2018, IEEE INT VEH SYM, P728.
   Yin H, 2020, IEEE T INTELL TRANSP, V21, P1380, DOI 10.1109/TITS.2019.2905046.},
Number-of-Cited-References = {27},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {7},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {QY0LG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000629731200025},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000269897400004,
Author = {Nuske, Stephen and Roberts, Jonathan and Wyeth, Gordon},
Title = {Robust Outdoor Visual Localization Using a Three-Dimensional-Edge Map},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2009},
Volume = {26},
Number = {9},
Pages = {728-756},
Month = {SEP},
Abstract = {Visual localization systems that are practical for autonomous vehicles
   in outdoor industrial applications must perform reliably in a wide range
   of conditions. Changing outdoor conditions cause difficulty by
   drastically altering the information available in the camera images. To
   confront the problem, we have developed a visual localization system
   that uses a surveyed three-dimensional (3D)-edge map of permanent
   structures in the environment. The map has the invariant properties
   necessary to achieve long-term robust operation. Previous 3D-edge map
   localization systems usually maintain a single pose hypothesis, making
   it difficult to initialize without an accurate prior pose estimate and
   also making them susceptible to misalignment with unmapped edges
   detected in the camera image. A multihypothesis particle filter is
   employed here to perform the initialization procedure with significant
   uncertainty in the vehicle's initial pose. A novel observation function
   for the particle filter is developed and evaluated against two existing
   functions. The new function is shown to further improve the abilities of
   the particle filter to converge given a very coarse estimate of the
   vehicle's initial pose. An intelligent exposure control algorithm is
   also developed that improves the quality of the pertinent information in
   the image. Results gathered over an entire sunny day and also during
   rainy weather illustrate that the localization system can operate in a
   wide range of outdoor conditions. The conclusion is that an invariant
   map, a robust multihypothesis localization algorithm, and an intelligent
   exposure control algorithm all combine to enable reliable visual
   localization through challenging outdoor conditions. (C) 2009 Wiley
   Periodicals, Inc.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Nuske, S (Corresponding Author), Univ Queensland, Sch Informat Technol \& Elect Engn, St Lucia, Qld 4072, Australia.
   Nuske, Stephen; Wyeth, Gordon, Univ Queensland, Sch Informat Technol \& Elect Engn, St Lucia, Qld 4072, Australia.
   Nuske, Stephen; Roberts, Jonathan, CSIRO ICT Ctr, Autonomous Syst Lab, Kenmore, Qld 4069, Australia.},
DOI = {10.1002/rob.20306},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords-Plus = {ODOMETRY; VEHICLE; VISION; SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {nuske@cmu.edu
   jonathan.roberts@csiro.au},
Affiliations = {University of Queensland; Commonwealth Scientific \& Industrial Research
   Organisation (CSIRO)},
ResearcherID-Numbers = {Roberts, Jonathan/B-7485-2011
   Wyeth, Gordon/B-7902-2010
   },
ORCID-Numbers = {Wyeth, Gordon/0000-0002-4996-3612},
Funding-Acknowledgement = {CSIRO ICT Centre; School of Information Technology and Electrical
   Engineering at the University of Queensland},
Funding-Text = {This work was a part of Stephen Nuske's Ph.D. research that was funded
   equally by the CSIRO ICT Centre and the School of Information Technology
   and Electrical Engineering at the University of Queensland. The material
   resources required for this work were provided by CSIRO's Light Metals
   Flagship Autonomous Hot Metal Carrier Project. The authors gratefully
   acknowledge the following members of the CSIRO ICT Centre's Autonomous
   Systems Lab team for their assistance with the setup, calibration, and
   experimental work conducted during this project: Cedric Pradalier,
   Ashley Tews, Peter Hansen, Paul Hick, Polly Alexander, Felix Duvallet,
   and Felix Ruess.},
Cited-References = {{*}1394 TRAD ASS, 2000, IIDC 1394 BAS DIG CA.
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620.
   Fox D, 2003, INT J ROBOT RES, V22, P985, DOI 10.1177/0278364903022012001.
   Georgiev A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P472, DOI 10.1109/IRDS.2002.1041435.
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135.
   KLEIN G, 2006, FULL 3D EDGE TRACKIN.
   KOSAKA A, 1992, P INT C INT ROB SYST.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184.
   Marks TK, 2008, IEEE INT CONF ROBOT, P3717, DOI 10.1109/ROBOT.2008.4543781.
   MICHEL R, 2007, IEEE RSJ INT C INT R, P463.
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188.
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103.
   NUSKE S, 2008, P IEEE INT C ROB AUT.
   Nuske S, 2006, IEEE INT CONF ROBOT, P162, DOI 10.1109/ROBOT.2006.1641178.
   {*}NVIDIA CORP, 2007, NVIDIA OPENGL EXT SP.
   Paz LM, 2008, IEEE T ROBOT, V24, P946, DOI 10.1109/TRO.2008.2004637.
   Pradalier C, 2008, J FIELD ROBOT, V25, P243, DOI 10.1002/rob.20240.
   Reitmayr G., 2006, INT S MIX AUGM REAL, P109, DOI DOI 10.1109/ISMAR.2006.297801.
   ROBERTS J, 2008, P 6 IARP IEEE RAS EU.
   Roberts J, 2007, IEEE INT CONF ROBOT, P2770, DOI 10.1109/ROBOT.2007.363888.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   SHIMIZU S, 1992, IEEE T CONSUM ELECTR, V38, P617, DOI 10.1109/30.156745.
   SIM R, 2003, INT JOINT C ART INT.
   Tews A, 2007, IEEE INT CONF ROBOT, P1176, DOI 10.1109/ROBOT.2007.363144.
   Thrun S., 2005, PROBABALISTIC ROBOTI.
   VALGREN C, 2008, IEEE INT C ROB AUT P.
   Valgren C., 2007, EUR C MOB ROB FREIB.
   YANG M, 2006, IEEE INT C COMP VIS.
   Ying XG, 2004, LECT NOTES COMPUT SC, V3021, P442.},
Number-of-Cited-References = {33},
Times-Cited = {20},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {495MO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000269897400004},
DA = {2022-05-17},
}

@inproceedings{ WOS:000755125506053,
Author = {Wen, Bowen and Bekris, Kostas},
Book-Group-Author = {IEEE},
Title = {BundleTrack: 6D Pose Tracking for Novel Objects without Instance or
   Category-Level 3D Models},
Booktitle = {2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2021},
Pages = {8067-8074},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, SEP 27-OCT 01, 2021},
Abstract = {Tracking the 6D pose of objects in video sequences is important for
   robot manipulation. Most prior efforts, however, often assume that the
   target object's CAD model, at least at a category-level, is available
   for offline training or during online template matching. This work
   proposes BundleTrack, a general framework for 6D pose tracking of novel
   objects, which does not depend upon 3D models, either at the instance or
   category-level. It leverages the complementary attributes of recent
   advances in deep learning for segmentation and robust feature
   extraction, as well as memory-augmented pose graph optimization for
   spatiotemporal consistency. This enables long-term, low-drift tracking
   under various challenging scenarios, including significant occlusions
   and object motions. Comprehensive experiments given two public
   benchmarks demonstrate that the proposed approach significantly
   outperforms state-of-art, category-level 6D tracking or dynamic SLAM
   methods. When compared against state-of-art methods that rely on an
   object instance CAD model, comparable performance is achieved, despite
   the proposed method's reduced information requirements. An efficient
   implementation in CUDA provides a real-time performance of 10Hz for the
   entire framework. Code is available at:
   https://github.com/wenbowen123/BundleTrack},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wen, BW (Corresponding Author), Rutgers, Comp Sci Dept, New Brunswick, NJ 08901 USA.
   Wen, Bowen; Bekris, Kostas, Rutgers, Comp Sci Dept, New Brunswick, NJ 08901 USA.},
DOI = {10.1109/IROS51168.2021.9635991},
ISSN = {2153-0858},
ISBN = {978-1-6654-1714-3},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {bw344@cs.rutgers.edu
   kostas.bekris@cs.rutgers.edu},
Affiliations = {Rutgers State University New Brunswick},
ResearcherID-Numbers = {Wen, Bowen/ACD-9179-2022},
ORCID-Numbers = {Wen, Bowen/0000-0002-9207-6103},
Funding-Acknowledgement = {NSF NRI award {[}1734492]},
Funding-Text = {This work is supported by NSF NRI award 1734492. The results do not
   express the sponspor's positions.},
Cited-References = {ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965.
   Ba LJ, 2015, 2015 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices (ASEMD), P3, DOI 10.1109/ASEMD.2015.7453438.
   Bourbaki N., 2008, LIE GROUPS LIE ALGEB.
   Calli B, 2015, IEEE ROBOT AUTOM MAG, V22, P36, DOI 10.1109/MRA.2015.2448951.
   Chang A X, 2015, COMPUTER SCI, V1512, P3.
   Chen DL, 2020, DISS MATH, P6.
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184.
   Chen X., 2020, ARXIV200808145.
   Choi C, 2013, IEEE INT C INT ROBOT, P1568, DOI 10.1109/IROS.2013.6696558.
   Cignoni P, 2008, COMPUTING.
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261.
   Danielczuk M., 2019, ICRA.
   Deng X., 2019, RSS.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Fua Pascal, 2018, ADV NEURAL INFORM PR, V31, P6234.
   He K., 2017, P 2017 IEEE INT C CO, DOI 10.1109/TPAMI.2018.2844175.
   He Y., 2020, P IEEE COMP VIS PATT, P11632.
   Hildebrand F.B., 1987, INTRO NUMERICAL ANAL.
   Issac J., 2016, ICRA.
   Kappler D., 2018, IEEE RAL.
   Krainin M., 2010, ICRA.
   Le T. H. N., 2018, PATTERN RECOGNITION.
   Li ZZ, 2019, PROC INT CONF ANTI, P6, DOI 10.1109/ICASID.2019.8924991.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Ma L., 2015, ICRA.
   Meyer F., 1992, INT C IM PROC ITS AP.
   Mitash C., 2020, CORL.
   Mitash C., 2020, IEEE RAL.
   Morgan A. S., 2021, RSS, P2021.
   Murali A, 2020, IEEE INT CONF ROBOT, P6232, DOI 10.1109/ICRA40945.2020.9197318.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   PAPON J, 2013, COMP VIS PATT REC CV, P2027, DOI DOI 10.1109/CVPR.2013.264.
   Park K., 2019, CVPR.
   Park K., 2020, CVPR.
   Pereira, 2001, INT C MACH LEARN WIL, DOI DOI 10.5555/645530.655813.
   Pont-Tuset J, 2017, ARXIV170400675 CORR.
   Ren Y., 2013, CVPR.
   Runz Martin, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4471, DOI 10.1109/ICRA.2017.7989518.
   Runz M., 2018, ISMAR.
   Schmidt T., 2014, RSS.
   Slavcheva M., 2016, ECCV.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Strecke M., 2019, CVPR.
   Suwajanakorn Supasorn, 2018, ARXIV180703146.
   Tan D. J., 2015, ICCV.
   ten Pas A., 2017, IJRR.
   Tjaden H., 2018, TPAMI.
   Tremblay J., 2018, ARXIV PREPRINT ARXIV.
   Tzionas D, 2015, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2015.90.
   Vassilevska V., 2006, INT C AUT LANG PROGR.
   WANG C, 2019, CVPR, P3338, DOI DOI 10.1109/CVPR.2019.00346.
   Wang C., 2020, ICRA.
   Wang F., 2019, ICRA.
   WANG H, 2019, CVPR, P2637, DOI DOI 10.1109/CVPR.2019.00275.
   Weise T., 2011, COMPUTER VISION IMAG.
   Weise W, 2008, PROG THEOR PHYS SUPP, P1, DOI 10.1143/PTPS.174.1.
   Wen B., 2020, IROS.
   Wen BW, 2020, IEEE INT CONF ROBOT, P6210, DOI 10.1109/ICRA40945.2020.9197350.
   Wuthrich M., 2013, IROS.
   Xiang Y., 2018, ARXIV171100199, DOI {[}10.15607/RSS.2018.XIV.019, DOI 10.15607/RSS.2018.XIV.019].
   Xiang Y., 2020, CORL.
   Xu B., 2019, ICRA.
   Xu N., 2018, ARXIV180903327.
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695.
   Zhang YH, 2020, PROC CVPR IEEE, P250, DOI 10.1109/CVPR42600.2020.00033.
   Zhong L., 2019, IJCV.
   Zhou Q.-Y., 2018, ARXIV180109847.
   Zollofer Michael, 2017, ACM T GRAPHIC, DOI DOI 10.1145/3054739.},
Number-of-Cited-References = {68},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS6ZK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000755125506053},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000438724400011,
Author = {Chebrolu, Nived and Laebe, Thomas and Stachniss, Cyrill},
Title = {Robust Long-Term Registration of UAV Images of Crop Fields for Precision
   Agriculture},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {3090-3097},
Month = {OCT},
Abstract = {Continuous crop monitoring is an important aspect of precision
   agriculture and requires the registration of sensor data over longer
   periods of time. Often, fields are monitored using cameras mounted on
   unmanned aerial vehicles (UAVs) but strong changes in the visual
   appearance of the growing crops and the field itself poses serious
   challenges to conventional image registration methods. In this letter,
   we present a method for registering images of agricultural fields taken
   by an UAV over the crop season and present a complete pipeline for
   computing temporally aligned three-dimensional (3-D) point clouds of the
   field. Our approach exploits the inherent geometry of the crop
   arrangement in the field, which remains mostly static over time. This
   allows us to register the images even in the presence of strong visual
   changes. To this end, we propose a scale invariant, geometric feature
   descriptor that encodes the local plant arrangement geometry. The
   experiments suggest that we are able to register images taken over the
   crop season, including situations where matching with an off-the-shelf
   visual descriptor fails. We evaluate the accuracy of our matching system
   with respect to manually labeled ground truth. We furthermore illustrate
   that the reconstructed 3-D models are qualitatively correct and the
   registration results allow for monitoring growth parameters at a per
   plant level.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Chebrolu, N (Corresponding Author), Univ Bonn, Inst Geodesy \& Geoinformat, D-53113 Bonn, Germany.
   Chebrolu, Nived; Laebe, Thomas; Stachniss, Cyrill, Univ Bonn, Inst Geodesy \& Geoinformat, D-53113 Bonn, Germany.},
DOI = {10.1109/LRA.2018.2849603},
ISSN = {2377-3766},
Keywords = {Robotics in agriculture and forestry; SLAM},
Keywords-Plus = {ALGORITHMS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {nived.chebrolu@igg.uni-bonn.de
   laebe@ipb.uni-bonn.de
   cyrill.stachniss@igg.uni-bonn.de},
Affiliations = {University of Bonn},
ORCID-Numbers = {Stachniss, Cyrill/0000-0003-1173-6972
   Laebe, Thomas/0000-0003-4873-513X},
Funding-Acknowledgement = {EC {[}H2020-ICT-644227-Flourish]},
Funding-Text = {This work was supported by the EC under Grant H2020-ICT-644227-Flourish.},
Cited-References = {Agarwal S, 2011, COMMUN ACM, V54, P105, DOI 10.1145/2001269.2001293.
   Bryson M, 2010, J FIELD ROBOT, V27, P632, DOI 10.1002/rob.20343.
   Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7.
   Das J, 2015, IEEE INT CON AUTO SC, P462, DOI 10.1109/CoASE.2015.7294123.
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161.
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1.
   Jing Dong, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3878, DOI 10.1109/ICRA.2017.7989447.
   Kusumam K, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P646, DOI 10.1109/IROS.2016.7759121.
   Labe T., 2006, P TURK GERM JOINT GE.
   Li YY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508368.
   Lottes Philipp, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3024, DOI 10.1109/ICRA.2017.7989347.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003.
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076.
   Pfeifer J., 2016, P INT C AGR ENG.
   Vysotska O, 2016, IEEE ROBOT AUTOM LET, V1, P213, DOI 10.1109/LRA.2015.2512936.
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604.
   Yang LM, 2015, IEEE T VIS COMPUT GR, V21, P1299, DOI 10.1109/TVCG.2015.2459897.},
Number-of-Cited-References = {20},
Times-Cited = {27},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GN1DE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000438724400011},
DA = {2022-05-17},
}

@inproceedings{ WOS:000482554002096,
Author = {Wang, Chengze and Yuan, Yuan and Wang, Qi},
Book-Group-Author = {IEEE},
Title = {LEARNING BY INERTIA: SELF-SUPERVISED MONOCULAR VISUAL ODOMETRY FOR ROAD
   VEHICLES},
DOI = {10.1109/ICASSP.2019.8683446},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL
   PROCESSING (ICASSP)},
Series = {International Conference on Acoustics Speech and Signal Processing
   ICASSP},
Year = {2019},
Pages = {2252-2256},
Note = {44th IEEE International Conference on Acoustics, Speech and Signal
   Processing (ICASSP), Brighton, ENGLAND, MAY 12-17, 2019},
Abstract = {In this paper, we present iDVO (inertia-embedded deep visual odometry),
   a self-supervised learning based monocular visual odometry (VO) for road
   vehicles. When modelling the geometric consistency within adjacent
   frames, most deep VO methods ignore the temporal continuity of the
   camera pose, which results in a very severe jagged fluctuation in the
   velocity curves. With the observation Mat road vehicles tend to perform
   smooth dynamic characteristics in most of the time, we design the
   inertia loss function to describe the abnormal motion variation, which
   assists the model to learn the consecutiveness from long-term camera
   ego-motion. Based on the recurrent convolutional neural network (RCNN)
   architecture, our method implicitly models the dynamics of road vehicles
   and the temporal consecutiveness by the extended Long., Short-Term
   Memory (LSTM) block. Furthermore, we develop the dynamic hard-edge mask
   to handle the non consistency in fast camera motion by blocking the
   boundary part and which generates more efficiency in the whole non
   consistency mask. The proposed method is evaluated on the KITTI dataset,
   and the results demonstrate state-of-the-art performance with respect to
   other monocular deep VO and SLAM approaches.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yuan, Y (Corresponding Author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   Yuan, Yuan, Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   Northwestern Polytech Univ, Ctr OPT IMagery Anal \& Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.},
ISSN = {1520-6149},
ISBN = {978-1-4799-8131-1},
Keywords = {Inertia; Self-supervised Learning; Visual Odometry; RCNN},
Research-Areas = {Acoustics; Engineering},
Web-of-Science-Categories  = {Acoustics; Engineering, Electrical \& Electronic},
Affiliations = {Northwestern Polytechnical University; Northwestern Polytechnical
   University},
ResearcherID-Numbers = {Yuan, Yuan/ABB-2379-2020},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}U1864204, 61773316];
   State Key Program of National Natural Science Foundation of China
   {[}61632018]; Natural Science Foundation of Shaanxi Province
   {[}2018KJXX-024]; Projects of Special Zone for National Defense Science
   and Technology Innovation; Fundamental Research Funds for the Central
   Universities {[}3102017AX010]; Open Research Fund of Key Laboratory of
   Spectral Imaging Technology, Chinese Academy of Sciences},
Funding-Text = {This work was supported by the National Natural Science Foundation of
   China under Grant U1864204 and 61773316, State Key Program of National
   Natural Science Foundation of China under Grant 61632018, Natural
   Science Foundation of Shaanxi Province under Grant 2018KJXX-024,
   Projects of Special Zone for National Defense Science and Technology
   Innovation, Fundamental Research Funds for the Central Universities
   under Grant 3102017AX010, and Open Research Fund of Key Laboratory of
   Spectral Imaging Technology, Chinese Academy of Sciences.},
Cited-References = {Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Eboli L, 2016, TRANSPORT RES C-EMER, V68, P113, DOI 10.1016/j.trc.2016.04.002.
   Eigen D., 2014, ADV NEURAL INFORM PR.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Geiger A., 2012, C COMP VIS PATT REC.
   Godard Clement, 2017, CVPR, V2, P7.
   Jaderberg M., 2015, ADV NEURAL INFORM PR, P2017.
   Kuderer M, 2015, IEEE INT CONF ROBOT, P2641, DOI 10.1109/ICRA.2015.7139555.
   Li R., 2017, ARXIV170906841.
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283.
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594.
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438.
   Mehar A., 2013, EUR TRANSP, V55, P1825.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   SZELISKI R, 1999, IEEE INT C COMP VIS, V2, P781.
   Ummenhofer B., 2017, IEEE C COMP VIS PATT, V5.
   Vijayanarasimhan S., 2017, ARXIV170407804.
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861.
   Zhou T., 2017, CVPR, V2, P7.},
Number-of-Cited-References = {21},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BN4NP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000482554002096},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000403027600002,
Author = {Latif, Yasir and Huang, Guoquan and Leonard, John and Neira, Jose},
Title = {Sparse optimization for robust and efficient loop closing},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2017},
Volume = {93},
Pages = {13-26},
Month = {JUL},
Abstract = {It is essential for a robot to be able to detect revisits or loop
   closures for long-term visual navigation. A key insight explored in this
   work is that the loop-closing event inherently occurs sparsely, i.e.,
   the image currently being taken matches with only a small subset (if
   any) of previous images. Based on this observation, we formulate the
   problem of loop-closure detection as a sparse, convex l(1)-minimization
   problem. By leveraging fast convex optimization techniques, we are able
   to efficiently find loop closures, thus enabling real-time robot
   navigation. This novel formulation requires no offline dictionary
   learning, as required by most existing approaches, and thus allows
   online incremental operation. Our approach ensures a unique hypothesis
   by choosing only a single globally optimal match when making a
   loop-closure decision. Furthermore, the proposed formulation enjoys a
   flexible representation with no restriction imposed on how images should
   be represented, while requiring only that the representations are
   ``close{''} to each other when the corresponding images are visually
   similar. The proposed algorithm is validated extensively using
   real-world datasets. (C) 2017 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Latif, Y (Corresponding Author), Univ Adelaide, ARC Ctr Robot Vis, Adelaide, SA 5005, Australia.
   Latif, Yasir, Univ Adelaide, ARC Ctr Robot Vis, Adelaide, SA 5005, Australia.
   Huang, Guoquan, Univ Delaware, Dept Mech Engn, Newark, DE 19716 USA.
   Leonard, John, MIT, Comp Sci \& Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Neira, Jose, Univ Zaragoza, I3A, Zaragoza, Spain.},
DOI = {10.1016/j.robot.2017.03.016},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {SLAM; Place recognition; Relocalization; Sparse optimization},
Keywords-Plus = {PLACE RECOGNITION; VISION; NAVIGATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {yasir.latif@adelaide.edu.au},
Affiliations = {University of Adelaide; University of Delaware; Massachusetts Institute
   of Technology (MIT); University of Zaragoza},
ResearcherID-Numbers = {Neira, Jose/AAM-6571-2020
   Huang, Guoquan/AAF-2094-2019
   Neira Parra, Jose/F-8887-2013},
ORCID-Numbers = {Huang, Guoquan/0000-0001-9932-0685
   /0000-0002-8863-6550
   Neira Parra, Jose/0000-0003-0668-977X},
Funding-Acknowledgement = {MINECO-FEDER {[}DPI2015-68905-P]; ONR {[}N0001410-1-0936,
   N00014-11-1-0688, N00014-13-1-0588]; NSF {[}IIS-1318392, IIS-1566129];
   DTRA {[}HDTRA 1-16-1-0039];  {[}BES-2010-033116];  {[}EEBB-I-13-07010];
   Direct For Computer \& Info Scie \& Enginr {[}1566129] Funding Source:
   National Science Foundation},
Funding-Text = {This work was partially supported by the MINECO-FEDER project
   DPI2015-68905-P, by the research grant BES-2010-033116, by the travel
   grant EEBB-I-13-07010, by the ONR grants N0001410-1-0936,
   N00014-11-1-0688 and N00014-13-1-0588, by the NSF awards IIS-1318392 and
   IIS-1566129, and by the DTRA award HDTRA 1-16-1-0039.},
Cited-References = {Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1.
   Asif M., 2008, PRIMAL DUAL PURSUIT.
   Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19.
   Bengio Y, 2012, UNSUPERVISED TRANSF, V7, P19.
   Boyd S., 2004, CONVEX OPTIMIZATION.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Cannell CJ, 2005, OCEANS-IEEE, P1514.
   Capezio Francesco, 2009, Journal of Computing and Information Technology - CIT, V17, P95, DOI 10.2498/cit.1001180.
   Casafranca JJ, 2013, IEEE INT C INT ROBOT, P17, DOI 10.1109/IROS.2013.6696326.
   Casafranca J.J., 2013, ROB MULT INF FACT GR.
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dalal N., 2005, 2005 IEEE COMPUTER S, P886, DOI {[}10.1109/CVPR.2005.177, DOI 10.1109/CVPR.2005.177].
   Donoho D., 2006, TECHNICAL REPORT.
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132.
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582.
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969.
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655.
   Everingham M, 2012, PASCAL VISUAL OBJECT.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Kumar B., 2016, IEEE C COMP VIS PATT.
   Latif Y., 2014, P ROB SCI SYST BERK.
   Latif Y, 2014, IEEE INT C INT ROBOT, P2683, DOI 10.1109/IROS.2014.6942929.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   LeCun Y., 1995, HDB BRAIN THEORY NEU.
   Lee JH, 2014, IEEE INT CONF ROBOT, P5550, DOI 10.1109/ICRA.2014.6907675.
   Lee JH, 2013, IEEE INT CONF ROBOT, P3799, DOI 10.1109/ICRA.2013.6631111.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Malioutov D.M., 2005, IEEE INT C AC SPEECH.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Paul R, 2013, INT J ROBOT RES, V32, P1742, DOI 10.1177/0278364913509859.
   RAWSEEDS, 2009, FP6IST045144 RAWSEED.
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508.
   Sfinderhauf N., 2015, P IEEE RJS INT C INT.
   Shakeri M., 2015, ONLINE LOOP CLOSURE.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Stinderhauf N., 2015, VISUAL PLACE RECOGNI.
   Sugiyama H., 2005, INT C COLL COMP NETW.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Zhang H, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII.},
Number-of-Cited-References = {46},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {21},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {EX2AJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000403027600002},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000521864000001,
Author = {Karaoguz, Hakan and Bozma, H. Isil},
Title = {Merging of appearance-based place knowledge among multiple robots},
Journal = {AUTONOMOUS ROBOTS},
Year = {2020},
Volume = {44},
Number = {6},
Pages = {1009-1027},
Month = {JUL},
Abstract = {If robots can merge the appearance-based place knowledge of other robots
   with their own, they can relate to these places even if they have not
   previously visited them. We have investigated this problem using robots
   with compatible visual sensing capabilities and with each robot having
   its individual long-term place memory. Here, each place refers to a
   spatial region as defined by a collection of appearances and in the
   place memory, the knowledge is organized in a tree hierarchy. In the
   proposed merging approach, the hierarchical organization plays a key
   role-as it corresponds to a nested sequence of hyperspheres in the
   appearance space. The merging proceeds by considering the extent of
   overlap of the respective nested hyperspheres-starting with the largest
   covering hypersphere. Thus, differing from related work, knowledge is
   merged in as large chunks as possible while the hierarchical structure
   is preserved accordingly. As such, the merging scales better as the
   extent of knowledge to be merged increases. This is demonstrated in an
   extensive set of multirobot experiments where robots share their
   knowledge and then use their merged knowledge when visiting these
   places.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Karaoguz, H (Corresponding Author), Kungliga Tekn Hgsk Stockholm, Stockholm, Sweden.
   Karaoguz, Hakan, Kungliga Tekn Hgsk Stockholm, Stockholm, Sweden.
   Bozma, H. Isil, Bogazici Univ, Fac Elect \& Elect Engn, Istanbul, Turkey.},
DOI = {10.1007/s10514-020-09911-2},
EarlyAccessDate = {MAR 2020},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Place recognition; Multi-robot; Unsupervised learning},
Keywords-Plus = {LARGE-SCALE; SLAM; MAPS},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {hkarao@kth.se},
Affiliations = {Royal Institute of Technology; Bogazici University},
Funding-Acknowledgement = {Royal Institute of Technology; TUBITAK {[}EEEAG-111E285]; Turkish State
   Planning Organization (DPT) {[}TAM 2007K120610]; BAP {[}9164]},
Funding-Text = {Open access funding provided by Royal Institute of Technology. This work
   has been supported in part by TUBITAK EEEAG-111E285, BAP 9164 and by the
   Turkish State Planning Organization (DPT) under the TAM 2007K120610.},
Cited-References = {Adluru N, 2008, INT C PATT RECOG, P382.
   Amigoni F, 2006, P IEEE, V94, P1340, DOI 10.1109/JPROC.2006.876925.
   Aragues R, 2012, IEEE T ROBOT, V28, P840, DOI 10.1109/TRO.2012.2192012.
   Beeson P, 2010, INT J ROBOT RES, V29, P428, DOI 10.1177/0278364909100586.
   Birk A, 2006, P IEEE, V94, P1384, DOI 10.1109/JPROC.2006.876965.
   Carpin S, 2005, ROBOT AUTON SYST, V53, P1, DOI 10.1016/j.robot.2005.07.001.
   Carpin S, 2008, AUTON ROBOT, V25, P305, DOI 10.1007/s10514-008-9097-4.
   Chella A, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P747.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Erinc G, 2014, AUTON ROBOT, V36, P241, DOI 10.1007/s10514-013-9352-1.
   Erkent O, 2017, ADV ROBOTICS, V31, P865, DOI 10.1080/01691864.2017.1356746.
   Erkent O, 2013, INT J ROBOT RES, V32, P672, DOI 10.1177/0278364913481393.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Ferreira F., 2008, ICLAWAR, P1.
   Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511.
   Garcia-Fidalgo E, 2017, IEEE T ROBOT, V33, P1061, DOI 10.1109/TRO.2017.2704598.
   Gil A, 2010, ROBOT AUTON SYST, V58, P68, DOI 10.1016/j.robot.2009.07.026.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Ho K., 2005, IEEE RSJ INT C INT R.
   Howard A, 2004, IEEE INT CONF ROBOT, P4198, DOI 10.1109/ROBOT.2004.1308933.
   Huang WH, 2005, INT J ROBOT RES, V24, P601, DOI 10.1177/0278364905056348.
   Karaoguz H, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5107, DOI 10.1109/IROS.2016.7759749.
   Karaoguz H, 2016, AUTON ROBOT, V40, P1379, DOI 10.1007/s10514-015-9514-4.
   Karaoguz H, 2014, IEEE INT CONF ROBOT, P697, DOI 10.1109/ICRA.2014.6906930.
   Ko J., 2003, IEEE RSJ INT C INT R, V4.
   Konolige K, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P212.
   Kostavelis I, 2015, ROBOT AUTON SYST, V66, P86, DOI 10.1016/j.robot.2014.12.006.
   Lee HC, 2011, ADV ROBOTICS, V25, P1675, DOI 10.1163/016918611X584631.
   Leung KYK, 2011, IEEE INT CONF ROBOT.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Ma X., 2008, WORLD C INT CONTR AU, P5704.
   Marjovi A, 2012, ROBOT AUTON SYST, V60, P1191, DOI 10.1016/j.robot.2012.05.007.
   Matlin M.W, 2005, COGNITION.
   Nieto-Granda C, 2014, INT J ROBOT RES, V33, P519, DOI 10.1177/0278364913515309.
   Ozkucur NE, 2009, LECT NOTES COMPUT SC, V5399, P189, DOI 10.1007/978-3-642-02921-9\_17.
   Park S, 2016, IEEE T ROBOT, V32, P528, DOI 10.1109/TRO.2016.2544301.
   Parker L. E, 2008, J PHYS AGENTS, V2, P5, DOI {[}DOI 10.14198/JOPHA.2008.2.1.02, 10.14198/jopha.2008.2.1.02].
   Pronobis A, 2009, INT J ROBOT RES, V28, P588, DOI 10.1177/0278364909103912.
   Ranganathan A., 2010, P ROB SCI SYST.
   Saeedi S, 2014, ROBOT AUTON SYST, V62, P1408, DOI 10.1016/j.robot.2014.06.002.
   Samatova NF, 2002, DISTRIB PARALLEL DAT, V11, P157.
   Thrun S., 2000, IEEE INT C ROB AUT, V1.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Tomono M, 2013, IEEE INT C INT ROBOT, P5172, DOI 10.1109/IROS.2013.6697104.
   Tungadi F, 2010, IEEE INT C INT ROBOT, P7, DOI 10.1109/IROS.2010.5654446.
   Williams SB, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2743, DOI 10.1109/ROBOT.2002.1013647.
   Zhou XS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1785, DOI 10.1109/IROS.2006.282219.},
Number-of-Cited-References = {47},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {MI1DC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000521864000001},
OA = {hybrid},
DA = {2022-05-17},
}

@inproceedings{ WOS:000589413000013,
Author = {Tian, Qi and Gao, YunFeng and Li, GuoLin and Song, JiaXin},
Book-Group-Author = {IEEE},
Title = {A Novel Global Relocalization Method Based on Hierarchical Registration
   of 3D Point Cloud Map for Mobile Robot},
DOI = {10.1109/ICCAR.2019.8813720},
Booktitle = {CONFERENCE PROCEEDINGS OF 2019 5TH INTERNATIONAL CONFERENCE ON CONTROL,
   AUTOMATION AND ROBOTICS (ICCAR)},
Year = {2019},
Pages = {68-73},
Note = {5th International Conference on Control, Automation and Robotics
   (ICCAR), Beijing, PEOPLES R CHINA, APR 19-22, 2019},
Abstract = {Indoor service mobile robots need to relocate when they are kidnapped,
   powered off, or lost in long-term work, thus unable to perform daily
   tasks. Solving this problem is challenging, especially for 3D maps due
   to the computational complexity. In order to solve this issue, a novel
   relocalization algorithm based on hierarchical registration is proposed
   for a known 3D map in this paper. For 3D point cloud maps, the algorithm
   obtains multi-layer information in the vertical direction through
   hierarchical registration at the robot's current position. To obtain the
   best 3D pose for relocalization, we fuse the poses calculated by the
   multi-layered point cloud into one and use it as the initial pose of the
   iterative closest point algorithm. The hierarchical registration based
   algorithm solves the problem of unknown initial value for registration
   between two large point clouds, improves the recall rate, and ensures
   the accuracy of algorithm at the same time. The related relocalization
   experiments are carried out in the indoor environment and the results
   verify the effectiveness and robustness of the algorithm.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Tian, Q (Corresponding Author), Harbin Inst Technol, State Key Lab Robot \& Syst, Harbin 150001, Peoples R China.
   Tian, Qi; Gao, YunFeng; Li, GuoLin; Song, JiaXin, Harbin Inst Technol, State Key Lab Robot \& Syst, Harbin 150001, Peoples R China.},
ISBN = {978-1-7281-3326-3},
Keywords = {visual SLAM; relocalization; mobile robot; point cloud registration},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {tianqihit@hotmail.com
   gyf@hit.edu.cn
   liguolin426@hotmail.com
   songjiaxina@gmail.com},
Affiliations = {Harbin Institute of Technology},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018YFB1307103]},
Funding-Text = {This work is supported in part by the National Key R\&D Program of China
   (No. 2018YFB1307103).},
Cited-References = {Bhatnagar V, 2002, IEEE INT C AC SPEECH, V5, P2717.
   Caruso D, 2015, IEEE INT C INT ROBOT, P141, DOI 10.1109/IROS.2015.7353366.
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199.
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Kendall A., 2016, ED INF, V11-18, P2938.
   Mur-Artal R., 2014, WORKSH MULT GEOM ROB.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377.
   Suarez J P, 2010, INT J NUMERICAL METH, V17, P903.
   Wu J, 2017, IEEE INT C ROB AUT.
   Ye Q, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P2109, DOI 10.1109/FSKD.2016.7603507.
   Zhang X, 2014, LASER OPTOELECTRONIC, V51.},
Number-of-Cited-References = {13},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BQ4FR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000589413000013},
DA = {2022-05-17},
}

@article{ WOS:000730066500001,
Author = {Tang, Li and Wang, Yue and Tan, Qimeng and Xiong, Rong},
Title = {Explicit feature disentanglement for visual place recognition across
   appearance changes},
Journal = {INTERNATIONAL JOURNAL OF ADVANCED ROBOTIC SYSTEMS},
Year = {2021},
Volume = {18},
Number = {6},
Month = {NOV},
Abstract = {In the long-term deployment of mobile robots, changing appearance brings
   challenges for localization. When a robot travels to the same place or
   restarts from an existing map, global localization is needed, where
   place recognition provides coarse position information. For visual
   sensors, changing appearances such as the transition from day to night
   and seasonal variation can reduce the performance of a visual place
   recognition system. To address this problem, we propose to learn
   domain-unrelated features across extreme changing appearance, where a
   domain denotes a specific appearance condition, such as a season or a
   kind of weather. We use an adversarial network with two discriminators
   to disentangle domain-related features and domain-unrelated features
   from images, and the domain-unrelated features are used as descriptors
   in place recognition. Provided images from different domains, our
   network is trained in a self-supervised manner which does not require
   correspondences between these domains. Besides, our feature extractors
   are shared among all domains, making it possible to contain more
   appearance without increasing model complexity. Qualitative and
   quantitative results on two toy cases are presented to show that our
   network can disentangle domain-related and domain-unrelated features
   from given data. Experiments on three public datasets and one proposed
   dataset for visual place recognition are conducted to illustrate the
   performance of our method compared with several typical algorithms.
   Besides, an ablation study is designed to validate the effectiveness of
   the introduced discriminators in our network. Additionally, we use a
   four-domain dataset to verify that the network can extend to multiple
   domains with one model while achieving similar performance.},
Publisher = {SAGE PUBLICATIONS INC},
Address = {2455 TELLER RD, THOUSAND OAKS, CA 91320 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, Dept Control Sci \& Engn, Hangzhou 30012, Peoples R China.
   Tang, Li; Wang, Yue; Xiong, Rong, Zhejiang Univ, Dept Control Sci \& Engn, Hangzhou 30012, Peoples R China.
   Tan, Qimeng, Beijing Inst Spacecraft Syst Engn, Beijing Key Lab Intelligent Space Robot Syst Tech, Beijing, Peoples R China.},
DOI = {10.1177/17298814211037497},
Article-Number = {17298814211037497},
ISSN = {1729-8814},
Keywords = {Place recognition; feature disentanglement; adversarial;
   self-supervised; changing appearance},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; NAVIGATION; SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {ywang24@zju.edu.cn},
Affiliations = {Zhejiang University},
Funding-Acknowledgement = {National Nature Science Foundation of China {[}61903332]; Natural
   Science Foundation of Zhejiang Province {[}LGG21F030012]},
Funding-Text = {The author(s) disclosed the receipt of the following financial support
   for the research, authorship, and/or publication of this article: This
   work was supported in part by the National Nature Science Foundation of
   China under Grant 61903332, and in part by the Natural Science
   Foundation of Zhejiang Province under grant number LGG21F030012.},
Cited-References = {Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387.
   Ba J.L., 2016, ARXIV160706450.
   Bresson G, 2017, IEEE T INTELL VEHICL, V2, P194, DOI 10.1109/TIV.2017.2749181.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Chen ZT, 2018, IEEE ROBOT AUTOM LET, V3, P4015, DOI 10.1109/LRA.2018.2859916.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Clement L, 2018, IEEE ROBOT AUTOM LET, V3, P2447, DOI 10.1109/LRA.2018.2799741.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Doan AD, 2019, IEEE I CONF COMP VIS, P9318, DOI 10.1109/ICCV.2019.00941.
   Facil JM, 2019, ARXIV190209516.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2.
   Garg S., 2019, INT J ROBOT RES, DOI {[}10.1177/0278364919839761, DOI 10.1177/0278364919839761].
   Garg S, 2020, IEEE INT CONF ROBOT, P3341, DOI 10.1109/ICRA40945.2020.9196827.
   Gomezojeda Ruben, 2015, COMPUTER SCI.
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672.
   Hausler S, 2020, IEEE INT CONF ROBOT, P3327, DOI 10.1109/ICRA40945.2020.9197360.
   Hausler S, 2019, IEEE INT C INT ROBOT, P3268, DOI 10.1109/IROS40897.2019.8967783.
   Higgins I, 2018, ARXIV181202230.
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647.
   Hong ZY, 2019, IEEE I CONF COMP VIS, P2861, DOI 10.1109/ICCV.2019.00295.
   Hu HJ, 2019, IEEE INT C INT ROBOT, P3684, DOI 10.1109/IROS40897.2019.8968047.
   Huang XW, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, TECHNOLOGIES AND APPLICATIONS (ICTA 2018), P172, DOI 10.1109/CICTA.2018.8706048.
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6\_43.
   Kanji, 2019, ARXIV PREPRINT ARXIV.
   Khaliq A, 2020, IEEE T ROBOT, V36, P561, DOI 10.1109/TRO.2019.2956352.
   Kingma D. P., 2014, 3 INT C LEARN REPR, DOI DOI 10.1145/1830483.1830503.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Latif Y, 2018, IEEE INT CONF ROBOT, P2349, DOI 10.1109/ICRA.2018.8461081.
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791.
   Lee HY, 2020, INT J COMPUT VISION, V128, P2402, DOI 10.1007/s11263-019-01284-z.
   Leonard J., 2019, LEARN LOC MAPP WOKSH.
   Li FY, 2006, IEEE INT CONF ROBOT, P3405, DOI 10.1109/ROBOT.2006.1642222.
   Liu MY, 2017, ADV NEUR IN, V30.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P600, DOI 10.1109/TRO.2016.2545711.
   Maas A. L., 2013, P INT C MACH LEARN, DOI DOI 10.1016/0010-0277(84)90022-2.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Mao Xudong, 2017, P IEEE INT C COMP VI, P2794.
   McDonald-Maier, 2019, ARXIV PREPRINT ARXIV.
   Merrill N, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mukherjee A, 2017, LECT NOTES COMPUT SC, V10597, P557, DOI 10.1007/978-3-319-69900-4\_71.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murillo AC, 2013, IEEE T ROBOT, V29, P146, DOI 10.1109/TRO.2012.2220211.
   Nowicki MR, 2017, WIRELESS PERS COMMUN, V97, P213, DOI 10.1007/s11277-017-4502-y.
   Porav H, 2018, IEEE INT CONF ROBOT, P1011, DOI 10.1109/ICRA.2018.8462894.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Schindler G., 2007, 2007 IEEE C COMP VIS, P1.
   Schlegel D, 2018, IEEE ROBOT AUTOM LET, V3, P3741, DOI 10.1109/LRA.2018.2856542.
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682.
   Schubert Stefan, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P4372, DOI 10.1109/ICRA40945.2020.9197044.
   Shanmugam Akshaya, 2015, 2015 41st Annual Northeast Biomedical Engineering Conference (NEBEC). Proceedings, P1, DOI 10.1109/NEBEC.2015.7117195.
   Simonyan K, 2014, C TRACK P.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Tang L, 2020, IEEE INT CONF ROBOT, P1301, DOI 10.1109/ICRA40945.2020.9196518.
   Tang L, 2019, AUTON ROBOT, V43, P197, DOI 10.1007/s10514-018-9724-7.
   Torii A., P IEEE C COMP VIS PA, P5297.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Ulyanov D, 2017, PROC CVPR IEEE, P4105, DOI 10.1109/CVPR.2017.437.
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579.
   Xin Z, 2019, IEEE INT CONF ROBOT, P5979, DOI 10.1109/ICRA.2019.8794383.
   Yin P, 2019, IEEE INT CONF ROBOT, P7137, DOI 10.1109/ICRA.2019.8793853.
   Yin P, 2019, IEEE INT CONF ROBOT, P319, DOI 10.1109/ICRA.2019.8793752.
   Yu J, 2020, IEEE T NEUR NET LEAR, V31, P661, DOI 10.1109/TNNLS.2019.2908982.
   Zaffar M, 2021, IEEE T INTELL TRANSP, V22, P7355, DOI 10.1109/TITS.2020.3001228.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.},
Number-of-Cited-References = {73},
Times-Cited = {0},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {4},
Journal-ISO = {Int. J. Adv. Robot. Syst.},
Doc-Delivery-Number = {XO3CL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000730066500001},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000446394504135,
Author = {Stenborg, Erik and Toft, Carl and Hammarstrand, Lars},
Book-Group-Author = {IEEE},
Title = {Long-term Visual Localization using Semantically Segmented Images},
DOI = {10.1109/ICRA.2018.8463150},
Booktitle = {2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2018},
Pages = {6484-6490},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Brisbane, AUSTRALIA, MAY 21-25, 2018},
Abstract = {Robust cross-seasonal localization is one of the major challenges in
   long-term visual navigation of autonomous vehicles. In this paper, we
   exploit recent advances in semantic segmentation of images, i.e., where
   each pixel is assigned a label related to the type of object it
   represents, to attack the problem of long-term visual localization. We
   show that semantically labeled 3D point maps of the environment,
   together with semantically segmented images, can be efficiently used for
   vehicle localization without the need for detailed feature descriptors
   (SIFT, SURF, etc.). Thus, instead of depending on hand-crafted feature
   descriptors, we rely on the training of an image segmenter. The
   resulting map takes up much less storage space compared to a traditional
   descriptor based map. A particle filter based semantic localization
   solution is compared to one based on SIFT-features, and even with large
   seasonal variations over the year we perform on par with the larger and
   more descriptive SIFT-features, and are able to localize with an error
   below 1 m most of the time.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Stenborg, E (Corresponding Author), Chalmers Univ Technol, Gothenburg, Sweden.
   Stenborg, E (Corresponding Author), Zenuity, Gothenburg, Sweden.
   Stenborg, Erik; Toft, Carl; Hammarstrand, Lars, Chalmers Univ Technol, Gothenburg, Sweden.
   Stenborg, Erik, Zenuity, Gothenburg, Sweden.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-5386-3081-5},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Affiliations = {Chalmers University of Technology; Zenuity},
Cited-References = {Aanaes H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8.
   Badino H, 2011, IEEE INT CONF ROBOT.
   Badino H., 2011, INT VEH S 4 BAD BAD.
   BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Cordts M., 2016, P IEEE C COMP VIS PA.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Enqvist O., 2011, WORKSH OMN VIS CAM N.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Li  Y., 2012, WORLDWIDE POSE ESTIM, P15, DOI DOI 10.1007/978-3-642-33718-5\_2.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Pascoe G., 2015, IEEE INT C COMP VIS.
   Ristic B., 2004, KALMAN FILTER PARTIC.
   Sattler T., 2017, BENCHMARKING 6DOF OU.
   Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5\_54.
   Toft C, 2017, IEEE INT CONF COMP V, P650, DOI 10.1109/ICCVW.2017.83.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   VEDALDI A., 2008, VLFEAT OPEN PORTABLE.
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4\_28.
   Yu F., 2016, ICLR.},
Number-of-Cited-References = {22},
Times-Cited = {39},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {11},
Doc-Delivery-Number = {BL0QZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000446394504135},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000595253700003,
Author = {Derner, Erik and Gomez, Clara and Hernandez, Alejandra C. and Barber,
   Ramon and Babuska, Robert},
Title = {Change detection using weighted features for image-based localization},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2021},
Pages = {103676},
Volume = {135},
Month = {JAN},
Abstract = {Autonomous mobile robots are becoming increasingly important in many
   industrial and domestic environments. Dealing with unforeseen situations
   is a difficult problem that must be tackled to achieve long-term robot
   autonomy. In vision-based localization and navigation methods, one of
   the major issues is the scene dynamics. The autonomous operation of the
   robot may become unreliable if the changes occurring in dynamic
   environments are not detected and managed. Moving chairs, opening and
   closing doors or windows, replacing objects and other changes make many
   conventional methods fail. To deal with these challenges, we present a
   novel method for change detection based on weighted local visual
   features. The core idea of the algorithm is to distinguish the valuable
   information in stable regions of the scene from the potentially
   misleading information in the regions that are changing. We evaluate the
   change detection algorithm in a visual localization framework based on
   feature matching by performing a series of long-term localization
   experiments in various real-world environments. The results show that
   the change detection method yields an improvement in the localization
   accuracy, compared to the baseline method without change detection. In
   addition, an experimental evaluation on a public long-term localization
   data set with more than 10000 images reveals that the proposed method
   outperforms two alternative localization methods on images recorded
   several months after the initial mapping. (c) 2020 Elsevier B.V. All
   rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Derner, E (Corresponding Author), Czech Tech Univ, Czech Inst Informat Robot \& Cybernet, Prague, Czech Republic.
   Derner, Erik; Babuska, Robert, Czech Tech Univ, Czech Inst Informat Robot \& Cybernet, Prague, Czech Republic.
   Derner, Erik, Czech Tech Univ, Fac Elect Engn, Dept Control Engn, Prague, Czech Republic.
   Gomez, Clara; Hernandez, Alejandra C.; Barber, Ramon, Carlos III Univ Madrid, Dept Syst Engn \& Automat, Robot Lab, Madrid, Spain.
   Babuska, Robert, Delft Univ Technol, Cognit Robot, Delft, Netherlands.},
DOI = {10.1016/j.robot.2020.103676},
Article-Number = {103676},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Mobile robotics; Image-based localization; Change detection; Long-term
   autonomy},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {erik.derner@cvut.cz},
Affiliations = {Czech Technical University Prague; Czech Technical University Prague;
   Delft University of Technology},
Funding-Acknowledgement = {European Regional Development Fund under the project Robotics for
   Industry 4.0 {[}CZ.02.1.01/0.0/0.0/15\_003/0000470]; Grant Agency of the
   Czech Technical University in Prague {[}SGS19/174/OHK3/3T/13]; HEROITEA:
   Heterogeneous Intelligent Multi-Robot Team for Assistance of Elderly
   People - Spanish Ministerio de Economia y Competitividad
   {[}RTI2018-095599-B-C21]; RoboCity2030 -DIH-CM project
   {[}S2018/NMT-4331]},
Funding-Text = {This work was supported by the European Regional Development Fund under
   the project Robotics for Industry 4.0 (reg. no.
   CZ.02.1.01/0.0/0.0/15\_003/0000470) and by the Grant Agency of the Czech
   Technical University in Prague, grant no. SGS19/174/OHK3/3T/13. This
   research has also received funding from HEROITEA: Heterogeneous
   Intelligent Multi-Robot Team for Assistance of Elderly People
   (RTI2018-095599-B-C21), funded by Spanish Ministerio de Economia y
   Competitividad, and the RoboCity2030 -DIH-CM project (S2018/NMT-4331,
   RoboCity2030 -Madrid Robotics Digital Innovation Hub, Spain).},
Cited-References = {Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5.
   Alterovitz R, 2016, AI MAG, V37, P76, DOI 10.1609/aimag.v37i2.2651.
   Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI {[}10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3].
   Bacca B, 2011, ROBOT AUTON SYST, V59, P840, DOI 10.1016/j.robot.2011.06.008.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Bezdek JC., 2013, PATTERN RECOGN.
   Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
   Boniardi F, 2019, ROBOT AUTON SYST, V112, P84, DOI 10.1016/j.robot.2018.11.003.
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Chen ZT, 2018, IEEE ROBOT AUTOM LET, V3, P4015, DOI 10.1109/LRA.2018.2859916.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Drews P, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR).
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614.
   Finman R, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P178, DOI 10.1109/ECMR.2013.6698839.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Folkesson, 2018, ARXIV PREPRINT ARXIV.
   Garcia-Fidalgo E, 2015, ROBOT AUTON SYST, V64, P1, DOI 10.1016/j.robot.2014.11.009.
   Hanheide, 2014, IEEE RSJ INT C INT R, DOI {[}10.1109/ IROS.2014.6943205, DOI 10.1109/IROS.2014.6943205].
   Hawes N, 2017, IEEE ROBOT AUTOM MAG, V24, P146, DOI 10.1109/MRA.2016.2636359.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kunze L., 2018, AAAI.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Naseer T, 2018, IEEE T ROBOT, V34, P289, DOI 10.1109/TRO.2017.2788045.
   Neira, 2018, ARXIV180605620.
   Neuman B, 2011, IEEE INT CONF ROBOT.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Nobre F, 2018, IEEE INT CONF ROBOT, P3661.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Sun L, 2018, IEEE ROBOT AUTOM LET, V3, P3749, DOI 10.1109/LRA.2018.2856268.
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832.
   Valgren C., 2007, EUR C MOB ROB.
   Wellhausen L, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY AND RESCUE ROBOTICS (SSRR), P81, DOI 10.1109/SSRR.2017.8088144.},
Number-of-Cited-References = {42},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {11},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {OZ9QO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000595253700003},
DA = {2022-05-17},
}

@article{ WOS:000606561000001,
Author = {Kim, Chansoo and Cho, Sungjin and Sunwoo, Myoungho and Resende, Paulo
   and Bradai, Benazouz and Jo, Kichun},
Title = {A Geodetic Normal Distribution Map for Long-Term LiDAR Localization on
   Earth},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {470-484},
Abstract = {Light detection and ranging (LiDAR) sensors enable a vehicle to estimate
   a pose by matching their measurements with a point cloud (PCD) map.
   However, the PCD map structure, widely used in robot fields, has some
   problems to be applied for mass production in automotive fields. First,
   the PCD map is too big to store all map data at in-vehicle units or
   download the map data from a wireless network according to the vehicle
   location. Second, the PCD map, represented by a single origin in the
   Cartesian coordinates, causes coordinate conversion errors due to an
   inaccurate plane-orb projection, when the vehicle estimate the geodetic
   pose on Earth. To solve two problems, this paper presents a geodetic
   normal distribution (GND) map structure. The GND map structure supports
   a geodetic quad-tree tiling system with multiple origins to minimize the
   coordinate conversion errors. The map data managed by the GND map
   structure are compressed by using Cartesian probabilistic distributions
   of points as map features. The truncation errors by heterogeneous
   coordinates between the geodetic tiling system and Cartesian
   distributions are compensated by the Cartesian voxelization rule. In
   order to match the LiDAR measurements with the GND map structure, the
   paper proposes map-matching approaches based on Monte-Carlo and
   optimization. The paper performed some experiments to evaluate the map
   size compression and the long-term localization on Earth: comparison
   with the PCD map structure, localization in various continents, and
   long-term localization.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Jo, K (Corresponding Author), Konkuk Univ, Dept Smart Vehicle Engn, Seoul 05029, South Korea.
   Kim, Chansoo; Cho, Sungjin; Sunwoo, Myoungho, Hanyang Univ, Dept Automot Engn, Seoul 04763, South Korea.
   Resende, Paulo; Bradai, Benazouz, Valeo Driving Assistance Res Ctr, F-93012 Bobigny, France.
   Jo, Kichun, Konkuk Univ, Dept Smart Vehicle Engn, Seoul 05029, South Korea.},
DOI = {10.1109/ACCESS.2020.3047421},
ISSN = {2169-3536},
Keywords = {World-scale map management; map compression; normal distribution map;
   registration},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {kichun.jo@gmail.com},
Affiliations = {Hanyang University; Valeo SA; Konkuk University},
ORCID-Numbers = {Myoungho, Sunwoo/0000-0002-3505-6675
   Cho, Sungjin/0000-0002-5819-4288
   Resende, Paulo/0000-0002-5170-7837
   Kim, Chansoo/0000-0002-3382-6250},
Funding-Acknowledgement = {BK21 Plus Program through the Ministry of Education, South Korea
   {[}22A20130000045]; Industrial Strategy Technology Development Program
   {[}10039673, 10060068, 10079961]; International Collaborative Research
   and Development Program through the Ministry of Trade, Industry, and
   Energy (MOTIE Korea) {[}N0001992]; National Research Foundation of Korea
   (NRF) - Korean Government (MEST) {[}2011-0017495]},
Funding-Text = {This work was supported in part by the BK21 Plus Program through the
   Ministry of Education, South Korea, under Grant 22A20130000045; in part
   by the Industrial Strategy Technology Development Program under Grant
   10039673, Grant 10060068, and Grant 10079961; in part by the
   International Collaborative Research and Development Program through the
   Ministry of Trade, Industry, and Energy (MOTIE Korea) under Grant
   N0001992; and in part by the National Research Foundation of Korea (NRF)
   Grant funded by the Korean Government (MEST) under Grant 2011-0017495.},
Cited-References = {Akai N., 2020, P IEEE INT VEH S 4 O, P1588.
   Akai N, 2020, IEEE ROBOT AUTOM LET, V5, P4384, DOI 10.1109/LRA.2020.2998403.
   Al Hage J, 2019, IEEE INT VEH SYM, P1232, DOI 10.1109/IVS.2019.8813988.
   Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Cho S., 2020, IEEE T INTELL TRANSP, DOI {[}10.1109/TITS.2020.3035801, DOI 10.1109/TITS.2020.3035801].
   Choi J, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P3082, DOI 10.1109/ITSC.2014.6958185.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Google, GOOGLE PROTOCOL BUFF.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hao Fu, 2020, 2020 12th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P217, DOI 10.1109/IHMSC49165.2020.10127.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Javanmardi E, 2018, IEEE INT C INTELL TR, P2237, DOI 10.1109/ITSC.2018.8569236.
   Jeong J, 2017, IEEE INT VEH SYM, P1736, DOI 10.1109/IVS.2017.7995958.
   Jo H, 2020, IEEE ACCESS, V8, P74485, DOI 10.1109/ACCESS.2020.2988464.
   Jo K., 2019, 2019010491 SAE.
   Jo KC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124119.
   Jo K, 2016, IEEE T INTELL TRANSP, V17, P2008, DOI 10.1109/TITS.2015.2475620.
   Kim C., 2017, P 14 WORKSH POS NAV, P1.
   Kim C, 2019, IEEE ACCESS, V7, P92791, DOI 10.1109/ACCESS.2019.2927736.
   Kim C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124172.
   Kim KW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041220.
   Kuutti S, 2018, IEEE INTERNET THINGS, V5, P829, DOI 10.1109/JIOT.2018.2812300.
   Levinson J., 2007, ROBOTICS SCI SYSTEMS, V4.
   Li L, 2016, IEEE INT VEH SYM, P883, DOI 10.1109/IVS.2016.7535492.
   Liu R, 2020, J NAVIGATION, V73, P324, DOI 10.1017/S0373463319000638.
   Liu ZZ, 2018, IEEE INT VEH SYM, P662, DOI 10.1109/IVS.2018.8500641.
   Maddern W, 2015, IEEE INT CONF ROBOT, P1684, DOI 10.1109/ICRA.2015.7139414.
   Magnusson M, 2007, J FIELD ROBOT, V24, P803, DOI 10.1002/rob.20204.
   Mobileye, ROAD EXPERIENCE MANA.
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258.
   Morton G. M., 1966, IBM RES.
   Mousavian A., 2015, P CVPR WORKSH.
   Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751.
   Reid T. G. R., 2019, SAE INT J CONNECTED, P1.
   Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509.
   Stewart AD, 2012, IEEE INT CONF ROBOT, P2625, DOI 10.1109/ICRA.2012.6224750.
   Stoyanov T, 2012, INT J ROBOT RES, V31, P1377, DOI 10.1177/0278364912460895.
   Suhr JK, 2017, IEEE T INTELL TRANSP, V18, P1078, DOI 10.1109/TITS.2016.2595618.
   Thrun S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P321, DOI 10.1109/ROBOT.2000.844077.
   Thrun S, 2006, J FIELD ROBOT, V23, P661, DOI 10.1002/rob.20147.
   TomTom, TOMTOM HD MAP ROADDN.
   Trehard G, 2015, IEEE INT VEH SYM, P814, DOI 10.1109/IVS.2015.7225785.
   Trehard G, 2014, IEEE INT C INT ROBOT, P2699, DOI 10.1109/IROS.2014.6942931.
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255.
   Wang ZP, 2020, IEEE T INTELL VEHICL, V5, P616, DOI 10.1109/TIV.2020.3003699.
   Wiggers K., 2020, BOSCH DEBUTS LONG RA.
   Wolcott RW, 2017, INT J ROBOT RES, V36, P292, DOI 10.1177/0278364917696568.
   Wolcott RW, 2015, IEEE INT CONF ROBOT, P2814, DOI 10.1109/ICRA.2015.7139582.
   Wurm K. M., 2010, P ICRA WORKSH BEST P, V2.
   Xu YQ, 2017, IEEE INT VEH SYM, P487, DOI 10.1109/IVS.2017.7995765.
   Yue YF, 2020, IEEE INT C INT ROBOT, P6188, DOI 10.1109/IROS45743.2020.9340970.
   Ziegler J, 2014, IEEE INT VEH SYM, P1231, DOI 10.1109/IVS.2014.6856560.},
Number-of-Cited-References = {53},
Times-Cited = {1},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {PQ5BP},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000606561000001},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000329510300008,
Author = {Koos, Sylvain and Cully, Antoine and Mouret, Jean-Baptiste},
Title = {Fast damage recovery in robotics with the T-resilience algorithm},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1700-1723},
Month = {DEC},
Abstract = {Damage recovery is critical for autonomous robots that need to operate
   for a long time without assistance. Most current methods are complex and
   costly because they require anticipating potential damage in order to
   have a contingency plan ready. As an alternative, we introduce the
   T-resilience algorithm, a new algorithm that allows robots to quickly
   and autonomously discover compensatory behavior in unanticipated
   situations. This algorithm equips the robot with a self-model and
   discovers new behavior by learning to avoid those that perform
   differently in the self-model and in reality. Our algorithm thus does
   not identify the damaged parts but it implicitly searches for efficient
   behavior that does not use them. We evaluate the T-resilience algorithm
   on a hexapod robot that needs to adapt to leg removal, broken legs and
   motor failures; we compare it to stochastic local search, policy
   gradient and the self-modeling algorithm proposed by Bongard et al. The
   behavior of the robot is assessed on-board thanks to an RGB-D sensor and
   a SLAM algorithm. Using only 25 tests on the robot and an overall
   running time of 20 min, T-resilience consistently leads to substantially
   better results than the other approaches.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Mouret, JB (Corresponding Author), Univ Paris 06, CNRS UMR 7222, ISIR, F-75252 Paris 05, France.
   Koos, Sylvain; Cully, Antoine; Mouret, Jean-Baptiste, Univ Paris 06, ISIR, F-75252 Paris 05, France.},
DOI = {10.1177/0278364913499192},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Damage recovery; evolutionary algorithm; fault tolerance; hexapod
   locomotion; learning; long-term autonomy; resilience; transferability},
Keywords-Plus = {EVOLUTIONARY ROBOTICS; REINFORCEMENT; WALKING; ADAPTATION; DIVERSITY;
   GAITS},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mouret@isir.upmc.fr},
Affiliations = {UDICE-French Research Universities; League of European Research
   Universities - LERU; Sorbonne Universite},
ResearcherID-Numbers = {Mouret, Jean Baptiste/B-5166-2019
   Mouret, Jean-Baptiste/A-9949-2012
   },
ORCID-Numbers = {Mouret, Jean Baptiste/0000-0002-2513-027X
   Mouret, Jean-Baptiste/0000-0002-2513-027X
   Cully, Antoine/0000-0002-3190-7073},
Funding-Acknowledgement = {Agence Nationale pour la Recherche {[}ANR-12-JS03-0009]; `Universite
   Pierre et Marie Curie - Direction Generale de l'Armement' scholarship;
   Polytech'Paris-UPMC},
Funding-Text = {This work was supported by the Agence Nationale pour la Recherche (grant
   number ANR-12-JS03-0009); a `Universite Pierre et Marie Curie -
   Direction Generale de l'Armement' scholarship to A Cully; and
   Polytech'Paris-UPMC.},
Cited-References = {Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024.
   Barfoot TD, 2006, ROBOT AUTON SYST, V54, P864, DOI 10.1016/j.robot.2006.04.009.
   Bellingham JG, 2007, SCIENCE, V318, P1098, DOI 10.1126/science.1146230.
   Berenson D, 2005, 2005 NASA/DOD CONFERENCE ON EVOLVABLE HARDWARE (EH-2005), PROCEEDINGS, P12, DOI 10.1109/EH.2005.30.
   Bongard JC, 2005, IEEE T EVOLUT COMPUT, V9, P361, DOI 10.1109/TEVC.2005.850293.
   Bongard J, 2006, SCIENCE, V314, P1118, DOI 10.1126/science.1133687.
   Bongard J, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P198.
   CACCAVALE F, 2002, FAULT DIAGNOSIS FAUL.
   Cantu-Paz E., 2000, EFFICIENT ACCURATE P.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Chernova S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2562.
   Clune J, 2011, IEEE T EVOLUT COMPUT, V15, P346, DOI 10.1109/TEVC.2010.2104157.
   CONNELL JH, 1993, ROBOT LEARNING.
   Corbato F., 2007, ACM TURING AWARD LEC, V34, P72.
   Zagal JC, 2009, ROBOT AUTON SYST, V57, P819, DOI 10.1016/j.robot.2009.03.010.
   Cully A, 2013, LEARNING WALK EVERY.
   Cully A, 2013, GECCO'13: PROCEEDINGS OF THE 2013 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P175.
   De Jong Kenneth A, 2006, EVOLUTIONARY COMPUTA.
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017.
   Deb K., 2001, MULTIOBJECTIVE OPTIM.
   DELCOMYN F, 1971, J EXP BIOL, V54, P443.
   Doncieux S, 2011, STUD COMPUT INTELL, V341, P3.
   Drucker H, 1997, ADV NEUR IN, V9, P155.
   Nguyen-Tuong D, 2011, COGN PROCESS, V12, P319, DOI 10.1007/s10339-011-0404-1.
   Endres F., 2012, P IEEE INT C ROB AUT.
   Gorner M, 2010, IEEE INT CONF ROBOT, P4728, DOI 10.1109/ROBOT.2010.5509332.
   Goldberg K., 2001, P IEEE RSJ INT C INT.
   Hartland C, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P1640, DOI 10.1109/ROBIO.2006.340190.
   Heidrich-Meisner V, 2009, J ALGORITHMS, V64, P152, DOI 10.1016/j.jalgor.2009.04.002.
   Hemker T, 2009, International Journal of Robotics Research, V28, P303, DOI 10.1177/0278364908095171.
   Hoffmann M, 2010, IEEE T AUTON MENT DE, V2, P304, DOI 10.1109/TAMD.2010.2086454.
   Holland O, 2003, J CONSCIOUSNESS STUD, V10, P1.
   Hoos H.H., 2005, STOCHASTIC LOCAL SEA.
   Hornby GS, 2011, EVOL COMPUT, V19, P1, DOI 10.1162/EVCO\_a\_00005.
   Hornby GS, 2005, IEEE T ROBOT, V21, P402, DOI 10.1109/TRO.2004.839222.
   Jakimovski B, 2010, CLIMBING WALKING ROB.
   Jakobi N, 1995, LECT NOTES ARTIF INT, V929, P704.
   Kajita S., 2008, LEGGED ROBOTS, P361.
   Katic D, 2003, J INTELL ROBOT SYST, V37, P117, DOI 10.1023/A:1024172417914.
   Kimura H, 2001, IEEE DECIS CONTR P, P411, DOI 10.1109/CDC.2001.980135.
   Klaus Gordon, 2012, Simulation, Modeling, and Programming for Autonomous Robots. Proceedings of the Third International Conference, SIMPAR 2012, P173, DOI 10.1007/978-3-642-34327-8\_18.
   Kober J, 2012, ADAPT LEARN OPTIM, V12, P579.
   Kober J, 2010, IEEE ROBOT AUTOM MAG, V17, P55, DOI 10.1109/MRA.2010.936952.
   Kohl N, 2004, IEEE INT CONF ROBOT, P2619, DOI 10.1109/ROBOT.2004.1307456.
   Koos S, 2013, IEEE T EVOLUTIONARY, V17, P22.
   Koos Sylvain, 2011, P C CLIMB WALK ROB C, P70, DOI 10.1142/97898143742860008.
   Koren I., 2007, FAULT TOLERANT SYSTE.
   Lin CM, 2007, IEEE T SYST MAN CY B, V37, P110, DOI 10.1109/TSMCB.2006.881905.
   Mahdavi SH, 2006, AUTON ROBOT, V20, P149, DOI 10.1007/s10514-006-5941-6.
   Mahdavi SH, 2003, LECT NOTES ARTIF INT, V2801, P248.
   Metzinger T., 2007, SCHOLARPEDIA, V2, P4174, DOI {[}DOI 10.4249/SCH0LARPEDIA.4174, DOI 10.4249/SCHOLARPEDIA.4174].
   Metzinger T., 2004, BEING NO ONE SELF MO.
   Moore G. E., 1975, 1975 International Electron Devices Meeting. (Technical digest), P11.
   Moriarty DE, 1999, J ARTIF INTELL RES, V11, P241, DOI 10.1613/jair.613.
   Mostafa K, 2010, INT J ADV ROBOT SYST, V7, P31.
   Mouret JB, 2012, EVOL COMPUT, V20, P91, DOI 10.1162/EVCO\_a\_00048.
   Mouret J. -B., 2010, P C EV COMP CEC, P4079.
   Mouret JB, 2012, P ALIFES WORKSH EV P, P1.
   Mulder T, 2008, CONSCIOUS COGN, V17, P1266, DOI 10.1016/j.concog.2007.04.001.
   Nakamura Y, 2007, NEURAL NETWORKS, V20, P723, DOI 10.1016/j.neunet.2007.01.002.
   Nelson AL, 2009, ROBOT AUTON SYST, V57, P345, DOI 10.1016/j.robot.2008.09.009.
   Palmer M, 2009, P IROS WORKSH EXPL N.
   Parker GB, 2009, STUD COMPUT INTELL, V177, P255.
   Peters J, 2008, NEURAL NETWORKS, V21, P682, DOI 10.1016/j.neunet.2008.02.003.
   Peters Jan, 2010, ENCY MACHINE LEARNIN, P774, DOI {[}10.4249/scholarpedia.3698, DOI 10.4249/SCHOLARPEDIA.3698].
   Prassler E., 2008, SPRINGER HDB ROBOTIC, P1253, DOI DOI 10.1007/978-3-540-30301-5\_55.
   Pretorius C, 2012, J INTELLIGENT ROBOTI, V71, P319.
   Qu ZH, 2003, AUTOMATICA, V39, P1763, DOI 10.1016/S0005-1098(03)00181-X.
   Quigley M, 2009, P ICRAS WORKSH OP SO.
   Ramachandran VS, 1998, BRAIN, V121, P1603, DOI 10.1093/brain/121.9.1603.
   Saranli U, 2001, INT J ROBOT RES, V20, P616, DOI 10.1177/02783640122067570.
   Schleyer G., 2010, P AUSTR C ROB AUT AC.
   Schmitz J, 2001, BIOL BULL, V200, P195, DOI 10.2307/1543315.
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88.
   Sproewitz A, 2008, INT J ROBOT RES, V27, P423, DOI 10.1177/0278364907088401.
   Steingrube S, 2010, NAT PHYS, V6, P224, DOI 10.1038/NPHYS1508.
   Sturm J, 2008, ROBOTICS SCI SYSTEMS.
   Sutton R.S., 1998, INTRO REINFORCEMENT.
   Sutton RS, 2000, ADV NEUR IN, V12, P1057.
   Tedrake R., 2005, P YAL WORKSH AD LEAR.
   Toffolo A, 2003, EVOL COMPUT, V11, P151, DOI 10.1162/106365603766646816.
   Togelius J., 2009, KUNSTLICHE INTELLIGE, V3, P30.
   Turing Alan M., 1950, MIND, V59, P433.
   VISINSKY ML, 1994, RELIAB ENG SYST SAFE, V46, P139, DOI 10.1016/0951-8320(94)90132-5.
   Vogeley K, 1999, CONSCIOUS COGN, V8, P343, DOI 10.1006/ccog.1999.0394.
   Weingarten JD, 2004, IEEE INT CONF ROBOT, P2153, DOI 10.1109/ROBOT.2004.1307381.
   Whiteson S, 2012, ADAPT LEARN OPTIM, V12, P325.
   WILSON DM, 1966, ANNU REV ENTOMOL, V11, P103, DOI 10.1146/annurev.en.11.010166.000535.
   Xilun Ding, 2010, Climbing and Walking Robots, P291.
   Yosinski J., 2011, P 20 EUR C ART LIF E, P11.
   Zagal J, 2004, P IFAC S INT AUT VEH.
   Zykov V, 2008, THESIS CORNELL U NY.
   Zykov V., 2004, P GEN EV COMP C LAT.},
Number-of-Cited-References = {93},
Times-Cited = {42},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {22},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300008},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000521238100021,
Author = {Yi, Siqi and Worrall, Stewart and Nebot, Eduardo},
Book-Group-Author = {IEEE},
Title = {Geographical Map Registration and Fusion of Lidar-Aerial Orthoimagery in
   GIS},
DOI = {10.1109/ITSC.2019.8917305},
Booktitle = {2019 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC)},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2019},
Pages = {128-134},
Note = {IEEE Intelligent Transportation Systems Conference (IEEE-ITSC),
   Auckland, NEW ZEALAND, OCT 27-30, 2019},
Abstract = {Centimeter level globally accurate and consistent maps for autonomous
   vehicles navigation has long been achieved by on board real-time
   kinematic(RTK)-GPS in open areas. However when dealing with urban
   environments, GPS frequently experiences multipath and blockage in urban
   canyon, under bridges, inside tunnels and in underground environments.
   In this paper we present strategies to efficiently register local maps
   in geographical coordinate systems through the tactical integration of
   GPS and information extracted from precisely geo-referenced high
   resolution aerial orthogonal imagery. Dense lidar point clouds obtained
   from moving vehicles are projected down to horizontal plane, accurately
   registered and overlaid on aerial orthoimagery. Sparse, robust and
   long-term pole-like landmarks are used as anchor points to link lidar
   and aerial image sensing, and constrain the spatial uncertainties of
   remaining lidar points that cannot be directly measured and identified.
   We achieved 15-75cm absolute average global accuracy using precisely
   geo-referenced aerial imagery as ground truth. This is valuable in
   enabling the fusion of ground vehicle on-board sensor features with
   features extracted from aerial images such as traffic and lane markings.
   It is also useful for cooperative sensing to have an unbiased and
   accurate global reference. Experimental results are presented
   demonstrating the accuracy and consistency of the maps when operating in
   large urban areas.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yi, SQ (Corresponding Author), Univ Sydney, Australian Ctr Field Robot, Sydney, NSW, Australia.
   Yi, Siqi; Worrall, Stewart; Nebot, Eduardo, Univ Sydney, Australian Ctr Field Robot, Sydney, NSW, Australia.},
ISSN = {2153-0009},
ISBN = {978-1-5386-7024-8},
Keywords-Plus = {SLAM},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation Science \& Technology},
Author-Email = {yisiqiyisiqi@gmail.com
   s.worrall@acfr.usyd.edu.au
   e.nebot@acfr.usyd.edu.au},
Affiliations = {University of Sydney},
ResearcherID-Numbers = {Worrall, Stewart/AAB-4633-2020},
ORCID-Numbers = {Worrall, Stewart/0000-0001-7940-4742},
Cited-References = {Bansal M., 2011, P 19 ACM INT C MULT, P1125, DOI DOI 10.1145/2072298.2071954.
   Berrio J. S., 2019, UPDATING VISIBILITY.
   Berrio J. S., 2019, IDENTIFYING ROBUST L.
   Blaga BCZ, 2018, INT C INTELL COMP CO, P293, DOI 10.1109/ICCP.2018.8516640.
   Bodei C, 2015, LECT NOTES COMPUT SC, V9465, P1, DOI 10.1007/978-3-319-25527-9\_1.
   Dogruer CU, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P2083.
   Guivant J, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1085.
   Im JH, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081268.
   Kampker A., 2018, P INT C INT AUT SYST, P689.
   Kuhner T., ACCURATE EFFICIENT S.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lothe P, 2010, PROC CVPR IEEE, P863, DOI 10.1109/CVPR.2010.5540127.
   Lothe P, 2009, PROC CVPR IEEE, P2874.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Nguatem W., 2014, ISPRS ANN PHOTOGRAMM, VII-3, P87.
   Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751.
   Schlichting A, 2014, IEEE INT VEH SYM, P414, DOI 10.1109/IVS.2014.6856460.
   Sefati M, 2017, IEEE INT VEH SYM, P13, DOI 10.1109/IVS.2017.7995692.
   Shengwen Xiang, 2018, 2018 AIAA Guidance, Navigation, and Control Conference, P1.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Sun YB, 2016, ISPRS INT J GEO-INF, V5, DOI 10.3390/ijgi5080127.
   Tournaire O., 2006, INT ARCH PHOT REM SE.
   Ventura J, 2014, IEEE T VIS COMPUT GR, V20, P531, DOI 10.1109/TVCG.2014.27.
   Wan GW, 2018, IEEE INT CONF ROBOT, P4670, DOI 10.1109/ICRA.2018.8461224.
   Wang R., 2011, 2010 IEEE COMP SOC C, P58.
   Weng LH, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (IEEE RCAR), P96, DOI 10.1109/RCAR.2018.8621688.
   Yi S., 2019, 30 IEEE INT VEH S IV.
   Yu L, 2020, IEEE T CLOUD COMPUT, V8, P459, DOI 10.1109/TCC.2016.2525984.},
Number-of-Cited-References = {28},
Times-Cited = {3},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BO6LS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000521238100021},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000709128900116,
Author = {Cai, Jiyuan and Luo, Lingkun and Yu, Qiuyu and Liu, Bing and Hu,
   Shiqiang},
Title = {Direct RGB-D Visual Odometry Based on Hybrid Strategy},
Journal = {IEEE SENSORS JOURNAL},
Year = {2021},
Volume = {21},
Number = {20},
Pages = {23278-23288},
Month = {OCT 15},
Abstract = {Edge-based Direct Visual Odometry (E-DVO) plays a crucial role in robot
   navigation across the low-texture and rich-texture scenes, however, two
   essential factors are overlooked in the traditional E-DVO methods. (1)
   Traditional E-DVO methods seriously rely on photometric or geometric
   cost, thereby generating the non-robust performance under the light
   changing or structure-less conditions; (2) EDVO methods generally suffer
   drift issue mainly derived from inaccurate rotation estimation for the
   long term visual odometry task. In this article, a novel hybrid cost
   function leveraging the photometric and geometric cost within a
   bi-direction framework is proposed to facilitate the addressed the
   former issue. While the latter issue is approached through hybridization
   of a simple yet effective switching strategy which can guarantee both
   robustness and accuracy by combining the global Manhattan model and
   direct edge alignment. We carry out various experiments on TUM RGB-D and
   ICL-NUIM datasets for performance evaluation. Results show that our
   method has the advantage of strong robustness and high accuracy compared
   with state-of-the-art methods, e.g., Canny-VO and ORB-SLAM2.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Hu, SQ (Corresponding Author), Shanghai Jiao Tong Univ, Sch Aeronaut \& Astronaut, Shanghai 200240, Peoples R China.
   Cai, Jiyuan; Luo, Lingkun; Yu, Qiuyu; Hu, Shiqiang, Shanghai Jiao Tong Univ, Sch Aeronaut \& Astronaut, Shanghai 200240, Peoples R China.
   Liu, Bing, China Natl Aeronaut Radio Elect Res Inst, Shanghai 200240, Peoples R China.},
DOI = {10.1109/JSEN.2021.3109413},
ISSN = {1530-437X},
EISSN = {1558-1748},
Keywords = {Visual odometry; Estimation; Image edge detection; Feature extraction;
   Sensors; Cost function; Robustness; Visual odometry (VO); RGB-D camera;
   edge feature; global Manhattan model},
Keywords-Plus = {SLAM SYSTEM; POINTS; LINES},
Research-Areas = {Engineering; Instruments \& Instrumentation; Physics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Instruments \& Instrumentation;
   Physics, Applied},
Author-Email = {caijiyuan95@126.com
   lolinkun1988@sjtu.edu.cn
   joeyyu@sjtu.edu.cn
   liubingerbian@163.com
   sqhu@sjtu.edu.cn},
Affiliations = {Shanghai Jiao Tong University},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61773262, 62006152];
   China Aviation Science Foundation {[}20142057006]},
Funding-Text = {This work was supported in part by the National Natural Science
   Foundation of China under Grant 61773262 and Grant 62006152 and in part
   by China Aviation Science Foundation under Grant 20142057006. The
   associate editor coordinating the review of this article and approving
   it for publication was Dr. Amitava Chatterjee.},
Cited-References = {Aguilar WG, 2017, LECT NOTES ARTIF INT, V10464, P298, DOI 10.1007/978-3-319-65298-6\_28.
   Barfoot T., 2017, STATE ESTIMATION ROB.
   Cai JY, 2020, APPL ARTIF INTELL, V34, P1137, DOI 10.1080/08839514.2020.1824093.
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851.
   Cho H, 2018, ROBOT AUTON SYST, V100, P206, DOI 10.1016/j.robot.2017.11.011.
   Christensen K., 2019, ARXIV190604838.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Fabbri R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322434.
   Fu Q, 2019, IEEE SENS J, V19, P9908, DOI 10.1109/JSEN.2019.2927405.
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054.
   Heo S, 2018, IEEE SENS J, V18, P3780, DOI 10.1109/JSEN.2018.2808330.
   Huang ZS, 2018, PATTERN RECOGN LETT, V115, P117, DOI 10.1016/j.patrec.2018.06.031.
   Iacono M, 2018, ROBOT AUTON SYST, V106, P38, DOI 10.1016/j.robot.2018.04.005.
   Kerl C, 2013, IEEE INT C INT ROBOT, P2100, DOI 10.1109/IROS.2013.6696650.
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104.
   Kim C, 2018, IEEE INT C INT ROBOT, P6887, DOI 10.1109/IROS.2018.8593594.
   Kim P., 2017, BMVC, V2, P7.
   Kim P, 2018, LECT NOTES COMPUT SC, V11208, P350, DOI 10.1007/978-3-030-01225-0\_21.
   Kim P, 2018, IEEE INT CONF ROBOT, P7247.
   Kuse M, 2016, IEEE INT CONF ROBOT, P573, DOI 10.1109/ICRA.2016.7487181.
   Li H, 2018, IEEE INT CONF ROBOT, P2518.
   Lin HY, 2021, IEEE SENS J, V21, P11810, DOI 10.1109/JSEN.2020.3015922.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Petrus P, 1999, IEEE T SIGNAL PROCES, V47, P1129, DOI 10.1109/78.752610.
   Proenca PF, 2018, ROBOT AUTON SYST, V104, P25, DOI 10.1016/j.robot.2018.02.018.
   Schenk F., 2017, P BRIT MACH VIS C LO, P1.
   Schenk F, 2017, IEEE INT C INT ROBOT, P1297, DOI 10.1109/IROS.2017.8202305.
   Straub J, 2018, IEEE T PATTERN ANAL, V40, P235, DOI 10.1109/TPAMI.2017.2662686.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.
   Yu HS, 2019, IEEE SENS J, V19, P2217, DOI 10.1109/JSEN.2018.2884321.
   Yu QH, 2018, IEEE ACCESS, V6, P28540, DOI 10.1109/ACCESS.2018.2836928.
   Zhou Y, 2019, IEEE T ROBOT, V35, P184, DOI 10.1109/TRO.2018.2875382.
   Zhou Y, 2017, LECT NOTES COMPUT SC, V10115, P3, DOI 10.1007/978-3-319-54193-8\_1.},
Number-of-Cited-References = {33},
Times-Cited = {0},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {7},
Journal-ISO = {IEEE Sens. J.},
Doc-Delivery-Number = {WJ6BS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000709128900116},
DA = {2022-05-17},
}

@inproceedings{ WOS:000343584000015,
Author = {Perez, Javier and Caballero, Fernando and Merino, Luis},
Editor = {Lau, N and Moreira, AP and Ventura, R and Faria, BM},
Title = {Integration of Monte Carlo Localization and Place Recognition for
   Reliable Long-Term Robot Localization},
DOI = {10.1109/ICARSC.2014.6849767},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON AUTONOMOUS ROBOT SYSTEMS AND
   COMPETITIONS (ICARSC)},
Series = {IEEE International Conference on Autonomous Robot Systems and
   Competitions ICARSC},
Year = {2014},
Pages = {85-91},
Note = {IEEE International Conference on Autonomous Robot Systems and
   Competitions (ICARSC), Espinho, PORTUGAL, MAY 14-15, 2014},
Abstract = {This paper proposes extending Monte Carlo Localization methods with
   visual information in order to build a long term robot localization
   system. This system is aimed to work in crowded and non-planar
   scenarios, where 2D laser rangefinders may not always be enough to match
   the robot position with the map. Thus, visual place recognition will be
   used in order to obtain robot position clues that can be used to detect
   when the robot is lost and also to reset its positions to the right one.
   The paper presents experimental results based on datasets gathered with
   a real robot in challenging scenarios.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Perez, J (Corresponding Author), Pablo de Olavide Univ, Seville, Spain.
   Perez, Javier; Merino, Luis, Pablo de Olavide Univ, Seville, Spain.
   Caballero, Fernando, Univ Seville, Seville, Spain.},
ISSN = {2573-9360},
EISSN = {2573-9387},
ISBN = {978-1-4799-4254-1},
Keywords-Plus = {BAGS},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {jiperlar@upo.es
   fcaballero@us.es
   lmercab@upo.es},
Affiliations = {Universidad Pablo de Olavide; University of Sevilla},
ResearcherID-Numbers = {Merino, Luis/B-2549-2013
   Perez Lara, Javier Ignacio/AAA-7159-2022
   Caballero, Fernando/E-6297-2010},
ORCID-Numbers = {Merino, Luis/0000-0003-4927-8647
   Perez Lara, Javier Ignacio/0000-0002-1167-7557
   Caballero, Fernando/0000-0001-8869-2846},
Funding-Acknowledgement = {European Commission {[}288235]; Junta de Andalucia {[}TIC- 7390]},
Funding-Text = {This work is partially funded by the European Commission 7th Framework
   Programme under grant agreement no. 288235 ( FROG) and the project
   PAIS-MultiRobot, funded by the Junta de Andalucia (TIC- 7390)},
Cited-References = {Alcantarilla PF, 2013, AUTON ROBOT, V34, P47, DOI 10.1007/s10514-012-9312-1.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Carloni Luca P, 2009, 2009 3rd ACM/IEEE International Symposium on Networks-on-Chip (NOCS 2009), P1, DOI 10.1109/NOCS.2009.5071456.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Hentschel M, 2011, J ROBOT, V2011, DOI 10.1155/2011/506245.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   KUMMERLE R, 2013, P IEEE INT C ROB AUT, P3225.
   Thrun S, 2000, INT J ROBOT RES, V19, P972, DOI 10.1177/02783640022067922.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Wallach MH, 2006, INT C MACHINE LEARNI, P977, DOI DOI 10.1145/1143844.1143967.},
Number-of-Cited-References = {15},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BB4ZO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000343584000015},
DA = {2022-05-17},
}

@inproceedings{ WOS:000297477504120,
Author = {Argiles, Alberto and Civera, Javier and Montesano, Luis},
Book-Group-Author = {IEEE},
Title = {Dense Multi-Planar Scene Estimation from a Sparse Set of Images},
DOI = {10.1109/IROS.2011.6094458},
Booktitle = {2011 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2011},
Pages = {4448-4454},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems, San
   Francisco, CA, SEP 25-30, 2011},
Abstract = {Ego-motion estimation and 3D scene reconstruction from image data has
   been a long term aim both in the Robotics and Computer Vision comm
   unities. Nevertheless, while both visual SLAM and Structure from Motion
   already provide an accurate ego-motion estimation, visual scene
   estimation does not offer yet such a satisfactory result; being in most
   cases limited to a sparse set of salient points. In this paper we
   propose an algorithm to densify a sparse point-based reconstruction into
   a dense multi-plane based one, from the only in put of a set of sparse
   images.
   The method starts by recovering a sparse set of 3D salient points and
   uses them to robustly estimate the dominant planes of the scene. The
   number of planes is not known in advance and there may exist outliers
   from the p lanes in the point cloud. In a second step, the image data
   and the estimated 3D structure are combined to determine which parts of
   each plane actually belong to the scene exploiting photoconsistency and
   geometrical constraints.
   Experimental results with real images show that the described approach
   achieves accurate and dense estimation results in man-made environments.
   Moreover, the method is able to recover areas without texture, where
   usually there are no salient points.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Argiles, A (Corresponding Author), Univ Zaragoza, Aragon Inst Engn Res I3A, Robot Percept \& Real Time Grp, Zaragoza 50018, Spain.
   Argiles, Alberto; Civera, Javier; Montesano, Luis, Univ Zaragoza, Aragon Inst Engn Res I3A, Robot Percept \& Real Time Grp, Zaragoza 50018, Spain.},
ISSN = {2153-0858},
ISBN = {978-1-61284-455-8},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {alargi@gmail.com
   jcivera@unizar.es
   montesano@unizar.es},
Affiliations = {University of Zaragoza},
ResearcherID-Numbers = {Civera, Javier/I-3651-2015},
ORCID-Numbers = {Civera, Javier/0000-0003-1368-1151},
Cited-References = {Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348.
   CASTELLANOS JA, 1999, MOBILE ROBOT LOCALIZ.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Fouhey D F, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P336, DOI 10.1109/ICPR.2010.91.
   Furukawa Y., 2010, P 23 IEEE C COMP VIS.
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161.
   Furukawa Y, 2009, IEEE I CONF COMP VIS, P80, DOI 10.1109/ICCV.2009.5459145.
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804.
   Gee AP, 2008, IEEE T ROBOT, V24, P980, DOI 10.1109/TRO.2008.2004641.
   Hartley R. I., 2004, MULTIPLE VIEW GEOMET, P4454.
   Kanazawa Y., 2004, P BRIT MACH VIS C, P247.
   Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4\_59.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593.
   Nevado MM, 2004, ROBOT AUTON SYST, V48, P131, DOI 10.1016/j.robot.2004.06.002.
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3.
   Sola J, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1553, DOI 10.1109/IROS.2009.5354754.
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2\_41.
   Toldo R, 2010, LECT NOTES COMPUT SC, V6315, P589, DOI 10.1007/978-3-642-15555-0\_43.
   Triggs B., 2000, VISION ALGORITHMS TH, V1883, DOI {[}DOI 10.1007/3-540-44480-7\_21, 10.1007/3-540-44480-7\_21].
   Zuliani M., 2005, IEEE INT C IM PROC S.},
Number-of-Cited-References = {23},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BXX70},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000297477504120},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000413726900012,
Author = {Santos, Joao Machado and Krajnik, Tomas and Fentanes, Jaime Pulido and
   Duckett, Tom},
Title = {Lifelong Information- Driven Exploration to Complete and Refine 4-D
   Spatio-Temporal Maps},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2016},
Volume = {1},
Number = {2},
Pages = {684-691},
Month = {JUL},
Abstract = {This letter presents an exploration method that allows mobile robots to
   build and maintain spatio-temporal models of changing environments. The
   assumption of a perpetually changing world adds a temporal dimension to
   the exploration problem, making spatio-temporal exploration a
   never-ending, lifelong learning process. We address the problem by
   application of information-theoretic exploration methods to
   spatio-temporal models that represent the uncertainty of environment
   states as probabilistic functions of time. This allows to predict the
   potential information gain to be obtained by observing a particular area
   at a given time, and consequently, to decide which locations to visit
   and the best times to go there. To validate the approach, a mobile robot
   was deployed continuously over 5 consecutive business days in a busy
   office environment. The results indicate that the robot's ability to
   spot environmental changes improved as it refined its knowledge of the
   world dynamics.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Santos, JM (Corresponding Author), Univ Lincoln, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.
   Santos, Joao Machado; Krajnik, Tomas; Fentanes, Jaime Pulido; Duckett, Tom, Univ Lincoln, Lincoln Ctr Autonomous Syst, Lincoln LN6 7TS, England.},
DOI = {10.1109/LRA.2016.2516594},
ISSN = {2377-3766},
Keywords = {Mapping; service robots},
Keywords-Plus = {MOBILE ROBOTS; ENVIRONMENTS; LOCALIZATION; NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {jsantos@lincoln.ac.uk},
Affiliations = {University of Lincoln},
ResearcherID-Numbers = {Krajník, Tomáš/O-2339-2013
   },
ORCID-Numbers = {Krajník, Tomáš/0000-0002-4408-7916
   Santos, Joao/0000-0002-4797-3542},
Funding-Acknowledgement = {EU ICT project Grant {[}600623]},
Funding-Text = {This work was supported by the EU ICT project Grant 600623 `STRANDS.'},
Cited-References = {Amigoni F, 2010, ROBOT AUTON SYST, V58, P684, DOI 10.1016/j.robot.2009.11.005.
   Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
   Caglioti V, 2001, IEEE T SYST MAN CY B, V31, P187, DOI 10.1109/3477.915342.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   CROES GA, 1958, OPER RES, V6, P791, DOI 10.1287/opre.6.6.791.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Fentanes JP, 2015, IEEE INT CONF ROBOT, P1112, DOI 10.1109/ICRA.2015.7139315.
   Hawes N., 2014, STRANDS SOFTWARE SYS.
   Holz D., 2010, ISR 2010 41 INT S RO, P1.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Koenig S, 2001, IEEE INT CONF ROBOT, P3594, DOI 10.1109/ROBOT.2001.933175.
   Krajnik T., 2015, MOB ROB ECMR 2015 EU, P1.
   Krajnik T., 2014, J INTELL ROBOT SYST.
   Krajnik T., 2014, ADV AUTONOMOUS ROBOT, P281.
   Krajnik T, 2015, IEEE INT CONF ROBOT, P2140, DOI 10.1109/ICRA.2015.7139481.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   LEVOY M, 1990, ACM T GRAPHIC, V9, P245, DOI 10.1145/78964.78965.
   Marchant R, 2014, IEEE INT CONF ROBOT, P6136, DOI 10.1109/ICRA.2014.6907763.
   Marchant R, 2012, IEEE INT C INT ROBOT, P2242, DOI 10.1109/IROS.2012.6385653.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   MORAVEC HP, 1988, AI MAG, V9, P61.
   Muhlfellner P., 2015, J FIELD ROBOT.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Fentanes JAP, 2011, J FIELD ROBOT, V28, P832, DOI 10.1002/rob.20402.
   Rahman M, 2011, APPLICATIONS OF FOURIER TRANSFORMS TO GENERALIZED FUNCTIONS, P1.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Singh Amarjeet, 2010, 2010 IEEE International Conference on Robotics and Automation (ICRA 2010), P5490, DOI 10.1109/ROBOT.2010.5509934.
   Stachniss C., 2005, P ROB SCI SYST RSS C.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {31},
Times-Cited = {17},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {FK7ZO},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000413726900012},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000777505000044,
Author = {Alijani, Farid and Peltomaki, Jukka and Puura, Jussi and Huttunen,
   Heikki and Kamarainen, Joni-Kristian and Rahtu, Esa},
Editor = {Farinella, GM and Radeva, P and Bouatouch, K},
Title = {Evaluation of Long-term Deep Visual Place Recognition},
Booktitle = {PROCEEDINGS OF THE 17TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP),
   VOL 5},
Series = {VISIGRAPP},
Year = {2022},
Pages = {437-447},
Note = {17th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP) / 17th
   International Conference on Computer Vision Theory and Applications
   (VISAPP), ELECTR NETWORK, FEB 06-08, 2022},
Abstract = {In this paper, we provide a comprehensive study on evaluating two
   state-of-the-art deep metric learning methods for visual place
   recognition. Visual place recognition is an essential component in the
   visual localization and the vision-based navigation where it provides an
   initial coarse location. It is used in variety of autonomous navigation
   technologies, including autonomous vehicles, drones and computer vision
   systems. We study recent visual place recognition and image retrieval
   methods and utilize them to conduct extensive and comprehensive
   experiments on two diverse and large long-term indoor and outdoor robot
   navigation datasets, e.g., COLD and Oxford Radar RobotCar along with
   ablation studies on the crucial parameters of the deep architectures.
   Our comprehensive results indicate that the methods can achieve 5 m of
   outdoor and 50 cm of indoor place recognition accuracy with high recall
   rate of 80 \%.},
Publisher = {SCITEPRESS},
Address = {AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Alijani, F (Corresponding Author), Tampere Univ, Tampere, Finland.
   Alijani, Farid; Peltomaki, Jukka; Kamarainen, Joni-Kristian; Rahtu, Esa, Tampere Univ, Tampere, Finland.
   Puura, Jussi, Sandvik Min \& Construct Ltd, Tampere, Finland.
   Huttunen, Heikki, Visy Oy, Tampere, Finland.},
DOI = {10.5220/0010834700003124},
ISSN = {2184-4321},
ISBN = {978-989-758-555-5},
Keywords = {Tracking and Visual Navigation; Content-Based Indexing; Search;
   Retrieval; Deep Convolutional Neural Network; Deep Learning for Visual
   Understanding},
Keywords-Plus = {FAB-MAP; SCALE; LOCALIZATION; NAVIGATION; FEATURES; VISION; LIDAR},
Research-Areas = {Computer Science; Imaging Science \& Photographic Technology},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Imaging Science \& Photographic Technology},
Affiliations = {Tampere University},
ORCID-Numbers = {Alijani, Farid/0000-0003-3928-7291},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270.
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150.
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
   Barnes D, 2020, IEEE INT CONF ROBOT, P6433, DOI 10.1109/ICRA40945.2020.9196884.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Blanco-Claraco JL, 2014, INT J ROBOT RES, V33, P207, DOI 10.1177/0278364913507326.
   Bonin-Font F, 2008, J INTELL ROBOT SYST, V53, P263, DOI 10.1007/s10846-008-9235-4.
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610.
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0\_48.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Masone C, 2021, IEEE ACCESS, V9, P19516, DOI 10.1109/ACCESS.2021.3054937.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Olid D, 2018, ABS180806516 CORR.
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640.
   Pion N., 2020, INT C 3D VIS 3DV.
   Pitropov M, 2021, INT J ROBOT RES, V40, P681, DOI 10.1177/0278364920979368.
   Pronobis A, 2009, INT J ROBOT RES, V28, P588, DOI 10.1177/0278364909103912.
   Radenovic F, 2016, ECCV.
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566.
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598.
   Radenovic F, 2018, LECT NOTES COMPUT SC, V11209, P774, DOI 10.1007/978-3-030-01228-1\_46.
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y.
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300.
   Sattler T., 2020, INT C 3D VIS 3DV.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76.
   Simonyan K., 2015, P 3 INT C LEARNING R.
   Taira H, 2021, IEEE T PATTERN ANAL, V43, P1293, DOI 10.1109/TPAMI.2019.2952114.
   Tolias G, 2016, PARTICULAR OBJECT RE.
   Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41.
   Xu M., 2002, VISION MOBILE ROBOT.
   Zhang XW, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107760.},
Number-of-Cited-References = {45},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS8TM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000777505000044},
DA = {2022-05-17},
}

@inproceedings{ WOS:000755125503078,
Author = {Peltomaki, Jukka and Alijani, Farid and Puura, Jussi and Huttunen,
   Heikki and Rahtu, Esa and Kamarainen, Joni-Kristian},
Book-Group-Author = {IEEE},
Title = {Evaluation of Long-term LiDAR Place Recognition},
Booktitle = {2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2021},
Pages = {4487-4492},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, SEP 27-OCT 01, 2021},
Abstract = {We compare a state-of-the-art deep image retrieval and a deep place
   recognition method for place recognition using LiDAR data. Place
   recognition aims to detect previously visited locations and thus
   provides an important tool for navigation, mapping, and localisation.
   Experimental comparisons are conducted using challenging outdoor and
   indoor datasets, Oxford Radar RobotCar and COLD, in the ``long-term{''}
   setting where the test conditions differ substantially from the training
   and gallery data. Based on our results the image retrieval methods using
   LiDAR depth images can achieve accurate localization (the single best
   match recall 80\%) within 5.00 m in urban outdoors. In office indoors
   the comparable accuracy is 50 cm but is more sensitive to changes in the
   environment.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Peltomaki, J (Corresponding Author), Tampere Univ, Tampere, Finland.
   Peltomaki, Jukka; Alijani, Farid; Huttunen, Heikki; Rahtu, Esa; Kamarainen, Joni-Kristian, Tampere Univ, Tampere, Finland.
   Puura, Jussi, Sandvik Min \& Construe Ltd, Stockholm, Sweden.},
DOI = {10.1109/IROS51168.2021.9636320},
ISSN = {2153-0858},
ISBN = {978-1-6654-1714-3},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Affiliations = {Tampere University},
ORCID-Numbers = {Alijani, Farid/0000-0003-3928-7291
   Rahtu, Esa/0000-0001-8767-0864
   Huttunen, Heikki/0000-0002-6571-0797},
Cited-References = {Arandjelovic R., 2016, P IEEE C COMP VIS PA.
   Arandjelovic R., 2018, TPAMI.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Guo JD, 2019, IEEE ROBOT AUTOM LET, V4, P1470, DOI 10.1109/LRA.2019.2893887.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Kim G, 2020, IEEE INT CONF ROBOT, P6246.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W., 2017, ACTA POLYTECH HUNG, V36, P3, DOI {[}10.1177/0278364916679498, DOI 10.1177/0278364916679498].
   Pion N., 2020, INT C 3D VIS 3DV.
   Pronobis A., INT J ROBOTICS RES I, V28.
   RADENOVIC F, 2018, ECCV, V1209, P774, DOI DOI 10.1007/978-3-030-01228-1\_46.
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566.
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0\_1.
   Ramezani M., 2020, 2020 IEEE RSJ INT C.
   Sarlin P.-E., 2019, CVPR.
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499.
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682.
   Shakeri M., 2016, IROS.
   Steder B, 2010, IEEE INT CONF ROBOT, P1400, DOI 10.1109/ROBOT.2010.5509401.
   Sunderhauf N., 2015, IROS.
   Ullah M., 2008, IROS.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Warburg F., 2020, IEEE C COMP VIS PATT.
   Xie S., 2020, SENSORS, V20.
   Xin Z., 2010, ICRA.
   Yin P, 2018, IEEE INT C INT ROBOT, P1162, DOI 10.1109/IROS.2018.8593562.
   Zhang XW, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107760.},
Number-of-Cited-References = {28},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BS6ZK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000755125503078},
DA = {2022-05-17},
}

@inproceedings{ WOS:000693397600087,
Author = {Rotsidis, Alexandros and Lutteroth, Christof and Hall, Peter and
   Richardt, Christian},
Book-Group-Author = {IEEE},
Title = {ExMaps: Long-Term Localization in Dynamic Scenes using Exponential Decay},
Booktitle = {2021 IEEE WINTER CONFERENCE ON APPLICATIONS OF COMPUTER VISION WACV 2021},
Series = {IEEE Winter Conference on Applications of Computer Vision},
Year = {2021},
Pages = {2866-2875},
Note = {IEEE Winter Conference on Applications of Computer Vision (WACV), ELECTR
   NETWORK, JAN 05-09, 2021},
Abstract = {Visual camera localization using offline maps is widespread in robotics
   and mobile applications. Most state-of-the-art localization approaches
   assume static scenes, so maps are often reconstructed once and then kept
   constant. However, many scenes are dynamic and as changes in the scene
   happen, future localization attempts may struggle or fail entirely.
   Therefore, it is important for successful long-term localization to
   update and maintain maps as new observations of the scene, and changes
   in it, arrive. We propose a novel method for automatically discovering
   which points in a map remain stable over time, and which are due to
   transient changes. To this end, we calculate a stability store for each
   point based on its visibility over time, weighted by an exponential
   decay over time. This allows us to consider the impact of time when
   scoring points, and to distinguish which points are useful for long-term
   localization. We evaluate our method on the CMU Extended Seasons dataset
   (outdoors) and a new indoor dataset of a retail shop, and show the
   benefit of maintaining a `live map' that integrates updates over time
   using our exponential decay based method over a static `base map'.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Rotsidis, A (Corresponding Author), Univ Bath, Ctr Digital Entertainment, Bath, Avon, England.
   Rotsidis, Alexandros; Lutteroth, Christof; Hall, Peter; Richardt, Christian, Univ Bath, Ctr Digital Entertainment, Bath, Avon, England.},
DOI = {10.1109/WACV48630.2021.00291},
ISSN = {2472-6737},
ISBN = {978-0-7381-4266-1},
Research-Areas = {Computer Science; Engineering; Imaging Science \& Photographic
   Technology},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Imaging Science \& Photographic Technology},
Author-Email = {A.Rotsidis@bath.ac.uk
   C.Lutteroth@bath.ac.uk
   P.M.Hall@bath.ac.uk
   christian@richardt.name},
Affiliations = {University of Bath},
ORCID-Numbers = {Richardt, Christian/0000-0001-6716-9845
   Lutteroth, Christof/0000-0003-0634-7569},
Funding-Acknowledgement = {EPSRC CDE {[}EP/L016540/1]; EPSRC-UKRI Innovation Fellowship
   {[}EP/S001050/1]},
Funding-Text = {This research was supported by Dcactiv, the EPSRC CDE (EP/L016540/1),
   and an EPSRC-UKRI Innovation Fellowship (EP/S001050/1).},
Cited-References = {Arandjelovic R., 2016, IEEE T PATTERN ANAL, P5297, DOI DOI 10.1109/TPAMI.2017.2711011.
   Arroyo R, 2018, AUTON ROBOT, V42, P665, DOI 10.1007/s10514-017-9664-7.
   Badino Hernan., 2011, CMU VISUAL LOCALIZAT, P5.
   Brachmann E, 2018, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2018.00489.
   Camposeco F, 2018, PROC CVPR IEEE, P136, DOI 10.1109/CVPR.2018.00022.
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610.
   Choudhary Siddharth, 2012, ECCV, P2.
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dymczyk Marcin, 2016, IROS, P3.
   Dymczyk Marcin, 2015, ICRA, V3, P6.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599.
   Google, 2020, ARCORE SDK.
   Gronat P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122.
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0.
   Irschara A, 2009, PROC CVPR IEEE, P2591, DOI 10.1109/cvpr.2009.5206587.
   Jian Wu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5644, DOI 10.1109/ICRA.2017.7989663.
   Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5\_2.
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791.
   Lim H, 2012, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2012.6247782.
   Liu L, 2017, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2017.260.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lynen S, 2020, INT J ROBOT RES, V39, P1061, DOI 10.1177/0278364920931151.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Maddern Will, 2013, ROBOTICS SCI SYSTEMS, P3.
   Massiceti Daniela, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5118, DOI 10.1109/ICRA.2017.7989598.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Santarcangelo Vito, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P518, DOI 10.1007/978-3-319-46604-0\_37.
   Sattler T, 2019, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR.2019.00342.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76.
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302.
   Schonberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445.
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377.
   Spera Emiliano, 2018, IEEE INT C PATT REC, P1.
   Spera Emiliano, 2020, IEEE TCSVT, P3.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Stylianou A, 2015, IEEE WINT CONF APPL, P892, DOI 10.1109/WACV.2015.123.
   Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752.
   Toft C., 2018, P EUR C COMP VIS ECC, P383.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Wang SL, 2015, IEEE I CONF COMP VIS, P2695, DOI 10.1109/ICCV.2015.309.
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1\_19.
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80.},
Number-of-Cited-References = {51},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS1MO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000693397600087},
DA = {2022-05-17},
}

@article{ WOS:000329510300007,
Author = {Fallon, Maurice and Johannsson, Hordur and Kaess, Michael and Leonard,
   John J.},
Title = {The MIT Stata Center dataset},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1695-1699},
Month = {DEC},
Abstract = {This paper presents a large scale dataset of vision (stereo and RGB-D),
   laser and proprioceptive data collected over an extended duration by a
   Willow Garage PR2 robot in the 10 story MIT Stata Center. As of
   September 2012 the dataset comprises over 2.3 TB, 38 h and 42 km (the
   length of a marathon). The dataset is of particular interest to robotics
   and computer vision researchers interested in long-term autonomy. It is
   expected to be useful in a variety of research areasrobotic mapping
   (long-term, visual, RGB-D or laser), change detection in indoor
   environments, human pattern analysis, long-term path planning. For ease
   of use the original ROS bag' log files are provided and also a
   derivative version combining human readable data and imagery in standard
   formats. Of particular importance, this dataset also includes
   ground-truth position estimates of the robot at every instance (to
   typical accuracy of 2 cm) using as-built floor-planswhich were carefully
   extracted using our software tools. The provision of ground-truth for
   such a large dataset enables more meaningful comparison between
   algorithms than has previously been possible.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Fallon, M (Corresponding Author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Fallon, Maurice; Johannsson, Hordur; Kaess, Michael; Leonard, John J., MIT, Cambridge, MA 02139 USA.},
DOI = {10.1177/0278364913509035},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Data paper; PR2; Willow Garage; laser; stereo; Simultaneous Localization
   and Mapping; mobile robotics; CSAIL; Stata; MIT},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mfallon@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT)},
ORCID-Numbers = {Fallon, Maurice/0000-0003-2940-0879
   Kaess, Michael/0000-0002-7590-3357},
Funding-Acknowledgement = {Office of Naval Research {[}N00014-10-1-0936, N00014-11-1-0688,
   N00014-12-10020, N00014-131-0588]},
Funding-Text = {This work was partially supported by the Office of Naval Research under
   grants N00014-10-1-0936, N00014-11-1-0688, N00014-12-10020, and
   N00014-131-0588, which we gratefully acknowledge.},
Cited-References = {Bachrach A, 2011, J FIELD ROBOT, V28, P644, DOI 10.1002/rob.20400.
   Huang A.S., 2011, P INT S ROB RES ISRR.
   Johannsson H, 2013, THESIS MIT US.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977.
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773.},
Number-of-Cited-References = {8},
Times-Cited = {31},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {51},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300007},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000458872701042,
Author = {Yin, Peng and Xu, Lingyun and Liu, Zhe and Li, Lu and Salman, Hadi and
   He, Yuqing and Xu, Weiliang and Wang, Hesheng and Choset, Howie},
Editor = {Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L},
Book-Author = {Kosecka, J},
Title = {Stabilize an Unsupervised Feature Learning for LiDAR-based Place
   Recognition},
DOI = {10.1109/IROS.2018.8593562},
Booktitle = {2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2018},
Pages = {1162-1167},
Note = {25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Madrid, SPAIN, OCT 01-05, 2018},
Abstract = {Place recognition is one of the major challenges for the LiDAR-based
   effective localization and mapping task. Traditional methods are usually
   relying on geometry matching to achieve place recognition, where a
   global geometry map need to be restored. In this paper, we accomplish
   the place recognition task based on an end-to-end feature learning
   framework with the LiDAR inputs. This method consists of two core
   modules, a dynamic octree mapping module that generates local 2D maps
   with the consideration of the robot's motion; and an unsupervised place
   feature learning module which is an improved adversarial feature
   learning network with additional assistance for the long-term place
   recognition requirement. More specially, in place feature learning, we
   present an additional Generative Adversarial Network with a designed
   Conditional Entropy Reduction module to stabilize the feature learning
   process in an unsupervised manner. We evaluate the proposed method on
   the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental
   results show that the proposed method outperforms state-of-the-art in
   place recognition tasks under long-term applications. What's more, the
   feature size and inference efficiency in the proposed method are
   applicable in real-time performance on practical robotic platforms.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Xu, LY (Corresponding Author), Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Liaoning, Peoples R China.
   Yin, Peng; Xu, Lingyun; He, Yuqing, Chinese Acad Sci, Shenyang Inst Automat, State Key Lab Robot, Shenyang, Liaoning, Peoples R China.
   Yin, Peng; Xu, Lingyun; He, Yuqing, Univ Chinese Acad Sci, Beijing, Peoples R China.
   Liu, Zhe, Chinese Univ Hong Kong, Dept Mech \& Automat Engn, Hong Kong, Peoples R China.
   Li, Lu; Salman, Hadi; Choset, Howie, Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Xu, Weiliang, Univ Auckland, Dept Mech Engn, Auckland, New Zealand.
   Wang, Hesheng, Shanghai Jiao Tong Univ, Dept Automat, Shanghai, Peoples R China.},
ISSN = {2153-0858},
ISBN = {978-1-5386-8094-0},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {pyin2@andrew.cmu.edu
   121067240@qq.com
   zheli-u@cuhk.edu.hk
   luli2@cmu.edu
   hadis@cmu.edu
   heyuqing@sia.cn
   p.xu@auckland.ac.nz
   wanghesheng@sjtu.edu.cn
   choset@cmu.edu},
Affiliations = {Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese University of Hong Kong; Carnegie Mellon University;
   University of Auckland; Shanghai Jiao Tong University},
ResearcherID-Numbers = {Yin, Peng/AEY-2004-2022
   },
ORCID-Numbers = {Xu, Peter/0000-0002-1960-0992},
Cited-References = {Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Donahue Jeff, 2016, ADVERSARIAL FEATURE.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Fossel J, 2017, IEEE INT C INT ROBOT, P6764, DOI 10.1109/IROS.2017.8206594.
   Garg S, 2017, IEEE INT C INT ROBOT, P6863, DOI 10.1109/IROS.2017.8206608.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Latif Y., 2017, ARXIV170908810.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Martin A, 2017, ARXIV170104862.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509.
   Sunderhauf N., 2013, WORKSH LONG TERM AUT.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Xiong T, 2014, BIOMED CIRC SYST C, P9, DOI 10.1109/BioCAS.2014.6981632.},
Number-of-Cited-References = {22},
Times-Cited = {7},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BM0LT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000458872701042},
DA = {2022-05-17},
}

@article{ WOS:000280869700006,
Author = {Civera, Javier and Grasa, Oscar G. and Davison, Andrew J. and Montiel,
   J. M. M.},
Title = {1-Point RANSAC for Extended Kalman Filtering: Application to Real-Time
   Structure from Motion and Visual Odometry},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2010},
Volume = {27},
Number = {5, SI},
Pages = {609-631},
Month = {SEP-OCT},
Note = {IEEE International Conference on Robotics and Automation, Kobe, JAPAN,
   MAY 12-17, 2009},
Abstract = {Random sample consensus (RANSAC) has become one of the most successful
   techniques for robust estimation from a data set that may contain
   outliers. It works by constructing model hypotheses from random minimal
   data subsets and evaluating their validity from the support of the whole
   data. In this paper we present a novel combination of RANSAC plus
   extended Kalman filter (EKF) that uses the available prior probabilistic
   information from the EKF in the RANSAC model hypothesize stage. This
   allows the minimal sample size to be reduced to one, resulting in large
   computational savings without the loss of discriminative power. 1-Point
   RANSAC is shown to outperform both in accuracy and computational cost
   the joint compatibility branch and bound (JCBB) algorithm, a
   gold-standard technique for spurious rejection within the EKF framework.
   Two visual estimation scenarios are used in the experiments: first,
   six-degree-of-freedom (DOF) motion estimation from a monocular sequence
   (structure from motion). Here, a new method for benchmarking six-DOF
   visual estimation algorithms based on the use of high-resolution images
   is presented, validated, and used to show the superiority of 1-point
   RANSAC. Second, we demonstrate long-term robot trajectory estimation
   combining monocular vision and wheel odometry (visual odometry). Here, a
   comparison against global positioning system shows an accuracy
   comparable to state-of-the-art visual odometry methods. (C) 2010 Wiley
   Periodicals, Inc.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Civera, J (Corresponding Author), Univ Zaragoza, Robot Percept \& Real Time Grp, Zaragoza 50018, Spain.
   Civera, Javier; Grasa, Oscar G.; Montiel, J. M. M., Univ Zaragoza, Robot Percept \& Real Time Grp, Zaragoza 50018, Spain.
   Davison, Andrew J., Univ London Imperial Coll Sci Technol \& Med, Dept Comp, London SW7 2AZ, England.},
DOI = {10.1002/rob.20345},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords-Plus = {SLAM},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {jcivera@unizar.es
   oscgg@unizar.es
   ajd@doc.ic.ac.uk
   josemari@unizar.es},
Affiliations = {University of Zaragoza; League of European Research Universities - LERU;
   Imperial College London},
ResearcherID-Numbers = {Montiel, Jose María Martínez/A-1197-2012
   Civera, Javier/I-3651-2015},
ORCID-Numbers = {Montiel, Jose María Martínez/0000-0002-3627-7306
   Civera, Javier/0000-0003-1368-1151},
Cited-References = {Blanco JL, 2009, AUTON ROBOT, V27, P327, DOI 10.1007/s10514-009-9138-7.
   BORENSTEIN J, 1996, UMMEAM9421.
   Capel D., 2005, P BMVC, P629.
   Castellanos J., 2004, 5 IFAC S INT AUT VEH.
   Cheng Y, 2006, IEEE ROBOT AUTOM MAG, V13, P54, DOI 10.1109/MRA.2006.1638016.
   Chli M, 2008, LECT NOTES COMPUT SC, V5302, P72, DOI 10.1007/978-3-540-88682-2\_7.
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787.
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276.
   Civera J, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P3498, DOI 10.1109/IROS.2009.5354410.
   Clemente L.A., 2007, ROBOTICS SCI SYSTEMS, V2.
   Comport AI, 2007, IEEE INT CONF ROBOT, P40, DOI 10.1109/ROBOT.2007.363762.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Eade E, 2007, IEEE I CONF COMP VIS, P2112.
   Fenwick JW, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1810, DOI 10.1109/ROBOT.2002.1014804.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   FUNKE J, 2009, P BRIT MACH VIS C LO.
   HANDA A, 2010, P IEEE C CO IN PRESS.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4\_59.
   Konolige K., 2007, INT S RES ROB HIR JA.
   Kummerle R, 2009, AUTON ROBOT, V27, P387, DOI 10.1007/s10514-009-9155-6.
   Moreno-Noguer F, 2008, LECT NOTES COMPUT SC, V5303, P405, DOI 10.1007/978-3-540-88688-4\_30.
   Mouragnon E, 2009, IMAGE VISION COMPUT, V27, P1178, DOI 10.1016/j.imavis.2008.11.006.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Nister D, 2005, MACH VISION APPL, V16, P321, DOI 10.1007/s00138-005-0006-y.
   Nister D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17.
   Nister D, 2004, PROC CVPR IEEE, P652.
   Ortin D, 2001, ROBOTICA, V19, P331, DOI 10.1017/S0263574700003143.
   Paz LM, 2008, IEEE T ROBOT, V24, P1107, DOI 10.1109/TRO.2008.2004639.
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4\_37.
   Scaramuzza D, 2009, IEEE INT CONF ROBOT, P488.
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Tardif JP, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2531, DOI 10.1109/IROS.2008.4651205.
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832.
   TORR PHS, 1993, P SOC PHOTO-OPT INS, V2059, P432, DOI 10.1117/12.150246.
   Triggs B., 2000, VISION ALGORITHMS TH, V1883, DOI {[}DOI 10.1007/3-540-44480-7\_21, 10.1007/3-540-44480-7\_21].
   VEDALDI A, 2005, P INT C COMP VIS ICC, V1, P633.
   Williams B, 2007, IEEE 11 INT C COMP V.
   Williams B., 2009, THESIS U OXFORD.},
Number-of-Cited-References = {41},
Times-Cited = {196},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {43},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {638CV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000280869700006},
DA = {2022-05-17},
}

@article{ WOS:000733448000001,
Author = {Berrio, Julie Stephany and Worrall, Stewart and Shan, Mao and Nebot,
   Eduardo},
Title = {Long-Term Map Maintenance Pipeline for Autonomous Vehicles},
Year = {2021},
Journal = {IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS},
Abstract = {For autonomous vehicles to operate persistently in a typical urban
   environment, it is essential to have high accuracy position information.
   This requires a mapping and localisation system that can adapt to
   changes over time. A localisation approach based on a single-survey map
   will not be suitable for long-term operation as it does not incorporate
   variations in the environment. In this paper, we present new algorithms
   to maintain a featured-based map. A map maintenance pipeline is proposed
   that can continuously update a map with the most relevant features
   taking advantage of the changes in the surroundings. Our pipeline
   detects and removes transient features based on their geometrical
   relationships with the vehicle's pose. Newly identified features became
   part of a new feature map and are assessed by the pipeline as candidates
   for the localisation map. By purging out-of-date features and adding
   newly detected features, we continually update the prior map to more
   accurately represent the most recent environment. We have validated our
   approach using the USyd Campus Dataset, which includes more than 18
   months of data. The results presented demonstrate that our maintenance
   pipeline produces a resilient map which can provide sustained
   localisation performance over time.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article; Early Access},
Language = {English},
Affiliation = {Berrio, JS (Corresponding Author), Univ Sydney, Australian Ctr Field Robot ACFR, Sydney, NSW 2006, Australia.
   Berrio, Julie Stephany; Worrall, Stewart; Shan, Mao; Nebot, Eduardo, Univ Sydney, Australian Ctr Field Robot ACFR, Sydney, NSW 2006, Australia.},
DOI = {10.1109/TITS.2021.3094485},
EarlyAccessDate = {JUL 2021},
ISSN = {1524-9050},
EISSN = {1558-0016},
Keywords = {Feature extraction; Pipelines; Maintenance engineering; Transient
   analysis; Visualization; Autonomous vehicles; Task analysis; Long-term
   localisation; feature-based map; map update},
Research-Areas = {Engineering; Transportation},
Web-of-Science-Categories  = {Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology},
Author-Email = {j.berrio@acfr.usyd.edu.au
   s.worrall@acfr.usyd.edu.au
   m.shan@acfr.usyd.edu.au
   e.nebot@acfr.usyd.edu.au},
Affiliations = {University of Sydney},
Funding-Acknowledgement = {ACFR; University of Sydney; University of Michigan/Ford Motors Company
   Contract Next generation Vehicles},
Funding-Text = {This work was supported in part by the ACFR, the University of Sydney
   through the Dean of Engineering and Information Technologies PhD
   Scholarship (South America) and in part by the University of
   Michigan/Ford Motors Company Contract Next generation Vehicles. The
   Associate Editor for this article was C. Wen.},
Cited-References = {Berrio J. Stephany, 2020, ARXIV200705490.
   Berrio JS, 2019, IEEE INT VEH SYM, P1173, DOI 10.1109/IVS.2019.8814189.
   Berrio JS, 2019, IEEE INT VEH SYM, P1166, DOI 10.1109/IVS.2019.8814289.
   Berrio JS, 2018, IEEE INT C INT ROBOT, P3174, DOI 10.1109/IROS.2018.8594024.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Carneiro G, 2009, IMAGE VISION COMPUT, V27, P1143, DOI 10.1016/j.imavis.2008.10.015.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   CivilMaps, 2020, FINGERPRINT BAS MAP.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Egger P, 2018, IEEE INT C INT ROBOT, P3430, DOI 10.1109/IROS.2018.8593854.
   Einhorn E, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P240, DOI 10.1109/ECMR.2013.6698849.
   Fankhauser P, 2016, STUD COMPUT INTELL, V625, P99, DOI 10.1007/978-3-319-26054-9\_5.
   Hilbrandie G., 2018, U.S. Patent, Patent No. {[}10 024 676, 10024676].
   Hochdorfer S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P382, DOI 10.1109/IROS.2009.5354433.
   Jo K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093145.
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T, 2019, IEEE ROBOT AUTOM LET, V4, P3310, DOI 10.1109/LRA.2019.2926682.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Kretzschmar H, 2010, KUNSTL INTELL, V24, P199, DOI 10.1007/s13218-010-0034-2.
   Lategahn H, 2013, IEEE INT VEH SYM, P285, DOI 10.1109/IVS.2013.6629483.
   MacTavish K, 2018, J FIELD ROBOT, V35, P1265, DOI 10.1002/rob.21838.
   Mihelich P, 2019, ROS PERCEPTION CAMER.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Nobre F, 2018, IEEE INT CONF ROBOT, P3661.
   Pannen D, 2020, IEEE INT CONF ROBOT, P2288, DOI 10.1109/ICRA40945.2020.9197419.
   Pannen D, 2019, IEEE INT CONF ROBOT, P2561, DOI 10.1109/ICRA.2019.8794329.
   Pirker K, 2011, IEEE INT C INT ROBOT, P3990, DOI 10.1109/IROS.2011.6048253.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Sekonix, 2018, SF332X10 FAM DAT.
   Ublox, 2020, NEO M8PU BLOX M8 HIG.
   Vardhan H, 2018, HD MAPS NEW AGE MAPS.
   Vectornav, 2020, VN 100 IMU AHRS.
   Velodyne, 2018, VLP 16 US MAN.
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165.
   Verma S, 2019, IEEE INT C INTELL TR, P3906, DOI 10.1109/ITSC.2019.8917108.
   Yi SQ, 2019, IEEE INT C INTELL TR, P128, DOI 10.1109/ITSC.2019.8917305.
   Yi SQ, 2019, IEEE INT VEH SYM, P1247, DOI 10.1109/IVS.2019.8814106.
   Zhou W, 2020, IEEE INTEL TRANSP SY, V12, P23, DOI 10.1109/MITS.2020.2990183.},
Number-of-Cited-References = {41},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {IEEE Trans. Intell. Transp. Syst.},
Doc-Delivery-Number = {XT2UA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000733448000001},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000386705700002,
Author = {Karaoguz, Hakan and Bozma, H. Isil},
Title = {An integrated model of autonomous topological spatial cognition},
Journal = {AUTONOMOUS ROBOTS},
Year = {2016},
Volume = {40},
Number = {8},
Pages = {1379-1402},
Month = {DEC},
Abstract = {This paper is focused on endowing a mobile robot with topological
   spatial cognition. We propose an integrated model-where the concept of a
   `place' is defined as a collection of appearances or locations sharing
   common perceptual signatures or physical boundaries. In this model, as
   the robot navigates, places are detected in a systematic manner via
   monitoring coherency in the incoming visual data while pruning out
   uninformative or scanty data. Detected places are then either recognized
   or learned along with mapping as necessary. The novelties of the model
   are twofold: First, it explicitly incorporates a long-term spatial
   memory where the knowledge of learned places and their spatial relations
   are retained in place and map memories respectively. Second, the
   processing modules operate together so that the robot is able to build
   its spatial memory in an organized, incremental and unsupervised manner.
   Thus, the robot's long-term spatial memory evolves completely on its own
   while learned knowledge is organized based on appearance-related
   similarities in a manner that is amenable for higher-level semantic
   reasoning, As such, the proposed model constitutes a step forward
   towards having robots that are capable of interacting with their
   environments in an autonomous manner.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Karaoguz, H (Corresponding Author), Bogazici Univ, Intelligent Syst Lab, Elect \& Elect Engn, Istanbul, Turkey.
   Karaoguz, Hakan; Bozma, H. Isil, Bogazici Univ, Intelligent Syst Lab, Elect \& Elect Engn, Istanbul, Turkey.},
DOI = {10.1007/s10514-015-9514-4},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Spatial cognition; Long-term spatial memory; Place recognition},
Keywords-Plus = {SEMANTIC MAPS; LOOP CLOSURE; LARGE-SCALE; FAB-MAP; LOCALIZATION; VISION;
   SPACE},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {hakan.karaoguz@boun.edu.tr},
Affiliations = {Bogazici University},
ResearcherID-Numbers = {Bozma, Huriye Isil/A-2348-2017},
Funding-Acknowledgement = {Bogazici University BAP {[}9164]; Tubitak {[}EEAG 111E285]; Turkish
   State Planning Organization (DPT) under the TAM {[}2007K120610]},
Funding-Text = {This work has been supported in part by Bogazici University BAP Project
   9164 and Tubitak Project EEAG 111E285. The first author is supported by
   Turkish State Planning Organization (DPT) under the TAM Project number
   2007K120610.},
Cited-References = {Beeson P, 2010, INT J ROBOT RES, V29, P428, DOI 10.1177/0278364909100586.
   Casati R., 2002, TOPOLOGY COGNITION.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Chella Antonio, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P741, DOI 10.1109/IROS.2007.4399614.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Denis M, 2007, PSYCHOL RES-PSYCH FO, V71, P235, DOI 10.1007/s00426-006-0079-x.
   Dolins F. L., 2010, LINKING SPATIAL PERC.
   Erkent O, 2015, IEEE INT CONF ROBOT, P5462, DOI 10.1109/ICRA.2015.7139962.
   Erkent O, 2012, IEEE INT CONF ROBOT, P3497, DOI 10.1109/ICRA.2012.6225367.
   Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Karaoguz H, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P218, DOI 10.1109/ICAR.2015.7251459.
   Karaoguz H, 2014, IEEE INT CONF ROBOT, P697, DOI 10.1109/ICRA.2014.6906930.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5.
   Lim J, 2012, INT J ROBOT RES, V31, P1394, DOI 10.1177/0278364912461455.
   Liu M, 2012, IEEE INT CONF ROBOT, P3503, DOI 10.1109/ICRA.2012.6225040.
   Mozos OM, 2007, ROBOT AUTON SYST, V55, P391, DOI 10.1016/j.robot.2006.12.003.
   Martinez-Gomez J, 2011, IEEE INT CONF ROBOT, P1936, DOI 10.1109/ICRA.2011.5980102.
   Mozos O. M., 2007, P IEEE RSJ IROS WORK.
   Murphy L, 2014, IEEE INT CONF ROBOT, P1312, DOI 10.1109/ICRA.2014.6907022.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Posner I, 2008, SPRINGER TRAC ADV RO, V39, P85.
   Pronobis A, 2009, INT J ROBOT RES, V28, P588, DOI 10.1177/0278364909103912.
   Pronobis A, 2010, 11 INT C INT AUT SYS.
   Pronobis A, 2012, IEEE INT CONF ROBOT, P3515, DOI 10.1109/ICRA.2012.6224637.
   Ranganathan A., 2010, P ROB SCI SYST.
   Ranganathan A, 2012, AUTON ROBOT, V32, P351, DOI 10.1007/s10514-012-9273-4.
   Remolina E, 2004, ARTIF INTELL, V152, P47, DOI 10.1016/S0004-3702(03)00114-0.
   Robert L., 1997, SPATIAL COGNITION GE.
   Shi L, 2012, IEEE INT C INT ROBOT, P2991, DOI 10.1109/IROS.2012.6385549.
   SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Tapus A., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2429.
   TVERSKY B, 1983, COGNITIVE PSYCHOL, V15, P121, DOI 10.1016/0010-0285(83)90006-3.
   Tversky B., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT `93 Proceedings, P14.
   Tversky B., 2005, CAMBRIDGE HDB VISUOS, P1, DOI DOI 10.1017/CBO9780511610448.002.
   Ursic P, 2012, IEEE INT C INT ROBOT, P1371, DOI 10.1109/IROS.2012.6385546.
   Vasudevan S, 2008, ROBOT AUTON SYST, V56, P522, DOI 10.1016/j.robot.2008.03.005.
   Vasudevan S, 2007, ROBOT AUTON SYST, V55, P359, DOI 10.1016/j.robot.2006.12.008.
   Walter MR, 2014, INT J ROBOT RES, V33, P1167, DOI 10.1177/0278364914537359.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Yeh T, 2008, PROC CVPR IEEE, P61.
   Zivkovic Z., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P2480.
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.},
Number-of-Cited-References = {47},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {EA6AB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000386705700002},
DA = {2022-05-17},
}

@inproceedings{ WOS:000508184100157,
Author = {Berrio, Julie Stephany and Ward, James and Worrall, Stewart and Nebot,
   Eduardo},
Book-Group-Author = {IEEE},
Title = {Identifying robust landmarks in feature-based maps},
DOI = {10.1109/IVS.2019.8814289},
Booktitle = {2019 30TH IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV19)},
Series = {IEEE Intelligent Vehicles Symposium},
Year = {2019},
Pages = {1166-1172},
Note = {30th IEEE Intelligent Vehicles Symposium (IV), Paris, FRANCE, JUN 09-12,
   2019},
Abstract = {To operate in an urban environment, an automated vehicle must be capable
   of accurately estimating its position within a global map reference
   frame. This is necessary for optimal path planning and safe navigation.
   To accomplish this over an extended period of time, the global map
   requires long term maintenance. This includes the addition of newly
   observable features and the removal of transient features belonging to
   dynamic objects. The latter is especially important for the long-term
   use of the map as matching against a map with features that no longer
   exist can result in incorrect data associations, and consequently
   erroneous localisation. This paper addresses the problem of removing
   features from the map that correspond to objects that are no longer
   observable/present in the environment. This is achieved by assigning a
   single score which depends on the geometric distribution and
   characteristics when the features are re-detected (or not) on different
   occasions. Our approach not only eliminates ephemeral features, but can
   also be used as a reduction algorithm for highly dense maps. We tested
   our approach using half a year of weekly drives over the same 500 metre
   section of road in an urban environment. The results presented
   demonstrate the validity of the long term approach to map maintenance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Berrio, JS (Corresponding Author), Univ Sydney, ACFR, Sydney, NSW, Australia.
   Berrio, Julie Stephany; Ward, James; Worrall, Stewart; Nebot, Eduardo, Univ Sydney, ACFR, Sydney, NSW, Australia.},
ISSN = {1931-0587},
ISBN = {978-1-7281-0560-4},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Robotics; Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics; Transportation Science \&
   Technology},
Author-Email = {j.berrio@acfr.usyd.edu.au
   j.ward@acfr.usyd.edu.au
   s.worrall@acfr.usyd.edu.au
   e.nebot@acfr.usyd.edu.au},
Affiliations = {University of Sydney},
ResearcherID-Numbers = {Worrall, Stewart/AAB-4633-2020
   Perez, Julie Stephany Berrio/AAL-1008-2021},
ORCID-Numbers = {Worrall, Stewart/0000-0001-7940-4742
   Perez, Julie Stephany Berrio/0000-0003-3126-7042},
Funding-Acknowledgement = {ACFR; University of Sydney through the Dean of Engineering and
   Information Technologies PhD Scholarship (South America); Australian
   Research Council {[}DP160104081]; University of Michigan / Ford Motors
   Company Contract ``Next generation Vehicles{''}},
Funding-Text = {This work has been funded by the ACFR, the University of Sydney through
   the Dean of Engineering and Information Technologies PhD Scholarship
   (South America) and the Australian Research Council Discovery Grant
   DP160104081 and University of Michigan / Ford Motors Company Contract
   ``Next generation Vehicles{''}.},
Cited-References = {Burgard W., 2012, 26 AAAI C ART INT, P2024.
   Carneiro G, 2009, IMAGE VISION COMPUT, V27, P1143, DOI 10.1016/j.imavis.2008.10.015.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Guo R, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P1122.
   Kaeli J. W., 2014, AUTONOMOUS UNDERWATE, P1.
   Kim DI, 2015, INT CONF UBIQ ROBOT, P218, DOI 10.1109/URAI.2015.7358940.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Kuutti S, 2018, IEEE INTERNET THINGS, V5, P829, DOI 10.1109/JIOT.2018.2812300.
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562.
   Lynen S., 2015, ROBOTICS SCI SYSTEMS.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Nobre F, 2018, IEEE INT CONF ROBOT, P3661.
   Pomerleau F, 2014, IEEE INT CONF ROBOT, P3712, DOI 10.1109/ICRA.2014.6907397.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Siritanawan P, 2017, 2017 18TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P112, DOI 10.1109/ICAR.2017.8023504.
   VANI S M., 2017, 2017 SMART CIT S PRA, P1.
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165.
   Yi S., 2019, ARXIV190408585.
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x.},
Number-of-Cited-References = {22},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BO2SH},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000508184100157},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000709847700197,
Author = {Gunatilake, Amal and Galea, Mitchell and Thiyagarajan, Karthick and
   Kodagoda, Sarath and Piyathilaka, Lasitha and Darji, Poojaben},
Book-Group-Author = {IEEE},
Title = {Using UHF-RFID Signals for Robot Localization Inside Pipelines},
Booktitle = {PROCEEDINGS OF THE 2021 IEEE 16TH CONFERENCE ON INDUSTRIAL ELECTRONICS
   AND APPLICATIONS (ICIEA 2021)},
Series = {IEEE Conference on Industrial Electronics and Applications},
Year = {2021},
Pages = {1109-1114},
Note = {16th IEEE Conference on Industrial Electronics and Applications (ICIEA),
   Chengdu, PEOPLES R CHINA, AUG 01-04, 2021},
Abstract = {Underground water pipes are important to any country's infrastructure.
   Overtime, the metallic pipes are prone to corrosion, which can lead to
   water leakage and pipe bursts. In order to prolong the service life of
   those assets, water utilities in Australia apply protective pipe
   linings. Long-term monitoring and timely intervention are crucial for
   maintaining those lining assets. However, the water utilities do not
   possess the comprehensive technology to achieve it. The main reasons for
   lacking such technology are the unavailability of sensors and accurate
   robot localization technologies. Feature based localization methods such
   as SLAM has limited use as the application of liners alters the features
   and the environment. Encoder based localization is not accurate enough
   to observe the evolution of defects over a long period of time requiring
   unique defect correspondence. This motivates us to explore accurate
   contact-less and wireless based localization methods. We propose a
   cost-effective localization method using UHF-RFID signals for robot
   localization inside pipelines based on Gaussian process combined
   particle filter. Experiments carried out in field extracted pipe samples
   from the Sydney water pipe network show that using the RSSI and Phase
   data together in the measurement model with particle filter algorithm
   improves the localization accuracy up to 15 centimeters precision.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gunatilake, A (Corresponding Author), Univ Technol Sydney, Fac Engn \& Informat Technol, UTS Robot Inst, iPipes Lab, Sydney, NSW 2007, Australia.
   Gunatilake, Amal; Galea, Mitchell; Thiyagarajan, Karthick; Kodagoda, Sarath; Piyathilaka, Lasitha; Darji, Poojaben, Univ Technol Sydney, Fac Engn \& Informat Technol, UTS Robot Inst, iPipes Lab, Sydney, NSW 2007, Australia.},
DOI = {10.1109/ICIEA51954.2021.9516284},
ISSN = {2156-2318},
ISBN = {978-1-6654-2248-2},
Keywords = {infrastructure robotics; linings; localization; particle filter; pipes;
   robotics for smart cities; RFID; robotic inspections; UHF-RFID},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Industrial; Engineering, Electrical \& Electronic},
Author-Email = {Amal.D.Gunatilake@student.uts.edu.au
   Karthick.Thiyagarajan@uts.edu.au
   Sarath.Kodagoda@uts.edu.au
   lasithaya@gmail.com
   Poojaben.Darji@student.uts.edu.au},
Affiliations = {University of Technology Sydney},
ResearcherID-Numbers = {Kodagoda, Sarath/AAE-2801-2022
   },
ORCID-Numbers = {Kodagoda, Sarath/0000-0001-5175-9138
   Thiyagarajan, Karthick/0000-0002-4044-1711
   Gunatilake, Amal/0000-0001-7304-3472},
Funding-Acknowledgement = {University of Technology Sydney (UTS) through the Faculty of Engineering
   and Information Technology (FEIT) Tech Lab Blue Sky Research Grant},
Funding-Text = {This work was supported by the University of Technology Sydney (UTS)
   through the Faculty of Engineering and Information Technology (FEIT)
   Tech Lab Blue Sky Research Grant.},
Cited-References = {Amin EM, 2014, IEEE SENS J, V14, P140, DOI 10.1109/JSEN.2013.2278560.
   Ams M., 2017, 11 INT C SENS TECHN.
   Buffi A, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON RFID TECHNOLOGY \& APPLICATION (RFID-TA), P40, DOI 10.1109/RFID-TA.2017.8098872.
   CanalesCanales R.V, 2010, 2010 9 IEEE IAS INT, P1.
   Ellison D., 2010, GLOBAL REVIEW SPRAY.
   Gammoudi I.I, 2015, 2015 IEEE INT S ANT.
   Gunatilake A, 2021, IEEE SENS J, V21, P11926, DOI 10.1109/JSEN.2020.3040396.
   Gunatilake A, 2019, C IND ELECT APPL, P916, DOI 10.1109/ICIEA.2019.8834089.
   Ko NY, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT INTELLIGENCE (URAL), P350, DOI 10.1109/URAI.2012.6463013.
   Kodagoda S., 2019, P INT ASS AUT ROB CO, P735.
   Li C. C, IEEE J RADIO FREQUEN, V3.
   Martinelli F, 2015, IEEE T CONTR SYST T, V23, P1782, DOI 10.1109/TCST.2014.2386777.
   Rasmussen C.E, 2006, LEARNING, V2006.
   Rusu S.R, 2011, 2011 24 CAN C EL COM.
   Thiyagarajan K., IEEE ACCESS, V6.
   Thiyagarajan K.K., IEEE SENSORS J.
   Thiyagarajan K, 2020, C IND ELECT APPL, P200, DOI 10.1109/iciea48937.2020.9248217.
   Thiyagarajan K, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-34121-3.
   Ulapane N., 2021, IEEE SENSORS J, V21.
   Virtanen J, 2011, 2011 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS), P312, DOI 10.1109/SAS.2011.5739788.
   Yabo Xu, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1564, DOI 10.1109/IMCEC.2018.8469578.
   Zhang J, 2018, IEEE T IND ELECTRON, V65, P8250, DOI 10.1109/TIE.2018.2803720.},
Number-of-Cited-References = {22},
Times-Cited = {2},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BS3DX},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000709847700197},
DA = {2022-05-17},
}

@inproceedings{ WOS:000447330600005,
Author = {Hansen, Christoph and Fuerstenberg, Kay},
Editor = {Zachaus, C and Muller, B and Meyer, G},
Title = {Enabling Robust Localization for Automated Guided Carts in Dynamic
   Environments},
Booktitle = {ADVANCED MICROSYSTEMS FOR AUTOMOTIVE APPLICATIONS 2017: SMART SYSTEMS
   TRANSFORMING THE AUTOMOBILE},
Series = {Lecture Notes in Mobility},
Year = {2018},
Pages = {47-57},
Note = {21st International Forum on Advanced Microsystems for Automotive
   Applications (AMAA) - Smart Systems Transforming the Automobile, Berlin,
   GERMANY, SEP 25-26, 2017},
Abstract = {The range of applications for autonomous guided carts (AGC) is
   increasingly growing. Especially in industrial environments ensuring
   high safety standards in combination with high availability and
   flexibility are major requirements. For this reason, knowledge about its
   own position in the environments becomes particularly important. For AGC
   with low vehicle height localization approaches based on contour
   observations are widespread. However, in over-time-changing environments
   the robustness of these techniques is limited. This paper proposes an
   approach for updating the underlying map in real time during operation.
   This map update allows for a long-term robust localization. The proposed
   approach is evaluated for a dynamic test scenario using a cellular
   transport vehicle.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Hansen, C (Corresponding Author), SICK AG, Merkurring 41, D-22143 Hamburg, Germany.
   Hansen, Christoph, SICK AG, Merkurring 41, D-22143 Hamburg, Germany.
   Fuerstenberg, Kay, SICK AG, Erwin Sick Str 1, D-79183 Waldkirch, Germany.},
DOI = {10.1007/978-3-319-66972-4\_5},
ISSN = {2196-5544},
EISSN = {2196-5552},
ISBN = {978-3-319-66972-4; 978-3-319-66971-7},
Keywords = {Map update; Dynamic environment; Localization; Pose estimation; Long
   term; Robust; Accuracy evaluation; Autonomous guided vehicle; AGV;
   Autonomous guided cart; AGC; Industrial applications},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation; Transportation Science \& Technology},
Author-Email = {christoph.hansen@sick.de
   kay.fuerstenberg@sick.de},
Cited-References = {Behnke J, 2014, LOGISTISCHE REGRESSI.
   Beinschob P, 2015, INT C INTELL COMP CO, P245, DOI 10.1109/ICCP.2015.7312637.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Fernandez-Madrigal J.-A., 2012, SIMULTANEOUS LOCALIZ.
   Fox D, 2003, INT J ROBOT RES, V22, P985, DOI 10.1177/0278364903022012001.
   Fujii A, 2015, IEEE INT C INT ROBOT, P4313, DOI 10.1109/IROS.2015.7353988.
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396.
   Gutmann JS, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P736, DOI 10.1109/IROS.1998.727280.
   Kamagaew A, 2011, 5 INT C AUT ROB APPL, P4045.
   Kirsch C, 2002, COMP LOCALIZATION AL.
   Kirsch C, 2011, P 18 IFAC WORLD C MA.
   Kleiner A, 2011, IEEE INT C INT ROBOT, P3276, DOI 10.1109/IROS.2011.6048339.
   Meyer-Delius D, 2011, PROBABILISTIC MODELI.
   Mongillo G, 2008, NEURAL COMPUT, V20, P1706, DOI 10.1162/neco.2008.10-06-351.
   Pampel F. C., 2000, LOGISTIC REGRESSION, V132.
   SCHULZ D, 2003, P INT JOINT C ART IN, P921.
   Tipaldi GD, 2013, INT J ROBOT RES, V32, P1662, DOI 10.1177/0278364913502830.
   Valencia R, 2014, IEEE INT CONF ROBOT, P3956, DOI 10.1109/ICRA.2014.6907433.},
Number-of-Cited-References = {18},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BL1FZ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)},
Unique-ID = {WOS:000447330600005},
DA = {2022-05-17},
}

@article{ WOS:000353082700003,
Author = {Neubert, Peer and Suenderhauf, Niko and Protzel, Peter},
Title = {Superpixel-based appearance change prediction for long-term navigation
   across seasons},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2015},
Volume = {69},
Number = {SI},
Pages = {15-27},
Month = {JUL},
Abstract = {Changing environments pose a serious problem to current robotic systems
   aiming at long term operation under varying seasons or local weather
   conditions. This paper is built on our previous work where we propose to
   learn to predict the changes in an environment. Our key insight is that
   the occurring scene changes are in part systematic, repeatable and
   therefore predictable. The goal of our work is to support existing
   approaches to place recognition by learning how the visual appearance of
   an environment changes over time and by using this learned knowledge to
   predict its appearance under different environmental conditions. We
   describe the general idea of appearance change prediction (ACP) and
   investigate properties of our novel implementation based on vocabularies
   of superpixels (SP-ACP). Our previous work showed that the proposed
   approach significantly improves the performance of SeqSLAM and
   BRIEF-Gist for place recognition on a subset of the Nordland dataset
   under extremely different environmental conditions in summer and winter.
   This paper deepens the understanding of the proposed SP-ACP system and
   evaluates the influence of its parameters. We present the results of a
   large-scale experiment on the complete 10 h Nordland dataset and
   appearance change predictions between different combinations of seasons.
   (C) 2014 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Neubert, P (Corresponding Author), Tech Univ Chemnitz, Dept Elect Engn \& Informat Technol, D-09111 Chemnitz, Germany.
   Neubert, Peer; Suenderhauf, Niko; Protzel, Peter, Tech Univ Chemnitz, Dept Elect Engn \& Informat Technol, D-09111 Chemnitz, Germany.},
DOI = {10.1016/j.robot.2014.08.005},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Appearance change prediction; Long term navigation; Place recognition;
   Appearance based localization; Changing environments},
Keywords-Plus = {MAP},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {peer.neubert@etit.tu-chemnitz.de},
Affiliations = {Technische Universitat Chemnitz},
ResearcherID-Numbers = {Sünderhauf, Niko/O-2192-2017},
ORCID-Numbers = {Sünderhauf, Niko/0000-0001-5286-3789},
Cited-References = {Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120.
   Badino H, 2011, IEEE INT CONF ROBOT.
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Churchill W., 2012, INT C ROB AUT ICRA.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Efros AA, 2001, COMP GRAPH, P341.
   Glover A., 2010, INT C ROB AUT ICRA.
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x.
   He XM, 2006, J FIELD ROBOT, V23, P1091, DOI 10.1002/rob.20170.
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295.
   Johannsson H, 2012, RSS WORKSH LONG TERM.
   Konolige K., 2009, INT C INT ROB SYST I.
   Liu C., 2008, EUR C COMP VIS ECCV.
   Maddern W., 2012, ROB SCI SYST C RSS.
   Milford M., 2013, IEEE INT C ROB AUT.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Neubert P., 2013, EUR C MOB ROB ECMR.
   Protzel P., 2013, P INT C ROB AUT ICRA.
   Ren X., 2003, INT C COMP VIS ICCV.
   Sunderhauf N., 2013, WORKSH LONG TERM AUT.
   Sunderhauf N., 2011, INT C INT ROB SYST I.
   Tighe J., 2010, EUR C COMP VIS ECCV.
   Torralba A., 2003, INT C COMP VIS ICCV.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Zhang W., 2005, C COMP VIS PATT REC.},
Number-of-Cited-References = {26},
Times-Cited = {47},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {CG2CO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000353082700003},
DA = {2022-05-17},
}

@article{ WOS:000320103400008,
Author = {Brunner, Christopher and Peynot, Thierry and Vidal-Calleja, Teresa and
   Underwood, James},
Title = {Selective Combination of Visual and Thermal Imaging for Resilient
   Localization in Adverse Conditions: Day and Night, Smoke and Fire},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2013},
Volume = {30},
Number = {4},
Pages = {641-666},
Month = {JUL-AUG},
Abstract = {Long-term autonomy in robotics requires perception systems that are
   resilient to unusual but realistic conditions that will eventually occur
   during extended missions. For example, unmanned ground vehicles (UGVs)
   need to be capable of operating safely in adverse and low-visibility
   conditions, such as at night or in the presence of smoke. The key to a
   resilient UGV perception system lies in the use of multiple sensor
   modalities, e.g., operating at different frequencies of the
   electromagnetic spectrum, to compensate for the limitations of a single
   sensor type. In this paper, visual and infrared imaging are combined in
   a Visual-SLAM algorithm to achieve localization. We propose to evaluate
   the quality of data provided by each sensor modality prior to data
   combination. This evaluation is used to discard low-quality data, i.e.,
   data most likely to induce large localization errors. In this way,
   perceptual failures are anticipated and mitigated. An extensive
   experimental evaluation is conducted on data sets collected with a UGV
   in a range of environments and adverse conditions, including the
   presence of smoke (obstructing the visual camera), fire, extreme heat
   (saturating the infrared camera), low-light conditions (dusk), and at
   night with sudden variations of artificial light. A total of 240
   trajectory estimates are obtained using five different variations of
   data sources and data combination strategies in the localization method.
   In particular, the proposed approach for selective data combination is
   compared to methods using a single sensor type or combining both
   modalities without preselection. We show that the proposed framework
   allows for camera-based localization resilient to a large range of
   low-visibility conditions. (C) 2013 Wiley Periodicals, Inc.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Brunner, C (Corresponding Author), Univ Sydney, Australian Ctr Field Robot, Sydney, NSW 2006, Australia.
   Brunner, Christopher; Peynot, Thierry; Underwood, James, Univ Sydney, Australian Ctr Field Robot, Sydney, NSW 2006, Australia.
   Vidal-Calleja, Teresa, Univ Technol Sydney, Ctr Autonomous Syst, Fac Engn \& IT, Sydney, NSW 2007, Australia.},
DOI = {10.1002/rob.21464},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords-Plus = {PERCEPTION; IMAGES; FUSION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {brunner.university@gmail.com
   tpeynot@acfr.usyd.edu.au
   Teresa.VidalCalleja@uts.edu.au
   j.underwood@acfr.usyd.edu.au},
Affiliations = {University of Sydney; University of Technology Sydney},
ORCID-Numbers = {Underwood, James/0000-0003-0189-0706
   Vidal-Calleja, Teresa/0000-0002-5763-9644},
Funding-Acknowledgement = {Australian Centre for Field Robotics (ACFR); Centre for Intelligent
   Mobile Systems (CIMS); BAE Systems; University of Sydney; New South
   Wales State Government},
Funding-Text = {This work was supported in part by the Australian Centre for Field
   Robotics (ACFR), by the Centre for Intelligent Mobile Systems (CIMS),
   funded by BAE Systems as part of an ongoing partnership with the
   University of Sydney, and by the New South Wales State Government. The
   authors would like to thank Joan Sola for software collaboration and
   Matthieu Simmoneau for his contribution to code development.},
Cited-References = {Borges P., 2010, IEEE INT C ROB AUT.
   Brooker G., 2009, INTRO SENSORS RANGIN.
   Brunner C., 2009, ARAA AUSTR C ROB AUT.
   Brunner C., 2010, INT S EXP ROB DELH I.
   Brunner C., 2011, INT J INTELLIGENT CO, V16, P142.
   Brunner C, 2011, IEEE INT C INT ROBOT.
   Burgard W., 2009, IEEE RSJ INT C INT R.
   Carlson J., 2005, USE DEMPSTER SHAFER.
   Castro M., 2012, ARAA AUSTR C ROB AUT.
   Davison A., 2003, INT C COMP VIS NIC F.
   Davison A. J., 2005, INT C COMP VIS LOS A.
   Dubbelman G., 2007, IEEE RSJ INT C INT R.
   Fay D., 2000, INT C INF FUS PAR FR.
   Ferwerda J., 1996, ANN C COMP GRAPH INT.
   Finlayson G., 2006, EUR C COMP VIS.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Foyle D., 1993, SAE T, P101.
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001.
   Green D. M, 1989, SIGNAL DETECTION THE.
   Gu XD, 2005, IEEE T NEURAL NETWOR, V16, P692, DOI 10.1109/TNN.2005.844902.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Hines G., 2005, SPIE ENHANCED SYNTHE.
   ITU-T RECOMMENDATION P, 1999, SUBJ VID QUAL ASS ME.
   Jung I., 2003, INT C COMP VIS NIC F.
   Kelly A, 2006, INT J ROBOT RES, V25, P449, DOI 10.1177/0278364906065543.
   Kobayashi M., 2010, INT C MULT COMP INF.
   Lanir J., 2006, IEEE INT C INF FUS.
   Leonard J, 2008, J FIELD ROBOT, V25, P727, DOI 10.1002/rob.20262.
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Luo R., 2003, IEEE INT C ROB AUT.
   MacKay D. J. C., 2007, INFORM THEORY INFERE.
   Maddern W., 2012, LASER VISION ALTERNA.
   Martinsen G., 2008, P SPIE.
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188.
   Montiel J. M. M., 2006, ROBOTICS SCI SYSTEMS.
   Moreno-Noguer F., 2011, IEEE C COMP VIS PATT.
   NANDHAKUMAR N, 1988, IEEE T PATTERN ANAL, V10, P469, DOI 10.1109/34.3911.
   Narasimhan S., 2003, IEEE COMP SOC C COMP.
   Nayar S., 1999, INT C COMP VIS CORF.
   Nuske S, 2009, J FIELD ROBOT, V26, P728, DOI 10.1002/rob.20306.
   Owens K., 1999, IEEE WORKSH COMP VIS.
   Paz LM, 2008, IEEE T ROBOT, V24, P946, DOI 10.1109/TRO.2008.2004637.
   Pearsall J., 1999, CONCISE OXFORD DICT.
   Perbet J., 1993, INT S HEAD DISPL ENH.
   Peynot T., 2009, IEEE RSJ INT C INT R.
   Peynot T, 2010, IEEE INT C INT ROBOT.
   Peynot T, 2010, INT J ROBOT RES, V29, P1602, DOI 10.1177/0278364910384638.
   Roberts J., 2008, 6 IARP INT RAS EURON.
   Sadjadi F., 2005, IEEE COMP SOC C COMP.
   Scandaliaris J., 2010, INT C PATT REC IST T.
   Scanlan J., 1990, INT C AC SPEECH SIGN.
   Sola J, 2008, IEEE T ROBOT, V24, P958, DOI 10.1109/TRO.2008.2004640.
   Soleimanpour S., 2008, IEEE INT C CYB INT S.
   Tan R., 2008, IEEE C COMP VIS PATT.
   Thrun S., 2007, STANLEY ROBOT WON DA.
   Thrun S., 2006, IEEE ACM INT C AUT S.
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034.
   Toet A., 2003, Information Fusion, V4, P155, DOI 10.1016/S1566-2535(03)00038-1.
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552.
   Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087.
   Toth D., 2000, IEEE SW S IM AN INT.
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554.
   Underwood J., 2009, THESIS U SYDNEY SYDN.
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255.
   VEDALDI A., 2008, VLFEAT OPEN PORTABLE.
   Vidal-Calleja TA, 2011, ROBOT AUTON SYST, V59, P654, DOI 10.1016/j.robot.2011.05.008.
   Wang Z., 2006, MODERN IMAGE QUALITY.
   Ward Greg, 1994, CONTRAST BASED SCALE.
   Waxman A. M., 1998, Lincoln Laboratory Journal, V11, P41.
   Waxman AM, 1997, NEURAL NETWORKS, V10, P1, DOI 10.1016/S0893-6080(96)00057-3.
   Winkler S., 2005, DIGITAL VIDEO QUALIT.
   Yu YN, 2012, IEEE T IMAGE PROCESS, V21, P229, DOI 10.1109/TIP.2011.2160271.
   Zabih R, 1996, IEEE T PATTERN ANAL.
   Zitova B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9.},
Number-of-Cited-References = {75},
Times-Cited = {31},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {18},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {160FR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000320103400008},
OA = {Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000555890700164,
Author = {Pitsch, Meredith L. and Pryor, Mitchell W.},
Editor = {Okamura, AM and Amato, N and Asfour, T and Choi, YJ and Chong, NY and Ding, H and Lee, DH and Lerma, CC and Li, JS and Marchand, E and Popa, D and Song, DZ and Sun, Y and Valdastri, P},
Title = {Obstacle Persistent Adaptive Map Maintenance for Autonomous Mobile
   Robots using Spatio-temporal Reasoning},
DOI = {10.1109/COASE.2019.8843095},
Booktitle = {2019 IEEE 15TH INTERNATIONAL CONFERENCE ON AUTOMATION SCIENCE AND
   ENGINEERING (CASE)},
Series = {IEEE International Conference on Automation Science and Engineering},
Year = {2019},
Pages = {1023-1028},
Note = {15th IEEE International Conference on Automation Science and Engineering
   (IEEE CASE), Vancouver, CANADA, AUG 22-26, 2019},
Abstract = {Mobile robotic systems operate in increasingly realistic scenarios even
   as users have increased expectations for the duration of autonomous
   tasks. Mobile robots face unique challenges when operating in
   environments that change over time, where systems must maintain an
   accurate representation of the environment with respect to both spatial
   and temporal dimensions. This paper describes a spatio-temporal
   technique for extending the autonomy of a mobile robot in a changing
   environment. This new technique called Obstacle Persistent Adaptive Map
   Maintenance (OPAMM) uses navigation data collected during normal
   operations to perform periodic self-maintenance of its environment
   model. OPAMM implements a probabilistic feature persistence model to
   predict the survival state of obstacles and update the world model.
   Maintaining an accurate world model is necessary for extending the
   long-term autonomy of robots in realistic scenarios. Results show that
   robots using OPAMM had localizations scores higher than other methods,
   thus reducing long-term localization degradation.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pitsch, ML (Corresponding Author), Univ Texas Austin, Dept Mech Engn, Austin, TX 78758 USA.
   Pitsch, Meredith L.; Pryor, Mitchell W., Univ Texas Austin, Dept Mech Engn, Austin, TX 78758 USA.},
ISSN = {2161-8070},
ISBN = {978-1-7281-0356-3},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Computer Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial Intelligence},
Author-Email = {pitschm1@utexas.edu
   mpryor@utexas.edu},
Affiliations = {University of Texas System; University of Texas Austin},
Funding-Acknowledgement = {Los Alamos National Laboratory (LANL)},
Funding-Text = {This work was supported by Los Alamos National Laboratory (LANL).},
Cited-References = {Beer JM, 2014, J HUM-ROBOT INTERACT, V3, P74, DOI 10.5898/JHRI.3.2.Beer.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Biswas J., 2014, VECTOR MAP BASED NON.
   Biswas J, 2014, IEEE INT CONF ROBOT, P3969, DOI 10.1109/ICRA.2014.6907435.
   Choset H., 2010, PRINCIPLES ROBOT MOT, V2005, P603.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Fentanes JP, 2015, IEEE INT CONF ROBOT, P1112, DOI 10.1109/ICRA.2015.7139315.
   Ilahnel D., 2003 IEEE INT C ROB.
   Koch K.R., INTRO BAYESIAN STAT.
   Konolige K., 2009, 2009 IEEE RSJ INT C.
   Krajnik T., 2014, 2014 IEEE INT C ROB.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Meyer-Delius D., 2010, 2010 IEEE RSJ INT C.
   Naseer T, 2017, ROBOT AUTON SYST, V89, P147, DOI 10.1016/j.robot.2016.11.008.
   Pitsch M. I, 2018, SPATIO TEMPORAL MAP.
   Rosen D. M., 2016, P IEEE INT C ROB RAO.
   Saarinen J., 2012, 2012 IEEE RSJ INT C.
   Santos JM, 2013, IEEE INT SYMP SAFE.
   Santos JM, 2017, ROBOT AUTON SYST, V88, P116, DOI 10.1016/j.robot.2016.11.016.
   Stachniss C., 2005, P C ART INT, P1324.
   Suarez C., 2019, WASTE ALANAGEMENT S.
   Thrun S., 2002, ROBOTIC MAPPING SURV.
   Thrun S., 1999, PROBABILISTIC ROBOTI.
   Walcott-Bryant A., 2012, IEEE INT C INT ROB S.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.},
Number-of-Cited-References = {28},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BP5KA},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000555890700164},
DA = {2022-05-17},
}

@inproceedings{ WOS:000542960700081,
Author = {Patel, Naman and Khorrami, Farshad and Krishnamurthy, Prashanth and
   Tzes, Anthony},
Book-Group-Author = {IEEE},
Title = {Tightly Coupled Semantic RGB-D Inertial Odometry for Accurate Long-Term
   Localization and Mapping},
DOI = {10.1109/ICAR46387.2019.8981658},
Booktitle = {2019 19TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR)},
Year = {2019},
Pages = {523-528},
Note = {19th International Conference on Advanced Robotics (ICAR), Belo
   Horizonte, BRAZIL, DEC 02-06, 2019},
Abstract = {In this paper, we utilize semantically enhanced feature matching and
   visual inertial bundle adjustment to improve the robustness of odometry
   especially in feature-sparse environments. A novel semantically enhanced
   feature matching algorithm is developed for robust: 1) medium and
   long-term tracking, and 2) loop-closing. Additionally, a semantic visual
   inertial bundle adjustment algorithm is introduced to robustly estimate
   pose in presence of ambiguous correspondences or in feature sparse
   environment. Our tightly coupled semantic RGB-D odometry approach is
   demonstrated on a real world indoor dataset collected using our unmanned
   ground vehicle (UGV). Our approach improves traditional visual odometry
   relying on low-level geometric features like corners, points, and planes
   for localization and mapping. Additionally, prior approaches are limited
   due to their sensitivity to scene geometry and changes in light
   intensity. The semantic inertial odometry is especially important to
   significantly reduce drifts in longer intervals.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Patel, N (Corresponding Author), NYU, Dept Elect \& Comp Engn, Tandon Sch Engn, 6 MetroTech Ctr, Brooklyn, NY 11201 USA.
   Patel, Naman; Khorrami, Farshad; Krishnamurthy, Prashanth, NYU, Dept Elect \& Comp Engn, Tandon Sch Engn, 6 MetroTech Ctr, Brooklyn, NY 11201 USA.
   Tzes, Anthony, NYU Abu Dhabi, Engn Div, Abu Dhabi 129188, U Arab Emirates.},
ISBN = {978-1-7281-2467-4},
Keywords-Plus = {ROBUST},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {naman.patel@nyu.edu
   khorrami@nyu.edu
   prashanth.krishnamurthy@nyu.edu
   anthony.tzes@nyu.edu},
Affiliations = {New York University; New York University Tandon School of Engineering},
ORCID-Numbers = {Khorrami, Farshad/0000-0002-8418-004X},
Cited-References = {Atanasov N., 2018, P 27 INT JOINT C ART, P5204, DOI DOI 10.24963/IJCAI.2018/722.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Caruso D, 2015, IEEE INT C INT ROBOT, P141, DOI 10.1109/IROS.2015.7353366.
   Civera J, 2011, IEEE INT C INT ROBOT, P1277, DOI 10.1109/IROS.2011.6048293.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Jung SH, 2001, PROC CVPR IEEE, P732.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Klein George, 2007, P1.
   Koltun V., 2015, MULTISCALE CONTEXT A.
   Kottas DG, 2013, IEEE INT CONF ROBOT, P1540, DOI 10.1109/ICRA.2013.6630775.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Patel N., 2018, P 50 INT S ROB MUN G, P352.
   Patel N, 2019, ROBOT AUTON SYST, V116, P80, DOI 10.1016/j.robot.2019.03.001.
   Patel N, 2017, IEEE INT C INT ROBOT, P1531, DOI 10.1109/IROS.2017.8205958.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Strelow D, 2004, INT J ROBOT RES, V23, P1157, DOI 10.1177/0278364904045593.
   Tue-Cuong Dong-Si, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5655, DOI 10.1109/ICRA.2011.5980267.
   Unlu HU, 2019, IEEE ROBOT AUTOM LET, V4, P4216, DOI 10.1109/LRA.2019.2930475.
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008.
   Yang SC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1222, DOI 10.1109/IROS.2016.7759204.
   Zhang J, 2017, AUTON ROBOT, V41, P31, DOI {[}10.1007/s10514-015-9525-1, 10.1109/MWSYM.2015.7167049].
   Zhou B., 2016, ARXIV160805442.},
Number-of-Cited-References = {28},
Times-Cited = {3},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP2KJ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000542960700081},
DA = {2022-05-17},
}

@article{ WOS:000291241400004,
Author = {Dayoub, Feras and Cielniak, Grzegorz and Duckett, Tom},
Title = {Long-term experiments with an adaptive spherical view representation for
   navigation in changing environments},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2011},
Volume = {59},
Number = {5, SI},
Pages = {285-295},
Month = {MAY},
Note = {4th European Conference on Mobile Robots, Dubrovnik, CROATIA, SEP 23-25,
   2009},
Abstract = {Real-world environments such as houses and offices change over time,
   meaning that a mobile robot's map will become out of date. In this work,
   we introduce a method to update the reference views in a hybrid
   metric-topological map so that a mobile robot can continue to localize
   itself in a changing environment. The updating mechanism, based on the
   multi-store model of human memory, incorporates a spherical metric
   representation of the observed visual features for each node in the map,
   which enables the robot to estimate its heading and navigate using
   multi-view geometry, as well as representing the local 3D geometry of
   the environment. A series of experiments demonstrate the persistence
   performance of the proposed system in real changing environments,
   including analysis of the long-term stability. (C) 2011 Elsevier B.V.
   All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Dayoub, F (Corresponding Author), Lincoln Univ, Sch Comp Sci, Lincoln LN6 7TS, England.
   Dayoub, Feras; Cielniak, Grzegorz; Duckett, Tom, Lincoln Univ, Sch Comp Sci, Lincoln LN6 7TS, England.},
DOI = {10.1016/j.robot.2011.02.013},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Persistent mapping; Omnidirectional vision; Mobile robot navigation},
Keywords-Plus = {LOCALIZATION; SCENE},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {fdayoub@lincoln.ac.uk
   gcielniak@lincoln.ac.uk
   tduckett@lincoln.ac.uk},
Affiliations = {University of Lincoln},
ResearcherID-Numbers = {Cielniak, Grzegorz/AAS-5387-2020
   },
ORCID-Numbers = {Cielniak, Grzegorz/0000-0002-6299-8465
   Dayoub, Feras/0000-0002-4234-7374},
Cited-References = {AKIHIKO T, 2005, IEIC TECHNICAL REPOR, V105, P29.
   Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI {[}10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3].
   BANDARI E, BMVA S SPAT IM PROC.
   Bay H., 2006, P EUR C COMP VIS ECC.
   BIBBY C, 2007, P ROB SCI SYST RSS A.
   BOOIJ O, P IEEE INT C ROB AUT.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Elinas P, 2006, IEEE INT CONF ROBOT, P1564, DOI 10.1109/ROBOT.2006.1641930.
   Ess A., 2008, P IEEE C COMP VIS PA.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   FRAUNDORFER C, 2007, P IEEE INT C INT ROB.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   GROSS H, 2003, P IEEE INT C INT ROB.
   Guerrero JJ, 2008, IEEE T ROBOT, V24, P494, DOI 10.1109/TRO.2008.918043.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443.
   HOWARD A, LASER STABILIZED ODO.
   ILA V, IEEE T ROBOTICS.
   Kang SB, 1997, INT J COMPUT VISION, V25, P167, DOI 10.1023/A:1007971901577.
   Kosecka J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008.
   Kuipers B., 1993, LEARNING ROBOTS, V8, P47.
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006.
   Menegatti E, 2004, ROBOT AUTON SYST, V48, P17, DOI 10.1016/j.robot.2004.05.003.
   Nister D., 2006, P IEEE C COMP VIS PA.
   SCARAMUZZA D, P IEEE INT C INT SYS.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   Sivic J., 2003, P IEEE INT C COMP VI.
   Uhlmann J., 1997, INT S AER DEF SENS S, V3, P26.
   UHLMANN JK, THESIS U OXFORD OXFO.
   Ulrich I., 2000, P IEEE INT C ROB AUT.
   VALGREN C, 2006, P IEEE INT C INT ROB.
   VLASSIS N, 2002, P IEEE INT C ROB AUT.
   Wang CC, 2003, IEEE INT CONF ROBOT, P842.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.},
Number-of-Cited-References = {39},
Times-Cited = {35},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {772NU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000291241400004},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000284356200080,
Author = {Ascher, Christian and Kessler, Christoph and Wankerl, Matthias and
   Trommer, Gert F.},
Book-Author = {Wang, J
   Feng, Y
   Wang, C},
Title = {Using OrthoSLAM and Aiding Techniques for Precise Pedestrian Indoor
   Navigation},
Url = {https://www.ion.org/publications/abstract.cfm?articleID=8480},
Booktitle = {PROCEEDINGS OF THE 22ND INTERNATIONAL TECHNICAL MEETING OF THE SATELLITE
   DIVISION OF THE INSTITUTE OF NAVIGATION (ION GNSS 2009)},
Series = {Institute of Navigation Satellite Division Proceedings of the
   International Technical Meeting},
Year = {2009},
Pages = {743-749},
Note = {22nd International Technical Meeting of the Satellite Division of the
   Institute-of-Navigation (ION GNSS-09), Savannah, GA, SEP 22-25, 2009},
Abstract = {An Integrated Pedestrian Navigation System (IPNS) for precise indoor
   localization is presented in this paper. A laser scanner enables mapping
   and long-term stability of the navigation solution.
   Reliable information about personnel positions and escape routes is a
   crucial factor in many security or first responder missions. Especially
   in indoor scenarios in previously unknown environments, precise
   localization within the explored surroundings is essential for effective
   coordination. Therefore, a robust and accurate indoor IPNS with mapping
   capabilities enables fast and successful missions and reduces risk for
   the deployed personnel.
   However, the mentioned applications make high demands on navigational
   hard-and software. Tracking highly dynamic motions is required as well
   as providing a long-term accurate navigation estimation, even without
   reliable satellite navigation signals. The pedestrian navigation system
   has to be portable, light and small, which leads to limited
   computational power being available. Deployment in unknown environments
   requires use of exteroceptive sensors and mapping techniques.
   Our proposal is an Integrated Pedestrian Navigation System comprising
   two inertial measurements units (IMUs), mounted at the foot and the
   torso, a magnetometer and a barometer, aided by a two-dimensional laser
   scanner. The navigation solution is obtained by a Strapdown approach,
   with Zero Velocity Updates used as aiding technique. The laser scanner
   enables mapping of the surrounding structure and guarantees long-term
   accuracy of the position and attitude estimation. The scan data is
   processed using an Orthogonal Simultaneous Localization and Mapping
   (OrthoSLAM) technique. In this approach, a reduction of required
   computational power is reached by considering only straight and
   perpendicular structures. OrthoSLAM exploits the fact that man-made
   buildings consist of orthogonal structures to a large extent and
   provides long-term stable navigation aiding at low computational cost.
   Therefore, this method is targeted to the special conditions of indoor
   navigation.
   First results indicate that the combined Dual-IMU/magnetometer/laser
   system can meet the challenging requirements of pedestrian indoor
   navigation. The capabilities of our approach will be demonstrated using
   post-processed data obtained in real-world test scenarios.},
Publisher = {INST NAVIGATION},
Address = {815 15TH ST NW, STE 832, WASHINGTON, DC 20005 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ascher, C (Corresponding Author), Univ Karlsruhe, Inst Syst Optimizat, Karlsruhe, Germany.
   Ascher, Christian; Kessler, Christoph; Wankerl, Matthias; Trommer, Gert F., Univ Karlsruhe, Inst Syst Optimizat, Karlsruhe, Germany.},
ISSN = {2331-5911},
EISSN = {2331-5954},
Keywords-Plus = {SAFE NAVIGATION; MOBILE ROBOTS},
Research-Areas = {Computer Science; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Telecommunications},
Affiliations = {Helmholtz Association; Karlsruhe Institute of Technology},
Cited-References = {Borges GA, 2000, INT C PATT RECOG, P441, DOI 10.1109/ICPR.2000.905371.
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903.
   Foxlin E, 2005, IEEE COMPUT GRAPH, V25, P38, DOI 10.1109/MCG.2005.140.
   Nguyen V, 2005, 2005 2nd IEEE International Conference on Group IV Photonics, P195.
   Nguyen V, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P664.
   Nguyen V, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5007, DOI 10.1109/IROS.2006.282527.
   OJEDA L, 2007, IEEE P INT WORKSH SA.
   SHIN SH, 2007, SAS 2007 IEEE SENS A.
   Victorino AC, 2003, INT J ROBOT RES, V22, P1019, DOI 10.1177/0278364903022012003.
   Victorino AC, 2003, INT J ROBOT RES, V22, P1005, DOI 10.1177/0278364903022012002.
   Wendel J., 2007, INTEGRIERTE NAVIGATI.},
Number-of-Cited-References = {11},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BSG19},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000284356200080},
DA = {2022-05-17},
}

@article{ WOS:000451130100001,
Author = {Zhu, Chaozheng and He, Ming and Chen, Pan and Sun, Kang and Wang,
   Jinglei and Huang, Qian},
Title = {Navigation for Indoor Robot: Straight Line Movement via Navigator},
Journal = {MATHEMATICAL PROBLEMS IN ENGINEERING},
Year = {2018},
Volume = {2018},
Pages = {8419384},
Abstract = {Due to the need of zigzag overlay strategy, long-term linear motion is
   essential for sweep robot. However, the existing indoor sweep robot
   navigation algorithm has many problems; for instance, algorithm with
   high complexity demands high hardware performance and is incapable of
   working at night. To overcome those problems, in this paper, a new
   method for indoor robot Straight Line Movement via Navigator (SLMN) is
   proposed to ensure long linear motion of robot with an acceptable error
   threshold and realize multiroom navigation. Firstly, in a short time,
   robot runs a suitable distance when it is covered by navigator's
   ultrasonic sensor. We can obtain a triangle with twice the distance
   between navigator and robot and the distance of robot motion. The
   forward angle of the robot can be conveniently obtained by the
   trigonometric functions. Comparing the robot's current angle with
   expected angle, the robot could correct itself and realize the indoor
   linear navigation. Secondly, discovering dozens of the magnitude gaps
   between the distance of robot run and the distance between navigator and
   robot, we propose an optimized method using approximate scaling which
   increases efficiency by nearly 70.8\%. Finally, to realize multiroom
   navigation, we introduce the conception of the depth-first search stack
   and a unique encode rule on rooms and navigators. It is proved by
   extensive quantitative evaluations that the proposed method realizes
   indoor full coverage at a lower cost than other state-of-the-art indoor
   vision navigation schemes, such as ORB-SLAM.},
Publisher = {HINDAWI LTD},
Address = {ADAM HOUSE, 3RD FLR, 1 FITZROY SQ, LONDON, W1T 5HF, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {He, M (Corresponding Author), Army Engn Univ PLA, Coll Command \& Control Engn, Nanjing 210007, Jiangsu, Peoples R China.
   He, M (Corresponding Author), Acad Mil Med Sci, Inst Network Informat, Inst Syst Engn, Beijing 100071, Peoples R China.
   Zhu, Chaozheng; He, Ming, Army Engn Univ PLA, Coll Command \& Control Engn, Nanjing 210007, Jiangsu, Peoples R China.
   He, Ming, Acad Mil Med Sci, Inst Network Informat, Inst Syst Engn, Beijing 100071, Peoples R China.
   Chen, Pan; Huang, Qian, Hohai Univ, Coll Comp \& Informat, Nanjing 211100, Jiangsu, Peoples R China.
   Sun, Kang, Hohai Univ, Coll Energy \& Elect Engn, Nanjing 211100, Jiangsu, Peoples R China.
   Wang, Jinglei, Nanjing Univ Sci \& Technol, Sch Elect \& Opt Engn, Nanjing 210094, Jiangsu, Peoples R China.
   Huang, Qian, Jilin Univ, Minist Educ, Key Lab Symbol Computat \& Knowledge Engn, Changchun 130012, Jilin, Peoples R China.},
DOI = {10.1155/2018/8419384},
Article-Number = {8419384},
ISSN = {1024-123X},
EISSN = {1563-5147},
Research-Areas = {Engineering; Mathematics},
Web-of-Science-Categories  = {Engineering, Multidisciplinary; Mathematics, Interdisciplinary
   Applications},
Author-Email = {paper\_review@126.com},
Affiliations = {Army Engineering University of PLA; Academy of Military Medical Sciences
   - China; Hohai University; Hohai University; Nanjing University of
   Science \& Technology; Jilin University},
ORCID-Numbers = {Zhu, Chaozheng/0000-0002-6216-7186},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018YFC0806900, 2016YFC0800606,
   2016YFC0800310, 2018YFC0407905]; Natural Science Foundation of Jiangsu
   Province {[}BK20150721, BK20161469]; Primary Research \& Development
   Plan of Jiangsu Province {[}BE2015728, BE2016904, BE2017616, BE2018754]},
Funding-Text = {This work was supported by National Key R\&D Program of China Nos.
   2018YFC0806900, 2016YFC0800606, 2016YFC0800310, and 2018YFC0407905;
   Natural Science Foundation of Jiangsu Province under Grants Nos.
   BK20150721 and BK20161469; and Primary Research \& Development Plan of
   Jiangsu Province under Grants Nos. BE2015728, BE2016904, BE2017616, and
   BE2018754.},
Cited-References = {Astrom K., 1995, PID CONTROLLERS THEO, Vsecond.
   Banner A., 2009, CALCULUS LIFESAVER.
   Barshan B., 1998, IEEE T ROBOTIC AUTOM, V11, P328.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Han D, 2014, IEEE PERVAS COMPUT, V13, P72, DOI 10.1109/MPRV.2014.24.
   Hcormen T., 2013, INTRO ALGORITHMS, V39.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Jia-jun L., 2016, J GUANGDONG U TECHNO.
   Jimenez A R, 2010, Proceedings of the 2010 7th Workshop on Positioning, Navigation and Communication (WPNC 2010), P135, DOI 10.1109/WPNC.2010.5649300.
   Joy N, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING, VLSI, ELECTRICAL CIRCUITS AND ROBOTICS (DISCOVER), P7, DOI 10.1109/DISCOVER.2016.7806217.
   Krejsa J, 2012, ELEKTRON ELEKTROTECH, V117, P17, DOI 10.5755/j01.eee.117.1.1046.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Li Bo-wen, 2014, Journal of Chinese Inertial Technology, V22, P719, DOI 10.13695/j.cnki.12-1222/o3.2014.06.004.
   Lin P, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/371456.
   Liu GX, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P945, DOI 10.1109/ICCNC.2015.7069473.
   Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917.
   Mehlhorn K., 2017, ENG DFS BASED GRAPH.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murty S. R. U., 1976, GRAPH THEORY APPL N.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Rodas J, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATION SYSTEMS (ISWCS 2008), P151.
   Shah P, 2016, MECHATRONICS, V38, P29, DOI 10.1016/j.mechatronics.2016.06.005.
   Shang JG, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/397298.
   Simanek J, 2015, IEEE-ASME T MECH, V20, P985, DOI 10.1109/TMECH.2014.2311416.
   Smisek J., 2013, ADV COMPUTER VISION, V21, P1154.
   Sud A., 2015, P ACMSIGGRAPH2008 CL.
   Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010.
   Wang K., 2017, P 2017 OPT FIB COMM.
   Wang K, 2018, INT J ELECTROCHEM SC, V13, P10766, DOI 10.20964/2018.11.30.
   Wang K, 2018, FRONT CHEM SCI ENG, V12, P376, DOI 10.1007/s11705-018-1705-z.
   Wang K, 2017, INT J ELECTROCHEM SC, V12, P8306, DOI 10.20964/2017.09.06.
   Yang CC, 2015, IEEE COMMUN MAG, V53, P150, DOI 10.1109/MCOM.2015.7060497.
   Yin S, 2015, IEEE T IND ELECTRON, V62, P657, DOI 10.1109/TIE.2014.2308133.
   Yun J, 2014, IEEE SENS J, V14, P1482, DOI 10.1109/JSEN.2013.2296601.
   Zheng Y., 2014, P INT C INF COMM TEC, P1.},
Number-of-Cited-References = {36},
Times-Cited = {2},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Math. Probl. Eng.},
Doc-Delivery-Number = {HB5VC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000451130100001},
OA = {Green Published, Green Submitted, gold},
DA = {2022-05-17},
}

@article{ WOS:000390507700012,
Author = {Biswas, Joydeep and Veloso, Manuela M.},
Title = {Episodic non-Markov localization},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2017},
Volume = {87},
Pages = {162-176},
Month = {JAN},
Abstract = {Markov localization and its variants are widely used for mobile robot
   localization. These methods assume Markov independence of observations,
   implying that the observations can be entirely explained by a map.
   However, in real human environments, robots frequently make unexpected
   observations due to unmapped static objects like chairs and tables, and
   dynamic objects like humans. We therefore introduce Episodic non-Markov
   Localization (EnML), which reasons about the world as consisting of
   three classes of objects: long-term features corresponding to permanent
   mapped objects, short-term features corresponding to unmapped static
   objects, and dynamic features corresponding to unmapped moving objects.
   Long-term features are represented by a static map, while short-term
   features are detected and tracked in real-time. To reason about
   unexpected observations and their correlations across poses, we augment
   the Dynamic Bayesian Network for Markov localization to include varying
   edges and nodes, resulting in a novel Varying Graphical Network
   representation. The maximum likelihood estimate of the belief is
   incrementally computed by non-linear functional optimization. By
   detecting timesteps along the robot's trajectory where unmapped
   observations prior to such time steps are unrelated to those afterwards,
   EnML limits the history of observations and pose estimates to
   ``episodes{''} over which the belief is computed. We demonstrate EnML
   using different types of sensors including laser rangefinders and depth
   cameras, and over multiple datasets, comparing it with alternative
   approaches. We further include results of a team of indoor autonomous
   service mobile robots traversing hundreds of kilometers using EnML. (C)
   2016 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Biswas, J (Corresponding Author), Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
   Biswas, J (Corresponding Author), Univ Massachusetts, Coll Informat \& Comp Sci, Amherst, MA 01003 USA.
   Biswas, Joydeep; Veloso, Manuela M., Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
   Biswas, Joydeep, Univ Massachusetts, Coll Informat \& Comp Sci, Amherst, MA 01003 USA.},
DOI = {10.1016/j.robot.2016.09.005},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Localization; Long-term autonomy; Mapping},
Keywords-Plus = {ALGORITHM; ALIGNMENT},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {joydeepb@cs.cmu.edu
   veloso@cs.cmu.edu},
Affiliations = {Carnegie Mellon University; University of Massachusetts System;
   University of Massachusetts Amherst},
ORCID-Numbers = {Biswas, Joydeep/0000-0002-1211-1731},
Funding-Acknowledgement = {NSF {[}IIS-1012733]; ONR {[}N00014-09-1-1031]},
Funding-Text = {This research was supported by NSF award IIS-1012733 and ONR grant
   number N00014-09-1-1031. The views and conclusions contained in this
   document are those of the authors only. We thank the members of the
   CORAL group, in particular Brian Coltin, Stephanie Rosenthal, and
   Richard Wang, for the underlying robot task scheduling, human-robot
   interaction planning, and data-collection deployments. We also thank
   Mike Licitra for the design and construction of the CoBot robots.},
Cited-References = {Agarwal S., 2012, CERES SOLVER TUTORIA.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007.
   Biswas J., 2012, 2012 IEEE International Conference on Robotics and Automation (ICRA), P1697, DOI 10.1109/ICRA.2012.6224766.
   Biswas J., 2014, VECTOR MAP BASED NON.
   Biswas J, 2013, INT J ROBOT RES, V32, P1679, DOI 10.1177/0278364913503892.
   Biswas J, 2011, IEEE INT C INT ROBOT, P73, DOI 10.1109/IROS.2011.6048263.
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995.
   Croz J. Du, 1990, FACTORIZATIONS BAND.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Fox D, 2001, STAT ENG IN, P401.
   Fox D., 2001, ADV NEURAL INF PROCE.
   Fox D., 1998, MARKOV LOCALIZATION.
   Griewank A., 2008, EVALUATING DERIVATIV.
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141.
   Koenig S, 1998, ARTIFICIAL INTELLIGENCE AND MOBILE ROBOTS, P91.
   Lenser S., 2000, INT C ROB AUT.
   LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402.
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Lu F, 1997, J INTELL ROBOT SYST, V18, P249, DOI 10.1023/A:1007957421070.
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Morris T, 2014, IEEE INT CONF ROBOT, P2765, DOI 10.1109/ICRA.2014.6907255.
   Nackman, 1994, SCI ENG C INTRO ADV.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Pearl J., 2014, PROBABILISTIC REASON.
   Rosenthal S., 2010, P 9 INT C AUT AG MUL, P915.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Stachniss C., 2005, P C ART INT, P1324.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Tipaldi G. D., 2012, RSS WORKSH ROB CLUTT.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {37},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {10},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {EF7KE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000390507700012},
DA = {2022-05-17},
}

@inproceedings{ WOS:000544658401117,
Author = {Ding, Xiaqing and Wang, Yue and Tang, Li and Yin, Huan and Xiong, Rong},
Book-Group-Author = {IEEE},
Title = {Communication constrained cloud-based long-term visual localization in
   real time},
DOI = {10.1109/IROS40897.2019.8968550},
Booktitle = {2019 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2019},
Pages = {2159-2166},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Macau, PEOPLES R CHINA, NOV 04-08, 2019},
Abstract = {Visual localization is one of the primary capabilities for mobile
   robots. Long-term visual localization in real time is particularly
   challenging, in which the robot is required to efficiently localize
   itself using visual data where appearance may change significantly over
   time. In this paper, we propose a cloud-based visual localization system
   targeting at long-term localization in real time. On the robot, we
   employ two estimators to achieve accurate and real-time performance. One
   is a sliding-window based visual inertial odometry, which integrates
   constraints from consecutive observations and selfmotion measurements,
   as well as the constraints induced by localization results from the
   cloud. This estimator builds a local visual submap as the virtual
   observation which is then sent to the cloud as new localization
   constraints. The other one is a delayed state Extended Kalman Filter to
   fuse the pose of the robot localized from the cloud, the local odometry
   and the high-frequency inertial measurements. On the cloud, we propose a
   longer sliding-window based localization method to aggregate the virtual
   observations for larger field of view, leading to more robust alignment
   between virtual observations and the map. Under this architecture, the
   robot can achieve drift-free and real-time localization using onboard
   resources even in a network with limited bandwidth, high latency and
   existence of package loss, which enables the autonomous navigation in
   real-world environment. We evaluate the effectiveness of our system on a
   dataset with challenging seasonal and illuminative variations. We
   further validate the robustness of the system under challenging network
   conditions.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Wang, Y; Xiong, R (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou, Peoples R China.
   Ding, Xiaqing; Wang, Yue; Tang, Li; Yin, Huan; Xiong, Rong, Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou, Peoples R China.},
ISSN = {2153-0858},
ISBN = {978-1-7281-4004-9},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods; Robotics},
Author-Email = {wangyue@iipc.zju.edu.cn
   rxiong@zju.edu.cn},
Affiliations = {Zhejiang University},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020},
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202},
Funding-Acknowledgement = {National Nature Science Foundation of China {[}U1609210]; Science and
   Technology Project of Zhejiang Province {[}2019C01043]; State Key
   Laboratory of Industrial Control Technology {[}ITC1904]; Science and
   Technology on Space Intelligent Control Laboratory {[}HTKJ2019KL502002]},
Funding-Text = {This work was supported by the National Nature Science Foundation of
   China (Grant No. U1609210) and Science and Technology Project of
   Zhejiang Province (Grant No. 2019C01043), the State Key Laboratory of
   Industrial Control Technology (ITC1904) and Science and Technology on
   Space Intelligent Control Laboratory (Grant No. HTKJ2019KL502002).},
Cited-References = {Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Ding XQ, 2018, IEEE INT C INT ROBOT, P4794, DOI 10.1109/IROS.2018.8593846.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   GUO B, 2018, IEEE T ROBOTICS, P1.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Kim Y, 2018, IEEE INT C INT ROBOT, P5826.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lynen S., 2013, P IEEE RSJ C INT ROB.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2\_18.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P423, DOI 10.1109/TASE.2015.2408456.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Naseer T., 2017, IEEE INT C ROB AUT.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Paull L, 2015, IEEE INT CONF ROBOT, P509, DOI 10.1109/ICRA.2015.7139227.
   Sattler T., 2018, P CVPR, V1.
   Sinha RS, 2017, ICT EXPRESS, V3, P14, DOI 10.1016/j.icte.2017.03.004.
   Sturm J, 2012, WORKSH COL DEPTH CAM.
   Tang L, 2019, AUTON ROBOT, V43, P197, DOI 10.1007/s10514-018-9724-7.
   Wang Y, 2015, ADV ROBOTICS, V29, P683, DOI 10.1080/01691864.2014.998707.
   Wu K. J., 2015, 2015 ROB SCI SYST C.
   Zhu X., 2017, J FIELD ROBOTICS, V34.},
Number-of-Cited-References = {27},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP2QS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000544658401117},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000589452902007,
Author = {Zhang, Mingming and Chen, Yiming and Li, Mingyang},
Book-Group-Author = {IEEE},
Title = {SDF-Loc: Signed Distance Field based 2D Relocalization and Map Update in
   Dynamic Environments},
DOI = {10.23919/ACC.2019.8814347},
Booktitle = {2019 AMERICAN CONTROL CONFERENCE (ACC)},
Series = {Proceedings of the American Control Conference},
Year = {2019},
Pages = {1997-2004},
Note = {American Control Conference (ACC), Philadelphia, PA, JUL 10-12, 2019},
Abstract = {To empower an autonomous robot to perform long-term navigation in a
   given area, a concurrent localization and map update algorithm is
   required. In this paper, we tackle this problem by providing both
   theoretical analysis and algorithm design for robotic systems equipped
   with 2D laser range finders. The first key contribution of this paper is
   that we propose a hybrid signed distance field (SDF) framework for laser
   based localization. The proposed hybrid SDF integrates two methods with
   complementary characteristics, namely Euclidean SDF (ESDF) and Truncated
   SDF (TSDF). With our framework, accurate pose estimation and fast map
   update can be performed simultaneously. Moreover, we introduce a novel
   sliding window estimator which attains better accuracy by consistently
   utilizing sensor and map information with both scan-to-scan and
   scan-to-map data association. Real-world experimental results
   demonstrate that the proposed algorithm can be used for commercial
   robots in various environments with long-term usage. Experiments also
   show that our approach outperforms competing approaches by a wide
   margin.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhang, MM (Corresponding Author), Alibaba DAMO Acad, AI Labs, Hangzhou, Peoples R China.
   Zhang, Mingming; Chen, Yiming; Li, Mingyang, Alibaba DAMO Acad, AI Labs, Hangzhou, Peoples R China.},
ISSN = {0743-1619},
EISSN = {2378-5861},
ISBN = {978-1-5386-7926-5},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic},
Author-Email = {ximing.zmm@alibaba-inc.com
   yimingchen@alibaba-inc.com
   na.lmy@alibaba-inc.com},
Cited-References = {Agarwal S., CERES SOLVER.
   Behl Aseem, 2018, ARXIV180602170.
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Felzenszwalb P.F., 2012, THEORY COMPUT, V8, P415, DOI DOI 10.4086/TOC.2012.V008A019.
   Fossel JD, 2015, IEEE INT C INT ROBOT, P1949, DOI 10.1109/IROS.2015.7353633.
   Fox D, 2002, ADV NEUR IN, V14, P713.
   Fox D., 1999, AAAI IAAI, V1999, P2.
   Hesch JA, 2010, IEEE INT CONF ROBOT, P5376, DOI 10.1109/ROBOT.2010.5509693.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Jaimez M, 2016, IEEE INT CONF ROBOT, P4479, DOI 10.1109/ICRA.2016.7487647.
   Jaimez Mariano, 2018, IEEE T ROBOTICS.
   Kallasi F, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1206, DOI 10.1109/IROS.2016.7759202.
   Klingensmith M., 2015, ROBOTICS SCI SYSTEMS, V4.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Krajnik T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4558, DOI 10.1109/IROS.2016.7759671.
   Kummerle R, 2009, AUTON ROBOT, V27, P387, DOI 10.1007/s10514-009-9155-6.
   Lau B, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P281, DOI 10.1109/IROS.2010.5650794.
   Li JX, 2017, IEEE INT C INT ROBOT, P763, DOI 10.1109/IROS.2017.8202236.
   Li MY, 2014, IEEE INT CONF ROBOT, P409, DOI 10.1109/ICRA.2014.6906889.
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251.
   Li YM, 2010, IEEE INT CONF ROBOT, P1388, DOI 10.1109/ROBOT.2010.5509690.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Nicolai A., 2016, RSS WORKSH LIM POT D, V184.
   Oleynikova H., 2016, RSS 2016 WORKSH GEOM.
   Oleynikova H., 2017, IEEE RSJ INT C INT R.
   Ruchti P, 2015, IEEE INT CONF ROBOT, P5260, DOI 10.1109/ICRA.2015.7139932.
   Schiotka A, 2017, IEEE INT C INT ROBOT, P642, DOI 10.1109/IROS.2017.8202219.
   Tue-Cuong Dong-Si, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P5655, DOI 10.1109/ICRA.2011.5980267.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Xing-Jian J., 2008, MOTION PLANNING, P382.
   Zucker M, 2013, INT J ROBOT RES, V32, P1164, DOI 10.1177/0278364913488805.},
Number-of-Cited-References = {34},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {7},
Doc-Delivery-Number = {BQ4FT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000589452902007},
DA = {2022-05-17},
}

@article{ WOS:000441935900004,
Author = {Chen, Zetao and Liu, Lingqiao and Sa, Inkyu and Ge, Zongyuan and Chli,
   Margarita},
Title = {Learning Context Flexible Attention Model for Long-Term Visual Place
   Recognition},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2018},
Volume = {3},
Number = {4},
Pages = {4015-4022},
Month = {OCT},
Abstract = {Identifying regions of interest in an image has long been of great
   importance in a wide range of tasks, including place recognition. In
   this letter, we propose a novel attention mechanism with flexible
   context, which can be incorporated into existing feed-forward network
   architecture to learn image representations for long-term place
   recognition. In particular, in order to focus on regions that contribute
   positively to place recognition, we introduce a multiscale
   context-flexible network to estimate the importance of each spatial
   region in the feature map. Our model is trained end-to-end for place
   recognition and can detect regions of interest of arbitrary shape.
   Extensive experiments have been conducted to verify the effectiveness of
   our approach and the results demonstrate that our model can achieve
   consistently better performance than the state of the art on standard
   benchmark datasets. Finally, we visualize the learned attention maps to
   generate insights into what attention the network has learned.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Chen, ZT (Corresponding Author), Swiss Fed Inst Technol, Vis Robot Lab, CH-8092 Zurich, Switzerland.
   Chen, Zetao; Chli, Margarita, Swiss Fed Inst Technol, Vis Robot Lab, CH-8092 Zurich, Switzerland.
   Liu, Lingqiao, Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
   Sa, Inkyu, Swiss Fed Inst Technol, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Ge, Zongyuan, Monash Univ, ERes Ctr, Melbourne, Vic 3800, Australia.},
DOI = {10.1109/LRA.2018.2859916},
ISSN = {2377-3766},
Keywords = {Localization; deep learning in robotics and automation; visual-based
   navigation},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {chenze@ethz.ch
   lingqiao.liu@adelaide.edu.au
   inkyu.sa@mavt.ethz.ch
   Zongyuan.Ge@monash.edu
   chlim@ethz.ch},
Affiliations = {ETH Zurich; University of Adelaide; ETH Zurich; Monash University},
ORCID-Numbers = {Sa, Inkyu/0000-0001-5429-0515
   Chli, Margarita/0000-0001-5611-7492
   Ge, Zongyuan/0000-0002-5880-8673
   Chen, Zetao/0000-0002-5596-5008},
Funding-Acknowledgement = {Swiss National Science Foundation {[}PP00P2 157585]; EC's Horizon 2020
   Programme {[}644128]; European Union's Horizon 2020 research and
   innovation Programme {[}644227]; Swiss State Secretariat for Education,
   Research and Innovation {[}15.0029]},
Funding-Text = {This work was supported in part by the Swiss National Science Foundation
   (Agreement PP00P2 157585), in part by the EC's Horizon 2020 Programme
   under Grant Agreement 644128 (AEROWORKS), in part by the European
   Union's Horizon 2020 research and innovation Programme under Grant
   Agreement 644227 (Flourish), and in part by the Swiss State Secretariat
   for Education, Research and Innovation under Contract 15.0029.},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Arbelaez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396.
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667.
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856.
   Chen Z., 2014, AUSTR C ROB AUT MELB.
   Chen ZT, 2017, IEEE INT C INT ROBOT, P9.
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468.
   Chu Xiao, 2017, PROC CVPR IEEE, P1831, DOI DOI 10.1109/CVPR.2017.601.
   CUMMINS M, 2009, P ROB SCI SYST SEATT.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754.
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135.
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Liu LQ, 2017, IEEE T PATTERN ANAL, V39, P2305, DOI 10.1109/TPAMI.2016.2637921.
   Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107.
   Lowry S, 2018, IEEE ROBOT AUTOM LET, V3, P957, DOI 10.1109/LRA.2018.2793308.
   McManus C., 2014, P ROB SCI SYST.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mousavian A, 2015, IEEE INT CONF ROBOT, P4882, DOI 10.1109/ICRA.2015.7139877.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374.
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424.
   Simonyan K, 2014, C TRACK P.
   Sunderhauf N., 2015, IEEE RSJ INT C INT R.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Szegedy Christian., 2014, PROC CVPR IEEE, V1409, P4842, DOI DOI 10.1109/CVPR.2015.7298594.
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683.
   Wang P, 2017, PROC CVPR IEEE, P6212, DOI 10.1109/CVPR.2017.658.
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009.},
Number-of-Cited-References = {39},
Times-Cited = {40},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {8},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {GQ7PI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000441935900004},
OA = {Green Accepted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000321818400029,
Author = {Bacca, Bladimir and Salvi, Joaquim and Cufi, Xavier},
Editor = {Alquezar, R and Moreno, A and Aguilar, J},
Title = {Mapping and Localization for Mobile Robots through Environment
   Appearance Update},
Booktitle = {ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT},
Series = {Frontiers in Artificial Intelligence and Applications},
Year = {2010},
Volume = {220},
Pages = {291-300},
Note = {13th International Conference of the
   Catalan-Association-for-Artificial-Intelligence (CCIA), L Espluga de
   Francoli, SPAIN, OCT 20-22, 2010},
Abstract = {The strength of appearance-based mapping models lies in their ability to
   represent the environment through high-level image features; and provide
   human-readable information. However, developing localization and mapping
   methods with these models could be very challenging, especially if
   robots must deal with long-term mapping, localization, navigation,
   occlusions, and dynamic environments. This paper proposes an
   appearance-based mapping and localization method based on the human
   memory model, which is used to build a Feature Stability Histogram (FSH)
   at each node in the robot topological map, these FSH register local
   feature stability over time through a voting scheme, and most stable
   features are considered for mapping and Bayesian localization.
   Experimental results are presented using omnidirectional images acquired
   through long-term acquisition considering: illumination changes (day
   time and seasons), occlusions, random removal of features, and
   perceptual aliasing. This method is able to adapt the internal node's
   representation through time to achieve global and local robot
   localization.},
Publisher = {IOS PRESS},
Address = {NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Bacca, B (Corresponding Author), Univ Girona, Campus Montilivi,Bldg P-4, Girona 17071, Catalunya, Spain.
   Bacca, Bladimir; Salvi, Joaquim; Cufi, Xavier, Univ Girona, Girona 17071, Catalunya, Spain.},
DOI = {10.3233/978-1-60750-643-0-291},
ISSN = {0922-6389},
EISSN = {1879-8314},
ISBN = {978-1-60750-643-0; 978-1-60750-642-3},
Keywords = {Appearance-based; omnidirectional vision; localization and mapping},
Keywords-Plus = {IMAGES},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications},
Author-Email = {bladimir@eia.udg.edu},
Affiliations = {Universitat de Girona},
ResearcherID-Numbers = {Salvi, Joaquim/L-2648-2014
   },
ORCID-Numbers = {Salvi, Joaquim/0000-0002-9482-7126
   Bacca Cortes, Bladimir/0000-0003-0113-4134},
Cited-References = {Andreasson H, 2008, IEEE T ROBOT, V24, P991, DOI 10.1109/TRO.2008.2004642.
   Angeli A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1031, DOI 10.1109/IROS.2008.4650675.
   Atkinson, 1968, PSYCHOL LEARNING MOT, V2, P89, DOI {[}DOI 10.1016/S0079-7421(08)60422-3, 10.1016/s0079-7421(08)60422-3.].
   Bacca B, 2009, FRONT ARTIF INTEL AP, V202, P55, DOI 10.3233/978-1-60750-061-2-55.
   Bailey T., 2006, ROBOTICS AUTOMATION, P10.
   Barber R., 2000, THESIS U CARLOS III.
   Barreto JP, 2005, IEEE T PATTERN ANAL, V27, P1327, DOI 10.1109/TPAMI.2005.163.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Gaspar J, 2007, STUD COMPUT INTELL, V70, P223.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Linaker F, 2006, ROBOT AUTON SYST, V54, P205, DOI 10.1016/j.robot.2005.11.003.
   Llinas R., 2001, I VORTEX NEURONS SEL.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Murillo AC, 2007, ROBOT AUTON SYST, V55, P372, DOI 10.1016/j.robot.2006.12.004.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Nieto J, 2007, ROBOT AUTON SYST, V55, P39, DOI 10.1016/j.robot.2006.06.008.
   Nuchter A, 2008, ROBOT AUTON SYST, V56, P915, DOI 10.1016/j.robot.2008.08.001.
   Porta J. M., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3424.
   Scaramuzza D., 2009, P 2009 IEEE INT C RO.
   Scaramuzza D., 2008, P 8 WORKSH OMN VIS O.
   Segvic S, 2009, COMPUT VIS IMAGE UND, V113, P172, DOI 10.1016/j.cviu.2008.08.005.
   Sujan VA, 2006, AUTON ROBOT, V21, P15, DOI 10.1007/s10514-005-6066-z.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005.},
Number-of-Cited-References = {25},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BFX70},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000321818400029},
DA = {2022-05-17},
}

@inproceedings{ WOS:000458872706137,
Author = {Furuta, Yuki and Okada, Kei and Kakiuchi, Yohei and Inaba, Masayuki},
Editor = {Maciejewski, AA and Okamura, A and Bicchi, A and Stachniss, C and Song, DZ and Lee, DH and Chaumette, F and Ding, H and Li, JS and Wen, J and Roberts, J and Masamune, K and Chong, NY and Amato, N and Tsagwarakis, N and Rocco, P and Asfour, T and Chung, WK and Yasuyoshi, Y and Sun, Y and Maciekeski, T and Althoefer, K and AndradeCetto, J and Chung, WK and Demircan, E and Dias, J and Fraisse, P and Gross, R and Harada, H and Hasegawa, Y and Hayashibe, M and Kiguchi, K and Kim, K and Kroeger, T and Li, Y and Ma, S and Mochiyama, H and Monje, CA and Rekleitis, I and Roberts, R and Stulp, F and Tsai, CHD and Zollo, L},
Book-Author = {Kosecka, J},
Title = {An Everyday Robotic System that Maintains Local Rules using Semantic Map
   based on Long-term Episodic Memory},
DOI = {10.1109/IROS.2018.8594481},
Booktitle = {2018 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2018},
Pages = {7641-7647},
Note = {25th IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Madrid, SPAIN, OCT 01-05, 2018},
Abstract = {To enable robots to work on real home environments, they have to not
   only consider common knowledge in the global society, but also be aware
   of existing rules there. Since such ``local rules{''} are not
   describable beforehand, robot agents must acquire them through their
   lives after deployment. To achieve this, we developed a framework that
   a) lets robots record long-term episodic memories in their deployed
   environments, b) autonomously builds probabilistic object localization
   map as structurization of logged data and c) make adapted task plans
   based on the map. We equipped our framework on PR2 and Fetch robots
   operating and recording episodic memory for 41 days with semantic common
   knowledge of the environment. We also conducted demonstrations in which
   a PR2 robot tidied up a room, showing that the robot agent can
   successfully plan and execute local-rule-aware home assistive tasks by
   using our proposed framework.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Furuta, Y (Corresponding Author), Univ Tokyo, Grad Sch Informat Sci \& Technol, JSK Lab, Dept Creat Informat, 7-3-1 Hongo, Bunkyo City, Tokyo 1138656, Japan.
   Furuta, Yuki; Okada, Kei; Kakiuchi, Yohei; Inaba, Masayuki, Univ Tokyo, Grad Sch Informat Sci \& Technol, JSK Lab, Dept Creat Informat, 7-3-1 Hongo, Bunkyo City, Tokyo 1138656, Japan.},
ISSN = {2153-0858},
ISBN = {978-1-5386-8094-0},
Keywords = {Service Robots; Learning and Adaptive Systems; Big Data in Robotics and
   Automation},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Robotics},
Author-Email = {furushchev@jsk.imi.i.u-tokyo.ac.jp},
Affiliations = {University of Tokyo},
ResearcherID-Numbers = {Kakiuchi, Yohei/AAO-6822-2021},
Cited-References = {Abdo N, 2015, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ICRA.2015.7139396.
   Asoh H, 2001, IEEE INTELL SYST, V16, P46, DOI 10.1109/5254.956081.
   Beetz Michael, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P529, DOI 10.1109/Humanoids.2011.6100855.
   FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5.
   Fox M., 2003, J ARTIFICIAL INTELLI.
   Hawes N, 2017, IEEE ROBOT AUTOM MAG, V24, P146, DOI 10.1109/MRA.2016.2636359.
   Kunze L, 2012, IEEE INT CONF ROBOT, P4385, DOI 10.1109/ICRA.2012.6224965.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0\_2.
   Niitani  Y., 2017, ARXIV170808169.
   Okada  K., 2013, ICRA WORKSH COMB TAS.
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
   Rybski PE, 2008, INTEL SERV ROBOT, V1, P159, DOI 10.1007/s11370-008-0016-5.
   Saxena A., 2014, ARXIV14120691.
   Taniguchi  A., 2017, ARXIV170404664.
   Tenorth M, 2010, IEEE INT CONF ROBOT, P1499, DOI 10.1109/ROBOT.2010.5509161.
   Yamazaki K, 2012, P IEEE, V100, P2429, DOI 10.1109/JPROC.2012.2200563.},
Number-of-Cited-References = {17},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BM0LT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000458872706137},
DA = {2022-05-17},
}

@article{ WOS:000328178200038,
Author = {Vu Anh Nguyen and Starzyk, Janusz A. and Goh, Wool-Boon},
Title = {A spatio-temporal Long-term Memory approach for visual place recognition
   in mobile robotic navigation},
Journal = {ROBOTICS AND AUTONOMOUS SYSTEMS},
Year = {2013},
Volume = {61},
Number = {12},
Pages = {1744-1758},
Month = {DEC},
Abstract = {This paper proposes a solution to the problem of mobile robotic
   localization using visual indoor image sequences with a biologically
   inspired spatio-temporal neural network approach. The system contains
   three major subsystems: a feature extraction module, a scene
   quantization module and a spatio-temporal long-term memory (LTM) module.
   During learning, the scene quantization module clusters the visual
   images set into scene tokens. A K-Iteration Fast Learning Artificial
   Neural Network (KFLANN) is employed as the core unit of the quantization
   module. The KFLANN network is driven by intrinsic statistics of the data
   stream and therefore does not require the number of clusters to be
   predefined. In addition, the KFLANN performance is less sensitive to
   data presentation ordering compared to popular clustering methods such
   as k-means, and can therefore produce a consistent number of stable
   centroids. Using scene tokens, the topological structure of the
   environment can be composed into sequences of tokens. These sequences
   are then learnt and stored in memory units in an LTM architecture, which
   is able to continuously and robustly recognize the visual input stream.
   The design of memory units addresses two critical problems in
   spatio-temporal learning, namely error tolerance and memory forgetting.
   The primary objective of this work is to explore the synergy between the
   strength of KFLANN and LTM models to address the visual topological
   localization problem. We demonstrate the efficiency and efficacy of the
   proposed framework on the challenging COsy Localization Dataset. (C)
   2013 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Nguyen, VA (Corresponding Author), Nanyang Technol Univ, Sch Comp Engn, CeMNet, Singapore 639798, Singapore.
   Vu Anh Nguyen; Goh, Wool-Boon, Nanyang Technol Univ, Sch Comp Engn, CeMNet, Singapore 639798, Singapore.
   Starzyk, Janusz A., Ohio Univ, Sch Elect Engn \& Comp Sci, Russ Coll Engn \& Technol, Athens, OH 45701 USA.
   Starzyk, Janusz A., Univ Informat Technol \& Management, Dept Appl Informat Syst, Rzeszow, Poland.},
DOI = {10.1016/j.robot.2012.12.004},
ISSN = {0921-8890},
EISSN = {1872-793X},
Keywords = {Visual place recognition; Spatio-temporal neural networks; Long-term
   Memory; Topological robotic mapping},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; NEURAL SYSTEM; SCENE; REPRESENTATION;
   HIPPOCAMPUS; SEQUENCES; NETWORKS; CELLS; SVM; MAP},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {anhngv102@gmail.com
   starzykj@gmail.com
   aswbgoh@ntu.edu.sg},
Affiliations = {Nanyang Technological University \& National Institute of Education
   (NIE) Singapore; Nanyang Technological University; Ohio University;
   University of Information Technology \& Management Rzeszow},
ORCID-Numbers = {Starzyk, Janusz/0000-0003-2678-5515},
Cited-References = {Ackerman C, 2005, IEEE T ROBOT, V21, P247, DOI 10.1109/TRO.2004.837241.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arleo A, 2004, IEEE T NEURAL NETWOR, V15, P639, DOI 10.1109/TNN.2004.826221.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555.
   Burgess N, 2005, TRENDS COGN SCI, V9, P535, DOI 10.1016/j.tics.2005.09.011.
   CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2.
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199.
   Cover T. M., 2006, ELEMENTS INFORM THEO, V2nd.
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eichenbaum H, 1999, NEURON, V23, P209, DOI 10.1016/S0896-6273(00)80773-4.
   Fei-Fei L, 2005, PROC CVPR IEEE, P524.
   Filliat D., 2003, COGN SYST RES, V4, P243, DOI DOI 10.1016/S1389-0417(03)00008-1.
   FILLIAT D, 2003, J COGN SYST RES, V4, P283.
   Gnadt W, 2008, NEURAL NETWORKS, V21, P699, DOI 10.1016/j.neunet.2007.09.016.
   Goedeme T., 2008, MOBILE ROBOTS MOTION, P63.
   Grossberg S, 2009, J VISION, V9, DOI 10.1167/9.4.6.
   Harris C. G., 1988, ALVEY VISION C, P1, DOI DOI 10.5244/C.2.23.
   Hebb D., 1949, ORG BEHAV.
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650.
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007.
   Kremer SC, 2001, NEURAL COMPUT, V13, P249, DOI 10.1162/089976601300014538.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112.
   McGaugh JL, 2000, SCIENCE, V287, P248, DOI 10.1126/science.287.5451.248.
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188.
   Nguyen V.A., 2009, INT C COGN NEUR SYST.
   Nguyen V. H., 2010, IEEE 25 INT S DEF FA, P1, DOI DOI 10.1109/RIVF.2010.5632316.
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   OReilly R.C., 2000, COMPUTATIONAL EXPLOR.
   Ping WL, 2003, IEEE IJCNN, P1517.
   Ponce J., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68.
   Poucet B, 2003, J PHYSIOL-PARIS, V97, P537, DOI 10.1016/j.jphysparis.2004.01.011.
   Pronobis A, 2008, IEEE INT CONF ROBOT, P522, DOI 10.1109/ROBOT.2008.4543260.
   Pronobis A, 2010, ROBOT AUTON SYST, V58, P81, DOI 10.1016/j.robot.2009.07.025.
   Pronobis A, 2010, IMAGE VISION COMPUT, V28, P1080, DOI 10.1016/j.imavis.2010.01.015.
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537.
   Redish Aaron David, 1999, COGNITIVE MAP PLACE.
   Ridella S, 1999, IEEE T NEURAL NETWOR, V10, P31, DOI 10.1109/72.737491.
   Rottmann A., 2005, P NAT C ART INT AAAI, P1306.
   Shastri L, 2001, EPISODIC MEMORY TRAC.
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40.
   Starner T, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P50, DOI 10.1109/ISWC.1998.729529.
   STARNER T, 1999, THESIS MIT.
   Starzyk J. A., 2008, FRONTIERS ROBOTICS A, P83.
   Starzyk JA, 2007, IEEE T NEURAL NETWOR, V18, P344, DOI 10.1109/TNN.2006.884681.
   Starzyk JA, 2009, IEEE T NEURAL NETWOR, V20, P768, DOI 10.1109/TNN.2009.2012854.
   Sun R, 2001, IEEE INTELL SYST, V16, P67, DOI 10.1109/MIS.2001.1463065.
   Tay ALP, 2007, IEEE T NEURAL NETWOR, V18, P1645, DOI 10.1109/TNN.2007.900231.
   Tay ALP, 2006, IEEE IJCNN, P4201.
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7.
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273.
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128.
   Tse R, 2008, IEEE SYS MAN CYBERN, P3033.
   Tulving E., 1972, ORG MEMORY, P381.
   Ullah MM, 2008, IEEE INT CONF ROBOT, P530, DOI 10.1109/ROBOT.2008.4543261.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Vapnik, 1998, STAT LEARNING THEORY.
   Nguyen VA, 2012, IEEE T NEUR NET LEAR, V23, P971, DOI 10.1109/TNNLS.2012.2191419.
   WANG DL, 1993, IEEE T SYST MAN CYB, V23, P993, DOI 10.1109/21.247884.
   WANG DL, 1995, IEEE T SYST MAN CYB, V25, P615, DOI 10.1109/21.370192.
   WANG DL, 1990, P IEEE, V78, P1536, DOI 10.1109/5.58329.
   Wolf J, 2005, IEEE T ROBOT, V21, P208, DOI 10.1109/TRO.2004.835453.
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224.
   Wu JX, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4763, DOI 10.1109/IROS.2009.5354164.
   Zabih R., 1994, Computer Vision - ECCV `94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151.},
Number-of-Cited-References = {70},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Robot. Auton. Syst.},
Doc-Delivery-Number = {268NS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000328178200038},
DA = {2022-05-17},
}

@article{ WOS:000329510300006,
Author = {Biswas, Joydeep and Veloso, Manuela M.},
Title = {Localization and navigation of the CoBots over long-term deployments},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2013},
Volume = {32},
Number = {14, SI},
Pages = {1679-1694},
Month = {DEC},
Abstract = {For the last three years, we have developed and researched multiple
   collaborative robots, CoBots, which have been autonomously traversing
   our multi-floor buildings. We pursue the goal of long-term autonomy for
   indoor service mobile robots as the ability for them to be deployed
   indefinitely while they perform tasks in an evolving environment. The
   CoBots include several levels of autonomy, and in this paper we focus on
   their localization and navigation algorithms. We present the Corrective
   Gradient Refinement (CGR) algorithm, which refines the proposal
   distribution of the particle filter used for localization with sensor
   observations using analytically computed state space derivatives on a
   vector map. We also present the Fast Sampling Plane Filtering algorithm
   that extracts planar regions from depth images in real time. These
   planar regions are then projected onto the 2D vector map of the
   building, and along with the laser rangefinder observations, used with
   CGR for localization. For navigation, we present a hierarchical planner,
   which computes a topological policy using a graph representation of the
   environment, computes motion commands based on the topological policy,
   and then modifies the motion commands to side-step perceived obstacles.
   We started logging the deployments of the CoBots one and a half years
   ago, and have since collected logs of the CoBots traversing more than
   130 km over 1082 deployments and a total run time of 182 h, which we
   publish as a dataset consisting of more than 10 million laser scans. The
   logs show that although there have been continuous changes in the
   environment, the robots are robust to most of them, and there exist only
   a few locations where changes in the environment cause increased
   uncertainty in localization.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Biswas, J (Corresponding Author), Carnegie Mellon Univ, Sch Comp Sci, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
   Biswas, Joydeep, Carnegie Mellon Univ, Sch Comp Sci, Inst Robot, Pittsburgh, PA 15213 USA.
   Veloso, Manuela M., Carnegie Mellon Univ, Sch Comp Sci, Dept Comp Sci, Pittsburgh, PA 15213 USA.},
DOI = {10.1177/0278364913503892},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Localization; navigation; long-term autonomy; indoor mobile robots;
   autonomous robots},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {joydeepb@cs.cmu.edu},
Affiliations = {Carnegie Mellon University; Carnegie Mellon University},
ORCID-Numbers = {Biswas, Joydeep/0000-0002-1211-1731},
Funding-Acknowledgement = {National Science Foundation {[}NSF IIS-1012733]},
Funding-Text = {This work was supported by the National Science Foundation (grant number
   NSF IIS-1012733).},
Cited-References = {Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Biswas J, 2013, ROBOCUP 2013 ROB SOC.
   Biswas J, 2012, IEEE INT CONF ROBOT, P1697, DOI 10.1109/icra.2012.6224766.
   Biswas J, 2011, IEEE INT C INT ROBOT, P73, DOI 10.1109/IROS.2011.6048263.
   Biswas J, 2010, IEEE INT CONF ROBOT, P4379, DOI 10.1109/ROBOT.2010.5509842.
   Bruce J, 2007, P 11 INT ROBOCUP S A.
   BUHMANN J, 1995, AI MAG, V16, P31.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Fox D., 2001, ADV NEURAL INFORM PR, V14, P713.
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Jetto L, 1999, IEEE T ROBOTIC AUTOM, V15, P219, DOI 10.1109/70.760343.
   Kalman R. E., 1960, J FLUIDS ENG, V82, P34, DOI {[}https://doi.org/10.1115/1.3662552, DOI 10.1115/1.3662552].
   Koenig S, 1998, ARTIFICIAL INTELLIGENCE AND MOBILE ROBOTS, P91.
   Lefebvre T, 2004, INT J CONTROL, V77, P639, DOI 10.1080/00207170410001704998.
   Lenser S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1225, DOI 10.1109/ROBOT.2000.844766.
   LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147.
   Mendoza JP, 2012, IEEE INT C INT ROBOT, P370, DOI 10.1109/IROS.2012.6386189.
   Nilsson N, 1984, 323 DTIC.
   Nourbakhsh IR, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3636.
   Oyama A, 2009, 27 ANN C ROB SOC JAP, V9, P2009.
   Rosenthal S, 2012, P 26 C ART INT AAAI, P886.
   Rosenthal S., 2010, P 9 INT C AUT AG MUL, P915.
   Roumeliotis SI, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P454, DOI 10.1109/IROS.2000.894646.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Samadi Mehdi, 2012, P IEEE AAAI C ART IN, P2074.
   Thrun S, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1999, DOI 10.1109/ROBOT.1999.770401.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Thrun S. a. o., 2002, EXPLORING ARTIFICIAL, V1, P1.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.
   Zhang L., 2000, P IEEE INT C ROB AUT, P2538, DOI DOI 10.1109/ROBOT.2000.846410.},
Number-of-Cited-References = {39},
Times-Cited = {37},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {21},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {287AL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000329510300006},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000254021300021,
Author = {Yang Jingdong and Hong Bingrong and Piao Songhao},
Title = {An efficient approach to odometric non-systematic error modeling for
   mobile robots},
Journal = {CHINESE JOURNAL OF ELECTRONICS},
Year = {2008},
Volume = {17},
Number = {1},
Pages = {95-99},
Month = {JAN},
Abstract = {Odometric non-systematic error modeling for mobile robot is the basis of
   localization. Most of the approaches to odometric non-systematic error
   modeling are designed for some special driving-type robots nowadays. And
   the long-term odometric errors without bound, which degrade the
   localization precision after long-distance movement, are not often
   capable of being compensated in real-time. Therefore, a general approach
   to odometric non-systematic error modeling for mobile robot is proposed
   in regard to both synchronous drive roller robots and differential drive
   roller robots. The approach assumes that the robot path is approximated
   to circular arcs. The function relationships, between the odometric
   process input and non-systematic errors, are derived on the basis of the
   odometric error transformation rules, further the accumulative errors of
   odometry in the localization process are compensated in real-time. The
   experiments show that the compensation of non-systematic error can
   reduce the odometric long-term errors efficiently, and improve the
   localization precision remarkably.},
Publisher = {TECHNOLOGY EXCHANGE LIMITED HONG KONG},
Address = {26-28 AU PUI WAN ST, STE 1102, FO TAN INDUSTRIAL CENTRE, FO TAN, SHATIN,
   00000, PEOPLES R CHINA},
Type = {Article},
Language = {English},
Affiliation = {Yang, JD (Corresponding Author), Harbin Inst Technol, Dept Comp Sci \& Technol, Harbin 150001, Peoples R China.
   Yang Jingdong; Hong Bingrong; Piao Songhao, Harbin Inst Technol, Dept Comp Sci \& Technol, Harbin 150001, Peoples R China.},
ISSN = {1022-4653},
EISSN = {2075-5597},
Keywords = {non-systematic error modeling; position estimate; simultaneous
   localization and mapping; Markov procedure},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic},
Affiliations = {Harbin Institute of Technology},
Cited-References = {Chong KS, 1999, INT J ROBOT RES, V18, P3.
   Josep M., 2005, IEEE T ROBOTICS, V21, P345.
   Julier SJ, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2749.
   Li Y, 2006, PROCEEDINGS OF THE 2006 NATIONAL TECHNICAL MEETING OF THE INSTITUTE OF NAVIGATION - NTM 2006, P958.
   Martinelli A, 2002, IEEE T ROBOTIC AUTOM, V18, P399, DOI 10.1109/TRA.2002.1019477.
   MARTINELLI A, 2001, P 5 IFAC S NONL CONT, P420.},
Number-of-Cited-References = {6},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Chin. J. Electron.},
Doc-Delivery-Number = {274SM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000254021300021},
DA = {2022-05-17},
}

@article{ WOS:000380103400001,
Author = {Muehlfellner, Peter and Burki, Mathias and Bosse, Michael and Derendarz,
   Wojciech and Philippsen, Roland and Furgale, Paul},
Title = {Summary Maps for Lifelong Visual Localization},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2016},
Volume = {33},
Number = {5},
Pages = {561-590},
Month = {AUG},
Abstract = {Robots that use vision for localization need to handle environments that
   are subject to seasonal and structural change, and operate under
   changing lighting and weather conditions. We present a framework for
   lifelong localization and mapping designed to provide robust and
   metrically accurate online localization in these kinds of changing
   environments. Our system iterates between offline map building, map
   summary, and online localization. The offline mapping fuses data from
   multiple visually varied datasets, thus dealing with changing
   environments by incorporating new information. Before passing these data
   to the online localization system, the map is summarized, selecting only
   the landmarks that are deemed useful for localization. This Summary Map
   enables online localization that is accurate and robust to the variation
   of visual information in natural environments while still being
   computationally efficient. We present a number of summary policies for
   selecting useful features for localization from the multisession map,
   and we explore the tradeoff between localization performance and
   computational complexity. The system is evaluated on 77 recordings, with
   a total length of 30 kilometers, collected outdoors over 16 months.
   These datasets cover all seasons, various times of day, and changing
   weather such as sunshine, rain, fog, and snow. We show that it is
   possible to build consistent maps that span data collected over an
   entire year, and cover day-to-night transitions. Simple statistics
   computed on landmark observations are enough to produce a Summary Map
   that enables robust and accurate localization over a wide range of
   seasonal, lighting, and weather conditions.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Muhlfellner, P (Corresponding Author), Halmstad Univ, Dept Driver Assistance \& Integrated Safety, Volkswagen AG, Letter Box 011-1777, Wolfsburg, Germany.
   Muehlfellner, Peter, Halmstad Univ, Dept Driver Assistance \& Integrated Safety, Volkswagen AG, Letter Box 011-1777, Wolfsburg, Germany.
   Burki, Mathias; Bosse, Michael; Furgale, Paul, ETH, Autonomous Syst Lab, Leonhardstr 21, Zurich, Switzerland.
   Derendarz, Wojciech, Volkswagen AG, Dept Driver Assistance \& Integrated Safety, Letter Box 011-1777, Wolfsburg, Germany.
   Philippsen, Roland, Halmstad Univ, Intelligent Syst Lab, Kristian IVs Vag 3, Halmstad, Sweden.},
DOI = {10.1002/rob.21595},
ISSN = {1556-4959},
EISSN = {1556-4967},
Keywords-Plus = {FAB-MAP; APPEARANCE; NAVIGATION; REPEAT; SCALE; TEACH},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {peter.muehlfellner@volkswagen.de
   mathias.buerki@mavt.ethz.ch
   mike.bosse@mavt.ethz.ch
   wojciech.derendarz@volkswagen.de
   roland.philippsen@hh.se
   paul.furgale@mavt.ethz.ch},
Affiliations = {Volkswagen; Volkswagen Germany; ETH Zurich; Volkswagen; Volkswagen
   Germany; Halmstad University},
Funding-Acknowledgement = {European Community {[}269916, 610603]},
Funding-Text = {This work is supported in part by the European Community's Seventh
   Framework Programme (FP7/2007-2013) under Grants No. 269916 (V-Charge)
   and No. 610603 (EU-ROPA2).},
Cited-References = {Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9\_3.
   Bosse M, 2003, IEEE INT CONF ROBOT, P1899, DOI 10.1109/ROBOT.2003.1241872.
   Bosse M, 2013, IEEE INT CONF ROBOT, P2677, DOI 10.1109/ICRA.2013.6630945.
   Brubaker MA, 2013, PROC CVPR IEEE, P3057, DOI 10.1109/CVPR.2013.393.
   Carlevaris-Bianco N., 2014, IEEE RSJ INT C INT R.
   Carlevaris-Bianco N, 2013, IEEE INT C INT ROBOT, P1034, DOI 10.1109/IROS.2013.6696478.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Furgale P, 2013, IEEE INT VEH SYM, P809, DOI 10.1109/IVS.2013.6629566.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Heng L., 2014, J FIELD ROBOTICS.
   Johannsson H., 2012, RSS WORKSH LONGT OP.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582.
   Kneip L, 2013, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2013.292.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Krajnik T., 2013, P 2013 16 INT C ADV, P1.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Krajnik T, 2010, J FIELD ROBOT, V27, P511, DOI 10.1002/rob.20354.
   Lategahn H., 2012, 2012 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2012), P1, DOI 10.1109/ICVES.2012.6294279.
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492.
   Lategahn H, 2013, IEEE INT VEH SYM, P285, DOI 10.1109/IVS.2013.6629483.
   Lee G., 2014, THESIS.
   Lee GH, 2013, IEEE INT C INT ROBOT, P564, DOI 10.1109/IROS.2013.6696407.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791.
   Lovegrove S, 2011, IEEE INT VEH SYM, P788, DOI 10.1109/IVS.2011.5940546.
   Maddern W., 2012, P ROB SCI SYST C 201.
   Maddern W, 2014, IEEE INT VEH SYM, P330, DOI 10.1109/IVS.2014.6856471.
   Mazuran M., 2014, P ROB SCI SYST BERK.
   McManus C, 2014, P ROB SCI SYST RSS B.
   McManus C., 2014, 2014 IEEE INT C ROB.
   McManus C, 2013, J FIELD ROBOT, V30, P254, DOI 10.1002/rob.21444.
   Milford M, 2014, J FIELD ROBOT, V31, P814, DOI 10.1002/rob.21532.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muehlfellner P, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P57.
   Naseer T., 2014, P NAT C ART INT AAAI.
   Neubert P, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P198, DOI 10.1109/ECMR.2013.6698842.
   Ni K, 2007, IEEE I CONF COMP VIS, P2009.
   Pepperell E, 2014, IEEE INT CONF ROBOT, P1612, DOI 10.1109/ICRA.2014.6907067.
   Sibley G., 2009, ROBOTICS SCI SYSTEMS.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Snavely N., 2008, CVPR, V1, P2.
   Stewart AD, 2012, IEEE INT CONF ROBOT, P2625, DOI 10.1109/ICRA.2012.6224750.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2.
   Ziegler J, 2014, IEEE INT VEH SYM, P1231, DOI 10.1109/IVS.2014.6856560.
   Ziegler J, 2014, IEEE INTEL TRANSP SY, V6, P8, DOI 10.1109/MITS.2014.2306552.},
Number-of-Cited-References = {53},
Times-Cited = {48},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {19},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {DR7TU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000380103400001},
DA = {2022-05-17},
}

@article{ WOS:000671993900001,
Author = {Wang, Sen and Chen, Xiaohe and Ding, Guanyu and Li, Yongyao and Xu,
   Wenchang and Zhao, Qinglei and Gong, Yan and Song, Qi},
Title = {A Lightweight Localization Strategy for LiDAR-Guided Autonomous Robots
   with Artificial Landmarks},
Journal = {SENSORS},
Year = {2021},
Pages = {4479},
Volume = {21},
Number = {13},
Month = {JUL},
Abstract = {This paper proposes and implements a lightweight, ``real-time{''}
   localization system (SORLA) with artificial landmarks (reflectors),
   which only uses LiDAR data for the laser odometer compensation in the
   case of high-speed or sharp-turning. Theoretically, due to the
   feature-matching mechanism of the LiDAR, locations of multiple
   reflectors and the reflector layout are not limited by geometrical
   relation. A series of algorithms is implemented to find and track the
   features of the environment, such as the reflector localization method,
   the motion compensation technique, and the reflector matching
   optimization algorithm. The reflector extraction algorithm is used to
   identify the reflector candidates and estimates the precise center
   locations of the reflectors from 2D LiDAR data. The motion compensation
   algorithm predicts the potential velocity, location, and angle of the
   robot without odometer errors. Finally, the matching optimization
   algorithm searches the reflector combinations for the best matching
   score, which ensures that the correct reflector combination could be
   found during the high-speed movement and fast turning. All those
   mechanisms guarantee the algorithm's precision and robustness in the
   high speed and noisy background. Our experimental results show that the
   SORLA algorithm has an average localization error of 6.45 mm at a speed
   of 0.4 m/s, and 9.87 mm at 4.2 m/s, and still works well with the
   angular velocity of 1.4 rad/s at a sharp turn. The recovery mechanism in
   the algorithm could handle the failure cases of reflector occlusion, and
   the long-term stability test of 72 h firmly proves the algorithm's
   robustness. This work shows that the strategy used in the SORLA
   algorithm is feasible for industry-level navigation with high precision
   and a promising alternative solution for SLAM.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Song, Q (Corresponding Author), Chinese Acad Sci, Suzhou Inst Biomed Engn \& Technol, Suzhou 215163, Peoples R China.
   Song, Q (Corresponding Author), Pilot AI Co, Hangzhou 310000, Peoples R China.
   Wang, Sen; Li, Yongyao, Changchun Univ Sci \& Technol, Sch Elect \& Informat Engn, Changchun 130022, Peoples R China.
   Chen, Xiaohe; Xu, Wenchang; Gong, Yan; Song, Qi, Chinese Acad Sci, Suzhou Inst Biomed Engn \& Technol, Suzhou 215163, Peoples R China.
   Ding, Guanyu; Song, Qi, Pilot AI Co, Hangzhou 310000, Peoples R China.
   Zhao, Qinglei, Chinese Acad Sci, Changchun Inst Opt Fine Mech \& Phys, Changchun 130033, Peoples R China.},
DOI = {10.3390/s21134479},
Article-Number = {4479},
EISSN = {1424-8220},
Keywords = {LiDAR navigation; reflector localization; motion compensation; reflector
   matching; high-speed movement},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {2019100549@mails.cust.edu.cn
   chenxh@sibet.ac.cn
   dingguanyu@gmail.com
   liyongyao@mails.cust.edu.cn
   xuwc@sibet.ac.cn
   coldsun@sina.com
   gongy@sibet.ac.cn
   songq@sibet.ac.cn},
Affiliations = {Changchun University of Science \& Technology; Chinese Academy of
   Sciences; Suzhou Institute of Biomedical Engineering \& Technology, CAS;
   Chinese Academy of Sciences; Changchun Institute of Optics, Fine
   Mechanics \& Physics, CAS},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61975228]},
Funding-Text = {This work was supported by the National Natural Science Foundation of
   China (\#61975228).},
Cited-References = {Beinschob P, 2015, INT C INTELL COMP CO, P245, DOI 10.1109/ICCP.2015.7312637.
   Bordoy J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041177.
   Chen X, 2017, IEEE SENS J, V17, P7143, DOI 10.1109/JSEN.2017.2749762.
   Davidek D, 2016, IFAC PAPERSONLINE, V49, P346, DOI 10.1016/j.ifacol.2016.12.063.
   Doer C., 2017, Gyroscopy and Navigation, V8, P181, DOI 10.1134/S2075108717030038.
   Gao RQ, 2019, OPT COMMUN, V446, P56, DOI 10.1016/j.optcom.2019.04.057.
   Gao RQ, 2018, PROC SPIE, V10823, DOI 10.1117/12.2500902.
   Ghallabi F, 2019, IEEE INT C INTELL TR, P4412, DOI 10.1109/ITSC.2019.8917057.
   Guo S, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419862985.
   Guo S, 2018, ADV MANUF, V6, P118, DOI 10.1007/s40436-018-0216-y.
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396.
   Hojabri H, 2011, IEEE T IND ELECTRON, V58, P949, DOI 10.1109/TIE.2010.2048836.
   Kim J, 2016, IEEE T IND ELECTRON, V63, P3616, DOI 10.1109/TIE.2016.2523460.
   Krinkin K, 2018, PROC CONF OPEN INNOV, P101, DOI 10.23919/FRUCT.2018.8468263.
   Lee HW, 2007, APPL OPTICS, V46, P2205, DOI 10.1364/AO.46.002205.
   Lin WY, 2017, 2017 32ND YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P1211, DOI 10.1109/YAC.2017.7967597.
   Liu F, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11222628.
   Mitterer T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040813.
   Moreno H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041102.
   Palacin J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092500.
   Park S, 2009, IEEE T IND ELECTRON, V56, P2366, DOI 10.1109/TIE.2009.2013690.
   Ravankar A, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/63540.
   Reinke Christoph, 2013, 2013 IEEE 9th International Conference on Intelligent Computer Communication and Processing (ICCP 2013), P223, DOI 10.1109/ICCP.2013.6646112.
   Ronzoni Davide, 2011, 2011 IEEE International Conference on Robotics and Automation, P287.
   Rubio F, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419839596.
   Song Q, 2020, IEEE ACCESS, V8, P62107, DOI 10.1109/ACCESS.2020.2984695.
   Song Z, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P952, DOI 10.1109/ROBIO.2016.7866447.
   Tomazic S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082857.
   Xu H, 2016, J ALGORITHMS COMPUT, V10, P158, DOI 10.1177/1748301816649078.
   Xu Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186152.
   Yang SJ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS (ICM), P123, DOI 10.1109/ICMECH.2017.7921091.
   Zhang C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041097.},
Number-of-Cited-References = {32},
Times-Cited = {1},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {15},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {TH3LI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000671993900001},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@article{ WOS:000375153700073,
Author = {Rituerto, Alejandro and Andreasson, Henrik and Murillo, Ana C. and
   Lilienthal, Achim and Jesus Guerrero, Jose},
Title = {Building an Enhanced Vocabulary of the Robot Environment with a Ceiling
   Pointing Camera},
Journal = {SENSORS},
Pages = {493},
Year = {2016},
Volume = {16},
Number = {4},
Month = {APR},
Abstract = {Mobile robots are of great help for automatic monitoring tasks in
   different environments. One of the first tasks that needs to be
   addressed when creating these kinds of robotic systems is modeling the
   robot environment. This work proposes a pipeline to build an enhanced
   visual model of a robot environment indoors. Vision based recognition
   approaches frequently use quantized feature spaces, commonly known as
   Bag of Words (BoW) or vocabulary representations. A drawback using
   standard BoW approaches is that semantic information is not considered
   as a criteria to create the visual words. To solve this challenging
   task, this paper studies how to leverage the standard vocabulary
   construction process to obtain a more meaningful visual vocabulary of
   the robot work environment using image sequences. We take advantage of
   spatio-temporal constraints and prior knowledge about the position of
   the camera. The key contribution of our work is the definition of a new
   pipeline to create a model of the environment. This pipeline
   incorporates (1) tracking information to the process of vocabulary
   construction and (2) geometric cues to the appearance descriptors.
   Motivated by long term robotic applications, such as the aforementioned
   monitoring tasks, we focus on a configuration where the robot camera
   points to the ceiling, which captures more stable regions of the
   environment. The experimental validation shows how our vocabulary models
   the environment in more detail than standard vocabulary approaches,
   without loss of recognition performance. We show different robotic tasks
   that could benefit of the use of our visual vocabulary approach, such as
   place recognition or object discovery. For this validation, we use our
   publicly available data-set.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Rituerto, A (Corresponding Author), Univ Zaragoza, Dept Informat \& Ingn Sistemas, Inst Invest Ingn Aragon, Zaragoza 50018, Spain.
   Rituerto, Alejandro; Murillo, Ana C.; Jesus Guerrero, Jose, Univ Zaragoza, Dept Informat \& Ingn Sistemas, Inst Invest Ingn Aragon, Zaragoza 50018, Spain.
   Andreasson, Henrik; Lilienthal, Achim, Univ Orebro, Deptartment Technol, Ctr Appl Autonomous Sensor Syst, SE-70182 Orebro, Sweden.},
DOI = {10.3390/s16040493},
Article-Number = {493},
EISSN = {1424-8220},
Keywords = {visual vocabulary; computer vision; bag of words; robotics; place
   recognition; environment description},
Keywords-Plus = {MOBILE ROBOT; FEATURES; RECOGNITION; SCALE; SLAM; BAG},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {aleritu@gmail.com
   henrik.andreasson@oru.se
   acm@unizar.es
   achim.lilienthal@oru.se
   jguerrer@unizar.es},
Affiliations = {University of Zaragoza; Orebro University},
ResearcherID-Numbers = {Guerrero, Jose J/K-5435-2014
   Lilienthal, Achim/AAB-1119-2019
   Lilienthal, Achim/AAO-6832-2020
   Rituerto Sin, Alejandro/H-4673-2015
   },
ORCID-Numbers = {Guerrero, Jose J/0000-0001-5209-2267
   Lilienthal, Achim/0000-0003-0217-9326
   Rituerto Sin, Alejandro/0000-0001-6738-3382
   Murillo Arnal, Ana Cristina/0000-0002-7580-9037},
Funding-Acknowledgement = {Spanish Government; European Union {[}DPI2015-65962-R]},
Funding-Text = {This work was supported by Spanish Government and European Union under
   project DPI2015-65962-R.},
Cited-References = {Achtert E., 2013, P SIGMOD, P1009, DOI DOI 10.1145/2463676.2463696.
   Arandjelovic R, 2015, LECT NOTES COMPUT SC, V9003, P178, DOI 10.1007/978-3-319-16865-4\_12.
   Astua C, 2014, SENSORS-BASEL, V14, P6734, DOI 10.3390/s140406734.
   Bai S, 2013, MACH VISION APPL, V24, P959, DOI 10.1007/s00138-012-0473-x.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Berg Tamara L., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204174.
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598.
   Bolovinou A, 2013, PATTERN RECOGN, V46, P1039, DOI 10.1016/j.patcog.2012.07.024.
   Bredeche N, 2003, ROBOT AUTON SYST, V43, P149, DOI 10.1016/S0921-8890(02)00356-1.
   Burgard W, 1999, ARTIF INTELL, V114, P3, DOI 10.1016/S0004-3702(99)00070-3.
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021.
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172.
   Chum O, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPRW.2009.5206531.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Doersch C, 2015, COMMUN ACM, V58, P103, DOI 10.1145/2830541.
   Duygulu P, 2011, MACH VISION APPL, V22, P99, DOI 10.1007/s00138-009-0217-8.
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226.
   EVERETT HR, 1995, P SOC PHOTO-OPT INS, V2352, P249, DOI 10.1117/12.198975.
   Fergus R, 2003, PROC CVPR IEEE, P264.
   Fernando B, 2012, PATTERN RECOGN, V45, P897, DOI 10.1016/j.patcog.2011.07.021.
   Fukuda T, 1996, IEEE INT CONF ROBOT, P1720, DOI 10.1109/ROBOT.1996.506960.
   Garcia-Fidalgo E, 2015, ROBOT AUTON SYST, V64, P1, DOI 10.1016/j.robot.2014.11.009.
   Hwang SY, 2011, IEEE T IND ELECTRON, V58, P4804, DOI 10.1109/TIE.2011.2109333.
   Irschara Arnold, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2599, DOI 10.1109/CVPRW.2009.5206587.
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2\_24.
   Jegou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2.
   Ji RR, 2010, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2010.5540118.
   Kani S, 2015, 2015 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P393, DOI 10.1109/SII.2015.7404951.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kostavelis I, 2013, ROBOT AUTON SYST, V61, P1460, DOI 10.1016/j.robot.2013.07.008.
   Kuemmerle R., G2O GEN FRAMEWORK GR.
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845.
   MANTHA BR, 2015, P INT S AUT ROB CONS, V32, P1.
   Mikulik A, 2013, INT J COMPUT VISION, V103, P163, DOI 10.1007/s11263-012-0600-1.
   Myers GK, 2014, MACH VISION APPL, V25, P17, DOI 10.1007/s00138-013-0527-8.
   Penatti OAB, 2014, PATTERN RECOGN, V47, P705, DOI 10.1016/j.patcog.2013.08.012.
   Philbin J., 2008, PROC 2008 IEEE C COM, P1, DOI DOI 10.1109/CVPR.2008.4587635.
   Rituerto A, 2014, ROBOT AUTON SYST, V62, P685, DOI 10.1016/j.robot.2012.10.002.
   Rituerto A., HIERARCHICAL VOCABUL.
   Russell B.C., 2006, IEEE COMP SOC C COMP, P1605, DOI DOI 10.1109/CVPR.2006.326.
   Singh S, 2012, LECT NOTES COMPUT SC, V7573, P73, DOI 10.1007/978-3-642-33709-3\_6.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   SOKAL ROBERT R., 1958, UNIV KANSAS SCI BULL, V38, P1409.
   Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Vieira M, 2016, ADV INTELL SYST, V418, P449, DOI 10.1007/978-3-319-27149-1\_35.
   Wang JJY, 2013, PATTERN RECOGN, V46, P3249, DOI 10.1016/j.patcog.2013.05.001.
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967.
   Wulf O, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1530, DOI 10.1109/IROS.2006.281984.
   Xu D, 2009, IEEE T IND ELECTRON, V56, P1617, DOI 10.1109/TIE.2009.2012457.
   Yang L, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/DYSPAN.2008.47.
   Yang Y, 2011, IEEE I CONF COMP VIS, P1465, DOI 10.1109/ICCV.2011.6126403.},
Number-of-Cited-References = {52},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {17},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {DK8CB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000375153700073},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000317042703009,
Author = {Baldwin, Ian and Newman, Paul},
Book-Group-Author = {IEEE
   Robotics Society of Japan},
Title = {Laser-only road-vehicle localization with dual 2D push-broom LIDARS and
   3D priors},
DOI = {10.1109/IROS.2012.6385677},
Booktitle = {2012 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2012},
Pages = {2490-2497},
Note = {25th IEEE\textbackslash{}RSJ International Conference on Intelligent
   Robots and Systems (IROS), Algarve, PORTUGAL, OCT 07-12, 2012},
Abstract = {We demonstrate the viability of using 2D LIDAR data as the sole means
   for accurate, robust, long-term road-vehicle localization within a prior
   map in a complex, dynamic real-world setting.
   We utilize a dual-LIDAR system - one oriented horizontally, in order to
   infer vehicle linear and rotational velocity, and one declined to
   capture a dense view of the surrounds - that allows us to estimate both
   velocity and position within a prior map. We show how probabilistically
   modelling the noisy local velocity estimates from the horizontal laser
   feed, fusing these estimates with data from the declined LIDAR to form a
   dense 3D swathe and matching this swathe statistically within a map will
   allow for robust, long-term position estimation.
   We accommodate estimation errors induced by passing vehicles,
   pedestrians, ground-strike etc., by learning a positional-dependent
   sensor model - that is, a sensor-model that varies spatially - and show
   that learning such a model for LIDAR data allows us to deal gracefully
   with the complexities of real-world data. We validate the concept over
   more than 9 kilometres of driven distance in and around the town of
   Woodstock, Oxfordshire.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Baldwin, I (Corresponding Author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.
   Baldwin, Ian; Newman, Paul, Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England.},
ISSN = {2153-0858},
ISBN = {978-1-4673-1736-8},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {ib@robots.ox.ac.uk
   pnewman@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
Cited-References = {Baldwin I., 2012, ROB AUT ICRA 2012 IE.
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791.
   Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Bishop CM, 2006, PATTERN RECOGNITION, V4.
   Bohren J, 2008, J FIELD ROBOT, V25, P598, DOI 10.1002/rob.20260.
   Bosse M., 2009, 2009 IEEE INT C ROBO, P4312, DOI {[}10.1109/ROBOT.2009.5152851, DOI 10.1109/ROBOT.2009.5152851].
   Bosse M, 2008, INT J ROBOT RES, V27, P667, DOI 10.1177/0278364908091366.
   Censi A, 2007, IEEE INT CONF ROBOT, P3167, DOI 10.1109/ROBOT.2007.363961.
   Diosi A, 2007, INT J ROBOT RES, V26, P1125, DOI 10.1177/0278364907082042.
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Kummerle Rainer, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P3395, DOI 10.1109/ROBOT.2009.5152365.
   Levinson J., 2007, P ROB SCI SYST C CIT.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Li YM, 2010, SENSORS-BASEL, V10, P10356, DOI 10.3390/s101110356.
   Moosmann F, 2010, IEEE INT CONF ROBOT, P142, DOI 10.1109/ROBOT.2010.5509381.
   Rasmussen CE, 2004, LECT NOTES ARTIF INT, V3176, P63, DOI 10.1007/978-3-540-28650-9\_4.
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423.
   Thrun S, 2006, SPRINGER TRAC ADV RO, V24, P287.},
Number-of-Cited-References = {19},
Times-Cited = {22},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BEK21},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000317042703009},
DA = {2022-05-17},
}

@inproceedings{ WOS:000755125507084,
Author = {Sheng, Diwei and Chai, Yuxiang and Li, Xinru and Feng, Chen and Lin,
   Jianzhe and Silva, Claudio and Rizzo, John-Ross},
Book-Group-Author = {IEEE},
Title = {NYU-VPR: Long-Term Visual Place Recognition Benchmark with View
   Direction and Data Anonymization Influences},
Booktitle = {2021 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2021},
Pages = {9773-9779},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, SEP 27-OCT 01, 2021},
Abstract = {Visual place recognition (VPR) is critical in not only localization and
   mapping for autonomous driving vehicles, but also assistive navigation
   for the visually impaired population. To enable a long-term VPR system
   on a large scale, several challenges need to be addressed. First,
   different applications could require different image view directions,
   such as front views for self-driving cars while side views for the low
   vision people. Second, VPR in metropolitan scenes can often cause
   privacy concerns due to the imaging of pedestrian and vehicle identity
   information, calling for the need for data anonymization before VPR
   queries and database construction. Both factors could lead to VPR
   performance variations that are not well understood yet. To study their
   influences, we present the NYU-VPR dataset that contains more than
   200,000 images over a 2km x2km area near the New York University campus,
   taken within the whole year of 2016. We present benchmark results on
   several popular VPR algorithms showing that side views are significantly
   more challenging for current VPR methods while the influence of data
   anonymization is almost negligible, together with our hypothetical
   explanations and in-depth analysis.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Feng, C (Corresponding Author), NYU, Brooklyn, NY 11201 USA.
   Sheng, Diwei; Chai, Yuxiang; Li, Xinru; Feng, Chen; Lin, Jianzhe; Silva, Claudio; Rizzo, John-Ross, NYU, Brooklyn, NY 11201 USA.},
DOI = {10.1109/IROS51168.2021.9636640},
ISSN = {2153-0858},
ISBN = {978-1-6654-1714-3},
Keywords-Plus = {ARCHITECTURE},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {cfeng@nyu.edu},
Affiliations = {New York University},
Funding-Acknowledgement = {Connected Cities for Smart Mobility towards Accessible and Resilient
   Transportation (C2SMART), a Tier 1 University Center - U.S. Department
   of Transportation {[}69A3351747124]},
Funding-Text = {We would like to thank Carmera for providing the raw NYC image data set
   that we used for creating the NYU-VPR. This research is funded by the
   Connected Cities for Smart Mobility towards Accessible and Resilient
   Transportation (C2SMART), a Tier 1 University Center awarded by U.S.
   Department of Transportation under contract 69A3351747124.},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Chancan M, 2020, IEEE ROBOT AUTOM LET, V5, P993, DOI 10.1109/LRA.2020.2967324.
   Choi Y., 2015, WORKSH VIS PLAC REC.
   DeTone Daniel, 2018, CVPR DEEP LEARN VIS.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Lambert J., 2020, P IEEE C COMP VIS PA.
   Lowe D. G., 1999, P 7 IEEE INT C COMP, DOI DOI 10.1109/ICCV.1999.790410.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Mirowski P., 2019, ARXIV190301292.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Neubert P., 2013, INT C ROB AUT ICRA W, DOI 10.1016/j.cell.2007.12.011.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sattler T, 2012, LECT NOTES COMPUT SC, V7572, P752, DOI 10.1007/978-3-642-33718-5\_54.
   Speciale P, 2019, PROC CVPR IEEE, P5488, DOI 10.1109/CVPR.2019.00564.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119.
   Warburg F, 2020, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR42600.2020.00270.
   Yu X., 2018, P IEEE RSJ INT C INT.
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.},
Number-of-Cited-References = {25},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BS6ZK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000755125507084},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921702013,
Author = {Paton, Michael and MacTavish, Kirk and Warren, Michael and Barfoot,
   Timothy D.},
Book-Group-Author = {IEEE},
Title = {Bridging the Appearance Gap: Multi-Experience Localization for Long-Term
   Visual Teach and Repeat},
DOI = {10.1109/IROS.2016.7759303},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {1918-1925},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {Vision-based, route-following algorithms enable autonomous robots to
   repeat manually taught paths over long distances using inexpensive
   vision sensors. However, these methods struggle with long-term, outdoor
   operation due to the challenges of environmental appearance change
   caused by lighting, weather, and seasons. While techniques exist to
   address appearance change by using multiple experiences over different
   environmental conditions, they either provide topological-only
   localization, require several manually taught experiences in different
   conditions, or require extensive offline mapping to produce metric
   localization. For real-world use, we would like to localize metrically
   to a single manually taught route and gather additional visual
   experiences during autonomous operations. Accordingly, we propose a
   novel multi-experience localization (MEL) algorithm developed
   specifically for route following applications; it provides continuous,
   six-degree-of-freedom (6DOF) localization with relative uncertainty to a
   privileged (manually taught) path using several experiences
   simultaneously. We validate our algorithm through two experiments: i) an
   offline performance analysis on a 9km subset of a challenging 27km
   route-traversal dataset and ii) an online field trial where we
   demonstrate autonomy on a small 250m loop over the course of a sunny
   day. Both exhibit significant appearance change due to lighting
   variation. Through these experiments we show that safe localization can
   he achieved by bridging the appearance gap.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Paton, M (Corresponding Author), Univ Toronto, Inst Aerosp Studies UTIAS, 4925 Dufferin St, Toronto, ON M3H 5T6, Canada.
   Paton, Michael; MacTavish, Kirk; Warren, Michael; Barfoot, Timothy D., Univ Toronto, Inst Aerosp Studies UTIAS, 4925 Dufferin St, Toronto, ON M3H 5T6, Canada.},
ISBN = {978-1-5090-3762-9},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Affiliations = {University of Toronto},
Funding-Acknowledgement = {Clearpath Robotics; Natural Sciences and Engineering Research Council
   (NSERC) through the NSERC Canadian Field Robotics Network (NCFRN)},
Funding-Text = {This work was supported financially and in-kind by Clearpath Robotics
   and the Natural Sciences and Engineering Research Council (NSERC)
   through the NSERC Canadian Field Robotics Network (NCFRN).},
Cited-References = {Anderson S., 2015, P IROS.
   Barfoot TD, 2014, IEEE T ROBOT, V30, P679, DOI 10.1109/TRO.2014.2298059.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   CHLI M, 2008, P EUR C COMP VIS ECC.
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Glover A., 2012, P ICRA.
   Klein George, 2007, P1.
   Krusi P, 2015, J FIELD ROBOT, V32, P534, DOI 10.1002/rob.21524.
   Linegar C., 2015, P ICRA.
   Maddern W., 2015, P ICRA SEATTL WA US.
   McManus C., 2012, P INT C ROB AUT ICRA.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   Mhlfellner P., 2016, J FIELD ROBOTICS EAR.
   Milford M. J., 2012, P ICRA.
   Naseer T., 2014, P C ART INT.
   Ostafew CJ, 2016, J FIELD ROBOT, V33, P133, DOI 10.1002/rob.21587.
   Paton M., 2015, P FIELD SERV ROB FSR.
   Paton M., 2016, J FIELD ROB IN PRESS.
   Pepperell E., 2015, P ICRA.},
Number-of-Cited-References = {21},
Times-Cited = {31},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921702013},
DA = {2022-05-17},
}

@article{ WOS:000370764000001,
Author = {Lowry, Stephanie and Suenderhauf, Niko and Newman, Paul and Leonard,
   John J. and Cox, David and Corke, Peter and Milford, Michael J.},
Title = {Visual Place Recognition: A Survey},
Journal = {IEEE TRANSACTIONS ON ROBOTICS},
Year = {2016},
Volume = {32},
Number = {1},
Pages = {1-19},
Month = {FEB},
Abstract = {Visual place recognition is a challenging problem due to the vast range
   of ways in which the appearance of real-world places can vary. In recent
   years, improvements in visual sensing capabilities, an ever-increasing
   focus on long-term mobile robot autonomy, and the ability to draw on
   state-of-the-art research in other disciplines-particularly recognition
   in computer vision and animal navigation in neuroscience-have all
   contributed to significant advances in visual place recognition systems.
   This paper presents a survey of the visual place recognition research
   landscape. We start by introducing the concepts behind place
   recognition-the role of place recognition in the animal kingdom, how a
   ``place{''} is defined in a robotics context, and the major components
   of a place recognition system. Long-term robot operations have revealed
   that changing appearance can be a significant factor in visual place
   recognition failure; therefore, we discuss how place recognition
   solutions can implicitly or explicitly account for appearance change
   within the environment. Finally, we close with a discussion on the
   future of visual place recognition, in particular with respect to the
   rapid advances being made in the related fields of deep learning,
   semantic scene understanding, and video description.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Lowry, S; Sunderhauf, N; Newman, P; Corke, P; Milford, MJ (Corresponding Author), Queensland Univ Technol, Australian Ctr Robot Vis, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4000, Australia.
   Lowry, S (Corresponding Author), Univ Orebro, Ctr Appl Autonomous Sensor Syst, S-70219 Orebro, Sweden.
   Newman, P (Corresponding Author), Univ Oxford, Dept Engn Sci, Mobile Robot Grp, Oxford OX1 3PJ, England.
   Leonard, JJ (Corresponding Author), MIT, Comp Sci \& Artificial Intelligence Lab, Cambridge, MA 02139 USA.
   Cox, D (Corresponding Author), Harvard Univ, Sch Engn \& Appl Sci, Dept Mol \& Cellular Biol, Cambridge, MA 02138 USA.
   Cox, D (Corresponding Author), Harvard Univ, Sch Engn \& Appl Sci, Ctr Brain Sci, Cambridge, MA 02138 USA.
   Lowry, Stephanie; Suenderhauf, Niko; Corke, Peter; Milford, Michael J., Queensland Univ Technol, Australian Ctr Robot Vis, Sch Elect Engn \& Comp Sci, Brisbane, Qld 4000, Australia.
   Lowry, Stephanie, Univ Orebro, Ctr Appl Autonomous Sensor Syst, S-70219 Orebro, Sweden.
   Newman, Paul, Univ Oxford, Dept Engn Sci, Mobile Robot Grp, Oxford OX1 3PJ, England.
   Leonard, John J., MIT, Comp Sci \& Artificial Intelligence Lab, Cambridge, MA 02139 USA.
   Cox, David, Harvard Univ, Sch Engn \& Appl Sci, Dept Mol \& Cellular Biol, Cambridge, MA 02138 USA.
   Cox, David, Harvard Univ, Sch Engn \& Appl Sci, Ctr Brain Sci, Cambridge, MA 02138 USA.},
DOI = {10.1109/TRO.2015.2496823},
ISSN = {1552-3098},
EISSN = {1941-0468},
Keywords = {Visual place recognition; place recognition},
Keywords-Plus = {HIPPOCAMPAL ENSEMBLE CODE; LOOP-CLOSURE DETECTION; SIMULTANEOUS
   LOCALIZATION; LARGE-SCALE; PROBABILISTIC LOCALIZATION; ROBOT
   LOCALIZATION; COGNITIVE MAPS; SPECIAL-ISSUE; SPATIAL MAP; FAB-MAP},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {stephanie.lowry@oru.se
   niko.suenderhauf@qut.edu.au
   pnewman@robots.ox.ac.uk
   jleonard@csail.mit.edu
   davidcox@fas.harvard.edu
   peter.corke@qut.edu.au
   michael.milford@qut.edu.au},
Affiliations = {Australian Centre for Robotic Vision; Queensland University of
   Technology (QUT); Orebro University; League of European Research
   Universities - LERU; University of Oxford; Massachusetts Institute of
   Technology (MIT); Harvard University; Harvard University},
ResearcherID-Numbers = {Lowry, Stephanie/AAX-2709-2020
   Corke, Peter/C-6770-2009
   Sünderhauf, Niko/O-2192-2017
   Milford, Michael/J-1304-2012
   Cox, David/C-4888-2008},
ORCID-Numbers = {Lowry, Stephanie/0000-0003-3788-499X
   Corke, Peter/0000-0001-6650-367X
   Sünderhauf, Niko/0000-0001-5286-3789
   Milford, Michael/0000-0002-5162-1793
   Cox, David/0000-0002-2189-9743},
Funding-Acknowledgement = {ARC Future Fellowship {[}FT140101229]; Microsoft Research Faculty
   Fellowship; Australian Centre for Robotic Vision; Engineering and
   Physical Sciences Research Council {[}EP/J012017/1] Funding Source:
   researchfish; EPSRC {[}EP/J012017/1, EP/J013501/1] Funding Source: UKRI},
Funding-Text = {This work was supported by an ARC Future Fellowship FT140101229, a
   Microsoft Research Faculty Fellowship, and the Australian Centre for
   Robotic Vision.},
Cited-References = {Abrams A., 2011, P IEEE WORKSH APPL C, P336.
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120.
   Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8\_8.
   Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Andreasson H, 2005, IEEE INT CONF ROBOT, P3348.
   Andreasson H., 2004, 5 IFAC S INT AUT VEH.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Angeli A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1031, DOI 10.1109/IROS.2008.4650675.
   Angeli A, 2008, IEEE INT CONF ROBOT, P1842, DOI 10.1109/ROBOT.2008.4543475.
   Angeli A, 2009, IEEE INT CONF ROBOT, P2029.
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   BAEZA-YATES R., 1999, MODERN INFORM RETRIE.
   Bailey T., 1999, INT C FIELD SERV ROB.
   Bailey T., 2002, THESIS U SYDNEY SYDN.
   Bailey T, 2006, IEEE ROBOT AUTOM MAG, V13, P108, DOI 10.1109/MRA.2006.1678144.
   Barfoot T, 2013, INT J ROBOT RES, V32, P1609, DOI 10.1177/0278364913511182.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bazeille Stephane, 2011, IEEE International Conference on Robotics and Automation, P4067.
   Beeson P, 2005, IEEE INT CONF ROBOT, P4373.
   Beeson P, 2010, INT J ROBOT RES, V29, P428, DOI 10.1177/0278364909100586.
   Bennett ATD, 1996, J EXP BIOL, V199, P219.
   Biber P., 2005, ROB SCI SYST C CAMBR.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   Biswas R, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1014.
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993.
   Borges P, 2010, IEEE INT CONF ROBOT, P4902, DOI 10.1109/ROBOT.2010.5509517.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   Bosse M, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P513, DOI 10.1109/ICIP.2002.1039020.
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339.
   Brooks R., 1985, P IEEE INT C ROB AUT, V2, P824.
   Cadena C., 2011, ICRA WORKSH LONG TER.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222.
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851.
   Carlevaris-Bianco N., 2012, IROS WORKSH LIF LEAR.
   Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Chapoulie A, 2013, IEEE INT C INT ROBOT, P1946, DOI 10.1109/IROS.2013.6696614.
   Chatila R., 1985, POSITION REFERENCING, P138, DOI DOI 10.1109/ROBOT.1985.1087373.
   Chen Z., 2014, AUSTR C ROB AUT MELB.
   Chou TC, 2008, IEEE T KNOWL DATA EN, V20, P289, DOI 10.1109/TKDE.2007.190702.
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Cummins M., 2009, ROB SCI SYST C SEATT.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2007, IEEE INT CONF ROBOT, P2042, DOI 10.1109/ROBOT.2007.363622.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Dayoub F, 2013, IEEE INT C INT ROBOT, P1923, DOI 10.1109/IROS.2013.6696611.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Dong J F, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1473, DOI 10.1109/IROS.2007.4399077.
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958.
   Duckett T., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3841, DOI 10.1109/ROBOT.2000.845330.
   DUDEK G, 1991, IEEE T ROBOTIC AUTOM, V7, P859, DOI 10.1109/70.105395.
   Durrant-Whyte H., 1995, 8 INT S ROB RES NEW, P613.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Eade E., 2008, BRIT MACH VIS C LEED.
   Eade E., 2006, P 16 C UNC ART INT S, V1, P469, DOI DOI 10.1109/CVPR.2006.263.
   Eade E., 2006, BMVC, P7.
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Esterby S. R., 1981, Applied Statistics, V30, P277, DOI 10.2307/2346352.
   Eustice R., 2005, ROB SCI SYST C CAMBR.
   Eustice RM, 2006, INT J ROBOT RES, V25, P1223, DOI 10.1177/0278364906072512.
   Fabrizi E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2972, DOI 10.1109/ROBOT.2000.846479.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Fei-Fei L, 2005, PROC CVPR IEEE, P524.
   Feldman D, 2013, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS (SODA 2013), P1434.
   Filliat D., 2012, 2012 IEEE Conference on Technologies for Practical Robot Applications (TePRA), P127, DOI 10.1109/TePRA.2012.6215666.
   Filliat D., 2002, P 7 INT C SIM AD BEH, P131.
   Filliat D., 2003, COGN SYST RES, V4, P243, DOI DOI 10.1016/S1389-0417(03)00008-1.
   Finman R., 2015, ICRA WORKSH VIS PLAC.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Galvez-Lopez D, 2011, IEEE INT C INT ROBOT, P51, DOI 10.1109/IROS.2011.6048525.
   Garcia-Fidalgo E, 2013, LECT NOTES COMPUT SC, V7887, P277.
   Gil A, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2076, DOI 10.1109/IROS.2006.282483.
   Giovannangeli C, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3293, DOI 10.1109/IROS.2006.282501.
   Girdhar Y, 2014, INT J ROBOT RES, V33, P645, DOI 10.1177/0278364913507325.
   Girdhar Y, 2012, IEEE INT CONF ROBOT, P3490, DOI 10.1109/ICRA.2012.6224657.
   Gothard KM, 1996, J NEUROSCI, V16, P8027.
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382.
   Gutmann J.-S., 1999, Proceedings 1999 IEEE International Symposium on Computational Intelligence in Robotics and Automation. CIRA'99 (Cat. No.99EX375), P318, DOI 10.1109/CIRA.1999.810068.
   Hafez AHA, 2013, IEEE INT C INT ROBOT, P2778, DOI 10.1109/IROS.2013.6696749.
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Harris C. G., 1988, ALVEY VISION C, P1, DOI DOI 10.5244/C.2.23.
   HARRIS CG, 1988, IMAGE VISION COMPUT, V6, P87, DOI 10.1016/0262-8856(88)90003-0.
   Hjort N., 1995, PATTERN RECOGNITION.
   Ho KL, 2007, INT J COMPUT VISION, V74, P261, DOI 10.1007/s11263-006-0020-1.
   Itti L, 2005, PROC CVPR IEEE, P631.
   Jacobs N., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383258.
   Jacobson A, 2015, J FIELD ROBOT, V32, P85, DOI 10.1002/rob.21500.
   Jensen R, 2006, BEHAV ANALYST, V29, P187, DOI 10.1007/BF03392130.
   Johannsson H, 2013, IEEE INT CONF ROBOT, P54, DOI 10.1109/ICRA.2013.6630556.
   Johns E, 2014, INT J COMPUT VISION, V106, P297, DOI 10.1007/s11263-013-0648-6.
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Klein George, 2007, P1.
   Konolige K., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P3041, DOI 10.1109/ICRA.2011.5980074.
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Korrapati H, 2012, IEEE INT CONF ROBOT, P1650, DOI 10.1109/ICRA.2012.6224892.
   Kortenkamp D., 1992, P 1992 IEEE RSJ INT, V3, P2209.
   Kosecka J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008.
   Krajnik T, 2014, IEEE INT C INT ROBOT, P4537, DOI 10.1109/IROS.2014.6943205.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Krose BJA, 2001, IMAGE VISION COMPUT, V19, P381, DOI 10.1016/S0262-8856(00)00086-X.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5.
   Kuipers B, 1978, COGNITIVE SCI, V2, P129, DOI {[}DOI 10.1207/S15516709COG0202\_3, 10.1207/s15516709cog0202\_3].
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Lamon P, 2001, IEEE INT CONF ROBOT, P1609, DOI 10.1109/ROBOT.2001.932841.
   Latif Y., 2014, ROB SCI SYST C BERK.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Li FY, 2006, IEEE INT CONF ROBOT, P3405, DOI 10.1109/ROBOT.2006.1642222.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Liu Y, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1261, DOI 10.1109/ICMA.2013.6618095.
   Liu Y, 2012, IEEE INT C INT ROBOT, P1051, DOI 10.1109/IROS.2012.6386145.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Lowry S., 2014, AUSTR C ROB AUT MELB.
   Lowry SM, 2014, IEEE INT CONF ROBOT, P3950, DOI 10.1109/ICRA.2014.6907432.
   Lu F, 1997, AUTON ROBOT, V4, P333, DOI 10.1023/A:1008854305733.
   Lynch K., 1960, IMAGE CITY, P1.
   Lynen Simon, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P303, DOI 10.1109/3DV.2014.36.
   Maddern W., 2014, ICRA WORKSH VIS PLAC.
   Maddern W., 2012, RSS WORK ALT SENS TE.
   Maddern W, 2012, IEEE INT CONF ROBOT, P822, DOI 10.1109/ICRA.2012.6224622.
   Maddern W, 2012, INT J ROBOT RES, V31, P429, DOI 10.1177/0278364912438273.
   Mahon I, 2008, IEEE T ROBOT, V24, P1002, DOI 10.1109/TRO.2008.2004888.
   McManus C., 2014, ROB SCI SYST C BERK.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   McManus C, 2013, ROBOT AUTON SYST, V61, P836, DOI 10.1016/j.robot.2013.04.008.
   Mei C., 2009, BRIT MACH VIS C LOND.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Mei C, 2010, IEEE INT C INT ROBOT, P3738, DOI 10.1109/IROS.2010.5652266.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561.
   Mikulik A, 2010, LECT NOTES COMPUT SC, V6313, P1.
   Milford M, 2014, IEEE INT CONF ROBOT, P5571, DOI 10.1109/ICRA.2014.6907678.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Milford MJ, 2008, IEEE T ROBOT, V24, P1038, DOI 10.1109/TRO.2008.2004520.
   Milford MJ, 2013, IEEE INT CONF ROBOT, P3755, DOI 10.1109/ICRA.2013.6631105.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Milford MJ, 2004, IEEE INT CONF ROBOT, P403, DOI 10.1109/ROBOT.2004.1307183.
   Mohan M, 2015, IEEE INT CONF ROBOT, P5487, DOI 10.1109/ICRA.2015.7139966.
   Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
   Morris T, 2014, IEEE INT CONF ROBOT, P2765, DOI 10.1109/ICRA.2014.6907255.
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Murillo AC, 2007, IEEE INT CONF ROBOT, P3901, DOI 10.1109/ROBOT.2007.364077.
   Murillo A C, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2196, DOI 10.1109/ICCVW.2009.5457552.
   Murillo AC, 2013, IEEE T ROBOT, V29, P146, DOI 10.1109/TRO.2012.2220211.
   Murphy L, 2014, IEEE INT CONF ROBOT, P1312, DOI 10.1109/ICRA.2014.6907022.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Neira J., 1997, P 5 INT S INT PROB S, P275.
   Neira J, 2008, IEEE T ROBOT, V24, P929, DOI 10.1109/TRO.2008.2004620.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378.
   Newman P, 2005, IEEE INT CONF ROBOT, P635.
   Newman P, 2009, INT J ROBOT RES, V28, P1406, DOI 10.1177/0278364909341483.
   Nicosevici T, 2012, IEEE T ROBOT, V28, P886, DOI 10.1109/TRO.2012.2192013.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Nuske S, 2009, J FIELD ROBOT, V26, P728, DOI 10.1002/rob.20306.
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1.
   OKEEFE J, 1978, EXP BRAIN RES, V31, P573.
   OKEEFE J, 1976, EXP NEUROL, V51, P78, DOI 10.1016/0014-4886(76)90055-8.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Olson E, 2013, INT J ROBOT RES, V32, P826, DOI 10.1177/0278364913479413.
   Olson E, 2009, ROBOT AUTON SYST, V57, P1157, DOI 10.1016/j.robot.2009.07.021.
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222.
   Paul R, 2014, IEEE INT CONF ROBOT, P1304, DOI 10.1109/ICRA.2014.6907021.
   Paul R, 2013, INT J ROBOT RES, V32, P1742, DOI 10.1177/0278364913509859.
   Paul R, 2012, IEEE INT CONF ROBOT, P4058, DOI 10.1109/ICRA.2012.6224762.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Pepperell E, 2014, IEEE INT CONF ROBOT, P1612, DOI 10.1109/ICRA.2014.6907067.
   Pronobis A, 2012, IEEE INT CONF ROBOT, P3515, DOI 10.1109/ICRA.2012.6224637.
   Ranganathan Ananth, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P2017, DOI 10.1109/ROBOT.2009.5152376.
   Ranganathan A., 2010, ROB SCI SYST C ZAR S.
   Ranganathan A, 2013, IEEE INT CONF ROBOT, P3791, DOI 10.1109/ICRA.2013.6631110.
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131.
   Redish AD, 2000, J NEUROSCI, V20, P9298.
   Ross P., 2014, AUSTR C ROB AUT MELB.
   Ross P., 2013, P ROB AUT ACRA 2013.
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023\_34.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178.
   Schindler G., 2007, 2007 IEEE C COMP VIS, P1.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   Shatkay H, 2002, J ARTIF INTELL RES, V16, P167, DOI 10.1613/jair.874.
   Siagian C, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1729.
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424.
   Sibley G., 2009, ROB SCI SYST C SEATT.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Sim R., 2005, IJCAI WORKSH REAS UN, P9.
   Singh G., 2010, ICRA WORKSH OMN ROB.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Smith Randall, 1988, P 4 INT S ROB RES, P467.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Stachniss C., 2005, NAT C ART INT PITTSB.
   STRUMWASSER F, 1958, SCIENCE, V127, P469, DOI 10.1126/science.127.3296.469.
   Stumm E, 2013, IEEE INT C INT ROBOT, P4158, DOI 10.1109/IROS.2013.6696952.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2012, IEEE INT C INT ROBOT, P1879, DOI 10.1109/IROS.2012.6385590.
   Sunderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590.
   Sunderhauf N., 2013, ICRA WORKSH LONG TER.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   TAUBE JS, 1990, J NEUROSCI, V10, P420.
   Thrun S., 2008, SPRINGER HDB ROBOTIC, P871, DOI DOI 10.1007/978-3-540-30301-5\_38.
   Thrun S., 2007, FASTSLAM SCALABLE ME.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626.
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273.
   Triggs B., 2000, VISION ALGORITHMS TH, V1883, DOI {[}DOI 10.1007/3-540-44480-7\_21, 10.1007/3-540-44480-7\_21].
   Tsechpenakis G., 2006, P COMP VIS PATT REC, P155.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Valgren C., 2007, 3 EUR C MOB ROB FREI.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Vlassis N, 1999, IEE CONF PUBL, P821, DOI 10.1049/cp:19991213.
   Vlassis N., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P677, DOI 10.1109/IROS.1999.812758.
   Volkov M, 2015, IEEE INT CONF ROBOT, P3638, DOI 10.1109/ICRA.2015.7139704.
   Walter M., 2013, ROB SCI SYST C BERL.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Wang J., 2005, P IEEE INT C IM PROC, V3.
   Whelan T, 2015, INT J ROBOT RES, V34, P598, DOI 10.1177/0278364914551008.
   WILSON MA, 1993, SCIENCE, V261, P1055, DOI 10.1126/science.8351520.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Wu JX, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4763, DOI 10.1109/IROS.2009.5354164.
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1\_26.},
Number-of-Cited-References = {237},
Times-Cited = {466},
Usage-Count-Last-180-days = {21},
Usage-Count-Since-2013 = {274},
Journal-ISO = {IEEE Trans. Robot.},
Doc-Delivery-Number = {DE6SN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000370764000001},
OA = {Green Submitted},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391310800043,
Author = {Dube, R. and Gawel, A. and Cadena, C. and Siegwart, R. and Freda, L. and
   Gianni, M.},
Editor = {Melo, K},
Title = {3D Localization, Mapping and Path Planning for Search and Rescue
   Operations},
DOI = {10.1109/SSRR.2016.7784311},
Booktitle = {2016 IEEE INTERNATIONAL SYMPOSIUM ON SAFETY, SECURITY, AND RESCUE
   ROBOTICS (SSRR)},
Series = {IEEE International Symposium on Safety Security and Rescue Robots},
Year = {2016},
Pages = {272-273},
Note = {14th IEEE International Symposium on Safety, Security, and Rescue
   Robotics (SSRR), Lausanne, SWITZERLAND, OCT 23-27, 2016},
Abstract = {This work presents our results on 3D robot localization, mapping and
   path planning for the latest joint exercise of the European project
   ``Long-Term Human-Robot Teaming for Robots Assisted Disaster
   Response{''} (TRADR)(1). The full system is operated and evaluated by
   firemen end-users in real-world search and rescue experiments. We
   demonstrate that the system is able to plan a path to a goal position
   desired by the fireman operator in the TRADR Operational Control Unit
   (OCU), using a persistent 3D map created by the robot during previous
   sorties.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dube, R (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Dube, R.; Gawel, A.; Cadena, C.; Siegwart, R., Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Freda, L.; Gianni, M., Sapienza Univ Rome, DIAG, ALCOR Lab, Rome, Italy.},
ISSN = {2374-3247},
ISBN = {978-1-5090-4349-1},
Research-Areas = {Engineering; Robotics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Robotics},
Affiliations = {ETH Zurich; Sapienza University Rome},
ResearcherID-Numbers = {Gianni, Mario/AAX-5406-2020
   Cadena, Cesar/AAM-4987-2020
   Freda, Luigi/AAG-2876-2019
   Siegwart, Roland/A-4495-2008
   },
ORCID-Numbers = {Gianni, Mario/0000-0001-5410-2377
   Cadena, Cesar/0000-0002-2972-6011
   Freda, Luigi/0000-0002-2268-6045
   Siegwart, Roland/0000-0002-2760-7983
   Gawel, Abel/0000-0003-2919-4040},
Cited-References = {Gianni M., 2015, J FIELD ROBOTICS.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Kruijff GJM, 2014, ADV ROBOTICS, V28, P1547, DOI 10.1080/01691864.2014.985335.
   Kubelka V, 2015, J FIELD ROBOT, V32, P447, DOI 10.1002/rob.21535.
   Menna M., 2014, P IEEE RSJ INT C INT.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Tardioli D., 2015, J FIELD ROBOTICS.},
Number-of-Cited-References = {7},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {6},
Doc-Delivery-Number = {BG7HX},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391310800043},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000376668800070,
Author = {Rapp, Matthias and Hahn, Markus and Thom, Markus and Dickmann, Juergen
   and Dietmayer, Klaus},
Book-Group-Author = {IEEE},
Title = {Semi-Markov Process Based Localization using Radar in Dynamic
   Environments},
Booktitle = {2015 IEEE 18TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION
   SYSTEMS},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2015},
Pages = {423-429},
Note = {18th IEEE International Conference on Intelligent Transportation
   Systems, SPAIN, SEP 15-18, 2015},
Abstract = {Automotive localization in urban environment faces natural long-term
   changes of the surroundings. In this work, a robust Monte-Carlo based
   localization is presented. Robustness is achieved through a stochastic
   analysis of previous observations of the area of interest. The model
   uses a grid-based Markov chain to instantly model changes. An extension
   of this model by a Levy process allows statements about reliability and
   prediction for each cell of the grid. Experiments with a vehicle
   equipped with four short range radars show the localization accuracy
   performance improvement in a dynamic environment.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Rapp, M (Corresponding Author), Univ Ulm, Inst Measurement Control \& Microtechnol, D-89069 Ulm, Germany.
   Rapp, Matthias; Thom, Markus; Dietmayer, Klaus, Univ Ulm, Inst Measurement Control \& Microtechnol, D-89069 Ulm, Germany.
   Hahn, Markus; Dickmann, Juergen, Daimler AG, Ulm, Germany.},
DOI = {10.1109/ITSC.2015.77},
ISSN = {2153-0009},
ISBN = {978-1-4673-6596-3},
Keywords-Plus = {MAPS},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation Science \& Technology},
Author-Email = {matthias.rapp@uni-ulm.de
   markus.hahn@daimler.de
   markus.thom@uni-ulm.de
   jurgen.dickmann@daimler.de
   klaus.dietmayer@uni-ulm.de},
Affiliations = {Ulm University; Daimler AG},
Cited-References = {Adams M, 2012, ROBOTIC NAVIGATION AND MAPPING WITH RADAR, P1.
   Anguelov D., 2002, P 18 C UNC ART INT, P10.
   Birk A, 2006, P IEEE, V94, P1384, DOI 10.1109/JPROC.2006.876965.
   Bouzouraa ME, 2010, IEEE INT VEH SYM, P294, DOI 10.1109/IVS.2010.5548106.
   Coue C, 2006, INT J ROBOT RES, V25, P19, DOI 10.1177/0278364906061158.
   Fink D., 1997, COMPENDIUM CONJUGATE.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Luber Matthias, 2011, INT J ROBOTICS RES.
   MEDHI J, 1983, STOCHASTIC PROCESSES.
   Meyer-Delius D., 2012, AAAI.
   Meyer-Delius D, 2010, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2010.5648920.
   Montemerlo M, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2436.
   Moravec H., 1985, P 1985 IEEE INT C RO, V2, P116.
   Morris Timothy, 2014, IEEE INT C ROB AUT 2.
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604.
   Rapp Matthias, 2015, INT VEH S.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Schreier M, 2014, IEEE INT CONF ROBOT, P3995, DOI 10.1109/ICRA.2014.6907439.
   Shephard N, 2012, BASICS LEVY PROCESSE.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Werber Klaudius, 2015, 2015 IEEE MTTS INT C.
   Wolf DF, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P594.
   Ziegler J, 2014, IEEE INTEL TRANSP SY, V6, P8, DOI 10.1109/MITS.2014.2306552.},
Number-of-Cited-References = {25},
Times-Cited = {11},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BE8OT},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000376668800070},
DA = {2022-05-17},
}

@article{ WOS:000526686300021,
Author = {Clement, Lee and Gridseth, Mona and Tomasi, Justin and Kelly, Jonathan},
Title = {Learning Matchable Image Transformations for Long-Term Metric Visual
   Localization},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2020},
Volume = {5},
Number = {2},
Pages = {1492-1499},
Month = {APR},
Abstract = {Long-term metric self-localization is an essential capability of
   autonomous mobile robots, but remains challenging for vision-based
   systems due to appearance changes caused by lighting, weather, or
   seasonal variations. While experience-based mapping has proven to be an
   effective technique for bridging the `appearance gap,' the number of
   experiences required for reliable metric localization over days or
   months can be very large, and methods for reducing the necessary number
   of experiences are needed for this approach to scale. Taking inspiration
   from color constancy theory, we learn a nonlinear RGB-to-grayscale
   mapping that explicitly maximizes the number of inlier feature matches
   for images captured under different lighting and weather conditions, and
   use it as a pre-processing step in a conventional single-experience
   localization pipeline to improve its robustness to appearance change. We
   train this mapping by approximating the target non-differentiable
   localization pipeline with a deep neural network, and find that
   incorporating a learned low-dimensional context feature can further
   improve cross-appearance feature matching. Using synthetic and
   real-world datasets, we demonstrate substantial improvements in
   localization performance across day-night cycles, enabling continuous
   metric localization over a 30-hour period using a single mapping
   experience, and allowing experience-based localization to scale to long
   deployments with dramatically reduced data requirements.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Clement, L (Corresponding Author), Univ Toronto, Inst Aerosp Studies UTIAS, Space \& Terr Autonomous Robot Syst STARS Lab, Toronto, ON M3H 5T6, Canada.
   Clement, Lee; Tomasi, Justin; Kelly, Jonathan, Univ Toronto, Inst Aerosp Studies UTIAS, Space \& Terr Autonomous Robot Syst STARS Lab, Toronto, ON M3H 5T6, Canada.
   Gridseth, Mona, UTIAS, ASRL, N York, ON M3H 5T6, Canada.},
DOI = {10.1109/LRA.2020.2967659},
ISSN = {2377-3766},
Keywords = {Deep learning in robotics and automation; visual learning; visual-based
   navigation; localization},
Keywords-Plus = {NAVIGATION; VISION; TEACH},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {lee.clement@mail.utoronto.ca
   mona.gridseth@robotics.utias.utoronto.ca
   justin.tomasi@mail.utoronto.ca
   jkelly@utias.utoronto.ca},
Affiliations = {University of Toronto},
ORCID-Numbers = {Tomasi, Justin/0000-0002-4284-5269
   Kelly, Jonathan/0000-0002-5528-6136},
Cited-References = {Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Clement L, 2018, IEEE ROBOT AUTOM LET, V3, P2447, DOI 10.1109/LRA.2018.2799741.
   Clement L, 2017, J FIELD ROBOT, V34, P74, DOI 10.1002/rob.21655.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Engel J, 2015, IEEE INT C INT ROBOT, P1935, DOI 10.1109/IROS.2015.7353631.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   GAIDON A, 2016, PROC CVPR IEEE, P4340, DOI DOI 10.1109/CVPR.2016.470.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Gomez-Ojeda R, 2018, IEEE INT CONF ROBOT, P805.
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672.
   Grzeszczuk R., 1998, P C NEUR INF PROC SY, P882.
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123.
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448.
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632.
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6\_43.
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90.
   Kingma D.P., 2015, 3 INT C LEARNING REP.
   Koziel S, 2011, STUD COMPUT INTELL, V356, P33.
   Krajnik T, 2017, ROBOT AUTON SYST, V88, P127, DOI 10.1016/j.robot.2016.11.011.
   Latif Y, 2018, IEEE INT CONF ROBOT, P2349, DOI 10.1109/ICRA.2018.8461081.
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   McManus C, 2015, AUTON ROBOT, V39, P363, DOI 10.1007/s10514-015-9463-y.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   Paszke A, ADV NEURAL INFORM PR.
   Paton M., 2018, FIELD SERVICE ROBOTI, P415.
   Paton M, 2017, J FIELD ROBOT, V34, P98, DOI 10.1002/rob.21669.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Peretroukhin V, 2018, IEEE ROBOT AUTOM LET, V3, P2424, DOI 10.1109/LRA.2017.2778765.
   Porav H, 2018, IEEE INT CONF ROBOT, P1011, DOI 10.1109/ICRA.2018.8462894.
   Ratnasingam S, 2010, J OPT SOC AM A, V27, P286, DOI 10.1364/JOSAA.27.000286.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Seonwook Park, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4523, DOI 10.1109/ICRA.2017.7989525.
   van der Merwe R, 2007, NEURAL NETWORKS, V20, P462, DOI 10.1016/j.neunet.2007.04.023.
   Zhang N, 2018, IEEE INT CONF ROBOT, P828, DOI 10.1109/ICRA.2018.8460674.
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244.},
Number-of-Cited-References = {40},
Times-Cited = {3},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {LE4JU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000526686300021},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000361459500010,
Author = {McManus, Colin and Upcroft, Ben and Newman, Paul},
Title = {Learning place-dependant features for long-term vision-based
   localisation},
Journal = {AUTONOMOUS ROBOTS},
Year = {2015},
Volume = {39},
Number = {3, SI},
Pages = {363-387},
Month = {OCT},
Note = {10th Conference on Robotics - Science and Systems (RSS), Univ Calif,
   Berkeley, CA, JUN, 2014},
Abstract = {This paper presents an alternative approach to the problem of outdoor,
   persistent visual localisation against a known map. Instead of blindly
   applying a feature detector/descriptor combination over all images of
   all places, we leverage prior experiences of a place to learn
   place-dependent feature detectors (i.e., features that are unique to
   each place in our map and used for localisation). Furthermore, as these
   features do not represent low-level structure, like edges or corners,
   but are in fact mid-level patches representing distinctive visual
   elements (e.g., windows, buildings, or silhouettes), we are able to
   localise across extreme appearance changes. Note that there is no
   requirement that the features posses semantic meaning, only that they
   are optimal for the task of localisation. This work is an extension on
   previous work (McManus et al. in Proceedings of robotics science and
   systems, 2014b) in the following ways: (i) we have included a landmark
   refinement and outlier rejection step during the learning phase, (ii) we
   have implemented an asynchronous pipeline design, (iii) we have tested
   on data collected in an urban environment, and (iv) we have implemented
   a purely monocular system. Using over 100 km worth of data for training,
   we present localisation results from Begbroke Science Park and central
   Oxford.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {McManus, C (Corresponding Author), Univ Oxford, Mobile Robot Grp, Oxford, England.
   McManus, Colin; Newman, Paul, Univ Oxford, Mobile Robot Grp, Oxford, England.
   Upcroft, Ben, Queensland Univ Technol, CyPhy Lab, Brisbane, Qld 4001, Australia.},
DOI = {10.1007/s10514-015-9463-y},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Feature learning; Appearance changes; Cross seasonal; Visual
   localisation; Long-term autonomy; Outdoor localisation},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {colin@robots.ox.ac.uk
   ben.upcroft@qut.edu.au
   pnewman@robots.ox.ac.uk},
Affiliations = {University of Oxford; Queensland University of Technology (QUT)},
Funding-Acknowledgement = {Nissan Motor Company; EPSRC Leadership Fellowship Grant
   {[}EP/J012017/1]; V-CHARGE {[}269916]; EPSRC {[}EP/J013501/1,
   EP/J012017/1] Funding Source: UKRI; Engineering and Physical Sciences
   Research Council {[}EP/J012017/1] Funding Source: researchfish},
Funding-Text = {This work would not have been possible without the financial support
   from the Nissan Motor Company, the EPSRC Leadership Fellowship Grant
   (EP/J012017/1), and V-CHARGE (Grant Agreement Number 269916).},
Cited-References = {Anati R., 2012, P IEEE INT C ROB AUT.
   Atanasov N., 2014, P ROB SCI SYST RSS B.
   Bao S. Y., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2025, DOI 10.1109/CVPR.2011.5995462.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Castle R. O., 2007, P IEEE INT C ROB AUT.
   Churchill W., 2012, P INT C ROB AUT SAIN.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597.
   Furgale P., 2001, J FIELD ROBOT, V27, P534.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Johns E., 2013, P INT C ROB AUT.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Ko DW, 2013, IEEE INT C INT ROBOT, P2630, DOI 10.1109/IROS.2013.6696727.
   Konolige K, 2010, INT J ROBOT RES, V29, P941, DOI 10.1177/0278364910370376.
   Lategahn H., 2013, IEEE INT VEH S GOLD.
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164.
   Linegar C., 2015, IEEE INT C ROB AUT I.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Maddern W., 2014, P VIS PLAC REC CHANG.
   McKinnon D., 2012, P IEEE INT C ROB AUT.
   McManus C, 2014, P ROB SCI SYST RSS B.
   McManus C., 2010, SIM LOC MAPP SLAM WO.
   McManus C, 2014, P IEEE INT C ROB AUT.
   McManus C., 2013, P IEEE INT C ROB AUT.
   Milford M, 2012, P IEEE INT C ROB AUT.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Naseer T., 2014, AAAI C ART INT AAAI.
   Neubert P., 2013, EUR C MOB ROB ECMR.
   Pinies P, 2010, J FIELD ROBOT, V27, P561, DOI 10.1002/rob.20355.
   Ranganathan A, 2013, IEEE INT CONF ROBOT, P3791, DOI 10.1109/ICRA.2013.6631110.
   Richardson A., 2013, P IEEE INT C ROB AUT.
   Salas-Moreno R. F., 2013, P IEEE C COMP VIS PA.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Singh S., 2012, P EUR C COMP VIS ECC.
   Stewart A., 2012, P INT C ROB AUT SAIN.
   Stewart A. D., 2015, THESIS U OXFORD.
   Valgren C., 2007, P 3 EUR C MOB ROB EC.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Yi C, 2009, IEEE SYS MAN CYBERN, P2161, DOI 10.1109/ICSMC.2009.5346258.},
Number-of-Cited-References = {41},
Times-Cited = {23},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {CR6LV},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000361459500010},
DA = {2022-05-17},
}

@article{ WOS:000408034300006,
Author = {Sujiwo, Adi and Takeuchi, Eijiro and Morales, Luis Yoichi and Akai,
   Naoki and Darweesh, Hatem and Ninomiya, Yoshiki and Edahiro, Masato},
Title = {Robust and Accurate Monocular Vision-Based Localization in Outdoor
   Environments of Real-World Robot Challenge},
Journal = {JOURNAL OF ROBOTICS AND MECHATRONICS},
Year = {2017},
Volume = {29},
Number = {4, SI},
Pages = {685-696},
Month = {AUG},
Abstract = {This paper describes our approach to perform robust monocular camera
   metric localization in the dynamic environments of Tsukuba Challenge
   2016. We address two issues related to vision-based navigation. First,
   we improved the coverage by building a custom vocabulary out of the
   scene and improving upon place recognition routine which is key for
   global localization. Second, we established possibility of lifelong
   localization by using previous year's map. Experimental results show
   that localization coverage was higher than 90\% for six different data
   sets taken in different years, while localization average errors were
   under 0.2 m. Finally, the average of coverage for data sets tested with
   maps taken in different years was of 75\%.},
Publisher = {FUJI TECHNOLOGY PRESS LTD},
Address = {4F TORANOMON SANGYO BLDG, 2-29, TORANOMON 1-CHOME, MINATO-KU, TOKYO,
   105-0001, JAPAN},
Type = {Article},
Language = {English},
Affiliation = {Sujiwo, A (Corresponding Author), Nagoya Univ, Grad Sch Informat, Dept Informat Engn, Chikusa Ku, Furo Cho,609 Natl Innovat Complex,4F IB South, Nagoya, Aichi 4648603, Japan.
   Sujiwo, Adi; Edahiro, Masato, Nagoya Univ, Grad Sch Informat, Dept Informat Engn, Chikusa Ku, Furo Cho,609 Natl Innovat Complex,4F IB South, Nagoya, Aichi 4648603, Japan.
   Darweesh, Hatem, Nagoya Univ, Grad Sch Informat, Dept Intelligent Syst, Chikusa Ku, Furo Cho,085 IB North, Nagoya, Aichi 4648603, Japan.
   Morales, Luis Yoichi; Akai, Naoki, Nagoya Univ, Inst Innovat Future Soc, Driving Scene Understanding Res Div, Chikusa Ku, Furo Cho,609 Natl Innovat Complex, Nagoya, Aichi 4648603, Japan.
   Ninomiya, Yoshiki, Nagoya Univ, Inst Innovat Future Soc, Intelligent Vehicle Res Div, Chikusa Ku, Furo Cho,609 Natl Innovat Complex, Nagoya, Aichi 4648603, Japan.},
DOI = {10.20965/jrm.2017.p0685},
ISSN = {0915-3942},
EISSN = {1883-8049},
Keywords = {visual localization; field robotics; Tsukuba Challenge},
Keywords-Plus = {PLACE RECOGNITION; NAVIGATION; ORB},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {sujiwo@ertl.jp
   takeuichi@coi.nagoya-u.ac.jp
   morales\_yoichi@coi.nagoya-u.ac.jp
   akai@coi.nagoya-u.ac.jp
   hatem.darweesh@g.sp.m.is.nagoya-u.ac.jp
   ninomiya@coi.nagoya-u.ac.jp
   eda@ertl.jp},
Affiliations = {Nagoya University; Nagoya University; Nagoya University; Nagoya
   University},
ResearcherID-Numbers = {Edahiro, Masato/M-4834-2014},
Funding-Acknowledgement = {MEXT COI stream program, A Diverse and Individualized Social Innovation
   Hub - The ``Mobility Society{''} for the Elderly: Lead to an Active and
   Joyful Lifestyle},
Funding-Text = {This work is supported by MEXT COI stream program, A Diverse and
   Individualized Social Innovation Hub - The ``Mobility Society{''} for
   the Elderly: Lead to an Active and Joyful Lifestyle. The robot for this
   experiment is provided by Tetsuo Tomizawa et al. Our fork of ORB-SLAM is
   available as part of Autoware, open source software for urban autonomous
   driving {[}36].},
Cited-References = {Adams A., 1981, THE NEGATIVE.
   Akai N, 2015, J ROBOT MECHATRON, V27, P327, DOI 10.20965/jrm.2015.p0327.
   Buerki M., 2015, IEEE RSJ INT C INT R.
   Caselitz T., 2016, 2016 IEEE RSJ INT C.
   Chang CK, 2010, IEEE INT C INT ROBOT, P4147, DOI 10.1109/IROS.2010.5649136.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Hartley R., 2003, MULTIPLE VIEW GEOMET.
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3\_54.
   Irie K, 2012, ADV ROBOTICS, V26, P327, DOI 10.1163/156855311X614608.
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740.
   Kato S, 2015, IEEE MICRO, V35, P60, DOI 10.1109/MM.2015.133.
   Kiimmerle R., 2014, J FIELD ROBOTICS.
   Klein George, 2007, P1.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Linegar C., 2015, P IEEE INT C ROB AUT.
   Lourakis M, 2013, LECT NOTES COMPUT SC, V8047, P498, DOI 10.1007/978-3-642-40261-6\_60.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2014, P IEEE C ROB AUT ICR, V2, P3.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Morales Y, 2009, J FIELD ROBOT, V26, P609, DOI 10.1002/rob.20301.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R., 2015, IEEE T ROBOTICS.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Paden B., 2016, IEEE T INTELLIGENT V.
   Ros G., 2012, INT VEH S IV WORKSH.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Siagian C, 2009, IEEE T ROBOT, V25, P861, DOI 10.1109/TRO.2009.2022424.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111.
   Strasdat H., 2010, ROBOTICS SCI SYSTEMS, V2, P7, DOI DOI 10.15607/RSS.2010.VI.010.
   Sujiwo A, 2016, J ROBOT MECHATRON, V28, P479, DOI 10.20965/jrm.2016.p0479.
   Szeliski R, 1997, IEEE T PATTERN ANAL, V19, P506, DOI 10.1109/34.589211.
   Takeuchi E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P3068, DOI 10.1109/IROS.2006.282246.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.},
Number-of-Cited-References = {36},
Times-Cited = {5},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {3},
Journal-ISO = {J. Robot. Mechatron.},
Doc-Delivery-Number = {FE2GI},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000408034300006},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000284150003008,
Author = {Ikeda, Kouichirou and Tanaka, Kanji},
Book-Group-Author = {IEEE},
Title = {Visual Robot Localization Using Compact Binary Landmarks},
Booktitle = {2010 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2010},
Pages = {4397-4403},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Anchorage, AK, MAY 03-08, 2010},
Abstract = {This paper is concerned with the problem of mobile robot localization
   using a novel compact representation of visual landmarks. With recent
   progress in lifelong map-learning as well as in information sharing
   networks, compact representation of a large-size landmark database has
   become crucial. In this paper, we propose a compact binary code (e.g.
   32bit code) landmark representation by employing the semantic hashing
   technique from web-scale image retrieval. We show how well such a binary
   representation achieves compactness of a landmark database while
   maintaining efficiency of the localization system. In our contribution,
   we investigate the cost-performance, the semantic gap, the saliency
   evaluation using the presented techniques as well as challenge to
   further reduce the resources (\#bits) per landmark. Experiments using a
   high-speed car-like robot show promising results.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ikeda, K (Corresponding Author), Univ Fukui, Fac Engn, Fukui, Japan.
   Ikeda, Kouichirou; Tanaka, Kanji, Univ Fukui, Fac Engn, Fukui, Japan.},
DOI = {10.1109/ROBOT.2010.5509579},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4244-5040-4},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Cited-References = {Angeli A, 2008, IEEE INT CONF ROBOT, P1842, DOI 10.1109/ROBOT.2008.4543475.
   BIBER P, 2005, P ROB SCI SYST 1.
   CSURKA G, 2004, ECCV2004 WORKSH STAT.
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Doucet A., 2001, SEQUENTIAL MONTE CAR.
   Douze M, 2009, P INT C IM VID RETR.
   GIONIS A, 1999, P VER LARG DAT C.
   HAYS J, 2008, IEEE COMP VIS PATT R.
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647.
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2.
   JENSFELT P, 1999, T IEEE ROB AUT, P13.
   LENSER S, 2002, P IEEE INT C ROB AUT, P1225.
   Lowe D. G., 1999, P 7 IEEE INT C COMP, DOI DOI 10.1109/ICCV.1999.790410.
   MONTEMERLO M, 2003, THESIS CARNEGIE MELL.
   NEWMAN P, 2008, P ROB SCI SYST 4.
   NISTER D, 2006, P IEEE C COMP VIS PA, P2161.
   Nister D, 2006, J FIELD ROBOT, V23, P3, DOI 10.1002/rob.20103.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   ROSENCRANTZ M, 2003, P UAI.
   Russell B., LABELME OPEN ANNOTAT.
   Saeki Kenichi, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P3523, DOI 10.1109/ROBOT.2009.5152201.
   Sala P, 2006, IEEE T ROBOT, V22, P334, DOI 10.1109/TRO.2005.861480.
   SALAKHUTDINOV R, 2008, INT J APPROXIMATE RE.
   SALTON, 1991, SCIENCE, P253.
   Schindler G., 2007, 2007 IEEE C COMP VIS, P1.
   Sivic J, 2008, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2008.4562950.
   SUKHATME GS, 2007, RSS07 WORKSH.
   Tanaka K, 2008, IEEE INT CONF ROBOT, P2784, DOI 10.1109/ROBOT.2008.4543632.
   Vlassis N, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P7, DOI 10.1109/ROBOT.2002.1013331.
   Williams BT, 2007, ROUTL STUD LITERACY, V3, P1.},
Number-of-Cited-References = {31},
Times-Cited = {9},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BSD39},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000284150003008},
DA = {2022-05-17},
}

@article{ WOS:000280653700018,
Author = {Bacca, B. and Salvi, J. and Batlle, J. and Cufi, X.},
Title = {Appearance-based mapping and localisation using feature stability
   histograms},
Journal = {ELECTRONICS LETTERS},
Year = {2010},
Volume = {46},
Number = {16},
Pages = {1120-U42},
Month = {AUG 5},
Abstract = {Proposed is an appearance-based mapping and localisation method based on
   the human memory model, which is used to build a feature stability
   histogram (FSH) at each node in the robot topological map. FSH registers
   local feature stability over time through a voting scheme, and most
   stable features are considered for mapping and Bayesian localisation.
   Experimental results are presented using omnidirectional images acquired
   through long-term acquisition considering: illumination changes,
   occlusions, random removal of features and perceptual aliasing. This
   method is able to adapt the internal node's representation through time
   to achieve global and local robot localisation.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Bacca, B (Corresponding Author), Univ Girona, VICOROB, Girona 17071, Spain.
   Bacca, B.; Salvi, J.; Cufi, X., Univ Girona, VICOROB, Girona 17071, Spain.
   Salvi, J.; Cufi, X., Univ Girona, Dept Comp Engn, Girona 17071, Spain.
   Bacca, B., Univ Valle, Cali, Colombia.},
DOI = {10.1049/el.2010.1599},
ISSN = {0013-5194},
EISSN = {1350-911X},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic},
Author-Email = {bladimir@eia.udg.edu},
Affiliations = {Universitat de Girona; Universitat de Girona; Universidad del Valle},
ResearcherID-Numbers = {Salvi, Joaquim/L-2648-2014
   },
ORCID-Numbers = {Salvi, Joaquim/0000-0002-9482-7126
   Bacca Cortes, Bladimir/0000-0003-0113-4134},
Funding-Acknowledgement = {Commission of Science and Technology of Spain {[}DPI-2007-66796-C03-02];
   University of Valle {[}644-190495]; LASPAUCOLCIENCIAS {[}136-2008]; 
   {[}SGR2005-01008]},
Funding-Text = {The authors acknowledge the Commission of Science and Technology of
   Spain, project DPI-2007-66796-C03-02, the University of Valle contract
   644-190495, the LASPAUCOLCIENCIAS grant 136-2008, and the research
   group's grant SGR2005-01008.},
Cited-References = {Atkinson RC., 1968, PSYCHOL LEARN MOTIV, P89, DOI {[}10.1016/S0079-7421(08)60422-3, DOI 10.1016/S0079-7421(08)60422-3].
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Orghidan R, 2007, IET COMPUT VIS, V1, P43, DOI 10.1049/iet-cvi:20065003.
   Scaramuzza Davide, 2009, International Journal of Robotics Research, V28, P149, DOI 10.1177/0278364908099858.
   Segvic S, 2009, COMPUT VIS IMAGE UND, V113, P172, DOI 10.1016/j.cviu.2008.08.005.
   Sujan VA, 2006, AUTON ROBOT, V21, P15, DOI 10.1007/s10514-005-6066-z.},
Number-of-Cited-References = {8},
Times-Cited = {9},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Journal-ISO = {Electron. Lett.},
Doc-Delivery-Number = {635KJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000280653700018},
DA = {2022-05-17},
}

@article{ WOS:000282245100025,
Author = {Kawewong, Aram and Tangruamsub, Sirinart and Hasegawa, Osamu},
Title = {Position-Invariant Robust Features for Long-Term Recognition of Dynamic
   Outdoor Scenes},
Journal = {IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS},
Year = {2010},
Volume = {E93D},
Number = {9},
Pages = {2587-2601},
Month = {SEP},
Abstract = {A novel Position-Invariant Robust Feature, designated as PIRF, is
   presented to address the problem of highly dynamic scene recognition.
   The PIRF is obtained by identifying existing local features (i.e. SIFT)
   that have a wide baseline visibility within a place (one place contains
   more than one sequential images). These wide-baseline visible features
   are then represented as a single PIRF, which is computed as an average
   of all descriptors associated with the PIRF. Particularly, PIRFs are
   robust against highly dynamical changes in scene: a single PIRF can be
   matched correctly against many features from many dynamical images. This
   paper also describes an approach to using these features for scene
   recognition. Recognition proceeds by matching an individual PIRF to a
   set of features from test images, with subsequent majority voting to
   identify a place with the highest matched PIRF. The PIRF system is
   trained and tested on 2000+ outdoor omnidirectional images and on COLD
   datasets. Despite its simplicity, PIRF offers a markedly better rate of
   recognition for dynamic outdoor scenes (ca. 90\%) than the use of other
   features. Additionally, a robot navigation system based on PIRF
   (PIRF-Nav) can outperform other incremental topological mapping methods
   in terms of time (70\% less) and memory. The number of PIRFs can be
   reduced further to reduce the time while retaining high accuracy, which
   makes it suitable for long-term recognition and localization.},
Publisher = {IEICE-INST ELECTRONICS INFORMATION COMMUNICATIONS ENG},
Address = {KIKAI-SHINKO-KAIKAN BLDG, 3-5-8, SHIBA-KOEN, MINATO-KU, TOKYO, 105-0011,
   JAPAN},
Type = {Article},
Language = {English},
Affiliation = {Kawewong, A (Corresponding Author), Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Yokohama, Kanagawa 2268503, Japan.
   Kawewong, Aram; Tangruamsub, Sirinart; Hasegawa, Osamu, Tokyo Inst Technol, Dept Computat Intelligence \& Syst Sci, Yokohama, Kanagawa 2268503, Japan.
   Hasegawa, Osamu, Tokyo Inst Technol, Imaging Sci \& Engn Lab, Yokohama, Kanagawa 2268503, Japan.},
DOI = {10.1587/transinf.E93.D.2587},
ISSN = {1745-1361},
Keywords = {scene localization; scale invariant feature transformation (SIFT); scene
   recognition; topological mapping},
Keywords-Plus = {LOCALIZATION; VISION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering},
Author-Email = {kawewong.a.aa@m.titech.ac.jp},
Affiliations = {Tokyo Institute of Technology; Tokyo Institute of Technology},
Funding-Acknowledgement = {New Energy and Industrial Technology Development Organization (NEDO) of
   Japan},
Funding-Text = {This research was supported by the Industrial Technology Research Grant
   Program in 2004 from the New Energy and Industrial Technology
   Development Organization (NEDO) of Japan.},
Cited-References = {Abe Y, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1299, DOI 10.1109/ROBOT.1999.772540.
   Andreasson H, 2008, IEEE T ROBOT, V24, P991, DOI 10.1109/TRO.2008.2004642.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Bailey SN, 2006, NAT METHODS, V3, P117, DOI 10.1038/NMETH848.
   Bay H., 2006, P EUR C COMP VIS.
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276.
   Clemente L. A., 2007, P ROB SCI SYST.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   FEIFEI L, 2005, P IEEE INT C COMP VI.
   Goedeme T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9.
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881.
   Kivinen J., 2007, P IEEE INT C COMP VI.
   KOSECKA J, 2004, P IEEE INT C ROB AUT.
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5.
   Lazebnik S., 2006, P IEEE INT C COMP VI.
   LEDWICH L, 2004, P AUST C ROB AUT.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   LUO J, 2007, P IEEE INT C INT ROB.
   Maeyama S., 1997, P 5 INT S EXP ROB, P185.
   Malik J., 2003, P IEEE INT C COMP VI.
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188.
   Mozos O., 2005, P IEEE INT C ROB AUT.
   Murillo AC, 2007, ROBOT AUTON SYST, V55, P372, DOI 10.1016/j.robot.2006.12.004.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724.
   Pronobis A., 2006, P IEEE RSJ INT C INT.
   Renninger LW, 2004, VISION RES, V44, P2301, DOI 10.1016/j.visres.2004.04.006.
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y.
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688.
   TAN C, 2006, P INT IEEE INT TRANS.
   TAPUS A, 2005, P IEEE INT C INT ROB.
   Thrun S, 1998, IEEE INT CONF ROBOT, P958, DOI 10.1109/ROBOT.1998.677210.
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273.
   Ullah MM, 2008, IEEE INT CONF ROBOT, P530, DOI 10.1109/ROBOT.2008.4543261.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Valgren C., 2008, P IEEE INT C ROB AUT.
   Valgren C., 2007, P IEEE INT C ROB AUT.
   WU J, 2008, P IEEE INT C COMP VI.},
Number-of-Cited-References = {40},
Times-Cited = {17},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IEICE Trans. Inf. Syst.},
Doc-Delivery-Number = {655JC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000282245100025},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370974905109,
Author = {Dong, Jing and Nelson, Erik and Indelman, Vadim and Michael, Nathan and
   Dellaert, Frank},
Book-Group-Author = {IEEE},
Title = {Distributed Real-time Cooperative Localization and Mapping using an
   Uncertainty-Aware Expectation Maximization Approach},
DOI = {10.1109/ICRA.2015.7140012},
Booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2015},
Pages = {5807-5814},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Seattle, WA, MAY 26-30, 2015},
Abstract = {We demonstrate distributed, online, and real-time cooperative
   localization and mapping between multiple robots operating throughout an
   unknown environment using indirect measurements. We present a novel
   Expectation Maximization ( EM) based approach to efficiently identify
   inlier multi-robot loop closures by incorporating robot pose
   uncertainty, which significantly improves the trajectory accuracy over
   long-term navigation. An EM and hypothesis based method is used to
   determine a common reference frame. We detail a 2D laser scan
   correspondence method to form robust correspondences between laser scans
   shared amongst robots. The implementation is experimentally validated
   using teams of aerial vehicles, and analyzed to determine its accuracy,
   computational efficiency, scalability to many robots, and robustness to
   varying environments. We demonstrate through multiple experiments that
   our method can efficiently build maps of large indoor and outdoor
   environments in a distributed, online, and real-time setting.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dong, J (Corresponding Author), Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.
   Dong, Jing; Dellaert, Frank, Georgia Inst Technol, Coll Comp, Atlanta, GA 30332 USA.
   Michael, Nathan, Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Indelman, Vadim, Technion Israel Inst Technol, Aerosp Engn, IL-32000 Haifa, Israel.},
ISSN = {1050-4729},
ISBN = {978-1-4799-6923-4},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {jdong@gatech.edu
   enelson@cmu.edu
   vadim.indelman@technion.ac.il
   nmichael@cmu.edu
   fd27@gatech.edu},
Affiliations = {University System of Georgia; Georgia Institute of Technology; Carnegie
   Mellon University; Technion Israel Institute of Technology},
ORCID-Numbers = {Dellaert, Frank/0000-0002-5532-3566},
Cited-References = {Andersson L., 2008, IEEE INT C ROB AUT I.
   Carlone L, 2010, IEEE INT CONF ROBOT, P243, DOI 10.1109/ROBOT.2010.5509307.
   Cunningham A., 2012, IEEE INT C ROB AUT I.
   Fox D., 2006, P IEEE SPEC ISS MULT, V94.
   Granstrom K, 2009, IEEE INT CONF ROBOT, P1990.
   Howard A, 2006, INT J ROBOT RES, V25, P1243, DOI 10.1177/0278364906072250.
   Indelman V., 2014, IEEE INT C ROB AUT I.
   Indelman V., 2012, INT J ROBOTICS RES, V31.
   Indelman V, 2014, RSS WORKSH DISTR CON.
   Indelman V, 2012, ROBOT AUTON SYST, V60, P822, DOI 10.1016/j.robot.2012.02.003.
   Jun JG, 2003, IEEE WIREL COMMUN, V10, P8, DOI 10.1109/MWC.2003.1241089.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kim B, 2010, IEEE INT CONF ROBOT, P3185, DOI 10.1109/ROBOT.2010.5509154.
   Leung KYK, 2012, J INTELL ROBOT SYST, V66, P321, DOI 10.1007/s10846-011-9620-2.
   Melnyk IV, 2012, IEEE INT CONF ROBOT, P936, DOI 10.1109/ICRA.2012.6225219.
   Merino L, 2006, IEEE ROBOT AUTOM MAG, V13, P53, DOI 10.1109/MRA.2006.1678139.
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331.
   Nelson E., 2014, INT S EXP ROB ISER.
   Tipaldi GD, 2010, IEEE INT CONF ROBOT, P3616, DOI 10.1109/ROBOT.2010.5509864.
   Zhou XS, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1785, DOI 10.1109/IROS.2006.282219.
   Zlot R, 2009, SPR TRA ADV ROBOT, V54, P363.},
Number-of-Cited-References = {21},
Times-Cited = {40},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BE3MR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370974905109},
DA = {2022-05-17},
}

@inproceedings{ WOS:000377221102133,
Author = {Morris, Timothy and Dayoub, Feras and Corke, Peter and Wyeth, Gordon and
   Upcroft, Ben},
Book-Group-Author = {IEEE},
Title = {Multiple map hypotheses for planning and navigating in non-stationary
   environments},
DOI = {10.1109/ICRA.2014.6907255},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2014},
Pages = {2765-2770},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014},
Abstract = {This paper presents a method to enable a mobile robot working in
   non-stationary environments to plan its path and localize within
   multiple map hypotheses simultaneously. The maps are generated using a
   long-term and short-term memory mechanism that ensures only persistent
   configurations in the environment are selected to create the maps. In
   order to evaluate the proposed method, experimentation is conducted in
   an office environment. Compared to navigation systems that use only one
   map, our system produces superior path planning and navigation in a
   non-stationary environment where paths can be blocked periodically, a
   common scenario which poses significant challenges for typical planners.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Morris, T (Corresponding Author), Queensland Univ Technol, CyPhy Lab, Brisbane, Qld 4001, Australia.
   Morris, Timothy; Dayoub, Feras; Corke, Peter; Wyeth, Gordon; Upcroft, Ben, Queensland Univ Technol, CyPhy Lab, Brisbane, Qld 4001, Australia.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-3685-4},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {timothy.morris@qut.edu.au
   feras.dayoub@qut.edu.au
   peter.corke@qut.edu.au
   gordon.wyeth@qut.edu.au
   ben.upcroft@qut.edu.au},
Affiliations = {Queensland University of Technology (QUT)},
ResearcherID-Numbers = {Corke, Peter/C-6770-2009
   },
ORCID-Numbers = {Corke, Peter/0000-0001-6650-367X
   Dayoub, Feras/0000-0002-4234-7374
   Wyeth, Gordon/0000-0002-4996-3612},
Cited-References = {ANGUELOV D, 2002, P 18 C UNC ART INT, P10.
   Dayoub F., 2013, IEEE RSJ INT C INT R.
   Dayoub F, 2011, ROBOT AUTON SYST, V59, P285, DOI 10.1016/j.robot.2011.02.013.
   Dong J F, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P1473, DOI 10.1109/IROS.2007.4399077.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Fox D., 2001, ADV NEURAL INFORM PR, V14, P713.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Hentschel M., 2012, J ROBOTICS, V2011.
   Hornung A, 2013, AUTON ROBOT, V34, P189, DOI 10.1007/s10514-012-9321-0.
   Migliore D., 2009, ICRA WORKSH SAF NAV, P27.
   Ortega S., 2007, THESIS I NATL POLYTE.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Stachniss C., 2005, P C ART INT, P1324.
   Tipaldi G. D., 2012, RSS WORKSH ROB CLUTT.
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229.
   Zhe Liu, 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P46, DOI 10.1109/MFI.2012.6343051.},
Number-of-Cited-References = {16},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE9BP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000377221102133},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000317042704119,
Author = {Latif, Yasir and Cadena, Cesar and Neira, Jose},
Book-Group-Author = {IEEE
   Robotics Society of Japan},
Title = {Realizing, Reversing, Recovering : Incremental Robust Loop Closing over
   time using the iRRR algorithm},
DOI = {10.1109/IROS.2012.6385879},
Booktitle = {2012 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2012},
Pages = {4211-4217},
Note = {25th IEEE\textbackslash{}RSJ International Conference on Intelligent
   Robots and Systems (IROS), Algarve, PORTUGAL, OCT 07-12, 2012},
Abstract = {The ability to reconsider information over time allows to detect
   failures and is crucial for long term robust autonomous robot
   applications. This applies to loop closure decisions in localization and
   mapping systems. This paper describes a method to analyze all available
   information up to date in order to robustly remove past incorrect loop
   closures from the optimization process. The main novelties of our
   algorithm are: 1. incrementally reconsidering loop closures and 2.
   handling multi-session, spatially related or unrelated experiments. We
   validate our proposal in real multi-session experiments showing better
   results than those obtained by state of the art methods.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Latif, Y (Corresponding Author), Univ Zaragoza, I3A, Zaragoza 50018, Spain.
   Latif, Yasir; Cadena, Cesar; Neira, Jose, Univ Zaragoza, I3A, Zaragoza 50018, Spain.},
ISSN = {2153-0858},
ISBN = {978-1-4673-1736-8},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {ylatif@unizar.es
   ccadena@unizar.es
   jneira@unizar.es},
Affiliations = {University of Zaragoza},
ResearcherID-Numbers = {Cadena, Cesar/AAM-4987-2020
   Neira, Jose/F-8887-2013
   Neira, Jose/AAM-6571-2020
   Lerma, Cesar D Cadena/X-4739-2018
   },
ORCID-Numbers = {Cadena, Cesar/0000-0002-2972-6011
   Neira, Jose/0000-0003-0668-977X
   Lerma, Cesar D Cadena/0000-0002-2972-6011
   Latif, Yasir/0000-0002-2529-5322},
Cited-References = {Bar-Shalom Y., 2001, ESTIMATION APPL TRAC.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Cummins M, 2010, INT J ROBOT RES.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Latif Y., 2012, P ROB SCI SYST.
   McDonald J., 2011, P EUR C MOB ROB ECMR, P69.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Ranganathan A, 2011, INT J ROBOT RES, V30, P755, DOI 10.1177/0278364910393287.
   RAWSEEDS, 2009, ROB ADV WEBP SENS EL.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Tully S., 2012, INT J ROBOT RES.},
Number-of-Cited-References = {16},
Times-Cited = {17},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Doc-Delivery-Number = {BEK21},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000317042704119},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000435574800011,
Author = {Ouerghi, Safa and Boutteau, Remi and Savatier, Xavier and Thai, Fethi},
Title = {Visual Odometry and Place Recognition Fusion for Vehicle Position
   Tracking in Urban Environments},
Pages = {939},
Journal = {SENSORS},
Year = {2018},
Volume = {18},
Number = {4},
Month = {APR},
Abstract = {In this paper, we address the problem of vehicle localization in urban
   environments. We rely on visual odometry, calculating the incremental
   motion, to track the position of the vehicle and on place recognition to
   correct the accumulated drift of visual odometry, whenever a location is
   recognized. The algorithm used as a place recognition module is SeqSLAM,
   addressing challenging environments and achieving quite remarkable
   results. Specifically, we perform the long-term navigation of a vehicle
   based on the fusion of visual odometry and SeqSLAM. The template library
   for this latter is created online using navigation information from the
   visual odometry module. That is, when a location is recognized, the
   corresponding information is used as an observation of the filter. The
   fusion is done using the EKF and the UKF, the well-known nonlinear state
   estimation methods, to assess the superior alternative. The algorithm is
   evaluated using the KITTI dataset and the results show the reduction of
   the navigation errors by loop-closure detection. The overall position
   error of visual odometery with SeqSLAM is 0.22\% of the trajectory,
   which is much smaller than the navigation errors of visual odometery
   alone 0.45\%. In addition, despite the superiority of the UKF in a
   variety of estimation problems, our results indicate that the UKF
   performs as efficiently as the EKF at the expense of an additional
   computational overhead. This leads to the conclusion that the EKF is a
   better choice for fusing visual odometry and SeqSlam in a long-term
   navigation context.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Ouerghi, S (Corresponding Author), Carthage Univ, SUPCOM, GRESCOM, El Ghazela 2083, Tunisia.
   Ouerghi, Safa; Thai, Fethi, Carthage Univ, SUPCOM, GRESCOM, El Ghazela 2083, Tunisia.
   Boutteau, Remi; Savatier, Xavier, Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, F-76000 Rouen, France.},
DOI = {10.3390/s18040939},
Article-Number = {939},
EISSN = {1424-8220},
Keywords = {real-time navigation; visual-odometry; SeqSLAM; loop-closure; EKF; UKF},
Keywords-Plus = {FAB-MAP; LOCALIZATION},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {safa.ouerghi@supcom.tn
   remi.boutteau@esigelec.fr
   xavier.savatier@esigelec.fr
   fethi.tlili@supcom.tn},
Affiliations = {Universite de Carthage},
ResearcherID-Numbers = {SAVATIER, Xavier/AAG-6093-2019
   Boutteau, Rémi/U-7674-2019},
ORCID-Numbers = {Boutteau, Rémi/0000-0003-1078-5043},
Cited-References = {Baatz G, 2012, INT J COMPUT VISION, V96, P315, DOI 10.1007/s11263-011-0458-7.
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504.
   Bonardi F, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17051167.
   Brubaker MA, 2016, IEEE T PATTERN ANAL, V38, P652, DOI 10.1109/TPAMI.2015.2453975.
   Chu H., 2015, ARXIV151009171.
   Clipp B, 2010, IEEE INT C INT ROBOT, P3961, DOI 10.1109/IROS.2010.5653696.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Floros G, 2013, IEEE INT CONF ROBOT, P1054, DOI 10.1109/ICRA.2013.6630703.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Hentschel M, 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1645, DOI 10.1109/ITSC.2010.5625092.
   Kaess M., 2009, P IEEE INT C ROB AUT.
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419.
   Kalman R. E., 1960, J FLUIDS ENG, V82, P34, DOI {[}https://doi.org/10.1115/1.3662552, DOI 10.1115/1.3662552].
   Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582.
   Kummerle R., 2011, P 2011 IEEE INT C RO.
   Majdik AL, 2014, IEEE INT CONF ROBOT, P920, DOI 10.1109/ICRA.2014.6906964.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Milford M., 2012, P ROB SCI SYST RSS S.
   Milford M, 2013, INT J ROBOT RES, V32, P766, DOI 10.1177/0278364913490323.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513.
   OH S, 2004, P IEEE RSJ INT C INT.
   Ouerghi S., 2017, P 25 INT C COMP GRAP.
   Paul R, 2010, IEEE INT CONF ROBOT, P2649, DOI 10.1109/ROBOT.2010.5509587.
   Pepperell E., 2013, P AUSTR C ROB AUT AR.
   Ranganathan A, 2011, INT J ROBOT RES, V30, P755, DOI 10.1177/0278364910393287.
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233.
   Stone T., 2014, P ROB SCI SYST 10 RS.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2013, P IEEE INT C ROB AUT.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   Thrun Sebastian, 2005, PROBABILISTIC ROBOTI, V1.
   Zhou DF, 2016, IEEE INT VEH SYM, P490, DOI 10.1109/IVS.2016.7535431.},
Number-of-Cited-References = {36},
Times-Cited = {6},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {GJ7NS},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000435574800011},
OA = {Green Published, Green Submitted, gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000380213600015,
Author = {Naseer, Tayyab and Suger, Benjamin and Ruhnke, Michael and Burgard,
   Wolfram},
Book-Group-Author = {IEEE},
Title = {Vision-Based Markov Localization Across Large Perceptual Changes},
DOI = {10.1109/ECMR.2015.7324181},
Pages = {1-6},
Booktitle = {2015 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR)},
Year = {2015},
Note = {European Conference on Mobile Robots, Lincoln, ENGLAND, SEP 02-04, 2015},
Abstract = {Recently, there has been significant progress towards lifelong,
   autonomous operation of mobile robots, especially in the field of
   localization and mapping. One important challenge in this context is
   visual localization under substantial perceptual changes, for example,
   coming from different seasons. In this paper, we present an approach to
   localize a mobile robot with a low frequency camera with respect to an
   image sequence, recorded previously within a different season. Our
   approach uses a discrete Bayes filter and a sensor model based on whole
   image descriptors. Thereby it exploits sequential information to model
   the dynamics of the system. Since we compute a probability distribution
   over the whole state space, our approach can handle more complex
   trajectories that may include same season loop-closures as well as
   fragmented sub-sequences. Throughout an extensive experimental
   evaluation on challenging datasets, we demonstrate that our approach
   outperforms state-of-the-art techniques.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Naseer, T (Corresponding Author), Univ Freiburg, Autonomous Intelligent Syst Grp, Freiburg, Germany.
   Naseer, Tayyab; Suger, Benjamin; Ruhnke, Michael; Burgard, Wolfram, Univ Freiburg, Autonomous Intelligent Syst Grp, Freiburg, Germany.},
ISBN = {978-1-4673-9163-4},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {naseer@informatik.uni-freiburg.de
   suger@informatik.uni-freiburg.de
   ruhnke@informatik.uni-freiburg.de
   burgard@informatik.uni-freiburg.de},
Affiliations = {University of Freiburg},
ResearcherID-Numbers = {Burgard, Wolfram/N-2381-2019},
ORCID-Numbers = {Burgard, Wolfram/0000-0002-5680-6500},
Cited-References = {Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bennewitz M., 2006, EUR ROB S, P143.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Churchill W, 2012, P IEEE INT C ROB AUT.
   Churchill W., 2009, P ROB SCI SYST SEATT.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   DALAL N, 2005, P IEEE INT C COMP VI.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Fox D, 2003, IEEE PERVAS COMPUT, V2, P24, DOI 10.1109/MPRV.2003.1228524.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Hansen P, 2014, IEEE INT C INT ROBOT, P4549, DOI 10.1109/IROS.2014.6943207.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Milford M, 2012, P IEEE INT C ROB AUT.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Naseer T., 2014, AAAI C ART INT AAAI.
   Neubert Peer, 2014, ROBOTICS AUTONOMOUS.
   Pepperell E., 2013, P AUSTR C ROB P AUST.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Vysotska O., 2015, P IEEE INT C ROB AUT.},
Number-of-Cited-References = {20},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BF1AR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380213600015},
DA = {2022-05-17},
}

@article{ WOS:000523846900001,
Author = {Lamarre, Olivier and Limoyo, Oliver and Maric, Filip and Kelly, Jonathan},
Title = {The Canadian Planetary Emulation Terrain Energy-Aware Rover Navigation
   Dataset},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2020},
Volume = {39},
Number = {6},
Pages = {641-650},
Month = {MAY},
Abstract = {Future exploratory missions to the Moon and to Mars will involve
   solar-powered rovers; careful vehicle energy management is critical to
   the success of such missions. This article describes a unique dataset
   gathered by a small, four-wheeled rover at a planetary analog test
   facility in Canada. The rover was equipped with a suite of sensors
   designed to enable the study of energy-aware navigation and path
   planning algorithms. The sensors included a colour omnidirectional
   stereo camera, a monocular camera, an inertial measurement unit, a
   pyranometer, drive power consumption monitors, wheel encoders, and a GPS
   receiver. In total, the rover drove more than 1.2 km over varied terrain
   at the analog test site. All data is presented in human-readable text
   files and as standard-format images; additional Robot Operating System
   (ROS) parsing tools and several georeferenced aerial maps of the test
   environment are also included. A series of potential research use cases
   is described.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Lamarre, O (Corresponding Author), Univ Toronto, Inst Aerosp Studies, 4925 Dufferin St, Toronto, ON M4Y 1G3, Canada.
   Lamarre, Olivier; Limoyo, Oliver; Maric, Filip; Kelly, Jonathan, Univ Toronto, Space \& Terr Autonomous Robot Syst Lab, Inst Aerosp Studies, Toronto, ON, Canada.
   Maric, Filip, Univ Zagreb, Lab Autonomous Syst \& Mobile Robot, Zagreb, Croatia.},
DOI = {10.1177/0278364920908922},
EarlyAccessDate = {MAR 2020},
Article-Number = {0278364920908922},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Planetary robotics; energy-aware path planning; localization and
   mapping; terrain assessment; long-term autonomy},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {olivier.lamarre@robotics.utias.utoronto.ca},
Affiliations = {University of Toronto; University of Zagreb},
ORCID-Numbers = {Lamarre, Olivier/0000-0002-2249-7658},
Funding-Acknowledgement = {Natural Sciences and Engineering Research Council of Canada (NSERC);
   University of Toronto},
Funding-Text = {Dataset collection and processing was supported in part by a Natural
   Sciences and Engineering Research Council of Canada (NSERC) Discovery
   Grant award to Jonathan Kelly and by a Dean's Catalyst Professorship
   from the University of Toronto.},
Cited-References = {Angelova A, 2007, J FIELD ROBOT, V24, P205, DOI 10.1002/rob.20179.
   Arvidson RE, 2017, J FIELD ROBOT, V34, P495, DOI 10.1002/rob.21647.
   Bresina J. L., 2005, ICAPS, P40.
   Di KC, 2011, PHOTOGRAMM ENG REM S, V77, P781, DOI 10.14358/PERS.77.8.781.
   Ebadi K, 2018, P 14 INT S ART INT R.
   Environment and Climate Change Canada, 2019, HIST CLIM DAT.
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514.
   Furgale P, 2012, INT J ROBOT RES, V31, P707, DOI 10.1177/0278364911433135.
   GDAL/OGR contributors, 2019, GDAL OGR GEOSP DAT A.
   Helmick D, 2009, J FIELD ROBOT, V26, P391, DOI 10.1002/rob.20292.
   Heverly M, 2013, J FIELD ROBOT, V30, P835, DOI 10.1002/rob.21481.
   Hewitt RA, 2018, INT J ROBOT RES, V37, P3, DOI 10.1177/0278364917737153.
   Higa S, 2019, IEEE ROBOT AUTOM LET, V4, P3876, DOI 10.1109/LRA.2019.2928765.
   Klein E, 2014, 2014 IEEE AEROSPACE CONFERENCE.
   Masters G.M., 2005, RENEWABLE EFFICIENT.
   MCEWEN AS, 2007, J GEOPHYS RES-PLANET, V112, DOI DOI 10.1029/2005JE002605.
   Otsu K, 2016, SPRINGER TRAC ADV RO, V113, P373, DOI 10.1007/978-3-319-27702-8\_25.
   Qin T., 2019, ABS190103642 CORR.
   Stella PM, 2009, 2009 34 IEEE PHOT SP.
   Tong CH, 2013, INT J ROBOT RES, V32, P389, DOI 10.1177/0278364913478897.
   Vo NN, 2016, LECT NOTES COMPUT SC, V9905, P494, DOI 10.1007/978-3-319-46448-0\_30.
   Workman S., 2015, IEEE INT C COMP VIS.},
Number-of-Cited-References = {22},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {10},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {LD9ZQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000523846900001},
DA = {2022-05-17},
}

@inproceedings{ WOS:000305906400004,
Author = {Lacaze, Alberto and Murphy, Karl and Del Giorno, Mark and Corley,
   Katrina},
Editor = {Karlsen, RE and Gage, DW and Shoemaker, CM and Gerhart, GR},
Title = {Reconnaissance and Autonomy for Small Robots (RASR) team: MAGIC 2010
   Challenge},
Pages = {838704},
Booktitle = {UNMANNED SYSTEMS TECHNOLOGY XIV},
Series = {Proceedings of SPIE},
Year = {2012},
Volume = {8387},
Note = {Conference on Unmanned Systems Technology XIV, Baltimore, MD, APR 25-27,
   2012},
Abstract = {The Reconnaissance and Autonomy for Small Robots (RASR) team developed a
   system for the coordination of groups of unmanned ground vehicles (UGVs)
   that can execute a variety of military relevant missions in dynamic
   urban environments. Historically, UGV operations have been primarily
   performed via tele-operation, requiring at least one dedicated operator
   per robot, and requiring substantial real-time bandwidth to accomplish
   those missions. Our team goal was to develop a system that can provide
   long-term value to the war-fighter, utilizing MAGIC-2010 as a stepping
   stone. To that end, we self-imposed a set of constraints that would
   force us to develop technology that could readily be used by the
   military in the near term:
   Use a relevant (deployed) platform
   Use low-cost, reliable sensors
   Develop an expandable and modular control system with innovative
   software algorithms to minimize the computing footprint required
   Minimize required communications bandwidth and handle communication
   losses
   Minimize additional power requirements to maximize battery life and
   mission duration},
Publisher = {SPIE-INT SOC OPTICAL ENGINEERING},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Lacaze, A (Corresponding Author), Robot Res LLC, 555 Quince Orchard Rd,Ste 300, Gaithersburg, MD 20878 USA.
   Lacaze, Alberto; Murphy, Karl, Robot Res LLC, 555 Quince Orchard Rd,Ste 300, Gaithersburg, MD 20878 USA.
   Del Giorno, Mark, Del Serv LLC, Eldersburg, MD 21784 USA.
   Corley, Katrina, Embry Riddle Aeronaut Univ, Daytona Beach, FL 32114 USA.},
DOI = {10.1117/12.918705},
Article-Number = {838704},
ISSN = {0277-786X},
ISBN = {978-0-8194-9065-0},
Keywords = {MAGIC 2010; UGV; Autonomous; Talon; Path Planning; Mapping/Localization},
Research-Areas = {Computer Science; Engineering; Robotics; Optics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics; Optics},
Affiliations = {Embry-Riddle Aeronautical University},
Cited-References = {ALBUS J, 2002, 4D RCS VERSION 2 0 R.
   Albus J. L, 1996, P INT C INT SYST SEM.
   ALI AI, 1986, DISCRETE APPL MATH, V13, P259.
   Balakirsky S. L, 2002, VALUE DRIVEN BEHAV G.
   Balakirsky S. L, 2000, P 2000 INT VEH C.
   Coombs D. M, 2000, P 2000 INT VEH C.
   GAVISH B, 1986, OPER RES, V34, P698, DOI 10.1287/opre.34.5.698.
   Lacaze A, 2002, P SPIE 16 ANN INT S.
   LACAZE A, 1998, P ISIC CIRA ISAS 98.
   Lacaze A., 2010, PERMIS.
   Lacaze Alberto, 2011, TARDEC Q ROB WORKSH.
   Lacaze A., 2010, LAND WELF C.},
Number-of-Cited-References = {12},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BAX09},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000305906400004},
DA = {2022-05-17},
}

@article{ WOS:000363981000020,
Author = {Perez, Javier and Caballero, Fernando and Merino, Luis},
Title = {Enhanced Monte Carlo Localization with Visual Place Recognition for
   Robust Robot Localization},
Journal = {JOURNAL OF INTELLIGENT \& ROBOTIC SYSTEMS},
Year = {2015},
Volume = {80},
Number = {3-4, SI},
Pages = {641-656},
Month = {DEC},
Abstract = {This paper proposes extending Monte Carlo Localization methods with
   visual place recognition information in order to build a robust robot
   localization system. This system is aimed to work in crowded and
   non-planar scenarios, where 2D laser rangefinders may not always be
   enough to match the robot position within the map. Thus, visual place
   recognition will be used in order to obtain robot position clues that
   can be used to detect when the robot is lost and also to reset its
   positions to the right one. The paper presents experimental results
   based on datasets gathered with a real robot in challenging scenarios.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Perez, J (Corresponding Author), Univ Pablo de Olavide, Seville, Spain.
   Perez, Javier; Merino, Luis, Univ Pablo de Olavide, Seville, Spain.
   Caballero, Fernando, Univ Seville, Seville, Spain.},
DOI = {10.1007/s10846-015-0198-y},
ISSN = {0921-0296},
EISSN = {1573-0409},
Keywords = {Monte Carlo localization; Long-term localization; Robust localization;
   Crowded environment},
Keywords-Plus = {BAGS},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {jiperlar@upo.es
   fcaballero@us.es
   lmercab@upo.es},
Affiliations = {Universidad Pablo de Olavide; University of Sevilla},
ResearcherID-Numbers = {Merino, Luis/B-2549-2013
   Perez Lara, Javier Ignacio/AAA-7159-2022},
ORCID-Numbers = {Merino, Luis/0000-0003-4927-8647
   Perez Lara, Javier Ignacio/0000-0002-1167-7557},
Funding-Acknowledgement = {FP7 FROG Project - European Commission {[}288235]; PAIS-MultiRobot
   Project - Regional Government of Andalucia {[}TIC-7390]},
Funding-Text = {This paper is an extension of work presented at ICARSC 2014 {[}14] and
   is partially supported by the FP7 FROG Project (Contract 288235) funded
   by the European Commission and the PAIS-MultiRobot Project (TIC-7390)
   funded by Regional Government of Andalucia},
Cited-References = {Alcantarilla PF, 2013, AUTON ROBOT, V34, P47, DOI 10.1007/s10514-012-9312-1.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Carloni Luca P, 2009, 2009 3rd ACM/IEEE International Symposium on Networks-on-Chip (NOCS 2009), P1, DOI 10.1109/NOCS.2009.5071456.
   Corke P, 2013, IEEE INT C INT ROBOT, P2085, DOI 10.1109/IROS.2013.6696648.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Hentschel M, 2011, J ROBOT, V2011, DOI 10.1155/2011/506245.
   Himstedt M., 2013, ICRA WORKSH ROB MULT.
   Kummerle R, 2013, IEEE INT CONF ROBOT, P3225, DOI 10.1109/ICRA.2013.6631026.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Perez-Lara J., 2014, P INT S ROB ISR.
   Perez-Lara J., 2014, IEEE INT C AUT ROB S.
   Ruhnke M., 2011, P INT C ROB AUT ICRA.
   Thrun S, 2000, INT J ROBOT RES, V19, P972, DOI 10.1177/02783640022067922.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Wallach MH, 2006, INT C MACHINE LEARNI, P977, DOI DOI 10.1145/1143844.1143967.},
Number-of-Cited-References = {19},
Times-Cited = {14},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {19},
Journal-ISO = {J. Intell. Robot. Syst.},
Doc-Delivery-Number = {CV0YX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000363981000020},
DA = {2022-05-17},
}

@article{ WOS:000439739400008,
Author = {Tejera, Gonzalo and Llofriu, Martin and Barrera, Alejandra and
   Weitzenfeld, Alfredo},
Title = {Bio-Inspired Robotics: A Spatial Cognition Model integrating Place
   Cells, Grid Cells and Head Direction Cells},
Journal = {JOURNAL OF INTELLIGENT \& ROBOTIC SYSTEMS},
Year = {2018},
Volume = {91},
Number = {1, SI},
Pages = {85-99},
Month = {JUL},
Abstract = {The paper presents a bio-inspired robotics model for spatial cognition
   derived from neurophysiological and experimental studies in rats. The
   model integrates Hippocampus place cells providing long-term spatial
   localization with Enthorinal Cortex grid cells providing short-term
   spatial localization in the form of ``neural odometry{''}. Head
   direction cells provide for orientation in the rat brain. The spatial
   cognition model is evaluated in simulation and experimentation showing a
   reduced number of localization errors during robot navigation when
   contrasted to previous versions of our model.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Weitzenfeld, A (Corresponding Author), Univ S Florida, Comp Sci \& Engn, Tampa, FL 33620 USA.
   Tejera, Gonzalo, Univ Republica, Fac Ingn, Montevideo, Uruguay.
   Llofriu, Martin; Weitzenfeld, Alfredo, Univ S Florida, Comp Sci \& Engn, Tampa, FL 33620 USA.
   Barrera, Alejandra, Inst Tecnol Autonomo Mexico, Dept Comp, Mexico City, DF, Mexico.},
DOI = {10.1007/s10846-018-0852-2},
ISSN = {0921-0296},
EISSN = {1573-0409},
Keywords = {Spatial cognition; Robot navigation; Place cells; Grid cells; Head
   direction cells},
Keywords-Plus = {PATH-INTEGRATION; NETWORK MODEL; WATER-MAZE; HIPPOCAMPAL; RAT; MAP;
   REPRESENTATION; NAVIGATION; CA3; INTERFERENCE},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {gtejera@fing.edu.uy
   mllofriualon@mail.usf.edu
   abarrera@itam.mx
   aweitzenfeld@usf.edu},
Affiliations = {Universidad de la Republica, Uruguay; State University System of
   Florida; University of South Florida; Instituto Tecnologico Autonomo de
   Mexico},
ORCID-Numbers = {Tejera, Gonzalo/0000-0003-0373-6200},
Funding-Acknowledgement = {NSF IIS Robust Intelligence research collaboration grant at USF
   {[}1117303]; Agencia Nacional de Investigacion e Innovacion (ANII);
   Asociacion Mexicana de Cultura, A. C; U. Arizona; Direct For Computer \&
   Info Scie \& Enginr {[}1429937] Funding Source: National Science
   Foundation},
Funding-Text = {This work was funded in part by NSF IIS Robust Intelligence research
   collaboration grant \#1117303 at USF and U. Arizona entitled
   ``Investigations of the Role of Dorsal versus Ventral Place and Grid
   Cells during Multi-Scale Spatial Navigation in Rats and Robots,{''} and
   also supported in part by the ``Agencia Nacional de Investigacion e
   Innovacion (ANII){''} and by the ``Asociacion Mexicana de Cultura, A.
   C.{''}},
Cited-References = {Agster KL, 2013, BEHAV BRAIN RES, V254, P50, DOI 10.1016/j.bbr.2013.07.005.
   Alvernhe A, 2012, ANIM COGN, V15, P359, DOI 10.1007/s10071-011-0460-z.
   Antonelo EA, 2009, LECT NOTES COMPUT SC, V5768, P747.
   Arleo A, 2004, IEEE T NEURAL NETWOR, V15, P639, DOI 10.1109/TNN.2004.826221.
   Barrera A, 2008, AUTON ROBOT, V25, P147, DOI 10.1007/s10514-007-9074-3.
   Barrera A, 2015, SPAT COGN COMPUT, V15, P27, DOI 10.1080/13875868.2014.961602.
   Barrera A, 2011, J INTELL ROBOT SYST, V63, P361, DOI 10.1007/s10846-010-9467-y.
   Barto A. G., 1995, MODELS INFORM PROCES, P215.
   Borenstein J, 1996, IEEE T ROBOTIC AUTOM, V12, P869, DOI 10.1109/70.544770.
   BROWN MA, 1995, HIPPOCAMPUS, V5, P171, DOI 10.1002/hipo.450050304.
   Burak Y., 2009, PLOS COMPUT BIOL.
   BURGESS N, 1994, NEURAL NETWORKS, V7, P1065, DOI 10.1016/S0893-6080(05)80159-5.
   Burgess N, 2007, HIPPOCAMPUS, V17, P801, DOI 10.1002/hipo.20327.
   Bush D, 2014, J NEUROSCI, V34, P5065, DOI 10.1523/JNEUROSCI.4017-13.2014.
   Caluwaerts K, 2012, BIOINSPIR BIOMIM, V7, DOI 10.1088/1748-3182/7/2/025009.
   Cheung A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002651.
   Cho JW, 2001, BEHAV NEUROSCI, V115, P3, DOI 10.1037//0735-7044.115.1.3.
   Dolle L, 2010, BIOL CYBERN, V103, P299, DOI 10.1007/s00422-010-0400-z.
   Etienne AS, 2004, HIPPOCAMPUS, V14, P180, DOI 10.1002/hipo.10173.
   Filliat D., 2002, P 7 INT C SIM AD BEH, P131.
   Fuhs MC, 2006, J NEUROSCI, V26, P4266, DOI 10.1523/JNEUROSCI.4353-05.2006.
   Fyhn M, 2004, SCIENCE, V305, P1258, DOI 10.1126/science.1099901.
   Gaussier P, 2002, BIOL CYBERN, V86, P15, DOI 10.1007/s004220100269.
   Gibson J.J., 1977, ECOLOGICAL APPROACH, P67.
   GIBSON JJ, 1954, PSYCHOL REV, V61, P304, DOI 10.1037/h0061885.
   Granon S, 2000, PSYCHOBIOLOGY, V28, P229.
   Guazzelli A, 1998, ADAPT BEHAV, V6, P435, DOI 10.1177/105971239800600305.
   Guzowski JF, 2004, NEURON, V44, P581, DOI 10.1016/j.neuron.2004.11.003.
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721.
   Hasselmo ME, 2007, HIPPOCAMPUS, V17, P1252, DOI 10.1002/hipo.20374.
   Hebb D.O., 2005, ORG BEHAV NEUROPSYCH, DOI DOI 10.4324/9781410612403.
   Houk J.C., 1995, MODELS INFORM PROCES, P249.
   Jeffery KJ, 1999, EXP BRAIN RES, V127, P151, DOI 10.1007/s002210050785.
   Keefe J., 1983, NEUROBIOLOGY HIPPOCA, P375.
   Kelley AE, 2004, NEUROSCI BIOBEHAV R, V27, P765, DOI 10.1016/j.neubiorev.2003.11.015.
   Krupic J, 2012, SCIENCE, V337, P853, DOI 10.1126/science.1222403.
   Leutgeb S, 2004, SCIENCE, V305, P1295, DOI 10.1126/science.1100265.
   Leutgeb S, 2007, LEARN MEMORY, V14, P745, DOI 10.1101/lm.703907.
   MCNAUGHTON BL, 1994, CEREB CORTEX, V4, P27, DOI 10.1093/cercor/4.1.27.
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932.
   McNaughton Bruce L., 1995, P585.
   Mhatre H, 2012, HIPPOCAMPUS, V22, P320, DOI 10.1002/hipo.20901.
   Milford M, 2007, LECT NOTES COMPUT SC, V4736, P203.
   Milford M, 2010, INT J ROBOT RES, V29, P1131, DOI 10.1177/0278364909340592.
   Mittelstaedt M. L., 1982, AVIAN NAVIGATION, P290.
   MORRIS R, 1984, J NEUROSCI METH, V11, P47, DOI 10.1016/0165-0270(84)90007-4.
   MORRIS RGM, 1981, LEARN MOTIV, V12, P239, DOI 10.1016/0023-9690(81)90020-5.
   Moser EI, 2008, ANNU REV NEUROSCI, V31, P69, DOI 10.1146/annurev.neuro.31.061307.090723.
   Navratilova Z., 2011, HIPPOCAMPUS, DOI 10.1002/hipo.20939.
   O'Keefe J., 1978, HIPPOCAMPUS COGNITIV.
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1.
   OKEEFE J, 1978, EXP BRAIN RES, V31, P573.
   Parron C, 2004, EXP BRAIN RES, V159, P349, DOI 10.1007/s00221-004-1960-8.
   POUCET B, 1993, PSYCHOL REV, V100, P163, DOI 10.1037/0033-295X.100.2.163.
   QUIRK GJ, 1990, J NEUROSCI, V10, P2008.
   RANCK J B JR, 1984, Society for Neuroscience Abstracts, V10, P599.
   Redish AD, 1997, HIPPOCAMPUS, V7, P15.
   Rolls E. T., 2005, HEAD DIRECTION CELLS, P299.
   Samu D, 2009, BIOL CYBERN, V101, P19, DOI 10.1007/s00422-009-0311-z.
   Schultz W, 1998, NEUROPHARMACOLOGY, V37, P421, DOI 10.1016/S0028-3908(98)00071-9.
   Solstad T, 2006, HIPPOCAMPUS, V16, P1026, DOI 10.1002/hipo.20244.
   Taube JS, 1998, PROG NEUROBIOL, V55, P225, DOI 10.1016/S0301-0082(98)00004-5.
   TAUBE JS, 1990, J NEUROSCI, V10, P436.
   Tejera G, 2015, IEEE IJCNN.
   Tejera G, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR).
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626.
   Towse B., 2013, PHILOS T ROYAL SOC.},
Number-of-Cited-References = {67},
Times-Cited = {12},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {15},
Journal-ISO = {J. Intell. Robot. Syst.},
Doc-Delivery-Number = {GO1TN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000439739400008},
DA = {2022-05-17},
}

@article{ WOS:000544038100038,
Author = {Tang, Dengqing and Fang, Qiang and Shen, Lincheng and Hu, Tianjiang},
Title = {Onboard Detection-Tracking-Localization},
Journal = {IEEE-ASME TRANSACTIONS ON MECHATRONICS},
Year = {2020},
Volume = {25},
Number = {3},
Pages = {1555-1565},
Month = {JUN},
Abstract = {This article investigates long-term positioning of moving objects by
   monocular vision of a miniature fixed-wing unmanned aerial vehicle. It
   is challenging to perform a real-time onboard vision processing task,
   due to the strict payload capacity and power budget limitations of
   microflying vehicles. We propose a parallel onboard architecture that
   explicitly decouples the long-term positioning task into iteratively
   operated detection, tracking, and localization. The proposed approach is
   eventually called onboard detection-tracking-localization, namely oDTL.
   The detector automatically extracts and identifies the object from image
   frames captured at in-flight durations. A learning-based network is
   constructed to improve detection accuracy and robustness against
   ever-changing outdoor illumination conditions and flying viewpoints. The
   tracker follows the object within specified region-of-interest from
   frame to frame with lower computing consumption. To further reduce
   target-losing rate, a concept of blind zone is proposed and applied, and
   its boundaries in sequential images are also theoretically inferred. The
   position estimator maps the flying vehicle pose, the image coordinates,
   and calibration specifications into real-world positions of the moving
   target. An extended Kalman filter is developed for rough position
   estimation, and a smooth module is introduced for the refinement of the
   position. Three offline comparative experiments and three online
   experiments have been conducted respectively to testify the real-time
   capability of our approach. The collected experimental results also
   demonstrate the feasible accuracy and robustness of the overall solution
   within the specified flying onboard scenarios.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Hu, TJ (Corresponding Author), Sun Yat Sen Univ, Guangzhou 510725, Peoples R China.
   Tang, Dengqing; Fang, Qiang; Shen, Lincheng, Natl Univ Def Technol, Coll Intelligence Sci \& Engn, Changsha 410073, Peoples R China.
   Hu, Tianjiang, Sun Yat Sen Univ, Guangzhou 510725, Peoples R China.},
DOI = {10.1109/TMECH.2020.2976794},
ISSN = {1083-4435},
EISSN = {1941-014X},
Keywords = {Robustness; Real-time systems; Visualization; Lighting; Cameras;
   Three-dimensional displays; IEEE transactions; Detection; localization;
   miniature fixed-wing unmanned aerial vehicle (UAV); monocular; onboard
   vision; parallel architecture; positioning; tracking},
Keywords-Plus = {OBJECT TRACKING; VISION; TARGET},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Manufacturing; Engineering,
   Electrical \& Electronic; Engineering, Mechanical},
Author-Email = {tangdengqing09@nudt.edu.cn
   qiang-fang@hotmail.com
   lcshen@nudt.edu.cn
   hutj3@mail.sysu.edu.cn},
Affiliations = {National University of Defense Technology - China; Sun Yat Sen
   University},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61703418, 61973327]},
Funding-Text = {This work was supported in part by the National Natural Science
   Foundation of China under Grants 61703418 and 61973327.},
Cited-References = {Barber DB, 2006, J INTELL ROBOT SYST, V47, P361, DOI 10.1007/s10846-006-9088-7.
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195.
   CLEVELAND WS, 1981, AM STAT, V35, P54, DOI 10.2307/2683591.
   CLEVELAND WS, 1988, J AM STAT ASSOC, V83, P596, DOI 10.2307/2289282.
   Feng GH, 2015, IEEE INT CONF ROBOT, P1893, DOI 10.1109/ICRA.2015.7139445.
   Feng Y, 2016, SIAM J CONTROL OPTIM, V54, P251, DOI 10.1137/15M1009998.
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584.
   Frew E.W., 2005, P AIAA GUID NAV CONT.
   Gomez-Balderas JE, 2013, J INTELL ROBOT SYST, V70, P65, DOI 10.1007/s10846-012-9747-9.
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974.
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322.
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390.
   Hou YT, 2007, IEEE INFOCOM SER, P1, DOI 10.1109/INFCOM.2007.9.
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291.
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239.
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5\_14.
   Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381.
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0\_2.
   Liu Y, 2016, IEEE T IND ELECTRON, V63, P6205, DOI 10.1109/TIE.2016.2573765.
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177.
   Moranduzzo T, 2014, IEEE T GEOSCI REMOTE, V52, P6356, DOI 10.1109/TGRS.2013.2296351.
   Oh H, 2016, MED C CONTR AUTOMAT, P1230, DOI 10.1109/MED.2016.7535884.
   Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250.
   Pestana J, 2014, P AMER CONTR CONF.
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91.
   REN S, 2015, ADV NEURAL INFORM PR, P91, DOI DOI 10.1109/TPAMI.2016.2577031.
   Ryan A, 2005, IEEE DECIS CONTR P, P1471.
   Shen PY, 2018, IEEE-ASME T MECH, V23, P735, DOI 10.1109/TMECH.2018.2810828.
   Shen PY, 2017, IEEE ROBOT AUTOM LET, V2, P888, DOI 10.1109/LRA.2017.2655580.
   Simonyan K, 2014, C TRACK P.
   Sun QX, 2018, IEEE-ASME T MECH, V23, P1071, DOI 10.1109/TMECH.2017.2773576.
   Teuliere Celine, 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P4929, DOI 10.1109/IROS.2011.6048050.
   Wang MM, 2018, IEEE-ASME T MECH, V23, P997, DOI 10.1109/TMECH.2018.2820172.
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312.
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88.
   Zhang LL, 2018, IEEE T IND ELECTRON, V65, P8052, DOI 10.1109/TIE.2018.2807401.
   Zhang XB, 2011, IEEE T ROBOT, V27, P1167, DOI 10.1109/TRO.2011.2162765.
   Zhao SY, 2015, IEEE T IND ELECTRON, V62, P1210, DOI 10.1109/TIE.2014.2345348.
   Zhou Z, 2019, IEEE ACCESS, V7, P108818, DOI 10.1109/ACCESS.2019.2933228.
   Zuo XZ, 2017, INT CONF ELECTRO INF, P240, DOI 10.1109/EIT.2017.8053362.},
Number-of-Cited-References = {40},
Times-Cited = {6},
Usage-Count-Last-180-days = {7},
Usage-Count-Since-2013 = {20},
Journal-ISO = {IEEE-ASME Trans. Mechatron.},
Doc-Delivery-Number = {MD5UQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000544038100038},
DA = {2022-05-17},
}

@article{ WOS:000071375200011,
Author = {Morris, BJ},
Title = {Stabilization of dendritic mRNAs by nitric oxide allows localized,
   activity-dependent enhancement of hippocampal protein synthesis},
Journal = {EUROPEAN JOURNAL OF NEUROSCIENCE},
Year = {1997},
Volume = {9},
Number = {11},
Pages = {2334-2339},
Month = {NOV},
Abstract = {A small number of mRNA species are not restricted to the neuronal cell
   body, but are also present in neuronal dendrites, The levels of two of
   these dendritic mRNAs, encoding the microtubule-associated protein MAP2
   and the oc subunit of calcium/calmodulin-dependent protein kinase II
   (CamKII alpha), are increased rapidly by high-frequency synaptic
   activity or by release of nitric oxide. To test the hypothesis that
   post-transcriptional mechanisms might contribute to this modulation,
   primary cultures of rat hippocampal neurons were exposed to
   s-nitroso-N-acetyl penicillamine (SNAP, 200 mu M) or vehicle, and mRNA
   stability was determined. The stability of both CamKII alpha mRNA and
   MAP2 mRNA was increased by SNAP treatment, whereas the stabilities of
   tubulin T26 mRNA and proenkephalin mRNA were unaffected. When the
   intensity of staining for MAP2 immunoreactivity and CamKII alpha
   immunoreactivity was monitored in cultured hippocampal neurons, nitric
   oxide-releasing agents induced increases in staining intensity that were
   dependent on protein synthesis but not on mRNA synthesis. These results
   show that nitric oxide can selectively stabilize CamKII alpha mRNA and
   MAP2 mRNA, leading to increased synthesis of the corresponding proteins.
   This demonstrates a mechanism whereby the presence of a particular mRNA
   in the vicinity of a synapse permits the levels of the protein product
   to be regulated by synaptic activity in a manner that is both prolonged
   and also highly localized to the region of stimulation. Thus, the
   dependence of sustained synaptic plasticity on de novo protein synthesis
   need not entail a loss of anatomical specificity.},
Publisher = {BLACKWELL SCIENCE LTD},
Address = {P O BOX 88, OSNEY MEAD, OXFORD OX2 0NE, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Morris, BJ (Corresponding Author), Univ Glasgow, Inst Biomed \& Life Sci, Div Neurosci \& Biomed Syst, Pharmacol Labs, W Med Bldg, Glasgow G12, Lanark, Scotland.
   Univ Glasgow, Inst Biomed \& Life Sci, Div Neurosci \& Biomed Syst, Pharmacol Labs, Glasgow G12, Lanark, Scotland.},
DOI = {10.1111/j.1460-9568.1997.tb01650.x},
ISSN = {0953-816X},
Keywords = {calcium-calmodulin-dependent protein kinase II; microtubule-associated
   protein 2; long-term potentiation; hippocampus; rat; synaptic plasticity},
Keywords-Plus = {LONG-TERM POTENTIATION; RECEPTOR MESSENGER-RNA; IMMEDIATE-EARLY GENE;
   DENTATE GYRUS; GRANULE CELLS; SYNAPTIC ACTIVITY; PYRAMIDAL CELLS;
   LATE-PHASE; KINASE-II; IN-VIVO},
Research-Areas = {Neurosciences \& Neurology},
Web-of-Science-Categories  = {Neurosciences},
Affiliations = {University of Glasgow},
Funding-Acknowledgement = {Wellcome Trust Funding Source: Medline},
Cited-References = {BARZILAI A, 1989, NEURON, V2, P1577, DOI 10.1016/0896-6273(89)90046-9.
   BIGOT D, 1990, NEUROSCI LETT, V111, P275, DOI 10.1016/0304-3940(90)90274-D.
   BIGOT D, 1991, EUR J NEUROSCI, V3, P551, DOI 10.1111/j.1460-9568.1991.tb00842.x.
   BLISS TVP, 1993, NATURE, V361, P31, DOI 10.1038/361031a0.
   BOHME GA, 1991, EUR J PHARMACOL, V199, P379, DOI 10.1016/0014-2999(91)90505-K.
   BOULTON CL, 1995, NEUROSCIENCE, V69, P699, DOI 10.1016/0306-4522(95)00349-N.
   Buchs PA, 1996, P NATL ACAD SCI USA, V93, P8040, DOI 10.1073/pnas.93.15.8040.
   CACERES A, 1992, NEURON, V9, P607, DOI 10.1016/0896-6273(92)90025-9.
   CHANG FLF, 1984, BRAIN RES, V309, P35, DOI 10.1016/0006-8993(84)91008-4.
   DINERMAN JL, 1994, P NATL ACAD SCI USA, V91, P4214, DOI 10.1073/pnas.91.10.4214.
   Doyle C, 1996, J NEUROSCI, V16, P418.
   FAZELI MS, 1993, J NEUROSCI, V13, P1346.
   Frey U, 1996, J PHYSIOL-LONDON, V490, P703, DOI 10.1113/jphysiol.1996.sp021179.
   Frey U, 1997, NATURE, V385, P533, DOI 10.1038/385533a0.
   GOSHIMA Y, 1993, J NEUROSCI, V13, P559.
   HOSOKAWA T, 1995, J NEUROSCI, V15, P5560.
   HUANG YY, 1994, CELL, V79, P69, DOI 10.1016/0092-8674(94)90401-4.
   JAFFREY SR, 1994, P NATL ACAD SCI USA, V91, P12994, DOI 10.1073/pnas.91.26.12994.
   JOHNSTON HM, 1995, MOL BRAIN RES, V31, P141, DOI 10.1016/0169-328X(95)00046-U.
   JOHNSTON HM, 1994, NEUROSCIENCE, V61, P435, DOI 10.1016/0306-4522(94)90423-5.
   JOHNSTON HM, 1994, J NEUROCHEM, V63, P379.
   JOHNSTON HM, 1994, NEUROSCI LETT, V177, P5, DOI 10.1016/0304-3940(94)90031-0.
   Kang HJ, 1996, SCIENCE, V273, P1402, DOI 10.1126/science.273.5280.1402.
   KRUG M, 1984, BRAIN RES BULL, V13, P39, DOI 10.1016/0361-9230(84)90005-4.
   LINK W, 1995, P NATL ACAD SCI USA, V92, P5734, DOI 10.1073/pnas.92.12.5734.
   LYFORD GL, 1995, NEURON, V14, P433, DOI 10.1016/0896-6273(95)90299-6.
   MACKLER SA, 1992, NEURON, V9, P539, DOI 10.1016/0896-6273(92)90191-F.
   MORRIS BJ, 1989, J COMP NEUROL, V290, P358, DOI 10.1002/cne.902900305.
   MORRIS BJ, 1995, TRENDS NEUROSCI, V18, P350, DOI 10.1016/0166-2236(95)93927-P.
   MORRIS BJ, 1995, J BIOL CHEM, V270, P24740.
   MORRIS BJ, 1988, P NATL ACAD SCI USA, V85, P3226, DOI 10.1073/pnas.85.9.3226.
   MOSER MB, 1994, P NATL ACAD SCI USA, V91, P12673, DOI 10.1073/pnas.91.26.12673.
   ODELL TJ, 1991, P NATL ACAD SCI USA, V88, P11285, DOI 10.1073/pnas.88.24.11285.
   OTANI S, 1989, NEUROSCIENCE, V28, P519, DOI 10.1016/0306-4522(89)90001-8.
   PANTOPOULOS K, 1995, P NATL ACAD SCI USA, V92, P1267, DOI 10.1073/pnas.92.5.1267.
   Papa M, 1996, NEUROSCIENCE, V71, P1005, DOI 10.1016/0306-4522(95)00490-4.
   PETTIT DL, 1994, SCIENCE, V266, P17881.
   Roberts LA, 1996, MOL BRAIN RES, V42, P123, DOI 10.1016/S0169-328X(96)00148-9.
   SCHUMAN EM, 1994, SCIENCE, V263, P532, DOI 10.1126/science.8290963.
   SEISER C, 1995, J BIOL CHEM, V270, P29400, DOI 10.1074/jbc.270.49.29400.
   STEWARD O, 1995, J NEUROBIOL, V26, P447, DOI 10.1002/neu.480260316.
   Steward Oswald, 1995, Current Opinion in Neurobiology, V5, P55, DOI 10.1016/0959-4388(95)80087-5.
   THOMAS KL, 1994, NEURON, V13, P737, DOI 10.1016/0896-6273(94)90040-X.
   WISDEN W, 1994, IN SITUR HYBRIDIZATI.
   Zou DJ, 1996, NEURON, V16, P529, DOI 10.1016/S0896-6273(00)80072-0.},
Number-of-Cited-References = {45},
Times-Cited = {19},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Eur. J. Neurosci.},
Doc-Delivery-Number = {YQ337},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000071375200011},
DA = {2022-05-17},
}

@inproceedings{ WOS:000078610000011,
Author = {Feder, HJS and Leonard, JJ and Smith, CM},
Book-Group-Author = {IEEE
   IEEE
   IEEE},
Title = {Incorporating environmental measurements in navigation},
Booktitle = {PROCEEDINGS OF THE 1998 WORKSHOP ON AUTONOMOUS UNDERWATER VEHICLES, (AUV
   `98)},
Year = {1998},
Pages = {115-122},
Note = {1998 Workshop on Autonomous Underwater Vehicles, DRAPER LAB, CAMBRIDGE,
   MA, AUG 20-21, 1998},
Abstract = {Extended missions in unknown regions present a significant navigational
   challenge for autonomous underwater vehicles (AUVs). This paper
   investigates the long-term performance of a concurrent mapping and
   localization (CML) algorithm for the scenario of an A UV making
   observations of point features in the environment with a forward look
   sonar. Simulation results demonstrate that position estimates with
   longterm bounded errors of a few meters can be achieved under realistic
   assumptions about the vehicle, its sensors, and the environment.
   Potential failure modes of the algorithm, such as divergence and map
   slip, are discussed. CML technology can provide a significant
   improvement in the navigational capabilities of AUVs and can enable stew
   missions in unmapped regions without reliance on acoustic beacons or
   surfacing for GPS resets.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Feder, HJS (Corresponding Author), MIT, Dept Ocean Engn, Cambridge, MA 02139 USA.
   MIT, Dept Ocean Engn, Cambridge, MA 02139 USA.},
DOI = {10.1109/AUV.1998.744447},
ISBN = {0-7803-5190-8},
Research-Areas = {Acoustics; Engineering},
Web-of-Science-Categories  = {Acoustics; Engineering, Marine; Engineering, Electrical \& Electronic},
Affiliations = {Massachusetts Institute of Technology (MIT)},
Cited-References = {BARSHALOM Y, 1988, TRACKING DATA ASS.
   CARPENTER RN, 1998, IN PRESS AUV 98.
   FEDER HJS, 1998, IN PRESS IEEE OCEANS.
   FEDER HJS, 1998, 983 MIT MAR ROB LAB.
   GEYER E, 1987, P INT S UNM UNT SUBM, P320.
   Hunt M.H., 1974, WHOI746.
   Kuristsky M., 1990, AUTONOMOUS ROBOT VEH.
   MEDEIROS M, 1996, AUV 96, P10.
   Milne P. H., 1983, UNDERWATER ACOUSTIC.
   MOUTARLIER P, 1989, 1 INT S EXPT ROB MON.
   PAGLIA JG, 1996, IEEE OCEANS, P794.
   Smith C. M., 1997, INT C FIELD SERV ROB.
   SMITH CM, 1997, IEEE OCEANS.
   SMITH CM, 1998, THESIS MIT.
   SMITH R, 1990, AUTONOMOUS ROBOT VEH.
   TUOHY ST, 1996, INT J OFFSHORE POLAR, V6, P9.
   UHLMANN JK, 1997, NONDIVERGENT SIMULTA.
   {[}No title captured].},
Number-of-Cited-References = {18},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BM39S},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000078610000011},
DA = {2022-05-17},
}

@inproceedings{ WOS:000221794800286,
Author = {Williams, S and Mahon, I},
Book-Group-Author = {IEEE},
Title = {Simultaneous localisation and mapping on the great barrier reef},
Booktitle = {2004 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-
   5, PROCEEDINGS},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2004},
Pages = {1771-1776},
Note = {IEEE International Conference on Robotics and Automation, New Orleans,
   LA, APR 26-MAY 01, 2004},
Abstract = {This paper presents results of the application of the Simultaneous
   Localisation and Mapping algorithm to data collected by an Unmanned
   Underwater Vehicle operating on the Great Barrier Reef in Australia. By
   fusing information from the vehicle's on-board sonar and vision systems,
   it is possible to use the highly textured reef to provide estimates of
   the vehicle motion as well as to generate models of the gross structure
   of the underlying reefs. Terrain-aided navigation promises to
   revolutionise the ability of marine systems to track underwater bodies
   in many applications. This work represents a crucial step in the
   development of underwater technologies capable of long-term, reliable
   deployment. Results of the application of this technique to the tracking
   of the vehicle position are shown.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Williams, S (Corresponding Author), Univ Sydney, Sch Aerosp Mech \& Mechatron Engn, ARC Ctr Excellence Autonomous Syst, Sydney, NSW 2006, Australia.
   Univ Sydney, Sch Aerosp Mech \& Mechatron Engn, ARC Ctr Excellence Autonomous Syst, Sydney, NSW 2006, Australia.},
DOI = {10.1109/ROBOT.2004.1308080},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {0-7803-8232-3},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {stefanw@cas.edu.au
   i.mahon@cas.edu.au},
Affiliations = {University of Sydney},
ResearcherID-Numbers = {Williams, Stefan/AAE-4376-2020},
ORCID-Numbers = {Williams, Stefan/0000-0001-9416-5639},
Cited-References = {Castellanos JA, 1999, IEEE T ROBOTIC AUTOM, V15, P948, DOI 10.1109/70.795798.
   CSORBA M, 1997, THESIS U OXFORD.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   Johnson AE, 1996, AUTON ROBOT, V3, P145, DOI 10.1007/BF00141152.
   KARLSSON R, 2002, LITHISYR2474.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   LEONARD JJ, 1999, P 9 INT S ROB RES, P169.
   LUCAS BD, 1981, P 7 INT JOINT C ART, P674.
   MAJUMDER S, 2000, P AUSTR C ROB AUT AU, P25.
   Maybeck P.S, 1982, STOCHASTIC MODELS ES, V1.
   NEWMAN P, 1999, THESIS U SYDNEY.
   RIGAUD V, 1990, P IEEE INT C ROB AUT, V2, P1310.
   Whitcomb L., 1999, 9 INT S ROB RES, P346.
   Wilkinson C, 2002, STATUS CORAL REEFS W.
   Willard MD, 2001, J VET INTERN MED, V15, P5, DOI 10.1111/j.1939-1676.2001.tb02290.x.
   WILLIAMS S, 2001, THESIS U SYDNEY.
   Williams SB, 2003, INT J ROBOT RES, V22, P541, DOI 10.1177/02783649030227006.
   WILLIAMS SB, 2003, P INT C FIELD SERV R, P55.
   {[}No title captured].},
Number-of-Cited-References = {19},
Times-Cited = {66},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BAE24},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000221794800286},
DA = {2022-05-17},
}

@inproceedings{ WOS:000777505000069,
Author = {Alijani, Farid and Peltomaki, Jukka and Puura, Jussi and Huttunen,
   Heikki and Kamarainen, Joni-Kristian and Rahtu, Esa},
Editor = {Farinella, GM and Radeva, P and Bouatouch, K},
Title = {Evaluation of RGB and LiDAR Combination for Robust Place Recognition},
Booktitle = {PROCEEDINGS OF THE 17TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER
   VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP),
   VOL 5},
Series = {VISIGRAPP},
Year = {2022},
Pages = {650-658},
Note = {17th International Joint Conference on Computer Vision, Imaging and
   Computer Graphics Theory and Applications (VISIGRAPP) / 17th
   International Conference on Computer Vision Theory and Applications
   (VISAPP), ELECTR NETWORK, FEB 06-08, 2022},
Abstract = {Place recognition is one of the main challenges in localization, mapping
   and navigation tasks of self-driving vehicles under various perceptual
   conditions, including appearance and viewpoint variations. In this
   paper, we provide a comprehensive study on the utility of fine-tuned
   Deep Convolutional Neural Network (DCNN) with three MAC, SpoC and GeM
   pooling layers to learn global image representation for place
   recognition in an end-to-end manner using three different sensor data
   modalities: (1) only RGB images; (2) only intensity or only depth 3D
   LiDAR point clouds projected into 2D images and (3) early fusion of RGB
   images and LiDAR point clouds (both intensity and depth) to form a
   unified global descriptor to leverage robust features of both
   modalities. The experimental results on a diverse and large long-term
   Oxford Radar RobotCar dataset illustrate an achievement of 5 m outdoor
   place recognition accuracy with high recall rate of 90 using early
   fusion of RGB and LiDAR sensor data modalities when fine-tuned network
   with GeM pooling layer is utilized.},
Publisher = {SCITEPRESS},
Address = {AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Alijani, F (Corresponding Author), Tampere Univ, Tampere, Finland.
   Alijani, Farid; Peltomaki, Jukka; Kamarainen, Joni-Kristian; Rahtu, Esa, Tampere Univ, Tampere, Finland.
   Puura, Jussi, Sandvik Min \& Construct Ltd, Tampere, Finland.
   Huttunen, Heikki, Visy Oy, Tampere, Finland.},
DOI = {10.5220/0010909100003124},
ISSN = {2184-4321},
ISBN = {978-989-758-555-5},
Keywords = {Visual Place Recognition; Image Retrieval; Deep Convolutional Neural
   Network; Deep Learning for Visual Understanding},
Keywords-Plus = {LOCALIZATION; FEATURES},
Research-Areas = {Computer Science; Imaging Science \& Photographic Technology},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Imaging Science \& Photographic Technology},
Affiliations = {Tampere University},
ORCID-Numbers = {Alijani, Farid/0000-0003-3928-7291},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270.
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150.
   Barnes D, 2020, IEEE INT CONF ROBOT, P6433, DOI 10.1109/ICRA40945.2020.9196884.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Chen DM, 2011, PROC CVPR IEEE, P737, DOI 10.1109/CVPR.2011.5995610.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693.
   Dewan A, 2018, IEEE INT C INT ROBOT, P4774, DOI 10.1109/IROS.2018.8594420.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Hadsell R., 2006, 2006 IEEE COMP VIS P, V2, P1735, DOI DOI 10.1109/CVPR.2006.100.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0\_48.
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99.
   Liu Z, 2019, IEEE I CONF COMP VIS, P2831, DOI 10.1109/ICCV.2019.00292.
   Losson O, 2010, ADV IMAG ELECT PHYS, V162, P173, DOI 10.1016/S1076-5670(10)62005-8.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Martinez J, 2020, IEEE INT C INT ROBOT, P4477, DOI 10.1109/IROS45743.2020.9340924.
   Masone C, 2021, IEEE ACCESS, V9, P19516, DOI 10.1109/ACCESS.2021.3054937.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Paszke A, 2019, ADV NEUR IN, V32.
   Qi C. R., 2017, ARXIV170602413.
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566.
   Radenovic F, 2018, LECT NOTES COMPUT SC, V11209, P774, DOI 10.1007/978-3-030-01228-1\_46.
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0\_1.
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y.
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848.
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802.
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114.
   Tolias G., 2016, PARTICULAR OBJECT RE.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Zhang WX, 2019, PROC CVPR IEEE, P12428, DOI 10.1109/CVPR.2019.01272.
   Zhang XW, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107760.
   Zou C, 2019, PATTERN RECOGN LETT, V125, P514, DOI 10.1016/j.patrec.2019.06.009.},
Number-of-Cited-References = {39},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS8TM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000777505000069},
OA = {hybrid},
DA = {2022-05-17},
}

@inproceedings{ WOS:000221794800094,
Author = {Sabe, K and Fukuchi, M and Gutmann, JS and Ohashi, T and Kawamoto, K and
   Yoshigahara, T},
Book-Group-Author = {IEEE},
Title = {Obstacle avoidance and path planning for humanoid robots using stereo
   vision},
Booktitle = {2004 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-
   5, PROCEEDINGS},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2004},
Pages = {592-597},
Note = {IEEE International Conference on Robotics and Automation, New Orleans,
   LA, APR 26-MAY 01, 2004},
Abstract = {This paper presents methods for path planning and obstacle avoidance for
   the humanoid robot QRIO, allowing the robot to autonomously walk around
   in a home environment. For an autonomous robot, obstacle detection and
   localization as well as representing them in a map are crucial tasks for
   the success of the robot. Our approach is based on plane extraction from
   data captured by a stereo-vision system that has been developed
   specifically for QRIO. We briefly overview the general software
   architecture composed of perception, short and long term memory,
   behavior control, and motion control, and emphasize on our methods for
   obstacle detection by plane extraction, occupancy grid mapping, and path
   planning. Experimental results complete the description of our system.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Sabe, K (Corresponding Author), Sony Corp, Tokyo, Japan.
   Sony Corp, Tokyo, Japan.},
DOI = {10.1109/ROBOT.2004.1307213},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {0-7803-8232-3},
Keywords = {component; humanoid robot; obstacle avoidance; stereo vision; plane
   extraction},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics},
Author-Email = {sabe@pdp.crl.sony.co.jp
   fukuchi@pdp.crl.sony.co.jp
   steffen@pdp.crl.sony.co.jp
   takeshi@pdp.crl.sony.co.jp
   kenta@pdp.crl.sony.co.jp
   takayuki.yoshigahara@jp.sony.com},
Affiliations = {Sony Corporation},
Cited-References = {BORENSTEIN J, 1995, IEEE T ROBOTIC AUTOM, V11, P132, DOI 10.1109/70.345945.
   Elfes A, 1989, THESIS CARNEGIE MELL.
   Fujita M., 1997, Proceedings of the First International Conference on Autonomous Agents, P435, DOI 10.1145/267658.267764.
   Fujita M, 1998, AUTON ROBOT, V5, P7, DOI 10.1023/A:1008856824126.
   FUJITA M, 2003, INT C INT ROB SYST I.
   FUJITA M, 2003, INT C ADV INT MECH.
   Ishida T, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1079, DOI 10.1109/IROS.2001.976312.
   KUROKI Y, 2001, P IEEE RAS INT C HUM, P181.
   OKADA K, 2001, INT C ROB AUT ICRA 0.
   Pagac D, 1998, IEEE T ROBOTIC AUTOM, V14, P623, DOI 10.1109/70.704234.
   WIJK O, 2001, THESIS ROYAL I TECHN.},
Number-of-Cited-References = {11},
Times-Cited = {79},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {8},
Doc-Delivery-Number = {BAE24},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000221794800094},
DA = {2022-05-17},
}

@inproceedings{ WOS:000250915303152,
Author = {Falliat, David},
Book-Group-Author = {IEEE},
Title = {A visual bag of words method for interactive qualitative localization
   and mapping},
DOI = {10.1109/ROBOT.2007.364080},
Booktitle = {PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND
   AUTOMATION, VOLS 1-10},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2007},
Pages = {3921-3926},
Note = {IEEE International Conference on Robotics and Automation, Rome, ITALY,
   APR 10-14, 2007},
Abstract = {Localization for low cost humanoid or animal-like personal robots has to
   rely on cheap sensors and has to be robust to user manipulations of the
   robot. We present a visual localization and map-learning system that
   relies on vision only and that is able to incrementally learn to
   recognize the different rooms of an apartment from any robot position.
   This system is inspired by visual categorization algorithms called bag
   of words methods that we modified to make fully incremental and to allow
   a user-interactive training. Our system is able to reliably recognize
   the room in which the robot is after a short training time and is stable
   for long term use. Empirical validation on a real robot and on an image
   database acquired in real environments are presented.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Falliat, D (Corresponding Author), ENSTA, 32 Blvd Victor, F-75015 Paris, France.
   ENSTA, F-75015 Paris, France.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4244-0601-2},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {david.filliat@ensta.fr},
Affiliations = {Institut Polytechnique de Paris},
Cited-References = {BAILLIE JC, 2004, INT J HUMANOID ROBOT.
   Beis JS, 1999, IEEE T PATTERN ANAL, V21, P1000, DOI 10.1109/34.799907.
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5.
   Cauwenberghs G, 2001, ADV NEUR IN, V13, P409.
   Csurka G, 2004, P WORKSH STAT LEARN.
   DAVISON A, 2004, P IFAC S INT AUT VEH.
   Filliat D., 2003, COGN SYST RES, V4, P243, DOI DOI 10.1016/S1389-0417(03)00008-1.
   Fox D, 1998, ROBOT AUTON SYST, V25, P195, DOI 10.1016/S0921-8890(98)00049-9.
   Fox D., 1999, J ARTIFICIAL INTELLI, V11.
   Gonzalez-Barbosa JJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1365, DOI 10.1109/ROBOT.2002.1014733.
   HAHNEL D, 2003, P IEEE RSJ INT C INT.
   Jogan M, 2003, ROBOT AUTON SYST, V45, P51, DOI 10.1016/S0921-8890(03)00064-2.
   Jude Frederic, 2005, INT C COMP VIS.
   Kosecka J, 2004, INT C PATT RECOG, P319, DOI 10.1109/ICPR.2004.1333767.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257.
   MOZOS OM, 2005, P INT C ROB AUT ICRA.
   Porta JM, 2003, IEEE INT CONF ROBOT, P2842, DOI 10.1109/ROBOT.2003.1242023.
   Rybski PE, 2003, IEEE INT CONF ROBOT, P850.
   Smith R., 1988, UNCERTAINTY ARTIFICI, V5, P435, DOI DOI 10.1016/B978-0-444-70396-5.50042-X.
   Tapus A., 2005, P IEEE RSJ INT C INT.
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243.
   ULRICH I, 2000, P IEEE INT C ROB AUT, V2, P1023.
   WOLF J, 2002, P INT C IM VID RETR.},
Number-of-Cited-References = {25},
Times-Cited = {122},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Doc-Delivery-Number = {BGW23},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000250915303152},
DA = {2022-05-17},
}

@inproceedings{ WOS:A1997BJ29M00006,
Author = {Graves, K and Adams, W and Schultz, A},
Book-Group-Author = {IEEE},
Title = {Continuous localization in changing environments},
Booktitle = {1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN
   ROBOTICS AND AUTOMATION - CIRA `97, PROCEEDINGS: TOWARDS NEW
   COMPUTATIONAL PRINCIPLES FOR ROBOTICS AND AUTOMATION},
Year = {1997},
Pages = {28-33},
Note = {1997 IEEE International Symposium on Computational Intelligence in
   Robotics and Automation (CIRA 97) - Towards New Computational Principles
   for Robotics and Automation, MONTEREY, CA, JUL 10-11, 1997},
Abstract = {Continuous localization is a technique that allows a robot to maintain
   an accurate estimate of its location by performing regular; small
   corrections to its odometry Continuous localization uses an evidence
   grid representation, a common representation scheme that is used by
   other map-dependent processes, such as path planning. Although
   techniques exist for building evidence grid maps, most are not adaptive
   to changes in the environment. In this research, we extend the
   continuous localization technique by adding a learning component. This
   allows continuous localization to update the long-term map (evidence
   grid) with current sensor readings. Results show that the addition of
   the learning behavior to continuous localization allows the system to
   adapt to changes in its environment without a loss in its ability to
   remain localized. This system was tested on a Nomad 200 mobile robot.},
Publisher = {I E E E, COMPUTER SOC PRESS},
Address = {10662 LOS VAQUEROS CIRCLE, LOS ALAMITOS, CA 90720},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Graves, K (Corresponding Author), USN ACAD,DEPT COMP SCI,ANNAPOLIS,MD 21402, USA.},
DOI = {10.1109/CIRA.1997.613834},
ISBN = {0-8186-8138-1},
Research-Areas = {Automation \& Control Systems; Computer Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial Intelligence},
Number-of-Cited-References = {0},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BJ29M},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:A1997BJ29M00006},
DA = {2022-05-17},
}

@inproceedings{ WOS:000474345000281,
Author = {Chavez, Arturo Gomez and Xu, Qingwen and Mueller, Christian A. and
   Schwertfeger, Soren and Birk, Andreas},
Book-Group-Author = {Assoc Comp Machinery},
Title = {Towards Accurate Deep-Sea Localization in Structured Environments based
   on Perception Quality Cues},
Booktitle = {AAMAS `19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON
   AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS},
Url = {https://dl.acm.org/doi/abs/10.5555/3306127.3331986},
Year = {2019},
Pages = {1988-1990},
Note = {18th International Conference on Autonomous Agents and MultiAgent
   Systems (AAMAS), Montreal, CANADA, MAY 13-17, 2019},
Abstract = {In recent years, the number of maritime exploration and exploitation
   activities has rapidly increased, and with it the necessity to perform
   more complex tasks underwater, e.g., floating manipulation and mapping
   with Remote Operated Vehicles (ROVs). The first step to perform these
   activities in a reliable manner, is to obtain an accurate robot
   localization estimate. Localization approaches based on multi-robot
   systems or complex acoustic infrastructures have been favored in the
   literature, but alternatively visual modalities are pursued when these
   options are not feasible. In this work, we present a two-stage
   navigation scheme that initially generates a coarse probabilistic map of
   the workspace that is used to refine localization accuracy and filter
   noise in the second stage. Additionally, an adaptive decision-making
   approach is introduced that determines which perception cues to
   incorporate into the localization filter, i.e., tracked 2D features or
   plane representations, to ensure high accuracy and reduce computation
   times. Our approach is thoroughly investigated in simulation and
   validated with deep-sea field trial data originated from oil \& gas
   commercial operations.},
Publisher = {ASSOC COMPUTING MACHINERY},
Address = {1515 BROADWAY, NEW YORK, NY 10036-9998 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Chavez, AG (Corresponding Author), Jacobs Univ, Comp Sci \& Elect Engn, Robot Grp, Bremen, Germany.
   Chavez, Arturo Gomez; Mueller, Christian A.; Birk, Andreas, Jacobs Univ, Comp Sci \& Elect Engn, Robot Grp, Bremen, Germany.
   Xu, Qingwen; Schwertfeger, Soren, ShanghaiTech Univ, Sch Informat Sci \& Technol, Shanghai, Peoples R China.},
ISBN = {978-1-4503-6309-9},
Keywords = {Localization; Navigation; Marine robotics; Field robotics; Multi-modal
   perception; Adaptive behavior; Long-term autonomy},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Theory \& Methods},
Author-Email = {a.gomezchavez@jacobs-university.de
   xuqw@shanghaitech.edu.cn
   chr.mueller@jacobs-university.de
   soerensch@shanghaitech.edu.cn
   a.birk@jacobs-university.de},
Affiliations = {Jacobs University; ShanghaiTech University},
ResearcherID-Numbers = {Schwertfeger, Sören/Y-8549-2019},
ORCID-Numbers = {Schwertfeger, Sören/0000-0003-2879-1636},
Cited-References = {Birk A, 2018, IEEE ROBOT AUTOM MAG, V25, P24, DOI 10.1109/MRA.2018.2869523.
   Gancet J., 2016, IFAC C CONTR APPL MA.
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438.
   Mueller CA, 2018, IEEE INT C INT ROBOT, P1892, DOI 10.1109/IROS.2018.8594392.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Nafchi HZ, 2018, IEEE T BROADCAST, V64, P518, DOI 10.1109/TBC.2018.2818402.
   Pathak K, 2010, IEEE T ROBOT, V26, P424, DOI 10.1109/TRO.2010.2042989.
   Poppinga J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3378, DOI 10.1109/IROS.2008.4650729.},
Number-of-Cited-References = {8},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BN1GG},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000474345000281},
DA = {2022-05-17},
}

@inproceedings{ WOS:000231762600061,
Author = {Leblond, I and Legris, M and Solaiman, B},
Book-Group-Author = {IEEE},
Title = {Use of classification and segmentation of sidescan sonar images for long
   term registration},
DOI = {10.1109/OCEANSE.2005.1511734},
Booktitle = {Oceans 2005 - Europe, Vols 1 and 2},
Year = {2005},
Pages = {322-327},
Note = {Oceans 2005 Europe International Conference, Brest, FRANCE, JUN 20-23,
   2005},
Abstract = {This article handles the possibility of using classification and
   segmentation of sidescan sonar images for long term registration.
   In our case, long term registration means to find the displacement
   between two images which can have been mapped with many weeks or many
   months between them. The aim of this study is to help AUV (Autonomous
   Underwater Vehicle) to navigate, in particular to correct the drift of
   navigation sensors.
   This type of positioning raises two sorts of problems, which come from
   image properties: spatial variability and temporal variability. The
   first one is caused above all by the sonar geometry and appears for
   example like a modification of the shape or the position of the shadow
   according to the point of view. This effect can also be seen in
   textures, for example on megaripples of sand, which can be more or less
   visible depending on the point of view of the sonar. The second one is
   more the consequence of the seafloor physics: between two images, mapped
   at different times, some elements may have changed. An obvious example
   is the presence of evanescent ``objects{''} like fishes but this
   variability can also be seen on sediments, which borders can move due to
   local bottom dynamics.
   With the aim to solve these problems and to provide reliable landmarks
   for matching, we decided to classify and segment the images. The data
   have first been corrected from TVG (Time Varying Gain) effects and
   despecklelised in order to process images which are more representative
   of the seafloor.
   The basis idea is to use a supervised method of classification. To do
   that, we consider some parameters which are coming from a decomposition
   by Gabor filters, in order to segment with linear discriminant analysis
   and use of the nearest neighbour method.
   Registration needs accurately localised landmarks: so, this operation is
   split in several stages, refining step by step the classification, in
   order to obtain a map which describes the seafloor with the most
   possible detailed frontiers.
   Then, we present the obtained results considering five texture classes:
   rocks, megaripples, sand, mud and shadow.
   These several areas and their frontiers are the basis landmarks to match
   the images. However, before using the segmentation, we must check its
   reliability. So, it appears that the frontiers, though they are
   realistic, are not accurate enough to make a registration precise to few
   pixels, especially in rock areas. Similarly, according to the
   orientation of the ripples, they may be seen as ripples or sand. These
   observations are due to the directivity of the sonar, which caused these
   effects on the segmentation. To do registration, we must take into
   account these problems. So, the results of the segmentation will be used
   only for a coarse registration, in order to find quickly the area of
   interest but also to assess the reliability of our registration
   (matching on ripples areas is a priori less reliable than on rocks
   areas). The results of registration are shown, proving the good adequacy
   between reference image and test image. Others methods, more
   quantitative, will be able to be tested, to refine the results.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Leblond, I (Corresponding Author), ENSIETA Lab E3I2, EA 3876, 2 Rue Francois Verny, F-29806 Brest, France.
   ENSIETA Lab E3I2, EA 3876, F-29806 Brest, France.},
ISBN = {0-7803-9103-9},
Research-Areas = {Acoustics; Engineering; Instruments \& Instrumentation; Imaging Science
   \& Photographic Technology},
Web-of-Science-Categories  = {Acoustics; Engineering, Ocean; Instruments \& Instrumentation; Imaging
   Science \& Photographic Technology},
Affiliations = {ENSTA Bretagne},
Cited-References = {Anstee S., 2001, REMOVAL RANGE DEPEND.
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009.
   Duda R., 2001, PATTERN CLASSIFICATI, Vxx.
   GUERINDUGUE A, 1996, TRAITEMENT SIGNAL 19, V13.
   HERVET E, 1998, P SAR IM AN MOD TECH, V3497.
   ISAR A, 2004, 64 RSTD.
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641.
   Lee J. S., 1987, P IGARSS 87 S, P1331.
   Lopes A., 1990, P IEEE INT GEOSC REM, V3, P2409.
   LUCIDO L, 1998, THESIS S ANTIPOLIS U.
   Saporta G., 1978, THEORIES METHODES ST.},
Number-of-Cited-References = {11},
Times-Cited = {5},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BCX53},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000231762600061},
DA = {2022-05-17},
}

@inproceedings{ WOS:000555473200044,
Author = {Zhu, Yilong and Xue, Bohuan and Zheng, Linwei and Huang, Huaiyang and
   Liu, Ming and Fan, Rui},
Book-Group-Author = {IEEE},
Title = {Real-Time, Environmentally-Robust 3D LiDAR Localization},
DOI = {10.1109/IST48021.2019.9010305},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON IMAGING SYSTEMS \& TECHNIQUES (IST
   2019)},
Series = {IEEE International Conference on Imaging Systems and Techniques},
Year = {2019},
Note = {IEEE International Conference on Imaging Systems and Techniques (IST) .
   IEEE International School on Imaging, Abu Dhabi, U ARAB EMIRATES, DEC
   08-10, 2019},
Abstract = {Localization, or position fixing, is an important problem in robotics
   research. In this paper, we propose a novel approach for long-term
   localization in a changing environment using 3D LiDAR. We first create
   the map of a real environment using GPS and LiDAR. Then, we divide the
   map into several small parts as the targets for cloud registration,
   which can not only improve the robustness but also reduce the
   registration time. We proposed a localization method called
   PointLocalization. PointLocalization allows us to fuse different kinds
   of odometers, which can optimize the accuracy and frequency of
   localization results. We evaluate our algorithm on an unmanned ground
   vehicle (UGV) using LiDAR and a wheel encoder, and obtain the
   localization results at more than 20 Hz after fusion. The algorithm can
   also localize the UGV in a 180-degree field of view (FOV). Using an
   outdated map captured six months ago, this algorithm shows great
   robustness, and the test results show that it can achieve an accuracy of
   10 cm. PointLocalization has been tested for a period of more than six
   months in a crowded factory and has operated successfully over a
   distance of more than 2000 km.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhu, YL (Corresponding Author), Hong Kong Univ Sci \& Technol, Robot \& Multipercept Lab, Robot Inst, Clear Water Bay, Hong Kong, Peoples R China.
   Zhu, Yilong; Xue, Bohuan; Zheng, Linwei; Huang, Huaiyang; Liu, Ming; Fan, Rui, Hong Kong Univ Sci \& Technol, Robot \& Multipercept Lab, Robot Inst, Clear Water Bay, Hong Kong, Peoples R China.},
ISSN = {2471-6162},
ISBN = {978-1-7281-3868-8},
Research-Areas = {Imaging Science \& Photographic Technology},
Web-of-Science-Categories  = {Imaging Science \& Photographic Technology},
Author-Email = {yzhubr@ust.hk
   bxueaa@ust.hk
   lzhengad@ust.hk
   hhuangat@ust.hk
   eelium@ust.hk
   eeruifan@ust.hk},
Affiliations = {Hong Kong University of Science \& Technology},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}U1713211]; Research
   Grant Council of Hong Kong SAR Government, China {[}11210017, 21202816];
   Shenzhen Science, Technology and Innovation Commission (SZSTI)
   {[}JCYJ20160428154842603]},
Funding-Text = {This work was supported by the National Natural Science Foundation of
   China, under grant No. U1713211, the Research Grant Council of Hong Kong
   SAR Government, China, under Project No. 11210017, No. 21202816, and the
   Shenzhen Science, Technology and Innovation Commission (SZSTI) under
   grant JCYJ20160428154842603, awarded to Prof. Ming Liu.},
Cited-References = {Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Burki M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4137, DOI 10.1109/IROS.2016.7759609.
   Burki Mathias, 2018, 2018 IEEE Intelligent Vehicles Symposium (IV), P682, DOI 10.1109/IVS.2018.8500432.
   Ding XQ, 2018, IEEE INT C INT ROBOT, P4794, DOI 10.1109/IROS.2018.8593846.
   Egger P, 2018, IEEE INT C INT ROBOT, P3430, DOI 10.1109/IROS.2018.8593854.
   Fan, 2018, THESIS.
   Fan R., ARXIV190602939.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Groves PD, 2013, ARTECH HSE GNSS TECH, P1.
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331.
   Huang H., 2019, ROBUST PAVEMENT MAPP.
   Koide Kenji, 2018, PORTABLE 3D LIDAR BA.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Liu YN, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1088, DOI 10.1109/ROBIO.2018.8665350.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Pfrunder A, 2017, IEEE INT C INT ROBOT, P2601, DOI 10.1109/IROS.2017.8206083.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Rui Fan, 2017, IEEE INT WORKSH IM S, P1.
   Shan TX, 2018, IEEE INT C INT ROBOT, P4758, DOI 10.1109/IROS.2018.8594299.
   Valls MI, 2018, IEEE INT CONF ROBOT, P2048.
   Wolcott RW, 2014, IEEE INT C INT ROBOT, P176, DOI 10.1109/IROS.2014.6942558.
   Xiong T, 2014, BIOMED CIRC SYST C, P9, DOI 10.1109/BioCAS.2014.6981632.
   Zheng L., LOW COST GPS AIDED L.},
Number-of-Cited-References = {25},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BP5GH},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000555473200044},
DA = {2022-05-17},
}

@inproceedings{ WOS:000377221105122,
Author = {Martin, Steven and Corke, Peter},
Book-Group-Author = {IEEE},
Title = {Long-Term Exploration \& Tours for Energy Constrained Robots with Online
   Proprioceptive Traversability Estimation},
DOI = {10.1109/ICRA.2014.6907708},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2014},
Pages = {5778-5785},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014},
Abstract = {This paper is concerned with how a localised and energy-constrained
   robot can maximise its time in the field by taking paths and tours that
   minimise its energy expenditure. A significant component of a robot's
   energy is expended on mobility and is a function of terrain
   traversability. We estimate traversability online from data sensed by
   the robot as it moves, and use this to generate maps, explore and
   ultimately converge on minimum energy tours of the environment. We
   provide results of detailed simulations and parameter studies that show
   the efficacy of this approach for a robot moving over terrain with
   unknown traversability as well as a number of a priori unknown hard
   obstacles. We also present preliminary experimental results to show the
   feasibility of this approach in natural terrain.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Martin, S (Corresponding Author), Queensland Univ Technol, Sch Elect Engn \& Comp Sci, CyPhy Lab, Brisbane, Qld 4001, Australia.
   Martin, Steven; Corke, Peter, Queensland Univ Technol, Sch Elect Engn \& Comp Sci, CyPhy Lab, Brisbane, Qld 4001, Australia.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-3685-4},
Keywords-Plus = {TIME OBSTACLE AVOIDANCE},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {steven.martin@qut.edu.au
   peter.corke@qut.edu.au},
Affiliations = {Queensland University of Technology (QUT)},
ResearcherID-Numbers = {Corke, Peter/C-6770-2009},
ORCID-Numbers = {Corke, Peter/0000-0001-6650-367X},
Cited-References = {Angelova A, 2007, IEEE INT CONF ROBOT, P1741, DOI 10.1109/ROBOT.2007.363574.
   Bagnell JA, 2010, IEEE ROBOT AUTOM MAG, V17, P74, DOI 10.1109/MRA.2010.936946.
   BORENSTEIN J, 1989, IEEE T SYST MAN CYB, V19, P1179, DOI 10.1109/21.44033.
   Brooks C., J FIELD ROBOTICS.
   Castelnovi M, 2005, IEEE INT CONF ROBOT, P891.
   Howard A, 2001, J ROBOTIC SYST, V18, P577, DOI 10.1002/rob.1046.
   Iagnemma K., 2004, MOBILE ROBOTS ROUGH.
   Ishigami G, 2011, IEEE INT C INT ROBOT, P601, DOI 10.1109/IROS.2011.6048429.
   Karumanchi S., 2010, THESIS U SYDNEY.
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106.
   Konolige K, 2009, J FIELD ROBOT, V26, P88, DOI 10.1002/rob.20271.
   Lawler EL, 1985, TRAVELING SALESMAN P, V3.
   Martin S., 2012, INT S EXP ROB.
   Molino V., 2006, P PERFO METR INT SYS.
   Plonski P., 2012, ENERGY EFFICIENT PAT.
   Rasmussen C. E., 2006, GAUSSIAN PROCESSES M, V1.
   Russell S., 2010, ARTIFICIAL INTELLIGE.
   Shneier M., 2009, PERFORMANCE EVALUATI.
   Silver D., 2006, EXPERIMENTAL ANAL OV, P2443.
   Singh S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1194, DOI 10.1109/ROBOT.2000.844761.
   Sofman B., 2005, TERRAIN CLASSIFICATI.
   Stentz A., 1997, INTELLIGENT UNMANNED, P203, DOI DOI 10.1007/978-1-4615-6325-9\_11.
   Stentz A, 1994, D ALGORITHM REAL TIM.
   Talukder A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P708, DOI 10.1109/IRDS.2002.1041474.
   Ulrich I., 1999, P NAT C ART INT, P866.
   Vasudevan S, 2009, J FIELD ROBOT, V26, P812, DOI 10.1002/rob.20309.},
Number-of-Cited-References = {26},
Times-Cited = {17},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE9BP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000377221105122},
DA = {2022-05-17},
}

@inproceedings{ WOS:000521238104023,
Author = {Hu, Jiaxin and Yang, Ming and Xu, Hanqing and He, Yuesheng and Wang,
   Chunxiang},
Book-Group-Author = {IEEE},
Title = {Mapping and Localization using Semantic Road Marking with
   Centimeter-level Accuracy in Indoor Parking Lots},
DOI = {10.1109/ITSC.2019.8917529},
Booktitle = {2019 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE (ITSC)},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2019},
Pages = {4068-4073},
Note = {IEEE Intelligent Transportation Systems Conference (IEEE-ITSC),
   Auckland, NEW ZEALAND, OCT 27-30, 2019},
Abstract = {Accurate localization is one of the fundamental tasks of vehicles visual
   navigation in parking lots. In this paper, we propose a practical and
   novel solution, which exploits road marking semantic segmentation to
   attack the problem of long-term and high-precision visual localization.
   Based on the semantic data association derived from road markings
   segmentation, point cloud fusion and loop detection strategies are
   designed to improve the performance of semantic map building. Applying
   the generated map, we present a point cloud registration algorithm
   combining semantic and geometric inference to improve the localization
   precision. Experiments on real-world indoor parking lots prove that the
   semantic map created by the proposed method reveals more accurate and
   consistent performance. Moreover, localization error is no more than
   10cm, while running in real-time performance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yang, M (Corresponding Author), Shanghai Jiao Tong Univ, Dept Automat, Key Lab Syst Control \& Informat Proc, Minist Educ China, Shanghai 200240, Peoples R China.
   Hu, Jiaxin; Yang, Ming; Xu, Hanqing; He, Yuesheng; Wang, Chunxiang, Shanghai Jiao Tong Univ, Dept Automat, Key Lab Syst Control \& Informat Proc, Minist Educ China, Shanghai 200240, Peoples R China.},
ISSN = {2153-0009},
ISBN = {978-1-5386-7024-8},
Keywords-Plus = {VERSATILE},
Research-Areas = {Transportation},
Web-of-Science-Categories  = {Transportation Science \& Technology},
Author-Email = {MingYANG@sjtu.edu.cn},
Affiliations = {Ministry of Education, China; Shanghai Jiao Tong University},
ResearcherID-Numbers = {Yang, Ming/K-8245-2012},
ORCID-Numbers = {Yang, Ming/0000-0002-8679-9137},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}U1764264/61873165];
   Shanghai Automotive Industry Science and Technology Development
   Foundation {[}1733/1807]},
Funding-Text = {This work is supported by the National Natural Science Foundation of
   China (U1764264/61873165), Shanghai Automotive Industry Science and
   Technology Development Foundation (1733/1807). Ming Yang is the
   corresponding author.},
Cited-References = {Agrawal P., 2014, COMPUTER VISIONECCV.
   Biswas J, 2010, IEEE INT CONF ROBOT, P4379, DOI 10.1109/ROBOT.2010.5509842.
   Bowman Sean L., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1722, DOI 10.1109/ICRA.2017.7989203.
   Cordts M., 2016, P IEEE C COMP VIS PA.
   Deng LY, 2017, IEEE INT VEH SYM, P231, DOI 10.1109/IVS.2017.7995725.
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577.
   Fischer G., 2004, P 1 WORKSH POS NAV C.
   Glvez-Lpez D, 2012, DBOW2 ENHANCED HIERA.
   Grupp M., EVO PYTHON PACKAGE E.
   Hess W., 2016, ROB AUT ICRA 2016 IE.
   Huang YW, 2018, IEEE INT VEH SYM, P636, DOI 10.1109/IVS.2018.8500516.
   Jeong J, 2017, IEEE INT VEH SYM, P1736, DOI 10.1109/IVS.2017.7995958.
   Liang Z, 2019, INT C ROB AUT ICRA.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Noh ASI, 2008, PROCEEDINGS OF NINTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING, P13, DOI 10.1109/SNPD.2008.125.
   Parkhiya P, 2018, IEEE INT CONF ROBOT, P4517.
   Qian YQ, 2017, IEEE INT VEH SYM, P33, DOI 10.1109/IVS.2017.7995695.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Scrafin J, 2015, IEEE INT C INT ROBOT, P742, DOI 10.1109/IROS.2015.7353455.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Zhang CM, 2006, IEEE RADIO WIRELESS, P515.
   Zhou X, ORB SLAM 2 OPEN SOUR.},
Number-of-Cited-References = {22},
Times-Cited = {2},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {7},
Doc-Delivery-Number = {BO6LS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000521238104023},
DA = {2022-05-17},
}

@inproceedings{ WOS:000676374700001,
Author = {Yin, Huan and Wang, Yue and Tang, Li and Xiong, Rong},
Book-Group-Author = {IEEE},
Title = {Radar-on-Lidar: metric radar localization on prior lidar maps},
DOI = {10.1109/RCAR49640.2020.9303291},
Booktitle = {2020 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS
   (IEEE-RCAR 2020)},
Year = {2020},
Pages = {1-7},
Note = {IEEE International Conference on Real-time Computing and Robotics
   (IEEE-RCAR), ELECTR NETWORK, SEP 28-29, 2020},
Abstract = {Radar and lidar, provided by two different range sensors, each has pros
   and cons of various perception tasks on mobile robots or autonomous
   driving. In this paper, a Monte Carlo system is used to localize the
   robot with a rotating radar sensor on 2D lidar maps. We first train a
   conditional generative adversarial network to transfer raw radar data to
   lidar data, and achieve reliable radar points from generator. Then an
   efficient radar odometry is included in the Monte Carlo system.
   Combining the initial guess from odometry, a measurement model is
   proposed to match the radar data and prior lidar maps for final 2D
   positioning. We demonstrate the effectiveness of the proposed
   localization framework on the public multi-session dataset. The
   experimental results show that our system can achieve high accuracy for
   long-term localization in outdoor scenes.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Yin, H (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou 310058, Peoples R China.
   Yin, H (Corresponding Author), Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310058, Peoples R China.
   Yin, Huan; Wang, Yue; Tang, Li; Xiong, Rong, Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou 310058, Peoples R China.
   Yin, Huan; Wang, Yue; Tang, Li; Xiong, Rong, Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310058, Peoples R China.},
ISBN = {978-1-7281-7293-4},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Theory \& Methods;
   Engineering, Electrical \& Electronic; Robotics},
Affiliations = {Zhejiang University; Zhejiang University},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020},
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018YFB1309300]; National Nature
   Science Foundation of China {[}61903332]; Key R\&D Program of Zhejiang
   Province {[}2019C01043]},
Funding-Text = {This work was supported in part by the National Key R\&D Program of
   China (2018YFB1309300), and in part by the National Nature Science
   Foundation of China (61903332), and in part by the Key R\&D Program of
   Zhejiang Province (2019C01043).},
Cited-References = {Aldera R, 2019, IEEE INT C INTELL TR, P2835, DOI 10.1109/ITSC.2019.8917111.
   Aldera R, 2019, IEEE INT CONF ROBOT, P1190, DOI 10.1109/ICRA.2019.8794014.
   Barnes D., 2019, ARXIV190903752.
   Cen SH, 2019, IEEE INT CONF ROBOT, P298, DOI 10.1109/ICRA.2019.8793990.
   Cen SH, 2018, IEEE INT CONF ROBOT, P6045, DOI 10.1109/ICRA.2018.8460687.
   Ding X., 2019, IEEE T INTELL TRANSP.
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632.
   Kim G, 2020, IEEE INT CONF ROBOT, P6246.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Krusi P, 2015, J FIELD ROBOT, V32, P534, DOI 10.1002/rob.21524.
   Lu C. X., 2019, ARXIV191100398.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Park YS, 2019, IEEE INT C INT ROBOT, P1307, DOI 10.1109/IROS40897.2019.8967633.
   Posner I, 2019, OXFORD RADAR ROBOTCA.
   Schuster F, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2559, DOI 10.1109/ITSC.2016.7795967.
   Schuster F, 2016, IEEE INT VEH SYM, P839, DOI 10.1109/IVS.2016.7535485.
   Thrun S, 2002, COMMUN ACM, V45, P52.
   Vivet D, 2013, SENSORS-BASEL, V13, P4527, DOI 10.3390/s130404527.
   Weston R, 2019, IEEE INT CONF ROBOT, P5446, DOI 10.1109/ICRA.2019.8793263.
   Yeong Sang Park, 2019, ICRA WORKSH DAT GEN.
   Yin H., 2019, IEEE T INTELLIGENT T.
   Yin Huan, 2020, IEEE T INTELLIGENT T.},
Number-of-Cited-References = {23},
Times-Cited = {7},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BR9JE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000676374700001},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000379703200024,
Author = {Ismail, Hesham and Balachandran, Balakumar},
Book-Group-Author = {ASME},
Title = {VEHICLE POSE ESTIMATION AND SONAR SENSOR BASED MAPPING},
Booktitle = {PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS
   AND EXPOSITION, 2015, VOL 4A},
DOI = {10.1115/IMECE2015-52427},
Pages = {1-10},
Year = {2016},
Note = {ASME International Mechanical Engineering Congress and Exposition
   (IMECE2015), Houston, TX, NOV 13-19, 2015},
Abstract = {In carrying out simultaneous localization and mapping, a mobile vehicle
   is used to simultaneously estimate its position and build a map of the
   environment. The long-term goal of this work is to build an autonomous
   inspection mobile vehicle for oil storage tanks and pipelines. The harsh
   environmental conditions in storage tanks and pipelines limit the types
   of feature extraction sensors and vehicle pose estimation sensors that
   one can use. Here, a SOund Navigation And Ranging (SONAR) sensor will be
   used for feature extraction, and a gyroscope and an encoder will be used
   for vehicle pose estimation. The integration of these sensors (SONAR,
   encoder, and gyroscope) will be discussed in this paper; along with the
   use of a recently developed algorithm fusion for SONAR sensors. The
   integration of the sensors represents a step towards implementation of
   concurrent localization and mapping progress in harsh environments.},
Publisher = {AMER SOC MECHANICAL ENGINEERS},
Address = {THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Ismail, H (Corresponding Author), Univ Maryland, Dept Mech Engn, College Pk, MD 20742 USA.
   Ismail, Hesham; Balachandran, Balakumar, Univ Maryland, Dept Mech Engn, College Pk, MD 20742 USA.},
Article-Number = {V04AT04A024},
ISBN = {978-0-7918-5739-7},
Keywords-Plus = {MOBILE; LOCALIZATION; NAVIGATION},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Mechanical},
Author-Email = {hismail@umd.edu
   balab@umd.edu},
Affiliations = {University System of Maryland; University of Maryland College Park},
Cited-References = {Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363.
   BARSHAN B, 1995, IEEE T ROBOTIC AUTOM, V11, P328, DOI 10.1109/70.388775.
   Borenstein J, 1996, IEEE T ROBOTIC AUTOM, V12, P869, DOI 10.1109/70.544770.
   Borenstein J, 1996, IEEE INT CONF ROBOT, P423, DOI 10.1109/ROBOT.1996.503813.
   BORENSTEIN J, 1991, IEEE T ROBOTIC AUTOM, V7, P278, DOI 10.1109/70.88137.
   CHENAVIER F, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P2588, DOI 10.1109/ROBOT.1992.220052.
   Chung H, 2001, IEEE T ROBOTIC AUTOM, V17, P80, DOI 10.1109/70.917085.
   COX IJ, 1991, IEEE T ROBOTIC AUTOM, V7, P193, DOI 10.1109/70.75902.
   Dincay Berkan, 2010, GPS OPTICAL ENCODER.
   Goel P., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P1134, DOI 10.1109/IROS.1999.812832.
   Ismail H., 2014, ASME 2014 INT MECH E.
   Ismail H., 2013, ASME 2013 INT MECH E.
   Jaai R., 2012, SPIE SMART STRUCTURE.
   Ji XS, 2006, INT CONF NANO MICRO, P218, DOI 10.1109/NEMS.2006.334690.
   Kim M. C., 1999, POWER, V12, p15mA.
   Kleeman L., 1995, MECSE951 MON U INT R.
   Lee SJ, 2012, ADV ROBOTICS, V26, P1055, DOI 10.1163/156855312X633093.
   LEONARD JJ, 1991, IEEE T ROBOTIC AUTOM, V7, P376, DOI 10.1109/70.88147.
   Liu B, 2007, C IND ELECT APPL, P1165.
   Tardos JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340.
   TSUMURA T, 1981, P 11 INT S IND ROB T, P18.
   Wang C. M., 1988, Proceedings of the 1988 IEEE International Conference on Robotics and Automation (Cat. No.88CH2555-1), P1231, DOI 10.1109/ROBOT.1988.12229.
   Wijk O, 1998, IEEE INT CONF ROBOT, P3419, DOI 10.1109/ROBOT.1998.680966.
   Zunaidi I., 2006, CMU J, V5, P1.},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BF0WS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000379703200024},
DA = {2022-05-17},
}

@inproceedings{ WOS:000177404200115,
Author = {Gross, HM and Boehme, HJ and Wilhelm, T},
Book-Group-Author = {IEEE
   IEEE
   IEEE
   IEEE},
Title = {A contribution to vision-based localization, tracking and navigation
   methods for an interactive mobile service-robot},
DOI = {10.1109/ICSMC.2001.972991},
Booktitle = {2001 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS,
   VOLS 1-5: E-SYSTEMS AND E-MAN FOR CYBERNETICS IN CYBERSPACE},
Series = {IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS,
   CONFERENCE PROCEEDINGS},
Year = {2002},
Pages = {672-677},
Note = {IEEE International Conference on Systems, Man and Cybernetics (SMC),
   TUCSON, AZ, OCT 07-10, 2001},
Abstract = {The paper presents vision-based robot navigation and user localization
   techniques of our long-term research project PERSES (PERsonal SErvice
   System), which aims to develop an interactive mobile shopping assistant
   that allows a continuous and intuitively understandable interaction with
   customers in a home store. Against this background, the paper describes
   a number of new or improved approaches, addressing challenges arising
   from the characteristics of the operation area, and from the need to
   continuously interact with users in a complex environment. With our
   approaches to vision-based or visually-controlled map building,
   self-localization and navigation as well as user localization and
   tracking, we want to make a contribution to the real-world suitability
   of interactive mobile service-robots in non-trivial application areas
   and demanding human-robot interaction scenarios.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gross, HM (Corresponding Author), Tech Univ Ilmenau, Dept Neuroinformat, D-98684 Ilmenau, Germany.
   Tech Univ Ilmenau, Dept Neuroinformat, D-98684 Ilmenau, Germany.},
ISSN = {1062-922X},
ISBN = {0-7803-7087-2},
Keywords = {service robots; human-robot systems; navigation; self-localization;
   person detection; visual tracking},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science,
   Cybernetics; Computer Science, Information Systems; Engineering,
   Electrical \& Electronic},
Affiliations = {Technische Universitat Ilmenau},
Cited-References = {BOEHME HJ, UNPUB EUROBOT 2001.
   Burgards W., 1998, MACH LEARN AUTON ROB, V31, P1.
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x.
   Duchon AP, 1998, ADAPT BEHAV, V6, P473, DOI 10.1177/105971239800600306.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   FOX D, 1999, P AAAI 99.
   GROSS HM, P IEEE SMC 2000, P80.
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650.
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7.},
Number-of-Cited-References = {9},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BU92K},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000177404200115},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921702049,
Author = {Spangenberg, Robert and Goehring, Daniel and Rojas, Raul},
Book-Group-Author = {IEEE},
Title = {Pole-based Localization for Autonomous Vehicles in Urban Scenarios},
DOI = {10.1109/IROS.2016.7759339},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {2161-2166},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {Localization is a key capability for autonomous vehicles especially in
   urban scenarios. We propose the use of pole-like landmarks as primary
   features in these environments, as they are distinct, long-term stable
   and can he detected reliably with a stereo camera system. Furthermore,
   the resulting map representation is memory efficient, allowing for easy
   storage and on-line updates. The localization is performed in real-time
   by a stereo camera system as a main sensor, using vehicle odometry and
   an off-the-shelf GPS as secondary information sources. Localization is
   performed by a particle filter approach, coupled with an Kalman filter
   for robustness and sensor fusion. This leads to a lateral accuracy below
   20 cm in various urban test areas. The system has been included in our
   autonomous test vehicle and successfully demonstrated the full loop from
   mapping to autonomous driving.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Spangenberg, R (Corresponding Author), Free Univ Berlin, Inst Informat, Arnimallee 7, D-14195 Berlin, Germany.
   Spangenberg, Robert; Goehring, Daniel; Rojas, Raul, Free Univ Berlin, Inst Informat, Arnimallee 7, D-14195 Berlin, Germany.},
ISBN = {978-1-5090-3762-9},
Keywords-Plus = {SELF-LOCALIZATION},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {robert.spangenberg@fu-berlin.de},
Affiliations = {Free University of Berlin},
ResearcherID-Numbers = {Rojas-Gonzalez, Raul/AAF-1871-2020},
ORCID-Numbers = {Rojas-Gonzalez, Raul/0000-0003-1596-7030},
Cited-References = {Vo BT, 2013, IEEE T SIGNAL PROCES, V61, P3460, DOI 10.1109/TSP.2013.2259822.
   Bar-Shalom Y., 2002, ESTIMATION APPL TRAC.
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890.
   Brenner C, 2009, LECT NOTES COMPUT SC, V5748, P61.
   Carlson J. D., 2010, THESIS.
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568.
   Deusch Hendrik, 2014, 2014 IEEE Intelligent Vehicles Symposium Proceedings, P555, DOI 10.1109/IVS.2014.6856413.
   Dodel H., 2010, SATELLITENNAVIGATION.
   Geiger A, 2012, IEEE T INTELL TRANSP, V13, P1008, DOI 10.1109/TITS.2012.2189882.
   Gruyer D, 2014, IEEE INT VEH SYM, P674, DOI 10.1109/IVS.2014.6856528.
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Lundgren M, 2014, IEEE INT VEH SYM, P522, DOI 10.1109/IVS.2014.6856524.
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006.
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003.
   Olson EB, 2009, IEEE INT CONF ROBOT, P1233.
   Pink O., 2011, THESIS.
   Schindler A, 2013, 2013 IEEE INTELLIGENT VEHICLES SYMPOSIUM WORKSHOPS (IV WORKSHOPS), P134, DOI 10.1109/IVWorkshops.2013.6615239.
   Schlichting A, 2014, IEEE INT VEH SYM, P414, DOI 10.1109/IVS.2014.6856460.
   Schubert R, 2008, 2008 11 INT C INF FU, P1.
   Spangenberg Robert, 2014, 2014 IEEE Intelligent Vehicles Symposium Proceedings, P195, DOI 10.1109/IVS.2014.6856419.
   Stubler M, 2015, IEEE INT VEH SYM, P267, DOI 10.1109/IVS.2015.7225697.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Zhou J, 2009, SAE INT J PASSEN CAR, V1, P450, DOI 10.4271/2008-01-0561.
   Ziegler J, 2014, IEEE INT VEH SYM, P1231, DOI 10.1109/IVS.2014.6856560.},
Number-of-Cited-References = {25},
Times-Cited = {39},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921702049},
DA = {2022-05-17},
}

@inproceedings{ WOS:000521828600063,
Author = {Shi, Tianxin and Shen, Shuhan and Gao, Xiang and Zhu, Lingjie},
Book-Group-Author = {IEEE},
Title = {VISUAL LOCALIZATION USING SPARSE SEMANTIC 3D MAP},
DOI = {10.1109/ICIP.2019.8802957},
Booktitle = {2019 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP)},
Series = {IEEE International Conference on Image Processing ICIP},
Year = {2019},
Pages = {315-319},
Note = {26th IEEE International Conference on Image Processing (ICIP), Taipei,
   TAIWAN, SEP 22-25, 2019},
Abstract = {Accurate and robust visual localization under a wide range of viewing
   condition variations including season and illumination changes, as well
   as weather and day-night variations, is the key component for many
   computer vision and robotics applications. Under these conditions, most
   traditional methods would fail to locate the camera. In this paper we
   present a visual localization algorithm that combines structure-based
   method and image-based method with semantic information. Given semantic
   information about the query and database images, the retrieved images
   are scored according to the semantic consistency of the 3D model and the
   query image. Then the semantic matching score is used as weight for
   RANSAC's sampling and the pose is solved by a standard PnP solver.
   Experiments on the challenging long-term visual localization benchmark
   dataset demonstrate that our method has significant improvement compared
   with the state-of-the-arts.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Shi, TX (Corresponding Author), Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.
   Shi, TX (Corresponding Author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   Shi, Tianxin; Shen, Shuhan; Gao, Xiang; Zhu, Lingjie, Chinese Acad Sci, Inst Automat, NLPR, Beijing 100190, Peoples R China.
   Shi, Tianxin; Shen, Shuhan; Gao, Xiang; Zhu, Lingjie, Univ Chinese Acad Sci, Beijing 100049, Peoples R China.},
ISSN = {1522-4880},
ISBN = {978-1-5386-6249-6},
Keywords = {Visual localization; semantic segmentation; image retrieval; camera pose
   estimation},
Research-Areas = {Imaging Science \& Photographic Technology},
Web-of-Science-Categories  = {Imaging Science \& Photographic Technology},
Affiliations = {Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   Academy of Sciences; University of Chinese Academy of Sciences, CAS},
Funding-Acknowledgement = {Natural Science Foundation of China {[}61632003, 61873265]},
Funding-Text = {This work was supported by the Natural Science Foundation of China under
   Grants 61632003, 61873265.},
Cited-References = {Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Castle R, 2008, TWELFTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P15, DOI 10.1109/ISWC.2008.4911577.
   Chen L, 2019, ASIA-PAC J ATMOS SCI, V55, P303, DOI 10.1007/s13143-018-0064-5.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791.
   Liu L, 2017, IEEE I CONF COMP VIS, P2391, DOI 10.1109/ICCV.2017.260.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175.
   Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243.
   Sattler T, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.76.
   Schonberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721.
   Schonberger J, 2016, ACCV.
   SCHONBERGER JL, 2016, PROC CVPR IEEE, P4104, DOI DOI 10.1109/CVPR.2016.445.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Svarm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331.
   Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8\_24.
   Toft Carl, 2017, IEEE INT C COMP VIS, V2, P3.
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790.
   Zeisl B, 2015, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2015.310.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.},
Number-of-Cited-References = {31},
Times-Cited = {4},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {4},
Doc-Delivery-Number = {BO6RM},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000521828600063},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000627604600001,
Author = {Yang, Zhe and Pan, Yun and Deng, Lei and Xie, Yuan and Huan, Ruohong},
Title = {PLSAV: Parallel loop searching and verifying for loop closure detection},
Journal = {IET INTELLIGENT TRANSPORT SYSTEMS},
Year = {2021},
Volume = {15},
Number = {5},
Pages = {683-698},
Month = {MAY},
Abstract = {Visual simultaneous localization and mapping (vSLAM), one of the most
   important applications in autonomous vehicles and robots to estimate the
   position and pose using inexpensive visual sensors, suffers from error
   accumulation for long-term navigation without loop closure detection.
   Recently, deep neural networks (DNNs) are leveraged to achieve high
   accuracy for loop closure detection, however the execution time is much
   slower than those employing handcrafted visual features. In this paper,
   a parallel loop searching and verifying method for loop closure
   detection with both high accuracy and high speed, which combines two
   parallel tasks using handcrafted and DNN features, respectively, is
   proposed. A fast loop searching is proposed to link the bag-of-words
   features and histogram for higher accuracy, and it splits the images
   into multiple grids for high parallelism; meanwhile, a DNN feature
   extractor is utilized for further verification. A loop state control
   method based on a finite state machine to control these tasks is
   designed, wherein the loop closure detection is described as a
   context-related procedure. The framework is implemented on a real
   machine, and the top-2 best accuracy and fastest execution time of
   80-543 frames per second (min: 1.84ms, and max: 12.45ms) are achieved on
   several public benchmarks compared with some existing algorithms.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Pan, Y (Corresponding Author), Zhejiang Univ, 1713 Yuquan Campus,38 Zheda Rd, Hangzhou 310027, Peoples R China.
   Yang, Zhe; Pan, Yun, Zhejiang Univ, Coll Informat Sci \& Elect Engn, Hangzhou, Peoples R China.
   Deng, Lei; Xie, Yuan, Univ Calif Santa Barbara, Dept Elect \& Comp Engn, Santa Barbara, CA 93106 USA.
   Huan, Ruohong, Zhejiang Univ Technol, Coll Comp Sci \& Technol, Hangzhou, Peoples R China.},
DOI = {10.1049/itr2.12054},
EarlyAccessDate = {MAR 2021},
ISSN = {1751-956X},
EISSN = {1751-9578},
Keywords-Plus = {PLACE RECOGNITION; LOCALIZATION; APPEARANCE; BAGS},
Research-Areas = {Engineering; Transportation},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Transportation Science \&
   Technology},
Author-Email = {panyun@zju.edu.cn},
Affiliations = {Zhejiang University; University of California System; University of
   California Santa Barbara; Zhejiang University of Technology},
ORCID-Numbers = {Yang, Zhe/0000-0001-7246-0012},
Funding-Acknowledgement = {International Cooperation Research for Doctoral Students in Zhejiang
   University; Zhejiang Provincial Natural Science Foundation of China
   {[}LY19F020032]; Zhejiang ProvincialKey Research andDevelopment Program
   of China {[}2021C03027]},
Funding-Text = {International Cooperation Research for Doctoral Students in Zhejiang
   University; Zhejiang Provincial Natural Science Foundation of China,
   Grant/Award Number: LY19F020032; Zhejiang ProvincialKey Research
   andDevelopment Program of China, Grant/Award Number: 2021C03027},
Cited-References = {Abadi M., 2016, ARXIV 160304467.
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514.
   Arroyo R, 2015, IEEE INT CONF ROBOT, P6328, DOI 10.1109/ICRA.2015.7140088.
   Bampis L, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4146.
   Bampis L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4530, DOI 10.1109/IROS.2016.7759667.
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890.
   Blanco JL, 2009, AUTON ROBOT, V27, P327, DOI 10.1007/s10514-009-9138-7.
   Cadena C, 2012, IEEE T ROBOT, V28, P871, DOI 10.1109/TRO.2012.2189497.
   Ceriani S, 2009, AUTON ROBOT, V27, P353, DOI 10.1007/s10514-009-9156-5.
   Chen JB, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P371, DOI 10.1109/ICIVC.2017.7984580.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Garcia-Fidalgo Emilio, 2018, IEEE Robotics and Automation Letters, V3, P3051, DOI 10.1109/LRA.2018.2849609.
   Garcia-Fidalgo E, 2017, IEEE T ROBOT, V33, P1061, DOI 10.1109/TRO.2017.2704598.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659.
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003.
   Khan S, 2015, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2015.7139959.
   Kim, 2014, ADV INTELLIGENT SYST, P113.
   Kim S, 2018, TENCON IEEE REGION, P1269, DOI 10.1109/TENCON.2018.8650164.
   Klein George, 2007, P1.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Li LH, 2018, IEEE INT VEH SYM, P965, DOI 10.1109/IVS.2018.8500714.
   Li YC, 2017, IEEE ACCESS, V5, P13835, DOI 10.1109/ACCESS.2017.2725387.
   Liu K, 2019, THIRTY-THIRD AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE / THIRTY-FIRST INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE / NINTH AAAI SYMPOSIUM ON EDUCATIONAL ADVANCES IN ARTIFICIAL INTELLIGENCE, P8034.
   Milford M., 2014, 2014 IFIP NETW C, P1.
   Milford M, 2014, IEEE INT CONF ROBOT, P5571, DOI 10.1109/ICRA.2014.6907678.
   Mirowski P, 2013, INT C IND POS IND NA, P1.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953.
   Muresan MP, 2019, INT C INTELL COMP CO, P11, DOI 10.1109/ICCP48234.2019.8959552.
   Naseer T, 2018, IEEE T ROBOT, V34, P289, DOI 10.1109/TRO.2017.2788045.
   Neubert P, 2016, IEEE ROBOT AUTOM LET, V1, P484, DOI 10.1109/LRA.2016.2517824.
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869.
   Pang, 2020, ARXIV200606664.
   Ponce J., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Shahbazi H, 2011, IEEE INT C INT ROBOT, P1228, DOI 10.1109/IROS.2011.6048862.
   Shin DW, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.1.013014.
   Siam Sayem Mohammad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5702, DOI 10.1109/ICRA.2017.7989671.
   Simonyan K., 2015, 3 INT C LEARNING REP.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Vlaminck M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19010023.
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010.
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682.
   Yang Z, 2021, IET INTELL TRANSP SY, V15, P683, DOI 10.1049/itr2.12054.
   Yang Z, 2019, ELECTRON LETT, V55, P931, DOI 10.1049/el.2019.1148.
   Yin JW, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION ENGINEERING (ICRAE), P73, DOI 10.1109/ICRAE.2017.8291356.
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691.
   Zhang K, 2017, CHIN AUTOM CONGR, P7916, DOI 10.1109/CAC.2017.8244215.
   Zhang XW, 2019, J INTELL ROBOT SYST, V95, P389, DOI 10.1007/s10846-018-0917-2.
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009.},
Number-of-Cited-References = {55},
Times-Cited = {7},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {5},
Journal-ISO = {IET Intell. Transp. Syst.},
Doc-Delivery-Number = {RH1FM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000627604600001},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000547403600001,
Author = {Tas, Muhammed Oguz and Yavuz, Hasan Serhan and Yazici, Ahmet},
Title = {High-definition map update framework for intelligent autonomous transfer
   vehicles},
Journal = {JOURNAL OF EXPERIMENTAL \& THEORETICAL ARTIFICIAL INTELLIGENCE},
Year = {2021},
Volume = {33},
Number = {5},
Pages = {847-865},
Month = {SEP 3},
Abstract = {Autonomous transfer vehicles (ATVs) can be considered as one of the
   critical components of context-aware structured smart factories in
   Industry 4.0 era. Conventional mapping methods such as grid maps can
   provide information for navigation, but they are not enough for complex
   environments that require interactions. On the other hand,
   high-definition (HD) mapping, which is mainly used in traffic networks,
   includes more information about an environment to perform excellent
   autonomous behaviour. In order to increase the efficiency of ATVs in
   flexible factories, an up-to-date environmental map information is
   required to perform successful long-term autonomous navigation.
   Therefore, when there exists a change in the environment, a simultaneous
   update of HD-map is as important as the creation of it. In this study,
   we propose an HD-map update methodology for ATVs that operates in smart
   factories. To the best of our knowledge, HD mapping has not been applied
   in smart factories. The proposed method includes the object detection
   and localisation tool to detect objects visually and determines their
   positions in connection with the conventional maps of the environment.
   Experimental results of a simulated factory environment demonstrate that
   the ATV can properly update the HD-map when a predefined sign is removed
   from or a new sign is added to the environment.},
Publisher = {TAYLOR \& FRANCIS LTD},
Address = {2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Yavuz, HS (Corresponding Author), Eskisehir Osmangazi Univ, Elekt Elekt Muhendisligi Bolumu, TR-26480 Bati Meselik, Eskisehir, Turkey.
   Tas, Muhammed Oguz; Yavuz, Hasan Serhan, Eskisehir Osmangazi Univ, Elect \& Elect Engn Dept, Eskisehir, Turkey.
   Yazici, Ahmet, Eskisehir Osmangazi Univ, Comp Engn Dept, Eskisehir, Turkey.},
DOI = {10.1080/0952813X.2020.1789754},
EarlyAccessDate = {JUL 2020},
ISSN = {0952-813X},
EISSN = {1362-3079},
Keywords = {HD Map; autonomous transfer vehicles; smart factories; autonomous
   navigation},
Keywords-Plus = {MOBILE ROBOT; SIMULTANEOUS LOCALIZATION},
Research-Areas = {Computer Science},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence},
Author-Email = {hsyavuz@ogu.edu.tr},
Affiliations = {Eskisehir Osmangazi University; Eskisehir Osmangazi University},
ResearcherID-Numbers = {Yavuz, Hasan Serhan/ABB-7723-2020
   Yazıcı, Ahmet/ABE-9333-2021},
ORCID-Numbers = {Yavuz, Hasan Serhan/0000-0002-4944-1013
   },
Funding-Acknowledgement = {Scientific and Technological Research Council of Turkey (TUBITAK)
   {[}TUBITAK-116E731]},
Funding-Text = {This work was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) under Grant number {[}TUBITAK-116E731].},
Cited-References = {Audras C., 2011, AUSTR C ROB AUT, P1.
   Bauer S., 2016, 2016 IEEE 19 INT C I.
   Bennewitz M, 2003, IEEE INT CONF ROBOT, P2000, DOI 10.1109/ROBOT.2003.1241887.
   Bittel S, 2017, IEEE SYS MAN CYBERN, P52, DOI 10.1109/SMC.2017.8122577.
   Brady M, 1997, J EXP THEOR ARTIF IN, V9, P257, DOI 10.1080/095281397147112.
   Busch S., 2018, 38 WISS TECHN JAHR D.
   Cheeseman P., 1987, P IEEE INT C ROB AUT, P850, DOI DOI 10.1109/R0B0T.1987.1087846.
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403.
   Demim F, 2018, J EXP THEOR ARTIF IN, V30, P389, DOI 10.1080/0952813X.2017.1409282.
   Doriya R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REAL-TIME COMPUTING AND ROBOTICS (RCAR), P598, DOI 10.1109/RCAR.2017.8311928.
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720.
   Fernandes M., 2016, 2016 INT C AUT ROB S.
   Frese U, 2006, AUTON ROBOT, V20, P25, DOI 10.1007/s10514-006-5735-x.
   Gaudiot J.-L, 2017, SYNTHESIS LECT COMPU, V6, pi.
   Gazebo, 2018, GAZEBO.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   He X., 2018, ABS180407028 CORR.
   Inovasyon M., 2018, INOVASYON MUHENDISLI.
   Jang C, 2017, EXPERT SYST APPL, V88, P290, DOI 10.1016/j.eswa.2017.07.003.
   Jialin Jiao, 2018, 2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC). Proceedings, P367, DOI 10.1109/COMPSAC.2018.00058.
   Jo K, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093145.
   Jung M., 2016, 2016 16 INT C CONTR.
   Labbe M., 2011, RTAB MAP.
   Labbe M., 2011, FIND OBJECT.
   Labbe M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926.
   Labbe M, 2011, IEEE INT C INT ROBOT, P1271, DOI 10.1109/IROS.2011.6048225.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   Li P, 2011, J EXP THEOR ARTIF IN, V23, P5, DOI 10.1080/0952813X.2010.506283.
   Lucke D, 2008, MANUFACTURING SYSTEMS AND TECHNOLOGIES FOR THE NEW FRONTIER, P115, DOI 10.1007/978-1-84800-267-8\_23.
   Ma H., 2017, INT ARCH PHOTOGRAMM, VXLII-2/W7, P825, DOI {[}10.5194/isprs-archives-XLII-2-W7-825-2017, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W7-825-2017].
   Martinez-Barbera H, 2010, ROBOT CIM-INT MANUF, V26, P296, DOI 10.1016/j.rcim.2009.10.003.
   Massow K, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P1745, DOI 10.1109/ITSC.2016.7795794.
   Mattyus G., 2016, IEEE C COMP VIS PATT.
   Min BK, 1997, ROBOT CIM-INT MANUF, V13, P41, DOI 10.1016/S0736-5845(96)00017-8.
   Murray D., 1997, P INT C ROB AUT.
   Sankrit H., 2016, INT J SCI TECHNOLOGY, V2, P1226.
   Schumann S., 2014, WHY WERE MAPPING 20C.
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467.
   Se S, 2001, IEEE INT CONF ROBOT, P2051, DOI 10.1109/ROBOT.2001.932909.
   Seff A., 2016, ARXIV161108583.
   SIAM M, 2017, IEEE INT C INTELL TR.
   Silva B. M. F. D., 2017, 2017 LAT AM ROB S LA.
   Steinbrucker F, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS).
   Tas MO, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CONTROL ENGINEERING \& INFORMATION TECHNOLOGY (CEIT).
   Thrun S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P321, DOI 10.1109/ROBOT.2000.844077.
   Vasiljevic G, 2016, ROBOT CIM-INT MANUF, V42, P1, DOI 10.1016/j.rcim.2016.05.001.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.
   Xiong HL, 2014, IEEE GLOB COMM CONF, P4090, DOI 10.1109/GLOCOM.2014.7037448.
   Zheng SR, 2017, INT CONF LOCAL GNSS.},
Number-of-Cited-References = {49},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {10},
Journal-ISO = {J. Exp. Theor. Artif. Intell.},
Doc-Delivery-Number = {WA5NC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000547403600001},
DA = {2022-05-17},
}

@inproceedings{ WOS:000457881301019,
Author = {Yoshiki, Takahashi and Kanji, Tanaka and Yang Naiming},
Book-Group-Author = {IEEE},
Title = {Scalable Change Detection from 3D Point Cloud Maps: Invariant Map
   Coordinate for Joint Viewpoint-Change Localization},
DOI = {10.1109/ITSC.2018.8569294},
Booktitle = {2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS
   (ITSC)},
Series = {IEEE International Conference on Intelligent Transportation Systems-ITSC},
Year = {2018},
Pages = {1115-1121},
Note = {21st IEEE International Conference on Intelligent Transportation Systems
   (ITSC), Maui, HI, NOV 04-07, 2018},
Abstract = {This study addresses the problem of visual change detection using a 3D
   point cloud (PC) map acquired by a car-like robot. With recent advances
   in long-term autonomous navigation, change detection under global
   viewpoint uncertainty has become a topic of considerable interest. In
   our study, we extend the traditional two-level pipeline of change
   detection: (1) scene registration and (2) scene comparison, to enable
   scalable and efficient change detection. In the traditional pipeline,
   the registration stage is required to align a given scene pair (i.e.,
   query and reference PC maps) that are taken at different times into the
   same coordinate system, before comparing the two PCs. However, the
   registration stage is a time-consuming step, which makes it harder to
   realize a scalable change detection. Our key concept is to transform
   every query or reference PC beforehand into an invariant coordinate
   system, which should be pre-defined and invariant to environment changes
   (e.g., dynamic objects, clutters, the mapper vehicle's trajectories), so
   as to enable a direct comparison of spatial layout between the two
   different maps. The proposed framework employs an efficient
   bag-of-local-features (BoLF) scene model and realizes a scalable joint
   viewpoint-change detection. Change detection experiments using a
   publicly available cross-season NCLT dataset validate the efficacy of
   the approach.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kanji, T (Corresponding Author), Univ Fukui, Grad Sch Engn, Fukui, Japan.
   Yoshiki, Takahashi; Kanji, Tanaka; Yang Naiming, Univ Fukui, Grad Sch Engn, Fukui, Japan.},
ISSN = {2153-0009},
ISBN = {978-1-7281-0323-5},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering;
   Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Transportation
   Science \& Technology},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Funding-Acknowledgement = {JSPS KAKENHI {[}26330297, 17K00361]},
Funding-Text = {Our work has been supported in part by JSPS KAKENHI Grant-in-Aid for
   Scientific Research (C) 26330297, and for Scientific Research (C)
   17K00361.},
Cited-References = {Andreasson Henrik, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3429, DOI 10.1109/IROS.2007.4399381.
   Arroyo R, 2018, AUTON ROBOT, V42, P665, DOI 10.1007/s10514-017-9664-7.
   Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Cieslewski T, 2016, IEEE INT CONF ROBOT, P4830, DOI 10.1109/ICRA.2016.7487687.
   Drews P, 2013, IEEE INT CONF ROBOT, P4685, DOI 10.1109/ICRA.2013.6631244.
   Enfu L., 2017, IND POS IND NAV IPIN, P1, DOI DOI 10.1109/IPIN.2017.8115884.
   Ioannou Y, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION \& TRANSMISSION (3DIMPVT 2012), P501, DOI 10.1109/3DIMPVT.2012.12.
   Kanji T., 2015, IROS15 WS PPNIV.
   Kanji T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4497, DOI 10.1109/IROS.2016.7759662.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Niedfeldt PC, 2016, IEEE T AUTOMAT CONTR, V61, P456, DOI 10.1109/TAC.2015.2437518.
   Olufs Sven, 2011, IEEE International Conference on Robotics and Automation, P5315.
   Ponce J., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68.
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187.
   Steder B, 2011, IEEE INT C INT ROBOT, P1249, DOI 10.1109/IROS.2011.6048325.
   Steder Bastian, 2010, WORKSH DEF SOLV REAL, V44.
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1\_26.
   Tomoya M, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P31, DOI 10.1109/ACPR.2017.21.
   Yoshiki T., 2017, 20 IEEE INT C INT TR, P842.
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29.},
Number-of-Cited-References = {24},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BL9OB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000457881301019},
DA = {2022-05-17},
}

@article{ WOS:000436774300040,
Author = {Xing, Boyang and Zhu, Quanmin and Pan, Feng and Feng, Xiaoxue},
Title = {Marker-Based Multi-Sensor Fusion Indoor Localization System for Micro
   Air Vehicles},
Pages = {1706},
Journal = {SENSORS},
Year = {2018},
Volume = {18},
Number = {6},
Month = {JUN},
Abstract = {A novel multi-sensor fusion indoor localization algorithm based on ArUco
   marker is designed in this paper. The proposed ArUco mapping algorithm
   can build and correct the map of markers online with Grubbs criterion
   and K-mean clustering, which avoids the map distortion due to lack of
   correction. Based on the conception of multi-sensor information fusion,
   the federated Kalman filter is utilized to synthesize the multi-source
   information from markers, optical flow, ultrasonic and the inertial
   sensor, which can obtain a continuous localization result and
   effectively reduce the position drift due to the long-term loss of
   markers in pure marker localization. The proposed algorithm can be
   easily implemented in a hardware of one Raspberry Pi Zero and two STM32
   micro controllers produced by STMicroelectronics (Geneva, Switzerland).
   Thus, a small-size and low-cost marker-based localization system is
   presented. The experimental results show that the speed estimation
   result of the proposed system is better than Px4flow, and it has the
   centimeter accuracy of mapping and positioning. The presented system not
   only gives satisfying localization precision, but also has the potential
   to expand other sensors (such as visual odometry, ultra wideband (UWB)
   beacon and lidar) to further improve the localization performance. The
   proposed system can be reliably employed in Micro Aerial Vehicle (MAV)
   visual localization and robotics control.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Feng, XX (Corresponding Author), Beijing Inst Technol, Sch Automat, Beijing 100081, Peoples R China.
   Xing, Boyang; Pan, Feng; Feng, Xiaoxue, Beijing Inst Technol, Sch Automat, Beijing 100081, Peoples R China.
   Zhu, Quanmin, Univ West England, Fac Comp Engn \& Math Sci, Bristol BS16 1QY, Avon, England.
   Pan, Feng, Kunming BIT Ind Technology Res Inst INC, Kunming 650106, Yunnan, Peoples R China.},
DOI = {10.3390/s18061706},
Article-Number = {1706},
EISSN = {1424-8220},
Keywords = {indoor localization; ArUco marker; federated filter; Micro Aerial
   Vehicle},
Keywords-Plus = {NAVIGATION; FILTER},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {golaced@163.com
   quan.zhu@uwe.ac.uk
   panfeng@bit.edu.cn
   fengxiaoxue@bit.edu.cn},
Affiliations = {Beijing Institute of Technology; University of West England},
ORCID-Numbers = {Zhu, Quanmin/0000-0001-8173-1179},
Funding-Acknowledgement = {National Natural Science Foundation (NNSF) of China {[}61603040]},
Funding-Text = {This work has been supported by the National Natural Science Foundation
   (NNSF) of China under Grant 61603040.},
Cited-References = {Agarwal S., 2012, IFAC P, P97, DOI DOI 10.3182/20120213-3-IN-4034.00020.
   Ardaens JS, 2013, ACTA ASTRONAUT, V91, P341, DOI 10.1016/j.actaastro.2013.06.025.
   Bacik J, 2017, INTEL SERV ROBOT, V10, P185, DOI 10.1007/s11370-017-0219-8.
   Balajiwale S, 2016, IFAC PAPERSONLINE, V49, P585, DOI 10.1016/j.ifacol.2016.03.118.
   CARLSON NA, 1990, IEEE T AERO ELEC SYS, V26, P517, DOI 10.1109/7.106130.
   FORGY EW, 1965, BIOMETRICS, V21, P768.
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005.
   Godil A., 2013, GROUND TRUTH SYSTEMS.
   GRUBBS FE, 1950, ANN MATH STAT, V21, P27, DOI 10.1214/aoms/1177729885.
   Gutierrez-Gomez D, 2016, ROBOT AUTON SYST, V75, P571, DOI 10.1016/j.robot.2015.09.026.
   Hamilton WR., 1844, PHILOS MAG J SCI, V33, P58, DOI {[}10.1080/14786444808646046, DOI 10.1080/14786444808646046].
   Honegger D, 2013, IEEE INT CONF ROBOT, P1736, DOI 10.1109/ICRA.2013.6630805.
   Hyon Lim, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P177.
   Jean-Yves B, 1999, OPENCV DOCUMENTS, V22, P363.
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141.
   Klopschitz M., 2007, ISMAR, P1.
   Li ZK, 2016, ADV SPACE RES, V58, P2424, DOI 10.1016/j.asr.2016.07.028.
   Lucas B.D., 1971, P INT JOINT C ART IN, P674.
   Lynen S, 2013, IEEE INT C INT ROBOT, P3923, DOI 10.1109/IROS.2013.6696917.
   Montemerlo M., 2003, P 18 INT JOINT C ART, P1151.
   Munoz-Salinas R, 2018, PATTERN RECOGN, V73, P158, DOI 10.1016/j.patcog.2017.08.010.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Qiu Kai, 2004, Control and Decision, V19, P1420.
   Sanchez-Lopez J.L., 2017, P 20 IFAC WORLD C TO.
   Shaya K., 2012, CAPABILITIES, V7508, P13.
   Sola J, 2012, INT J COMPUT VISION, V97, P339, DOI 10.1007/s11263-011-0492-5.
   Song YL, 2015, OPTIK, V126, P3877, DOI 10.1016/j.ijleo.2015.07.058.
   Yang Z, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543592.
   {[}张怡 ZHANG Yi], 2009, {[}计算机仿真, Computer Simulation], V26, P358.
   Zhao L, 2016, MEASUREMENT, V80, P138, DOI 10.1016/j.measurement.2015.11.008.},
Number-of-Cited-References = {30},
Times-Cited = {21},
Usage-Count-Last-180-days = {11},
Usage-Count-Since-2013 = {48},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {GL0KD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000436774300040},
OA = {Green Submitted, gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000089546000050,
Author = {Zimmer, UR},
Book-Group-Author = {IEEE
   IEEE},
Title = {Embedding local metrical map patches in a globally consistent
   topological map},
DOI = {10.1109/UT.2000.852560},
Booktitle = {PROCEEDINGS OF THE 2000 INTERNATIONAL SYMPOSIUM ON UNDERWATER TECHNOLOGY},
Year = {1998},
Pages = {301-305},
Note = {2nd International Symposium on Underwater Technology, TOKYO, JAPAN, MAY
   23-26, 2000},
Abstract = {This article considers some practical and theoretical issues in the
   trade-off between globally consistent navigation and local precision
   manoeuvring. Precise local metrical maps are the common base for
   docking, manipulation, or other exact trajectory planning and control
   tasks. Yet these models are not scaling fine in the total geometrical
   size, when handling real world sensory data, and drifts. Nevertheless
   there is a need for a globally consistent spatial model for long term
   navigation. The presented work proposes a method of embedding local
   metric area patches in a topologically consistent global structure
   suitable for qualitative, and robust navigation. A global positioning
   information is not required at any stage, which limits the global
   precision of the spatial model, but on the other hand recommends it for
   environments where this information is not available. Results from
   physical experiments with autonomous robots are presented to demonstrate
   the robustness and practicality of the approach.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zimmer, UR (Corresponding Author), GMD Japan Res Lab, Kokurakita Ku, AIM Bldg 8F,3-8-1 Ansano, Kitakyushu, Fukuoka 8020001, Japan.
   GMD Japan Res Lab, Kokurakita Ku, Kitakyushu, Fukuoka 8020001, Japan.},
ISBN = {0-7803-6378-7},
Keywords = {mobile robots; world modelling; dynamical environments; exploration;
   self-localization; self-organization},
Keywords-Plus = {REAL-WORLD; NAVIGATION},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Civil},
Cited-References = {BARAKOVA E, P INT C ADV INT SYST.
   ELFES A, 1987, IEEE T ROBOTIC AUTOM, V3, P249, DOI 10.1109/JRA.1987.1087096.
   GAT E, 1992, P AAAI 92 SAN MAT CA.
   HERTZBERG J, 1998, ISIC CIRA ISAS 98 SE.
   MARTINETZ TM, 1993, IEEE T NEURAL NETWOR, V4, P558, DOI 10.1109/72.238311.
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7.
   Tieche F, 1999, CONTROL ENG PRACT, V7, P797, DOI 10.1016/S0967-0661(99)00026-X.
   TIECHE F, 1999, CONTROL ENG PRACTICE, V7, P802.
   Zimmer UR, 1996, NEUROCOMPUTING, V13, P247, DOI 10.1016/0925-2312(95)00097-6.},
Number-of-Cited-References = {9},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BQ79V},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000089546000050},
DA = {2022-05-17},
}

@inproceedings{ WOS:000258320300001,
Author = {Andreopoulos, Alexander and Tsotsos, John K.},
Book-Group-Author = {IEEE Computer Society},
Title = {Active vision for door localization and door opening using Playbot: A
   computer controlled wheelchair for people with mobility impairments},
Booktitle = {PROCEEDINGS OF THE FIFTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT
   VISION},
Year = {2008},
Pages = {3-10},
Note = {5th Canadian Conference on Computer and Robot Vision, Windsor, CANADA,
   MAY 28-30, 2008},
Abstract = {Playbot {[}1, 13] is a long-term, large-scale research project, whose
   goal is to provide a vision-based computer controlled wheelchair that
   enables children and adults with mobility impairments to become more
   independent. Within this context, we show how Playbot can actively
   search an indoor environment to localize a door approach the door use a
   mounted robotic arm to open the door and go through the door, using
   exclusively vision-based sensors and without using a map of the
   environment. We demonstrate the effectiveness of active vision for
   localizing objects that are too large to fall within a single camera's
   field of view and show that well-calibrated vision-based sensors are
   sufficient to safely pass through a doorframe that is narrow enough to
   tolerate a wheelchair localization error of at most a few centimetres.
   We provide experimental results demonstrating near perfect performance
   in an indoor environment.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Andreopoulos, A (Corresponding Author), York Univ, Dept Comp Sci \& Engn, Toronto, ON M3J 1P3, Canada.
   Andreopoulos, Alexander; Tsotsos, John K., York Univ, Dept Comp Sci \& Engn, Toronto, ON M3J 1P3, Canada.},
DOI = {10.1109/CRV.2008.23},
ISBN = {978-0-7695-3153-3},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {alekos@cse.yorku.ca
   tsotsos@cse.yorku.ca},
Affiliations = {York University - Canada},
ResearcherID-Numbers = {Tsotsos, John K/G-3436-2011
   Tsotsos, John/N-1131-2019},
ORCID-Numbers = {Tsotsos, John/0000-0002-8621-9147},
Cited-References = {ANDREOPOULOS A, 2007, 8 AS C COMP VIS ACCV.
   ANDREOPOULOS A, 2007, ROBOTICS SCI SYSTEMS.
   Bajcsy R., 1985, IEEE WORKSH COMP VIS.
   BROOKS R, 2004, INT J HUM ROBOT, V1, P1.
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851.
   EJIRI M, 2007, 8 AS C COMP VIS ACCV.
   NAGATANI K, 1996, IEEE INT C ROB AUT A.
   NIEMEYER G, 1997, IEEE INT C ROB AUT.
   RHEE C, 2004, IEEE INT C ROB AUT A.
   Shi J., 1994, COMPUTER VISION PATT.
   Tsotsos JK, 1998, IMAGE VISION COMPUT, V16, P275, DOI 10.1016/S0262-8856(97)00088-7.
   TSOTSOS JK, 1992, INT J COMPUT VISION, V7, P127, DOI 10.1007/BF00128132.
   Viola P., 2001, CVPR.},
Number-of-Cited-References = {13},
Times-Cited = {13},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Doc-Delivery-Number = {BIB97},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000258320300001},
DA = {2022-05-17},
}

@inproceedings{ WOS:000659928700131,
Author = {Stoven-Dubois, Alexis and Dziri, Aziz and Leroy, Bertrand and Chapuis,
   Roland},
Book-Group-Author = {IEEE},
Title = {Graph Optimization Methods for Large-Scale Crowdsourced Mapping},
DOI = {10.23919/FUSION45008.2020.919029},
Booktitle = {PROCEEDINGS OF 2020 23RD INTERNATIONAL CONFERENCE ON INFORMATION FUSION
   (FUSION 2020)},
Year = {2020},
Pages = {980-987},
Note = {23rd International Conference on Information Fusion (FUSION), ELECTR
   NETWORK, JUL 06-09, 2020},
Abstract = {Automotive players have recently shown an increasing interest in
   high-precision mapping, with the aim of enhancing vehicles safety and
   autonomy. Nevertheless, the acquisition, processing, and updates of
   accurate maps remains an economic challenge. Collaborative mapping
   through vehicles crowd-sourcing represents a promising solution to
   tackle this problem. However, the potential scalability and accuracy
   provided by such an approach have yet to be studied and assessed.
   In this paper, we study the use of graph optimization in the scope of
   collaborative mapping. We build a map of geo-localized landmarks by
   crowdsourcing observations from multiple vehicles, and applying several
   successive map updates. We present different strategies to adapt graph
   optimization to the crowdsourced approach, and compare their
   performances in terms of map quality and scalability on simulation data.
   We show the critical requirement, in a long-term context, to ensure
   consistency of the map updates, and we propose a scalable solution which
   is able to build an accurate map of geolocalized landmarks.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Stoven-Dubois, A (Corresponding Author), VEDECOM, Mobil Dept, F-78000 Versailles, France.
   Stoven-Dubois, Alexis; Dziri, Aziz; Leroy, Bertrand, VEDECOM, Mobil Dept, F-78000 Versailles, France.
   Chapuis, Roland, Univ Clermont Auvergne, Inst Pascal, SIGMA Clermont, CNRS, F-63000 Clermont Ferrand, France.},
ISBN = {978-0-578-64709-8},
Keywords = {Crowdsourced Mapping; Collaborative Mapping; Graph Optimization;
   High-Precision Mapping; Geolocalization},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic},
Author-Email = {alexis.stoven-dubois@vedecom.fr
   roland.chapuis@uca.fr},
Affiliations = {Centre National de la Recherche Scientifique (CNRS); Universite Clermont
   Auvergne (UCA)},
Cited-References = {Bailey T, 2006, IEEE INT CONF ROBOT, P424, DOI 10.1109/ROBOT.2006.1641748.
   Bresson G, 2017, IEEE T INTELL VEHICL, V2, P194, DOI 10.1109/TIV.2017.2749181.
   Delobel L, 2019, IEEE T INTELL TRANSP, V20, P1644, DOI 10.1109/TITS.2018.2840822.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Grisetti G, 2010, IEEE INTEL TRANSP SY, V2, P31, DOI 10.1109/MITS.2010.939925.
   Ila V, 2017, INT J ROBOT RES, V36, P210, DOI 10.1177/0278364917691110.
   Indelman V, 2013, ROBOT AUTON SYST, V61, P721, DOI 10.1016/j.robot.2013.05.001.
   Kim C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124172.
   Li H, 2013, IEEE T INTELL TRANSP, V14, P1860, DOI 10.1109/TITS.2013.2267800.
   Noack B, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1862.
   Seif HG, 2016, ENGINEERING, V2, P159, DOI 10.1016/J.ENG.2016.02.010.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Stoven-Dubois A, 2019, IEEE INT C INTELL TR, P1845, DOI 10.1109/ITSC.2019.8917292.
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Vallve J, 2018, IEEE ROBOT AUTOM LET, V3, P1322, DOI 10.1109/LRA.2018.2798283.
   Wilbers D, 2019, IEEE INT CONF ROBOT, P5951, DOI 10.1109/ICRA.2019.8793971.
   Zolotovitski A, 2015, PROCEEDINGS OF 10TH ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON COMPUTATIONAL TRANSPORTATION SCIENCE (IWCTS 2017), P24, DOI 10.1145/3151547.3151552.},
Number-of-Cited-References = {19},
Times-Cited = {1},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BR6DF},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000659928700131},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921702140,
Author = {Su, Daobilige and Nakamura, Keisuke and Nakadai, Kazuhiro and Miro,
   Jaime Valls},
Book-Group-Author = {IEEE},
Title = {Robust Sound Source Mapping using Three-layered Selective Audio Rays for
   Mobile Robots},
DOI = {10.1109/IROS.2016.7759430},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {2771-2777},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {This paper investigates sound source mapping in a real environment using
   a mobile robot. Our approach is based on audio ray tracing which
   integrates occupancy grids and sound source localization using a laser
   range finder and a microphone array. Previous audio ray tracing
   approaches rely on all observed rays and grids. As such observation
   errors caused by sound reflection, sound occlusion, wall occlusion,
   sounds at misdetected grids, etc. can significantly degrade the ability
   to locate sound sources in a map. A three-layered selective audio ray
   tracing mechanism is proposed in this work. The first layer conducts
   frame-based unreliable ray rejection (sensory rejection) considering
   sound reflection and wall occlusion. The second layer introduces
   triangulation and audio tracing to detect falsely detected sound
   sources, rejecting audio rays associated to these misdetected sounds
   sources (short-term rejection). A third layer is tasked with rejecting
   rays using the whole history (long-term rejection) to disambiguate sound
   occlusion. Experimental results under various situations are presented,
   which proves the effectiveness of our method.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Su, D (Corresponding Author), Univ Technol Sydney, CAS, Sydney, NSW, Australia.
   Su, D (Corresponding Author), Honda Res Inst Japan Co Ltd, Wako, Saitama 3510114, Japan.
   Su, Daobilige; Miro, Jaime Valls, Univ Technol Sydney, CAS, Sydney, NSW, Australia.
   Su, Daobilige; Nakamura, Keisuke; Nakadai, Kazuhiro, Honda Res Inst Japan Co Ltd, Wako, Saitama 3510114, Japan.},
ISBN = {978-1-5090-3762-9},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {daobilige.su@student.uts.edu.au
   keisuke@jp.honda-ri.com
   nakadai@jp.honda-ri.com
   jaime.vallsmiro@uts.edu.au},
Affiliations = {University of Technology Sydney; Honda Motor Company},
ResearcherID-Numbers = {Miro, Jaime Valls/G-2656-2017},
ORCID-Numbers = {Miro, Jaime Valls/0000-0002-0083-7797},
Cited-References = {ALLEN JB, 1979, J ACOUST SOC AM, V65, P943, DOI 10.1121/1.382599.
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027.
   Brandstein MS, 1997, INT CONF ACOUST SPEE, P375, DOI 10.1109/ICASSP.1997.599651.
   Hu JS, 2009, IEEE INT CONF ROBOT, P4004.
   Kagami S, 2009, INT CONF ACOUST SPEE, P3689, DOI 10.1109/ICASSP.2009.4960427.
   Kallakuri N, 2013, IEEE INT CONF ROBOT, P2270, DOI 10.1109/ICRA.2013.6630884.
   Kohlbrecher S., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P155, DOI 10.1109/SSRR.2011.6106777.
   Martinson E, 2009, AUTON ROBOT, V27, P221, DOI 10.1007/s10514-009-9123-1.
   Nakadai K, 2010, ADV ROBOTICS, V24, P739, DOI 10.1163/016918610X493561.
   Narang G, 2014, IEEE SYS MAN CYBERN, P4021, DOI 10.1109/SMC.2014.6974560.
   Sasaki Y, 2009, ADV ROBOTICS, V23, P145, DOI 10.1163/156855308X392717.
   SCHMIDT RO, 1986, IEEE T ANTENN PROPAG, V34, P276, DOI 10.1109/TAP.1986.1143830.
   Thrun Sebastian, 2005, PROBABILISTIC ROBOTI, V1.},
Number-of-Cited-References = {13},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921702140},
OA = {Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000349834604097,
Author = {Krajnik, Tomas and Fentanes, Jaime P. and Mozos, Oscar M. and Duckett,
   Tom and Ekekrantz, Johan and Hanheide, Marc},
Book-Group-Author = {IEEE},
Title = {Long-Term Topological Localisation for Service Robots in Dynamic
   Environments using Spectral Maps},
DOI = {10.1109/IROS.2014.6943205},
Booktitle = {2014 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2014)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2014},
Pages = {4537+},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Chicago, IL, SEP 14-18, 2014},
Abstract = {This paper presents a new approach for topological localisation of
   service robots in dynamic indoor environments. In contrast to typical
   localisation approaches that rely mainly on static parts of the
   environment, our approach makes explicit use of information about
   changes by learning and modelling the spatio-temporal dynamics of the
   environment where the robot is acting. The proposed spatio-temporal
   world model is able to predict environmental changes in time, allowing
   the robot to improve its localisation capabilities during longterm
   operations in populated environments. To investigate the proposed
   approach, we have enabled a mobile robot to autonomously patrol a
   populated environment over a period of one week while building the
   proposed model representation. We demonstrate that the experience
   learned during one week is applicable for topological localization even
   after a hiatus of three months by showing that the localization error
   rate is significantly lower compared to static environment
   representations.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Krajnik, T (Corresponding Author), Lincoln Univ, Lincoln Ctr Autonomous Syst, Lincoln, England.
   Krajnik, Tomas; Fentanes, Jaime P.; Mozos, Oscar M.; Duckett, Tom; Hanheide, Marc, Lincoln Univ, Lincoln Ctr Autonomous Syst, Lincoln, England.},
ISSN = {2153-0858},
ISBN = {978-1-4799-6934-0},
Keywords = {topological localisation; mobile robotics; spatio-temporal
   representations},
Research-Areas = {Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Engineering, Electrical \&
   Electronic; Robotics},
Author-Email = {tkrajnik@lincoln.ac.uk},
Affiliations = {University of Lincoln},
ResearcherID-Numbers = {Hanheide, Marc/AAO-9299-2021
   Krajník, Tomáš/O-2339-2013
   Mozos, Oscar M/A-7450-2017},
ORCID-Numbers = {Hanheide, Marc/0000-0001-7728-1849
   Krajník, Tomáš/0000-0002-4408-7916
   Mozos, Oscar M/0000-0002-3908-4921},
Cited-References = {Agrawal M, 2008, ECCV.
   Badino H., 2011, IEEE INT VEH S 4.
   Biber P., 2009, INT J ROBOTICS RES.
   Bracewell R.N., 1986, FOURIER TRANSFORM IT.
   Cadena C., 2012, IEEE T ROBOTICS.
   Calonder M., 2010, P ICCV.
   Churchill W., 2012, ICRA.
   Dayoub F, 2008, IROS.
   Dayoub F., 2011, ROBOTICS AUTONOMOUS.
   Ekekrantz J., 2013, ECMR.
   Hahnel D., 2003, ADV ROBOTICS.
   Konolige K., 2009, INT ROB SYST IROS 20.
   Kosnar K., 2013, ECMR.
   Krajnik T., 2014, ICRA.
   Krajnik T., 2010, J FIELD ROBOTICS, V27.
   Krajnik T, 2014, J INTELL ROBOT SYST, V76, P539, DOI 10.1007/s10846-014-0041-x.
   Migliore D., 2009, ICRA WORKSH SNODE AP.
   Milford M., 2010, IJRR.
   Milford Michael J, 2012, ICRA.
   Montesano L., 2008, AUT ROBOTS.
   Murillo A. C., 2007, ICRA.
   Neubert P., 2013, ECMR.
   Pronobis A., 2010, ROBOTICS AUTONOMOUS.
   Tipaldi Gian Diego, 2013, INT J ROBOTICS RES.
   Valgren C., 2010, RAS.
   Valgren C., 2007, ECMR.
   Wolf D., 2005, AUTONOMOUS ROBOTS.
   {[}No title captured].},
Number-of-Cited-References = {28},
Times-Cited = {21},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BC0YL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000349834604097},
OA = {Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000166106900014,
Author = {Gross, HM and Boehme, HJ},
Book-Group-Author = {IEEE
   IEEE},
Title = {PERSES - a vision-based interactive mobile shopping assistant},
DOI = {10.1109/ICSMC.2000.884968},
Booktitle = {SMC 2000 CONFERENCE PROCEEDINGS: 2000 IEEE INTERNATIONAL CONFERENCE ON
   SYSTEMS, MAN \& CYBERNETICS, VOL 1-5},
Series = {IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings},
Year = {2000},
Pages = {80-85},
Note = {IEEE International Conference on Systems, Man and Cybernetics,
   NASHVILLE, TN, OCT 08-11, 2000},
Abstract = {The paper describes the general idea, the application scenario, and
   selected methodological approaches of our long-term research project
   PERSES (PERsonal SErvice System). The aim of the project consists in the
   development of an interactive mobile shopping assistant that allows a
   continuous and intuitively understandable interaction with a customer in
   a home improvement store. Typical tasks we have to tackle ate to detect
   and contact potential users in the operation area, to guide them to
   desired areas or articles within the store or to follow them as a mobile
   information kiosk while continuously observing their behavior. Due to
   the specificity of the interaction-oriented scenario and the
   characteristics of the operation area, we have focused on vision-based
   methods for both human-robot interaction and robot navigation. Besides
   some methodological approaches, we present preliminary results of
   experiments achieved with our mobile robot PERSES in the store with an
   emphasis on vision-based methods for user localization, map building and
   serf-localization.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Gross, HM (Corresponding Author), Tech Univ Ilmenau, Dept Neuroinformat, D-98684 Ilmenau, Germany.
   Tech Univ Ilmenau, Dept Neuroinformat, D-98684 Ilmenau, Germany.},
ISSN = {1062-922X},
ISBN = {0-7803-6583-6},
Keywords-Plus = {ROBOT; DYNAMICS; BEHAVIOR},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Cybernetics; Engineering, Electrical \& Electronic},
Author-Email = {Horst-Michael.Gross@informatik.tu-ilmenau.de},
Affiliations = {Technische Universitat Ilmenau},
Cited-References = {AMARI SI, 1977, BIOL CYBERN, V27, P77, DOI 10.1007/BF00337259.
   Bergener T, 1999, NEURAL NETWORKS, V12, P1087, DOI 10.1016/S0893-6080(99)00045-3.
   BOEHME HJ, 1999, P 3 INT GEST WORKSH, P105.
   BURGARD W, 1999, ARTIFICIAL INTELLIGE, V114.
   Duchon AP, 1998, ADAPT BEHAV, V6, P473, DOI 10.1177/105971239800600306.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   FOX D, P AAAI 99.
   MORAVEC HP, 1988, AI MAG, V9, P61.
   SCHAUER C, P IEEE ICASSP 2000, V2, P865.
   Schoner G, 1995, ROBOT AUTON SYST, V16, P213, DOI 10.1016/0921-8890(95)00049-6.
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7.
   Thrun S., 1999, P IEEE INT C ROB AUT.
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236.},
Number-of-Cited-References = {13},
Times-Cited = {18},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BR32T},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000166106900014},
DA = {2022-05-17},
}

@inproceedings{ WOS:000236887500011,
Author = {Williams, S and Mahon, I},
Editor = {Ang, MH and Khatib, O},
Title = {Terrain aided localisation and mapping for marine environments},
DOI = {10.1007/11552246_11},
Booktitle = {EXPERIMENTAL ROBOTICS IX},
Series = {Springer Tracts in Advanced Robotics},
Year = {2006},
Volume = {21},
Pages = {111+},
Note = {9th International Symposium on Experimental Robotics (ISER), Singapore,
   SINGAPORE, JUN 18-21, 2004},
Abstract = {This paper presents experimental results of the application of terrain
   aided localisation and mapping algorithms to vehicle deployments in
   marine environments. The application of a terrain aided navigation
   filter to the tracking of a ship operating on Sydney Harbour is
   described. This approach allows highly unstructured seafloor bathymetric
   information to be incorporated into the navigation solution. In
   addition, experimental validation of the Simultaneous Localisation and
   Mapping algorithm using data collected by an Unmanned Underwater Vehicle
   operating on the Great Barrier Reef in Australia is reported. By fusing
   information from the vehicle's on-board sonar and vision systems, it is
   possible to use the highly textured reef to provide estimates of the
   vehicle motion as well as to generate models of the gross structure of
   the underlying reefs. Terrain-aided navigation promises to revolutionise
   the ability of marine systems to track underwater bodies in many
   applications. This work represents a crucial step in the development of
   underwater technologies capable of long-term, reliable deployment.},
Publisher = {SPRINGER-VERLAG BERLIN},
Address = {HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Williams, S (Corresponding Author), Univ Sydney, ARC Ctr Excellence Autonomous Syst CAS, Sydney, NSW 2006, Australia.
   Univ Sydney, ARC Ctr Excellence Autonomous Syst CAS, Sydney, NSW 2006, Australia.},
ISSN = {1610-7438},
EISSN = {1610-742X},
ISBN = {3-540-28816-3},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {s.williams@cas.edu.au
   i.mahon@cas.edu.au},
Affiliations = {University of Sydney},
ResearcherID-Numbers = {Williams, Stefan/AAE-4376-2020},
ORCID-Numbers = {Williams, Stefan/0000-0001-9416-5639},
Funding-Acknowledgement = {ARC Center of Excellence Program by the Austrlian Research Council New
   South Wales goverment},
Funding-Text = {The authors wish to acknowledge the support provided under the ARC
   Center of Excellence Program by the Austrlian Research Council and the
   New South Wales goverment. The advanced Technology Center of BAe Systems
   have also contributed generoulsy towards the costs of deploying the
   vechicle in a field enviroment.},
Cited-References = {Bergman N, 1999, IEEE CONTR SYST MAG, V19, P33, DOI 10.1109/37.768538.
   Castellanos JA, 1999, IEEE T ROBOTIC AUTOM, V15, P948, DOI 10.1109/70.795798.
   DEMOUSTIER C, 1993, MAR GEOPHYS RES, V15, P27, DOI 10.1007/BF01204150.
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381.
   GUSTAFSSON F, 1999, IEEE T SIGNAL PROCES.
   Johnson AE, 1996, AUTON ROBOT, V3, P145, DOI 10.1007/BF00141152.
   KARLSSON R, 2002, LITHISYR2474.
   LANGER D, 1991, 1991 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, P2478, DOI 10.1109/ROBOT.1991.131997.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   LEONARD JJ, 1999, P 9 INT S ROB RES, P169.
   Lowe D., 2003, INT J COMPUTER VISIO, P547.
   LUCAS BD, 1981, P 7 INT JOINT C ART, P674.
   MAJUMDER S, 2000, P AUSTR C ROB AUT AU, P25.
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384.
   Maybeck P.S, 1982, STOCHASTIC MODELS ES, V1.
   NEWMAN P, 1999, THESIS U SYDNEY.
   RIGAUD V, 1990, P IEEE INT C ROB AUT, V2, P1310.
   Thrun S., 1998, MACHINE LEARNING AUT.
   Whitcomb L., 1999, 9 INT S ROB RES, P346.
   WILLIAMS S, 2001, THESIS U SYDNEY.
   WILLIAMS S, 2004, P IEEE INT C ROB AUT.
   WILLIAMS SB, 2004, IN PRESS FIELD SERVI.},
Number-of-Cited-References = {22},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BED74},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000236887500011},
DA = {2022-05-17},
}

@article{ WOS:000761315100002,
Author = {McMurray, Katherine M. J. and Winter, Andrew and Ahlbrand, Rebecca and
   Wilson, Allison and Shukla, Sachi and Sah, Renu},
Title = {Subfornical organ interleukin 1 receptor: A novel regulator of
   spontaneous and conditioned fear associated behaviors in mice},
Journal = {BRAIN BEHAVIOR AND IMMUNITY},
Year = {2022},
Volume = {101},
Pages = {304-317},
Month = {MAR},
Abstract = {Impaired threat responding and fear regulation is a hallmark of
   psychiatric conditions such as post-traumatic stress disorder (PTSD) and
   Panic Disorder (PD). Most studies have focused on external psychogenic
   threats to study fear, however, accumulating evidence suggests a primary
   role of homeostatic perturbations and interoception in regulating
   emotional behaviors. Heightened reactivity to interoceptive threat
   carbon dioxide (CO2) inhalation associates with increased risk for
   developing PD and PTSD, however, contributory mechanisms and molecular
   targets are not well understood. Previous studies from our group
   suggested a potential role of interleukin 1 receptor (IL-1R1) signaling
   within BBB-devoid sensory circumventricular organ, the subfornical organ
   (SFO) in CO2-evoked fear. However, the necessity of SFO-IL-1R1 in
   regulating CO2-associated spontaneous fear as well as, long-term fear
   potentiation relevant to PD/PTSD has not been investigated. The current
   study tested male mice with SFO-targeted microinfusion of the IL-1R1
   antagonist (IL-1RA) or vehicle in a recently developed CO2-startle-fear
   conditioning-extinction paradigm. Consistent with our hypothesis, SFO
   IL-1RA treatment elicited significant attenuation of freezing and
   increased rearing during CO2 inhalation suggesting SFO-IL1R1 regulation
   of spontaneous fear to CO2. Intriguingly, SFO IL-1RA treatment
   normalized CO2-associated potentiation of conditioned fear and impaired
   extinction a week later suggesting modulation of long-term fear by
   SFO-IL-1R1 signaling. Post behavior FosB mapping revealed recruitment of
   prefrontal cortex-amygdala-periaqueductal gray (PAG) areas in SFO-IL-1RA
   mediated effects. Additionally, we localized cellular IL-1R1 expression
   within the SFO to blood vessel endothelial cells and observed
   CO2-induced alterations in IL-1 beta/IL-1R1 expression in peripheral
   mononuclear cells and SFO. Lastly, CO2-evoked microglial activation was
   attenuated in SFO-IL-1RA treated mice. These observations suggest a
   peripheral monocyte-endothelial-microglia interplay in SFO-IL-1R1
   modulation of CO2-associated spontaneous fear and delayed fear memory.
   Collectively, our data highlight a novel, ``bottom-up{''} neuroimmune
   mechanism that integrates interoceptive and exteroceptive threat
   processing of relevance to fear-related pathologies.},
Publisher = {ACADEMIC PRESS INC ELSEVIER SCIENCE},
Address = {525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA},
Type = {Article},
Language = {English},
Affiliation = {Sah, R (Corresponding Author), Univ Cincinnati, Dept Pharmacol \& Syst Physiol, UC North Reading Campus,2170 East Galbraith Rd, Cincinnati, OH 45237 USA.
   McMurray, Katherine M. J.; Winter, Andrew; Ahlbrand, Rebecca; Sah, Renu, Univ Cincinnati, Dept Pharmacol \& Syst Physiol, UC North Reading Campus,2170 East Galbraith Rd, Cincinnati, OH 45237 USA.
   Winter, Andrew; Sah, Renu, Univ Cincinnati, Neurosci Grad Program, Cincinnati, OH 45237 USA.
   Wilson, Allison; Shukla, Sachi, Univ Cincinnati, Neurosci Undergrad Program, Cincinnati, OH 45237 USA.
   McMurray, Katherine M. J.; Sah, Renu, Vet Affairs Med Ctr, Cincinnati, OH 45267 USA.},
DOI = {10.1016/j.bbi.2022.01.004},
ISSN = {0889-1591},
EISSN = {1090-2139},
Keywords = {Subfornical organ; Fear; Threat; CO2; Panic; PTSD},
Keywords-Plus = {POSTTRAUMATIC-STRESS-DISORDER; SENSORY CIRCUMVENTRICULAR ORGANS;
   35-PERCENT CARBON-DIOXIDE; ENHANCED FEAR; PERIAQUEDUCTAL GRAY;
   INTERCALATED NEURONS; SEX-DIFFERENCES; CO2 INHALATION; ANIMAL-MODELS;
   AMYGDALA},
Research-Areas = {Immunology; Neurosciences \& Neurology; Psychiatry},
Web-of-Science-Categories  = {Immunology; Neurosciences; Psychiatry},
Author-Email = {sahr@uc.edu},
Affiliations = {University of Cincinnati; University of Cincinnati; University of
   Cincinnati; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Case Western Reserve University; Louis Stokes
   Cleveland Veterans Affairs Medical Center; Cincinnati VA Medical Center},
Funding-Acknowledgement = {VA Merit Grants {[}2I0-1BX001075, I01-BX001075]; T32 pre-doctoral
   training program in Neuroscience grant {[}T32 NS 007453]; 
   {[}F32MH117913]},
Funding-Text = {This work was supported by VA Merit Grants 2I0-1BX001075 and
   I01-BX001075 to RS. Support is also acknowledged from postdoctoral
   training award F32MH117913 (KMJM). AW would like to acknowledge support
   from a T32 pre-doctoral training program in Neuroscience grant (T32 NS
   007453). The content is solely the responsibility of the authors and
   does not necessarily represent the official views of the NIH. The
   authors declare no competing interests.},
Cited-References = {Biagioni AF, 2016, BEHAV BRAIN RES, V298, P65, DOI 10.1016/j.bbr.2015.10.059.
   Bollinger JL, 2020, NEUROPSYCHOPHARMACOL, V45, P1766, DOI 10.1038/s41386-020-0720-1.
   Chiu GS, 2012, J NEUROSCI, V32, P13945, DOI 10.1523/JNEUROSCI.0704-12.2012.
   Coryell W, 2006, J AFFECT DISORDERS, V92, P63, DOI 10.1016/j.jad.2005.12.045.
   COSTEROUSSE O, 1992, J CARDIOVASC PHARM, V20, pS10, DOI 10.1097/00005344-199200209-00004.
   Damasio A, 2013, NAT REV NEUROSCI, V14, P143, DOI 10.1038/nrn3403.
   Dantzer R, 2009, IMMUNOL ALLERGY CLIN, V29, P247, DOI 10.1016/j.iac.2009.02.002.
   Deslauriers J, 2018, BIOL PSYCHIAT, V83, P895, DOI 10.1016/j.biopsych.2017.11.019.
   DiSabato DJ, 2021, MOL PSYCHIATR, V26, P4770, DOI 10.1038/s41380-020-0788-3.
   Do-Monte FH, 2015, J NEUROSCI, V35, P3607, DOI 10.1523/JNEUROSCI.3137-14.2015.
   FANSELOW MS, 1994, PSYCHON B REV, V1, P429, DOI 10.3758/BF03210947.
   Faull OK, 2019, NEUROSCI BIOBEHAV R, V98, P135, DOI 10.1016/j.neubiorev.2018.12.020.
   Feinstein JS, 2013, NAT NEUROSCI, V16, P270, DOI 10.1038/nn.3323.
   Ferguson A.V, 2014, CIRCUMVENTRICULAR OR.
   FERGUSON AV, 1989, CAN J PHYSIOL PHARM, V67, P1097, DOI 10.1139/y89-173.
   Floyd NS, 2000, J COMP NEUROL, V422, P556, DOI 10.1002/1096-9861(20000710)422:4<556::AID-CNE6>3.0.CO;2-U.
   Furtado M, 2015, PSYCHIAT RES, V229, P37, DOI 10.1016/j.psychres.2015.05.036.
   GORMAN JM, 1994, AM J PSYCHIAT, V151, P547.
   Goshen I, 2007, PSYCHONEUROENDOCRINO, V32, P1106, DOI 10.1016/j.psyneuen.2007.09.004.
   Griebel G, 1996, PHYSIOL BEHAV, V60, P1255, DOI 10.1016/S0031-9384(96)00230-2.
   Gross CT, 2012, NAT REV NEUROSCI, V13, P651, DOI 10.1038/nrn3301.
   Harricharan S, 2016, BRAIN BEHAV, V6, DOI 10.1002/brb3.579.
   Hsu TM, 2020, P NATL ACAD SCI USA, V117, P30744, DOI 10.1073/pnas.2009233117.
   JOHNSON AK, 1993, FASEB J, V7, P678, DOI 10.1096/fasebj.7.8.8500693.
   Johnson PL, 2005, J PSYCHOPHARMACOL, V19, P327, DOI 10.1177/0269881105053281.
   Jones ME, 2018, BRAIN BEHAV IMMUN, V67, P355, DOI 10.1016/j.bbi.2017.09.016.
   Jones ME, 2015, NEUROPSYCHOPHARMACOL, V40, P1289, DOI 10.1038/npp.2014.317.
   Kellner M, 2018, J PSYCHIATR RES, V96, P260, DOI 10.1016/j.jpsychires.2017.10.019.
   Kelly MM, 2006, BEHAV RES THER, V44, P1421, DOI 10.1016/j.brat.2005.10.012.
   Khalsa SS, 2018, BIOL PSYCHIAT-COGN N, V3, P501, DOI 10.1016/j.bpsc.2017.12.004.
   Koo JW, 2009, NEUROSCI LETT, V456, P39, DOI 10.1016/j.neulet.2009.03.068.
   Kyaw H, 1998, DNA CELL BIOL, V17, P493, DOI 10.1089/dna.1998.17.493.
   Leibold NK, 2016, TRANSL PSYCHIAT, V6, DOI 10.1038/tp.2016.162.
   Likhtik E, 2008, NATURE, V454, P642, DOI 10.1038/nature07167.
   Liu XY, 2019, IMMUNITY, V50, P317, DOI {[}10.1016/j.immuni.2018.12.012, 10.1016/j.immuni.2019.02.012].
   Liu XY, 2015, J NEUROSCI, V35, P2860, DOI 10.1523/JNEUROSCI.3199-14.2015.
   LOESCHCKE HH, 1982, J PHYSIOL-LONDON, V332, P1.
   Maddox SA, 2019, NEURON, V102, P60, DOI 10.1016/j.neuron.2019.03.017.
   Magnotta VA, 2012, P NATL ACAD SCI USA, V109, P8270, DOI 10.1073/pnas.1205902109.
   Marek R, 2013, J PHYSIOL-LONDON, V591, P2381, DOI 10.1113/jphysiol.2012.248575.
   Marques DA, 2021, BRAIN RES, V1756, DOI 10.1016/j.brainres.2021.147276.
   Matsuda T, 2017, NAT NEUROSCI, V20, P230, DOI 10.1038/nn.4463.
   McKim DB, 2018, MOL PSYCHIATR, V23, P1421, DOI 10.1038/mp.2017.64.
   McKinley MJ, 2019, J NEUROENDOCRINOL, V31, DOI 10.1111/jne.12689.
   McKinley MJ, 2003, ADV ANAT EMBRYOL CEL, V172, P1.
   McKinley MJ, 1998, CLIN EXP PHARMACOL P, V25, pS61, DOI 10.1111/j.1440-1681.1998.tb02303.x.
   McMurray KMJ, 2020, NEUROSCIENCE, V429, P92, DOI 10.1016/j.neuroscience.2019.12.009.
   McMurray KMJ, 2019, NEUROSCIENCE, V396, P108, DOI 10.1016/j.neuroscience.2018.10.042.
   Michopoulos V, 2017, NEUROPSYCHOPHARMACOL, V42, P254, DOI 10.1038/npp.2016.146.
   Mimee A, 2013, PHYSIOL BEHAV, V121, P96, DOI 10.1016/j.physbeh.2013.02.012.
   MISELIS RR, 1981, BRAIN RES, V230, P1, DOI 10.1016/0006-8993(81)90388-7.
   Misslin R, 2003, NEUROPHYSIOL CLIN, V33, P55, DOI 10.1016/S0987-7053(03)00009-1.
   Muhtz C, 2012, CURR PHARM DESIGN, V18, P5608, DOI 10.2174/138161212803530817.
   NAKAMORI T, 1995, BRAIN RES, V675, P103, DOI 10.1016/0006-8993(95)00045-R.
   Olff M, 2005, PSYCHONEUROENDOCRINO, V30, P974, DOI 10.1016/j.psyneuen.2005.04.009.
   PAPP LA, 1993, AM J PSYCHIAT, V150, P1149.
   Pare D, 2004, J NEUROPHYSIOL, V92, P1, DOI 10.1152/jn.00153.2004.
   Paxinos G, 1998, MOUSE BRAIN STEREOTA.
   Pfeifer G, 2017, BIOL PSYCHOL, V126, P19, DOI 10.1016/j.biopsycho.2017.04.001.
   Pugh CR, 2001, NEUROSCI BIOBEHAV R, V25, P29, DOI 10.1016/S0149-7634(00)00048-8.
   Quadt L, 2018, ANN NY ACAD SCI, V1428, P112, DOI 10.1111/nyas.13915.
   Rassovsky Y, 2003, J ANXIETY DISORD, V17, P1, DOI 10.1016/S0887-6185(02)00181-0.
   RIZVI TA, 1991, J COMP NEUROL, V303, P121, DOI 10.1002/cne.903030111.
   Schubert I, 2018, BRAIN BEHAV IMMUN, V68, P34, DOI 10.1016/j.bbi.2017.09.013.
   Shansky RM, 2015, NEUROBIOL STRESS, V1, P60, DOI 10.1016/j.ynstr.2014.09.005.
   Sierra-Mercado D, 2011, NEUROPSYCHOPHARMACOL, V36, P529, DOI 10.1038/npp.2010.184.
   Siso S, 2010, ACTA NEUROPATHOL, V120, P689, DOI 10.1007/s00401-010-0743-5.
   Smith PM, 2010, AM J PHYSIOL-REG I, V299, pR405, DOI 10.1152/ajpregu.00103.2010.
   Strawn JR, 2018, BRAIN BEHAV IMMUN, V67, P36, DOI 10.1016/j.bbi.2017.07.014.
   Strobel C, 2015, CELL REP, V10, P1435, DOI 10.1016/j.celrep.2015.02.008.
   Sumner JA, 2020, BIOL PSYCHIAT, V87, P885, DOI 10.1016/j.biopsych.2019.11.005.
   SWANSON LW, 1986, BRAIN RES, V379, P399, DOI 10.1016/0006-8993(86)90799-7.
   Taugher RJ, 2014, J NEUROSCI, V34, P10247, DOI 10.1523/JNEUROSCI.1680-14.2014.
   Telch MJ, 2012, ARCH GEN PSYCHIAT, V69, P1161, DOI 10.1001/archgenpsychiatry.2012.8.
   Terpou BA, 2020, NEUROIMAGE-CLIN, V27, DOI 10.1016/j.nicl.2020.102345.
   van Duinen MA, 2008, J PSYCHOSOM RES, V64, P305, DOI 10.1016/j.jpsychores.2007.10.004.
   Vollmer LL, 2015, TRANSL PSYCHIAT, V5, DOI 10.1038/tp.2015.67.
   Vollmer LL, 2016, BIOL PSYCHIAT, V80, P541, DOI 10.1016/j.biopsych.2016.04.022.
   Webb EK, 2020, BIOL PSYCHIAT-COGN N, V5, P891, DOI 10.1016/j.bpsc.2020.03.004.
   Wei SG, 2013, HYPERTENSION, V62, P118, DOI 10.1161/HYPERTENSIONAHA.113.01404.
   Wemmie John A, 2011, Dialogues Clin Neurosci, V13, P475.
   Winter A, 2019, PROG NEURO-PSYCHOPH, V92, P378, DOI 10.1016/j.pnpbp.2019.02.007.
   Won E, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21186546.
   Zhu L, 2019, BRAIN BEHAV IMMUN, V81, P292, DOI 10.1016/j.bbi.2019.06.026.
   Ziemann AE, 2009, CELL, V139, P1012, DOI 10.1016/j.cell.2009.10.029.
   Zimmerman CA, 2016, NATURE, V537, P680, DOI 10.1038/nature18950.},
Number-of-Cited-References = {86},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Journal-ISO = {Brain Behav. Immun.},
Doc-Delivery-Number = {ZI0KD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000761315100002},
DA = {2022-05-17},
}

@article{ WOS:000702761400009,
Author = {Abushamma, Faris and Barqawi, Abdulkarim and Al-Jabi, Samah W. and
   Akkawi, Maha and Maree, Mosab and Zyoud, Sa'ed H.},
Title = {Global Analysis of Research Trends on Kidney Function After
   Nephron-Sparing Surgery: A Bibliometric and Visualised Study},
Journal = {CANCER MANAGEMENT AND RESEARCH},
Year = {2021},
Volume = {13},
Pages = {7479-7487},
Abstract = {Background: Nephron-sparing surgery (NSS) for small renal masses (SRMs)
   is currently the standard of care to treat renal cell carcinoma (RCC).
   The concept of partial resection of RCC has mainly been developed to
   preserve kidney function. Therefore, we have performed this study to
   explore the research activity that has been undertaken since the early
   twentyfirst century to investigate the advantages of NSS on preserving
   kidney function and preventing chronic kidney disease (CKD). Methods:
   Based on the Scopus database, this bibliometric study was used to reveal
   publication patterns in the kidney function and NSS research field. The
   data were analysed with VOSviewer version 1.6.16 software, which was
   used to create a network visualisation map that included research
   hotspots in this area. Results: A total of 449 scientific publications
   focused on renal function in NSS between 2001 and 2020. One hundred and
   seventy (38\%) of the total published articles originated from the USA.
   Journal of Urology, European Urology, and Journal of Endourology were
   the top publications detailing research in this field. Half (50\%) of
   the top 10 cited articles were published in the Journal of Urology, with
   an average citation of around 200 per article. The three most
   encountered research themes were comparative studies between partial and
   radical nephrectomy in terms of kidney function and development of CKD,
   the impact of type and duration of ischemia during resection on
   glomerular filtration rate (GFR) decline, and the effect of different
   surgical approaches on intermediate and long-term kidney function.
   Conclusion: NSS for SRMs and RCC and its impact on kidney function is a
   hot topic in the literature, and the amount of published data has
   consistently been rising since 2000. However, even though hundreds of
   documents have studied this topic from various perspectives, there is a
   compelling need to answer several questions such as the overall survival
   (OS) benefit of performing NSS in localised RCC and head-to-head
   comparison of robotic-assisted versus laparoscopic NSS in terms of warm
   ischemia time and long-term decline in GFR.},
Publisher = {DOVE MEDICAL PRESS LTD},
Address = {PO BOX 300-008, ALBANY, AUCKLAND 0752, NEW ZEALAND},
Type = {Article},
Language = {English},
Affiliation = {Abushamma, F (Corresponding Author), An Najah Natl Univ, Coll Med \& Hlth Sci, Dept Med, Nablus 44839, Palestine.
   Abushamma, Faris; Barqawi, Abdulkarim; Akkawi, Maha; Maree, Mosab, An Najah Natl Univ, Coll Med \& Hlth Sci, Dept Med, Nablus 44839, Palestine.
   Abushamma, Faris, An Najah Natl Univ Hosp, Dept Urol, Nablus 44839, Palestine.
   Barqawi, Abdulkarim, An Najah Natl Univ Hosp, Dept Gen Surg, Nablus 44839, Palestine.
   Al-Jabi, Samah W.; Zyoud, Sa'ed H., An Najah Natl Univ Hosp, Coll Med \& Hlth Sci, Dept Clin \& Community Pharm, Nablus 44839, Palestine.
   Akkawi, Maha, An Najah Natl Univ Hosp, Dept Pathol, Nablus 44839, Palestine.
   Maree, Mosab, An Najah Natl Univ Hosp, Dept Radiol, Nablus 44839, Palestine.
   Zyoud, Sa'ed H., An Najah Natl Univ Hosp, Coll Med \& Hlth Sci, Poison Control \& Drug Informat Ctr PCDIC, Nablus 44839, Palestine.
   Zyoud, Sa'ed H., An Najah Natl Univ Hosp, Clin Res Ctr, Nablus 44839, Palestine.},
DOI = {10.2147/CMAR.S324284},
ISSN = {1179-1322},
Keywords = {nephron-sparing surgery; partial nephrectomy; kidney function; renal
   insufficiency; bibliometric; Scopus},
Keywords-Plus = {RENAL-CELL CARCINOMA; PARTIAL NEPHRECTOMY; RADICAL NEPHRECTOMY; WARM
   ISCHEMIA; NATURAL-HISTORY; MORTALITY; TUMORS; PRESERVATION; OUTCOMES;
   DISEASE},
Research-Areas = {Oncology},
Web-of-Science-Categories  = {Oncology},
Author-Email = {farisabushamma@hotmail.com},
Affiliations = {An Najah National University; An Najah National University; An Najah
   National University; An Najah National University; An Najah National
   University; An Najah National University; An Najah National University;
   An Najah National University},
ResearcherID-Numbers = {Zyoud, Sa'ed/F-5968-2017
   },
ORCID-Numbers = {Zyoud, Sa'ed/0000-0002-7369-2058
   Maree, Mosab/0000-0001-8987-2400},
Cited-References = {Akpinar C, 2021, INT UROL NEPHROL, V53, P393, DOI 10.1007/s11255-020-02660-2.
   Amparore D, 2021, MINERVA UROL NEPHROL, V73, P509, DOI 10.23736/S2724-6051.21.04390-1.
   Antonelli A, 2020, EUR UROL FOCUS, V6, P344, DOI 10.1016/j.euf.2018.09.020.
   Baas J, 2020, QUANT SCI STUD, V1, P377, DOI 10.1162/qss\_a\_00019.
   Becker F, 2009, EUR UROL, V56, P625, DOI 10.1016/j.eururo.2009.07.016.
   Berg RNWV, 2016, UROL ONCOL-SEMIN ORI, V34, P24, DOI 10.1016/j.urolonc.2015.07.003.
   Breau RH, 2020, CUAJ-CAN UROL ASSOC, V14, P337, DOI 10.5489/cuaj.6436.
   Campbell S, 2017, J UROLOGY, V198, P520, DOI 10.1016/j.juro.2017.04.100.
   Capitanio U, 2020, EUR UROL ONCOL, V3, P209, DOI 10.1016/j.euo.2019.02.006.
   Chenam Avinash, 2018, Cancer Treat Res, V175, P105, DOI 10.1007/978-3-319-93339-9\_5.
   Choi JE, 2015, EUR UROL, V67, P891, DOI 10.1016/j.eururo.2014.12.028.
   Desai MM, 2005, BJU INT, V95, P377, DOI 10.1111/j.1464-410X.2005.05304.x.
   Di Lullo L, 2015, HEART FAIL REV, V20, P259, DOI 10.1007/s10741-014-9460-9.
   Faria EF, 2014, WORLD J UROL, V32, P265, DOI 10.1007/s00345-013-1115-2.
   Huang WC, 2009, J UROLOGY, V181, P55, DOI 10.1016/j.juro.2008.09.017.
   Iizuka J, 2012, INT J UROL, V19, P980, DOI 10.1111/j.1442-2042.2012.03085.x.
   Janetschek G, 2004, J UROLOGY, V171, P68, DOI 10.1097/01.ju.0000101040.13244.c4.
   Kates M, 2011, J UROLOGY, V186, P1247, DOI 10.1016/j.juro.2011.05.054.
   Kato M, 2004, J UROLOGY, V172, P863, DOI 10.1097/01.ju.0000136315.80057.99.
   Kim SP, 2012, J UROLOGY, V188, P51, DOI {[}10.1016/j.juro.2012.03.006, 10.1016/j.juro.2012.10.026].
   Lane BR, 2013, J UROLOGY, V189, P1649, DOI 10.1016/j.juro.2012.11.121.
   Lane BR, 2011, J UROLOGY, V185, P421, DOI 10.1016/j.juro.2010.09.131.
   Lane BR, 2010, J UROLOGY, V183, P473, DOI 10.1016/j.juro.2009.10.023.
   Marszalek M, 2009, EUR UROL, V55, P1171, DOI 10.1016/j.eururo.2009.01.042.
   Masson-Lecomte A, 2013, UROL ONCOL-SEMIN ORI, V31, P924, DOI 10.1016/j.urolonc.2011.08.004.
   McKiernan J, 2002, UROLOGY, V59, P816, DOI 10.1016/S0090-4295(02)01501-7.
   Miller DC, 2008, CANCER-AM CANCER SOC, V112, P511, DOI 10.1002/cncr.23218.
   Mir MC, 2015, J UROLOGY, V193, P1889, DOI 10.1016/j.juro.2015.01.093.
   Muramaki Mototsugu, 2013, Curr Urol, V6, P129, DOI 10.1159/000343526.
   Palacios DA, 2021, EUR UROL, V79, P774, DOI 10.1016/j.eururo.2021.02.035.
   Patard JJ, 2004, J UROLOGY, V171, P2181, DOI 10.1097/01.ju.0000124846.37299.5e.
   Rod X, 2016, BJU INT, V118, P691, DOI 10.1111/bju.13580.
   Scosyrev E, 2014, EUR UROL, V65, P372, DOI 10.1016/j.eururo.2013.06.044.
   Simmons MN, 2011, J UROLOGY, V186, P405, DOI 10.1016/j.juro.2011.03.154.
   Sun M, 2014, EUR UROL, V65, P235, DOI 10.1016/j.eururo.2013.03.034.
   Sweileh WM, 2020, GLOB HEALTH RES POL, V5, DOI 10.1186/s41256-020-00165-0.
   Sweileh WM, 2020, GLOBALIZATION HEALTH, V16, DOI 10.1186/s12992-020-00602-2.
   Thompson RH, 2012, UROLOGY, V79, P356, DOI 10.1016/j.urology.2011.10.031.
   van Eck NJ, 2017, SCIENTOMETRICS, V111, P1053, DOI 10.1007/s11192-017-2300-7.
   van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3.
   Van Poppel H, 2011, EUR UROL, V59, P543, DOI 10.1016/j.eururo.2010.12.013.
   Xu JH, 2020, WORLD J SURG ONCOL, V18, DOI 10.1186/s12957-020-01990-w.
   Zargar H, 2015, BJU INT, V115, P787, DOI 10.1111/bju.12825.
   Zyoud SH, 2021, WORLD J GASTROENTERO, V27, P1341, DOI 10.3748/wjg.v27.i13.1341.
   Zyoud SH, 2020, BMC INFECT DIS, V20, DOI 10.1186/s12879-020-05293-z.},
Number-of-Cited-References = {45},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Journal-ISO = {Cancer Manag. Res.},
Doc-Delivery-Number = {WA3AG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000702761400009},
OA = {Green Published, gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370974902115,
Author = {Dymczyk, Martin and Lynen, Simon and Cieslewsld, Titus and Bosse,
   Michael and Siegwart, Roland and Furgale, Paul},
Book-Group-Author = {IEEE},
Title = {The Gist of Maps - Summarizing Experience for Lifelong Localization},
DOI = {10.1109/ICRA.2015.7139575},
Booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2015},
Pages = {2767-2773},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Seattle, WA, MAY 26-30, 2015},
Abstract = {Robust, scalable place recognition is a core competency for many robotic
   applications. However, when revisiting places over and over, many
   state-of-the-art approaches exhibit reduced performance in terms of
   computation and memory complexity and in terms of accuracy. For
   successful deployment of robots over long time scales, we must develop
   algorithms that get better with repeated visits to the same environment,
   while still working within a fixed computational budget.
   This paper presents and evaluates an algorithm that alternates between
   online place recognition and offline map maintenance with the goal of
   producing the best performance with a fixed map size. At the core of the
   algorithm is the concept of a Summary Map, a reduced map representation
   that includes only the landmarks that are deemed most useful for place
   recognition. To assign landmarks to the map, we use a scoring function
   that ranks the utility of each landmark and a sampling policy that
   selects the landmarks for each place. The Summary Map can then be used
   by any descriptor-based inference method for constant-complexity online
   place recognition. We evaluate a number of scoring functions and
   sampling policies and show that it is possible to build and maintain
   maps of a constant size and that place-recognition performance improves
   over multiple visits.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dymczyk, M (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Dymczyk, Martin; Lynen, Simon; Cieslewsld, Titus; Bosse, Michael; Siegwart, Roland; Furgale, Paul, Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.},
ISSN = {1050-4729},
ISBN = {978-1-4799-6923-4},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Affiliations = {ETH Zurich},
ResearcherID-Numbers = {Siegwart, Roland/A-4495-2008},
ORCID-Numbers = {Siegwart, Roland/0000-0002-2760-7983},
Cited-References = {Agrawal M., 2008, IEEE T ROBOTICS.
   Allen R., 2014, COMP ROB VIS CRV CAN.
   Beinhofer M., 2013, ROBOTICS AUTONOMOUS.
   Carlevaris-Bianco N., 2014, IEEE T ROBOTICS.
   Churchill Winston, 2013, INT J ROBOTICS RES I.
   Cieslewski T., 2015, ROB AUT ICRA 2015 IE.
   Cummins M., 2008, INT J ROBOTICS RES.
   Furgale P., 2010, J FIELD ROBOTICS.
   Huang G., 2013, MOB ROB ECMR EUR C.
   Jegou H., COMP VIS ECCV 2008 I.
   Johannsson H., 2013, ROB AUT ICRA IEEE IN.
   Johns E., 2013, ROB AUT ICRA IEEE IN.
   Konolige K., 2010, INT J ROBOTICS RES.
   Kretzschmar H., 2012, INT J ROBOTICS RES.
   Lee J., GOOGLE PROJECT TANGO.
   Lynen S., 2014, 3DV.
   Maddern W., 2012, ROBOTICS SCI SYSTEMS.
   Maddern W., 2012, INT ROB SYST IROS IE.
   Milford M., 2012, ROB AUT ICRA IEEE IN.
   Muehlfellner P., 2013, IEEE INT VEH S IV.
   Muhlfellner P., 2014, SUMMARY MAPS L UNPUB.
   Naseer Tayyab, 2014, AAAI.
   Paul R., 2011, ROB AUT ICRA IEEE IN.
   Pepperell E., 2014, ROB AUT ICRA IEEE IN.
   Sattler T., 2011, COMP VIS ICCV IEEE I.
   Sivic J., COMP VIS ICCV 2003 I.
   Vitus M.P., 2010, ROBOTICS SCI SYSTEMS.},
Number-of-Cited-References = {27},
Times-Cited = {29},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BE3MR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370974902115},
DA = {2022-05-17},
}

@article{ WOS:000728139000013,
Author = {Kilic, Cagri and Martinez, Jr., Bernardo R. and Tatsch, Christopher A.
   and Beard, Jared and Strader, Jared and Das, Shounak and Ross, Derek and
   Gu, Yu and Pereira, Guilherme A. S. and Gross, Jason N.},
Title = {NASA Space Robotics Challenge 2 Qualification Round: An Approach to
   Autonomous Lunar Rover Operations},
Journal = {IEEE AEROSPACE AND ELECTRONIC SYSTEMS MAGAZINE},
Year = {2021},
Volume = {36},
Number = {12},
Pages = {24-41},
Month = {DEC},
Abstract = {Plans for establishing a long-term human presence on the Moon will
   require substantial increases in robot autonomy and multirobot
   coordination to support establishing a lunar outpost. To achieve these
   objectives, algorithm design choices for the software developments need
   to be tested and validated for expected scenarios such as autonomous in
   situ resource utilization, localization in challenging environments, and
   multirobot coordination. However, real-world experiments are extremely
   challenging and limited for extraterrestrial environment. Also,
   realistic simulation demonstrations in these environments are still rare
   and demanded for initial algorithm testing capabilities. To help some of
   these needs, the NASA Centennial Challenges program established the
   Space Robotics Challenge Phase 2 (SRC2), which consist of virtual
   robotic systems in a realistic lunar simulation environment, where a
   group of mobile robots were tasked with reporting volatile locations
   within a global map, excavating and transporting these resources, and
   detecting and localizing a target of interest. The main goal of this
   article is to share our team's experiences on the design tradeoffs to
   perform autonomous robotic operations in a virtual lunar environment and
   to share strategies to complete the mission requirements posed by NASA
   SRC2 competition during the qualification round. Of the 114 teams that
   registered for participation in the NASA SRC2, team Mountaineers
   finished as one of only six teams to receive the top qualification round
   prize.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Gross, JN (Corresponding Author), West Virginia Univ, Dept Mech \& Aerosp Engn, Morgantown, WV 26506 USA.
   Kilic, Cagri; Martinez, Bernardo R., Jr.; Tatsch, Christopher A.; Beard, Jared; Strader, Jared; Das, Shounak; Ross, Derek; Gu, Yu; Pereira, Guilherme A. S.; Gross, Jason N., West Virginia Univ, Dept Mech \& Aerosp Engn, Morgantown, WV 26506 USA.},
DOI = {10.1109/MAES.2021.3115897},
ISSN = {0885-8985},
EISSN = {1557-959X},
Keywords = {NASA; Space vehicles; Robot kinematics; Moon; Software algorithms;
   Multi-robot systems; Resource management},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Aerospace; Engineering, Electrical \& Electronic},
Author-Email = {Jason.Gross@mail.wvu.edu},
Affiliations = {West Virginia University},
ResearcherID-Numbers = {Gu, Yu/C-4424-2013
   },
ORCID-Numbers = {Gross, Jason/0000-0002-7771-2757
   Kilic, Cagri/0000-0002-8117-3602
   Martinez Rocamora Junior, Bernardo/0000-0001-8048-0523
   Pereira, Guilherme/0000-0003-0739-9934
   Gu, Yu/0000-0003-3165-3269
   Beard, Jared/0000-0002-4184-1178
   Das, Shounak/0000-0002-5481-3969},
Funding-Acknowledgement = {B. M. Statler College of Engineering and Mineral Resources at West
   Virginia University; Statler College of Engineering of West Virginia
   University; Mineral Resources of West Virginia University},
Funding-Text = {The authors would like to thank N. Ohi, C. Yang, M. de Petrillo, R.
   Lima, and T. Smith for their contributions on the qualification round of
   the competition, and A. Baheri for helping review this article. Team
   Mountaineers would like to thank B. M. Statler College of Engineering
   and Mineral Resources at West Virginia University for sponsoring our
   team in the Space Robotics Challenge Phase 2. This work was supported in
   part by the Statler College of Engineering and in part by the Mineral
   Resources of West Virginia University.},
Cited-References = {Bertram, 2020, ARXIV200603534.
   Brock O, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P341, DOI 10.1109/ROBOT.1999.770002.
   Colaprete A., 2017, P 48 LUN PLAN SCI C, P20.
   Filotheou A, 2020, J INTELL ROBOT SYST, V98, P567, DOI 10.1007/s10846-019-01086-y.
   Fox D, 1997, IEEE ROBOT AUTOM MAG, V4, P23, DOI 10.1109/100.580977.
   Gu Y, 2018, IEEE ROBOT AUTOM MAG, V25, P93, DOI 10.1109/MRA.2018.2803174.
   Hirschmuller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56.
   Kilic C., 2020, ARXIV200309968.
   Kilic C, 2019, IEEE INT C INT ROBOT, P552, DOI 10.1109/IROS40897.2019.8967634.
   Konolige K., 2008, P ICRA WORKSH PATH P.
   Kumar V, PLANAR ROBOT KINEMAT.
   Larson, 2012, J AERO ENG, P457.
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0\_2.
   Marder-Eppstein, 2012, MOVE BASE.
   Mendell WW, 2005, ACTA ASTRONAUT, V57, P676, DOI 10.1016/j.actaastro.2005.03.024.
   NASA, LUN SURF INN IN.
   NASA Centennial Challenges Program (CCP), 2021, SPAC ROB CHALL PHAS.
   Open Robotics, DOCUMENTATION.
   Open Source Robotics. Foundation, TUTORIALS.
   QUINLAN S, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pB802.
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690.
   Reynolds D.A., 2009, ENCY BIOM, P659, DOI 10.1007/978-0-387-73003-5\_196.
   Rosmann C, 2017, ROBOT AUTON SYST, V88, P142, DOI 10.1016/j.robot.2016.11.007.
   Simonyan K, 2014, C TRACK P.
   Smits Maaike L, 2020, Psychol Med, P1, DOI 10.1017/S0033291720004018.
   Stramigioli S., 2011, P 11 ESA WORKSH ADV.
   The Artemis Plan, 2020, NASAS LUNAR EXPLORAT.},
Number-of-Cited-References = {28},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {2},
Journal-ISO = {IEEE Aerosp. Electron. Syst. Mag.},
Doc-Delivery-Number = {XL4UB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000728139000013},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000523478400004,
Author = {Yin, Huan and Wang, Yue and Ding, Xiaqing and Tang, Li and Huang,
   Shoudong and Xiong, Rong},
Title = {3D LiDAR-Based Global Localization Using Siamese Neural Network},
Journal = {IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS},
Year = {2020},
Volume = {21},
Number = {4},
Pages = {1380-1392},
Month = {APR},
Abstract = {Global localization in 3D point clouds is a challenging task for mobile
   vehicles in outdoor scenarios, which requires the vehicle to localize
   itself correctly in a given map without prior knowledge of its pose.
   This is a critical component of autonomous vehicles or robots on the
   road for handling localization failures. In this paper, based on reduced
   dimension scan representations learned from neural networks, a solution
   to global localization is proposed by achieving place recognition first
   and then metric pose estimation in the global prior map. Specifically,
   we present a semi-handcrafted feature learning method for 3D Light
   detection and ranging (LiDAR) point clouds using artificial statistics
   and siamese network, which transforms the place recognition problem into
   a similarity modeling problem. Additionally, the sensor data using
   dimension reduced representations require less storage space and make
   the searching easier. With the learned representations by networks and
   the global poses, a prior map is built and used in the localization
   framework. In the localization step, position only observations obtained
   by place recognition are used in a particle filter algorithm to achieve
   precise pose estimation. To demonstrate the effectiveness of our place
   recognition and localization approach, KITTI benchmark and our
   multi-session datasets are employed for comparison with other
   geometric-based algorithms. The results show that our system can achieve
   both high accuracy and efficiency for long-term autonomy.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou 310058, Peoples R China.
   Wang, Y (Corresponding Author), Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310058, Peoples R China.
   Yin, Huan; Wang, Yue; Ding, Xiaqing; Tang, Li; Xiong, Rong, Zhejiang Univ, State Key Lab Ind Control \& Technol, Hangzhou 310058, Peoples R China.
   Yin, Huan; Wang, Yue; Ding, Xiaqing; Tang, Li; Xiong, Rong, Zhejiang Univ, Inst Cyber Syst \& Control, Hangzhou 310058, Peoples R China.
   Yin, Huan; Wang, Yue; Ding, Xiaqing; Tang, Li; Huang, Shoudong; Xiong, Rong, Zhejiang Univ, Joint Ctr Robot Res, Hangzhou 310058, Peoples R China.
   Yin, Huan; Wang, Yue; Ding, Xiaqing; Tang, Li; Xiong, Rong, Univ Technol Sydney, Sydney, NSW 2007, Australia.
   Huang, Shoudong, Univ Technol Sydney, CAS, Sydney, NSW 2007, Australia.},
DOI = {10.1109/TITS.2019.2905046},
ISSN = {1524-9050},
EISSN = {1558-0016},
Keywords = {Three-dimensional displays; Laser radar; Pose estimation; Neural
   networks; Task analysis; Robot sensing systems; Measurement; Mobile
   vehicles; place recognition; siamese network; global localization},
Keywords-Plus = {OBJECT RECOGNITION; ICP},
Research-Areas = {Engineering; Transportation},
Web-of-Science-Categories  = {Engineering, Civil; Engineering, Electrical \& Electronic;
   Transportation Science \& Technology},
Author-Email = {wangyue@iipc.zju.edu.cn},
Affiliations = {Zhejiang University; Zhejiang University; Zhejiang University;
   University of Technology Sydney; University of Technology Sydney},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020
   },
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202
   Huang, Shoudong/0000-0002-6124-4178},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2017YFB1300400]; National Nature Science Foundation of China
   {[}U1609210]},
Funding-Text = {This work was supported in part by the National Key Research and
   Development Program of China under Grant 2017YFB1300400 and in part by
   the National Nature Science Foundation of China Grant U1609210. The
   Associate Editor for this paper was L. M. Bergasa. (Corresponding
   author: Yue Wang.)},
Cited-References = {Anguelova M., 2004, THESIS.
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558.
   Bosse M, 2013, IEEE INT CONF ROBOT, P2677, DOI 10.1109/ICRA.2013.6630945.
   Bromley  J., 1994, ADV NEURAL INFORM PR, P737.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Dube Renaud, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5266, DOI 10.1109/ICRA.2017.7989618.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Fernandez-Moral E, 2013, IEEE INT CONF ROBOT, P2719, DOI 10.1109/ICRA.2013.6630951.
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Granstrom K, 2011, INT J ROBOT RES, V30, P1728, DOI 10.1177/0278364911405086.
   Hadsell R., 2006, 2006 IEEE COMP VIS P, V2, P1735, DOI DOI 10.1109/CVPR.2006.100.
   Hata A. Y., 2017, IEEE T INTELL TRANSP, V19, P2839.
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889.
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955.
   Linegar C, 2015, IEEE INT CONF ROBOT, P90, DOI 10.1109/ICRA.2015.7138985.
   Magnusson Martin, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P23, DOI 10.1109/ROBOT.2009.5152712.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Naseer T, 2018, IEEE T ROBOT, V34, P289, DOI 10.1109/TRO.2017.2788045.
   Naseer T, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564.
   Pomerleau F., 2015, FDN TRENDS ROBOT, V4, P1, DOI DOI 10.1561/2300000035.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Rohling T, 2015, IEEE INT C INT ROBOT, P736, DOI 10.1109/IROS.2015.7353454.
   Rozsa Z, 2018, IEEE T INTELL TRANSP, V19, P2708, DOI 10.1109/TITS.2018.2790264.
   Rusu R.B., 2009, IEEE INT C ROB AUT I, P3212, DOI DOI 10.1109/R0B0T.2009.5152473.
   Steder B, 2011, IEEE INT C INT ROBOT, P1249, DOI 10.1109/IROS.2011.6048325.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Tang L, 2019, AUTON ROBOT, V43, P197, DOI 10.1007/s10514-018-9724-7.
   Tombari F, 2011, IEEE IMAGE PROC, P809, DOI 10.1109/ICIP.2011.6116679.
   Wohlkinger W., 2011, 2011 IEEE International Conference on Robotics and Biomimetics (ROBIO), P2987, DOI 10.1109/ROBIO.2011.6181760.
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405.
   Yin HX, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P721, DOI 10.1109/ICCT.2018.8599957.},
Number-of-Cited-References = {38},
Times-Cited = {22},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {34},
Journal-ISO = {IEEE Trans. Intell. Transp. Syst.},
Doc-Delivery-Number = {KZ7ZL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000523478400004},
DA = {2022-05-17},
}

@article{ WOS:000364735800006,
Author = {Hitz, Gregory and Pomerleau, Francois and Colas, Francis and Siegwart,
   Roland},
Title = {Relaxing the planar assumption: 3D state estimation for an autonomous
   surface vessel},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2015},
Volume = {34},
Number = {13, SI},
Pages = {1604-1621},
Month = {NOV},
Note = {14th International Symposium on Experimental Robotics (ISER), MOROCCO,
   JUN 15-18, 2014},
Abstract = {Autonomous Surface Vessels (ASVs) are increasingly being proposed as
   tools to automate environmental data collection, bathymetric mapping and
   shoreline monitoring. For many applications it can be assumed that the
   boat operates on a 2D plane. However, with the involvement of
   exteroceptive sensors like cameras or laser rangefinders, knowing the 3D
   pose of the boat becomes critical. In this paper, we formulate three
   different algorithms based on 3D extended Kalman filter state estimation
   for ASV localization. We compare them using field testing results with
   ground truth measurements, and demonstrate that the best performance is
   achieved with a model-based solution in combination with a complementary
   filter for attitude estimation. Furthermore, we present a parameter
   identification methodology and show that it also yields accurate results
   when used with inexpensive sensors. Finally, we present a long-term
   series (i.e. over a full year) of shoreline monitoring data sets and
   discuss the need for map maintenance routines based on a variant of the
   Iterative Closest Point algorithm.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Hitz, G (Corresponding Author), ETH, Autonomous Syst Lab, LEE Leonhardstr 21, CH-8092 Zurich, Switzerland.
   Hitz, Gregory; Pomerleau, Francois; Colas, Francis; Siegwart, Roland, ETH, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Pomerleau, Francois, Univ Toronto, Autonomous Space Robot Lab, Toronto, ON M5S 1A1, Canada.
   Colas, Francis, Inria, F-54600 Villers Les Nancy, France.
   Colas, Francis, CNRS, Loria, UMR, F-54500 Vandoeuvre Les Nancy, France.
   Colas, Francis, Univ Lorraine, Loria, France.},
DOI = {10.1177/0278364915583680},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Localization; marine robotics; field and service robotics; field robots;
   mapping},
Keywords-Plus = {EXPLORATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {gregory.hitz@mavt.ethz.ch},
Affiliations = {ETH Zurich; University of Toronto; Inria; Centre National de la
   Recherche Scientifique (CNRS); Universite de Lorraine; Universite de
   Lorraine},
ResearcherID-Numbers = {Pomerleau, François/N-7629-2017
   Siegwart, Roland/A-4495-2008},
ORCID-Numbers = {Pomerleau, François/0000-0003-1288-2744
   Siegwart, Roland/0000-0002-2760-7983},
Funding-Acknowledgement = {Swiss National Science Fund {[}CR22I2-130023]; EU FP7 projects NIFTi
   {[}ICT-247870]; Tradr {[}ICT-609763]; Natural Sciences and Engineering
   Research Council of Canada (NSERC); EUROPA2 project {[}FP7-610603]},
Funding-Text = {This work was funded by the Swiss National Science Fund (grant number
   CR22I2-130023) and the EU FP7 projects NIFTi (grant number ICT-247870)
   and Tradr (grant number ICT-609763). This research was also partially
   funded by the Natural Sciences and Engineering Research Council of
   Canada (NSERC). We also thank M-E Garneau for her thorough review and
   the EUROPA2 project (grant number FP7-610603) for the use of the
   Velodyne.},
Cited-References = {Almeida J, 2010, INT J ROBUST NONLIN, V20, P1549, DOI 10.1002/rnc.1526.
   Amiri-Simkooei AR, 2007, J GEOPHYS RES-SOL EA, V112, DOI 10.1029/2006JB004913.
   Bibuli M, 2009, J FIELD ROBOT, V26, P669, DOI 10.1002/rob.20303.
   Bosse M., 2009, 2009 IEEE INT C ROBO, P4312, DOI {[}10.1109/ROBOT.2009.5152851, DOI 10.1109/ROBOT.2009.5152851].
   Brown J, 2011, INTEL SERV ROBOT, V4, P233, DOI 10.1007/s11370-011-0095-6.
   Chen VL, 2008, IEEE INT CONF ROBOT, P629, DOI 10.1109/ROBOT.2008.4543276.
   Dhariwal A, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1708.
   Dunbabin M, 2009, 11 AUSTR C ROB AUT A.
   Feemster MG, 2011, J FIELD ROBOT, V28, P80, DOI 10.1002/rob.20369.
   Fossen T.I, 2011, HDB MARINE CRAFT HYD, V1st.
   Griffith S, 2014, 14 INT S EXP ROB ISE.
   Grinham A, 2011, ATMOS ENVIRON, V45, P7166, DOI 10.1016/j.atmosenv.2011.09.011.
   Hansen N, 2006, STUD FUZZ SOFT COMP, V192, P75.
   Hitz G, 2014, 14 INT S EXP ROB ISE.
   Hitz G, 2014, IEEE INT CONF ROBOT, P2658, DOI 10.1109/ICRA.2014.6907240.
   Hitz G, 2012, IEEE ROBOT AUTOM MAG, V19, P62, DOI 10.1109/MRA.2011.2181771.
   Hollinger GA, 2014, INT J ROBOT RES, V33, P1271, DOI 10.1177/0278364914533443.
   Kubelka V, 2015, J FIELD ROBOT, V32, P447, DOI 10.1002/rob.21535.
   Leutenegger S, 2012, IEEE INT CONF ROBOT, P612, DOI 10.1109/ICRA.2012.6225061.
   Mahony R, 2008, IEEE T AUTOMAT CONTR, V53, P1203, DOI 10.1109/TAC.2008.923738.
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184.
   Michael N, 2012, J FIELD ROBOT, V29, P832, DOI 10.1002/rob.21436.
   Miskovic N, 2011, J FIELD ROBOT, V28, P101, DOI 10.1002/rob.20374.
   Neal M, 2012, J FIELD ROBOT, V29, P880, DOI 10.1002/rob.21420.
   Pomerleau F, 2014, IEEE INT CONF ROBOT, P3712, DOI 10.1109/ICRA.2014.6907397.
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2.
   Scherer S, 2012, AUTON ROBOT, V33, P189, DOI 10.1007/s10514-012-9293-0.
   Subramanian A, 2006, OCEANS 2006, P1, DOI {[}10.1109/OCEANS.2006.306906, DOI 10.1109/OCEANS.2006.306906].
   Trawny N, 2005, 612 U MINN.
   Weiss S, 2013, J FIELD ROBOT, V30, P803, DOI 10.1002/rob.21466.},
Number-of-Cited-References = {30},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {21},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {CW1FU},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000364735800006},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370073807021,
Author = {Song, Zhuoyuan and Mohseni, Kamran},
Book-Group-Author = {IEEE},
Title = {Towards background flow based AUV localization},
DOI = {10.1109/CDC.2014.7040480},
Booktitle = {2014 IEEE 53RD ANNUAL CONFERENCE ON DECISION AND CONTROL (CDC)},
Series = {IEEE Conference on Decision and Control},
Year = {2014},
Pages = {6945-6950},
Note = {53rd IEEE Annual Conference on Decision and Control (CDC), Los Angeles,
   CA, DEC 15-17, 2014},
Abstract = {Underwater localization faces many constrains and long-term persistent
   global localization for autonomous underwater vehicles (AUVs) is very
   difficult. In this paper, we propose a novel AUV localization method
   taking advantage of the recent progress in ocean general circulation
   models (OGCMs). During navigation, the AUV performs intermittent local
   background flow velocity measurements or estimates using on-board
   sensors. A series of preloaded flow velocity forecast maps generated by
   OGCMs are referred by a particle filter in updating particle weights
   based on resemblance between forecasts and local estimation. A rigorous
   derivation of the problem in probability theory is presented to reveal
   the recursive structure of the target distribution function. Simulations
   in a simple double-gyre velocity field exhibit satisfactory converging
   localization error. Further simulations in a flow field with local flow
   fluctuations that are not resolved by OGCMs show similar convergent
   localization error with a slower converging rate. As a first step
   towards a new set of underwater localization methods, this work presents
   promising results and reveals the possibility of realizing converging
   global underwater localization through partial utilization of the
   background flow information that is easily accessible.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Song, ZY (Corresponding Author), Univ Florida, Dept Mech \& Aerosp Engn, Gainesville, FL 32611 USA.
   Song, Zhuoyuan; Mohseni, Kamran, Univ Florida, Dept Mech \& Aerosp Engn, Gainesville, FL 32611 USA.
   Song, Zhuoyuan; Mohseni, Kamran, Univ Florida, Inst Networked Autonomous Syst, Gainesville, FL 32611 USA.
   Mohseni, Kamran, Univ Florida, Dept Elect \& Comp Engn, Gainesville, FL 32611 USA.},
ISSN = {0743-1546},
ISBN = {978-1-4673-6090-6},
Keywords-Plus = {MODEL; GYRE},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {nick.songzy@ufl.edu
   mohseni@ufl.edu},
Affiliations = {State University System of Florida; University of Florida; State
   University System of Florida; University of Florida; State University
   System of Florida; University of Florida},
ResearcherID-Numbers = {Song, Zhuoyuan/A-2717-2019},
ORCID-Numbers = {Song, Zhuoyuan/0000-0002-7442-8435},
Cited-References = {AKASHI H, 1977, AUTOMATICA, V13, P429, DOI 10.1016/0005-1098(77)90028-0.
   ARRICHIELLO F, 2012, ROB AUT ICRA 2012 IE, P5307.
   Bahr A, 2009, INT J ROBOT RES, V28, P714, DOI 10.1177/0278364908100561.
   Caiti A, 2005, IEEE J OCEANIC ENG, V30, P140, DOI 10.1109/JOE.2004.841432.
   Chagnaud BP, 2008, J NEUROSCI, V28, P4479, DOI 10.1523/JNEUROSCI.4959-07.2008.
   Chassignet EP, 2009, OCEANOGRAPHY, V22, P64, DOI 10.5670/oceanog.2009.39.
   Donald S, 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616.
   Donovan GT, 2012, IEEE J OCEANIC ENG, V37, P431, DOI 10.1109/JOE.2012.2190810.
   Douc R, 2005, ISPA 2005: Proceedings of the 4th International Symposium on Image and Signal Processing and Analysis, P64, DOI 10.1109/ISPA.2005.195385.
   Ee H. V., 2006, P 1 ACM INT WORKSH U, P33, DOI DOI 10.1145/1161039.1161047.
   Eichhorn M., 2013, ROBOTICS AU IN PRESS.
   Fallon MF, 2010, INT J ROBOT RES, V29, P1461, DOI 10.1177/0278364910380760.
   Fong DA, 2006, LIMNOL OCEANOGR-METH, V4, P58, DOI 10.4319/lom.2006.4.58.
   Garau B., 2009, J MARITIME RES, V6, P5.
   Griffa A, 1996, STOCHASTIC MODELLING, V39, P113, DOI DOI 10.1007/978-1-4612-2430-3\_.
   Gutmann JS, 2012, IEEE INT C INT ROBOT, P3144, DOI 10.1109/IROS.2012.6386062.
   Gutmann JS, 2012, IEEE T ROBOT, V28, P650, DOI 10.1109/TRO.2011.2177691.
   HAMMERSLEY JM, 1954, J ROY STAT SOC B, V16, P23.
   Handschin J. E., 1969, International Journal of Control, V9, P547, DOI 10.1080/00207176908905777.
   Haza AC, 2007, OCEAN MODEL, V17, P68, DOI 10.1016/j.ocemod.2006.10.004.
   HSIEH MA, 2012, ROB AUT ICRA IEEE IN, P4242.
   Kitagawa G, 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750.
   Lipinski D., 2014, AIAA SCITECH 2014.
   Lipinski D, 2011, IEEE INT CONF ROBOT.
   Liu Jun S., 2001, SPRINGER SERIES STAT.
   Lolla T, 2012, IEEE INT CONF ROBOT, P166, DOI 10.1109/ICRA.2012.6225364.
   Mallory K, 2013, NONLINEAR PROC GEOPH, V20, P657, DOI 10.5194/npg-20-657-2013.
   Mehra A, 2010, TERR ATMOS OCEAN SCI, V21, P211, DOI 10.3319/TAO.2009.04.16.01(IWNOP).
   Newman PM, 2005, SPRINGER TRAC ADV RO, V15, P409.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Ramp SR, 2009, DEEP-SEA RES PT II, V56, P68, DOI 10.1016/j.dsr2.2008.08.013.
   Shen J, 1999, J COMPUT PHYS, V155, P387, DOI 10.1006/jcph.1999.6344.
   Song ZY, 2013, IEEE INT C INT ROBOT, P3356, DOI 10.1109/IROS.2013.6696834.
   SONG ZY, 2014, AM CONTR C ACC 2014, P4721.
   Tan HP, 2011, OCEAN ENG, V38, P1663, DOI 10.1016/j.oceaneng.2011.07.017.
   THOMSON DJ, 1986, Q J ROY METEOR SOC, V112, P511, DOI 10.1002/qj.49711247213.
   Tokdar ST, 2010, WILEY INTERDISCIP RE, V2, P54, DOI 10.1002/wics.56.
   Xu Y., 2013, IEEE-ASME T MECH, P1, DOI DOI 10.1186/1475-2859-12-90.},
Number-of-Cited-References = {38},
Times-Cited = {8},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BE2TY},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370073807021},
DA = {2022-05-17},
}

@article{ WOS:000656239300001,
Author = {Yin, Huan and Xu, Xuecheng and Wang, Yue and Xiong, Rong},
Title = {Radar-to-Lidar: Heterogeneous Place Recognition via Joint Learning},
Journal = {FRONTIERS IN ROBOTICS AND AI},
Year = {2021},
Pages = {661199},
Volume = {8},
Month = {MAY 17},
Abstract = {Place recognition is critical for both offline mapping and online
   localization. However, current single-sensor based place recognition
   still remains challenging in adverse conditions. In this paper, a
   heterogeneous measurement based framework is proposed for long-term
   place recognition, which retrieves the query radar scans from the
   existing lidar (Light Detection and Ranging) maps. To achieve this, a
   deep neural network is built with joint training in the learning stage,
   and then in the testing stage, shared embeddings of radar and lidar are
   extracted for heterogeneous place recognition. To validate the
   effectiveness of the proposed method, we conducted tests and
   generalization experiments on the multi-session public datasets and
   compared them to other competitive methods. The experimental results
   indicate that our model is able to perform multiple place recognitions:
   lidar-to-lidar (L2L), radar-to-radar (R2R), and radar-to-lidar (R2L),
   while the learned model is trained only once. We also release the source
   code publicly:
   https://github.com/ZJUYH/radar-to-lidar-place-recognition.},
Publisher = {FRONTIERS MEDIA SA},
Address = {AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, Inst Cyber Syst \& Control, Coll Control Sci \& Engn, Hangzhou, Peoples R China.
   Yin, Huan; Xu, Xuecheng; Wang, Yue; Xiong, Rong, Zhejiang Univ, Inst Cyber Syst \& Control, Coll Control Sci \& Engn, Hangzhou, Peoples R China.},
DOI = {10.3389/frobt.2021.661199},
Article-Number = {661199},
ISSN = {2296-9144},
Keywords = {radar; lidar; heterogeneous measurements; place recognition; deep neural
   network; mobile robot},
Keywords-Plus = {SCAN CONTEXT; LOCALIZATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {ywang24@zju.edu.cn},
Affiliations = {Zhejiang University},
ResearcherID-Numbers = {Yin, Huan/ABC-9483-2020},
ORCID-Numbers = {Yin, Huan/0000-0002-0872-8202},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2020YFB1313300]},
Funding-Text = {This work was supported by the National Key R\&D Program of China under
   grant 2020YFB1313300.},
Cited-References = {Adolfsson D., 2019, 2019 EUR C MOB ROB E, P1.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Barnes D., 2020, C ROB LEARN, P303.
   Barnes D, 2020, IEEE INT CONF ROBOT, P6433, DOI 10.1109/ICRA40945.2020.9196884.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Bosse M, 2013, IEEE INT CONF ROBOT, P2677, DOI 10.1109/ICRA.2013.6630945.
   Carballo A., 2020, 2020 IEEE INT VEH S.
   Cattaneo D, 2020, IEEE INT CONF ROBOT, P4365, DOI 10.1109/ICRA40945.2020.9196859.
   Cen SH, 2018, IEEE INT CONF ROBOT, P6045, DOI 10.1109/ICRA.2018.8460687.
   Chen XYL, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Ding XQ, 2020, IEEE T INTELL TRANSP, V21, P4646, DOI 10.1109/TITS.2019.2942760.
   Dube R, 2020, INT J ROBOT RES, V39, P339, DOI 10.1177/0278364919863090.
   Elhousni M, 2020, IEEE INT VEH SYM, P1879, DOI 10.1109/IV47402.2020.9304812.
   Falliat D, 2007, IEEE INT CONF ROBOT, P3921.
   Feng MD, 2019, IEEE INT CONF ROBOT, P4790, DOI 10.1109/ICRA.2019.8794415.
   Gadd Matthew, 2020, 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), P270, DOI 10.1109/PLANS46316.2020.9109951.
   Granstrom K, 2011, INT J ROBOT RES, V30, P1728, DOI 10.1177/0278364911405086.
   Groft E., 2012, US Patent, Patent No. {[}8,279,107, 8279107].
   He L, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P231, DOI 10.1109/IROS.2016.7759060.
   Hong Z., 2020, 2020 IEEE RSJ INT C.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Kim G., 2020, IEEE INT C ROB AUT I.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Kingma D.P., 2015, P 3 INT C LEARN REPR.
   Latif Y, 2018, IEEE INT CONF ROBOT, P2349, DOI 10.1109/ICRA.2018.8461081.
   Le Gentil C., 2020, 2020 IEEE RSJ INT C.
   Li L, 2017, JOINT URB REMOTE SEN.
   Liu Z, 2019, IEEE I CONF COMP VIS, P2831, DOI 10.1109/ICCV.2019.00292.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Paszke A, 2019, ADV NEUR IN, V32.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Saftescu S, 2020, IEEE INT CONF ROBOT, P4358, DOI 10.1109/ICRA40945.2020.9196682.
   Sun L, 2020, IEEE INT CONF ROBOT, P4386, DOI 10.1109/ICRA40945.2020.9196708.
   Tang TYQ, 2020, IEEE ROBOT AUTOM LET, V5, P1087, DOI 10.1109/LRA.2020.2965907.
   Uy MA, 2018, PROC CVPR IEEE, P4470, DOI 10.1109/CVPR.2018.00470.
   Wang Y, 2020, IEEE INT C INT ROBOT, P5769, DOI 10.1109/IROS45743.2020.9341010.
   Xie SR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102870.
   Xu XC, 2021, IEEE ROBOT AUTOM LET, V6, P2791, DOI 10.1109/LRA.2021.3060741.
   Yin H., 2020, 2020 IEEE INT C REAL.
   Yin H, 2021, IEEE T INTELL TRANSP, DOI 10.1109/TITS.2021.3061165.
   Yin H, 2020, IEEE T INTELL TRANSP, V21, P1380, DOI 10.1109/TITS.2019.2905046.
   Yin H, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), P481, DOI 10.1109/ROBIO.2017.8324463.
   Zhang, 2020, QUANTIFYING HUMAN MO.
   Zhang XW, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2020.107760.},
Number-of-Cited-References = {48},
Times-Cited = {1},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {14},
Journal-ISO = {Front. Robot. AI},
Doc-Delivery-Number = {SK5EU},
Web-of-Science-Index = {Emerging Sources Citation Index (ESCI)},
Unique-ID = {WOS:000656239300001},
OA = {Green Submitted, gold, Green Published},
DA = {2022-05-17},
}

@article{ WOS:000492207000006,
Author = {Nobre, Fernando and Heckman, Christoffer},
Title = {Learning to calibrate: Reinforcement learning for guided calibration of
   visual-inertial rigs},
Journal = {INTERNATIONAL JOURNAL OF ROBOTICS RESEARCH},
Year = {2019},
Volume = {38},
Number = {12-13, SI},
Pages = {1388-1402},
Month = {OCT},
Abstract = {We present a new approach to assisted intrinsic and extrinsic
   calibration with an observability-aware visual-inertial calibration
   system that guides the user through the calibration procedure by
   suggesting easy-to-perform motions that render the calibration
   parameters observable. This is done by identifying which subset of the
   parameter space is rendered observable with a rank-revealing
   decomposition of the Fisher information matrix, modeling calibration as
   a Markov decision process and using reinforcement learning to establish
   which discrete sequence of motions optimizes for the regression of the
   desired parameters. The goal is to address the assumption common to most
   calibration solutions: that sufficiently informative motions are
   provided by the operator. We do not make use of a process model and
   instead leverage an experience-based approach that is broadly applicable
   to any platform in the context of simultaneous localization and mapping.
   This is a step in the direction of long-term autonomy and
   ``power-on-and-go{''} robotic systems, making repeatable and reliable
   calibration accessible to the non-expert operator.},
Publisher = {SAGE PUBLICATIONS LTD},
Address = {1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND},
Type = {Article},
Language = {English},
Affiliation = {Heckman, C (Corresponding Author), Univ Colorado, Autonomous Robot \& Percept Grp, 1111 Engn Dr,UCB 430,ECOT 717, Boulder, CO 80309 USA.
   Nobre, Fernando; Heckman, Christoffer, Univ Colorado, Autonomous Robot \& Percept Grp, 1111 Engn Dr,UCB 430,ECOT 717, Boulder, CO 80309 USA.},
DOI = {10.1177/0278364919844824},
ISSN = {0278-3649},
EISSN = {1741-3176},
Keywords = {Calibration; reinforcement learning; observability; extrinsic; intrinsic},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {christoffer.heckman@colorado.edu},
Affiliations = {University of Colorado System; University of Colorado Boulder},
ORCID-Numbers = {HECKMAN, CHRISTOFFER/0000-0002-9651-6866},
Cited-References = {Agarwal S, 2018, CERES SOLVER.
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240.
   Brookshire J., 2013, ROBOTICS SCI SYSTEMS, VVIII, P504.
   Chatterjee K, 2015, IEEE INT CONF ROBOT, P325, DOI 10.1109/ICRA.2015.7139019.
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Francois-Lavet Vincent, 2015, NIPS 2015 WORKSH DEE.
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514.
   Gibbs B.P., 2011, ADV KALMAN FILTERING.
   Golub G. H., 2012, MATRIX COMPUTATIONS, V3.
   Grady DK, 2015, IEEE T ROBOT, V31, P948, DOI 10.1109/TRO.2015.2441511.
   Hansen P. C., 1998, RANK DEFICIENT DISCR.
   Hausman K, 2017, IEEE ROBOT AUTOM LET, V2, P1770, DOI 10.1109/LRA.2017.2647799.
   Heckman C, 2014, VICALIB VISUAL INERT.
   HERMANN R, 1977, IEEE T AUTOMAT CONTR, V22, P728, DOI 10.1109/TAC.1977.1101601.
   Hussein A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054912.
   Jauffret C, 2007, IEEE T AERO ELEC SYS, V43, P756, DOI 10.1109/TAES.2007.4285368.
   Jaulmes R, 2005, LECT NOTES ARTIF INT, V3720, P601.
   Kelly J, 2011, INT J ROBOT RES, V30, P56, DOI 10.1177/0278364910382802.
   Klein George, 2007, P1.
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721.
   Kummerle R, 2011, IEEE INT C INT ROBOT, P3716, DOI 10.1109/IROS.2011.6048393.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Levinson J., 2014, EXPT ROBOTICS, P179, DOI DOI 10.1007/978-3-642-28572-1\_13.
   Low K.-H., 2007, IND ROBOTICS PROGRAM.
   Martinelli A, 2006, IEEE INT CONF ROBOT, P43, DOI 10.1155/IMRN/2006/91426.
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Nobre F, 2017, 2017 IEEE INT C ROB.
   Nobre F, 2017, INT S ROB RES.
   Nobre F., 2016, INT S EXP ROB ISER.
   Preiss JA, 2017, ROBOTICS SCI SYSTEMS.
   Richardson A, 2013, IEEE INT C INT ROBOT, P1814, DOI 10.1109/IROS.2013.6696595.
   Russell S. J, 2016, ARTIFICIAL INTELLIGE.
   Sheehan M, 2012, INT J ROBOT RES, V31, P675, DOI 10.1177/0278364911429475.
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636.
   Sturm P. F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P432, DOI 10.1109/CVPR.1999.786974.
   WINTERER L, 2017, IEEE DECIS CONTR P, P2201.
   Zhang Q., 2004, 2004 IEEERSJ INT C I, V3, P2301, DOI {[}10.1109/IROS.2004.1389752, DOI 10.1109/IROS.2004.1389752].},
Number-of-Cited-References = {40},
Times-Cited = {3},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {24},
Journal-ISO = {Int. J. Robot. Res.},
Doc-Delivery-Number = {JG6UM},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000492207000006},
OA = {Bronze},
DA = {2022-05-17},
}

@inproceedings{ WOS:000298736200132,
Author = {Badino, H. and Huber, D. and Kanade, T.},
Book-Group-Author = {IEEE},
Title = {Visual Topometric Localization},
DOI = {10.1109/IVS.2011.5940504},
Booktitle = {2011 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV)},
Series = {IEEE Intelligent Vehicles Symposium},
Year = {2011},
Pages = {794-799},
Note = {IEEE Intelligent Vehicles Symposium (IV), Baden-Baden, GERMANY, JUN
   05-09, 2011},
Abstract = {One of the fundamental requirements of an autonomous vehicle is the
   ability to determine its location on a map. Frequently, solutions to
   this localization problem rely on GPS information or use expensive three
   dimensional (3D) sensors. In this paper, we describe a method for
   long-term vehicle localization based on visual features alone. Our
   approach utilizes a combination of topological and metric mapping, which
   we call topometric localization, to encode the coarse topology of the
   route as well as detailed metric information required for accurate
   localization. A topometric map is created by driving the route once and
   recording a database of visual features. The vehicle then localizes by
   matching features to this database at runtime. Since individual feature
   matches are unreliable, we employ a discrete Bayes filter to estimate
   the most likely vehicle position using evidence from a sequence of
   images along the route. We illustrate the approach using an 8.8 km route
   through an urban and suburban environment. The method achieves an
   average localization error of 2.7 m over this route, with isolated worst
   case errors on the order of 10 m.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Badino, H (Corresponding Author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Badino, H.; Huber, D.; Kanade, T., Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.},
ISSN = {1931-0587},
ISBN = {978-1-4577-0891-6},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Affiliations = {Carnegie Mellon University},
Cited-References = {Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8\_8.
   Andreasson Henrik, 2005, ICRA.
   Ascani A, 2008, IROS.
   Bay H., 2006, ECCV.
   Blanco JL, 2008, IEEE T ROBOT, V24, P259, DOI 10.1109/TRO.2008.918049.
   Bosse M., 2003, ICRA, V2.
   Cumani A., 2010, MATH MODELLING APPL, V1.
   Kouzoubov K, 2004, IEEE INT CONF ROBOT, P872, DOI 10.1109/ROBOT.2004.1307259.
   Lowe D. G., 2004, INT J ROBOTICS RES, V2.
   Murillo A. C., 2007, ICRA.
   Se S., 2005, IEEE T ROBOTICS.
   Silveira G., 2008, IEEE T ROBOTICS.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Thrun S, 2006, J FIELD ROBOT, V23, P661, DOI 10.1002/rob.20147.
   TOMATIS N, 2003, ROBOTICS AUTONOMOUS, V3.
   Urmson C., 2008, J FIELD ROBOTICS S 1, V25.
   Valgren C., 2010, SIFT SURF SEAS UNPUB.},
Number-of-Cited-References = {17},
Times-Cited = {70},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BYH14},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000298736200132},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000443894700061,
Author = {Tang, Yazhe and Hu, Yuchao and Cui, Jinqiang and Liao, Fang and Lao,
   Mingjie and Lin, Feng and Teo, Rodney S. H.},
Title = {Vision-Aided Multi-UAV Autonomous Flocking in GPS-Denied Environment},
Journal = {IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS},
Year = {2019},
Volume = {66},
Number = {1},
Pages = {616-626},
Month = {JAN},
Abstract = {This paper presents a sophisticated vision-aided flocking system for
   unmanned aerial vehicles (UAVs), which is able to operate in GPS-denied
   unknown environments for exploring and searching missions, and also able
   to adopt two types of vision sensors, day and thermal cameras, to
   measure relative motion between UAVs in different lighting conditions
   without using wireless communication. In order to realize robust
   vision-aided flocking, an integrated framework of
   tracking-learning-detection on the basis of multifeature coded
   correlation filter has been developed. To achieve long-term tracking, a
   redetector is trained online to adaptively reinitialize target for
   global sensing. An advanced flocking strategy is developed to address
   the autonomous multi-UAVs' cooperative flight. Light detection and
   ranging (LiDAR)-based navigation modules are developed for autonomous
   localization, mapping, and obstacle avoidance. Flight experiments of a
   team of UAVs have been conducted to verify the performance of this
   flocking system in a GPS-denied environment. The extensive experiments
   validate the robustness of the proposed vision algorithms in challenging
   scenarios.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Cui, JQ (Corresponding Author), Natl Univ Singapore, Temasek Labs, Singapore 119077, Singapore.
   Tang, Yazhe; Hu, Yuchao; Cui, Jinqiang; Liao, Fang; Lao, Mingjie; Lin, Feng; Teo, Rodney S. H., Natl Univ Singapore, Temasek Labs, Singapore 119077, Singapore.},
DOI = {10.1109/TIE.2018.2824766},
ISSN = {0278-0046},
EISSN = {1557-9948},
Keywords = {Flocking; unmanned system; visual sensing},
Keywords-Plus = {TRACKING},
Research-Areas = {Automation \& Control Systems; Engineering; Instruments \&
   Instrumentation},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {yztang2008@yahoo.com
   tslhuyu@nus.edu.sg
   jinqiang@u.nus.edu
   tsllf@nus.edu.sg
   tsllaom@nus.edu.sg
   linfeng@nus.edu.sg
   tsltshr@nus.edu.sg},
Affiliations = {National University of Singapore},
ResearcherID-Numbers = {Liao, Fang/E-6654-2011
   Jinqiang, Cui/ABB-3052-2020},
Cited-References = {Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737.
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960.
   Burgard W, 2005, IEEE T ROBOT, V21, P376, DOI 10.1109/TRO.2004.839232.
   Cui JQ, 2016, J INTELL ROBOT SYST, V84, P259, DOI 10.1007/s10846-015-0292-1.
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143.
   Dong WJ, 2011, IEEE T SYST MAN CY B, V41, P414, DOI 10.1109/TSMCB.2010.2056917.
   Faessler M, 2014, IEEE INT CONF ROBOT, P907, DOI 10.1109/ICRA.2014.6906962.
   Fu CH, 2014, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2014.6907659.
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381.
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390.
   Hung SM, 2017, IEEE T CYBERNETICS, V47, P186, DOI 10.1109/TCYB.2015.2509646.
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239.
   Liao F, 2016, IEEE INT VEH SYM, P246, DOI 10.1109/IVS.2016.7535393.
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352.
   Mueller M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1562, DOI 10.1109/IROS.2016.7759253.
   Nebehay G, 2015, PROC CVPR IEEE, P2784, DOI 10.1109/CVPR.2015.7298895.
   No TS, 2011, AEROSP SCI TECHNOL, V15, P431, DOI 10.1016/j.ast.2010.08.011.
   Nussberger A, 2015, IEEE INT CONF ROBOT, P6380, DOI 10.1109/ICRA.2015.7140095.
   O'Loan OJ, 1999, J PHYS A-MATH GEN, V32, pL99, DOI 10.1088/0305-4470/32/8/002.
   Pestana J, 2013, IEEE INT SYMP SAFE.
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823.
   Reynolds, 1987, ACM SIGGRAPH COMPUTE, P25, DOI {[}DOI 10.1145/37402.37406, 10.1145/37402.37406].
   Saber RF, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P2022.
   Shi H, 2006, PHYSICA D, V213, P51, DOI 10.1016/j.physd.2005.10.012.
   Tanner HG, 2004, IEEE INT CONF ROBOT, P3006, DOI 10.1109/ROBOT.2004.1307518.
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226.
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808.
   Zhao SY, 2015, IEEE T IND ELECTRON, V62, P1210, DOI 10.1109/TIE.2014.2345348.
   {[}No title captured].},
Number-of-Cited-References = {29},
Times-Cited = {44},
Usage-Count-Last-180-days = {12},
Usage-Count-Since-2013 = {234},
Journal-ISO = {IEEE Trans. Ind. Electron.},
Doc-Delivery-Number = {GS7PL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000443894700061},
DA = {2022-05-17},
}

@inproceedings{ WOS:000714033802075,
Author = {Pauls, Jan-Hendrik and Petek, Kuersat and Poggenhans, Fabian and
   Stiller, Christoph},
Book-Group-Author = {IEEE},
Title = {Monocular Localization in HD Maps by Combining Semantic Segmentation and
   Distance Transform},
Booktitle = {2020 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2020},
Pages = {4595-4601},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, OCT 24-JAN 24, 2020-2021},
Abstract = {Easy, yet robust long-term localization is still an open topic in
   research. Existing approaches require either dense maps, expensive
   sensors, specialized map features or proprietary detectors.
   We propose using semantic segmentation on a monocular camera to localize
   directly in a HD map as used for automated driving. This combines
   lightweight, yet powerful HD maps with the simplicity of monocular
   vision and the flexibility of neural networks.
   The major challenges arising from this combination are data association
   and robustness against misdetections. Association is solved efficiently
   by applying distance transform on binary per-class images. This provides
   not only a fast lookup table for a smooth gradient as needed for
   pose-graph optimization, but also dynamic association by default.
   A sliding-window pose graph optimization combines single image
   detections with vehicle odometry, smoothing results and helping overcome
   even misclassifications in consecutive frames.
   Evaluation against a highly accurate 6D visual localization shows that
   our approach can achieve accuracy levels as required for automated
   driving, being one of the most lightweight and flexible methods to do
   so.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pauls, JH (Corresponding Author), Karlsruhe Inst Technol KIT, Inst Measurement \& Control Syst, Karlsruhe, Germany.
   Pauls, Jan-Hendrik; Petek, Kuersat; Stiller, Christoph, Karlsruhe Inst Technol KIT, Inst Measurement \& Control Syst, Karlsruhe, Germany.
   Poggenhans, Fabian; Stiller, Christoph, FZI Res Ctr Informat Technol, Intelligent Syst \& Prod Engn, Karlsruhe, Germany.},
DOI = {10.1109/IROS45743.2020.9341003},
ISSN = {2153-0858},
ISBN = {978-1-7281-6212-6},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {pauls@kit.edu
   poggenhans@fzi.de
   stiller@kit.edu},
Affiliations = {Helmholtz Association; Karlsruhe Institute of Technology},
Cited-References = {Agarwal S., CERES SOLVER.
   Bradski G, 2000, DR DOBBS J, V25, P120.
   Chen YQ, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1391989.1391995.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Hu HH, 2019, IEEE INT VEH SYM, P1186, DOI 10.1109/IVS.2019.8814054.
   Jeong J, 2017, IEEE INT VEH SYM, P1736, DOI 10.1109/IVS.2017.7995958.
   Kummerle J, 2019, IEEE INT CONF ROBOT, P5965, DOI 10.1109/ICRA.2019.8793497.
   Lategahn H, 2014, IEEE T INTELL TRANSP, V15, P1246, DOI 10.1109/TITS.2014.2298492.
   Ma WC, 2019, IEEE INT C INT ROBOT, P5304, DOI 10.1109/IROS40897.2019.8968122.
   Meyer A, 2018, IEEE INT C INT ROBOT, P869, DOI 10.1109/IROS.2018.8594450.
   Milioto A, 2019, IEEE INT CONF ROBOT, P7094, DOI 10.1109/ICRA.2019.8793510.
   Mu BP, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4602, DOI 10.1109/IROS.2016.7759677.
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534.
   Nicholson L, 2019, IEEE ROBOT AUTOM LET, V4, P1, DOI 10.1109/LRA.2018.2866205.
   Poggenhans F, 2018, IEEE INT C INT ROBOT, P2167, DOI 10.1109/IROS.2018.8594414.
   Poggenhans F, 2018, IEEE INT C INTELL TR, P1672, DOI 10.1109/ITSC.2018.8569929.
   Porzi L, 2019, PROC CVPR IEEE, P8269, DOI 10.1109/CVPR.2019.00847.
   Salscheider NO, 2020, ICPRAM: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P555, DOI 10.5220/0009142905550561.
   SCHALLER AA, 2019, 2019 EUR C MOB ROB E.
   Schreiber M, 2013, IEEE INT VEH SYM, P449, DOI 10.1109/IVS.2013.6629509.
   SCHUBERT H, 2008, 2008 11 INT C INF FU, P1.
   Sefati M, 2017, IEEE INT VEH SYM, P13, DOI 10.1109/IVS.2017.7995692.
   Sons M, 2018, IEEE INT C INTELL TR, P2671, DOI 10.1109/ITSC.2018.8570011.
   Sons M, 2015, IEEE INT VEH SYM, P901, DOI 10.1109/IVS.2015.7225799.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   Toft C, 2017, IEEE INT CONF COMP V, P650, DOI 10.1109/ICCVW.2017.83.
   Welzel A, 2015, IEEE INT C INTELL TR, P2728, DOI 10.1109/ITSC.2015.438.
   Wilbers D, 2019, IEEE INT CONF ROBOT, P5951, DOI 10.1109/ICRA.2019.8793971.
   Yang SC, 2019, IEEE T ROBOT, V35, P925, DOI 10.1109/TRO.2019.2909168.},
Number-of-Cited-References = {29},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BS3PB},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000714033802075},
DA = {2022-05-17},
}

@inproceedings{ WOS:000508184100158,
Author = {Berrio, Julie Stephany and Ward, James and Worrall, Stewart and Nebot,
   Eduardo},
Book-Group-Author = {IEEE},
Title = {Updating the visibility of a feature-based map for long-term maintenance},
DOI = {10.1109/IVS.2019.8814189},
Booktitle = {2019 30TH IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV19)},
Series = {IEEE Intelligent Vehicles Symposium},
Year = {2019},
Pages = {1173-1179},
Note = {30th IEEE Intelligent Vehicles Symposium (IV), Paris, FRANCE, JUN 09-12,
   2019},
Abstract = {Mobile vehicles operating in urban navigation applications can achieve
   high integrity localisation with high accuracy by using maps of the
   surroundings. To accomplish this, the map should always have an accurate
   representation of the environment. Thus, it is necessary to detect and
   remove the map components that no longer exist in the current
   environment. This maintains the map compactness and dependability while
   simplifying the data association problem. This paper addresses the
   problem of deletion of transient map components by taking advantage of
   the geometric connection between the map and agent poses in order to
   establish and update the visibility of each feature. Once the map is
   created an initial visibility vector is associated with every map
   element and updated over time. The visibility of a map element which no
   longer exists is reduced and ultimately removed from the map. We
   demonstrate our approach in a 2D feature-based map composed of poles and
   corners extracted from information provided by a lidar sensor. The
   experimental results show the map update using a seven month data set
   collected in the University of Sydney campus.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Berrio, JS (Corresponding Author), Univ Sydney, ACFR, Sydney, NSW, Australia.
   Berrio, Julie Stephany; Ward, James; Worrall, Stewart; Nebot, Eduardo, Univ Sydney, ACFR, Sydney, NSW, Australia.},
ISSN = {1931-0587},
ISBN = {978-1-7281-0560-4},
Research-Areas = {Automation \& Control Systems; Robotics; Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics; Transportation Science \&
   Technology},
Author-Email = {j.berrio@acfr.usyd.edu.au
   j.ward@acfr.usyd.edu.au
   s.worrall@acfr.usyd.edu.au
   e.nebot@acfr.usyd.edu.au},
Affiliations = {University of Sydney},
ResearcherID-Numbers = {Worrall, Stewart/AAB-4633-2020
   Perez, Julie Stephany Berrio/AAL-1008-2021},
ORCID-Numbers = {Worrall, Stewart/0000-0001-7940-4742
   Perez, Julie Stephany Berrio/0000-0003-3126-7042},
Funding-Acknowledgement = {University of Sydney through the Dean of Engineering and Information
   Technologies PhD Scholarship (South America); Australian Research
   Council {[}DP160104081]; University of Michigan / Ford Motors Company
   Contract ``Next generation Vehicles{''}},
Funding-Text = {This work has been funded by the The University of Sydney through the
   Dean of Engineering and Information Technologies PhD Scholarship (South
   America) and the Australian Research Council Discovery Grant DP160104081
   and University of Michigan / Ford Motors Company Contract ``Next
   generation Vehicles{''}.},
Cited-References = {Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113.
   Alcantarilla Pablo F., 2011, 2011 IEEE International Conference on Robotics and Automation, P6205.
   Alcantarilla PF, 2010, IEEE INT CONF ROBOT, P4881, DOI 10.1109/ROBOT.2010.5509383.
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049.
   Dymczyk M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4572, DOI 10.1109/IROS.2016.7759673.
   Garnier J, 1838, CORRES MATH PHYS, V10.
   Klippenstein J, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P157, DOI 10.1109/CRV.2007.52.
   Martin-Gorostiza E, 2010, IEEE T INSTRUM MEAS, V59, P266, DOI 10.1109/TIM.2009.2023146.
   Meng Q., 2014, 2014 3 INT C AGR GEO, P1.
   Nobre F, 2018, IEEE INT CONF ROBOT, P3661.
   Pradalier C, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P708, DOI 10.1109/ROBOT.2002.1013441.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Sasaki Y., 2007, TEACH TUTOR MATER, V01.
   Shi XX, 2014, 2014 11TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P934, DOI 10.1109/WCICA.2014.7052841.
   Sooyong Lee, 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3505, DOI 10.1109/ROBOT.2000.845277.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Wang Z, 2007, MOL NEUROBIOL, V35, P317, DOI 10.1007/s12035-007-0014-1.},
Number-of-Cited-References = {17},
Times-Cited = {4},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BO2SH},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000508184100158},
DA = {2022-05-17},
}

@article{ WOS:000457365700044,
Author = {Yang, Yongquan and Wu, Yang and Chen, Ning},
Title = {Explorations on visual localization from active to passive},
Journal = {MULTIMEDIA TOOLS AND APPLICATIONS},
Year = {2019},
Volume = {78},
Number = {2},
Pages = {2269-2309},
Month = {JAN},
Abstract = {In this paper, we novelly consider visual localization in active and
   passive two ways, with simple definition that active localization
   assists device to estimate location of its interest while passive
   localization aids device to estimate its own location in environment.
   Expecting to indicate some insights into visual localization, we
   specifically performed two explorations on active localization and more
   importantly explored to upgrade them from active to passive localization
   with extra geometry information available. In order to produce
   unconstrained and accurate 2D location estimation of interested object,
   we constructed an active localization system by fusing detection,
   tracking and recognition. Based on recognition, we proposed a
   collaborative strategy making mutual enhancement between detection and
   tracking possible to obtain better performance on 2D location
   estimation. Meanwhile, to actively estimate semantic location of
   interested visual region, we employed latest state-of-the-art light
   weight CNN models specifically designed for efficiency and trained two
   of them with large place dataset in perspective of scene recognition.
   What's more, using depth information available from RGB-D camera, we
   improved the active system for 2D location of interested object to a
   passive system for relative 3D location of device to the interested
   object. Firstly estimated was the 3D location of the interested object
   in the coordinate system of device, then relative location of device to
   the interested object in world coordinate system was deduced with
   appropriate assumption. Evaluations both subjectively on a RGB-D
   sequence obtained in a lab environment and practically on a robotic
   platform in an office environment indicated that the improved system was
   suitable for autonomous following robot. As well, the active system for
   rough semantic location estimation of interested visual region was
   promoted to a passive system for fine location estimation of device,
   with available 3D map describing the visited environment. In perspective
   of place recognition, we first adopted one of the efficient CNN models
   previously trained for semantic location estimation as a base to
   generate CNN features for both retrieval of candidate loops in the map
   and geometrical consistency checking of retrieved loops, then true loops
   were used to deduce fine location of device itself in environment.
   Comparison with state-of-the-art results reflected that the promoted
   system was adequate for long-term robotic autonomy. Achieving favorable
   performances, the presented four explorations have implied adequacy for
   elaborating on some insights into visual localization.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Yang, YQ (Corresponding Author), Nara Inst Sci \& Technol, Ikoma, Japan.
   Yang, Yongquan, Nara Inst Sci \& Technol, Ikoma, Japan.
   Wu, Yang, Nara Inst Sci \& Technol, NAIST Int Collaborat Lab Robot Vis, Inst Res Initiat, Ikoma, Japan.
   Chen, Ning, Xian Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.},
DOI = {10.1007/s11042-018-6347-0},
ISSN = {1380-7501},
EISSN = {1573-7721},
Keywords = {Visual localization; Following robot; Loop closure detection; Long-term
   robotic autonomy},
Keywords-Plus = {LOOP CLOSURE DETECTION; LARGE-SCALE; TRACKING; TIME},
Research-Areas = {Computer Science; Engineering},
Web-of-Science-Categories  = {Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory \& Methods; Engineering,
   Electrical \& Electronic},
Author-Email = {remy\_yang@foxmail.com
   yangwu@rsc.naist.jp
   chennvictor@gmail.com},
Affiliations = {Nara Institute of Science \& Technology; Nara Institute of Science \&
   Technology; Xi'an Polytechnic University},
ORCID-Numbers = {Yang, Yongquan/0000-0002-3965-4816},
Funding-Acknowledgement = {JSPS KAKENHI {[}15K16024]},
Funding-Text = {This work was supported by JSPS KAKENHI Grant Number 15K16024.We
   gratefully acknowledge Intel China Lab and Beijing Qfeel Technology Co.,
   Ltd., China for equipment support.},
Cited-References = {Abadi M., 2016, ARXIV 160304467.
   Adam A., 2006, IEEE C COMP VIS PATT, P798, DOI DOI 10.1109/CVPR.2006.256.
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715.
   Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363.
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53.
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35.
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1\_38.
   Babenko B., 2009, CVPR.
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Beaudet P, P IJCPR.
   Bertinetto Luca, 2016, ARXIV160609549.
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302.
   Bolme D S, 2010, VISUAL OBJECT TRACKI.
   BRADSKI GR, 1998, INTEL TECHNOLOGY J, V2, P12.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Chatfield K, 2014, BRI MACH VIS C BMVC.
   Chen T., 2015, NEUR INF PROC SYST W.
   Chen Z., 2015, JAPANESE CIRCULATION, V53, P68.
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Dalal N, 2005, P IEEE COMP SOC C CO, V1, P886.
   Danelljan M., 2017, ECO EFFICIENT CONVOL.
   Danelljan M., 2014, P BRIT MACH VIS C BM.
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143.
   Danelljan Martin, 2015, ICCV WORKSH.
   Deng J., 2009, P CVPR.
   Doersch C, 2013, ADV NEU INF P SYST.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Felzenszwalb P. F., 2008, DISCRIMINATIVELY TRA.
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504.
   Friedman J., 2008, ELEMENTS STAT LEARNI.
   Fu C.-Y., 2016, ARXIV170106659.
   G Nebehay, 2015, CLUSTERING STATIC AD.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Girshick R., 2014, RICH FEATURE HIERARC.
   Girshick R. B., 2015, FAST R CNN.
   Gouda W, 2014, ELECTRONICS, P170.
   Graziotin D, 2015, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.18.
   Hahnel D, 2003, EFFICIENT FASTSLAM A.
   Han L, 2017, SIFT USING BINARY FE.
   Han L., 2017, INT C MULT EXP.
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251.
   Harris C, 1988, P 4 ALV VIS C, V15, P10, DOI DOI 10.5244/C.2.23.
   He K., 2016, COMPUT VIS PATTERN R.
   He K., 2017, P 2017 IEEE INT C CO, P2961.
   Held David, 2016, LEARNING TRACK 100 F.
   Henriques J. F., 2014, HIGH SPEED TRACKING.
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9\_50.
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659.
   Howard AN, 2017, MOBILENETS EFFICIENT.
   Jaderberg M., 2014, ARXIV14053866.
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2\_24.
   Jia Y., 2014, ARXIV14085093.
   Jiang Y.-G., 2007, P 6 ACM INT C IMAGE, P494, DOI DOI 10.1145/1282280.1282352.
   Jones M., 2001, COMPUTER VISION PATT, P1.
   Kalal Zdenek, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2756, DOI 10.1109/ICPR.2010.675.
   Kalal Z, 2010, 23 IEEE C COMP VIS P.
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239.
   Kejriwal N, 2016, ROBOT AUTON SYST, V77, P55, DOI 10.1016/j.robot.2015.12.003.
   Khan S, 2015, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2015.7139959.
   Klein DA, 2010, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2010.5650583.
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9\_54.
   Krizhevsky A, 2012, ADV NEURAL INFORM PR, P1097, DOI 10.1145/3065386.
   Kumari D., 2016, INT J ENG MANUF, V4, P40, DOI DOI 10.5815/IJEM.2016.04.05.
   Kwon J, 2009, TRACKING NONRIGID OB.
   L Wen, 2014, IEEE T IMAGE P.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Latif Y, 2013, INT J ROBOT RES, V32, P1611, DOI 10.1177/0278364913498910.
   Lebedev V., 2014, ARXIV14126553.
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542.
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5\_18.
   Lin T.-Y., 2017, FEATURE PYRAMID NETW.
   Lin T.-Y., 2017, ICCV.
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935.
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124.
   Liu W, 2016, SSD SINGLE SHOT MULT, DOI DOI 10.1007/978-3-319-46448-0\_2.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lucas Bruce D, 1981, ITERATIVE IMAGE REGI.
   Luo Jian-Hao, 2017, ICCV.
   Ma C., 2015, HIERARCHICAL CONVOLU.
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177.
   Mair E., 2010, P ECCV.
   Nam H., 2016, LEARNING MULTIDOMAIN.
   Nebehay G., 2014, TPAMI, DOI DOI 10.1109/WACV.2014.6836013.
   Nister D, 2004, IEEE COMP SOC C COMP, V1.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Ozyesil O., 2017, ACTA NUMERICA, V26, P01.
   Pernici F, 2014, IEEE T PATTERN ANAL, V36, P2538, DOI 10.1109/TPAMI.2013.250.
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0\_32.
   Redmon J, 2017, CVPR, V1, P8.
   Redmon J., 2016, YOU ONLY LOOK ONCE U, V1.
   Ren Shaoqing, 2015, FASTER R CNN REAL TI.
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sanchez Jorge, 2013, INT J COMPUT VIS.
   Shrivastava A., 2016, TRAINING REGION BASE.
   Sifre L, 2014, THESIS CITESEER.
   Simonyan A. Z. Karen, 2014, CORR.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Strasdat H., 2012, THESIS.
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594.
   Taketomi T., 2017, IPSJ T COMPUTER VISI, V9, P1, DOI {[}10.1186/s41074-016-0012-1, DOI 10.1186/S41074-017-0027-2, 10.1186/s41074-017-0027-2].
   Uchida Y, 2016, ARXIV160708368.
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5.
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734.
   Vojir T, 2014, ENHANCED FLOCK TRACK.
   W Zhong, 2012, ROBUST OBJECT TRACKI.
   Wang N., 2013, NIPS, P809, DOI DOI 10.5555/2999611.2999702.
   Wei YM, 2013, J ZHEJIANG U-SCI C, V14, P486, DOI 10.1631/jzus.CIDE1302.
   Wen W., 2016, NIPS, P2074.
   Williams B, 2011, IEEE T PATTERN ANAL, V33, P1699, DOI 10.1109/TPAMI.2011.41.
   Zhang K., 2012, ECCV.
   Zhang K, 2014, FAST TRACKING VIA DE.
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4.
   Zhang X, 2015, INTELL CONTROL AUTOM, V22, P2026.
   Zhang X., 2017, ARXIV170701083.
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579.
   Zhou B, 2014, ADV NEU INF P SYST.
   Zhou B, 2017, IEEE T PATTERN ANAL, V99.},
Number-of-Cited-References = {120},
Times-Cited = {3},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {9},
Journal-ISO = {Multimed. Tools Appl.},
Doc-Delivery-Number = {HJ7HD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000457365700044},
DA = {2022-05-17},
}

@inproceedings{ WOS:000330192800110,
Author = {Slimane, Noureddine and Khireddine, Mohamed Salah and Chafaa,
   Kheireddine},
Book-Group-Author = {IEEE},
Title = {A metric approach for Environments mapping},
DOI = {10.1109/CoDIT.2013.6689619},
Booktitle = {2013 INTERNATIONAL CONFERENCE ON CONTROL, DECISION AND INFORMATION
   TECHNOLOGIES (CODIT)},
Year = {2013},
Pages = {647-652},
Note = {International Conference on Control, Decision and Information
   Technologies (CoDIT), Hammamet, TUNISIA, MAY 06-08, 2013},
Abstract = {One of the main issues in mobile robotics is the autonomous navigation
   of a mobile robot in an unknown environment. Concurrent mapping and
   localisation or simultaneous localisation and mapping is a stochastic
   map building method which permits consistent robot navigation without
   requiring an a priori map. The governing idea which guides autonomous
   robotics consists in saying that the vehicle builds its chart
   progressively during exploration enabling it to evolve in the long term
   in unknown places in advance. When the robot environment chart is not
   known a priori, a generation module of incremental chart must
   obligatorily be integrated into the navigation system. The map is built
   incrementally as the robot observes the environment with its on-board
   sensors and, at the same time, is used to localise the robot.
   Unfortunately, the inaccuracy of the odometric sensors does not allow a
   sufficiently correct positioning of the robot. In this paper,
   simultaneous localisation and map building is performed with a metric
   approach which permits both precision and robustness. The most important
   innovation of the approach is the way how errors in the robot
   localisation control are handled by map building using the landmarks
   localisation information. The method uses data from a laser scanner to
   extract distances and orientations of landmarks and combines control
   localisation and metric paradigm. The metric approach, based on the
   Kalman filter, uses a new concept to avoid the problem of the drift in
   odometry. The simulation section will validate the maps representation
   approach and presents different aspect of environments.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Slimane, N (Corresponding Author), Univ Batna, Fac Engn, Adv Elect Lab, Batna, Algeria.
   Slimane, Noureddine, Univ Batna, Fac Engn, Adv Elect Lab, Batna, Algeria.
   Khireddine, Mohamed Salah, Univ Batna, Fac Engn, Robot \& Product Lab, Batna, Algeria.
   Chafaa, Kheireddine, Univ Batna, Fac Engn, Dept Elect, Batna, Algeria.},
ISBN = {978-1-4673-5547-6; 978-1-4673-5549-0},
Keywords = {Map building; metric chart; real-time control; mobile robot
   localisation; extended Kalman filter; landmarks detection},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic},
Author-Email = {slimane\_doudi@yahoo.fr},
Affiliations = {University of Batna; University of Batna; University of Batna},
Cited-References = {Castellanos JA, 2000, LECT NOTES CONTR INF, V250, P287.
   Choset H, 2001, IEEE T ROBOTIC AUTOM, V17, P125, DOI 10.1109/70.928558.
   Dissanayake MWMG, 2000, LECT NOTES CONTR INF, V250, P265.
   Duckett T., 2000, P INT IFAC S ROB CON, P357.
   Gasos J., 1999, P 3 INT S SOFT COMP.
   Leonard J. J., 1991, Proceedings IROS `91. IEEE/RSJ International Workshop on Intelligent Robots and Systems `91. Intelligence for Mechanical Systems (Cat. No.91TH0375-6), P1442, DOI 10.1109/IROS.1991.174711.
   Montemerlo Michael, INT JOINT C ART INT.
   Murphy K., 1999, BAYESIAN MAP LEARNIN.
   Pradalier Cedric, 2002, 2002 IEEE RSJ INT C.
   Ranganathan P, 2002, ROBOT AUTON SYST, V41, P137, DOI 10.1016/S0921-8890(02)00276-2.
   RENCKEN WD, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P2192, DOI 10.1109/IROS.1993.583932.
   Simhon S, 1998, 1998 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - PROCEEDINGS, VOLS 1-3, P1708, DOI 10.1109/IROS.1998.724844.
   Thrun S, 1998, MACH LEARN, V31, P29, DOI 10.1023/A:1007436523611.
   Tomatis N., 2001, THESIS.},
Number-of-Cited-References = {14},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BJT43},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000330192800110},
DA = {2022-05-17},
}

@article{ WOS:000679943600001,
Author = {Khan, Subhan and Guivant, Jose},
Title = {Nonlinear Model Predictive Path-Following Controller for a Small-Scale
   Autonomous Bulldozer for Accurate Placement of Materials and Debris of
   Masonry in Construction Contexts},
Journal = {IEEE ACCESS},
Year = {2021},
Volume = {9},
Pages = {102069-102080},
Abstract = {This paper presents a nonlinear model predictive control (NMPC) scheme
   for the medium-level control of a small-scale autonomous bulldozer to
   accurately and safely displace crushed materials of masonry in
   construction contexts. For this purpose, the controller is required to
   minimize the error between the achieved and required paths;
   additionally, the control actions must be smooth for minimizing the
   mistreatment of equipment, which is intended to operate in the long
   term, as it is usual in industrial-grade solutions. The proposed NMPC
   based path-follower can adequately handle the platform's constraints and
   usual perturbations. In terms of state estimation, a map-based localizer
   is implemented via an extended Kalman filter (EKF) based on the platform
   nominal process model and light detecting and ranging (LiDAR) and
   inertial measurement unit (IMU) sensors measurements. The localizer
   provides estimates of the platform's pose, necessary for the MPC
   controller's state feedback. An actual experiment on a modified UGV
   (Clearpaths Husky A-200) is performed to validate the performance of the
   proposed control scheme. The UGV is retrofitted with a blade (for
   pushing material) and appropriate sensors for the necessary perception
   tasks. Experimental results indicate that the proposed control scheme is
   robust and suitable for safely pushing the crushed materials, presenting
   appropriately low deviation from the nominal path and requiring
   reasonably low processing time.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Khan, S (Corresponding Author), Univ New South Wales, Sch Mech Engn, Sydney, NSW 2052, Australia.
   Khan, Subhan; Guivant, Jose, Univ New South Wales, Sch Mech Engn, Sydney, NSW 2052, Australia.},
DOI = {10.1109/ACCESS.2021.3098524},
ISSN = {2169-3536},
Keywords = {Land vehicles; Task analysis; Wheels; Predictive models; Computational
   modeling; Real-time systems; Predictive control; Extended Kalman filter;
   masonry construction; nonlinear model predictive control; path-follower;
   small-scale bulldozer; unmanned ground vehicle},
Keywords-Plus = {TRAJECTORY TRACKING; MOBILE ROBOTS; VEHICLES; MPC},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {subhan.khan@unsw.edu.au},
Affiliations = {University of New South Wales Sydney},
ORCID-Numbers = {Khan, Subhan/0000-0002-0979-3751},
Funding-Acknowledgement = {UNSW Sydney {[}PS38925/OP001]; University International Post-Graduate
   Award (UIPA) {[}RSRE7061]},
Funding-Text = {This work was supported by the UNSW Sydney under Project PS38925/OP001,
   and in part by the University International Post-Graduate Award (UIPA)
   under Grant RSRE7061.},
Cited-References = {Alcala E, 2018, CONTROL ENG PRACT, V73, P1, DOI 10.1016/j.conengprac.2017.12.004.
   Barbosa FM, 2019, CONTROL ENG PRACT, V85, P246, DOI 10.1016/j.conengprac.2019.01.017.
   Boyd S., 2004, CONVEX OPTIMIZATION.
   Choi J, 2020, AUTOMAT CONSTR, V110, DOI 10.1016/j.autcon.2019.102974.
   Cui QJ, 2018, P I MECH ENG D-J AUT, V232, P1237, DOI 10.1177/0954407017728199.
   Dou FQ, 2019, INT J HEAVY VEH SYST, V26, P315, DOI 10.1504/IJHVS.2019.101475.
   Guivant J, 2012, J FIELD ROBOT, V29, P793, DOI 10.1002/rob.21432.
   Guo HY, 2019, MECH SYST SIGNAL PR, V118, P41, DOI 10.1016/j.ymssp.2018.08.028.
   Ha QP, 2019, AUTOMAT CONSTR, V107, DOI 10.1016/j.autcon.2019.102934.
   Hirayama M., 2020, U.S. Patent, Patent No. {[}16 335 392, 16335392].
   Hirayama M., 2020, AU Patent, Patent No. {[}2018 334 390, 2018334390].
   Hirayama M, 2019, INT J INNOV COMPUT I, V15, P825, DOI 10.24507/ijicic.15.03.825.
   Hirayama M, 2019, MECHATRONICS, V58, P20, DOI 10.1016/j.mechatronics.2019.01.001.
   Hirayama M, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881418764716.
   Hu C, 2016, IEEE T TRANSP ELECTR, V2, P221, DOI 10.1109/TTE.2016.2537046.
   Hu JS, 2014, IEEE T IND ELECTRON, V61, P1916, DOI 10.1109/TIE.2013.2262758.
   Kang HS, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55738.
   Kayacan E, 2018, IEEE-ASME T MECH, V23, P2023, DOI 10.1109/TMECH.2018.2854877.
   Kayacan E, 2016, IEEE-ASME T MECH, V21, P806, DOI 10.1109/TMECH.2015.2492984.
   Khan S., 2021, SUPPLEMENTARY DOCUME.
   Killian M, 2016, BUILD ENVIRON, V105, P403, DOI 10.1016/j.buildenv.2016.05.034.
   Kim SH, 2019, AUTOMAT CONSTR, V106, DOI 10.1016/j.autcon.2019.102890.
   Klancar G, 2007, ROBOT AUTON SYST, V55, P460, DOI 10.1016/j.robot.2007.01.002.
   Lee YS, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103264.
   Li HX, 2020, AUTOMAT CONSTR, V113, DOI 10.1016/j.autcon.2020.103139.
   Li XF, 2019, AUTOMAT CONSTR, V107, DOI 10.1016/j.autcon.2019.102928.
   Li ZJ, 2016, IEEE T SYST MAN CY-S, V46, P740, DOI 10.1109/TSMC.2015.2465352.
   Lian CQ, 2016, IEEE T CYBERNETICS, V46, P2484, DOI 10.1109/TCYB.2015.2478857.
   Lucia S, 2014, J PROCESS CONTR, V24, P1247, DOI 10.1016/j.jprocont.2014.05.008.
   Nascimento TP, 2018, ROBOTICA, V36, P676, DOI 10.1017/S0263574717000637.
   Nebot E, 2006, J FIELD ROBOT, V23, P141, DOI 10.1002/rob.20114.
   Ni J, 2019, IEEE T VEH TECHNOL, V68, P5518, DOI 10.1109/TVT.2019.2911862.
   Ohtsuka T, 2004, AUTOMATICA, V40, P563, DOI 10.1016/j.automatica.2003.11.005.
   Olsen SG, 2011, CAN CON EL COMP EN, P1188, DOI 10.1109/CCECE.2011.6030650.
   Ostafew CJ, 2016, INT J ROBOT RES, V35, P1547, DOI 10.1177/0278364916645661.
   Quemelli MB, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101913.
   Siroky J, 2011, APPL ENERG, V88, P3079, DOI 10.1016/j.apenergy.2011.03.009.
   Sun ZQ, 2018, AUTOMATICA, V90, P172, DOI 10.1016/j.automatica.2017.12.048.
   Wu JY, 2020, MECH MACH THEORY, V154, DOI 10.1016/j.mechmachtheory.2020.104100.
   Wu X, 2019, J INTELL ROBOT SYST, V96, P109, DOI 10.1007/s10846-019-00980-9.
   Yamamoto S., 1995, U.S. Patent, Patent No. {[}5 462 122, 5462122].
   Yang HJ, 2018, IET CONTROL THEORY A, V12, P206, DOI 10.1049/iet-cta.2017.0395.
   Yang HJ, 2016, IEEE T CONTR SYST T, V24, P741, DOI 10.1109/TCST.2015.2457877.
   Yang HJ, 2016, ADV ROBOTICS, V30, P68, DOI 10.1080/01691864.2015.1085900.
   Yuan H, 2016, VEHICLE SYST DYN, V54, P1428, DOI 10.1080/00423114.2016.1208251.
   Zhang L, 2021, IEEE ACCESS, V9, P65174, DOI 10.1109/ACCESS.2021.3075325.
   Zhou H, 2017, AUTOMAT CONSTR, V83, P68, DOI 10.1016/j.autcon.2017.08.014.},
Number-of-Cited-References = {47},
Times-Cited = {1},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {8},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {TS9CE},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000679943600001},
OA = {gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000724145801033,
Author = {Zhu, Pengxiang and Ren, Wei},
Book-Group-Author = {IEEE},
Title = {Multi-Robot Joint Visual-Inertial Localization and 3-D Moving Object
   Tracking},
Booktitle = {2020 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2020},
Pages = {11573-11580},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), ELECTR NETWORK, OCT 24-JAN 24, 2020-2021},
Abstract = {In this paper, we present a novel distributed algorithm to track a
   moving object's state by utilizing a heterogenous mobile robot network
   in a three-dimensional (3-D) environment, wherein the robots' poses
   (positions and orientations) are unknown. Each robot is equipped with a
   monocular camera and an inertial measurement unit (IMU), and has the
   ability to communicate with its neighbors. Rather than assuming a known
   common global frame for all the robots (which is often the case in the
   literature regarding multi-robot systems), we allow each robot to
   perform motion estimation locally. For localization, we propose a
   multi-robot visual-inertial navigation systems (VINS) where one robot
   builds a prior map and then the map is used to bound the long-term
   drifts of the visual-inertial odometry (VIO) running on the other
   robots. Moreover, a novel distributed Kalman filter is introduced and
   employed to cooperatively track the six degree-of-freedom (6-DoF) motion
   of the object which is represented as a point cloud. Further, the object
   can be totally invisible to some robots during the tracking period. The
   proposed algorithm is extensively validated in Monte-Carlo simulations.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Zhu, PX (Corresponding Author), Univ Calif Riverside, Dept Elect \& Comp Engn, Riverside, CA 92521 USA.
   Zhu, Pengxiang; Ren, Wei, Univ Calif Riverside, Dept Elect \& Comp Engn, Riverside, CA 92521 USA.},
DOI = {10.1109/IROS45743.2020.9341393},
ISSN = {2153-0858},
ISBN = {978-1-7281-6212-6},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {pzhu008@ucr.edu
   ren@ee.ucr.edu},
Affiliations = {University of California System; University of California Riverside},
Cited-References = {Ahmadi A, 2013, IEEE INT CONF ROBOT, P5696, DOI 10.1109/ICRA.2013.6631396.
   Battistelli G, 2015, IEEE T AUTOMAT CONTR, V60, P1410, DOI 10.1109/TAC.2014.2357135.
   Breckenridge W., 1999, 343791199 IOM, P343.
   Chatfield A. B., 1997, FUNDAMENTALS HIGH AC.
   Chen J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P446, DOI 10.1109/IROS.2016.7759092.
   Eckenhoff K, 2019, IEEE ROBOT AUTOM LET, V4, P1541, DOI 10.1109/LRA.2019.2896472.
   Forster C, 2017, IEEE T ROBOT, V33, P1, DOI 10.1109/TRO.2016.2597321.
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514.
   Furrer F, 2016, STUD COMPUT INTELL, V625, P595, DOI 10.1007/978-3-319-26054-9\_23.
   Geneva P, 2019, PROC CVPR IEEE, P12097, DOI 10.1109/CVPR.2019.01238.
   Guo CX, 2018, IEEE T ROBOT, V34, P1349, DOI 10.1109/TRO.2018.2858229.
   Guo CX, 2016, IEEE INT CONF ROBOT, P1071, DOI 10.1109/ICRA.2016.7487238.
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629.
   Hu JW, 2012, IEEE T SIGNAL PROCES, V60, P891, DOI 10.1109/TSP.2011.2175386.
   Huang GQ, 2015, ROBOT AUTON SYST, V69, P52, DOI 10.1016/j.robot.2014.08.007.
   Kamal AT, 2013, IEEE T AUTOMAT CONTR, V58, P3112, DOI 10.1109/TAC.2013.2277621.
   Karrer M, 2018, IEEE ROBOT AUTOM LET, V3, P2762, DOI 10.1109/LRA.2018.2837226.
   Koenig N., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P2149.
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813.
   Li MY, 2013, INT J ROBOT RES, V32, P690, DOI 10.1177/0278364913481251.
   Markley FL, 2007, J GUID CONTROL DYNAM, V30, P1193, DOI 10.2514/1.28949.
   Martinelli A, 2019, IEEE ROBOT AUTOM LET, V4, P453, DOI 10.1109/LRA.2019.2891025.
   Martins AA, 2019, ANIMAL, V13, P1865, DOI 10.1017/S1751731119000259.
   Melnyk IV, 2012, IEEE INT CONF ROBOT, P936, DOI 10.1109/ICRA.2012.6225219.
   Mirzaei FM, 2007, IEEE INT CONF ROBOT, P3482, DOI 10.1109/ROBOT.2007.364011.
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024.
   Mur-Artal R, 2017, IEEE ROBOT AUTOM LET, V2, P796, DOI 10.1109/LRA.2017.2653359.
   Olfati-Saber R, 2007, IEEE DECIS CONTR P, P1814.
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729.
   Qin T, 2017, IEEE INT C INT ROBOT, P4225, DOI 10.1109/IROS.2017.8206284.
   Qiu KJ, 2019, IEEE T ROBOT, V35, P799, DOI 10.1109/TRO.2019.2909085.
   Rozantsev A., 2017, C COMP VIS PATT REC, P6030.
   Vo M, 2016, PROC CVPR IEEE, P1710, DOI 10.1109/CVPR.2016.189.
   Zhu F, 2020, EFFICIENT PETROCHEMICAL PROCESSES: TECHNOLOGY, DESIGN AND OPERATION, P3.
   Zhu PX, 2019, P AMER CONTR CONF, P3261.},
Number-of-Cited-References = {35},
Times-Cited = {1},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BS4YL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000724145801033},
DA = {2022-05-17},
}

@inproceedings{ WOS:000544658400081,
Author = {Haris, Muhammad and Franzius, Mathias and Bauer-Wersing, Ute},
Book-Group-Author = {IEEE},
Title = {Robust Outdoor Self-localization In Changing Environments},
DOI = {10.1109/IROS40897.2019.8967549},
Booktitle = {2019 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2019},
Pages = {714-719},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Macau, PEOPLES R CHINA, NOV 04-08, 2019},
Abstract = {In outdoor scenarios changing conditions (e.g., seasonal, weather and
   lighting effects) have a substantial impact on the appearance of a
   scene, which often prevents successful visual localization. The
   application of an unsupervised Slow Feature Analysis (SFA) on the images
   captured by an autonomous robot enables self-localization from a single
   image. However, changes occurring during the training phase or over a
   more extended period can affect the learned representations. To address
   the problem, we propose to join long-term recordings from an outdoor
   environment based on their position correspondences. The established
   hierarchical model trained on raw images performs well, but as an
   extension, we extract Fourier components of the views and use that for
   learning of spatial representations, which reduces the computation time
   and makes it adequate to run on an ARM embedded system. We present the
   experimental results from a simulated environment and real-world outdoor
   recordings collected over a full year, which has effects like different
   day time, weather, seasons and dynamic objects. Results show an
   increasing invariance w.r.t. changing conditions over time, thus an
   outdoor robot can improve its localization performance during operation.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Haris, M (Corresponding Author), Frankfurt Univ Appl Sci, Fac Comp Sci \& Engn, D-60318 Frankfurt, Germany.
   Haris, Muhammad; Bauer-Wersing, Ute, Frankfurt Univ Appl Sci, Fac Comp Sci \& Engn, D-60318 Frankfurt, Germany.
   Franzius, Mathias, Honda Res Inst Europe GmbH, D-63073 Offenbach, Germany.},
ISSN = {2153-0858},
ISBN = {978-1-7281-4004-9},
Keywords-Plus = {SLOW FEATURE ANALYSIS; MAP},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods; Robotics},
Author-Email = {muhammad.haris@fb2.fra-uas.de},
Affiliations = {Honda Motor Company},
Cited-References = {Carlevaris-Bianco N, 2014, IEEE INT C INT ROBOT, P2769, DOI 10.1109/IROS.2014.6942941.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Einecke N., 2017, C FIELD SERV ROB.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Escalante-B A. N., 2016, CORR, Vabs/1601.03945.
   Foldiak P, 1991, NEURAL COMPUT, V3, P194, DOI 10.1162/neco.1991.3.2.194.
   Franzius M., 2007, PLOS COMPUTATIONAL B, V3.
   Hahnel D, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P206.
   Ishiguro H, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P634, DOI 10.1109/IROS.1996.571018.
   Jeffery KJ, 1999, EXP BRAIN RES, V127, P151, DOI 10.1007/s002210050785.
   Kendall A., 2017, CORR.
   Kendall A., 2015, CORR.
   McManus C, 2014, IEEE INT CONF ROBOT, P901, DOI 10.1109/ICRA.2014.6906961.
   Menegatti E, 2003, LECT NOTES ARTIF INT, V2829, P423.
   Metka B, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203994.
   Metka B, 2016, LECT NOTES COMPUT SC, V9887, P489, DOI 10.1007/978-3-319-44781-0\_58.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R., 2015, CORR.
   OKEEFE J, 1971, BRAIN RES, V34, P171, DOI 10.1016/0006-8993(71)90358-1.
   STONE J, 1995, NETWORK-COMP NEURAL, V6, P429, DOI 10.1088/0954-898X/6/3/008.
   Sunderhauf N., 2015, CORR, Vabs/1501.04158.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   TAUBE JS, 1990, J NEUROSCI, V10, P420.
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010.
   Wiskott L, 2002, NEURAL COMPUT, V14, P715, DOI 10.1162/089976602317318938.
   Wiskott L., 1998, ICANN 98. Proceedings of the 8th International Conference on Artificial Neural Networks, P555.
   Wiskott L., 2011, SCHOLARPEDIA, V6, P5282, DOI {[}10.4249/scholarpedia.5282, DOI 10.4249/SCHOLARPEDIA.5282].
   Zichao Zhang, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3894, DOI 10.1109/ICRA.2017.7989449.
   Zito Tiziano, 2008, Front Neuroinform, V2, P8, DOI 10.3389/neuro.11.008.2008.},
Number-of-Cited-References = {30},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP2QS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000544658400081},
DA = {2022-05-17},
}

@inproceedings{ WOS:000079075400006,
Author = {Knotts, RM and Nourbakhsh, IR and Morris, RC},
Editor = {Demsetz, LA and Bryne, RH and Wetzel, JP},
Title = {NaviGates: A benchmark for indoor navigation},
DOI = {10.1061/40337(205)6},
Booktitle = {ROBOTICS 98},
Year = {1998},
Pages = {36-42},
Note = {3rd ASCE Speciality Conference on Robotics for Challenging Environments
   (Robotics 98), ALBUQUERQUE, NM, APR 26-30, 1998},
Abstract = {Reliable indoor navigation has been a goal of mobile robotics research
   in recent years. Probabilistic belief update, occupancy grid methods,
   and multi-tiered hybrid architectures have all been implemented in the
   pursuit of autonomous navigation systems that can function in the face
   of danger and incomplete information. The conventional approach applies
   AI techniques to the localization problem in order to attain reasonable
   navigation reliability. In this paper, we describe a simple navigation
   system that is neither multi-tiered nor AI-based. The system has been
   implemented on a Nomad 150 mobile robot that has demonstrated
   statistically significant navigation reliability during working hours in
   several buildings in the San Francisco Bay Area. In addition to
   providing navigation benchmarks based on Long-term empirical tests,
   NaviGates demonstrates implementations of robot skills that are
   essential to robot autonomy: robust dynamic obstacle avoidance, path
   replanning in case of obstruction. automatic avoidance of dangerous
   regions such as staircases, and automatic human-guided mapping for a new
   building. allowing the robot to be introduced to a new office building
   without the need for lime consuming manual mapping. Simplicity itself is
   an important thesis of this research, as a robot with an extremely
   simple control algoritm is shown to perform admirably in a variety of
   environments.},
Publisher = {AMER SOC CIVIL ENGINEERS},
Address = {UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Knotts, RM (Corresponding Author), Cisco Syst Inc, San Jose, CA 95134 USA.
   Cisco Syst Inc, San Jose, CA 95134 USA.},
ISBN = {0-7844-0337-6},
Research-Areas = {Automation \& Control Systems; Engineering},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Civil},
Affiliations = {Cisco Systems Inc},
Cited-References = {BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M.
   CONNELL, 1992, P 1992 IEEE INT C RO.
   GUTIERREZOSUNA, 1996, AI MAGAZINE, V17, P55.
   NILSSON, 1996, P 13 NAT C ART INT, P1344.
   NOURBAKHSH, 1995, AI MAGAZINE, V16.
   SIMMONS, 1995, P 14 INT JOINT C ART.},
Number-of-Cited-References = {6},
Times-Cited = {1},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BM53M},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000079075400006},
DA = {2022-05-17},
}

@inproceedings{ WOS:000377221103147,
Author = {Biswas, Joydeep and Veloso, Manuela},
Book-Group-Author = {IEEE},
Title = {Episodic Non-Markov Localization: Reasoning About Short-Term and
   Long-Term Features},
DOI = {10.1109/ICRA.2014.6907435},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2014},
Pages = {3969-3974},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014},
Abstract = {Markov localization and its variants are widely used for localization of
   mobile robots. These methods assume Markov independence of observations,
   implying that observations made by a robot correspond to a static map.
   However, in real human environments, observations include occlusions due
   to unmapped objects like chairs and tables, and dynamic objects like
   humans. We introduce an episodic non-Markov localization algorithm that
   maintains estimates of the belief over the trajectory of the robot while
   explicitly reasoning about observations and their correlations arising
   from unmapped static objects, moving objects, as well as objects from
   the static map. Observations are classified as arising from longterm
   features, short-term features, or dynamic features, which correspond to
   mapped objects, unmapped static objects, and unmapped dynamic objects
   respectively. By detecting time steps along the robot's trajectory where
   unmapped observations prior to such time steps are unrelated to those
   afterwards, nonMarkov localization limits the history of observations
   and pose estimates to ``episodes{''} over which the belief is computed.
   We demonstrate non-Markov localization in challenging real world indoor
   and outdoor environments over multiple datasets, comparing it with
   alternative state-of-the-art approaches, showing it to be robust as well
   as accurate.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Biswas, J (Corresponding Author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Biswas, Joydeep, Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   Veloso, Manuela, Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-3685-4},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {joydeepb@cs.cmu.edu
   mmv@cs.cmu.edu},
Affiliations = {Carnegie Mellon University; Carnegie Mellon University},
ORCID-Numbers = {Biswas, Joydeep/0000-0002-1211-1731},
Cited-References = {AGARWAL S, CERES SOLVER TUTORIA.
   Anguelov D., 2002, P 18 C UNC ART INT, P10.
   Barton J.J., SCI ENG C INTRO ADV.
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007.
   Biber P., RSS 2005, P17.
   Biswas J, 2011, IEEE INT C INT ROBOT, P73, DOI 10.1109/IROS.2011.6048263.
   Fox D, 2001, STAT ENG IN, P401.
   Fox D., 1998, THESIS U BONN GERMAN.
   Griewank A., 2008, EVALUATING DERIVATIV.
   Meyer-Delius D., IROS 2012, P5750.
   Petrovskaya A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2178.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Stachniss, AAAI 2005, P1324.
   Tipaldi G. D., 2012, RSS WORKSH ROB CLUTT.
   Walcott-Bryant A, 2012, IEEE INT C INT ROBOT, P1871, DOI 10.1109/IROS.2012.6385561.},
Number-of-Cited-References = {15},
Times-Cited = {16},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE9BP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000377221103147},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000736739800005,
Author = {Gridseth, Mona and Barfoot, Timothy D.},
Title = {Keeping an Eye on Things: Deep Learned Features for Long-Term Visual
   Localization},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2022},
Volume = {7},
Number = {2},
Pages = {1016-1023},
Month = {APR},
Abstract = {In this letter, we learn visual features that we use to first build a
   map and then localize a robot driving autonomously across a full day of
   lighting change, including in the dark. We train a neural network to
   predict sparse keypoints with associated descriptors and scores that can
   be used together with a classical pose estimator for localization. Our
   training pipeline includes a differentiable pose estimator such that
   training can be supervised with ground truth poses from data collected
   earlier, in our case from 2016 and 2017 gathered with multi-experience
   Visual Teach and Repeat (VT\&R). We insert the learned features into the
   existing VT\&R pipeline to perform closed-loop path following in
   unstructured outdoor environments. We show successful path following
   across all lighting conditions despite the robot's map being constructed
   using daylight conditions. Moreover, we explore generalizability of the
   features by driving the robot across all lighting conditions in new
   areas not present in the feature training dataset. In all, we validated
   our approach with 35.5 km of autonomous path following experiments in
   challenging conditions.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Gridseth, M (Corresponding Author), Univ Toronto, Inst Aerosp Studies, Toronto, ON M3H 5T6, Canada.
   Gridseth, Mona; Barfoot, Timothy D., Univ Toronto, Inst Aerosp Studies, Toronto, ON M3H 5T6, Canada.},
DOI = {10.1109/LRA.2021.3136867},
ISSN = {2377-3766},
Keywords = {Localization; deep learning for visual perception; vision-based
   navigation},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mona.gridseth@robotics.utias.utoronto.ca
   tim.barfoot@utoronto.ca},
Affiliations = {University of Toronto},
Funding-Acknowledgement = {Clearpath Robotics; Natural Sciences and Engineering Research Council of
   Canada (NSERC)},
Funding-Text = {Thisworkwas supported by Clearpath Robotics and the Natural Sciences and
   Engineering Research Council of Canada (NSERC).},
Cited-References = {Barfoot T., 2017, STATE ESTIMATION ROB.
   Barnes D, 2020, IEEE INT CONF ROBOT, P9484, DOI 10.1109/ICRA40945.2020.9196835.
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023\_32.
   Chen C, 2020, ARXIV200612567.
   Christiansen P.H., 2019, ARXIV190704011.
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060.
   Dusmanu M, 2019, PROC CVPR IEEE, P8084, DOI 10.1109/CVPR.2019.00828.
   Fua Pascal, 2018, ADV NEURAL INFORM PR, V31, P6234.
   Gladkova Mariia, 2021, 2021 IEEE International Conference on Robotics and Automation (ICRA), P9608, DOI 10.1109/ICRA48506.2021.9561217.
   Gridseth M, 2020, IEEE INT CONF ROBOT, P1674, DOI 10.1109/ICRA40945.2020.9197362.
   Hirschmuller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI {[}10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166].
   Kasper M., 2020, P 4 C ROB LEARN, V155, P1736.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kingma D. P., 2014, 3 INT C LEARN REPR, DOI DOI 10.1145/1830483.1830503.
   Laskar Z, 2017, IEEE INT CONF COMP V, P920, DOI 10.1109/ICCVW.2017.113.
   Luo ZX, 2020, PROC CVPR IEEE, P6588, DOI 10.1109/CVPR42600.2020.00662.
   Lv ZY, 2019, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR.2019.00471.
   Paton M., 2018, FIELD SERVICE ROBOTI, P415.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Piasco N, 2019, IEEE INT CONF ROBOT, P9094, DOI 10.1109/ICRA.2019.8794221.
   Qianqian Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P757, DOI 10.1007/978-3-030-58452-8\_44.
   Revaud J, 2019, ADV NEUR IN, V32.
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275.
   Sarlin P.-E., 2021, P IEEE C COMP VIS PA, P3247.
   Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499.
   Sattler T, 2019, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR.2019.00342.
   Spencer J, 2020, PROC CVPR IEEE, P6458, DOI 10.1109/CVPR42600.2020.00649.
   Sun L, 2021, IEEE INT C INT ROBOT, P2635, DOI 10.1109/IROS51168.2021.9635886.
   Tang CR, 2020, PHARMACOLOGY, V105, P339, DOI 10.1159/000503865.
   Tang J., 2020, P C ROB LEARN.
   Valada A, 2018, IEEE INT CONF ROBOT, P6939, DOI 10.1109/ICRA.2018.8462979.
   von Stumberg L, 2020, INT CONF 3D VISION, P968, DOI 10.1109/3DV50981.2020.00107.
   von Stumberg L, 2020, IEEE ROBOT AUTOM LET, V5, P890, DOI 10.1109/LRA.2020.2965031.
   Xu BB, 2021, IEEE ROBOT AUTOM LET, V6, P223, DOI 10.1109/LRA.2020.3039216.
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4\_28.},
Number-of-Cited-References = {35},
Times-Cited = {1},
Usage-Count-Last-180-days = {6},
Usage-Count-Since-2013 = {6},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {XY1KG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000736739800005},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000787016500001,
Author = {Rozsypalek, Zdenek and Broughton, George and Linder, Pavel and Roucek,
   Tomas and Blaha, Jan and Mentzl, Leonard and Kusumam, Keerthy and
   Krajnik, Tomas},
Title = {Contrastive Learning for Image Registration in Visual Teach and Repeat
   Navigation},
Pages = {2975},
Journal = {SENSORS},
Year = {2022},
Volume = {22},
Number = {8},
Month = {APR},
Abstract = {Visual teach and repeat navigation (VT\&R) is popular in robotics thanks
   to its simplicity and versatility. It enables mobile robots equipped
   with a camera to traverse learned paths without the need to create
   globally consistent metric maps. Although teach and repeat frameworks
   have been reported to be relatively robust to changing environments,
   they still struggle with day-to-night and seasonal changes. This paper
   aims to find the horizontal displacement between prerecorded and
   currently perceived images required to steer a robot towards the
   previously traversed path. We employ a fully convolutional neural
   network to obtain dense representations of the images that are robust to
   changes in the environment and variations in illumination. The proposed
   model achieves state-of-the-art performance on multiple datasets with
   seasonal and day/night variations. In addition, our experiments show
   that it is possible to use the model to generate additional training
   examples that can be used to further improve the original model's
   robustness. We also conducted a real-world experiment on a mobile robot
   to demonstrate the suitability of our method for VT\&R.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Rozsypalek, Z (Corresponding Author), Czech Tech Univ, Fac Elect Engn, Artificial Intelligence Ctr, Prague 16627 6, Czech Republic.
   Rozsypalek, Zdenek; Broughton, George; Linder, Pavel; Roucek, Tomas; Blaha, Jan; Mentzl, Leonard; Krajnik, Tomas, Czech Tech Univ, Fac Elect Engn, Artificial Intelligence Ctr, Prague 16627 6, Czech Republic.
   Kusumam, Keerthy, Univ Nottingham, Dept Comp Sci, Jubilee Campus,7301 Wollaton Rd, Nottingham NG8 1BB, England.},
DOI = {10.3390/s22082975},
Article-Number = {2975},
EISSN = {1424-8220},
Keywords = {visual teach and repeat navigation; long-term autonomy; machine
   learning; contrastive learning; image representations},
Keywords-Plus = {LOCALIZATION; AUTONOMY},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {rozsyzde@fel.cvut.cz
   brouggeo@fel.cvut.cz
   lindepav@fel.cvut.cz
   tomas.roucek@fel.cvut.cz
   jan.blaha@fel.cvut.cz
   leonard.mentzl@fel.cvut.cz
   keerthy.kusumam2@nottingham.ac.uk
   krajnt1@fel.cvut.cz},
Affiliations = {Czech Technical University Prague; University of Nottingham},
ResearcherID-Numbers = {Krajnik, Tomas/P-9137-2014
   },
ORCID-Numbers = {Krajnik, Tomas/0000-0002-4408-7916
   Broughton, George/0000-0003-0071-5834
   Kusumam, Keerthy/0000-0002-7464-3784},
Funding-Acknowledgement = {Czech Science Foundation {[}20-27034J]; CzechMinistry of Education by OP
   VVV {[}CZ.02.1.01/0.0/0.0/16 019/0000765]},
Funding-Text = {This research was funded by Czech Science Foundation grant number
   20-27034J `ToltaTempo'. The computational resources used for the
   research were funded by the CzechMinistry of Education by OP VVV funded
   project CZ.02.1.01/0.0/0.0/16 019/0000765 ``Research Center for
   Informatics{''}.},
Cited-References = {Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014.
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339.
   Broughton G., 2021, P 2021 EUR C MOB ROB, P1, DOI {[}10.1109/ECMR50962.2021.9568832, DOI 10.1109/ECMR50962.2021.9568832].
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1\_56.
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8\_13.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Cen MB, 2018, IEEE IMAGE PROC, P3718, DOI 10.1109/ICIP.2018.8451102.
   Chen T, 2020, PR MACH LEARN RES, V119.
   Chen Z., 2010, MOB ROBOT NAVIG, P427, DOI {[}10.5772/8981, DOI 10.5772/8981].
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Clement L, 2017, J FIELD ROBOT, V34, P74, DOI 10.1002/rob.21655.
   Corporation N.B, 2013, NORDL MIN MIN SEAS S.
   Dall'Osto D, 2021, IEEE INT C INT ROBOT, P500, DOI 10.1109/IROS51168.2021.9636334.
   Dayoub F, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3364, DOI 10.1109/IROS.2008.4650701.
   Debeunne C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072068.
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060.
   Dosovitskiy A., 2020, ARXIV201011929.
   Fox D, 2001, STAT ENG IN, P401.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Girshick, 2020, P IEEE CVF C COMP VI, P9726, DOI DOI 10.1109/CVPR42600.2020.00975.
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630.
   Halodova L., 2019, P 2019 IEEERSJ INT C.
   Halodova L, 2019, LECT NOTES COMPUT SC, V11472, P456, DOI 10.1007/978-3-030-14984-0\_34.
   Han Y, 2020, IEEE PHOTON CONF.
   Hawes N, 2017, IEEE ROBOT AUTOM MAG, V24, P146, DOI 10.1109/MRA.2016.2636359.
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90.
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3\_7.
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI {[}10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372].
   Ichida A.Y., P 2018 INT JOINT C N, DOI {[}10.1109/ijcnn.2018.8489433, DOI 10.1109/IJCNN.2018.8489433].
   Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002.
   Karoly AI, 2021, IEEE T SYST MAN CY-S, V51, P266, DOI 10.1109/TSMC.2020.3018325.
   Khosla P., 2020, ADV NEURAL INF PROCE.
   Kingma D. P., 2014, 3 INT C LEARN REPR, DOI DOI 10.1145/1830483.1830503.
   Krajnik T., 2013, P 2013 16 INT C ADV, P1.
   Krajnik T., 2015, P 2015 EUR C MOB ROB, P1.
   Krajnik T, 2018, IEEE INT C INT ROBOT, P1657, DOI 10.1109/IROS.2018.8593803.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Krajnik T, 2017, ROBOT AUTON SYST, V88, P127, DOI 10.1016/j.robot.2016.11.011.
   Krajnik T, 2010, J FIELD ROBOT, V27, P511, DOI 10.1002/rob.20354.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386.
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Neubert P, 2015, EUR SIGNAL PR CONF, P614, DOI 10.1109/EUSIPCO.2015.7362456.
   Neubert P, 2015, ROBOT AUTON SYST, V69, P15, DOI 10.1016/j.robot.2014.08.005.
   Nitsche Matias, 2014, Advances in Autonomous Robotics Systems. 15th Annual Conference (TAROS 2014). Proceedings: LNCS 8717, P13, DOI 10.1007/978-3-319-10401-0\_2.
   Paszke A, 2019, ADV NEUR IN, V32.
   Rosen DM, 2016, IEEE INT CONF ROBOT, P1063, DOI 10.1109/ICRA.2016.7487237.
   Spencer J, 2020, PROC CVPR IEEE, P6458, DOI 10.1109/CVPR42600.2020.00649.
   Stibinger P, 2021, IEEE ROBOT AUTOM LET, V6, P2595, DOI 10.1109/LRA.2021.3061377.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Tan M., 2021, P INT C MACH LEARN J, V139, P10096.
   Thrun S., 2010, PROBABILISTIC ROBOTI.
   Thrun S., 1994, P IEEERSJ INT C INT, P201, DOI {[}10.1016/b978-044482250-5/50015-3, DOI 10.1016/B978-044482250-5/50015-3].
   Yang L., 2017, P 2017 INT C DIG IM, DOI {[}10.1109/dicta.2017.8227487, DOI 10.1109/DICTA.2017.8227487].
   Zhang ZC, 2021, INT J COMPUT VISION, V129, P821, DOI 10.1007/s11263-020-01399-8.},
Number-of-Cited-References = {58},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {0T5OA},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000787016500001},
OA = {gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000250915300070,
Author = {Martinson, E. and Schultz, A.},
Book-Group-Author = {IEEE},
Title = {Robotic discovery of the auditory scene},
Booktitle = {PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND
   AUTOMATION, VOLS 1-10},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2007},
Pages = {435-440},
Note = {IEEE International Conference on Robotics and Automation, Rome, ITALY,
   APR 10-14, 2007},
Abstract = {In this work, we describe an autonomous mobile robotic system for
   finding and investigating ambient noise sources in the environment.
   Motivated by the large negative effect of ambient noise sources on robot
   audition, the long-term goal is to provide awareness of the auditory
   scene to a robot, so that it may more effectively act to filter out the
   interference or re-position itself to increase the signal-to-noise
   ratio. Here, we concentrate on the discovery of new sources of sound
   through the use of mobility and directed investigation. This is
   performed in a two-step process. In the first step, a mobile robot first
   explores the surrounding acoustical environment, creating evidence grid
   representations to localize the most influential sound sources in the
   auditory scene. Then in the second step, the robot investigates each
   potential sound source location in the environment so as to improve the
   localization result, and identify volume and directionality
   characteristics of the sound source. Once every source has been
   investigated, a noise map of the entire auditory scene is created for
   use by the robot in avoiding areas of loud ambient noise when performing
   an auditory task.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Martinson, E (Corresponding Author), Georgia Inst Technol, Atlanta, GA 30332 USA.
   Martinson, E., Georgia Inst Technol, Atlanta, GA 30332 USA.
   Schultz, A., US Naval Res Lab, Washington, DC 20375 USA.},
DOI = {10.1109/ROBOT.2007.363825},
ISSN = {1050-4729},
ISBN = {978-1-4244-0601-2},
Keywords = {sound source localization; evidence grid; mobile robots; sound mapping},
Keywords-Plus = {OPTIC TECTUM},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {ebeowulf@cc.gatech.edu
   schultz@aic.nrl.navy.mil},
Affiliations = {University System of Georgia; Georgia Institute of Technology; United
   States Department of Defense; United States Navy; Naval Research
   Laboratory},
Funding-Acknowledgement = {Office of Naval Research {[}N0001406WX30002]},
Funding-Text = {This research was supported by the Office of Naval Research under work
   order number N0001406WX30002.},
Cited-References = {GERKEY B, 2006, PLAYER STAGE PROJECT.
   Huang J, 1999, ROBOT AUTON SYST, V27, P199, DOI 10.1016/S0921-8890(99)00002-0.
   HUGHES K, 1992, INT C INT ROB SYST I.
   Hyde PS, 2000, J COMP NEUROL, V421, P146, DOI 10.1002/(SICI)1096-9861(20000529)421:2<146::AID-CNE2>3.0.CO;2-5.
   MARTINSON E, 2004, P SPIE, V5609.
   MARTINSON E, 2006, INT C INT ROB SYST I.
   MUNGAMURU B, 2004, IEEE T SYSTEMS MAN C, V34.
   NAKADAI K, 2001, IEEE RSJ INT C INT R.
   Raichel D, 2000, SCI APPL ACOUSTICS.
   Rucci M, 1997, J NEUROSCI, V17, P334, DOI 10.1523/JNEUROSCI.17-01-00334.1997.
   SASAKI Y, 2006, INT C INT ROB SYST I.
   SCHULTZ A, 1998, IEEE INT C ROB AUT L.},
Number-of-Cited-References = {12},
Times-Cited = {11},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BGW23},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000250915300070},
OA = {Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000494942303026,
Author = {Kanji, Tanaka},
Editor = {Howard, A and Althoefer, K and Arai, F and Arrichiello, F and Caputo, B and Castellanos, J and Hauser, K and Isler, V and Kim, J and Liu, H and Oh, P and Santos, V and Scaramuzza, D and Ude, A and Voyles, R and Yamane, K and Okamura, A},
Book-Group-Author = {IEEE},
Title = {Detection-by-Localization: Maintenance-Free Change Object Detector},
DOI = {10.1109/ICRA.2019.8793482},
Booktitle = {2019 INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2019},
Pages = {4348-4355},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Montreal, CANADA, MAY 20-24, 2019},
Abstract = {Recent researches demonstrate that selflocalization performance is a
   very useful measure of likelihood-of-change (LoC) for change detection.
   In this paper, this ``detection-by-localization{''} scheme is studied in
   a novel generalized task of object-level change detection. In our
   framework, a given query image is segmented into object-level subimages
   (termed ``scene parts{''}), which are then converted to subimage-level
   pixel-wise LoC maps via the detection-by-localization scheme. Our
   approach models a self-localization system as a ranking function,
   outputting a ranked list of reference images, without requiring
   relevance score. Thanks to this new setting, we can generalize our
   approach to a broad class of self-localization systems. We further
   propose an aggregation of different self-localization results from
   different queries so as to achieve higher precision. Our ranking based
   self-localization model allows to fuse self-localization results from
   different modalities via an unsupervised rank fusion derived from a
   field of multi-modal information retrieval (MMR). Our framework does not
   rely on the raw-score-merging hypothesis. Challenging experiments of
   cross-season change detection using the publicly available North Campus
   Long-Term (NCLT) dataset validates the efficacy of our proposed method.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kanji, T (Corresponding Author), Univ Fukui, Fac Engn, Fukui, Japan.
   Kanji, Tanaka, Univ Fukui, Fac Engn, Fukui, Japan.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-5386-6026-3},
Keywords-Plus = {MOBILE ROBOTS; SEGMENTATION; NAVIGATION; GRADIENTS; ALIGNMENT; FUSION;
   ROBUST},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {tnkknj@u-fukui.ac.jp},
Affiliations = {University of Fukui},
Funding-Acknowledgement = {JSPS KAKENHI {[}26330297, 17K00361]},
Funding-Text = {Our work has been supported in part by JSPS KAKENHI Grant-in-Aid for
   Scientific Research (C) 26330297, and (C) 17K00361.},
Cited-References = {Alcantarilla PF, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII.
   Andrade-Cetto J, 2002, INT J PATTERN RECOGN, V16, P361, DOI 10.1142/S0218001402001745.
   Andreasson H, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3435.
   Arbuckle D, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P409, DOI 10.1109/IRDS.2002.1041424.
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0.
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040.
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1\_38.
   Barnes D, 2018, IEEE INT CONF ROBOT, P1894.
   Burgard W., 2012, 26 AAAI C ART INT, P2024.
   Burki M, 2018, IEEE INT VEH SYM, P682.
   Buscaldi D., 2008, CLEF WORKING NOTES.
   Carlevaris-Bianco N, 2016, INT J ROBOT RES, V35, P1023, DOI 10.1177/0278364915614638.
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184.
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414.
   Christiansen P, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16111904.
   Chum O, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPRW.2009.5206531.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Cormack GV, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P758, DOI 10.1145/1571941.1572114.
   Dalal N., 2005, 2005 IEEE COMPUTER S, P886, DOI {[}10.1109/CVPR.2005.177, DOI 10.1109/CVPR.2005.177].
   Drews P, 2010, IEEE INT CONF ROBOT, P3635, DOI 10.1109/ROBOT.2010.5509405.
   Duckett T., 2005, ROBOTICS SCI SYSTEMS, P17.
   Dymczyk M, 2015, IEEE INT C INT ROBOT, P2536, DOI 10.1109/IROS.2015.7353722.
   Dymczyk M, 2015, IEEE INT CONF ROBOT, P2767, DOI 10.1109/ICRA.2015.7139575.
   Eden I, 2008, LECT NOTES COMPUT SC, V5305, P172, DOI 10.1007/978-3-540-88693-8\_13.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Fehr Marius, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5237, DOI 10.1109/ICRA.2017.7989614.
   Finman R, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P178, DOI 10.1109/ECMR.2013.6698839.
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616.
   Garcia-Fidalgo Emilio, 2018, IEEE Robotics and Automation Letters, V3, P3051, DOI 10.1109/LRA.2018.2849609.
   Glover A., 1998, ROBOTICS AUTOMATION.
   Glover A, 2012, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ICRA.2012.6224843.
   Gueguen L, 2015, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2015.7298737.
   Hahnel D, 2003, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ROBOT.2003.1241816.
   Hartmann W, 2014, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2014.9.
   Hsu DF, 2005, INFORM RETRIEVAL, V8, P449, DOI 10.1007/s10791-005-6994-4.
   Im J, 2008, INT J REMOTE SENS, V29, P399, DOI 10.1080/01431160601075582.
   Imhof M, 2018, INFORM RETRIEVAL J, V21, P81, DOI 10.1007/s10791-017-9322-x.
   Jiang YN, 2012, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2012.6248042.
   Kanji T, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4497, DOI 10.1109/IROS.2016.7759662.
   Kanji T, 2015, IEEE INT CONF ROBOT, P6359, DOI 10.1109/ICRA.2015.7140092.
   Khan S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2008.
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004.
   Kosecka J., 2012, AS C COMP VIS, P590.
   Krajnik T, 2014, IEEE INT CONF ROBOT, P3706, DOI 10.1109/ICRA.2014.6907396.
   Li W., 2006, P ICPR.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Luft L, 2018, IEEE ROBOT AUTOM LET, V3, P1299, DOI 10.1109/LRA.2018.2797317.
   Mangelson JG, 2018, IEEE INT CONF ROBOT, P2916.
   Manso LJ, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/57360.
   Meng FM, 2017, IEEE T IMAGE PROCESS, V26, P4019, DOI 10.1109/TIP.2017.2708839.
   Merrill N, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Montague M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P538.
   Muhlfellner P, 2016, J FIELD ROBOT, V33, P561, DOI 10.1002/rob.21595.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019.
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040.
   Palazzolo E., 2018, P IEEE INT C ROB AUT.
   Paton M, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1918, DOI 10.1109/IROS.2016.7759303.
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598.
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698.
   Redmon J, 2018, YOLO V 3.
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690.
   Ross P, 2014, IEEE INT CONF ROBOT, P1699, DOI 10.1109/ICRA.2014.6907080.
   Saarinen J, 2012, IEEE INT C INT ROBOT, P3489, DOI 10.1109/IROS.2012.6385629.
   Shah M, 2015, IMAGE VISION COMPUT, V38, P52, DOI 10.1016/j.imavis.2015.02.001.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Sofman B, 2011, J FIELD ROBOT, V28, P589, DOI 10.1002/rob.20396.
   Stent S, 2016, MACH VISION APPL, V27, P319, DOI 10.1007/s00138-014-0648-8.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Sugimoto T., 2018, INT VEH S IEEE, P397.
   Takahashi Y., 2018, INT TRANSP SYST ITSC.
   Taneja A, 2015, IEEE T PATTERN ANAL, V37, P2193, DOI 10.1109/TPAMI.2015.2404834.
   Thrun S, 2000, TECH REP.
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400.
   van de Wouw DWJM, 2016, IEEE ROBOT AUTOM LET, V1, P361, DOI 10.1109/LRA.2016.2520561.
   Villegas M, 2015, LECT NOTES COMPUT SC, V9283, P444, DOI 10.1007/978-3-319-24027-5\_45.
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004.
   Xie HR, 2016, INFORM PROCESS MANAG, V52, P61, DOI 10.1016/j.ipm.2015.03.001.
   Yamauchi B, 1996, IEEE T SYST MAN CY B, V26, P496, DOI 10.1109/3477.499799.
   Yan R., 2006, THESIS.
   Yang N., 2018, INT TRANSP SYST ITSC.
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749.},
Number-of-Cited-References = {84},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BO1CN},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000494942303026},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000568683900012,
Author = {Zhang, Shengkai and Wang, Wei and Tang, Sheyang and Jin, Shi and Jiang,
   Tao},
Title = {Robot-Assisted Backscatter Localization for IoT Applications},
Journal = {IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS},
Year = {2020},
Volume = {19},
Number = {9},
Pages = {5807-5818},
Month = {SEPT},
Note = {IEEE Global Communications Conference (GLOBECOM), Waikoloa, HI, DEC
   09-13, 2019},
Abstract = {Recent years have witnessed the rapid proliferation of backscatter
   technologies that realize the ubiquitous and long-term connectivity to
   empower smart cities and smart homes. Localizing such backscatter tags
   is crucial for IoT-based smart applications. However, current
   backscatter localization systems require prior knowledge of the site,
   either a map or landmarks with known positions, which is laborious for
   deployment. To empower universal localization service, this paper
   presents Rover, an indoor localization system that localizes multiple
   backscatter tags without any start-up cost using a robot equipped with
   inertial sensors. Rover runs in a joint optimization framework, fusing
   measurements from backscattered WiFi signals and inertial sensors to
   simultaneously estimate the locations of both the robot and the
   connected tags. Our design addresses practical issues including
   interference among multiple tags, real-time processing, as well as the
   data marginalization problem in dealing with degenerated motions. We
   prototype Rover using off-the-shelf WiFi chips and customized
   backscatter tags. Our experiments show that Rover achieves localization
   accuracies of 39.3 cm for the robot and 74.6 cm for the tags.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article; Proceedings Paper},
Language = {English},
Affiliation = {Wang, W (Corresponding Author), Huazhong Univ Sci \& Technol, Sch Elect Informat \& Commun, Wuhan 430074, Peoples R China.
   Zhang, Shengkai; Wang, Wei; Tang, Sheyang; Jiang, Tao, Huazhong Univ Sci \& Technol, Sch Elect Informat \& Commun, Wuhan 430074, Peoples R China.
   Jin, Shi, Southeast Univ, Sch Informat Sci \& Engn, Nanjing 211189, Peoples R China.},
DOI = {10.1109/TWC.2020.2997393},
ISSN = {1536-1276},
EISSN = {1558-2248},
Keywords = {Wireless fidelity; Backscatter; Interference; Robot sensing systems;
   Receivers; Antenna arrays; Backscatter; localization; inertial sensor;
   channel state information},
Keywords-Plus = {NAVIGATION; SYSTEMS; AOA},
Research-Areas = {Engineering; Telecommunications},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Telecommunications},
Author-Email = {szhangk@hust.edu.cn
   weiwangw@hust.edu.cn
   sheyangtang@hust.edu.cn
   jinshi@seu.edu.cn
   taojiang@hust.edu.cn},
Affiliations = {Huazhong University of Science \& Technology; Southeast University -
   China},
ResearcherID-Numbers = {Jin, Shi/ABG-5416-2021},
Funding-Acknowledgement = {National Key Research and Development Program of China
   {[}2019YFB180003400]; Young Elite Scientists Sponsorship Program by CAST
   {[}2018QNRC001]; National Science Foundation of China {[}91738202]},
Funding-Text = {This work was supported in part by the National Key Research and
   Development Program of China under Grant 2019YFB180003400, in part by
   the Young Elite Scientists Sponsorship Program by CAST under Grant
   2018QNRC001, and in part by the National Science Foundation of China
   with Grant 91738202.},
Cited-References = {Ai Y, 2019, INT CONF ACOUST SPEE, P7025, DOI 10.1109/ICASSP.2019.8683016.
   Amato F, 2018, IEEE T WIREL COMMUN, V17, P2718, DOI 10.1109/TWC.2018.2801803.
   Bharadia D, 2015, ACM SIGCOMM COMP COM, V45, P283, DOI 10.1145/2829988.2787490.
   Dube R, 2017, IEEE INT C INT ROBOT, P1004, DOI 10.1109/IROS.2017.8202268.
   Ferris B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2480.
   Forster EC, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P1, DOI 10.1109/PCS.2015.7170035.
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8.
   Gentner C, 2016, IEEE T WIREL COMMUN, V15, P6104, DOI 10.1109/TWC.2016.2578336.
   Guo J, 2018, IEEE T WIREL COMMUN, V17, P6837, DOI 10.1109/TWC.2018.2864741.
   Halperin D, 2011, ACM SIGCOMM COMP COM, V41, P53, DOI 10.1145/1925861.1925870.
   He YA, 2017, IEEE J SEL AREA COMM, V35, P1132, DOI 10.1109/JSAC.2017.2679659.
   Hess W, 2016, IEEE INT CONF ROBOT, P1271, DOI 10.1109/ICRA.2016.7487258.
   Hessar M, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P271.
   Huang AS, 2017, SPRINGER TRAC ADV RO, V100, DOI 10.1007/978-3-319-29363-9\_14.
   Huang J, 2011, IEEE INT CONF ROBOT, P1038.
   Kellogg B., 2016, MOB COMPUT COMMUN RE, P38.
   Kellogg B, 2014, ACM SIGCOMM COMP COM, V44, P607, DOI {[}10.1145/2619239.2626319, 10.1145/2740070.2626319].
   Kotaru M, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P251, DOI 10.1145/3143361.3143379.
   Kotaru M, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P269, DOI 10.1145/2785956.2787487.
   Li B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS (MFI), P244.
   Li XH, 2019, IEEE T WIREL COMMUN, V18, P4254, DOI 10.1109/TWC.2019.2922264.
   Lin Y, 2018, J FIELD ROBOT, V35, P23, DOI 10.1002/rob.21732.
   Liu V, 2013, ACM SIGCOMM COMP COM, V43, P39, DOI 10.1145/2534169.2486015.
   Liu WC, 2018, IEEE T WIREL COMMUN, V17, P5713, DOI 10.1109/TWC.2018.2849372.
   Lu X, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.106872.
   Luo ZH, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P765.
   Lupton T, 2012, IEEE T ROBOT, V28, P61, DOI 10.1109/TRO.2011.2170332.
   Ma YF, 2017, SIGCOMM `17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P335, DOI 10.1145/3098822.3098847.
   Peng Y, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM `18), P147, DOI 10.1145/3230543.3230567.
   Sabatini AM, 2006, IEEE T BIO-MED ENG, V53, P1346, DOI 10.1109/TBME.2006.875664.
   Shen SJ, 2016, SPRINGER TRAC ADV RO, V109, P211, DOI 10.1007/978-3-319-23778-7\_15.
   Taponecco L, 2011, IEEE T WIREL COMMUN, V10, P2207, DOI 10.1109/TWC.2011.042211.100966.
   Vasish D, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI `16), P165.
   Venkatnarayan Raghav H., 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3328918.
   Wang J, 2013, ACM SIGCOMM COMP COM, V43, P51, DOI 10.1145/2534169.2486029.
   Wang XY, 2017, IEEE T VEH TECHNOL, V66, P763, DOI 10.1109/TVT.2016.2545523.
   Wang Y, 2018, IEEE T WIREL COMMUN, V17, P1242, DOI 10.1109/TWC.2017.2777457.
   Xia XJ, 2019, PROCEEDINGS OF THE 17TH CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS `19), P192, DOI 10.1145/3356250.3360024.
   Xie Y., 2019, P IEEE 90 VEH TECHN, P1.
   Xu CR, 2018, IEEE SIGNAL PROC MAG, V35, P16, DOI 10.1109/MSP.2018.2848361.
   Zhang PY, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM `16), P370, DOI 10.1145/2934872.2934901.
   Zhang Pengyu, 2016, P 14 ACM C EMB NETW.
   Zhang SZ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0216879.},
Number-of-Cited-References = {43},
Times-Cited = {7},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {24},
Journal-ISO = {IEEE Trans. Wirel. Commun.},
Doc-Delivery-Number = {NN3IC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000568683900012},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000544658404043,
Author = {Pang, Su and Kent, Daniel and Morris, Daniel and Radha, Hayder},
Book-Group-Author = {IEEE},
Title = {FLAME: Feature-Likelihood Based Mapping and Localization for Autonomous
   Vehicles},
DOI = {10.1109/IROS40897.2019.8968082},
Booktitle = {2019 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS)},
Series = {IEEE International Conference on Intelligent Robots and Systems},
Year = {2019},
Pages = {5312-5319},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Macau, PEOPLES R CHINA, NOV 04-08, 2019},
Abstract = {Accurate vehicle localization is arguably the most critical and
   fundamental task for autonomous vehicle navigation. While dense 3D
   point-cloud-based maps enable precise localization, they impose
   significant storage and transmission burdens when used in city-scale
   environments. In this paper, we propose a highly compressed
   representation for LiDAR maps, along with an efficient and robust
   real-time alignment algorithm for on-vehicle LiDAR scans. The proposed
   mapping framework, which we refer to as Feature Likelihood Acquisition
   Map Emulation (FLAME), requires less than 0.1\% of the storage space of
   the original 3D point cloud map. In essence, FLAME emulates an original
   map through feature likelihood functions. In particular, FLAME models
   planar, pole and curb features. These three feature classes are
   long-term stable, distinct and common among vehicular roadways.
   Multiclass feature points are extracted from LiDAR scans through feature
   detection. A new multiclass-based point-to-distribution alignment method
   is proposed to find the association and alignment between the multiclass
   feature points and the FLAME map. The experimental results show that the
   proposed framework can achieve the same level of accuracy (less than
   10cm) as the 3D point cloud based localization.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Pang, S (Corresponding Author), Michigan State Univ, Coll Engn, Dept Elect \& Comp Engn, 220 Trowbridge Rd, E Lansing, MI 48824 USA.
   Pang, Su; Kent, Daniel; Morris, Daniel; Radha, Hayder, Michigan State Univ, Coll Engn, Dept Elect \& Comp Engn, 220 Trowbridge Rd, E Lansing, MI 48824 USA.},
ISSN = {2153-0858},
ISBN = {978-1-7281-4004-9},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory \& Methods; Robotics},
Author-Email = {pangsu@msu.edu
   kentdan@egr.msu.edu
   dmorris@msu.edu
   radha@egr.msu.edu},
Affiliations = {Michigan State University},
ORCID-Numbers = {Morris, Daniel/0000-0003-3032-5511},
Cited-References = {Biber P, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2743, DOI 10.1109/iros.2003.1249285.
   Cadena C., 2017, PROC IEEE INT C ROBO, P5266.
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754.
   Caesar H., 2019, ARXIV190311027.
   Chen TT, 2015, IEEE INT VEH SYM, P241, DOI 10.1109/IVS.2015.7225693.
   Chen TT, 2014, J INTELL ROBOT SYST, V76, P563, DOI 10.1007/s10846-013-9889-4.
   Douillard B., 2011 IEEE INT C ROB, P2798, DOI {[}10.1109/ICRA.2011.5979818, DOI 10.1109/ICRA.2011.5979818].
   Dube R., 2018, IEEE ROBOT AUTONT LE.
   Fernandez C, 2015, IEEE INT VEH SYM, P579, DOI 10.1109/IVS.2015.7225747.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Gruyer D, 2014, IEEE INT VEH SYM, P674, DOI 10.1109/IVS.2014.6856528.
   Gu YL, 2016, IEEE T VEH TECHNOL, V65, P4274, DOI 10.1109/TVT.2015.2497001.
   Himmelsbach M, 2010, IEEE INT VEH SYM, P560, DOI 10.1109/IVS.2010.5548059.
   Javanmardi E, 2017, IEEE INT VEH SYM, P437, DOI 10.1109/IVS.2017.7995757.
   Kammel S, 2008, J FIELD ROBOT, V25, P615, DOI 10.1002/rob.20252.
   Kuutti S, 2018, IEEE INTERNET THINGS, V5, P829, DOI 10.1109/JIOT.2018.2812300.
   Leonard J, 2008, J FIELD ROBOT, V25, P727, DOI 10.1002/rob.20262.
   Levinson J., 2007, ROBOTICS SCI SYSTEMS, V4, P1.
   Levinson J, 2010, IEEE INT CONF ROBOT, P4372, DOI 10.1109/ROBOT.2010.5509700.
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258.
   Morris DD, 2016, PROC SPIE, V9837, DOI 10.1117/12.2224545.
   Ruchti P, 2015, IEEE INT CONF ROBOT, P5260, DOI 10.1109/ICRA.2015.7139932.
   Spangenberg R, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2161, DOI 10.1109/IROS.2016.7759339.
   STEPHENS RS, 1991, IMAGE VISION COMPUT, V9, P66, DOI 10.1016/0262-8856(91)90051-P.
   Su P., 2018, IEEE CONN AUT VEH S.
   Thom S., 2006, INT J ROBOT RES, V25, P403.
   Urmson C, 2009, SPRINGER TRAC ADV RO, V56, P1.
   Wang P, 2018, PROC CVPR IEEE, P5860, DOI 10.1109/CVPR.2018.00614.
   Wolcott RW, 2017, INT J ROBOT RES, V36, P292, DOI 10.1177/0278364917696568.
   Yozevitch R, 2014, IEEE T INTELL TRANSP, V15, P1113, DOI 10.1109/TITS.2013.2294537.
   Zaganidis A, 2018, IEEE ROBOT AUTOM LET, V3, P2942, DOI 10.1109/LRA.2018.2848308.
   Zhang MF, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P615, DOI 10.1109/3DV.2015.76.
   Zhang WD, 2010, IEEE INT VEH SYM, P845, DOI 10.1109/IVS.2010.5548134.
   Zhang WM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060501.},
Number-of-Cited-References = {34},
Times-Cited = {0},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BP2QS},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000544658404043},
DA = {2022-05-17},
}

@article{ WOS:000462540400138,
Author = {Bennetts, Victor Hernandez and Kamarudin, Kamarulzaman and Wiedemann,
   Thomas and Kucner, Tomasz Piotr and Somisetty, Sai Lokesh and
   Lilienthal, Achim J.},
Title = {Multi-Domain Airflow Modeling and Ventilation Characterization Using
   Mobile Robots, Stationary Sensors and Machine Learning},
Journal = {SENSORS},
Year = {2019},
Volume = {19},
Pages = {1119},
Number = {5},
Month = {MAR 1},
Abstract = {Ventilation systems are critically important components of many public
   buildings and workspaces. Proper ventilation is often crucial for
   preventing accidents, such as explosions in mines and avoiding health
   issues, for example, through long-term exposure to harmful respirable
   matter. Validation and maintenance of ventilation systems is thus of key
   interest for plant operators and authorities. However, methods for
   ventilation characterization, which allow us to monitor whether the
   ventilation system in place works as desired, hardly exist. This article
   addresses the critical challenge of ventilation
   characterizationmeasuring and modelling air flow at micro-scalesthat is,
   creating a high-resolution model of wind speed and direction from
   airflow measurements. Models of the near-surface micro-scale flow fields
   are not only useful for ventilation characterization, but they also
   provide critical information for planning energy-efficient paths for
   aerial robots and many applications in mobile robot olfaction. In this
   article we propose a heterogeneous measurement system composed of
   static, continuously sampling sensing nodes, complemented by localized
   measurements, collected during occasional sensing missions with a mobile
   robot. We introduce a novel, data-driven, multi-domain airflow modelling
   algorithm that estimates (1) fields of posterior distributions over wind
   direction and speed (ventilation maps, spatial domain); (2) sets of
   ventilation calendars that capture the evolution of important airflow
   characteristics at measurement positions (temporal domain); and (3) a
   frequency domain analysis that can reveal periodic changes of airflow in
   the environment. The ventilation map and the ventilation calendars make
   use of an improved estimation pipeline that incorporates a wind sensor
   model and a transition model to better filter out sporadic, noisy
   airflow changes. These sudden changes may originate from turbulence or
   irregular activity in the surveyed environment and can, therefore,
   disturb modelling of the relevant airflow patterns. We tested the
   proposed multi-domain airflow modelling approach with simulated data and
   with experiments in a semi-controlled environment and present results
   that verify the accuracy of our approach and its sensitivity to
   different turbulence levels and other disturbances. Finally, we deployed
   the proposed system in two different real-world industrial environments
   (foundry halls) with different ventilation regimes for three weeks
   during full operation. Since airflow ground truth cannot be obtained, we
   present a qualitative discussion of the generated airflow models with
   plant operators, who concluded that the computed models accurately
   depicted the expected airflow patterns and are useful to understand how
   pollutants spread in the work environment. This analysis may then
   provide the basis for decisions about corrective actions to avoid
   long-term exposure of workers to harmful respirable matter.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Bennetts, VH (Corresponding Author), Orebro Univ, Mobile Robot \& Olfact Lab, S-70281 Orebro, Sweden.
   Bennetts, Victor Hernandez; Kucner, Tomasz Piotr; Lilienthal, Achim J., Orebro Univ, Mobile Robot \& Olfact Lab, S-70281 Orebro, Sweden.
   Kamarudin, Kamarulzaman, Univ Malaysia Perlis, Sch Mechatron Engn, Ctr Excellence Adv Sensor Technol, Arau Perlis 02600, Malaysia.
   Wiedemann, Thomas, German Aerosp Ctr, Inst Commun \& Nav, D-82234 Oberpfaffenhofen, Germany.
   Somisetty, Sai Lokesh, Sastra Univ, Dept Mechatron, Thanjavur 613401, India.},
DOI = {10.3390/s19051119},
Article-Number = {1119},
EISSN = {1424-8220},
Keywords = {airflow modeling; ventilation; mobile robotics; static sensor networks;
   environmental monitoring; machine learning},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {victor.hernandez@oru.se
   kamarulzaman@unimap.edu.my
   Thomas.Wiedemann@dlr.de
   Tomasz.Kucner@oru.se
   slvslokesh@gmail.com
   achim.lilienthal@oru.se},
Affiliations = {Orebro University; University of Malaysia Perlis; Helmholtz Association;
   German Aerospace Centre (DLR); Shanmugha Arts, Science, Technology \&
   Research Academy (SASTRA)},
ResearcherID-Numbers = {Lilienthal, Achim/AAB-1119-2019
   Lilienthal, Achim/AAO-6832-2020
   Kucner, Tomasz Piotr/AAH-3022-2020
   },
ORCID-Numbers = {Lilienthal, Achim/0000-0003-0217-9326
   Kucner, Tomasz Piotr/0000-0002-9503-0602
   KAMARUDIN, KAMARULZAMAN/0000-0001-7764-0821
   Hernandez Bennetts, Victor/0000-0001-5061-5474},
Funding-Acknowledgement = {project SURVEYOR (Vinnova) {[}2017-05468]; Strategic Innovation Program
   STRIM; joint venture of Vinnova, Formas and Energy Agency (Sweden)},
Funding-Text = {This work was funded by the project SURVEYOR (Vinnova, project number
   2017-05468), which was carried out within the Strategic Innovation
   Program STRIM, a joint venture of Vinnova, Formas and Energy Agency
   (Sweden).},
Cited-References = {Al-Sabban W.H., 2012, P IEEE RSJ INT C INT.
   Anand Y, 2016, RENEW SUST ENERG REV, V57, P1174, DOI 10.1016/j.rser.2015.12.198.
   Bennetts VH, 2017, IEEE ROBOT AUTOM LET, V2, P1117, DOI 10.1109/LRA.2017.2661803.
   Berens P, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i10.
   Carta JA, 2007, RENEW ENERG, V32, P518, DOI 10.1016/j.renene.2006.05.005.
   Carta JA, 2008, ENERG CONVERS MANAGE, V49, P897, DOI 10.1016/j.enconman.2007.10.017.
   Chatfield C., 2003, ANAL TIME SERIES INT.
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568.
   Drobinski P, 2015, BOUND-LAY METEOROL, V157, P97, DOI 10.1007/s10546-015-0035-7.
   Ertel H., 1929, Gerlands Beitrage zur Geophysik, V23, P15.
   Gressel MG, 1997, AM IND HYG ASSOC J, V58, P354, DOI 10.1202/0002-8894(1997)058<0354:AEOALE>2.0.CO;2.
   Hernandez V., 2016, P IEEE RSJ INT C INT.
   Jammalamadaka S. R., 2001, TOPICS CIRCULAR STAT.
   Justus C., 1978, WINDS WIND SYSTEM PE.
   Khan SS, 2010, LECT NOTES ARTIF INT, V6206, P188.
   Kowadlo G, 2009, ROBOT AUTON SYST, V57, P723, DOI 10.1016/j.robot.2008.10.019.
   Krajnik T, 2017, IEEE T ROBOT, V33, P964, DOI 10.1109/TRO.2017.2665664.
   Kucner TP, 2017, IEEE ROBOT AUTOM LET, V2, P1093, DOI 10.1109/LRA.2017.2660060.
   Manor A, 2015, ATMOS RES, V164, P27, DOI 10.1016/j.atmosres.2015.04.014.
   Mardia K.V., 2000, DIRECTIONAL STAT.
   Marjovi A, 2015, 2015 INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING IN SENSOR SYSTEMS (DCOSS), P11, DOI 10.1109/DCOSS.2015.32.
   Nadaraya E. A., 1964, THEORY PROBAB ITS AP, V9, P141, DOI {[}DOI 10.1137/1109020, 10.1137/1109020].
   Neumann P.P., 2014, P 13 INT C INT AUT S, P1.
   Neumann PP, 2013, ADV ROBOTICS, V27, P725, DOI 10.1080/01691864.2013.779052.
   Reggente M, 2010, IEEE SENSOR, P999, DOI 10.1109/ICSENS.2010.5690924.
   Rossi AP, 2016, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ANIMAL-COMPUTER INTERACTION, ACI 2016, DOI 10.1145/2995257.3012019.
   Saarinen J, 2013, IEEE INT C INT ROBOT, P382, DOI 10.1109/IROS.2013.6696380.
   Schaffernicht Erik, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2659, DOI 10.1109/ICRA.2017.7989310.
   Silverman B., 1986, DENSITY ESTIMATION S.
   Spera DA, 1994, WIND TURBINE TECHNOL.
   Syono S., 1966, J METEOROL SOC JPN, V44, P89, DOI {[}10.2151/jmsj1965.44.2\_89, DOI 10.2151/JMSJ1965.44.2\_89].
   TAKLE ES, 1978, J APPL METEOROL, V17, P556, DOI 10.1175/1520-0450(1978)017<0556:NOTUOW>2.0.CO;2.
   TULLER SE, 1984, J CLIM APPL METEOROL, V23, P124, DOI 10.1175/1520-0450(1984)023<0124:TCOWVT>2.0.CO;2.
   Xue YK, 2014, ATMOS RES, V147, P68, DOI 10.1016/j.atmosres.2014.05.001.
   Zhang S., 1996, COMPUTATION SPECIAL.},
Number-of-Cited-References = {35},
Times-Cited = {0},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {6},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {HQ6PO},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000462540400138},
OA = {Green Submitted, Green Published, gold},
DA = {2022-05-17},
}

@inproceedings{ WOS:000570976400004,
Author = {Mu, Beipeng and Agha-mohammadi, Ali-akbar and Paull, Liam and Graham,
   Matthew and How, Jonathan and Leonard, John},
Editor = {Kavraki, LE and Hsu, D and Buchli, J},
Title = {Two-Stage Focused Inference for Resource-Constrained Collision-Free
   Navigation},
Url = {http://hdl.handle.net/1721.1/97917},
Booktitle = {ROBOTICS: SCIENCE AND SYSTEMS XI},
Year = {2015},
Note = {11th Conference on Robotics - Science and Systems, Sapienza Univ Rome,
   Rome, ITALY, JUL 13-17, 2015},
Abstract = {Long-term operations of resource-constrained robots typically require
   hard decisions be made about which data to process and/or retain. The
   question then arises of how to choose which data is most useful to keep
   to achieve the task at hand. As spacial scale grows, the size of the map
   will grow without bound, and as temporal scale grows, the number of
   measurements will grow without bound. In this work, we present the first
   known approach to tackle both of these issues.
   The approach has two stages. First, a subset of the variables (focused
   variables) is selected that are most useful for a particular task.
   Second, a task-agnostic and principled method (focused inference) is
   proposed to select a subset of the measurements that maximizes the
   information over the focused variables. The approach is then applied to
   the specific task of robot navigation in an obstacle-laden environment.
   A landmark selection method is proposed to minimize the probability of
   collision and then select the set of measurements that best localizes
   those landmarks. It is shown that the two-stage approach outperforms
   both only selecting measurement and only selecting landmarks in terms of
   minimizing the probability of collision. The performance improvement is
   validated through detailed simulation and real experiments on a Pioneer
   robot.},
Publisher = {MIT PRESS},
Address = {ONE ROGERS ST, CAMBRIDGE, MA 02142 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Mu, BP (Corresponding Author), MIT, Lab Informat \& Decis Syst, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Mu, Beipeng; Agha-mohammadi, Ali-akbar; Graham, Matthew; How, Jonathan, MIT, Lab Informat \& Decis Syst, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Paull, Liam; Leonard, John, MIT, Comp Sci \& Artificial Intelligence Lab, Cambridge, MA 02139 USA.},
ISBN = {978-0-9923747-1-6},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; LANDMARK SELECTION; MOTION UNCERTAINTY},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {mubp@mit.edu
   aliapha@mit.edu
   lpaull@mit.edu
   mcgraham@mit.edu
   jhow@mit.edu
   jleonard@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT); Massachusetts Institute of
   Technology (MIT)},
Funding-Acknowledgement = {ARO MURI {[}W911NF-11-1-0391]; ONR {[}N00014-11-1-0688]; NSF
   {[}IIS-1318392]},
Funding-Text = {This research is supported in part by ARO MURI grant W911NF-11-1-0391,
   ONR grant N00014-11-1-0688 and NSF Award IIS-1318392.},
Cited-References = {Agha-Mohammadi AA, 2014, INT J ROBOT RES, V33, P268, DOI 10.1177/0278364913501564.
   Bishop C. M., 2007, PATTERN RECOGNITION.
   Blackmore L, 2011, IEEE T ROBOT, V27, P1080, DOI 10.1109/TRO.2011.2161160.
   Carlevaris-Bianco N, 2013, IEEE INT CONF ROBOT, P5748, DOI 10.1109/ICRA.2013.6631403.
   Carlone L, 2014, IEEE INT C INT ROBOT, P2667, DOI 10.1109/IROS.2014.6942927.
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768.
   Dissanayake G., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1009, DOI 10.1109/ROBOT.2000.844732.
   Friedman N., 2009, PROBABILISTIC GRAPHI.
   Frintrop S, 2008, IEEE T ROBOT, V24, P1054, DOI 10.1109/TRO.2008.2004977.
   Hochdorfer S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P382, DOI 10.1109/IROS.2009.5354433.
   Huang GQ, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P150, DOI 10.1109/ECMR.2013.6698835.
   Huang YF, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1426, DOI 10.1109/IROS.2009.5354168.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706.
   Kim Ayoung, 2014, INT J ROBOTICS RES.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Kurniawati H, 2012, AUTON ROBOT, V33, P255, DOI 10.1007/s10514-012-9307-y.
   Lerner R, 2007, IEEE T ROBOT, V23, P494, DOI 10.1109/TRO.2007.895070.
   Luders Brandon D., 2014, THESIS.
   MacKay DJC., 2002, INFORM THEORY INFERE.
   Mazuran M., 2014, ROBOTICS SCI SYSTEMS, P1.
   Mourikis AI, 2006, INT J ROBOT RES, V25, P1273, DOI 10.1177/0278364906072515.
   Prentice S., 2009, INT J ROBOTICS RES.
   Rosen DM, 2014, IEEE INT CONF ROBOT, P1261, DOI 10.1109/ICRA.2014.6907015.
   Sala P, 2006, IEEE T ROBOT, V22, P334, DOI 10.1109/TRO.2005.861480.
   Steiner Ted J., 2015, ROB AUT ICRA 2015 IE.
   Strasdat H., 2009, IEEE INT C ROB AUT K, P1410.
   van den Berg J, 2011, INT J ROBOT RES, V30, P895, DOI 10.1177/0278364911406562.
   Vial J, 2011, IEEE INT C INT ROBOT, P886, DOI 10.1109/IROS.2011.6048728.
   Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001.
   Zhang Sen, INT ROB SYST IROS 20, P1175.},
Number-of-Cited-References = {31},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BP9YE},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000570976400004},
DA = {2022-05-17},
}

@inproceedings{ WOS:000377221101048,
Author = {Murphy, Liz and Sibley, Gabe},
Book-Group-Author = {IEEE},
Title = {Incremental Unsupervised Topological Place Discovery},
DOI = {10.1109/ICRA.2014.6907022},
Booktitle = {2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2014},
Pages = {1312-1318},
Note = {IEEE International Conference on Robotics and Automation (ICRA), Hong
   Kong, PEOPLES R CHINA, MAY 31-JUN 07, 2014},
Abstract = {This paper describes an online place discovery and recognition engine
   that fuses information over time to create topologically distinct
   places. A key motivation is the recognition that a single image may be a
   poor exemplar of what constitutes a place. Images are not `places' nor
   are they `documents'. Instead, by treating image-sequences as a
   multi-modal distribution over topics - and by discovering topics
   incrementally and online - it is possible to both reduce the memory
   footprint of place recognition systems, and to improve precision and
   recall. Distinctive key-places are represented by a cluster topics found
   from the covisibility graph of a relative simultaneous localization and
   mapping engine - key-places inherently span many images. A dynamic
   vocabulary of visual words and density based clustering is used to
   continually estimate a set of visual topics, changes in which drive the
   place-recognition process. The system is evaluated using an indoor robot
   sequence, a standard outdoor robot sequence and a long-term sequence
   from a static camera. Experiments demonstrate qualitatively distinct
   themes associated with discovered places - from common place types such
   as `hallway', or `desk-area', to temporal concepts such as `dusk',
   `dawn' or `mid-day'. Compared to traditional image-based
   place-recognition, this reduces the information that must be stored
   without reducing place-recognition performance.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Murphy, L (Corresponding Author), George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
   Murphy, Liz; Sibley, Gabe, George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4799-3685-4},
Research-Areas = {Automation \& Control Systems; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Robotics},
Author-Email = {liz\_murphy@gwu.edu},
Affiliations = {George Washington University},
Cited-References = {Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993.
   Chapoulie A, 2012, IEEE INT C INT ROBOT, P4288, DOI 10.1109/IROS.2012.6385962.
   Chou TC, 2008, IEEE T KNOWL DATA EN, V20, P289, DOI 10.1109/TKDE.2007.190702.
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226.
   Girdhar Y., 2012, 13 INT S EXP ROB ISE.
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649.
   Ila V, 2010, IEEE T ROBOT, V26, P78, DOI 10.1109/TRO.2009.2034435.
   Konolige K, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1156, DOI 10.1109/IROS.2009.5354121.
   Korrapati H, 2012, IEEE INT CONF ROBOT, P1650, DOI 10.1109/ICRA.2012.6224892.
   Kretzschmar H, 2012, INT J ROBOT RES, V31, P1219, DOI 10.1177/0278364912455072.
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7.
   Nicosevici T, 2012, IEEE T ROBOT, V28, P886, DOI 10.1109/TRO.2012.2192013.
   Paul Rohan, 2011, IEEE International Conference on Robotics and Automation, P445.
   Paul R, 2012, IEEE INT CONF ROBOT, P4058, DOI 10.1109/ICRA.2012.6224762.
   Ranganathan Ananth, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P2017, DOI 10.1109/ROBOT.2009.5152376.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.},
Number-of-Cited-References = {16},
Times-Cited = {17},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BE9BP},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000377221101048},
DA = {2022-05-17},
}

@inproceedings{ WOS:000380485500430,
Author = {Stuntz, Andrew and Liebel, David and Smith, Ryan N.},
Book-Group-Author = {IEEE},
Title = {Enabling Persistent Autonomy for Underwater Gliders Through Terrain
   Based Navigation},
DOI = {10.1109/OCEANS-Genova.2015.7271751},
Booktitle = {OCEANS 2015 - GENOVA},
Year = {2015},
Note = {Oceans 2015 Genova, Ctr Congressi Genova, Genova, ITALY, MAY 18-21, 2015},
Abstract = {To effectively examine ocean processes we must often sample over the
   duration of long (weeks to months) oscillation patterns. Such sampling
   requires persistent autonomous underwater vehicles, that have a
   similarly long deployment duration. Actively actuated (propeller-driven)
   underwater vehicles have proven effective in multiple sampling
   scenarios, however they have limited deployment endurance. The emergence
   of less actuated vehicles, i.e., underwater gliders, has enabled greater
   energy savings and thus increased endurance. Due to reduced actuation,
   these vehicles are more susceptible to external forces, e.g., ocean
   currents, causing them to have poor navigational and localization
   accuracy underwater. This is exacerbated in coastal regions, where
   current velocities are the same order of magnitude as the vehicle
   velocity.
   In this paper, we examine a method of reducing navigation and
   localization error, not only for navigation, but more so for more
   accurately reconstructing the path that the glider traversed to
   contextualize the gathered data, with respect to the science question at
   hand. We present a set of algorithms for offline processing that
   accurately localizes the traversed path of an underwater glider over
   long-term, ocean deployments. The proposed method utilizes terrain-based
   navigation with only depth, altimeter and compass data compared to local
   bathymetry maps to provide accurate reconstructions of traversed paths
   in the ocean.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Smith, RN (Corresponding Author), Ft Lewis Coll, Dept Phys \& Engn, Durango, CO 81301 USA.
   Stuntz, Andrew; Liebel, David; Smith, Ryan N., Ft Lewis Coll, Dept Phys \& Engn, Durango, CO 81301 USA.},
DOI = {10.1109/OCEANS-Genova.2015.7271751},
ISBN = {978-1-4799-8737-5},
Keywords-Plus = {HARMFUL ALGAL BLOOMS; OCEAN; VEHICLES},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Marine; Engineering, Electrical \& Electronic; Oceanography},
Author-Email = {rnsmith@fortlewis.edu},
Cited-References = {Anderson DM, 2002, ESTUARIES, V25, P704, DOI 10.1007/BF02804901.
   Anonsen K. B., 2006, P IEEE ION POS LOC N.
   Anonsen Kjetil Bergh, 2007, P IFAC C CONTR APPL, V40, P106, DOI {[}10.3182/20070919-3-HR-3904.00020, DOI 10.3182/20070919-3-HR-3904.00020].
   Chavez F., 2010, CANON C ONTROLLED A.
   Davis RE, 2008, LIMNOL OCEANOGR, V53, P2151, DOI 10.4319/lo.2008.53.5\_part\_2.2151.
   Ferrari R, 2011, SCIENCE, V332, P316, DOI 10.1126/science.1203632.
   Flenniken W., 2005, ION GNSS, P967.
   Fulton-Bennett K., 2005, CANYONS CURRENTS ALG.
   Godin M. A., 2006, P MAR TECHN SOC I EL.
   Golden J. P., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P10.
   Griffiths G, 2007, J OCEAN TECHNOL, V2, P64.
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396.
   Horner RA, 1997, LIMNOL OCEANOGR, V42, P1076, DOI 10.4319/lo.1997.42.5\_part\_2.1076.
   Kinsey J., 2006, P C MAN CONTR MAR CR, P1.
   Kudela Raphael, 2005, Oceanography, V18, P184.
   Lagadec J., 2010, THESIS.
   Mancho AM, 2008, J PHYS OCEANOGR, V38, P1222, DOI 10.1175/2007JPO3677.1.
   Paley DA, 2008, IEEE T CONTR SYST T, V16, P735, DOI 10.1109/TCST.2007.912238.
   Pereira AA, 2013, J FIELD ROBOT, V30, P741, DOI 10.1002/rob.21472.
   Schofield O, 2007, J FIELD ROBOT, V24, P473, DOI 10.1002/rob.20200.
   Sekula-Wood E., 2009, NATURE GEOSCIENCES, V2, P273, DOI DOI 10.1038/NGE0472.
   SHUMAKER BP, 1984, SKY TELESCOPE, V68, P158.
   Smith RN, 2012, IEEE INT CONF ROBOT, P4870, DOI 10.1109/ICRA.2012.6224609.
   Smith RN, 2011, J FIELD ROBOT, V28, P714, DOI 10.1002/rob.20405.
   Smith RN, 2010, PROCEEDINGS OF THE ASME 29TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING, 2010, VOL 4, P597.
   Smith RN, 2010, INT J ROBOT RES, V29, P1475, DOI 10.1177/0278364910377243.
   Smith RN, 2010, IEEE ROBOT AUTOM MAG, V17, P20, DOI 10.1109/MRA.2010.935795.
   Taylor J. R., 1996, INTRO ERROR ANAL STU, P166.
   Whitcomb L., 1999, P 9 INT S ROB RES, P439, DOI DOI 10.1007/978-1-4471-0765-1\_53.
   YSI Incorporated, 2010, YSI ECOMAPPER.
   Zhang Y, 2013, J MATER CHEM B, V1, P132, DOI 10.1039/c2tb00071g.},
Number-of-Cited-References = {31},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BF2OL},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380485500430},
DA = {2022-05-17},
}

@article{ WOS:000633637000015,
Author = {Tschopp, Florian and von Einem, Cornelius and Cramariuc, Andrei and Hug,
   David and Palmer, Andrew William and Siegwart, Roland and Chli,
   Margarita and Nieto, Juan},
Title = {Hough(2)Map - Iterative Event-Based Hough Transform for High-Speed
   Railway Mapping},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {2},
Pages = {2745-2752},
Month = {APR},
Abstract = {To cope with the growing demand for transportation on the railway
   system, accurate, robust, and high-frequency positioning is required to
   enable a safe and efficient utilization of the existing railway
   infrastructure. As a basis for a localization system we propose a
   complete on-board mapping pipeline able to map robust meaningful
   landmarks, such as poles from power lines, in the vicinity of the
   vehicle. Such poles are good candidates for reliable and long term
   landmarks even through difficult weather conditions or seasonal changes.
   To address the challenges of motion blur and illumination changes in
   railway scenarios we employ a Dynamic Vision Sensor, a novel event-based
   camera. Using a sideways oriented on-board camera, poles appear as
   vertical lines. To map such lines in a real-time event stream, we
   introduce Hough(2)Map, a novel consecutive iterative event-based Hough
   transform framework capable of detecting, tracking, and triangulating
   close-by structures. We demonstrate the mapping reliability and accuracy
   of Hough(2)Map on real-world data in typical usage scenarios and
   evaluate using surveyed infrastructure ground truth maps. Hough(2)Map
   achieves a detection reliability of up to 92\% and a mapping root mean
   square error accuracy of 1.1518 m.(1)},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Tschopp, F (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   Tschopp, Florian; von Einem, Cornelius; Cramariuc, Andrei; Siegwart, Roland; Nieto, Juan, Swiss Fed Inst Technol, Autonomous Syst Lab, CH-8092 Zurich, Switzerland.
   von Einem, Cornelius; Hug, David; Chli, Margarita, Swiss Fed Inst Technol, Vis Robot Lab, CH-8092 Zurich, Switzerland.
   Palmer, Andrew William, Siemens Mobil, D-12489 Berlin, Germany.},
DOI = {10.1109/LRA.2021.3061404},
ISSN = {2377-3766},
Keywords = {Computer vision for transportation; object detection; segmentation and
   categorization; mapping},
Keywords-Plus = {VISION; LINES},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {ftschopp@ethz.ch
   cornelius.einem@icloud.com
   andrei.cramariuc@maviethz.ch
   david.hug@mavt.ethz.ch
   andrew.palmer@emesent.io
   rsiegwart@ethz.ch
   chlim@ethz.ch
   jnieto@ethz.ch},
Affiliations = {ETH Zurich; ETH Zurich},
ResearcherID-Numbers = {Siegwart, Roland/A-4495-2008
   },
ORCID-Numbers = {Siegwart, Roland/0000-0002-2760-7983
   Nieto, Juan/0000-0003-4808-0831
   Cramariuc, Andrei/0000-0002-9301-0253
   von Einem, Cornelius/0000-0003-4378-1516
   Tschopp, Florian/0000-0001-7346-2941
   Palmer, Andrew/0000-0003-4729-7895
   Chli, Margarita/0000-0001-5611-7492
   Hug, David/0000-0002-4430-3877},
Funding-Acknowledgement = {Siemens Mobility GmbH, Germany; ETH Mobility Initiative under Project
   PROMPT},
Funding-Text = {This letter was recommended for publication by Associate Editor A.
   Nuechter and Editor S. Behnke upon evaluation of the reviewers'
   comments. This work was supported in part by Siemens Mobility GmbH,
   Germany and in part by ETH Mobility Initiative under Project PROMPT.
   (Florian Tschopp, Cornelius von Einem, and Andrei Cramariuc contributed
   equally to this work.)},
Cited-References = {Albrecht Thomas, 2013, Proceedings of the 2013 IEEE International Conference on Intelligent Rail Transportation (ICIRT), P134, DOI 10.1109/ICIRT.2013.6696282.
   Arth C., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P37, DOI 10.1109/ISMAR.2011.6092368.
   ATRAUCEAN PVP, 2012, LECT NOTES COMPUT SC, P572.
   Bagchi S, 2020, IEEE WINT CONF APPL, P2132, DOI 10.1109/WACV45572.2020.9093309.
   Bah B., 2008, 22 ECMI MOD WEEK EI.
   Benosman R, 2014, IEEE T NEUR NET LEAR, V25, P407, DOI 10.1109/TNNLS.2013.2273537.
   Benosman R, 2012, NEURAL NETWORKS, V27, P32, DOI 10.1016/j.neunet.2011.11.001.
   Beugin J, 2012, TRANSPORT RES C-EMER, V22, P42, DOI 10.1016/j.trc.2011.12.002.
   Boehringer F, 2006, WIT TRANS BUILT ENV, V88, P459, DOI 10.2495/CR060461.
   Brandli C, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON EVENT-BASED CONTROL, COMMUNICATION, AND SIGNAL PROCESSING (EBCCSP), DOI 10.1109/EBCCSP.2016.7605244.
   Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715.
   Burki M, 2019, J FIELD ROBOT, V36, P1041, DOI 10.1002/rob.21870.
   BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808.
   Burri M, 2015, IEEE INT C INT ROBOT, P1872, DOI 10.1109/IROS.2015.7353622.
   Conradt J, 2009, IEEE INT SYMP CIRC S, P781, DOI 10.1109/ISCAS.2009.5117867.
   Dalitz C, 2017, IMAGE PROCESS ON LIN, V7, P184, DOI 10.5201/ipol.2017.208.
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242.
   ETEMADI A, 1992, IEE CONF PUBL, V354, P311.
   Fehr M, 2018, IEEE INT C INT ROBOT, P5037, DOI 10.1109/IROS.2018.8593416.
   Furgale P, 2013, IEEE INT C INT ROBOT, P1280, DOI 10.1109/IROS.2013.6696514.
   Gerlach K, 2009, ITST: 2009 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORT SYSTEMS TELECOMMUNICATIONS, P343, DOI 10.1109/ITST.2009.5399330.
   Glover A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2203, DOI 10.1109/IROS.2016.7759345.
   Hartley R., 2004, MULTIPLE VIEW GEOMET, V2nd.
   Hasberg C, 2012, IEEE T INTELL TRANSP, V13, P541, DOI 10.1109/TITS.2011.2177522.
   Heirich O, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1835.
   Heirich O, 2013, IEEE INT CONF ROBOT, P5212, DOI 10.1109/ICRA.2013.6631322.
   Hensel S, 2011, IEEE T INTELL TRANSP, V12, P1525, DOI 10.1109/TITS.2011.2161291.
   Hough P. V. C., 1962, U.S.Patent, Patent No. {[}3069654, 3,069,654].
   iniVation AG, 2019, DAVIS 240 DAT.
   KAHN P, 1990, IEEE T PATTERN ANAL, V12, P1098, DOI 10.1109/34.61710.
   KITTLER J, 1987, IEEE T PATTERN ANAL, P690.
   LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3.
   Lichtsteiner Patrick, 2008, IEEE Journal of Solid-State Circuits, V43, P566, DOI 10.1109/JSSC.2007.914337.
   Localization Working Group (LWG), 2019, RAILW LOC SYST HIGH.
   Lynen Simon, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P303, DOI 10.1109/3DV.2014.36.
   Lynen S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Mahowald M., 1992, VLSI ANALOGS NEURONA.
   Mao, 2016, BMVC.
   Marais J, 2017, IEEE T INTELL TRANSP, V18, P2602, DOI 10.1109/TITS.2017.2658179.
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831.
   Mueggler E, 2017, INT J ROBOT RES, V36, P142, DOI 10.1177/0278364917691115.
   Mueggler E, 2014, IEEE INT C INT ROBOT, P2761, DOI 10.1109/IROS.2014.6942940.
   Ni Z, 2012, J MICROSC-OXFORD, V245, P236, DOI 10.1111/j.1365-2818.2011.03565.x.
   Nieto, 2020, ARXIV200805749.
   Otegui J, 2017, IEEE SENS J, V17, P6788, DOI 10.1109/JSEN.2017.2747137.
   Palmer AW, 2018, IEEE INT C INT ROBOT, P3167, DOI 10.1109/IROS.2018.8594473.
   Saeporsdottir AD, 2020, ENVIRONMENTS, V7, DOI 10.3390/environments7080059.
   Siebler Benjamin, 2020, 2020 IEEE/ION Position, Location and Navigation Symposium (PLANS), P941, DOI 10.1109/PLANS46316.2020.9110149.
   Stanley P, 2011, ETCS ENG, P43.
   Tschopp F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051439.
   Tschopp F, 2019, IEEE ROBOT AUTOM LET, V4, P1815, DOI 10.1109/LRA.2019.2897169.
   Valeiras DR, 2019, IEEE T NEUR NET LEAR, V30, P1218, DOI 10.1109/TNNLS.2018.2807983.
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300.
   Winter H., 2020, TECH REP.
   Wohlfeil J, 2011, IEEE INT VEH SYM, P1025, DOI 10.1109/IVS.2011.5940466.
   YLAJAASKI A, 1994, IEEE T PATTERN ANAL, V16, P911, DOI 10.1109/34.310688.
   Yuan WZ, 2016, IEEE INT CONF ROBOT, P4564, DOI 10.1109/ICRA.2016.7487657.},
Number-of-Cited-References = {57},
Times-Cited = {3},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {3},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {RD7ET},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000633637000015},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000617447400079,
Author = {Jiao, Yanmei and Wang, Yue and Ding, Xiaqing and Fu, Bo and Huang,
   Shoudong and Xiong, Rong},
Title = {2-Entity Random Sample Consensus for Robust Visual Localization:
   Framework, Methods, and Verifications},
Journal = {IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS},
Year = {2021},
Volume = {68},
Number = {5},
Pages = {4519-4528},
Month = {MAY},
Abstract = {Robust and efficient visual localization is essential for numerous
   robotic applications. However, it remains a challenging problem
   especially when significant environmental or perspective changes are
   present, as there are high percentage of outliers, i.e., incorrect
   feature matches between the query image and the map. In this article, we
   propose a novel 2-entity random sample consensus (RANSAC) framework
   using three-dimensional-two-dimensional point and line feature matches
   for visual localization with the aid of inertial measurements and derive
   minimal closed-form solutions using only 1 point 1 line or 2 point
   matches for both monocular and multi-camera system. The proposed
   2-entity RANSAC can achieve higher robustness against outliers as
   multiple types of features are utilized and the number of matches needed
   to compute a pose is reduced. Furthermore, we propose a learning-based
   sampling strategy selection mechanism and a feature scoring network to
   be adaptive to different environmental characteristics such as
   structured and unstructured. Finally, both simulation and real-world
   experiments are performed to validate the robustness and effectiveness
   of the proposed method in scenarios with long-term and perspective
   changes. (1) (1) https://youtu.be/Zqgxntz11hI.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, Y (Corresponding Author), Zhejiang Univ, Dept Control Sci \& Engn, State Key Lab Ind Control \& Technol, Hangzhou 310027, Peoples R China.
   Jiao, Yanmei; Wang, Yue; Ding, Xiaqing; Fu, Bo; Xiong, Rong, Zhejiang Univ, Dept Control Sci \& Engn, State Key Lab Ind Control \& Technol, Hangzhou 310027, Peoples R China.
   Huang, Shoudong, Univ Technol, Fac Engn \& IT, Ctr Autonomous Syst, Sydney, NSW 2007, Australia.},
DOI = {10.1109/TIE.2020.2984970},
ISSN = {0278-0046},
EISSN = {1557-9948},
Keywords = {Cameras; Visualization; Robustness; Robot vision systems; Pose
   estimation; Closed-form solutions; Computational modeling; Camera pose
   estimation; random sample consensus (RANSAC); robust localization},
Research-Areas = {Automation \& Control Systems; Engineering; Instruments \&
   Instrumentation},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {ymjiao@zju.edu.cn
   wangyue@iipc.zju.edu.cn
   xqding@zju.edu.cn
   fubofb@zju.edu.cn
   shoudong.huang@uts.edu.au
   rxiong@zju.edu.cn},
Affiliations = {Zhejiang University; University of Technology Sydney},
ORCID-Numbers = {Huang, Shoudong/0000-0002-6124-4178},
Funding-Acknowledgement = {National Key R\&D Program of China {[}2018YFB1309300]; National Nature
   Science Foundation of China {[}61903332, U1609210]},
Funding-Text = {This work was supported in part by the National Key R\&D Program of
   China under Grant 2018YFB1309300 and in part by the National Nature
   Science Foundation of China under Grant 61903332 and Grant U1609210.},
Cited-References = {Bradski G, 2000, DR DOBBS J, V25, P120.
   Brahmachari AS, 2009, IEEE I CONF COMP VIS, P1685, DOI 10.1109/ICCV.2009.5459379.
   DEVOS BD, 2019, PROC CVPR IEEE, V52, P128, DOI DOI 10.1016/j.media.2018.11.010.
   DHOME M, 1989, IEEE T PATTERN ANAL, V11, P1265, DOI 10.1109/34.41365.
   Ding XQ, 2018, IEEE INT C INT ROBOT, P4794, DOI 10.1109/IROS.2018.8593846.
   DORNAIKA F, 1999, IEEE INT C INT ROBOT, V5, P215.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Fraundorfer F, 2010, LECT NOTES COMPUT SC, V6314, P269, DOI 10.1007/978-3-642-15561-1\_20.
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599.
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405.
   Goshen L, 2008, IEEE T PATTERN ANAL, V30, P1230, DOI 10.1109/TPAMI.2007.70768.
   Huang, 2018, AUTON ROBOT, P1.
   Jiao, SUPPLEMENTARY MAT 2.
   Jiao YM, 2019, IEEE INT C INT ROBOT, P2478, DOI 10.1109/IROS40897.2019.8967671.
   Kim J, 2016, IEEE T IND ELECTRON, V63, P3616, DOI 10.1109/TIE.2016.2523460.
   Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464.
   Kneip L, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.16.
   Kneip L, 2014, IEEE INT CONF ROBOT, P1, DOI 10.1109/ICRA.2014.6906582.
   Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1\_9.
   Kneip L, 2013, IEEE INT CONF ROBOT, P3770, DOI 10.1109/ICRA.2013.6631107.
   Kukelova Zuzana, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P216, DOI 10.1007/978-3-642-19309-5\_17.
   Lee GH, 2016, LECT NOTES COMPUT SC, V9909, P170, DOI 10.1007/978-3-319-46454-1\_11.
   Lee JA, 2019, IEEE I CONF COMP VIS, P5076, DOI 10.1109/ICCV.2019.00518.
   Lee JA, 2015, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR.2015.7298707.
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6.
   Linegar C, 2016, IEEE INT CONF ROBOT, P787, DOI 10.1109/ICRA.2016.7487208.
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94.
   MURARTAL R, 2015, DR DOBBS J, V31, P1147, DOI DOI 10.1109/TRO.2015.2463671.
   MURARTAL R, 2017, PROC CVPR IEEE, V2, P796, DOI DOI 10.1109/LRA.2017.2653359.
   Omari S, 2015, IEEE INT CONF ROBOT, P2634, DOI 10.1109/ICRA.2015.7139554.
   Paszke A., 2017, P NEURIPS AUT WORKSH.
   Ramalingam, 2018, P EUR C COMP VIS ECC, P474.
   Ramalingam Srikumar, 2011, 2011 IEEE International Conference on Robotics and Automation, P4716.
   Raposo C, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.114.
   ROSTEN E, 2006, EUR C COMP VIS, V1, P430, DOI DOI 10.1007/11744023\_.
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Simonyan K., 2015, P 3 INT C LEARNING R.
   Zhang JH, 2019, IEEE T IND ELECTRON, V66, P9673, DOI 10.1109/TIE.2018.2880727.},
Number-of-Cited-References = {39},
Times-Cited = {5},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {24},
Journal-ISO = {IEEE Trans. Ind. Electron.},
Doc-Delivery-Number = {QG2VF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000617447400079},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000249594500019,
Author = {Galindo, Cipriano and Fernandez-Madrigal, Juan-Antonio and Gonzalez,
   Javier and Saffiotti, Alessandro and Buschka, Par},
Title = {Life-long optimization of the symbolic model of indoor environments for
   a mobile robot},
Journal = {IEEE TRANSACTIONS ON SYSTEMS MAN AND CYBERNETICS PART B-CYBERNETICS},
Year = {2007},
Volume = {37},
Number = {5},
Pages = {1290-1304},
Month = {OCT},
Abstract = {The use of a symbolic model of the spatial environment becomes crucial
   for a mobile robot. that is intended to operate optimally and
   intelligently in indoor scenarios. Constructing such a model involves
   important problems that are not solved completely at present. One is
   called anchoring, which implies to maintain a correct dynamic
   correspondence between the real world and the symbols in the model. The
   other problem is adaptation: among the numerous possible models that
   could be constructed for representing a given environment, optimization
   involves the selection of one that improves as much as possible the
   operations of the robot. To cope with both problems, in this paper, we
   propose a framework that allows an indoor mobile robot to learn
   automatically a symbolic model of its environment and to optimize it
   over time with respect to changes in both the environment and the robot
   operational needs through an evolutionary algorithm. For coping
   efficiently with the large amounts of information that the real world
   provides, we use abstraction, which also helps in improving task
   planning. Our experiments demonstrate that the proposed framework is
   suitable for providing an indoor mobile robot with a good symbolic model
   and adaptation capabilities.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Galindo, C (Corresponding Author), Univ Malaga, Dept Syst Engn \& Automat, Malaga 29071, Spain.
   Univ Malaga, Dept Syst Engn \& Automat, Malaga 29071, Spain.
   Univ Orebro, Ctr Appl Auonomous Sensor Syst, Dept Technol, S-70182 Orebro, Sweden.
   IRobis, S-41134 Gothenburg, Sweden.
   Creamos Engn, S-41134 Gothenburg, Sweden.},
DOI = {10.1109/TSMCB.2007.900074},
ISSN = {1083-4419},
EISSN = {1941-0492},
Keywords = {anchoring; evolutionary algorithms; robotics; situated agents; symbol
   grounding; world modeling},
Keywords-Plus = {SIMULTANEOUS LOCALIZATION; NAVIGATION; INTEGRATION; EVOLUTION; MAPS},
Research-Areas = {Automation \& Control Systems; Computer Science},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Computer Science, Cybernetics},
Author-Email = {cipriano@ctima.uma.es
   jafma@ctima.uma.es
   jgonzalez@ctima.uma.es
   alessandro.saffiotti@aass.oru.se
   par.buschka@aass.oru.se},
Affiliations = {Universidad de Malaga; Orebro University},
ResearcherID-Numbers = {Galindo, Cipriano/AAD-9158-2020
   Gonzalez-Jimenez, Javier/D-5774-2011
   Fernández-Madrigal, Juan-Antonio/D-5871-2011
   Galindo, Cipriano/D-5861-2011
   Saffiotti, Alessandro/B-4213-2013},
ORCID-Numbers = {Galindo, Cipriano/0000-0003-2922-1969
   Gonzalez-Jimenez, Javier/0000-0003-3845-3497
   Fernández-Madrigal, Juan-Antonio/0000-0003-1376-7967
   Galindo, Cipriano/0000-0003-2922-1969
   Saffiotti, Alessandro/0000-0001-8229-1363},
Cited-References = {Allen J.G., 2004, P PAN SYDN AR WORKSH, P3.
   ASADA M, 1990, IEEE T SYST MAN CYB, V20, P1326, DOI 10.1109/21.61204.
   Back T., 1997, IEEE Transactions on Evolutionary Computation, V1, P3, DOI 10.1109/4235.585888.
   Blanco JL, 2007, IEEE INT CONF ROBOT, P4032, DOI 10.1109/ROBOT.2007.364098.
   BONARINI A, 2001, CONCEPTS ANCHORING R.
   Bosse M, 2004, INT J ROBOT RES, V23, P1113, DOI 10.1177/0278364904049393.
   BROXVALL M, 2005, P 20 NAT C ART INT, P1254.
   Buschka P, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P637, DOI 10.1109/IRDS.2002.1041463.
   Choset H, 2001, IEEE T ROBOTIC AUTOM, V17, P125, DOI 10.1109/70.928558.
   Coradeschi S, 2003, ROBOT AUTON SYST, V43, P85, DOI 10.1016/S0921-8890(03)00021-6.
   Doherty CP, 1999, BRAIN RES PROTOC, V4, P1, DOI 10.1016/S1385-299X(98)00053-1.
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038.
   Fabrizi E., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2972, DOI 10.1109/ROBOT.2000.846479.
   FABRIZI E, 2001, FUZZY LOGIC TECHNIQU, P257.
   Fernandez JA, 1999, ENG APPL ARTIF INTEL, V12, P543, DOI 10.1016/S0952-1976(99)00018-4.
   FERNANDEZ JA, 2001, MULTI HIERARCHICAL R.
   Fernandez-Madrigal JA, 2004, INTEGR COMPUT-AID E, V11, P309.
   Fernandez-Madrigal JA, 2002, IEEE T PATTERN ANAL, V24, P103, DOI 10.1109/34.982887.
   Floreano D, 1996, IEEE T SYST MAN CY B, V26, P396, DOI 10.1109/3477.499791.
   Fritsch J, 2003, ROBOT AUTON SYST, V43, P133, DOI 10.1016/S0921-8890(02)00355-X.
   Galindo C, 2004, IEEE T ROBOTIC AUTOM, V20, P677, DOI 10.1109/TRO.2004.829480.
   Galindo C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2278, DOI 10.1109/IROS.2005.1545511.
   Garey M. R., 1979, COMPUTERS INTRACTABI, V174.
   GONZALEZ J, 1994, IEEE INT CONF ROBOT, P1904, DOI 10.1109/ROBOT.1994.351183.
   Guivant J, 2004, INT J ROBOT RES, V23, P449, DOI 10.1177/0278364904042203.
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6.
   Hoffmann J, 2001, J ARTIF INTELL RES, V14, P253, DOI 10.1613/jair.855.
   Isard M., 1996, P EUR C COMP VIS, P343.
   Kuipers B., 1991, Robotics and Autonomous Systems, V8, P47, DOI 10.1016/0921-8890(91)90014-C.
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5.
   KUIPERS BJ, 1987, P IEEE WORKSH SPAT R, P390.
   Lisien B, 2005, IEEE T ROBOT, V21, P473, DOI 10.1109/TRO.2004.837237.
   Loutfi A, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1477.
   MAIO D, 1995, PATTERN RECOGN LETT, V16, P89, DOI 10.1016/0167-8655(94)00069-F.
   Nordin P, 1998, ROBOT AUTON SYST, V25, P105, DOI 10.1016/S0921-8890(98)00004-9.
   Poncela A, 2002, ROBOT AUTON SYST, V41, P21, DOI 10.1016/S0921-8890(02)00272-5.
   Ram Ashwin, 1994, Adaptive Behavior, V2, P277, DOI 10.1177/105971239400200303.
   Rizzi S, 1998, INT C PATT RECOG, P1543, DOI 10.1109/ICPR.1998.712002.
   SAFFIOTTI A, 1995, ARTIF INTELL, V76, P481, DOI 10.1016/0004-3702(94)00088-I.
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794.
   Takeuchi I, 1998, 1998 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AT THE IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE - PROCEEDINGS, VOL 1-2, P715, DOI 10.1109/FUZZY.1998.687576.
   Tani J, 1996, IEEE T SYST MAN CY B, V26, P421, DOI 10.1109/3477.499793.
   Taniguchi T, 2004, IEEE SYS MAN CYBERN, P2073.
   Thrun S, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P944.
   Thrun S, 1998, IEEE INT CONF ROBOT, P1546, DOI 10.1109/ROBOT.1998.677346.
   Thrun S., 2002, EXPLORING ARTIFICIAL, V298, P1, DOI 10.1126/science.298.5592.1.
   Tomatis N, 2003, ROBOT AUTON SYST, V44, P3, DOI 10.1016/S0921-8890(03)00006-X.
   Trudeau R.J., 1993, INTRO GRAPH THEORY.
   Urdiales C, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P225, DOI 10.1109/IAT.2003.1241072.
   WAH BW, 1989, P IEEE, V77, P509, DOI 10.1109/5.24142.
   WALLGRUN JO, 2004, P 4 INT COGN ROB WOR, P64.
   WHITLEY D, 1994, STAT COMPUT, V4, P65.},
Number-of-Cited-References = {52},
Times-Cited = {10},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {10},
Journal-ISO = {IEEE Trans. Syst. Man Cybern. Part B-Cybern.},
Doc-Delivery-Number = {212KF},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000249594500019},
DA = {2022-05-17},
}

@inproceedings{ WOS:000337617302044,
Author = {Delmerico, Jeffrey A. and Baran, David and David, Philip and Ryde,
   Julian and Corso, Jason J.},
Book-Group-Author = {IEEE},
Title = {Ascending Stairway Modeling from Dense Depth Imagery for Traversability
   Analysis},
DOI = {10.1109/ICRA.2013.6630886},
Booktitle = {2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2013},
Pages = {2283-2290},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Karlsruhe, GERMANY, MAY 06-10, 2013},
Abstract = {Localization and modeling of stairways by mobile robots can enable
   multi-floor exploration for those platforms capable of stair traversal.
   Existing approaches focus on either stairway detection or traversal, but
   do not address these problems in the context of path planning for the
   autonomous exploration of multi-floor buildings. We propose a system for
   detecting and modeling ascending stairways while performing simultaneous
   localization and mapping, such that the traversability of each stairway
   can be assessed by estimating its physical properties. The long-term
   objective of our approach is to enable exploration of multiple floors of
   a building by allowing stairways to be considered during path planning
   as traversable portals to new frontiers. We design a generative model of
   a stairway as a single object. We localize these models with respect to
   the map, and estimate the dimensions of the stairway as a whole, as well
   as its steps. With these estimates, a robot can determine if the
   stairway is traversable based on its climbing capabilities. Our system
   consists of two parts: a computationally efficient detector that
   leverages geometric cues from dense depth imagery to detect sets of
   ascending stairs, and a stairway modeler that uses multiple detections
   to infer the location and parameters of a stairway that is discovered
   during exploration. We demonstrate the performance of this system when
   deployed on several mobile platforms using a Microsoft Kinect sensor.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Delmerico, JA (Corresponding Author), SUNY Buffalo, Buffalo, NY 14260 USA.
   Delmerico, Jeffrey A.; Ryde, Julian; Corso, Jason J., SUNY Buffalo, Buffalo, NY 14260 USA.
   Baran, David; David, Philip, US Army Res Lab, Buffalo, NY 14260 USA.},
ISSN = {1050-4729},
EISSN = {2577-087X},
ISBN = {978-1-4673-5641-1; 978-1-4673-5643-5},
Research-Areas = {Automation \& Control Systems; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Engineering, Electrical \& Electronic;
   Robotics},
Author-Email = {jad12@buffalo.edu
   david.g.baran.civ@mail.mil
   philip.j.david4.civ@mail.mil
   jryde@buffalo.edu
   jcorso@buffalo.edu},
Affiliations = {State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; United States Department of Defense; United States Army;
   US Army Research, Development \& Engineering Command (RDECOM); US Army
   Research Laboratory (ARL)},
Funding-Acknowledgement = {Federal Highway Administration {[}DTFH61-07-H-00023]; Army Research
   Office {[}W911NF-ll-I-0090]; National Science Foundation CAREER
   {[}IIS-0845282]},
Funding-Text = {This material is based upon work partially supported by the Federal
   Highway Administration under Cooperative Agreement No.
   DTFH61-07-H-00023, the Army Research Office (W911NF- ll-I-0090) and the
   National Science Foundation CAREER grant (IIS-0845282). Any opinions,
   findings, conclusions or recommendations are those of the authors and do
   not necessarily reflect the views of the FHWA, ARO, or NSF},
Cited-References = {Brunner M., 2012, 2012 13th International Carpathian Control Conference (ICCC 2012), P63, DOI 10.1109/CarpathianCC.2012.6228617.
   Choi KH, 2007, IEEE ASME INT C ADV, P78.
   Cong Y, 2008, IEEE INT C NETW SENS, P1806.
   Delmerico J., 2012, AUTONOMOUS MULTIFLOO.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Hernandez Danilo Caceres, 2011, Modern Approaches in Applied Intelligence. Proceedings 24th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2011, P338, DOI 10.1007/978-3-642-21822-4\_34.
   Hernandez D.C., 2010, P INT FOR STRAT TECH, P82.
   Hesch J A, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P5525, DOI 10.1109/IROS.2010.5649411.
   Johnson A. M., 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P134, DOI 10.1109/SSRR.2011.6106785.
   Lu XY, 2005, IEEE INT CONF ROBOT, P4648.
   Mihankhah E, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P1980, DOI 10.1109/ROBIO.2009.4913304.
   Mourikis AI, 2007, INT J ROBOT RES, V26, P737, DOI 10.1177/0278364907080423.
   Osswald Stefan, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P93, DOI 10.1109/Humanoids.2011.6100836.
   Osswald Stefan, 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P4844, DOI 10.1109/IROS.2011.6048209.
   Ozkil AG, 2011, IEEE INT C INT ROBOT, P847, DOI 10.1109/IROS.2011.6048647.
   Pradeep V, 2008, WORKSH COMP VIS APPL.
   Ray R, 2010, STUD COMPUT INTELL, V275, P87.
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005.
   Rusu Radu Bogdan, 2011, IEEE INT C ROB AUT I.
   Shaojie Shen, 2011, IEEE International Conference on Robotics and Automation, P20.
   Wang SQ, 2009, PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2, P1, DOI 10.1109/PLASMA.2009.5227540.},
Number-of-Cited-References = {21},
Times-Cited = {27},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {2},
Doc-Delivery-Number = {BA7KQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000337617302044},
OA = {Green Submitted},
DA = {2022-05-17},
}

@inproceedings{ WOS:000345059700057,
Author = {Kadlecek, Boleslav and Ruzicka, Miroslav and Kotek, Martin},
Book-Group-Author = {CULSP},
Title = {THE ENVIRONMENTAL ASPECTS OF SUBURB AREAS' DEVELOPMENT},
Booktitle = {TRENDS IN AGRICULTURAL ENGINEERING 2013},
Year = {2013},
Pages = {293-297},
Note = {5th International Conference on Trends in Agricultural Engineering,
   Prague, CZECH REPUBLIC, SEP 03-06, 2013},
Abstract = {The intensive and even chaotic development of the capital Prague's
   suburb areas was not performed usually in accordance with the transport
   infrastructure development and public facility construction. Traffic
   intensities doubled on the roads (of 2nd. or 3rd. class) on surveyed
   areas during the last five years, in extreme cases of the morning
   traffic peak vehicles spend about 50\% of total drive in congestions.
   The offer of transit (public transport) has non adequate development in
   suburb areas as well. The passenger car transport has low average
   occupancy rate app. 1.3 persons per car. These conclusions result from
   long term traffic surveys carried out on the selected localities of
   suburb settlements up to 20(km) of radial distance from the Prague city
   centre. The quantification of transport environmental impacts of
   observed area requires not only accept the proportion of increased
   intensities but it is necessary to take into account a progressive
   influence of increased drive transience of traffic flows and
   congestions. That is why the traffic surveys were carried out
   simultaneously with experimental drives done by vehicles with
   measurement equipment to map emission production and fuel consumption in
   the suburb areas. Results confirm expectations that the higher rate of
   suburb populating increases vehicles' fuel consumption and consequently
   emission impacts. The important influencing factor is the quality of
   transport infrastructure and its control, including road horizontal and
   vertical profile shape.},
Publisher = {CZECH UNIVERSITY LIFE SCIENCES PRAGUE},
Address = {DEPT SYSTEMS ENG, KAMYCKA 129, PRAGUE 6 165 21, CZECH REPUBLIC},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kadlecek, B (Corresponding Author), Czech Univ Life Sci Prague, Prague 16521 6, Suchdol, Czech Republic.
   Kadlecek, Boleslav; Ruzicka, Miroslav; Kotek, Martin, Czech Univ Life Sci Prague, Prague 16521 6, Suchdol, Czech Republic.},
ISBN = {978-80-213-2388-9},
Keywords = {environmental aspects; suburb areas development},
Research-Areas = {Agriculture},
Web-of-Science-Categories  = {Agricultural Engineering},
Author-Email = {kadlecek@tf.czu.cz},
Affiliations = {Czech University of Life Sciences Prague},
ResearcherID-Numbers = {Kotek, Martin/J-2741-2018},
ORCID-Numbers = {Kotek, Martin/0000-0003-2886-265X},
Cited-References = {Breheny M., 1992, SUSTAINABLE DEV URBA, P138.
   Ewing R, 1997, J AM PLANN ASSOC, V63, P107, DOI 10.1080/01944369708975728.
   Gordon I., 1997, ASS AM GEAGR FORT WO.
   GORDON P, 1989, J AM PLANN ASSOC, V55, P342, DOI 10.1080/01944368908975421.
   Newman P., 1999, SUSTAINABILITY CITIE.
   Newman PG., 1989, CITIES AUTOMOBILE DE.},
Number-of-Cited-References = {6},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BB6WA},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000345059700057},
DA = {2022-05-17},
}

@inproceedings{ WOS:000391921704089,
Author = {Dymczyk, Marcin and Schneider, Thomas and Gilitschenski, Igor and
   Siegwart, Roland and Stumm, Elena},
Book-Group-Author = {IEEE},
Title = {Erasing bad memories: agent-side summarization for long-term mapping},
DOI = {10.1109/IROS.2016.7759673},
Booktitle = {2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS
   (IROS 2016)},
Year = {2016},
Pages = {4572-4579},
Note = {IEEE/RSJ International Conference on Intelligent Robots and Systems
   (IROS), Daejeon, SOUTH KOREA, OCT 09-14, 2016},
Abstract = {Precisely estimating the pose of an agent in a global reference frame is
   a crucial goal that unlocks a multitude of robotic applications,
   including autonomous navigation and collaboration. In order to achieve
   this, current state-of-the-art localization approaches collect data
   provided by one or more agents and create a single, consistent
   localization map, maintained over time. However, with the introduction
   of lengthier sorties and the growing size of the environments, data
   transfers between the backend server where the global map is stored and
   the agents are becoming prohibitively large. While some existing methods
   partially address this issue by building compact summary maps, the data
   transfer from the agents to the backend can still easily become
   unmanageable.
   In this paper, we propose a method that is designed to reduce the amount
   of data that needs to be transferred from the agent to the backend,
   functioning in large-scale, multi-session mapping scenarios. Our
   approach is based upon a landmark selection method that exploits
   information coming from multiple, possibly weak and correlated, landmark
   utility predictors; fused using learned feature coefficients. Such a
   selection yields a drastic reduction in data transfer while maintaining
   localization performance and the ability to efficiently summarize
   environments over time. We evaluate our approach on a data set that was
   autonomously collected in a dynamic indoor environment over a period of
   several months.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dymczyk, M (Corresponding Author), Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.
   Dymczyk, Marcin; Schneider, Thomas; Gilitschenski, Igor; Siegwart, Roland; Stumm, Elena, Swiss Fed Inst Technol, Autonomous Syst Lab, Zurich, Switzerland.},
ISBN = {978-1-5090-3762-9},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Affiliations = {ETH Zurich},
ORCID-Numbers = {Schneider, Thomas/0000-0002-1383-769X},
Funding-Acknowledgement = {Google},
Funding-Text = {We would like to thank Mathias Gehrig for the preparation of the
   Turtlebot, our autonomous mapping platform. The research leading to
   these results has received funding from Google's project Tango.},
Cited-References = {Arth C., 2011, IEEE INT S MIX AUGM.
   Buoncompagni S, 2015, PATTERN RECOGN LETT, V62, P32, DOI 10.1016/j.patrec.2015.04.019.
   Carneiro G, 2009, IMAGE VISION COMPUT, V27, P1143, DOI 10.1016/j.imavis.2008.10.015.
   Churchill Winston, 2013, INT J ROBOTICS RES I.
   Cieslewski T, 2015, IEEE INT CONF ROBOT, P6241, DOI 10.1109/ICRA.2015.7140075.
   Dymczyk M., 2015, IEEE INT C ROB AUT.
   Dymczyk M., 2015, IEEE RSJ INT C INT R.
   Forster C., 2013, IEEE RSJ INT C INT R.
   Galvez-Lopez D., 2012, IEEE T ROBOTICS, V28.
   Hartmann W., 2014, IEEE C COMP VIS PATT.
   Knopp J., 2010, EUR C COMP VIS.
   Leutenegger S., 2011, INT C COMP VIS.
   Lynen S., 2014, 3DV.
   Lynen S, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Marder-Eppstein E, 2010, IEEE INT CONF ROBOT, P300, DOI 10.1109/ROBOT.2010.5509725.
   Middelberg S., 2014, EUR C COMP VIS.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Muhlfellner P., 2015, J FIELD ROBOTICS.
   Nikolic J, 2014, IEEE INT CONF ROBOT, P431, DOI 10.1109/ICRA.2014.6906892.
   Park H. S., 2013, IEEE C COMP VIS PATT.
   Riazuelo L., 2013, ROBOTICS AUTONOMOUS.
   Sattler T., 2011, INT C COMP VIS.
   Sunderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI.
   Verdie Y., 2015, IEEE C COMP VIS PATT.
   Walcott-Bryant A., 2012, IEEE RSJ INT C INT R.
   Zhang W, 2007, IMAGE VISION COMPUT, V25, P704, DOI 10.1016/j.imavis.2006.05.016.},
Number-of-Cited-References = {26},
Times-Cited = {8},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BG7XO},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000391921704089},
DA = {2022-05-17},
}

@article{ WOS:000714714500012,
Author = {Hu, Hanjiang and Wang, Hesheng and Liu, Zhe and Chen, Weidong},
Title = {Domain-Invariant Similarity Activation Map Contrastive Learning for
   Retrieval-Based Long-Term Visual Localization},
Journal = {IEEE-CAA JOURNAL OF AUTOMATICA SINICA},
Year = {2022},
Volume = {9},
Number = {2},
Pages = {313-328},
Month = {FEB},
Abstract = {Visual localization is a crucial component in the application of mobile
   robot and autonomous driving. Image retrieval is an efficient and
   effective technique in image-based localization methods. Due to the
   drastic variability of environmental conditions, e.g., illumination
   changes, retrieval-based visual localization is severely affected and
   becomes a challenging problem. In this work, a general architecture is
   first formulated probabilistically to extract domain-invariant features
   through multi-domain image translation. Then, a novel gradient-weighted
   similarity activation mapping loss (Grad-SAM) is incorporated for finer
   localization with high accuracy. We also propose a new adaptive triplet
   loss to boost the contrastive learning of the embedding in a
   self-supervised manner. The final coarse-to-fine image retrieval
   pipeline is implemented as the sequential combination of models with and
   without Grad-SAM loss. Extensive experiments have been conducted to
   validate the effectiveness of the proposed approach on the CMU-Seasons
   dataset. The strong generalization ability of our approach is verified
   with the RobotCar dataset using models pre-trained on urban parts of the
   CMU-Seasons dataset. Our performance is on par with or even outperforms
   the state-of-the-art image-based localization baselines in medium or
   high precision, especially under challenging environments with
   illumination variance, vegetation, and night-time images. Moreover,
   real-site experiments have been conducted to validate the efficiency and
   effectiveness of the coarse-to-fine strategy for localization.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Wang, HS (Corresponding Author), Shanghai Jiao Tong Univ, Inst Med Robot, Dept Automat,Key Lab Marine Intelligent Equipment, Key Lab Syst Control \& Informat Proc,Minist Educ, Shanghai 200240, Peoples R China.
   Hu, Hanjiang; Chen, Weidong, Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   Wang, Hesheng, Shanghai Jiao Tong Univ, Inst Med Robot, Dept Automat,Key Lab Marine Intelligent Equipment, Key Lab Syst Control \& Informat Proc,Minist Educ, Shanghai 200240, Peoples R China.
   Liu, Zhe, Univ Cambridge, Dept Comp Sci \& Technol, Cambridge CB3 0FD, England.},
DOI = {10.1109/JAS.2021.1003907},
ISSN = {2329-9266},
EISSN = {2329-9274},
Keywords = {Deep representation learning; place recognition; visual localization},
Keywords-Plus = {PLACE RECOGNITION; ATTENTION MODEL},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {huhanjiang@sjtu.edu.cn
   wanghesheng@sjtu.edu.cn
   zl457@cam.ac.uk
   wdchen@sjtu.edu.cn},
Affiliations = {Shanghai Jiao Tong University; Shanghai Jiao Tong University; League of
   European Research Universities - LERU; University of Cambridge},
ResearcherID-Numbers = {Hu, Hanjiang/AHD-8358-2022
   },
ORCID-Numbers = {Hu, Hanjiang/0000-0002-5698-5887},
Cited-References = {ACHILLE A, 2018, P INF THEOR APPL WOR, P1.
   Anoosheh A, 2019, IEEE INT CONF ROBOT, P5958, DOI 10.1109/ICRA.2019.8794387.
   Anoosheh A, 2018, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2018.00122.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Badino H, 2011, IEEE INT CONF ROBOT.
   Balntas V, 2018, LECT NOTES COMPUT SC, V11218, P782, DOI 10.1007/978-3-030-01264-9\_46.
   Bescos B, 2018, IEEE ROBOT AUTOM LET, V3, P4076, DOI 10.1109/LRA.2018.2860039.
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097.
   Chen X, 2016, ADV NEUR IN, V29.
   Chen ZT, 2018, IEEE ROBOT AUTOM LET, V3, P4015, DOI 10.1109/LRA.2018.2859916.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Doan AD, 2019, IEEE I CONF COMP VIS, P9318, DOI 10.1109/ICCV.2019.00941.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Garg S, 2018, IEEE INT CONF ROBOT, P3645, DOI 10.1109/ICRA.2018.8461051.
   Gong R, 2019, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2019.00258.
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672.
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8.
   Gu HY, 2021, IEEE T IND ELECTRON, V68, P9778, DOI 10.1109/TIE.2020.3028813.
   HAN LJ, 2020, IEEEASME T MECHATRON, DOI DOI 10.1109/TMECH.2020.
   Hausler S, 2019, IEEE INT C INT ROBOT, P3268, DOI 10.1109/IROS40897.2019.8967783.
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3\_7.
   Hu HJ, 2019, IEEE INT C INT ROBOT, P3684, DOI 10.1109/IROS40897.2019.8968047.
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9\_11.
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632.
   Jegou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039.
   Jenicek T, 2019, IEEE I CONF COMP VIS, P9695, DOI 10.1109/ICCV.2019.00979.
   Kim HJ, 2017, PROC CVPR IEEE, P3251, DOI 10.1109/CVPR.2017.346.
   Kim H, 2018, PR MACH LEARN RES, V80.
   Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581.
   Liu MY, 2017, ADV NEUR IN, V30.
   Liu ZY, 2014, IEEE T PATTERN ANAL, V36, P1258, DOI 10.1109/TPAMI.2013.223.
   Lopez-Antequera M, 2017, PATTERN RECOGN LETT, V92, P89, DOI 10.1016/j.patrec.2017.04.017.
   Lowry S, 2016, IEEE T ROBOT, V32, P600, DOI 10.1109/TRO.2016.2545711.
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823.
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505.
   Luo X, 2021, IEEE T SYST MAN CY-S, V51, P916, DOI 10.1109/TSMC.2018.2884191.
   Ma YF, 2020, IEEE-CAA J AUTOMATIC, V7, P315, DOI 10.1109/JAS.2020.1003021.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Makhzani A., 2015, ARXIV151105644.
   Mathieu M. F., 2016, P 30 INT C NEUR INF, P5040.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103.
   Naseer Tayyab, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2614, DOI 10.1109/ICRA.2017.7989305.
   Piasco N, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01363-6.
   Piasco N, 2019, IEEE INT CONF ROBOT, P9094, DOI 10.1109/ICRA.2019.8794221.
   Porav H, 2018, IEEE INT CONF ROBOT, P1011, DOI 10.1109/ICRA.2018.8462894.
   Puckette Miller, 2018, ARXIV PREPRINT ARXIV.
   Qiao H, 2014, IEEE T CYBERNETICS, V44, P1485, DOI 10.1109/TCYB.2013.2287014.
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566.
   Radford A., 2015, ARXIV PREPRINT ARXIV.
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300.
   Sattler T, 2019, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR.2019.00342.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74.
   Shi W, 2019, IEEE-CAA J AUTOMATIC, V6, P917, DOI 10.1109/JAS.2019.1911561.
   Siam Sayem Mohammad, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5702, DOI 10.1109/ICRA.2017.7989671.
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434.
   Stenborg E, 2018, IEEE INT CONF ROBOT, P6484, DOI 10.1109/ICRA.2018.8463150.
   Tang L, 2020, IEEE INT CONF ROBOT, P1301, DOI 10.1109/ICRA40945.2020.9196518.
   Torii A, 2018, IEEE T PATTERN ANAL, V40, P257, DOI 10.1109/TPAMI.2017.2667665.
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8\_48.
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180.
   Wang LP, 2020, IEEE-CAA J AUTOMATIC, V7, P1190, DOI 10.1109/JAS.2020.1003117.
   Wang XH, 2019, IEEE-CAA J AUTOMATIC, V6, P540, DOI 10.1109/JAS.2017.7510664.
   Weinberger K. Q., 2008, P 25 INT C MACH LEAR, P1160, DOI DOI 10.1145/1390156.1390302.
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930.
   Wu D, 2022, IEEE T SERV COMPUT, V15, P793, DOI 10.1109/TSC.2019.2961895.
   Xin Z, 2019, IEEE INT CONF ROBOT, P5979, DOI 10.1109/ICRA.2019.8794383.
   Xing, 2002, NIPS, V15, P505.
   Xing Y, 2018, IEEE-CAA J AUTOMATIC, V5, P645, DOI 10.1109/JAS.2018.7511063.
   Yin P, 2019, IEEE INT CONF ROBOT, P319, DOI 10.1109/ICRA.2019.8793752.
   Zetao Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3223, DOI 10.1109/ICRA.2017.7989366.
   Zhou B., 2016, PROC CVPR IEEE, P2921, DOI {[}DOI 10.1109/CVPR.2016.319, 10.1109/CVPR.2016.319].
   Zhou Q, 2017, IEEE T SYST MAN CY-S, V47, P1, DOI 10.1109/TSMC.2016.2557222.
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244.},
Number-of-Cited-References = {76},
Times-Cited = {1},
Usage-Count-Last-180-days = {8},
Usage-Count-Since-2013 = {8},
Journal-ISO = {IEEE-CAA J. Automatica Sin.},
Doc-Delivery-Number = {WR7ZG},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000714714500012},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000589315500001,
Author = {De Martini, Daniele and Gadd, Matthew and Newman, Paul},
Title = {kRadar plus plus : Coarse-to-Fine FMCW Scanning Radar Localisation},
Journal = {SENSORS},
Year = {2020},
Volume = {20},
Number = {21},
Pages = {6002},
Month = {NOV},
Abstract = {Simple Summary
   This paper presents a hierarchical approach to place recognition and
   pose refinement for Frequency-Modulated Continuous-Wave (FMCW) scanning
   radar localisation.
   This paper presents a novel two-stage system which integrates
   topological localisation candidates from a radar-only place recognition
   system with precise pose estimation using spectral landmark-based
   techniques. We prove that the-recently available-seminal radar place
   recognition (RPR) and scan matching sub-systems are complementary in a
   style reminiscent of the mapping and localisation systems underpinning
   visual teach-and-repeat (VTR) systems which have been exhibited robustly
   in the last decade. Offline experiments are conducted on the most
   extensive radar-focused urban autonomy dataset available to the
   community with performance comparing favourably with and even rivalling
   alternative state-of-the-art radar localisation systems. Specifically,
   we show the long-term durability of the approach and of the sensing
   technology itself to autonomous navigation. We suggest a range of
   sensible methods of tuning the system, all of which are suitable for
   online operation. For both tuning regimes, we achieve, over the course
   of a month of localisation trials against a single static map, high
   recalls at high precision, and much reduced variance in erroneous metric
   pose estimation. As such, this work is a necessary first step towards a
   radar teach-and-repeat (RTR) system and the enablement of autonomy
   across extreme changes in appearance or inclement conditions.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {De Martini, D; Gadd, M (Corresponding Author), Univ Oxford, Oxford Robot Inst, Dept Engn Sci, Oxford OX1 3PJ, England.
   De Martini, Daniele; Gadd, Matthew; Newman, Paul, Univ Oxford, Oxford Robot Inst, Dept Engn Sci, Oxford OX1 3PJ, England.},
DOI = {10.3390/s20216002},
Article-Number = {6002},
EISSN = {1424-8220},
Keywords = {radar; mapping; localisation; place recognition; autonomous vehicles;
   deep learning},
Keywords-Plus = {NAVIGATION},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {Correspondencedaniele@robots.ox.ac.uk
   mattgadd@robots.ox.ac.uk
   pnewman@robots.ox.ac.uk},
Affiliations = {League of European Research Universities - LERU; University of Oxford},
ResearcherID-Numbers = {Gadd, Matthew/AAS-4274-2020},
ORCID-Numbers = {Gadd, Matthew/0000-0001-9447-8619},
Funding-Acknowledgement = {Lloyd's Register Foundation; University of York; UK EPSRC
   {[}EP/M019918/1]; EPSRC {[}EP/M019918/1] Funding Source: UKRI},
Funding-Text = {This project is supported by the Assuring Autonomy International
   Programme, a partnership between Lloyd's Register Foundation and the
   University of York and UK EPSRC Programme Grant EP/M019918/1.},
Cited-References = {Aldera R., 2019, P IEEE INT TRANSP SY.
   Aldera R, 2019, IEEE INT CONF ROBOT, P1190, DOI 10.1109/ICRA.2019.8794014.
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI {[}10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572].
   Barnes D., 2019, ARXIV190903752.
   Barnes D, 2020, IEEE INT CONF ROBOT, P9484, DOI 10.1109/ICRA40945.2020.9196835.
   Bengio Yoshua, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P437, DOI 10.1007/978-3-642-35289-8\_26.
   Cen SH, 2019, IEEE INT CONF ROBOT, P298, DOI 10.1109/ICRA.2019.8793990.
   Cen SH, 2018, IEEE INT CONF ROBOT, P6045, DOI 10.1109/ICRA.2018.8460687.
   Chen X., 2020, P ROB SCI ROB SCI SY.
   Churchill W, 2013, INT J ROBOT RES, V32, P1645, DOI 10.1177/0278364913499193.
   Churchill W, 2012, IEEE INT CONF ROBOT, P4525, DOI 10.1109/ICRA.2012.6224596.
   Cieslewski T, 2018, IEEE INT CONF ROBOT, P2466.
   Dequaire J., 2016, P IEEE INT C ROB AUT.
   Farina B, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082287.
   Furgale P, 2010, J FIELD ROBOT, V27, P534, DOI 10.1002/rob.20342.
   Gadd M., 2020, P IEEE INT VEH S 4 W.
   Gadd M., 2020, P IEEE ION POS LOC N.
   Garcia-Fidalgo E, 2017, IEEE T ROBOT, V33, P1061, DOI 10.1109/TRO.2017.2704598.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1.
   Hong ZY, 2020, IEEE INT C INT ROBOT, P5164, DOI 10.1109/IROS45743.2020.9341287.
   Horn RA., 1990, MATRIX ANAL.
   Kaul P., 2020, P IEEE INT VEH S IV.
   Kim G, 2020, IEEE INT CONF ROBOT, P6246.
   Kim G, 2018, IEEE INT C INT ROBOT, P4802, DOI 10.1109/IROS.2018.8593953.
   Kim T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154126.
   Krajnik T, 2018, IEEE INT C INT ROBOT, P1657, DOI 10.1109/IROS.2018.8593803.
   Kyberd S., 2019, P INT C FIELD SERV R.
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482.
   MacTavish Kirk, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2065, DOI 10.1109/ICRA.2017.7989238.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Maddern W, 2015, IEEE INT CONF ROBOT, P1684, DOI 10.1109/ICRA.2015.7139414.
   Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2\_18.
   Mielle M, 2019, 2019 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR).
   Reina G, 2015, SENSORS-BASEL, V15, P14661, DOI 10.3390/s150614661.
   Sarlin P.E., 2018, P 2 ANN C ROB LEARN.
   Sarlin PE, 2019, PROC CVPR IEEE, P12708, DOI 10.1109/CVPR.2019.01300.
   Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243.
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682.
   Sftescu S., 2020, P IEEE INT C ROB AUT.
   Sibley G, 2010, IEEE INT CONF ROBOT, P285, DOI 10.1109/ROBOT.2010.5509527.
   Sibley G, 2010, INT J ROBOT RES, V29, P958, DOI 10.1177/0278364910369268.
   Simonyan K, 2014, C TRACK P.
   Sprunk C, 2013, IEEE INT C INT ROBOT, P3144, DOI 10.1109/IROS.2013.6696803.
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517.
   Tang TY, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI.
   Tang TYQ, 2020, IEEE ROBOT AUTOM LET, V5, P1087, DOI 10.1109/LRA.2020.2965907.
   Mau TN, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072539.
   Vivet D, 2013, SENSORS-BASEL, V13, P4527, DOI 10.3390/s130404527.
   Wan Y, 2020, J COASTAL RES, P9, DOI 10.2112/SI99-002.1.
   Wang TH, 2018, IEEE INT CONF ROBOT, P2341.
   Weston R, 2019, IEEE INT CONF ROBOT, P5446, DOI 10.1109/ICRA.2019.8793263.
   Williams WD, 2005, LAKES HANDBOOK, VOL 2: LAKE RESTORATION AND REHABILITATION, P200.},
Number-of-Cited-References = {52},
Times-Cited = {6},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {OR2OX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000589315500001},
OA = {Green Submitted, gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000380560500011,
Author = {Kanai, S. and Hatakeyama, R. and Date, H.},
Editor = {Fuse, T and Nakagawa, M},
Title = {IMPROVEMENT OF 3D MONTE CARLO LOCALIZATION USING A DEPTH CAMERA AND
   TERRESTRIAL LASER SCANNER},
Booktitle = {INDOOR-OUTDOOR SEAMLESS MODELLING, MAPPING AND NAVIGATION},
Series = {International Archives of the Photogrammetry Remote Sensing and Spatial
   Information Sciences},
Year = {2015},
Volume = {44},
Number = {W5},
Pages = {61-66},
Note = {Indoor-Outdoor Seamless Modelling, Mapping and Navigation, Tokyo, JAPAN,
   MAY 21-22, 2015},
Abstract = {Effective and accurate localization method in three-dimensional indoor
   environments is a key requirement for indoor navigation and lifelong
   robotic assistance. So far, Monte Carlo Localization (MCL) has given one
   of the promising solutions for the indoor localization methods. Previous
   work of MCL has been mostly limited to 2D motion estimation in a planar
   map, and a few 3D MCL approaches have been recently proposed. However,
   their localization accuracy and efficiency still remain at an
   unsatisfactory level (a few hundreds millimetre error at up to a few
   FPS) or is not fully verified with the precise ground truth. Therefore,
   the purpose of this study is to improve an accuracy and efficiency of
   6DOF motion estimation in 3D MCL for indoor localization. Firstly, a
   terrestrial laser scanner is used for creating a precise 3D mesh model
   as an environment map, and a professional-level depth camera is
   installed as an outer sensor. GPU scene simulation is also introduced to
   upgrade the speed of prediction phase in MCL. Moreover, for further
   improvement, GPGPU programming is implemented to realize further speed
   up of the likelihood estimation phase, and anisotropic particle
   propagation is introduced into MCL based on the observations from an
   inertia sensor. Improvements in the localization accuracy and efficiency
   are verified by the comparison with a previous MCL method. As a result,
   it was confirmed that GPGPU-based algorithm was effective in increasing
   the computational efficiency to 10-50 FPS when the number of particles
   remain below a few hundreds. On the other hand, inertia sensor-based
   algorithm reduced the localization error to a median of 47mm even with
   less number of particles. The results showed that our proposed 3D MCL
   method outperforms the previous one in accuracy and efficiency.},
Publisher = {COPERNICUS GESELLSCHAFT MBH},
Address = {BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Kanai, S (Corresponding Author), Hokkaido Univ, Grad Sch Informat Sci \& Technol, Kita Ku, Sapporo, Hokkaido 0600814, Japan.
   Kanai, S.; Hatakeyama, R.; Date, H., Hokkaido Univ, Grad Sch Informat Sci \& Technol, Kita Ku, Sapporo, Hokkaido 0600814, Japan.},
DOI = {10.5194/isprsarchives-XL-4-W5-61-2015},
ISSN = {2194-9034},
Keywords = {Monte Carlo Localization; Depth Camera; Terrestrial Laser Scanner;
   GPGPU; IMU; Scene Simulation},
Research-Areas = {Physical Geography; Remote Sensing; Imaging Science \& Photographic
   Technology},
Web-of-Science-Categories  = {Geography, Physical; Remote Sensing; Imaging Science \& Photographic
   Technology},
Author-Email = {kanai@ssi.ist.hokudai.ac.jp
   r\_hatakeyama@sdm.ssi.ist.hokudai.ac.jp
   hdate@ssi.ist.hokudai.ac.jp},
Affiliations = {Hokkaido University},
Funding-Acknowledgement = {Grants-in-Aid for Scientific Research {[}26560168] Funding Source: KAKEN},
Cited-References = {Borenstein J, 1997, J ROBOTIC SYST, V14, P231.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Doucet A, 2001, STAT SEQUENTIAL MONT, P437.
   Eberly D.H., 2014, GPGPU PROGRAMMING GA.
   Fallon MF, 2012, IEEE INT CONF ROBOT, P1663, DOI 10.1109/ICRA.2012.6224951.
   Hornung A, 2014, INT J HUM ROBOT, V11, DOI 10.1142/S0219843614410023.
   Sanders Jason., 2010, CUDA EXAMPLE INTRO G.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   THRUN S, 2005, PROBABILISTIC ROBOTI, P189.
   Yongjin J., 2013, J ROBOT SOC JPN, V31, P896.},
Number-of-Cited-References = {10},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Doc-Delivery-Number = {BF3NW},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000380560500011},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000330774900015,
Author = {Kaplan, Haylee and van Niekerk, Adriaan and Le Roux, Johannes J. and
   Richardson, David M. and Wilson, John R. U.},
Title = {Incorporating risk mapping at multiple spatial scales into eradication
   management plans},
Journal = {BIOLOGICAL INVASIONS},
Year = {2014},
Volume = {16},
Number = {3, SI},
Pages = {691-703},
Month = {MAR},
Abstract = {The success of pro-active management of invasive plants depends on the
   ability to rapidly detect invasive populations and individuals. However,
   the factors important for detection depend on the spatial scale
   examined. We propose a protocol for developing risk maps at national,
   landscape, and local scales to improve detection rates of invasive plant
   species. We test this approach in the context of developing an
   eradication plan for the invasive tree Acacia stricta in South Africa.
   At a national scale we used bioclimatic models coupled with the most
   likely sites of introduction (i.e. forestry nursery plantations) to
   identify areas where national-scale surveillance should be focussed. At
   the landscape and local scales we correlated the presence of A. stricta
   populations to various attributes. Regional populations were found in
   forestry plantations only, and mostly on highly used graded roads along
   which seeds are spread by road maintenance vehicles. Locally, previously
   recorded plant localities accurately predicted individuals in subsequent
   surveys. Using these variables, we produced a map of high-risk areas
   that facilitated targeted searches-which reduced the required search
   effort by ca. 83 \%-and developed recommendations for site-specific
   surveying. With the high visibility of plants, and relatively small seed
   banks, long-term annual clearing should achieve eradication. We propose
   that such multi-scale risk mapping is valuable for prioritising
   management and surveillance efforts, though caution that the approach is
   correlative and so it does not represent all the sites that can be
   invaded.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Wilson, JRU (Corresponding Author), Univ Stellenbosch, Dept Bot \& Zool, Ctr Invas Biol, ZA-7602 Matieland, South Africa.
   Kaplan, Haylee; Le Roux, Johannes J.; Richardson, David M.; Wilson, John R. U., Univ Stellenbosch, Dept Bot \& Zool, Ctr Invas Biol, ZA-7602 Matieland, South Africa.
   van Niekerk, Adriaan, Univ Stellenbosch, Dept Geog \& Environm Studies, Ctr Geog Anal, ZA-7602 Matieland, South Africa.
   Wilson, John R. U., Kirstenbosch Res Ctr, South African Natl Biodivers Inst, Invas Species Programme, ZA-7735 Claremont, CA, South Africa.},
DOI = {10.1007/s10530-013-0611-z},
ISSN = {1387-3547},
EISSN = {1573-1464},
Keywords = {Biological invasions; Early detection; Eradication; Invasive plant; Risk
   mapping; Surveillance; Tree invasions},
Keywords-Plus = {AUSTRALIAN ACACIAS; SOUTH-AFRICA; INVASIVE PLANTS; SURVEILLANCE;
   FEASIBILITY; POPULATION; IMPACTS; BIOLOGY; SEARCH; ROADS},
Research-Areas = {Biodiversity \& Conservation; Environmental Sciences \& Ecology},
Web-of-Science-Categories  = {Biodiversity Conservation; Ecology},
Author-Email = {invasivespecies@sanbi.org.za
   john.wilson2@gmail.com},
Affiliations = {Stellenbosch University; Stellenbosch University; South African National
   Biodiversity Institute},
ResearcherID-Numbers = {Richardson, David M/A-1495-2008
   Wilson, John R./B-4101-2008
   },
ORCID-Numbers = {Richardson, David M/0000-0001-9574-8297
   Wilson, John R./0000-0003-0174-3239
   Le Roux, Johannes/0000-0001-7911-9810
   Van Niekerk, Adriaan/0000-0002-5631-0206},
Funding-Acknowledgement = {DST-NRF Centre of Excellence in Invasion Biology; Working for Water
   (WfW) Programme through ``Research for Integrated Management of Invasive
   Alien Species''; National Research Foundation {[}85417]; Oppenheimer
   Memorial Trust; WfW through South African National Biodiversity
   Institute's Invasive Species Progamme},
Funding-Text = {This project was funded by the DST-NRF Centre of Excellence in Invasion
   Biology and the Working for Water (WfW) Programme through their
   collaborative project on ``Research for Integrated Management of
   Invasive Alien Species'' and through the WfW funded South African
   National Biodiversity Institute's Invasive Species Progamme. DMR
   acknowledges financial support from the National Research Foundation
   (Grant 85417), and the Oppenheimer Memorial Trust. We thank Dane
   Paijmans and Suzaan Kritzinger-Klopper for assistance in the field;
   Ernita van Wyk for co-ordinating the management meeting; and SANParks
   and MTO Forestry (Pty) Ltd. for logistical support.},
Cited-References = {Butcher ER, 2011, AUSTRAL ECOL, V36, P621, DOI 10.1111/j.1442-9993.2010.02196.x.
   Cacho OJ, 2007, AUST J AGR RESOUR EC, V51, P425, DOI 10.1111/j.1467-8489.2007.00389.x.
   Cacho OJ, 2006, BIOL INVASIONS, V8, P903, DOI 10.1007/s10530-005-4733-9.
   Cacho OJ, 2010, ENVIRON MODELL SOFTW, V25, P444, DOI 10.1016/j.envsoft.2009.10.014.
   Christy MT, 2010, J APPL ECOL, V47, P106, DOI 10.1111/j.1365-2664.2009.01753.x.
   Ferguson L., 2003, BACKCOUNTRY ROAD MAI.
   Fox JC, 2009, DIVERS DISTRIB, V15, P577, DOI 10.1111/j.1472-4642.2009.00562.x.
   Gaertner M, 2009, PROG PHYS GEOG, V33, P319, DOI 10.1177/0309133309341607.
   Gardener MR, 2010, RESTOR ECOL, V18, P20, DOI 10.1111/j.1526-100X.2009.00614.x.
   Gelbard JL, 2003, CONSERV BIOL, V17, P420, DOI 10.1046/j.1523-1739.2003.01408.x.
   Gibson MR, 2011, DIVERS DISTRIB, V17, P911, DOI 10.1111/j.1472-4642.2011.00808.x.
   Giorgis MA, 2011, BIOL INVASIONS, V13, P1423, DOI 10.1007/s10530-010-9900-y.
   Glen H.F., 2002, CULTIVATED PLANTS SO.
   Gordon Doria R., 2010, Plant Protection Quarterly, V25, P56.
   Harrison SD, 2002, COMMENTARY, V113, P4.
   Hauser CE, 2009, ECOL LETT, V12, P683, DOI 10.1111/j.1461-0248.2009.01323.x.
   Henderson L., 1998, Applied Plant Science, V12, P31.
   Hester SM, 2013, DIVERS DISTRIB, V19, P580, DOI 10.1111/ddi.12053.
   Hijmans RJ, 2005, INT J CLIMATOL, V25, P1965, DOI 10.1002/joc.1276.
   Jimenez-Valverde A, 2011, BIOL INVASIONS, V13, P2785, DOI 10.1007/s10530-011-9963-4.
   Kaplan H, 2012, S AFR J BOT, V83, P23, DOI 10.1016/j.sajb.2012.07.016.
   Kery M, 2003, J ECOL, V91, P265, DOI 10.1046/j.1365-2745.2003.00759.x.
   Le Maitre DC, 2011, DIVERS DISTRIB, V17, P1015, DOI 10.1111/j.1472-4642.2011.00816.x.
   Moore JL, 2011, DIVERS DISTRIB, V17, P1047, DOI 10.1111/j.1472-4642.2011.00809.x.
   Mortensen DA, 2009, INVAS PLANT SCI MANA, V2, P191, DOI 10.1614/IPSM-08-125.1.
   Myers JH, 2000, TRENDS ECOL EVOL, V15, P316, DOI 10.1016/S0169-5347(00)01914-5.
   Panetta FD, 2009, INVAS PLANT SCI MANA, V2, P360, DOI 10.1614/IPSM-09-003.1.
   Panetta FD, 2005, DIVERS DISTRIB, V11, P435, DOI 10.1111/j.1366-9516.2005.00179.x.
   Peltzer DA, 2008, J APPL ECOL, V45, P467, DOI 10.1111/j.1365-2664.2007.01410.x.
   Peters J, 2005, TETRAZOLIUM TESTING, V29.
   Peterson AT, 2005, CURR SCI INDIA, V89, P9.
   Pheloung PC, 1999, J ENVIRON MANAGE, V57, P239, DOI 10.1006/jema.1999.0297.
   Phillips SJ, 2006, ECOL MODEL, V190, P231, DOI 10.1016/j.ecolmodel.2005.03.026.
   Poynton RJ, 2009, TREE PLANTING SO AFR.
   Pysek P, 2010, ANNU REV ENV RESOUR, V35, P25, DOI 10.1146/annurev-environ-033009-095548.
   Reese GC, 2005, ECOL APPL, V15, P554, DOI 10.1890/03-5374.
   Rejmanek M, 2000, AUSTRAL ECOL, V25, P497, DOI 10.1046/j.1442-9993.2000.01080.x.
   Rejmanek M, 2002, TURNING TIDE ERADICA, P249.
   Richardson DM, 2008, PERSPECT PLANT ECOL, V10, P161, DOI 10.1016/j.ppees.2008.03.001.
   Richardson DM, 2011, DIVERS DISTRIB, V17, P771, DOI 10.1111/j.1472-4642.2011.00824.x.
   Rouget M, 2004, DIVERS DISTRIB, V10, P475, DOI 10.1111/j.1366-9516.2004.00118.x.
   Simberloff D, 2003, WEED SCI, V51, P247, DOI 10.1614/0043-1745(2003)051{[}0247:EPIATO]2.0.CO;2.
   Simberloff D, 2003, CONSERV BIOL, V17, P83, DOI 10.1046/j.1523-1739.2003.02028.x.
   Spooner PG, 2004, BIOL CONSERV, V117, P393, DOI 10.1016/j.biocon.2003.08.003.
   Taylor K, 2012, DIVERS DISTRIB, V18, P942, DOI 10.1111/j.1472-4642.2012.00926.x.
   Thompson GD, 2011, DIVERS DISTRIB, V17, P1001, DOI 10.1111/j.1472-4642.2011.00820.x.
   van Wilgen BW, 2011, DIVERS DISTRIB, V17, P1060, DOI 10.1111/j.1472-4642.2011.00785.x.
   Vanderhoof M, 2009, INVAS PLANT SCI MANA, V2, P260, DOI 10.1614/IPSM-09-005.1.
   Wilson JRU, 2013, S AFR J SCI, V109, DOI 10.1590/sajs.2013/20120111.
   Wilson JRU, 2011, DIVERS DISTRIB, V17, P1030, DOI 10.1111/j.1472-4642.2011.00815.x.
   Zenni RD, 2009, S AFR J BOT, V75, P485, DOI 10.1016/j.sajb.2009.04.001.},
Number-of-Cited-References = {51},
Times-Cited = {37},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {56},
Journal-ISO = {Biol. Invasions},
Doc-Delivery-Number = {AA0GZ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000330774900015},
OA = {Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000374442300019,
Author = {Prasanna, Prateek and Dana, Kristin J. and Gucunski, Nenad and Basily,
   Basily B. and La, Hung M. and Lim, Ronny Salim and Parvardeh, Hooman},
Title = {Automated Crack Detection on Concrete Bridges},
Journal = {IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING},
Year = {2016},
Volume = {13},
Number = {2},
Pages = {591-599},
Month = {APR},
Abstract = {Detection of cracks on bridge decks is a vital task for maintaining the
   structural health and reliability of concrete bridges. Robotic imaging
   can be used to obtain bridge surface image sets for automated on-site
   analysis. We present a novel automated crack detection algorithm, the
   STRUM (spatially tuned robust multifeature) classifier, and demonstrate
   results on real bridge data using a state-of-the-art robotic bridge
   scanning system. By using machine learning classification, we eliminate
   the need for manually tuning threshold parameters. The algorithm uses
   robust curve fitting to spatially localize potential crack regions even
   in the presence of noise. Multiple visual features that are spatially
   tuned to these regions are computed. Feature computation includes
   examining the scale-space of the local feature in order to represent the
   information and the unknown salient scale of the crack. The
   classification results are obtained with real bridge data from hundreds
   of crack regions over two bridges. This comprehensive analysis shows a
   peak STRUM classifier performance of 95\% compared with 69\% accuracy
   from a more typical image-based approach. In order to create a composite
   global view of a large bridge span, an image sequence from the robot is
   aligned computationally to create a continuous mosaic. A crack density
   map for the bridge mosaic provides a computational description as well
   as a global view of the spatial patterns of bridge deck cracking. The
   bridges surveyed for data collection and testing include Long-Term
   Bridge Performance program's (LTBP) pilot project bridges at Haymarket,
   VA, USA, and Sacramento, CA, USA.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Prasanna, P; Dana, KJ (Corresponding Author), Rutgers State Univ, Dept Elect \& Comp Engn, Piscataway, NJ 08854 USA.
   Gucunski, N (Corresponding Author), Rutgers State Univ, Dept Civil \& Environm Engn, Piscataway, NJ 08854 USA.
   Lim, RS; Parvardeh, H (Corresponding Author), Rutgers State Univ, Ctr Adv Infrastruct \& Transportat, Piscataway, NJ 08854 USA.
   La, HM (Corresponding Author), Univ Nevada, Dept Comp Sci \& Engn, Reno, NV 89557 USA.
   Prasanna, Prateek; Dana, Kristin J., Rutgers State Univ, Dept Elect \& Comp Engn, Piscataway, NJ 08854 USA.
   Gucunski, Nenad; Basily, Basily B., Rutgers State Univ, Dept Civil \& Environm Engn, Piscataway, NJ 08854 USA.
   Lim, Ronny Salim; Parvardeh, Hooman, Rutgers State Univ, Ctr Adv Infrastruct \& Transportat, Piscataway, NJ 08854 USA.
   La, Hung M., Univ Nevada, Dept Comp Sci \& Engn, Reno, NV 89557 USA.},
DOI = {10.1109/TASE.2014.2354314},
ISSN = {1545-5955},
EISSN = {1558-3783},
Keywords = {Adaboost; bridge deck inspection; bridge maintenance; computer vision;
   concrete; crack detection; crack pattern},
Keywords-Plus = {IMAGE; RETRIEVAL},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {prateek.prasanna@gmail.com
   kdana@ece.rutgers.edu
   gucunski@rci.rutgers.edu
   hla@unr.edu
   ronny.lim@rutgers.edu
   hml42@rci.rutgers.edu},
Affiliations = {Rutgers State University New Brunswick; Rutgers State University New
   Brunswick; Rutgers State University New Brunswick; Nevada System of
   Higher Education (NSHE); University of Nevada Reno},
ResearcherID-Numbers = {Prasanna, Prateek/Y-5136-2019
   },
ORCID-Numbers = {Prasanna, Prateek/0000-0002-3068-3573},
Funding-Acknowledgement = {Federal Highway Administration, U.S. Department of Transportation},
Funding-Text = {The authors would like to thank the Federal Highway Administration, U.S.
   Department of Transportation, for supporting this research as part of
   the Long-Term Bridge Performance Program. They also express their
   gratitude to K. Zhao, graduate student at Rutgers University, for his
   valuable contribution towards the deck-mosaicing application.},
Cited-References = {Adhikari RS, 2014, AUTOMAT CONSTR, V39, P180, DOI 10.1016/j.autcon.2013.06.011.
   Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9\_3.
   Bishop C. M., 2006, PATTERN RECOGNITION, V1.
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324.
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552.
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411.
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755.
   Duda R., 2001, PATTERN CLASSIFICATI, Vxx.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML `96), P148.
   Garg R, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION \& TRANSMISSION (3DIMPVT 2012), P65, DOI 10.1109/3DIMPVT.2012.35.
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P1, DOI 10.1145/1656274.1656278.
   Hoang-Nam Nguyen, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P766, DOI 10.1109/ISPACS.2012.6473594.
   Jahanshahi MR, 2013, MACH VISION APPL, V24, P227, DOI 10.1007/s00138-011-0394-0.
   Kruschwitz S., 2009, M LTBP PROGRAM OBJEC.
   La Hung M., 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P1053, DOI 10.1109/CoASE.2013.6653886.
   La HM, 2013, IEEE-ASME T MECH, V18, P1655, DOI 10.1109/TMECH.2013.2279751.
   Lee BY, 2013, STRUCT INFRASTRUCT E, V9, P567, DOI 10.1080/15732479.2011.593891.
   Lim Ronny Salim, 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P6288, DOI 10.1109/ICRA.2011.5980131.
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030.
   Mitchell T. M., 2006, CMUML06108 SCH COMP.
   Mitchell T.M., 1997, MACH LEARN, Vfirst.
   Mitchell TM, 1997, AI MAG, V18, P11.
   Nishikawa T, 2012, COMPUT-AIDED CIV INF, V27, P29, DOI 10.1111/j.1467-8667.2011.00716.x.
   Tong X., 2011, P INT C IM AN SIGN P, P568.
   Triggs Bill, 1999, LECT NOTES COMPUTER, P298, DOI DOI 10.1007/3-540-44480-7\_21.
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517.
   Wan B., 2010, WHATS CAUSING CRACKI.
   Yamaguchi T, 2008, C IND ELECT APPL, P1875, DOI 10.1109/ICIEA.2008.4582845.
   Yamaguchi T, 2010, MACH VISION APPL, V21, P797, DOI 10.1007/s00138-009-0189-8.
   Zhu ZH, 2011, AUTOMAT CONSTR, V20, P874, DOI 10.1016/j.autcon.2011.03.004.},
Number-of-Cited-References = {31},
Times-Cited = {178},
Usage-Count-Last-180-days = {39},
Usage-Count-Since-2013 = {175},
Journal-ISO = {IEEE Trans. Autom. Sci. Eng.},
Doc-Delivery-Number = {DJ8DI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000374442300019},
ESI-Highly-Cited-Paper = {Y},
ESI-Hot-Paper = {N},
DA = {2022-05-17},
}

@inproceedings{ WOS:000412755000034,
Author = {Dehghan, S. M. Mehdi and Moradi, Hadi},
Book-Group-Author = {IEEE},
Title = {A Geometrical Approach for Aerial Cooperative Obstacle Mapping using
   RSSI Observations},
DOI = {10.1109/ICRoM.2014.6990900},
Booktitle = {2014 SECOND RSI/ISM INTERNATIONAL CONFERENCE ON ROBOTICS AND
   MECHATRONICS (ICROM)},
Series = {RSI International Conference on Robotics and Mechatronics ICRoM},
Year = {2014},
Pages = {197-202},
Note = {2nd RSI/ISM International Conference on Robotics and Mechatronics
   (ICRoM), Tehran, IRAN, OCT 15-17, 2014},
Abstract = {The effect of an obstacle on signal strength attenuation is the most
   important reason that affects the performance of distance estimation
   based on Received Signal Strength Indication (RSSI) observations.
   Consequently, in this paper, a novel approach for estimation of the
   location and height of an obstacle between two UAVs using RSSI
   observations is proposed which would help to better estimate the
   location of a radio frequency (RF) source. The long-term goal of
   developing this approach is to improve the localization of an RF source
   by removing the effect of obstacle(s) on the signal attenuation. This
   approach is based on path planning of the UAVs to estimate the tip of
   the obstacle between them. The change in the diffraction loss
   observations are used to find the Line Of Sight (LOS) positions of the
   UAVs. These LOS lines, constructed by connecting the UAVs in LOS
   situation, are the locus of the tip of the obstacle and used in an
   iterative geometrical approach for estimation of the location of the tip
   of the obstacle. Due to the uncertainty in determining the LOS position
   which is created because of the radius of the Fresnel zone, the motion
   steps of UAVs, and the non-modeled dynamics in signal attenuation, an
   EKF filter is used to estimate the tip of the obstacle. The approach has
   been simulated and the results show that the approach provides better
   accuracy in RF source localization compared to the basic approach which
   does not consider the obstacles in the localization process.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dehghan, SMM (Corresponding Author), Univ Tehran, Adv Robot \& Intelligent Syst Lab, Sch Elect \& Comp Engn, Tehran, Iran.
   Dehghan, S. M. Mehdi; Moradi, Hadi, Univ Tehran, Adv Robot \& Intelligent Syst Lab, Sch Elect \& Comp Engn, Tehran, Iran.},
ISSN = {2377-679X},
EISSN = {2572-6889},
ISBN = {978-1-4799-6743-8},
Keywords = {Unmanned Aerial Vehicle; Obstacle Mapping; RSSI observation},
Keywords-Plus = {LOCALIZATION},
Research-Areas = {Engineering; Mechanics; Robotics},
Web-of-Science-Categories  = {Engineering, Electrical \& Electronic; Engineering, Mechanical;
   Mechanics; Robotics},
Author-Email = {smm.dehghan@ut.ac.ir
   moradih@ut.ac.ir},
Affiliations = {University of Tehran},
ResearcherID-Numbers = {Dehghan, SMM/ABB-3757-2021},
ORCID-Numbers = {Dehghan, SMM/0000-0002-3835-0212},
Cited-References = {Dehghan S. M. M., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1146, DOI 10.1109/ROBIO.2012.6491124.
   Dehghan S.M.M., 2014, INT C ROB MECH ICROM.
   Dehghan S.M.M., INT J ROBOTICS UNPUB.
   Eren T., 2007, TURKISH J ELECT ENG, V15.
   Fidan B, 2009, 2009 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING (ISSNIP 2009), P115, DOI 10.1109/ISSNIP.2009.5416817.
   Frew EW, 2008, J AEROS COMP INF COM, V5, P84, DOI 10.2514/1.26558.
   Hmam H, 2010, IEEE T AERO ELEC SYS, V46, P944, DOI 10.1109/TAES.2010.5461671.
   Jain R., 2007, CHANNEL MODELS TUTOR.
   Kim C. Y., 2011, IEEE INT CONF ROBOT.
   Kwon H, 2012, J INTELL ROBOT SYST, V65, P479, DOI 10.1007/s10846-011-9581-5.
   Lee S. C., 2009, INT J CONTROL AUTOMA, V2.
   Lee SC, 2009, INT J CONTROL AUTOM, V2, P35.
   Li M., 2008, 16 EUR SIGN PROC C E.
   Okello N, 2011, IEEE T AERO ELEC SYS, V47, P1723, DOI 10.1109/TAES.2011.5937261.
   Pack DJ, 2009, IEEE T SYST MAN CY B, V39, P959, DOI 10.1109/TSMCB.2008.2010865.
   Tassetto Dimitri, 2008, 2008 4th Advanced Satellite Mobile Systems (ASMS), P320, DOI 10.1109/ASMS.2008.62.
   WONG HK, 2002, FIELD STRENGTH PREDI.
   Zhang K. S., 2012, J APPL MECH MAT, V192.},
Number-of-Cited-References = {18},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BI5RK},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000412755000034},
DA = {2022-05-17},
}

@article{ WOS:000277697400001,
Author = {Lee, Jung-Suk and Chung, Wan Kyun},
Title = {Robust mobile robot localization in highly non-static environments},
Journal = {AUTONOMOUS ROBOTS},
Year = {2010},
Volume = {29},
Number = {1},
Pages = {1-16},
Month = {JUL},
Abstract = {In this paper, we propose a robust pose tracking method for mobile robot
   localization with an incomplete map in a highly non-static environment.
   This algorithm will work with a simple map that does not include
   complete information about the non-static environment. With only an
   initial incomplete map, a mobile robot cannot estimate its pose because
   of the inconsistency between the real observations from the environment
   and the predicted observations on the incomplete map. The proposed
   localization algorithm uses the approach of sampling from a
   non-corrupted window, which allows the mobile robot to estimate its pose
   more robustly in a non-static environment even when subjected to severe
   corruption of observations. The algorithm sequence involves identifying
   the corruption by comparing the real observations with the corresponding
   predicted observations of all particles, sampling particles from a
   non-corrupted window that consists of multiple non-corrupted sets, and
   filtering sensor measurements to provide weights to particles in the
   corrupted sets. After localization, the estimated path may still contain
   some errors due to long-term corruption. These errors can be corrected
   using nonlinear constrained least-squares optimization. The incomplete
   map is then updated using both the corrected path and the stored sensor
   information. The performance of the proposed algorithm was verified via
   simulations and experiments in various highly non-static environments.
   Our localization algorithm can increase the success rate of tracking its
   pose to more than 95\% compared to estimates made without its use. After
   that, the initial incomplete map is updated based on the localization
   result.},
Publisher = {SPRINGER},
Address = {VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Chung, WK (Corresponding Author), Pohang Univ Sci \& Technol POSTECH, Robot Lab, Dept Mech Engn, Pohang, South Korea.
   Lee, Jung-Suk; Chung, Wan Kyun, Pohang Univ Sci \& Technol POSTECH, Robot Lab, Dept Mech Engn, Pohang, South Korea.},
DOI = {10.1007/s10514-010-9184-1},
ISSN = {0929-5593},
EISSN = {1573-7527},
Keywords = {Non-static environment; Localization; Pose tracking; Monte Carlo
   localization (MCL); Mobile robot},
Keywords-Plus = {MAPS},
Research-Areas = {Computer Science; Robotics},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Robotics},
Author-Email = {badol@postech.ac.kr
   wkchung@postech.ac.kr},
Affiliations = {Pohang University of Science \& Technology (POSTECH)},
Cited-References = {Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374.
   Bergman N., 1999, THESIS LINKOPING U L.
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286.
   CHUNG WK, 2007, P 13 INT S ROB RES, P277.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Dellaert F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P588, DOI 10.1109/CVPR.1999.784976.
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038.
   Doucet A, 2001, SEQUENTIAL MONTE CAR.
   Estrada C, 2005, IEEE T ROBOT, V21, P588, DOI 10.1109/TRO.2005.844673.
   Fox D, 1999, P 16 NAT C ART INT A.
   Fox D, 2001, ADV NEURAL INFORM PR, V14.
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015.
   Jensfelt P., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2531, DOI 10.1109/ROBOT.2000.846409.
   Jensfelt P., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2518, DOI 10.1109/ROBOT.2000.846407.
   Kanazawa K., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P346.
   Kwok C, 2003, IEEE INT CONF ROBOT, P2836, DOI 10.1109/ROBOT.2003.1242022.
   KWOK C, 2002, ADV NEURAL INFORM PR, V15.
   LEE D, 2005, P IEEE RSJ INT C INT, P3746.
   Lee JS, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1133, DOI 10.1109/IROS.2008.4650943.
   Lee K, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2908, DOI 10.1109/IROS.2008.4650882.
   Lenser S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1225, DOI 10.1109/ROBOT.2000.844766.
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275.
   MORAVEC HP, 1988, AI MAG, V9, P61.
   Oriolo G, 1997, J ROBOTIC SYST, V14, P179, DOI 10.1002/(SICI)1097-4563(199703)14:3<179::AID-ROB3>3.0.CO;2-O.
   Pagac D, 1998, IEEE T ROBOTIC AUTOM, V14, P623, DOI 10.1109/70.704234.
   Siciliano B, 2008, HDB ROBOTICS.
   Smith R., 1990, AUTONOMOUS ROBOT VEH, P167, DOI DOI 10.1007/978-1-4613-8997-2\_14.
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404.
   Stachniss C., 2005, P C ART INT, P1324.
   Thrun S, 2001, ARTIF INTELL, V128, P99, DOI 10.1016/S0004-3702(01)00069-8.
   Thrun S., 2005, PROBABILISTIC ROBOTI.
   Wolf DF, 2005, AUTON ROBOT, V19, P53, DOI 10.1007/s10514-005-0606-4.},
Number-of-Cited-References = {32},
Times-Cited = {13},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {7},
Journal-ISO = {Auton. Robot.},
Doc-Delivery-Number = {596PN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000277697400001},
DA = {2022-05-17},
}

@article{ WOS:000615495900001,
Author = {Leordeanu, Marius and Paraicu, Iulia},
Title = {Driven by Vision: Learning Navigation by Visual Localization and
   Trajectory Prediction},
Journal = {SENSORS},
Year = {2021},
Volume = {21},
Number = {3},
Pages = {852},
Month = {FEB},
Abstract = {When driving, people make decisions based on current traffic as well as
   their desired route. They have a mental map of known routes and are
   often able to navigate without needing directions. Current published
   self-driving models improve their performances when using additional GPS
   information. Here we aim to push forward self-driving research and
   perform route planning even in the complete absence of GPS at inference
   time. Our system learns to predict in real-time vehicle's current
   location and future trajectory, on a known map, given only the raw video
   stream and the final destination. Trajectories consist of instant
   steering commands that depend on present traffic, as well as longer-term
   navigation decisions towards a specific destination. Along with our
   novel proposed approach to localization and navigation from visual data,
   we also introduce a novel large dataset in an urban environment, which
   consists of video and GPS streams collected with a smartphone while
   driving. The GPS is automatically processed to obtain supervision labels
   and to create an analytical representation of the traversed map. In
   tests, our solution outperforms published state of the art methods on
   visual localization and steering and provides reliable navigation
   assistance between any two known locations. We also show that our system
   can adapt to short and long-term changes in weather conditions or the
   structure of the urban environment. We make the entire dataset and the
   code publicly available.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Leordeanu, M (Corresponding Author), Romanian Acad IMAR, Inst Math, Calea Grivitei 21, Bucharest 010702, Romania.
   Leordeanu, M (Corresponding Author), Univ Politehn Bucharest UPB, Dept Automat \& Comp Sci, Splaiul Independentei 313, Bucharest 060042, Romania.
   Leordeanu, Marius; Paraicu, Iulia, Romanian Acad IMAR, Inst Math, Calea Grivitei 21, Bucharest 010702, Romania.
   Leordeanu, Marius, Univ Politehn Bucharest UPB, Dept Automat \& Comp Sci, Splaiul Independentei 313, Bucharest 060042, Romania.},
DOI = {10.3390/s21030852},
Article-Number = {852},
EISSN = {1424-8220},
Keywords = {autonomous driving; self-driving; visual localization; visual
   navigation; deep learning; trajectory prediction; geometric computer
   vision; autonomous driving dataset; localization by image segmentation},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {marius.leordeanu@cs.pub.ro
   iulia.paraicu@stud.acs.upb.ro},
Affiliations = {Institute of Mathematics of the Romanian Academy; Romanian Academy of
   Sciences; University of Bucharest},
Funding-Acknowledgement = {UEFISCDI {[}EEA-RO-2018-0496, PN-III-P11.2-PCCDI-2017-0734]},
Funding-Text = {This work was funded by UEFISCDI, under Projects EEA-RO-2018-0496 and
   PN-III-P11.2-PCCDI-2017-0734. The authors wish to thank Victor Robu for
   his great help with preparing the dataset and the code for public
   release.},
Cited-References = {Amini A, 2019, IEEE INT CONF ROBOT, P8958, DOI 10.1109/ICRA.2019.8793579.
   Badue C, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113816.
   BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108.
   Bojarski Mariusz, 2016, arXiv.
   Chen B, 2009, UIST 2009: PROCEEDINGS OF THE 22ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P223.
   Chi Peng, 2010, 2010 International Computer Symposium (ICS 2010), P319, DOI 10.1109/COMPSYM.2010.5685494.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Corke P., 2017, ROBOTICS VISION CONT, V118.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Glassner Y., 2019, ARXIV190100114.
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918.
   Hassan I., 2020, ADV INTELLIGENT SYST, V4, P30.
   Hecker S., 2019, ARXIV190310995.
   Hecker S, 2018, LECT NOTES COMPUT SC, V11211, P449, DOI 10.1007/978-3-030-01234-2\_27.
   Janai Joel, 2020, Foundations and Trends in Computer Graphics and Vision, V12, P1, DOI 10.1561/0600000079.
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781.
   Kendall A, 2017, PROC CVPR IEEE, P6555, DOI 10.1109/CVPR.2017.694.
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336.
   Kuga R, 2017, IEEE INT CONF COMP V, P403, DOI 10.1109/ICCVW.2017.54.
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498.
   Marcu A., 2018, ARXIV180401322.
   Mattern Norman, 2010, 2010 IEEE/ION Position, Location and Navigation Symposium - PLANS 2010, P1100, DOI 10.1109/PLANS.2010.5507195.
   Mozaffari S, 2022, IEEE T INTELL TRANSP, V23, P33, DOI 10.1109/TITS.2020.3012034.
   Muller U., 2006, ADV NEURAL INFORM PR, V18, P739.
   Nedevschi S, 2013, IEEE T INTELL TRANSP, V14, P673, DOI 10.1109/TITS.2012.2228191.
   Piasco N, 2018, PATTERN RECOGN, V74, P90, DOI 10.1016/j.patcog.2017.09.013.
   Pomerleau D, 1988, TECH REP.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Santana E., 2016, ARXIV160801230.
   Sattler T, 2018, PROC CVPR IEEE, P8601, DOI 10.1109/CVPR.2018.00897.
   Sattler T, 2017, IEEE T PATTERN ANAL, V39, P1744, DOI 10.1109/TPAMI.2016.2611662.
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI 10.1007/s11263-019-01228-7.
   Shreyas V., 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P361, DOI 10.1007/978-981-15-0694-9\_34.
   Springenberg J. T., 2014, STRIVING SIMPLICITY.
   Sunderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986.
   Teichmann M, 2018, IEEE INT VEH SYM, P1013, DOI 10.1109/IVS.2018.8500504.
   Teplyashin D., 2018, P ADV NEUR INF PROC, P2424.
   Toft C, 2018, LECT NOTES COMPUT SC, V11206, P391, DOI 10.1007/978-3-030-01216-8\_24.
   Volk G, 2019, IEEE INT C INTELL TR, P285, DOI 10.1109/ITSC.2019.8917269.
   von Bernuth A, 2019, IEEE INT C INTELL TR, P41, DOI 10.1109/ITSC.2019.8917367.
   Xu H, 2017, IEEE INT C COMPUT, P740, DOI 10.1109/CSE-EUC.2017.145.},
Number-of-Cited-References = {41},
Times-Cited = {1},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {8},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {QD4NB},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000615495900001},
OA = {Green Published},
DA = {2022-05-17},
}

@article{ WOS:000517790100163,
Author = {Torok, Akos and Bogoly, Gyula and Somogyi, Arpad and Lovas, Tamas},
Title = {Application of UAV in Topographic Modelling and Structural Geological
   Mapping of Quarries and Their Surroundings-Delineation of Fault-Bordered
   Raw Material Reserves},
Journal = {SENSORS},
Year = {2020},
Volume = {20},
Number = {2},
Pages = {489},
Month = {JAN},
Abstract = {A 3D surface model of an active limestone quarry and a
   vegetation-covered plateau was created using unmanned aerial vehicle
   (UAV) technique in combination with terrestrial laser scanning (TLS).
   The aim of the research was to identify major fault zones that dissect
   the inaccessible quarry faces and to prepare a model that shows the
   location of these fault zones at the entire study area. An additional
   purpose was to calculate reserves of the four identified lithological
   units. It was only possible to measure faults at the lowermost two
   meters of the quarry faces. At the upper parts of the quarry and on the
   vegetation-covered plateau where no field geological information was
   available, remote sensing was used. Former logs of core drillings were
   obtained for the modelling of the spatial distribution of four
   lithological units representing cover beds and various quality of
   limestone reserves. With the comparison of core data, field measurements
   and remote sensing, it was possible to depict major faults. Waste
   material volumes and limestone reserves were calculated for five blocks
   that are surrounded by these faults. The paper demonstrates that, with
   remote sensing and with localised control field measurements, it is
   possible: (a) to provide all geometric data of faults and (b) to create
   a 3D model with fault planes even at no exposure or at hardly accessible
   areas. The surface model with detected faults serves as a basis for
   calculating geological reserves.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Torok, A (Corresponding Author), Budapest Univ Technol \& Econ, Dept Engn Geol \& Geotech, H-1111 Budapest, Hungary.
   Torok, Akos; Bogoly, Gyula, Budapest Univ Technol \& Econ, Dept Engn Geol \& Geotech, H-1111 Budapest, Hungary.
   Somogyi, Arpad; Lovas, Tamas, Budapest Univ Technol \& Econ, Dept Photogrammetry \& Geoinformat, H-1111 Budapest, Hungary.},
DOI = {10.3390/s20020489},
Article-Number = {489},
EISSN = {1424-8220},
Keywords = {UAV; surface model; fault zone; spatial analysis; limestone reserve},
Keywords-Plus = {UNMANNED AERIAL VEHICLES; SLOPE STABILITY; LONG-TERM; PHOTOGRAMMETRY;
   SYSTEMS; LIDAR; RECONSTRUCTION; HAZARD},
Research-Areas = {Chemistry; Engineering; Instruments \& Instrumentation},
Web-of-Science-Categories  = {Chemistry, Analytical; Engineering, Electrical \& Electronic;
   Instruments \& Instrumentation},
Author-Email = {torokakos@mail.bme.hu
   bogoly.gyula@epito.bme.hu
   somogyi.arpad@epito.bme.hu
   lovas.tamas@epito.bme.hu},
Affiliations = {Budapest University of Technology \& Economics; Budapest University of
   Technology \& Economics},
ResearcherID-Numbers = {Bögöly, Gyula/AAF-8111-2021
   Török, Ákos/P-4167-2019
   Torok, Akos/H-9136-2012},
ORCID-Numbers = {Bögöly, Gyula/0000-0001-8251-6577
   Török, Ákos/0000-0002-5394-4510
   Torok, Akos/0000-0002-5394-4510},
Funding-Acknowledgement = {Higher Education Excellence Program of the Ministry of Human Capacities
   in the frame of the Water Sciences \& Disaster Prevention research area
   of BME (BME FIKP-VIZ)},
Funding-Text = {The research reported in this paper was supported by the Higher
   Education Excellence Program of the Ministry of Human Capacities in the
   frame of the Water Sciences \& Disaster Prevention research area of BME
   (BME FIKP-VIZ).},
Cited-References = {Achille C, 2015, SENSORS-BASEL, V15, P15520, DOI 10.3390/s150715520.
   Aguera-Vega F, 2018, MEASUREMENT, V121, P127, DOI 10.1016/j.measurement.2018.02.062.
   Boccardo P, 2015, SENSORS-BASEL, V15, P15717, DOI 10.3390/s150715717.
   Campana S, 2017, ARCHAEOL PROSPECT, V24, P275, DOI 10.1002/arp.1569.
   Cappelletti C, 2019, INT ARCH PHOTOGRAMM, V42-2, P227, DOI 10.5194/isprs-archives-XLII-2-W9-227-2019.
   Cawood AJ, 2017, J STRUCT GEOL, V98, P67, DOI 10.1016/j.jsg.2017.04.004.
   Chen J, 2016, ISPRS J PHOTOGRAMM, V115, P3, DOI 10.1016/j.isprsjprs.2015.09.008.
   Chudley T.R., 2018, CRYOSPHERE DISCUSS, P1, DOI {[}10.5194/tc-2018-256, DOI 10.5194/TC-13-955-2019].
   Colomina I, 2014, ISPRS J PHOTOGRAMM, V92, P79, DOI 10.1016/j.isprsjprs.2014.02.013.
   Comba L, 2018, COMPUT ELECTRON AGR, V155, P84, DOI 10.1016/j.compag.2018.10.005.
   Dering GM, 2019, J VOLCANOL GEOTH RES, V373, P148, DOI 10.1016/j.jvolgeores.2019.01.018.
   Di Bartolo S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030450.
   Villanueva JRE, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143205.
   Francioni M, 2014, ENG GEOL, V183, P290, DOI 10.1016/j.enggeo.2014.09.003.
   Fritz A, 2013, INT ARCH PHOTOGRAMM, P141.
   Gao MX, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08119-2.
   Giordan D, 2018, NAT HAZARD EARTH SYS, V18, P1079, DOI 10.5194/nhess-18-1079-2018.
   Giordan D, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16101750.
   Gotz AE, 2008, GEOL CARPATH, V59, P307.
   Gotz A. E., 2018, STRATIGRAPHY TIMESCA, P265.
   Haas F, 2016, NAT HAZARD EARTH SYS, V16, P1269, DOI 10.5194/nhess-16-1269-2016.
   He HQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163534.
   Bordehore LJ, 2017, INT J ROCK MECH MIN, V97, P24, DOI 10.1016/j.ijrmms.2017.06.004.
   Langhammer J, 2019, HYDROLOGY-BASEL, V6, DOI 10.3390/hydrology6020029.
   Langhammer J, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9030240.
   Mancini F, 2013, REMOTE SENS-BASEL, V5, P6880, DOI 10.3390/rs5126880.
   Margottini C, 2015, LANDSLIDES, V12, P193, DOI 10.1007/s10346-014-0548-z.
   Martin PG, 2015, J ENVIRON RADIOACTIV, V143, P135, DOI 10.1016/j.jenvrad.2015.02.004.
   Mazzanti P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10091475.
   Menegoni N, 2018, GEOSCIENCES, V8, DOI 10.3390/geosciences8080299.
   Mizinski B, 2017, COLD REG SCI TECHNOL, V138, P63, DOI 10.1016/j.coldregions.2017.03.006.
   Neugirg F, 2016, GEOMORPHOLOGY, V269, P8, DOI 10.1016/j.geomorph.2016.06.027.
   Nex F, 2014, INT ARCH PHOTOGRAMM, V40-1, P315, DOI 10.5194/isprsarchives-XL-1-315-2014.
   Niedzielski T, 2019, J HYDROL, V578, DOI 10.1016/j.jhydrol.2019.124046.
   Niedzielski T, 2016, HYDROL EARTH SYST SC, V20, P3193, DOI 10.5194/hess-20-3193-2016.
   Ong WH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081731.
   Pappalardo G, 2014, NAT HAZARD EARTH SYS, V14, P2735, DOI 10.5194/nhess-14-2735-2014.
   Rossini M, 2018, GEOMORPHOLOGY, V304, P159, DOI 10.1016/j.geomorph.2017.12.039.
   Salvini R, 2017, GEOMAT NAT HAZ RISK, V8, P34, DOI 10.1080/19475705.2016.1199053.
   Saroglou C., 2019, P ICONHIC 2 INT C NA.
   Sayab M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081296.
   Scholtz A., 2012, ISPRS INT ARCH PHOTO, VXXXVIII-1/C22, P149, DOI {[}10.5194/isprsarchives-XXXVIII-1-C22-149-2011, DOI 10.5194/ISPRSARCHIVES-XXXVIII-1-C22-149-2011].
   Shahbazi M, 2015, SENSORS-BASEL, V15, P27493, DOI 10.3390/s151127493.
   Tannant DD, 2017, ENG GEOL, V220, P144, DOI 10.1016/j.enggeo.2017.02.004.
   Tannant D.D., 2015, INT J GEOHAZARDS ENV, V1, P76.
   TOROK A, 1998, GEOL SOC SPEC PUBL, V149, P339.
   Torok A, 2018, NAT HAZARD EARTH SYS, V18, P583, DOI 10.5194/nhess-18-583-2018.
   Vanneschi C, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8080325.
   Wierzbicki D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082433.
   Zekkos D., 2018, INT J GEOENGINEERING, V4, P254, DOI {[}10.4417/IJGCH-04-04-03, DOI 10.4417/IJGCH-04-04-03].},
Number-of-Cited-References = {50},
Times-Cited = {9},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {6},
Journal-ISO = {Sensors},
Doc-Delivery-Number = {KR7IT},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000517790100163},
OA = {gold, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000370974905063,
Author = {Mohan, Mahesh and Galvez-Lopez, Dorian and Montcleoni, Claire and
   Sibley, Gabe},
Book-Group-Author = {IEEE},
Title = {Environment Selection And Hierarchical Place Recognition},
DOI = {10.1109/ICRA.2015.7139966},
Booktitle = {2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA)},
Series = {IEEE International Conference on Robotics and Automation ICRA},
Year = {2015},
Pages = {5487-5494},
Note = {IEEE International Conference on Robotics and Automation (ICRA),
   Seattle, WA, MAY 26-30, 2015},
Abstract = {As robots continue to create long-term maps, the amount of information
   that they need to handle increases over time. In terms of place
   recognition, this implies that the number of images being considered may
   increase until exceeding the computational resources of the robot. In
   this paper we consider a scenario where, given multiple independent
   large maps, possibly from different cities or locations, a robot must
   effectively and in real time decide whether it can localize itself in
   one of those known maps. Since the number of images to be handled by
   such a system is likely to be extremely large, we find that it is
   beneficial to decompose the set of images into independent groups or
   environments. This raises a new question: Given a query image, how do we
   select the best environment? This paper proposes a similarity criterion
   that can be used to solve this problem. It is based on the observation
   that, if each environment is described in terms of its co-occurrent
   features, similarity between environments can be established by
   comparing their co-occurrence matrices. We show that this leads to a
   novel place recognition algorithm that divides the collection of images
   into environments and arranges them in a hierarchy of inverted indices.
   By selecting first the relevant environment for the operating robot, we
   can reduce the number of images to perform the actual loop detection,
   reducing the execution time while preserving the accuracy. The
   practicality of this approach is shown through experimental results on
   several large datasets covering a combined distance of more than 750Km.},
Publisher = {IEEE COMPUTER SOC},
Address = {10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Mohan, M (Corresponding Author), George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
   Mohan, Mahesh; Galvez-Lopez, Dorian; Montcleoni, Claire, George Washington Univ, Dept Comp Sci, Washington, DC 20052 USA.
   Sibley, Gabe, Univ Colorado Boulder, Dept Comp Sci, Boulder, CO USA.},
ISSN = {1050-4729},
ISBN = {978-1-4799-6923-4},
Keywords-Plus = {NAVIGATION; VISION; WORDS},
Research-Areas = {Automation \& Control Systems; Computer Science; Engineering; Robotics},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Engineering, Electrical \& Electronic; Robotics},
Author-Email = {mahesh\_mohan@gwu.edu
   dorian@gwu.edu
   cmontel@gwu.edu
   GSibley@colorado.edu},
Affiliations = {George Washington University; University of Colorado System; University
   of Colorado Boulder},
ORCID-Numbers = {Monteleoni, Claire/0000-0002-9488-0517},
Cited-References = {{[}Anonymous], 2013, NORDLANDSBANEN MINUT.
   Blanco JL, 2009, AUTON ROBOT, V27, P327, DOI 10.1007/s10514-009-9138-7.
   Cummins M, 2010, INT J ROBOT RES.
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961.
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597.
   Galvez-Lopez D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158.
   Gartner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9\_11.
   Glover AJ, 2010, IEEE INT CONF ROBOT, P3507, DOI 10.1109/ROBOT.2010.5509547.
   Kashima H., 2003, INT C MACHINE LEARNI, P321.
   Labbe M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375.
   Li Maohai, 2011, Information Technology Journal, V10, P29.
   MacTavish K., 2014, IEEE INT C ROB AUT I.
   Mei Christopher, 2010, INT C INT ROB SYST T.
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623.
   Morrison Jack, 2014, INT S DISTR IN PRESS.
   Murphy L, 2014, IEEE INT CONF ROBOT, P1312, DOI 10.1109/ICRA.2014.6907022.
   Nicosevici T, 2012, IEEE T ROBOT, V28, P886, DOI 10.1109/TRO.2012.2192013.
   Nistr D., 2006, P IEEE COMP VIS PAT, V2, P2161.
   Pandey G, 2011, INT J ROBOT RES, V30, P1543, DOI 10.1177/0278364911400640.
   Ponce J., 2006, P IEEE C COMP VIS PA, V2, P2169, DOI DOI 10.1109/CVPR.2006.68.
   Rawseeds, 2007, FP6IST045144 RAWS.
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663.
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911.
   Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201.
   Xiao J., 2014, INT J COMPUT VISION, P1.},
Number-of-Cited-References = {25},
Times-Cited = {14},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BE3MR},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000370974905063},
DA = {2022-05-17},
}

@article{ WOS:000481688500125,
Author = {Fridman, Lex and Brown, Daniel E. and Glazer, Michael and Angell,
   William and Dodd, Spencer and Jenik, Benedikt and Terwilliger, Jack and
   Patsekin, Aleksandr and Kindelsberger, Julia and Ding, Li and Seaman,
   Sean and Mehler, Alea and Sipperley, Andrew and Pettinato, Anthony and
   Seppelt, Bobbie D. and Angell, Linda and Mehler, Bruce and Reimer, Bryan},
Title = {MIT Advanced Vehicle Technology Study: Large-Scale Naturalistic Driving
   Study of Driver Behavior and Interaction With Automation},
Journal = {IEEE ACCESS},
Year = {2019},
Volume = {7},
Pages = {102021-102038},
Abstract = {Today, and possibly for a long time to come, the full driving task is
   too complex an activity to be fully formalized as a sensing-acting
   robotics system that can be explicitly solved through model-based and
   learning-based approaches in order to achieve full unconstrained vehicle
   autonomy. Localization, mapping, scene perception, vehicle control,
   trajectory optimization, and higher-level planning decisions associated
   with autonomous vehicle development remain full of open challenges. This
   is especially true for unconstrained, real-world operation where the
   margin of allowable error is extremely small and the number of
   edge-cases is extremely large. Until these problems are solved, human
   beings will remain an integral part of the driving task, monitoring the
   AI system as it performs anywhere from just over 0\% to just under 100\%
   of the driving. The governing objectives of the MIT Advanced Vehicle
   Technology (MIT-AVT) study are to 1) undertake large-scale real-world
   driving data collection that includes high-definition video to fuel the
   development of deep learning-based internal and external perception
   systems; 2) gain a holistic understanding of how human beings interact
   with vehicle automation technology by integrating video data with
   vehicle state data, driver characteristics, mental models, and
   self-reported experiences with technology; and 3) identify how
   technology and other factors related to automation adoption and use can
   be improved in ways that save lives. In pursuing these objectives, we
   have instrumented 23 Tesla Model S and Model X vehicles, 2 Volvo S90
   vehicles, 2 Range Rover Evoque, and 2 Cadillac CT6 vehicles for both
   long-term (over a year per driver) and medium-term (one month per
   driver) naturalistic driving data collection. Furthermore, we are
   continually developing new methods for the analysis of the massive-scale
   dataset collected from the instrumented vehicle fleet. The recorded data
   streams include IMU, GPS, and CAN messages, and high-definition video
   streams of the driver's face, the driver cabin, the forward roadway, and
   the instrument cluster (on select vehicles). The study is on-going and
   growing. To date, we have 122 participants, 15 610 days of
   participation, 511 638 mi, and 7.1 billion video frames. This paper
   presents the design of the study, the data collection hardware, the
   processing of the data, and the computer vision algorithms currently
   being used to extract actionable knowledge from the data.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Fridman, L (Corresponding Author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Fridman, Lex; Brown, Daniel E.; Glazer, Michael; Angell, William; Dodd, Spencer; Jenik, Benedikt; Terwilliger, Jack; Patsekin, Aleksandr; Kindelsberger, Julia; Ding, Li; Mehler, Alea; Sipperley, Andrew; Pettinato, Anthony; Seppelt, Bobbie D.; Mehler, Bruce; Reimer, Bryan, MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   Seaman, Sean; Angell, Linda, Touchstone Evaluat Inc, Detroit, MI 48202 USA.},
DOI = {10.1109/ACCESS.2019.2926040},
ISSN = {2169-3536},
Keywords = {Artificial intelligence; automation; human factors; autonomous vehicles;
   human-robot interaction; computer vision; machine learning; neural
   networks},
Keywords-Plus = {HEAD POSE; GAZE; RECOGNITION; VIDEO},
Research-Areas = {Computer Science; Engineering; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Information Systems; Engineering, Electrical \&
   Electronic; Telecommunications},
Author-Email = {fridman@mit.edu},
Affiliations = {Massachusetts Institute of Technology (MIT)},
ResearcherID-Numbers = {Mehler, Bruce/E-4538-2017
   },
ORCID-Numbers = {Mehler, Bruce/0000-0001-5929-4179
   Patsekin, Aleksandr/0000-0001-8626-7328
   /0000-0003-1484-6843
   Ding, Li/0000-0002-1315-1196},
Funding-Acknowledgement = {Advanced Vehicle Technology (AVT) consortium at MIT},
Funding-Text = {Support for this work was provided by the Advanced Vehicle Technology
   (AVT) consortium at MIT. The views and conclusions being expressed are
   those of the authors, and have not been sponsored, approved, or
   necessarily endorsed by members of the consortium. All authors listed as
   affiliated with MIT contributed to the work only during their time at
   MIT as employees or visiting graduate students.},
Cited-References = {Abdic I, 2016, LECT NOTES ARTIF INT, V9904, P237.
   {[}Anonymous], 2016, ADV VEHICLE TECHNOLO.
   Badrinarayanan V, 2010, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR.2010.5540054.
   Barry K., TOO MUCH SAFETY COUL.
   Benmimoun M., P 22 ENH SAF VEH C W, V201, P1.
   Bojarski M., 2016, ARXIV160407316, DOI DOI 10.1109/IVS.2017.7995975.
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005.
   Buehler M, 2009, SPRINGER TRAC ADV RO, V56, P1, DOI 10.1007/978-3-642-03991-1.
   Campbell K. L., 2012, TR NEWS.
   Cordts M., 2015, TECH REP.
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350.
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89.
   Davies A., OH LOOK MORE EVIDENC.
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848.
   Dingus T. A., 2006, DOT HS, V810, P593.
   Dixit VV, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168054.
   ENDSLEY MR, 1995, HUM FACTORS, V37, P381, DOI 10.1518/001872095779064555.
   Favaro FM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184952.
   Fridman L., 2017, ARXIV171004459.
   Fridman L, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2805, DOI 10.1145/3025453.3025929.
   Fridman L, 2016, IET COMPUT VIS, V10, P308, DOI 10.1049/iet-cvi.2015.0296.
   Fridman L, 2016, IEEE INTELL SYST, V31, P49, DOI 10.1109/MIS.2016.47.
   Fridman L, 2016, PATTERN RECOGN LETT, V75, P9, DOI 10.1016/j.patrec.2016.02.011.
   Gao H, 2014, IEEE IMAGE PROC, P5961, DOI 10.1109/ICIP.2014.7026203.
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297.
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1.
   Hartley R., 2003, MULTIPLE VIEW GEOMET.
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI 10.1109/ICCV.2017.322.
   Hoffman EA, 2000, NAT NEUROSCI, V3, P80, DOI 10.1038/71152.
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90.
   Kalra N, 2016, TRANSPORT RES A-POL, V94, P182, DOI 10.1016/j.tra.2016.09.010.
   Klauer SG., 2006, 810594 DOT HS NAT HI.
   Knipling R. R., 2015, DRIVING ASSESSMENT 2, P196.
   Knipling RR, 2017, TRANSPORT RES REC, P117, DOI 10.3141/2663-15.
   Li R., P 2008 IEEE VEH POW, P1, DOI {[}10.1109/VPPC.2008.4677544, DOI 10.1109/VPPC.2008.4677544].
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1\_48.
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233.
   Liu S, 2017, IEEE I CONF COMP VIS, P3516, DOI 10.1109/ICCV.2017.378.
   Mbouna RO, 2013, IEEE T INTELL TRANSP, V14, P1462, DOI 10.1109/TITS.2013.2262098.
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925.
   Miller G.A., 1990, INT J LEXICOGRAPHY, V3, P235, DOI {[}10.1093/ijl/3.4.235, DOI 10.1093/IJL/3.4.235].
   Neale V.L., 2005, 050400 NAT HIGHW TRA.
   Puggelli A., 2014, 2014 16 EUR C POW EL, P1.
   Reimer, 2014, PUBLIC POLICY AGING, V24, P27, DOI {[}10.1093/ppar/prt006, DOI 10.1093/PPAR/PRT006].
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y.
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8.
   Shankar V, 2008, TRANSPORT RES REC, P1, DOI 10.3141/2061-01.
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381.
   Tedrake R., 2016, 6832 MIT.
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143.
   Tompson J.J, 2014, NIPS, P1799, DOI DOI 10.1063/1.5024463.
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214.
   VANDERBILT T, 2009, TRAFFIC WHY WE DRIVE.
   Vicente F, 2015, IEEE T INTELL TRANSP, V16, P2014, DOI 10.1109/TITS.2015.2396031.
   Victor T., 2015, S2S08ARW1 CHALM U TE.
   Wang P., 2017, ARXIV170208502.
   WHO, 2015, GLOBAL STATUS REPORT.
   Wisniewska J, 2014, LECT NOTES COMPUT SC, V8671, P636, DOI 10.1007/978-3-319-11331-9\_76.
   Xu H., 2017, P IEEE C COMP VIS PA, P2174.
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435.
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660.
   Zhou MM, 2014, INTERNATIONAL CONFERENCE ON EDUCATION AND SOCIAL SCIENCES (INTCESS14), VOLS I AND II, P487.},
Number-of-Cited-References = {63},
Times-Cited = {51},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {17},
Journal-ISO = {IEEE Access},
Doc-Delivery-Number = {IR8JN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000481688500125},
OA = {Green Submitted, gold},
DA = {2022-05-17},
}

@article{ WOS:000369499600004,
Author = {Cornick, Matthew and Koechling, Jeffrey and Stanley, Byron and Zhang,
   Beijia},
Title = {Localizing Ground Penetrating RADAR: A Step Toward Robust Autonomous
   Ground Vehicle Localization},
Journal = {JOURNAL OF FIELD ROBOTICS},
Year = {2016},
Volume = {33},
Number = {1},
Pages = {82-102},
Month = {JAN},
Abstract = {Autonomous ground vehicles navigating on road networks require robust
   and accurate localization over long-term operation and in a wide range
   of adverse weather and environmental conditions. GPS/INS (inertial
   navigation system) solutions, which are insufficient alone to maintain a
   vehicle within a lane, can fail because of significant radio frequency
   noise or jamming, tall buildings, trees, and other blockage or multipath
   scenarios. LIDAR and camera map-based vehicle localization can fail when
   optical features become obscured, such as with snow or dust, or with
   changes to gravel or dirt road surfaces. Localizing ground penetrating
   radar (LGPR) is a new mode of a priori map-based vehicle localization
   designed to complement existing approaches with a low sensitivity to
   failure modes of LIDAR, camera, and GPS/INS sensors due to its
   low-frequency RF energy, which couples deep into the ground. Most
   subsurface features detected are inherently stable over time.
   Significant research, discussed herein, remains to prove general
   utility. We have developed a novel low-profile ultra-low power LGPR
   system and demonstrated real-time operation underneath a passenger
   vehicle. A correlation maximizing optimization technique was developed
   to allow real-time localization at 126Hz. Here we present the detailed
   design and results from highway testing, which uses a simple heuristic
   for fusing LGPR estimates with a GPS/INS system. Cross-track
   localization accuracies of 4.3cm RMS relative to a truth RTK GPS/INS
   unit at speeds up to 100km/h (60mph) are demonstrated. These results, if
   generalizable, introduce a widely scalable real-time localization method
   with cross-track accuracy as good as or better than current localization
   methods.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Stanley, B (Corresponding Author), MIT, Lincoln Lab, 244 Wood St, Lexington, MA 02420 USA.
   Cornick, Matthew; Koechling, Jeffrey; Stanley, Byron; Zhang, Beijia, MIT, Lincoln Lab, 244 Wood St, Lexington, MA 02420 USA.},
DOI = {10.1002/rob.21605},
ISSN = {1556-4959},
EISSN = {1556-4967},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {stanley@ll.mit.edu},
Affiliations = {Lincoln Laboratory; Massachusetts Institute of Technology (MIT)},
Cited-References = {ABE T, 1990, IEEE T GEOSCI REMOTE, V28, P915, DOI 10.1109/36.58981.
   Badino H., 2012, INT C ROB AUT ST PAU.
   Brunner C, 2013, J FIELD ROBOT, V30, P641, DOI 10.1002/rob.21464.
   Buehler M, 2009, SPRINGER TRAC ADV RO, V56, P1, DOI 10.1007/978-3-642-03991-1.
   Christopher B. R., 2006, NHI05037 FHWA US DOT.
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483.
   Daniels D., 2004, GROUND PENETRATING R, V1.
   Federal Highway Administration, 2007, MIT STRAT DES EXC.
   Federal Highway Administration, 2010, 2010 STAT NAT HIGHW.
   Fenn A. J., 2013, IEEE INT S PHAS ARR.
   Floyd L. R., 1978, GEODETIC BENCH MARKS.
   Herman H., 1997, CMURITR9719.
   HOEKSTRA P, 1974, J GEOPHYS RES, V79, P1699, DOI 10.1029/JB079i011p01699.
   Jol HM, 2009, GROUND PENETRATING RADAR THEORY AND APPLICATIONS, P1.
   Kennedy J., 1995, IEEE INT C NEUR NETW.
   Kennedy S., 2008, IEEE ION POS LOC NAV.
   Lever JH, 2013, J FIELD ROBOT, V30, P194, DOI 10.1002/rob.21445.
   Levinson J., 2010, INT C ROB AUT ANCH A.
   Levinson J., 2007, P ROB SCI SYST ATL G.
   Milford M. J., 2012, IEEE INT C ROB AUT I.
   Moulton L. K., 1980, FHWATS80224 US DOT.
   National Highway Traffic Safety Administration, 2011, NCSA DAT RES FAT AN.
   Nuske S, 2009, J FIELD ROBOT, V26, P728, DOI 10.1002/rob.20306.
   Saarenketo T, 2000, J APPL GEOPHYS, V43, P119, DOI 10.1016/S0926-9851(99)00052-X.
   Shi Y., 1999, P 1999 C EV COMP.
   Stanley B., 2013, GROUND VEH SYST ENG.
   Unnikrishnan R., 2002, IEEE INT C ROB AUT I.
   WHO, 2013, GLOB STAT REP ROAD S.
   Williams R., 2012, GEOSC REM SENS S IGA.
   Yamauchi B, 2010, P SPIE, V7692.},
Number-of-Cited-References = {30},
Times-Cited = {30},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {34},
Journal-ISO = {J. Field Robot.},
Doc-Delivery-Number = {DC8WD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000369499600004},
OA = {hybrid},
DA = {2022-05-17},
}

@article{ WOS:000448542200010,
Author = {Song, Zhuoyuan and Mohseni, Kamran},
Title = {Long-Term Inertial Navigation Aided by Dynamics of Flow Field Features},
Journal = {IEEE JOURNAL OF OCEANIC ENGINEERING},
Year = {2018},
Volume = {43},
Number = {4},
Pages = {940-954},
Month = {OCT},
Abstract = {A current-aided inertial navigation framework is proposed for small
   autonomous underwater vehicles in long-duration operations (>1 h), where
   neither frequent surfacing nor consistent bottom tracking is available.
   We instantiate this concept through mid-depth underwater navigation.
   This strategy mitigates dead-reckoning uncertainty of a traditional
   inertial navigation system by comparing the estimate of local ambient
   flow velocity with preloaded ocean current maps. The proposed navigation
   system is implemented through a marginalized particle filter where the
   vehicle's states are sequentially tracked along with sensor bias and
   local turbulence that is not resolved by general flow prediction. The
   performance of the proposed approach is first analyzed through Monte
   Carlo simulations in two artificial background flow fields, resembling
   real-world ocean circulation patterns, superposed with smaller scale
   turbulent components with Kolmogorov energy spectrum. The current-aided
   navigation scheme significantly improves the dead-reckoning performance
   of the vehicle even when unresolved small-scale flow perturbations are
   present. For a 6-h navigation with an automotive-grade inertial
   navigation system, the current-aided navigation scheme results in
   positioning estimates with under 3\% uncertainty per distance traveled
   (UDT) in a turbulent double-gyre flow field, and under 7.3\% UDT in a
   turbulent meandering jet flow field. Further evaluation with field test
   data and actual ocean simulation analysis demonstrates consistent
   performance for a 6-h mission, positioning result with under 25\% UDT
   for a 24-h navigation when provided direct heading measurements, and
   terminal positioning estimate with 16\% UDT at the cost of increased
   uncertainty at an early stage of the navigation.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Mohseni, K (Corresponding Author), Univ Florida, Dept Mech \& Aerosp Engn, Dept Elect \& Comp Engn, Gainesville, FL 32611 USA.
   Song, Zhuoyuan, Univ Florida, Dept Mech \& Aerosp Engn, Gainesville, FL 32611 USA.
   Mohseni, Kamran, Univ Florida, Dept Mech \& Aerosp Engn, Dept Elect \& Comp Engn, Gainesville, FL 32611 USA.
   Mohseni, Kamran, Univ Florida, Inst Networked Autonomous Syst, Gainesville, FL 32611 USA.},
DOI = {10.1109/JOE.2017.2766900},
ISSN = {0364-9059},
EISSN = {1558-1691},
Keywords = {Autonomous vehicles; navigation; ocean current; state estimation},
Keywords-Plus = {AUTONOMOUS UNDERWATER VEHICLE; COOPERATIVE LOCALIZATION; AUV NAVIGATION;
   MEANDERING JET; ATLANTIC-OCEAN; TURBULENCE; SYSTEM; PERFORMANCE;
   CIRCULATION; PROPULSION},
Research-Areas = {Engineering; Oceanography},
Web-of-Science-Categories  = {Engineering, Civil; Engineering, Ocean; Engineering, Electrical \&
   Electronic; Oceanography},
Author-Email = {nick.songzy@ufl.edu
   mohseni@ufl.edu},
Affiliations = {State University System of Florida; University of Florida; State
   University System of Florida; University of Florida; State University
   System of Florida; University of Florida},
ResearcherID-Numbers = {Song, Zhuoyuan/A-2717-2019},
ORCID-Numbers = {Song, Zhuoyuan/0000-0002-7442-8435},
Funding-Acknowledgement = {U.S. Office of Naval Research {[}N00014-16-1-2083]; National Science
   Foundation {[}NRI-1638034]},
Funding-Text = {This work was supported in part by the U.S. Office of Naval Research
   under Grant N00014-16-1-2083 and in part by the National Science
   Foundation under Grant NRI-1638034.},
Cited-References = {Arrichiello F, 2012, IEEE INT CONF ROBOT, P5307, DOI 10.1109/ICRA.2012.6224733.
   Bahr A, 2009, INT J ROBOT RES, V28, P714, DOI 10.1177/0278364908100561.
   Bergman N., 1999, THESIS.
   BOWER AS, 1991, J PHYS OCEANOGR, V21, P173, DOI 10.1175/1520-0485(1991)021<0173:ASKMFM>2.0.CO;2.
   BOWER AS, 1989, J PHYS OCEANOGR, V19, P1177, DOI 10.1175/1520-0485(1989)019<1177:EOCFEP>2.0.CO;2.
   BRUMLEY BH, 1991, IEEE J OCEANIC ENG, V16, P402, DOI 10.1109/48.90905.
   Buckley MW, 2016, REV GEOPHYS, V54, P5, DOI 10.1002/2015RG000493.
   Caruso Antonio, 2008, 2008 Proceedings IEEE INFOCOM, P771.
   Chang D, 2015, J ATMOS OCEAN TECH, V32, P562, DOI 10.1175/JTECH-D-14-00098.1.
   Chassignet EP, 2009, OCEANOGRAPHY, V22, P64, DOI 10.5670/oceanog.2009.39.
   Chung J., 2011, P 9 INT C MOB SYST A, P141, DOI DOI 10.1145/1999995.2000010.
   Claus B, 2015, J FIELD ROBOT, V32, P935, DOI 10.1002/rob.21563.
   DAVIS RE, 1991, ANNU REV FLUID MECH, V23, P43, DOI 10.1146/annurev.fluid.23.1.43.
   Dellaert F, 1999, ICRA `99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1322, DOI 10.1109/ROBOT.1999.772544.
   Donovan GT, 2012, IEEE J OCEANIC ENG, V37, P431, DOI 10.1109/JOE.2012.2190810.
   Doucet A, 2001, SEQUENTIAL MONTE CAR.
   Doucet A., 2000, P 16 C UNC ART INT S, P176.
   Durrant-Whyte H, 2006, IEEE ROBOT AUTOM MAG, V13, P99, DOI 10.1109/MRA.2006.1638022.
   Ee H. V., 2006, P 1 ACM INT WORKSH U, P33, DOI DOI 10.1145/1161039.1161047.
   Fallon MF, 2010, INT J ROBOT RES, V29, P1461, DOI 10.1177/0278364910380760.
   Fiorelli E, 2006, IEEE J OCEANIC ENG, V31, P935, DOI 10.1109/JOE.2006.880429.
   Fossen T.I, 2011, HDB MARINE CRAFT HYD, V1st.
   Fossen T I, 1991, THESIS.
   FUNG JCH, 1992, J FLUID MECH, V236, P281, DOI 10.1017/S0022112092001423.
   GIBSON MM, 1963, J FLUID MECH, V15, P161, DOI 10.1017/S002211206300015X.
   GRANT HL, 1962, J FLUID MECH, V12, P241, DOI 10.1017/S002211206200018X.
   Gutmann JS, 2012, IEEE T ROBOT, V28, P650, DOI 10.1109/TRO.2011.2177691.
   Hegrens O., 2009, OCEANS 2009 EUROPE, P1, DOI DOI 10.1109/0CEANSE.2009.5278307.
   Inanc T, 2005, P AMER CONTR CONF, P674, DOI 10.1109/ACC.2005.1470035.
   Kinsey J., 2006, P C MAN CONTR MAR CR, P1.
   Krieg M, 2011, MAR TECHNOL SOC J, V45, P153, DOI 10.4031/MTSJ.45.4.11.
   Kussat NH, 2005, IEEE J OCEANIC ENG, V30, P153, DOI 10.1109/JOE.2004.835249.
   Lavender KL, 2000, NATURE, V407, P66, DOI 10.1038/35024048.
   Leonard NE, 2007, P IEEE, V95, P48, DOI 10.1109/JPROC.2006.887295.
   Lermusiaux PFJ, 2016, SPRINGER HANDBOOK OF OCEAN ENGINEERING, P481.
   Lipinski Doug, 2011, IEEE International Conference on Robotics and Automation, P3347.
   Lipinski D., 2013, P IEEE RSJ INT C INT, P3847.
   Mallory K, 2013, NONLINEAR PROC GEOPH, V20, P657, DOI 10.5194/npg-20-657-2013.
   Medagoda L, 2016, AUTON ROBOT, V40, P1207, DOI 10.1007/s10514-016-9547-3.
   Medagoda L, 2015, IEEE INT CONF ROBOT, P565, DOI 10.1109/ICRA.2015.7139235.
   Mehra A, 2010, TERR ATMOS OCEAN SCI, V21, P211, DOI 10.3319/TAO.2009.04.16.01(IWNOP).
   Metzger E., 2017, NRLMR7320179722 STEN.
   Mourikis AI, 2006, IEEE T ROBOT, V22, P666, DOI 10.1109/TRO.2006.878957.
   Newman PM, 2005, SPRINGER TRAC ADV RO, V15, P409.
   Paley D. A., 2007, THESIS.
   Paley DA, 2008, IEEE T CONTR SYST T, V16, P735, DOI 10.1109/TCST.2007.912238.
   PATTERSON SL, 1985, J PHYS OCEANOGR, V15, P865, DOI 10.1175/1520-0485(1985)015<0865:SCAKED>2.0.CO;2.
   Paull L, 2014, IEEE J OCEANIC ENG, V39, P131, DOI 10.1109/JOE.2013.2278891.
   Samelson R. M., 2006, INTERDISCIPLINARY AP.
   SAMELSON RM, 1992, J PHYS OCEANOGR, V22, P431, DOI 10.1175/1520-0485(1992)022<0431:FEAAMJ>2.0.CO;2.
   Shadden SC, 2005, PHYSICA D, V212, P271, DOI 10.1016/j.physd.2005.10.007.
   Smith RN, 2011, J FIELD ROBOT, V28, P714, DOI 10.1002/rob.20405.
   Song Z., 2014, P IEEE RSJ INT C INT, P2292.
   Song Z., 2017, P IEEE RSJ INT C INT.
   Song ZY, 2017, OCEAN ENG, V141, P388, DOI 10.1016/j.oceaneng.2017.06.024.
   Song ZY, 2016, MAR TECHNOL SOC J, V50, P88, DOI 10.4031/MTSJ.50.5.9.
   Song ZY, 2015, IEEE DECIS CONTR P, P240, DOI 10.1109/CDC.2015.7402115.
   Song ZY, 2014, IEEE DECIS CONTR P, P6945, DOI 10.1109/CDC.2014.7040480.
   Stanway M. J., 2012, THESIS.
   SWALLOW JC, 1955, DEEP-SEA RES, V3, P74, DOI 10.1016/0146-6313(55)90037-X.
   Tan HP, 2011, OCEAN ENG, V38, P1663, DOI 10.1016/j.oceaneng.2011.07.017.
   Testor P., 2010, ESA PUBLICATION, V2.
   Veneziani M, 2004, J PHYS OCEANOGR, V34, P1884, DOI 10.1175/1520-0485(2004)034<1884:OTASMF>2.0.CO;2.
   Wei MZ, 2016, DEEP-SEA RES PT II, V129, P374, DOI 10.1016/j.dsr2.2013.09.002.
   Wymeersch H, 2009, P IEEE, V97, P427, DOI 10.1109/JPROC.2008.2008853.
   Wynn RB, 2014, MAR GEOL, V352, P451, DOI 10.1016/j.margeo.2014.03.012.
   Zhang F, 2007, INT J CONTROL, V80, P1186, DOI 10.1080/00207170701222947.
   {[}No title captured].},
Number-of-Cited-References = {68},
Times-Cited = {17},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {18},
Journal-ISO = {IEEE J. Ocean. Eng.},
Doc-Delivery-Number = {GY4OJ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000448542200010},
OA = {hybrid, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000668907500001,
Author = {Chua, Christianne J. and Han, Julie L. and Li, Weizhen and Liu, Wei and
   Entcheva, Emilia},
Title = {Integration of Engineered ``Spark-Cell{''} Spheroids for Optical Pacing
   of Cardiac Tissue},
Journal = {FRONTIERS IN BIOENGINEERING AND BIOTECHNOLOGY},
Year = {2021},
Volume = {09},
Pages = {658594},
Month = {JUN 18},
Abstract = {Optogenetic methods for pacing of cardiac tissue can be realized by
   direct genetic modification of the cardiomyocytes to express
   light-sensitive actuators, such as channelrhodopsin-2, ChR2, or by
   introduction of light-sensitized non-myocytes that couple to the cardiac
   cells and yield responsiveness to optical pacing. In this study, we
   engineer three-dimensional ``spark cells{''} spheroids, composed of
   ChR2-expressing human embryonic kidney cells (from 100 to 100,000 cells
   per spheroid), and characterize their morphology as function of cell
   density and time. These ``spark-cell{''} spheroids are then deployed to
   demonstrate site-specific optical pacing of human stem-cell-derived
   cardiomyocytes (hiPSC-CMs) in 96-well format using non-localized light
   application and all-optical electrophysiology with voltage and calcium
   small-molecule dyes or genetically encoded sensors. We show that the
   spheroids can be handled using liquid pipetting and can confer optical
   responsiveness of cardiac tissue earlier than direct viral or liposomal
   genetic modification of the cardiomyocytes, with 24\% providing reliable
   stimulation of the iPSC-CMs within 6 h and >80\% within 24 h. Moreover,
   our data show that the spheroids can be frozen in liquid nitrogen for
   long-term storage and transportation, after which they can be deployed
   as a reagent on site for optical cardiac pacing. In all cases, optical
   stimulation was achieved at relatively low light levels (<0.15 mW/mm(2))
   when 5 ms or longer pulses were used. Our results demonstrate a
   scalable, cost-effective method with a cryopreservable reagent to
   achieve contactless optical stimulation of cardiac cell constructs
   without genetically modifying the myocytes, that can be integrated in a
   robotics-amenable workflow for high-throughput drug testing.},
Publisher = {FRONTIERS MEDIA SA},
Address = {AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Entcheva, E (Corresponding Author), George Washington Univ, Dept Biomed Engn, Cardiac Optogenet \& Opt Imaging Lab, Washington, DC 20052 USA.
   Chua, Christianne J.; Han, Julie L.; Li, Weizhen; Liu, Wei; Entcheva, Emilia, George Washington Univ, Dept Biomed Engn, Cardiac Optogenet \& Opt Imaging Lab, Washington, DC 20052 USA.},
DOI = {10.3389/fbioe.2021.658594},
Article-Number = {658594},
ISSN = {2296-4185},
Keywords = {spheroids; optogenetics; induced pluripotent stem-cell-derived
   cardiomyocytes; channelrhodopsin-2; all-optical electrophysiology;
   optical mapping; pacing; cryopreservation},
Keywords-Plus = {OPTOGENETIC CONTROL; CHANNELRHODOPSIN-2; MUSCLE},
Research-Areas = {Biotechnology \& Applied Microbiology; Science \& Technology - Other
   Topics},
Web-of-Science-Categories  = {Biotechnology \& Applied Microbiology; Multidisciplinary Sciences},
Author-Email = {entcheva@gwu.edu},
Affiliations = {George Washington University},
Funding-Acknowledgement = {NIH {[}R01HL144157]; National Science Foundation {[}EFMA 1830941, PFI
   1827535]; SEAS SUPER Fellowship; Clare Boothe Luce Research Fellowship;
   Barry Goldwater Scholarship},
Funding-Text = {This work was supported in part by an NIH grant R01HL144157 and grants
   from theNational Science Foundation EFMA 1830941 and PFI 1827535 to EE,
   as well as a SEAS SUPER Fellowship, Clare Boothe Luce Research
   Fellowship, and Barry Goldwater Scholarship awarded to CC.},
Cited-References = {Ambrosi CM, 2015, SCI REP-UK, V5, DOI 10.1038/srep17350.
   Ambrosi Christina M, 2014, Methods Mol Biol, V1181, P215, DOI 10.1007/978-1-4939-1047-2\_19.
   Ambrosil CM, 2019, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.00168.
   Arrenberg AB, 2010, SCIENCE, V330, P971, DOI 10.1126/science.1195929.
   Ashammakhi N, 2019, MATER TODAY BIO, V1, DOI 10.1016/j.mtbio.2019.100008.
   Bien H, 2006, BIOPHYS J, V90, P2628, DOI 10.1529/biophysj.105.063321.
   Boyden ES, 2005, NAT NEUROSCI, V8, P1263, DOI 10.1038/nn1525.
   Boyle PM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-88573-1.
   Bruegmann T, 2016, J CLIN INVEST, V126, P3894, DOI 10.1172/JCI88950.
   Bruegmann T, 2010, NAT METHODS, V7, P897, DOI 10.1038/nmeth.1512.
   Campbell M, 2019, METHODS MOL BIOL, V2002, P51, DOI 10.1007/7651\_2018\_187.
   Crocini C, 2016, SCI REP-UK, V6, DOI 10.1038/srep35628.
   Dana H, 2016, ELIFE, V5, DOI 10.7554/eLife.12727.
   Deisseroth K, 2006, J NEUROSCI, V26, P10380, DOI 10.1523/JNEUROSCI.3863-06.2006.
   Entcheva E, 2021, NAT REV CARDIOL, V18, P349, DOI 10.1038/s41569-020-00478-0.
   Entcheva E, 2016, J PHYSIOL-LONDON, V594, P2503, DOI 10.1113/JP271559.
   Grijalva SI, 2019, ADV SCI, V6, DOI 10.1002/advs.201901099.
   Hochbaum DR, 2014, NAT METHODS, V11, P825, DOI {[}10.1038/NMETH.3000, 10.1038/nmeth.3000].
   Huang YL, 2015, J AM CHEM SOC, V137, P10767, DOI 10.1021/jacs.5b06644.
   Jia ZH, 2011, CIRC-ARRHYTHMIA ELEC, V4, P753, DOI 10.1161/CIRCEP.111.964247.
   Kilgus C, 2012, PHARM RES-DORDR, V29, P1380, DOI 10.1007/s11095-011-0647-7.
   Kim TY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196714.
   Kirkton RD, 2012, EUROPACE, V14, pV40, DOI 10.1093/europace/eus269.
   Kirkton RD, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1302.
   Klimas A, 2020, PROG BIOPHYS MOL BIO, V154, P62, DOI 10.1016/j.pbiomolbio.2019.02.004.
   Klimas A, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms11542.
   Kostecki GM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83398-4.
   Lapp H, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-09760-7.
   Li WZ, 2020, AM J PHYSIOL-HEART C, V319, pH1112, DOI 10.1152/ajpheart.00148.2020.
   McBeth C, 2017, BIOFABRICATION, V9, DOI 10.1088/1758-5090/aa53bd.
   McNamara HM, 2018, CELL SYST, V7, P359, DOI 10.1016/j.cels.2018.08.013.
   Mehesz AN, 2011, BIOFABRICATION, V3, DOI 10.1088/1758-5082/3/2/025002.
   Nagel G, 2003, P NATL ACAD SCI USA, V100, P13940, DOI 10.1073/pnas.1936192100.
   Napolitano AP, 2007, BIOTECHNIQUES, V43, P494, DOI 10.2144/000112591.
   Nyns ECA, 2019, SCI TRANSL MED, V11, DOI 10.1126/scitranslmed.aau6447.
   Oltolina F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137999.
   Park J, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0085221.
   Rehnelt S, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18122634.
   Valiunas V, 2009, J PHYSIOL-LONDON, V587, P5211, DOI 10.1113/jphysiol.2009.180505.
   Williams JC, 2015, BIOPHYS J, V108, P1934, DOI 10.1016/j.bpj.2015.03.032.
   Zaglia T, 2015, P NATL ACAD SCI USA, V112, pE4495, DOI 10.1073/pnas.1509380112.
   Zhang F, 2006, NAT METHODS, V3, P785, DOI 10.1038/nmeth936.
   Zhang HK, 2017, TRENDS BIOTECHNOL, V35, P625, DOI 10.1016/j.tibtech.2017.04.002.
   Zhao H, 2010, CYTOM PART A, V77A, P399, DOI 10.1002/cyto.a.20867.},
Number-of-Cited-References = {44},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {4},
Journal-ISO = {Front. Bioeng. Biotechnol.},
Doc-Delivery-Number = {TC8SC},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000668907500001},
OA = {gold, Green Submitted, Green Published},
DA = {2022-05-17},
}

@inproceedings{ WOS:000226861200026,
Author = {Everett, HR and Pacis, EB and Kogut, G and Farrington, N and Khurana, S},
Editor = {Gage, DW},
Title = {Towards a Warrighter's Associate: Eliminating the operator control unit},
Booktitle = {MOBILE ROBOTS XVII},
Series = {PROCEEDINGS OF THE SOCIETY OF PHOTO-OPTICAL INSTRUMENTATION ENGINEERS
   (SPIE)},
Year = {2004},
Volume = {5609},
Pages = {267-279},
Note = {Conference on Mobile Robots XVII, Philadelphia, PA, OCT 26-28, 2004},
Abstract = {In addition to the challenges of equipping a mobile robot with the
   appropriate sensors, actuators, and processing electronics necessary to
   perform some useful function, there coexists the equally important
   challenge of effectively controlling the system's desired actions. This
   need is particularly critical if the intent is to operate in conjunction
   with human forces in a military application, as any low-level
   distractions can seriously reduce a warfighter's chances of survival in
   hostile environments. Historically there can be seen a definitive trend
   towards making the robot smarter in order to reduce the control burden
   on the operator, and while much progress has been made in laboratory
   prototypes, all equipment deployed in theatre to date has been strictly
   teleoperated.
   There exists a definite tradeoff between the value added by the robot,
   in terms of how it contributes to the performance of the mission, and
   the loss of effectiveness associated with the operator control unit.
   From a command-and-control perspective, the ultimate goal would be to
   eliminate the need for a separate robot controller altogether, since it
   represents an unwanted burden and potential liability from the
   operator's perspective. This paper introduces the long-term concept of a
   supervised autonomous Warfighter's Associate, which employs a
   natural-language interface for communication with (and oversight by) its
   human counterpart. More realistic near-term solutions to achieve
   intermediate success are then presented, along with actual results to
   date. The primary application discussed is military, but the concept
   also applies to law enforcement, space exploration, and
   search-and-rescue scenarios.},
Publisher = {SPIE-INT SOC OPTICAL ENGINEERING},
Address = {1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Everett, HR (Corresponding Author), Space \& Naval Warfare Syst Ctr, SSC San Diego, San Diego, CA USA.
   Space \& Naval Warfare Syst Ctr, SSC San Diego, San Diego, CA USA.},
DOI = {10.1117/12.571458},
ISSN = {0277-786X},
ISBN = {0-8194-5562-8},
Keywords = {robotics; autonomous systems; augmented reality; natural language
   understanding; sign interpretation; speech recognition; simultaneous
   localization and mapping; world modeling; collision avoidance; target
   acquisition; machine vision},
Research-Areas = {Automation \& Control Systems; Computer Science; Robotics;
   Transportation},
Web-of-Science-Categories  = {Automation \& Control Systems; Computer Science, Artificial
   Intelligence; Robotics; Transportation Science \& Technology},
Affiliations = {Naval Information Warfare Center Pacific},
Cited-References = {Carlsson G, 2004, ARCH ENVIRON CON TOX, V46, P102, DOI 10.1007/s00244-003-2288-2.
   ESTRELLINA P, 2004, P SPIE UNM GROUND VE.
   Everett HR, 2003, IEEE INSTRU MEAS MAG, V6, P30, DOI 10.1109/MIM.2003.1251480.
   EVERETT HR, 1990, 1835 NOSC.
   EVERETT HR, 1996, ROBOTICS PRACTIT WIN, P15.
   FOX D, 1999, 16 NAT C ART INT AAA.
   Gilbert DR, 2001, BUS ETHICS Q, V11, P1, DOI 10.2307/3857865.
   GUTMAN JS, 1999, CIRCA 99.
   HOA N, 2004, ANS 10 INT C ROB REM.
   HOLLAND JM, 1995, 22 ANN TECHN S EXH.
   KILOUGH SN, 1989, ANS 3 TOP M ROB REM, P1.
   LAIRD RT, 1990, 17 ANN TECHN S EXH A, P280.
   MILGRAM P, 1994, IEICE T INFORMATIO D, V77.
   PEPI A, 2004, DS10012PH501040147 E.
   WANG CC, 2003, P IEEE INT C ROB AUT.
   Weizenbaum J., 1976, COMPUTER POWER HUMAN.},
Number-of-Cited-References = {16},
Times-Cited = {1},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {1},
Doc-Delivery-Number = {BBP24},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000226861200026},
DA = {2022-05-17},
}

@article{ WOS:000377725200009,
Author = {Qian, Kun and Ma, Xudong and Dai, Xianzhong and Fang, Fang and Zhou, Bo},
Title = {Gaussian process based IAQ distribution mapping using an interactive
   service robot},
Journal = {JOURNAL OF AMBIENT INTELLIGENCE AND SMART ENVIRONMENTS},
Year = {2016},
Volume = {8},
Number = {3},
Pages = {359-373},
Abstract = {In recent years, how poor Indoor Air Quality (IAQ) affects the residents
   and staff in living homes has raised many concerns. For the upcoming
   ambient assisted living facilities, the monitoring of IAQ pollution
   levels in indoor environments is of great significance for ensuring the
   health and comfort of individuals. Instead of the widely used wireless
   sensor network or wearable sensors, in this paper we consider the use of
   interactive service robots as a natural way to learn the environmental
   map as well as the distribution of Volatile Organic Compounds (VOCs). In
   order to map the VOC distribution in a framework that is consistent to
   the room coordinate, even if the environment is unknown to the robot, we
   designed an Initial Guided Mapping Mode which allows the robot to
   effectively map the environment obstacles by human guidance using a
   laser sensor and a RGB-D sensor. In the following Autonomous IAQ Mapping
   Mode, the robot carried a tailored sensor board for sampling a number of
   VOC measurements for learning the spatial distribution. A key problem is
   to deal with uncertainties brought by mobile sensing with co-existing
   people. Thus we applied Gaussian processes combined with Monte Carlo
   sampling method for modeling VOC distribution as well as querying
   concentration at uncovered locations. By incorporating the method in
   predicting the posterior predictive statistics of the VOC distribution,
   more accurate VOC distribution mapping is achieved in our implemented
   system. We provide experimental results in several testing scenarios to
   demonstrate the system performance. The proposed approach not only
   outperforms the traditional method, but is also human-friendly and easy
   to install. The method is feasible for applying service robots to
   predict the IAQ distribution or the spatial concentrations of any
   interest during its long-term operation in residential environments.},
Publisher = {IOS PRESS},
Address = {NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Qian, K (Corresponding Author), Minist Educ, Key Lab Measurement \& Control Complex Syst Engn, Nanjing, Jiangsu, Peoples R China.
   Qian, K (Corresponding Author), Southeast Univ, Sch Automat, 2 Sipailou, Nanjing 210096, Jiangsu, Peoples R China.
   Qian, Kun; Ma, Xudong; Dai, Xianzhong; Fang, Fang; Zhou, Bo, Minist Educ, Key Lab Measurement \& Control Complex Syst Engn, Nanjing, Jiangsu, Peoples R China.
   Qian, Kun; Ma, Xudong; Dai, Xianzhong; Fang, Fang; Zhou, Bo, Southeast Univ, Sch Automat, 2 Sipailou, Nanjing 210096, Jiangsu, Peoples R China.},
DOI = {10.3233/AIS-160376},
ISSN = {1876-1364},
EISSN = {1876-1372},
Keywords = {Indoor Air Quality; service robot; Gaussian process; VOC distribution
   modeling; human-robot interaction},
Keywords-Plus = {NAVIGATION; LOCALIZATION; SYSTEM},
Research-Areas = {Computer Science; Telecommunications},
Web-of-Science-Categories  = {Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Telecommunications},
Author-Email = {kqian@seu.edu.cn},
Affiliations = {Southeast University - China},
ORCID-Numbers = {Qian, Kun/0000-0001-7429-1742},
Funding-Acknowledgement = {National Natural Science Foundation of China {[}61105094, 61573101,
   61573100]; Fundamental Research Funds for the Central Universities
   {[}2242013K30004]; Priority Academic Program Development of Jiangsu
   Higher Education Institutions},
Funding-Text = {This work is supported by the National Natural Science Foundation of
   China (Grant No. 61105094, 61573101 and 61573100), the Fundamental
   Research Funds for the Central Universities (No. 2242013K30004), and
   it's also funded by the Priority Academic Program Development of Jiangsu
   Higher Education Institutions.},
Cited-References = {Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116.
   Bennetts VMH, 2013, IEEE INT CONF ROBOT, P2335, DOI 10.1109/ICRA.2013.6630893.
   Deisenroth P.M., 2014, IEEE T PATTERN ANAL.
   Deleawe S, 2010, J AMB INTEL SMART EN, V2, P145, DOI 10.3233/AIS-2010-0061.
   {*}DUSTBOT, 2008, DUSTBOT NETW COOP RO.
   Ferris B., 2006, P ROB SCI SYST P ROB SCI SYST.
   Grisetti G, 2005, IEEE INT CONF ROBOT, P2432.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Gross H-M, 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2430, DOI 10.1109/IROS.2011.6048377.
   Hall E.T., 1966, HIDDEN DIMENSION.
   Jadaliha M, 2013, IEEE T SIGNAL PROCES, V61, P223, DOI 10.1109/TSP.2012.2223695.
   Kowadlo G, 2008, INT J ROBOT RES, V27, P869, DOI 10.1177/0278364908095118.
   Krause A, 2008, J MACH LEARN RES, V9, P235.
   Lilienthal A., 2007, P ICRA WORKSH ROB OL.
   Manes G., 2012, INT J DISTRIBUTED SE.
   Minguez J, 2005, ROBOT AUTON SYST, V52, P290, DOI 10.1016/j.robot.2005.06.001.
   Ninomura PT, 1999, ASHRAE J, V41, P34.
   Peng CH, 2014, SCI WORLD J, DOI 10.1155/2014/528410.
   Qian K, 2014, J AMB INTEL SMART EN, V6, P5, DOI 10.3233/AIS-130243.
   Qian K, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/55926.
   Qian K, 2012, J AMB INTEL SMART EN, V4, P547, DOI 10.3233/AIS-2012-0178.
   Qian K, 2010, ADV ROBOTICS, V24, P1813, DOI 10.1163/016918610X527176.
   Qian K, 2010, J BIONIC ENG, V7, P150, DOI 10.1016/S1672-6529(09)60199-2.
   Quigley M., 2009, P ICRA WORKSH OP SOU, V3, P5.
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1.
   Robbel P., 2011, P RSS 2011 RGB D WOR.
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381.
   Snelson E., 2006, ADV NEURAL INF PROCE, P1257.
   Stachniss C, 2009, SPRINGER TRAC ADV RO, V55, P3.
   Stachniss C, 2009, AUTON ROBOT, V26, P187, DOI 10.1007/s10514-009-9111-5.
   Tani A., 2011, 2011 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2011), P2423, DOI 10.1109/IROS.2011.6048316.
   Topp E.A., 2008, THESIS.
   Trincavelli M., 2012, P 2012 IEEE SENS C.
   Tsow F, 2009, IEEE SENS J, V9, P1734, DOI 10.1109/JSEN.2009.2030747.
   United States Environmental Protection Agency, INTR IND AIR QUAL IA.
   Weschler CJ, 2011, INDOOR AIR, V21, P205, DOI 10.1111/j.1600-0668.2011.00713.x.
   Williams CKI, 2001, ADV NEUR IN, V13, P682.
   Xu YF, 2011, IEEE T ROBOT, V27, P1118, DOI 10.1109/TRO.2011.2162766.
   Xu YF, 2011, SENSORS-BASEL, V11, P3051, DOI 10.3390/s110303051.
   Zhao C, 2013, INT J MODEL IDENTIF, V20, P319, DOI 10.1504/IJMIC.2013.057565.},
Number-of-Cited-References = {40},
Times-Cited = {2},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {17},
Journal-ISO = {J. Ambient Intell. Smart Environ.},
Doc-Delivery-Number = {DO4AW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000377725200009},
DA = {2022-05-17},
}

@article{ WOS:000671953500001,
Author = {Lin, Yi-Chun and Manish, Raja and Bullock, Darcy and Habib, Ayman},
Title = {Comparative Analysis of Different Mobile LiDAR Mapping Systems for Ditch
   Line Characterization},
Journal = {REMOTE SENSING},
Year = {2021},
Volume = {13},
Number = {13},
Pages = {2485},
Month = {JUL},
Abstract = {Maintenance of roadside ditches is important to avoid localized flooding
   and premature failure of pavements. Scheduling effective preventative
   maintenance requires a reasonably detailed mapping of the ditch profile
   to identify areas in need of excavation to remove long-term sediment
   accumulation. This study utilizes high-resolution, high-quality point
   clouds collected by mobile LiDAR mapping systems (MLMS) for mapping
   roadside ditches and performing hydrological analyses. The performance
   of alternative MLMS units, including an unmanned aerial vehicle, an
   unmanned ground vehicle, a portable backpack system along with its
   vehicle-mounted version, a medium-grade wheel-based system, and a
   high-grade wheel-based system, is evaluated. Point clouds from all the
   MLMS units are in agreement within the +/- 3 cm range for solid surfaces
   and +/- 7 cm range for vegetated areas along the vertical direction. The
   portable backpack system that could be carried by a surveyor or mounted
   on a vehicle is found to be the most cost-effective method for mapping
   roadside ditches, followed by the medium-grade wheel-based system.
   Furthermore, a framework for ditch line characterization is proposed and
   tested using datasets acquired by the medium-grade wheel-based and
   vehicle-mounted portable systems over a state highway. An existing
   ground-filtering approach-cloth simulation-is modified to handle
   variations in point density of mobile LiDAR data. Hydrological analyses,
   including flow direction and flow accumulation, are applied to extract
   the drainage network from the digital terrain model (DTM).
   Cross-sectional/longitudinal profiles of the ditch are automatically
   extracted from the LiDAR data and visualized in 3D point clouds and 2D
   images. The slope derived from the LiDAR data turned out to be very
   close to the highway cross slope design standards of 2\% on driving
   lanes, 4\% on shoulders, and a 6-by-1 slope for ditch lines.},
Publisher = {MDPI},
Address = {ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND},
Type = {Article},
Language = {English},
Affiliation = {Habib, A (Corresponding Author), Purdue Univ, Lyles Sch Civil Engn, W Lafayette, IN 47907 USA.
   Lin, Yi-Chun; Manish, Raja; Bullock, Darcy; Habib, Ayman, Purdue Univ, Lyles Sch Civil Engn, W Lafayette, IN 47907 USA.},
DOI = {10.3390/rs13132485},
Article-Number = {2485},
EISSN = {2072-4292},
Keywords = {LiDAR; mobile mapping system; digital terrain model; slope analysis;
   longitudinal; cross-sectional profiles; roadside ditch; drainage network},
Keywords-Plus = {DRAINAGE NETWORKS; CROSS-SECTIONS; EXTRACTION; TERRESTRIAL; LANDSCAPES;
   RESOLUTION; INVENTORY},
Research-Areas = {Environmental Sciences \& Ecology; Geology; Remote Sensing; Imaging
   Science \& Photographic Technology},
Web-of-Science-Categories  = {Environmental Sciences; Geosciences, Multidisciplinary; Remote Sensing;
   Imaging Science \& Photographic Technology},
Author-Email = {lin934@purdue.edu
   rmanish@purdue.edu
   darcy@purdue.edu
   ahabib@purdue.edu},
Affiliations = {Purdue University System; Purdue University; Purdue University West
   Lafayette Campus},
ORCID-Numbers = {Habib, Ayman/0000-0001-6498-5951
   Lin, Yi Chun/0000-0003-3564-372X},
Funding-Acknowledgement = {Joint Transportation Research Program},
Funding-Text = {This work was supported in part by the Joint Transportation Research
   Program administered by the Indiana Department of Transportation and
   Purdue University. The contents of this paper reflect the views of the
   authors, who are responsible for the facts and the accuracy of the data
   presented herein, and do not necessarily reflect the official views or
   policies of the sponsoring organizations.},
Cited-References = {Ariza-Villaverde AB, 2015, GEOMORPHOLOGY, V241, P243, DOI 10.1016/j.geomorph.2015.03.040.
   Bailly JS, 2008, INT J REMOTE SENS, V29, P3489, DOI 10.1080/01431160701469057.
   Balado J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19163466.
   Barber C.P., 2005, CARTOGR GEOGR INF SC, V32, P401, DOI {[}10.1559/152304005775194692, DOI 10.1559/152304005775194692].
   Bertels L, 2011, INT J REMOTE SENS, V32, P2905, DOI 10.1080/01431161003745632.
   Bolkas D, 2021, J SURV ENG, V147, DOI 10.1061/(ASCE)SU.1943-5428.0000346.
   Broersen T, 2017, COMPUT GEOSCI-UK, V106, P171, DOI 10.1016/j.cageo.2017.06.003.
   Buchanan B, 2013, J HYDROL, V486, P293, DOI 10.1016/j.jhydrol.2013.01.040.
   Cai H, 2008, COMPUT-AIDED CIV INF, V23, P157, DOI 10.1111/j.1467-8667.2008.00518.x.
   Castro M, 2016, SURV REV, V48, P309, DOI 10.1179/1752270615Y.0000000037.
   Cheng YT, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091379.
   Costabile P, 2021, ENVIRON MODELL SOFTW, V135, DOI 10.1016/j.envsoft.2020.104889.
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692.
   Gargoum S, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P563, DOI 10.1109/ICTIS.2017.8047822.
   Gargoum SA, 2018, J COMPUT CIVIL ENG, V32, DOI 10.1061/(ASCE)CP.1943-5487.0000753.
   Gharaibeh NG, 2014, STRUCT INFRASTRUCT E, V10, P409, DOI 10.1080/15732479.2012.757330.
   Gong J., 2012, COMPUTING CIVIL ENG, P545.
   Guan HY, 2016, INT J IMAGE DATA FUS, V7, P219, DOI 10.1080/19479832.2016.1188860.
   Gunen M.A., 2019, E J NEW WORLD SCI AC, V14, P1, DOI {[}10.12739/NWSA.2019.14.1.4A0062, DOI 10.12739/NWSA.2019.14.1.4A0062].
   Habib A., LIDAR ERROR PROPAGAT.
   Hendricks MD, 2018, SUSTAIN CITIES SOC, V38, P265, DOI 10.1016/j.scs.2017.12.039.
   Holgado-Barco A, 2017, COMPUT-AIDED CIV INF, V32, P3, DOI 10.1111/mice.12213.
   Ibeh C., LIDAR BASED ROADSIDE, P1.
   Jalayer M, 2015, J TRANSP SAF SECUR, V7, P345, DOI 10.1080/19439962.2014.976691.
   JENSON SK, 1988, PHOTOGRAMM ENG REM S, V54, P1593.
   Lague D, 2013, ISPRS J PHOTOGRAMM, V82, P10, DOI 10.1016/j.isprsjprs.2013.04.009.
   Levavasseur F, 2015, J LAND USE SCI, V10, P256, DOI 10.1080/1747423X.2014.884644.
   Levavasseur F, 2012, HYDROL PROCESS, V26, P3393, DOI 10.1002/hyp.8422.
   Lin YC, 2019, TRANSPORT RES REC, V2673, P117, DOI 10.1177/0361198119835802.
   Lin YC, 2021, REMOTE SENS ENVIRON, V256, DOI 10.1016/j.rse.2021.112299.
   Maidment D., 2002, ARC HYDRO GIS WATER.
   Matos J.A., 2016, THESIS U CINCINNATI THESIS U CINCINNATI.
   McGee H.W., 2009, FHWASA09024 FHWASA09024.
   Metz M, 2011, HYDROL EARTH SYST SC, V15, P667, DOI 10.5194/hess-15-667-2011.
   Murphy PNC, 2008, HYDROL PROCESS, V22, P1747, DOI 10.1002/hyp.6770.
   Oti IC, 2019, J INFRASTRUCT SYST, V25, DOI 10.1061/(ASCE)IS.1943-555X.0000495.
   Pricope NG, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164453.
   Puente I, 2016, TUNN UNDERGR SP TECH, V59, P48, DOI 10.1016/j.tust.2016.06.010.
   Rapinel S, 2015, HYDROL RES, V46, P276, DOI 10.2166/nh.2013.121.
   Ravi R., 2021, PHOTOGRAMM ENG REMOT.
   Ravi R, 2020, TRANSPORT RES REC, V2674, P124, DOI 10.1177/0361198120927006.
   Ravi R, 2018, IEEE J-STARS, V11, P1694, DOI 10.1109/JSTARS.2018.2812796.
   Renaudin E, 2011, ETRI J, V33, P517, DOI 10.4218/etrij.11.1610.0006.
   Roelens J, 2018, ISPRS J PHOTOGRAMM, V146, P409, DOI 10.1016/j.isprsjprs.2018.10.014.
   Roelens J, 2018, HYDROL PROCESS, V32, P1026, DOI 10.1002/hyp.11472.
   Schneider R, 2019, TRANSPORT RES REC, V2673, P767, DOI 10.1177/0361198119854092.
   Siegel ZS, 2021, WEATHER CLIM EXTREME, V32, DOI 10.1016/j.wace.2021.100311.
   Soilan M, 2016, ISPRS J PHOTOGRAMM, V114, P92, DOI 10.1016/j.isprsjprs.2016.01.019.
   Tsai YC, 2013, TRANSPORT RES REC, P53, DOI 10.3141/2367-06.
   Wen CL, 2019, ISPRS J PHOTOGRAMM, V147, P178, DOI 10.1016/j.isprsjprs.2018.10.007.
   Williams K, 2013, REMOTE SENS-BASEL, V5, P4652, DOI 10.3390/rs5094652.
   Yan L, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090958.
   Yilmaz CS, 2018, INT J REMOTE SENS, V39, P5016, DOI 10.1080/01431161.2017.1420942.
   You CB, 2019, IEEE T INTELL TRANSP, V20, P2550, DOI 10.1109/TITS.2018.2868168.
   Zhang WM, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060501.},
Number-of-Cited-References = {55},
Times-Cited = {2},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {3},
Journal-ISO = {Remote Sens.},
Doc-Delivery-Number = {TH2VX},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000671953500001},
OA = {gold},
DA = {2022-05-17},
}

@article{ WOS:000686762900011,
Author = {Li, Liang and Bano, Sophia and Deprest, Jan and David, Anna L. and
   Stoyanov, Danail and Vasconcelos, Francisco},
Title = {Globally Optimal Fetoscopic Mosaicking Based on Pose Graph Optimisation
   With Affine Constraints},
Journal = {IEEE ROBOTICS AND AUTOMATION LETTERS},
Year = {2021},
Volume = {6},
Number = {4},
Pages = {7831-7838},
Month = {OCT},
Abstract = {Fetoscopic laser ablation surgery could be guided using a high-quality
   panorama of the operating site, representing a map of the placental
   vasculature. This can be achieved during the initial inspection phase of
   the procedure using image mosaicking techniques. Due to the lack of
   camera calibration in the operating room, it has been mostly modelled as
   an affine registration problem. While previous work mostly focuses on
   image feature extraction for visual odometry, the challenges related to
   large-scale reconstruction (re-localisation, loop closure, drift
   correction) remain largely unaddressed in this context. This letter
   proposes using pose graph optimisation to produce globally optimal image
   mosaics of placental vessels. Our approach follows the SLAMframework
   with a front-end for visual odometry and a back-end for long-term
   refinement. Our front-end uses a recent state-of-the-art odometry
   approach based on vessel segmentation, which is then managed by a
   key-frame structure and the bag-of-words (BoW) scheme to retrieve loop
   closures. The back-end, which is our key contribution, models odometry
   and loop closure constraints as a pose graph with affine warpings
   between states. This problem in the special Euclidean space cannot be
   solved by existing pose graph algorithms and available libraries such as
   G2O. We model states on affine Lie group with local linearisation in its
   Lie algebra. The cost function is established using Mahalanobis distance
   with the vectorisation of the Lie algebra. Finally, an iterative
   optimisation algorithm is adopted to minimise the cost function. The
   proposed pose graph optimisation is first validated on simulation data
   with a synthetic trajectory that has different levels of noise and
   different numbers of loop closures. Then the whole system is validated
   using real fetoscopic data that has three sequences with different
   numbers of frames and loop closures. Experimental results validate the
   advantage of the proposed method compared with baselines.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Li, L (Corresponding Author), UCL, Wellcome EPSRC Ctr Intervent \& Surg Sci WEISS, London WC1E 6BT, England.
   Li, L (Corresponding Author), UCL, Dept Comp Sci, London WC1E 6BT, England.
   Li, Liang; Bano, Sophia; Stoyanov, Danail; Vasconcelos, Francisco, UCL, Wellcome EPSRC Ctr Intervent \& Surg Sci WEISS, London WC1E 6BT, England.
   Li, Liang; Bano, Sophia; Stoyanov, Danail; Vasconcelos, Francisco, UCL, Dept Comp Sci, London WC1E 6BT, England.
   Deprest, Jan, Univ Hosp KU Leuven, WEISS, B-3000 Leuven, Belgium.
   Deprest, Jan, Univ Hosp KU Leuven, Dept Dev \& Regenerat, B-3000 Leuven, Belgium.
   Deprest, Jan, UCL, Inst Womens Hlth, London WC1E 6HU, England.
   David, Anna L., UCL, WEISS, London WC1E 6BT, England.
   David, Anna L., UCL, EGA Inst Womens Hlth, London WC1E 6BT, England.
   David, Anna L., Univ Coll London Hosp, Natl Inst Hlth Res, Biomed Res Ctr, London WC1E 6BT, England.},
DOI = {10.1109/LRA.2021.3100938},
ISSN = {2377-3766},
Keywords = {Surgical robotics; pose graph optimisation; fetoscopic camera; image
   mosaicking; affine Lie group},
Research-Areas = {Robotics},
Web-of-Science-Categories  = {Robotics},
Author-Email = {liang-li@ucl.ac.uk
   sophia.bano@ucl.ac.uk
   Jan.Deprest@uz.kuleuven.ac.be
   a.david@ucl.ac.uk
   danail.stoyanov@ucl.ac.uk
   f.vasconcelos@ucl.ac.uk},
Affiliations = {UK Research \& Innovation (UKRI); Engineering \& Physical Sciences
   Research Council (EPSRC); University of London; University College
   London; University of London; University College London; League of
   European Research Universities - LERU; KU Leuven; University Hospital
   Leuven; League of European Research Universities - LERU; KU Leuven;
   University Hospital Leuven; University of London; University College
   London; University of London; University College London; University of
   London; University College London; University College London Hospitals
   NHS Foundation Trust; University of London; University College London},
ResearcherID-Numbers = {Li, Liang/H-6189-2017
   },
ORCID-Numbers = {Bano, Sophia/0000-0003-1329-4565
   Li, Liang/0000-0001-5802-2681
   David, Anna/0000-0002-0199-6140},
Funding-Acknowledgement = {Wellcome/EPSRC Centre for Interventional and Surgical Sciences (WEISS)
   at UCL {[}203145Z/16/Z]; EPSRC {[}EP/P027938/1, EP/R004080/1,
   NS/A000027/1, EP/P012841/1]; H2020 FET {[}GA863146]; Wellcome
   {[}WT101957]; Royal Academy of Engineering Chair in Emerging
   Technologies {[}CiET1819/2/36]},
Funding-Text = {This work was supported in part by the Wellcome/EPSRC Centre for
   Interventional and Surgical Sciences (WEISS) at UCL (203145Z/16/Z),
   EPSRC (EP/P027938/1, EP/R004080/1,NS/A000027/1), the H2020 FET
   (GA863146) and Wellcome {[}WT101957]. The work of Danail Stoyanov was
   supported by a Royal Academy of Engineering Chair in Emerging
   Technologies (CiET1819/2/36) and an EPSRC Early Career Research
   Fellowship (EP/P012841/1).},
Cited-References = {Ahmad MA, 2020, INT J COMPUT ASS RAD, V15, P1561, DOI 10.1007/s11548-020-02166-3.
   Aloise I, 2020, IEEE ROBOT AUTOM LET, V5, P274, DOI 10.1109/LRA.2019.2956456.
   Bano Sophia, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12263), P763, DOI 10.1007/978-3-030-59716-0\_73.
   Bano S, 2020, INT J COMPUT ASS RAD, V15, P1807, DOI 10.1007/s11548-020-02242-8.
   Bano S, 2019, LECT NOTES COMPUT SC, V11764, P311, DOI 10.1007/978-3-030-32239-7\_35.
   Baschat A, 2011, J PERINAT MED, V39, P107, DOI {[}10.1515/JPM.2010.147, 10.1515/jpm.2010.147].
   Bergen T, 2016, IEEE J BIOMED HEALTH, V20, P304, DOI 10.1109/JBHI.2014.2384134.
   Bouguet J.-Y., 2001, INTEL CORP, V5, P4.
   Carlone L, 2018, IEEE ROBOT AUTOM LET, V3, P1160, DOI 10.1109/LRA.2018.2793352.
   Carlone L, 2014, INT J ROBOT RES, V33, P965, DOI 10.1177/0278364914523689.
   Chadebecq F, 2020, INT J COMPUT VISION, V128, P1101, DOI 10.1007/s11263-019-01218-9.
   Chang CH, 2017, PROC CVPR IEEE, P3777, DOI 10.1109/CVPR.2017.402.
   Daga P, 2016, PROC SPIE, V9786, DOI 10.1117/12.2217172.
   Deprest JA, 1998, ULTRASOUND OBST GYN, V11, P347, DOI 10.1046/j.1469-0705.1998.11050347.x.
   Dwyer G, 2017, IEEE ROBOT AUTOM LET, V2, P1656, DOI 10.1109/LRA.2017.2679902.
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2\_54.
   Forster C, 2017, IEEE T ROBOT, V33, P249, DOI 10.1109/TRO.2016.2623335.
   Gaisser F, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010024.
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607.
   Lopez M., 2019, P IEEE C COMP VIS PA, P11817.
   Okumura KI, 2013, IEEE INT C INT ROBOT, P2665, DOI 10.1109/IROS.2013.6696732.
   Peter L, 2018, INT J COMPUT ASS RAD, V13, P713, DOI 10.1007/s11548-018-1728-4.
   Reeff M, 2006, GI JAHRESTAGUNG, V1, P467.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4\_28.
   Sunderhauf N, 2012, IEEE INT CONF ROBOT, P1254, DOI 10.1109/ICRA.2012.6224709.
   Thrun S, 2006, INT J ROBOT RES, V25, P403, DOI 10.1177/0278364906065387.
   Tian YL, 2020, IEEE ROBOT AUTOM LET, V5, P5819, DOI 10.1109/LRA.2020.3010216.
   Vandebroek T, 2019, IEEE INT C INT ROBOT, P425, DOI 10.1109/IROS40897.2019.8968219.
   Wu F, 2020, IEEE ROBOT AUTOM LET, V5, P6193, DOI 10.1109/LRA.2020.3011394.
   Xiang TZ, 2018, PATTERN RECOGN, V83, P481, DOI 10.1016/j.patcog.2018.06.013.
   Zheng J, 2019, IEEE T MULTIMEDIA, V21, P2561, DOI 10.1109/TMM.2019.2905692.},
Number-of-Cited-References = {31},
Times-Cited = {3},
Usage-Count-Last-180-days = {5},
Usage-Count-Since-2013 = {6},
Journal-ISO = {IEEE Robot. Autom. Lett.},
Doc-Delivery-Number = {UC8HL},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000686762900011},
OA = {Green Published},
DA = {2022-05-17},
}

@article{ WOS:000437224100003,
Author = {Anderson, Kristen M. and Barback, Christopher V. and Qin, Zhengtao and
   Hall, David J. and Hoh, Carl K. and Vera, David R. and McHale, Michael
   T.},
Title = {Molecular Imaging of endometrial sentinel lymph nodes utilizing
   fluorescent-labeled Tilmanocept during robotic-assisted surgery in a
   porcine model},
Journal = {PLOS ONE},
Year = {2018},
Volume = {13},
Number = {7},
Pages = {e0197842},
Month = {JUL 2},
Abstract = {Molecular imaging with a fluorescent version of Tilmanocept may permit
   an accurate and facile detection of sentinel nodes of endometrial
   cancer. Tilmanocept accumulates in sentinel lymph nodes (SLN) by binding
   to a cell surface receptor unique to macrophages and dendritic cells.
   Four female Yorkshire pigs underwent cervical stromal injection of
   IRDye800-Tilmanocept, a molecular imaging agent tagged with
   near-infrared fluorescent dye and radiolabeled with gallium-68 and
   technetium-99m. PET/CT scans 1.5 hours post-injection provided
   preoperative SLN mapping. Robotic-assisted lymphadenectomy was performed
   two days after injection, using the FireFly imaging system to identify
   nodes demonstrating fluorescent signal. After removal of fluorescent
   nodes, pelvic and periaortic node dissections were performed. Nodes were
   assayed for technetium-99m activity, and SLNs were established using the
   ``10\%-rule{''}, requiring that the radioactivity of additional SLNs be
   greater than 10\% of the ``hottest{''} SLN. Thirty-four nodal samples
   were assayed ex vivo for radioactivity. All the SLNs satisfying the
   ``10\%-rule{''} were detected using the FireF/ysystem. Five fluorescent
   nodes were detected, corresponding with preoperative PET/CT scan. Three
   pigs had one SLN and one pig had two SLNs, with 100\% concordance
   between fluorescence and radioactivity. Fluorescent-labeled Tilmanocept
   permits real-time intraoperative detection of SLNs during
   robotic-assisted lymphadenectomy for endometrial cancer in a porcine
   model. When radiolabeled with gallium-68, Tilmanocept allows for
   preoperative localization of SLNs using PET/CT, and shows specificity to
   SLNs with persistent fluorescent signal, detectable using the
   FireF/ysystem, for two days post-injection. In conclusion, these
   findings suggest that a phase I trial in human subjects is warranted,
   and that a long-term goal of an intra-operative administration of
   non-radioactive fluorescent-labeled Tilmanocept is possible.},
Publisher = {PUBLIC LIBRARY SCIENCE},
Address = {1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA},
Type = {Article},
Language = {English},
Affiliation = {Anderson, KM (Corresponding Author), Univ Calif San Diego, Dept Reprod Med, Div Gynecol Oncol, San Diego, CA 92103 USA.
   Anderson, Kristen M.; McHale, Michael T., Univ Calif San Diego, Dept Reprod Med, Div Gynecol Oncol, San Diego, CA 92103 USA.
   Barback, Christopher V.; Qin, Zhengtao; Hall, David J.; Hoh, Carl K.; Vera, David R., Univ Calif San Diego, Dept Radiol, San Diego, CA 92103 USA.
   Barback, Christopher V.; Qin, Zhengtao; Hall, David J.; Hoh, Carl K.; Vera, David R., Univ Calif San Diego, UCSD Mol Imaging Program, San Diego, CA 92103 USA.},
DOI = {10.1371/journal.pone.0197842},
Article-Number = {e0197842},
ISSN = {1932-6203},
Keywords-Plus = {SYSTEMATIC PELVIC LYMPHADENECTOMY; SQUAMOUS-CELL CARCINOMA; INDOCYANINE
   GREEN; BLUE-DYE; CANCER; IDENTIFICATION; RADIOTRACER; TRIAL},
Research-Areas = {Science \& Technology - Other Topics},
Web-of-Science-Categories  = {Multidisciplinary Sciences},
Author-Email = {kranderson@ucsd.edu},
Affiliations = {University of California System; University of California San Diego;
   University of California System; University of California San Diego;
   University of California System; University of California San Diego},
Cited-References = {Abu-Rustum NR, 2014, J NATL COMPR CANC NE, V12, P288, DOI 10.6004/jnccn.2014.0026.
   Abu-Rustum NR, 2009, GYNECOL ONCOL, V113, P163, DOI 10.1016/j.ygyno.2009.01.003.
   Agrawal A, 2015, ANN SURG ONCOL, V22, P3708, DOI 10.1245/s10434-015-4382-x.
   Barlin JN, 2012, GYNECOL ONCOL, V125, P531, DOI 10.1016/j.ygyno.2012.02.021.
   Barton DPJ, 2009, INT J GYNECOL CANCER, V19, P1465, DOI 10.1111/IGC.0b013e3181b89f95.
   Buda A, 2017, J MINIM INVAS GYN, V24, P165, DOI 10.1016/j.jmig.2016.09.006.
   CHOI HJ, 2016, J GYNECOL ONCOL, V27.
   Emerson DK, 2012, RADIOLOGY, V265, P186, DOI 10.1148/radiol.12120638.
   Holloway RW, 2016, GYNECOL ONCOL, V141, P206, DOI 10.1016/j.ygyno.2016.02.018.
   Hosseini A, 2014, J SURG RES, V190, P528, DOI 10.1016/j.jss.2014.05.012.
   Imboden S, 2015, ANN SURG ONCOL, V22, P4198, DOI 10.1245/s10434-015-4701-2.
   Lee HJ, 2017, J NUCL MED, V58, P547, DOI 10.2967/jnumed.116.178582.
   LISS MA, 2014, UROLOGY, V84, DOI DOI 10.1016/J.JACI.2014.07.006.
   Liss MA, 2014, J NUCL MED, V55, P1552, DOI 10.2967/jnumed.114.140871.
   Marcinow AM, 2013, JAMA OTOLARYNGOL, V139, P895, DOI 10.1001/jamaoto.2013.4239.
   NCCN, 2017, CLIN PRACT GUID UT N.
   Panici PB, 2008, JNCI-J NATL CANCER I, V100, P1707, DOI 10.1093/jnci/djn397.
   Papadia A, 2017, J CANCER RES CLIN, V143, P2039, DOI 10.1007/s00432-017-2501-8.
   Papadia A, 2017, J CANCER RES CLIN, V143, P475, DOI 10.1007/s00432-016-2297-y.
   Qin ZT, 2015, NUCL MED BIOL, V42, P917, DOI 10.1016/j.nucmedbio.2015.07.011.
   Qin ZT, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.10.101315.
   Rossi EC, 2017, LANCET ONCOL, V18, P384, DOI 10.1016/S1470-2045(17)30068-2.
   Seamon LG, 2010, GYNECOL ONCOL, V117, P6, DOI 10.1016/j.ygyno.2009.12.025.
   Siegel RL, 2016, CA-CANCER J CLIN, V66, P7, DOI 10.3322/caac.21332.
   Sondak VK, 2013, ANN SURG ONCOL, V20, P680, DOI 10.1245/s10434-012-2612-z.
   Stroup SP, 2012, CLIN EXP METASTAS, V29, P673, DOI 10.1007/s10585-012-9498-9.
   Todo Y, 2010, LANCET, V375, P1165, DOI 10.1016/S0140-6736(09)62002-X.
   Unkart JT, 2015, ANN SURG ONCOL, V22, pS559, DOI 10.1245/s10434-015-4802-y.
   Vera DR, 2001, J NUCL MED, V42, P951.
   Wallace AM, 2003, ANN SURG ONCOL, V10, P531, DOI 10.1245/ASO.2003.07.012.
   Wallace AM, 2013, ANN SURG ONCOL, V20, P2590, DOI 10.1245/s10434-013-2887-8.
   Wallace AM, 2009, NUCL MED BIOL, V36, P687, DOI 10.1016/j.nucmedbio.2009.04.007.},
Number-of-Cited-References = {32},
Times-Cited = {7},
Usage-Count-Last-180-days = {1},
Usage-Count-Since-2013 = {8},
Journal-ISO = {PLoS One},
Doc-Delivery-Number = {GL5QR},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000437224100003},
OA = {Green Published, Green Submitted, gold},
DA = {2022-05-17},
}

@article{ WOS:000507640900033,
Author = {Mohamed, Sharaf C. and Rajaratnam, Sanjif and Hong, Seung Tae and Nejat,
   Goldie},
Title = {Person Finding: An Autonomous Robot Search Method for Finding Multiple
   Dynamic Users in Human-Centered Environments},
Journal = {IEEE TRANSACTIONS ON AUTOMATION SCIENCE AND ENGINEERING},
Year = {2020},
Volume = {17},
Number = {1},
Pages = {433-449},
Month = {JAN},
Abstract = {Robot search for multiple dynamic users within a multi-room environment
   is important for social robots to find and engage in various human-robot
   interaction scenarios with these users. In this paper, we present a
   novel autonomous person search technique for a robot finding a group of
   dynamic users before a deadline. The uniqueness of our approach is that
   unlike existing robot search methods, we consider activity information
   to predict where, when, and for how long a user will be in a specific
   room. This allows for the generation of search plans without any
   assumption on the frequency of user movements. We represent our search
   problem as an extension of the orienteering problem (OP), which we
   define herein as the robot person search OP (PSOP). User activity
   information is represented as spatial-temporal user activity probability
   density functions (APDFs). We solve the PSOP using APDFs to generate a
   search plan to maximize the expected number of users found before the
   deadline. The solution of the PSOP is obtained in two steps. First, by
   solving a variant of the multiperiod knapsack problem to determine which
   rooms should be searched and for how long these rooms should be
   searched. Then, we solve the traveling salesman problem to obtain the
   order in which to search these rooms. Experiments were conducted to
   validate the performance of our robot search method in finding different
   numbers of multiple dynamic users for varying environment sizes and
   search durations. We also compared our method with two coverage planners
   and a Markov decision process planner. On average, our planner found
   more users than the other planners for a variety of scenarios. Finally,
   we performed experiments that introduced uncertainty into both the APDFs
   as well as during the search to validate the robustness of our overall
   approach. Note to Practitioners-The majority of current social robot
   applications either consider users being collocated with the robot in
   the same region or users being static within another region in the
   environment. However, several applications exist where users are dynamic
   within their environments and for which a robot needs to find them in
   order to provide assistance, for example, in office buildings, airports,
   museums, hospitals, and long-term care facilities. In general, these
   users are performing activities within these regions. We uniquely
   consider such activity information in order to model user location
   probabilities. We developed a robot search planner that uses these
   probabilities to find users of interest in multi-room environments. The
   planner is novel as it reasons about when and which regions to search
   and for how long, as well as if the same region needs to be searched
   multiple times as users can perform multiple activities during the
   search time frame in the same region or revisit a region to perform a
   new activity. We have integrated the search planner within a robot
   system architecture. The robot travels to each region and then uses a
   local planner to navigate to locations within the region. At each
   location, a person identification technique is used to identify the
   target users in order to engage in human-robot interactions. Experiments
   were performed for two search applications: 1) a simulated Blueberry
   robot finding multiple residents in a virtual representation of one of
   our collaborating long-term care facilities and 2) the physical
   Blueberry robot finding multiple staff/students on a physical floor of a
   university building.
   For both experiments, plans were generated on the robot's onboard Lenovo
   Thinkpad X230 using the robot operating system (ROS) in Ubuntu. User
   activity data and maps used for the experiments in the care facility can
   be found on our website
   (http://asblab.mie.utoronto.ca/research-areas/person-search-human-center
   ed-environments), under multi-user robot search. The physical Blueberry
   robot was also equipped with an ASUS Xtion IR depth camera, a Logitech
   pro c920 RGB camera, and a Hokuyo laser range finder for person
   identification and navigation in the environment. The results showed
   that our system was effective in finding multiple dynamic users under
   varying environment sizes and search durations. Our search planner also
   outperformed other planners and was robust to uncertainties in the user
   model. Future work will consider environments with multiple floors and
   crowded regions, planners that directly reason about environment
   dynamics, and local planners that reason about user location
   probabilities within regions.},
Publisher = {IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC},
Address = {445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA},
Type = {Article},
Language = {English},
Affiliation = {Mohamed, SC (Corresponding Author), Univ Toronto, Dept Mech \& Ind Engn, Autonomous Syst \& Biomechatron Lab ASBLab, Toronto, ON M5S 3G8, Canada.
   Mohamed, Sharaf C.; Rajaratnam, Sanjif; Hong, Seung Tae; Nejat, Goldie, Univ Toronto, Dept Mech \& Ind Engn, Autonomous Syst \& Biomechatron Lab ASBLab, Toronto, ON M5S 3G8, Canada.},
DOI = {10.1109/TASE.2019.2928774},
ISSN = {1545-5955},
EISSN = {1558-3783},
Keywords = {Robots; Search problems; Probability density function; Hidden Markov
   models; Task analysis; Surveillance; Human-robot interaction (HRI);
   multiple dynamic users; orienteering problem (OP); search plans; social
   robots},
Keywords-Plus = {MOBILE ROBOT; ORIENTEERING PROBLEM; WILDERNESS SEARCH; SURVEILLANCE;
   LOCALIZATION; EXPLORATION; COLLECTION; STRATEGIES; KNAPSACK; TEAMS},
Research-Areas = {Automation \& Control Systems},
Web-of-Science-Categories  = {Automation \& Control Systems},
Author-Email = {sharaf.mohamed@mail.utoronto.ca
   sanjif.rajaratnam@mail.utoronto.ca
   rio.hong@mail.utoronto.ca
   nejat@mie.utoronto.ca},
Affiliations = {University of Toronto},
Funding-Acknowledgement = {Natural Sciences and Engineering Research Council of Canada (NSERC); Dr.
   Robot Inc.; Ontario Centres of Excellence (OCE); Canadian Consortium on
   Neurodegeneration in Aging (CCNA); Canada Research Chairs (CRC) Program},
Funding-Text = {This work was supported in part by the Natural Sciences and Engineering
   Research Council of Canada (NSERC), in part by Dr. Robot Inc., in part
   by the Ontario Centres of Excellence (OCE), in part by the Canadian
   Consortium on Neurodegeneration in Aging (CCNA), and in part by the
   Canada Research Chairs (CRC) Program.},
Cited-References = {Amos B., 2016, CMU SCH COMPUTER SCI, V6, P1.
   Avci M, 2017, COMPUT IND ENG, V113, P323, DOI 10.1016/j.cie.2017.09.032.
   Basilico N, 2016, SPRINGER TRAC ADV RO, V112, P3, DOI 10.1007/978-4-431-55879-8\_1.
   Bayoumi A, 2019, ROBOT AUTON SYST, V115, P40, DOI 10.1016/j.robot.2019.02.001.
   Beham A, 2015, LECT NOTES COMPUT SC, V9520, P359, DOI 10.1007/978-3-319-27340-2\_45.
   BELLMAN R, 1962, J ACM, V9, P61, DOI 10.1145/321105.321111.
   Bellman R., 1958, Q APPL MATH, V16, P87, DOI {[}10.1090/qam/102435, DOI 10.1090/QAM/102435].
   Bernardini S, 2017, AUTON ROBOT, V41, P181, DOI 10.1007/s10514-015-9534-0.
   Bialek L, 2016, ADV INTELL SYST, V440, P483, DOI 10.1007/978-3-319-29357-8\_43.
   Bolzoni P, 2017, LECT NOTES COMPUT SC, V10411, P24, DOI 10.1007/978-3-319-64367-0\_2.
   Booth KEC, 2016, IEEE ROBOT AUTOM LET, V1, P500, DOI 10.1109/LRA.2016.2522096.
   Bovbel P, 2014, J MED DEVICES, V8, DOI 10.1115/1.4027113.
   Butt SE, 1999, COMPUT OPER RES, V26, P427, DOI 10.1016/S0305-0548(98)00071-9.
   Christofides, 1976, 388 CARNEGIE MELL U.
   Dames P, 2015, IEEE T AUTOM SCI ENG, V12, P850, DOI 10.1109/TASE.2015.2425212.
   Doroodgar B, 2014, IEEE T CYBERNETICS, V44, P2719, DOI 10.1109/TCYB.2014.2314294.
   Douglas DH., 1973, CANADIAN CARTOGRAPHE, V10, P112, DOI {[}10.3138/FM57-6770-U75U-7727, DOI 10.3138/FM57-6770-U75U-7727].
   Durham JW, 2012, AUTON ROBOT, V32, P81, DOI 10.1007/s10514-011-9260-1.
   Elinas P., 2003, AAAI SPRING S HUM IN, P45.
   Erdogan G, 2013, NETWORKS, V61, P104, DOI 10.1002/net.21496.
   FAALAND BH, 1981, OPER RES, V29, P612, DOI 10.1287/opre.29.3.612.
   GOLDEN BL, 1987, NAV RES LOG, V34, P307, DOI 10.1002/1520-6750(198706)34:3<307::AID-NAV3220340302>3.0.CO;2-D.
   Goodrich MA, 2008, J FIELD ROBOT, V25, P89, DOI 10.1002/rob.20226.
   Grisetti G, 2007, IEEE T ROBOT, V23, P34, DOI 10.1109/TRO.2006.889486.
   Hasan MM, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P1, DOI 10.1109/IC3INA.2013.6819138.
   Helsgaun K, 2000, EUR J OPER RES, V126, P106, DOI 10.1016/S0377-2217(99)00284-2.
   Hollinger Geoffrey, 2009, International Journal of Robotics Research, V28, P201, DOI 10.1177/0278364908099853.
   Acevedo JJ, 2013, J INTELL ROBOT SYST, V70, P329, DOI 10.1007/s10846-012-9716-3.
   Keller J, 2017, IEEE T AUTOM SCI ENG, V14, P17, DOI 10.1109/TASE.2016.2623642.
   Kolling A, 2010, IEEE T ROBOT, V26, P32, DOI 10.1109/TRO.2009.2035737.
   Kruskal JB., 1956, AM MATH SOC, V7, P48, DOI {[}10.1090/s0002-9939-1956-0078686-7, 10.1090/S0002-9939-1956-0078686-7].
   Kwon WY, 2016, INT CONF BIG DATA, P505, DOI 10.1109/BIGCOMP.2016.7425980.
   Lau H., 2005, 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3740.
   Lavis B, 2008, AUTON ROBOT, V24, P387, DOI 10.1007/s10514-007-9081-4.
   Li J., 2016, P IEEE INT S ROB INT, P1.
   Lienhart R, 2002, IEEE IMAGE PROC, P900.
   Lin S., 2018, P ASME INT DES ENG T.
   Liu ZY, 2011, INTERNATIONAL CONFERENCE ON ENGINEERING AND BUSINESS MANAGEMENT (EBM2011), VOLS 1-6, P3001.
   Lodree EJ, 2016, SPRINGER P MATH STAT, V185, P159, DOI 10.1007/978-3-319-43709-5\_9.
   Macwan A, 2015, IEEE T CYBERNETICS, V45, P1784, DOI 10.1109/TCYB.2014.2360368.
   Mann M, 2016, J OPTIMIZ THEORY APP, V168, P246, DOI 10.1007/s10957-015-0767-z.
   McColl D, 2013, IEEE ROBOT AUTOM MAG, V20, P74, DOI 10.1109/MRA.2012.2229939.
   Mehdi SA, 2014, UNIVERSAL ACCESS INF, V13, P45, DOI 10.1007/s10209-013-0301-8.
   Mobasher A, 2015, COMPUT IND ENG, V87, P260, DOI 10.1016/j.cie.2015.05.020.
   Mohamed Sharaf C., 2016, P 26 INT C AUT PLANN, P58.
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P587.
   Morin M, 2018, CONSTRAINTS, V23, P335, DOI 10.1007/s10601-018-9288-3.
   Moyle W, 2013, J GERONTOL NURS, V39, P46, DOI 10.3928/00989134-20130313-03.
   Osswald S, 2016, IEEE ROBOT AUTOM LET, V1, P716, DOI 10.1109/LRA.2016.2520560.
   Palomo-Martinez PJ, 2017, COMPUT OPER RES, V78, P408, DOI 10.1016/j.cor.2015.11.007.
   Patel R, 2015, IEEE T AUTOMAT CONTR, V60, P3156, DOI 10.1109/TAC.2015.2426317.
   Rashid M, 2015, 2015 IEEE/ACM FOURTH INTERNATIONAL WORKSHOP ON GREEN AND SUSTAINABLE SOFTWARE (GREENS), P15, DOI 10.1109/GREENS.2015.10.
   Rossi S, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY \& INTERNET-BASED SYSTEMS (SITIS), P455, DOI 10.1109/SITIS.2016.77.
   Santos JM, 2017, ROBOT AUTON SYST, V88, P116, DOI 10.1016/j.robot.2016.11.016.
   Schwenk M, 2014, PROCEEDINGS OF THE TWENTY-EIGHTH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2571.
   Stiffler NM, 2014, IEEE INT CONF ROBOT, P1660, DOI 10.1109/ICRA.2014.6907074.
   Sujit PB, 2011, IEEE T AUTOM SCI ENG, V8, P705, DOI 10.1109/TASE.2011.2155058.
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7.
   Sylejmani K, 2017, INF TECHNOL TOUR, V17, P275, DOI 10.1007/s40558-017-0080-9.
   Thompson C, 2017, 2017 IEEE 5TH INTERNATIONAL SYMPOSIUM ON ROBOTICS AND INTELLIGENT SENSORS (IRIS), P173, DOI 10.1109/IRIS.2017.8250117.
   Thunberg J, 2011, AUTON ROBOT, V31, P333, DOI 10.1007/s10514-011-9247-y.
   Tipaldi GD, 2011, IEEE INT CONF ROBOT, P1217.
   Triebel R, 2016, SPRINGER TRAC ADV RO, V113, P607, DOI 10.1007/978-3-319-27702-8\_40.
   TSILIGIRIDES T, 1984, J OPER RES SOC, V35, P797, DOI 10.1057/jors.1984.162.
   Volkhardt M, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P282, DOI 10.1109/ECMR.2013.6698855.
   Wallar A, 2015, IEEE T AUTOM SCI ENG, V12, P969, DOI 10.1109/TASE.2015.2443033.
   Walters ML, 2005, IEEE-RAS INT C HUMAN, P450.
   Zalama E, 2014, ROBOT2013, P3.
   Zhang CY, 2016, ACM T INFORM SYST, V35, DOI 10.1145/2948065.
   Zheng WM, 2017, TOURISM MANAGE, V62, P335, DOI 10.1016/j.tourman.2017.05.006.},
Number-of-Cited-References = {70},
Times-Cited = {5},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {15},
Journal-ISO = {IEEE Trans. Autom. Sci. Eng.},
Doc-Delivery-Number = {KD1OD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000507640900033},
DA = {2022-05-17},
}

@article{ WOS:000369532100018,
Author = {Laviana, Aaron A. and Ilg, Annette M. and Veruttipong, Darlene and Tan,
   Hung-Jui and Burke, Michael A. and Niedzwiecki, Douglas R. and Kupelian,
   Patrick A. and King, Chris R. and Steinberg, Michael L. and Kundavaram,
   Chandan R. and Kamrava, Mitchell and Kaplan, Alan L. and Moriarity,
   Andrew K. and Hsu, William and Margolis, Daniel J. A. and Hu, Jim C. and
   Saigal, Christopher S.},
Title = {Utilizing time-driven activity-based costing to understand the short-
   and long-term costs of treating localized, low-risk prostate cancer},
Journal = {CANCER},
Year = {2016},
Volume = {122},
Number = {3},
Pages = {447-455},
Month = {FEB 1},
Abstract = {BACKGROUNDGiven the costs of delivering care for men with prostate
   cancer remain poorly described, this article reports the results of
   time-driven activity-based costing (TDABC) for competing treatments of
   low-risk prostate cancer.
   METHODSProcess maps were developed for each phase of care from the
   initial urologic visit through 12 years of follow-up for
   robotic-assisted laparoscopic prostatectomy (RALP), cryotherapy,
   high-dose rate (HDR) and low-dose rate (LDR) brachytherapy,
   intensity-modulated radiation therapy (IMRT), stereotactic body
   radiation therapy (SBRT), and active surveillance (AS). The last
   modality incorporated both traditional transrectal ultrasound (TRUS)
   biopsy and multiparametric-MRI/TRUS fusion biopsy. The costs of
   materials, equipment, personnel, and space were calculated per unit of
   time and based on the relative proportion of capacity used. TDABC for
   each treatment was defined as the sum of its resources.
   RESULTSSubstantial cost variation was observed at 5 years, with costs
   ranging from \$7,298 for AS to \$23,565 for IMRT, and they remained
   consistent through 12 years of follow-up. LDR brachytherapy (\$8,978)
   was notably cheaper than HDR brachytherapy (\$11,448), and SBRT
   (\$11,665) was notably cheaper than IMRT, with the cost savings
   attributable to shorter procedure times and fewer visits required for
   treatment. Both equipment costs and an inpatient stay (\$2,306)
   contributed to the high cost of RALP (\$16,946). Cryotherapy (\$11,215)
   was more costly than LDR brachytherapy, largely because of increased
   single-use equipment costs (\$6,292 vs \$1,921). AS reached cost
   equivalence with LDR brachytherapy after 7 years of follow-up.
   CONCLUSIONSThe use of TDABC is feasible for analyzing cancer services
   and provides insights into cost-reduction tactics in an era focused on
   emphasizing value. By detailing all steps from diagnosis and treatment
   through 12 years of follow-up for low-risk prostate cancer, this study
   has demonstrated significant cost variation between competing
   treatments. Cancer 2016;122:447-455. (c) 2015 American Cancer Society.},
Publisher = {WILEY},
Address = {111 RIVER ST, HOBOKEN 07030-5774, NJ USA},
Type = {Article},
Language = {English},
Affiliation = {Laviana, AA (Corresponding Author), Univ Calif Los Angeles, David Geffen Sch Med, Dept Urol, Inst Urol Oncol, 300 Stein Plaza,3rd Floor, Los Angeles, CA 90095 USA.
   Laviana, Aaron A.; Ilg, Annette M.; Tan, Hung-Jui; Kundavaram, Chandan R.; Kaplan, Alan L.; Saigal, Christopher S., Univ Calif Los Angeles, David Geffen Sch Med, Dept Urol, Inst Urol Oncol, 300 Stein Plaza,3rd Floor, Los Angeles, CA 90095 USA.
   Veruttipong, Darlene; Kupelian, Patrick A.; King, Chris R.; Steinberg, Michael L.; Kamrava, Mitchell, Univ Calif Los Angeles, David Geffen Sch Med, Dept Radiat Oncol, Los Angeles, CA 90095 USA.
   Tan, Hung-Jui, Univ Calif Los Angeles, Robert Wood Johnson Clin Scholars Program, Los Angeles, CA 90095 USA.
   Burke, Michael A., Univ Calif Los Angeles Hlth Syst, Performance Excellence, Los Angeles, CA USA.
   Niedzwiecki, Douglas R., Univ Calif Los Angeles Hlth Syst, Operat Serv, Los Angeles, CA USA.
   Moriarity, Andrew K.; Hsu, William; Margolis, Daniel J. A., Univ Calif Los Angeles, David Geffen Sch Med, Dept Radiol, Los Angeles, CA 90095 USA.
   Hu, Jim C., NewYork Presbyterian Hosp, Weill Cornell Med Coll, Dept Urol, New York, NY USA.},
DOI = {10.1002/cncr.29743},
ISSN = {0008-543X},
EISSN = {1097-0142},
Keywords = {active surveillance; brachytherapy; cost analysis; prostate neoplasms;
   radical prostatectomy; radiotherapy; value-based purchasing},
Keywords-Plus = {RADICAL PROSTATECTOMY; ULTRASOUND FUSION; SURGERY; HEALTH; CARE; BIOPSY;
   ASSOCIATION; MANAGEMENT; SURVIVAL; OUTCOMES},
Research-Areas = {Oncology},
Web-of-Science-Categories  = {Oncology},
Author-Email = {alaviana@mednet.ucla.edu},
Affiliations = {David Geffen School of Medicine at UCLA; University of California
   System; University of California Los Angeles; David Geffen School of
   Medicine at UCLA; University of California System; University of
   California Los Angeles; University of California System; University of
   California Los Angeles; University of California System; University of
   California Los Angeles; University of California System; University of
   California Los Angeles; David Geffen School of Medicine at UCLA;
   University of California System; University of California Los Angeles;
   Cornell University; NewYork-Presbyterian Hospital},
ResearcherID-Numbers = {Kupelian, Patrick/AAU-6311-2021
   Hsu, William/AAA-1935-2021},
ORCID-Numbers = {Hsu, William/0000-0002-5168-070X},
Funding-Acknowledgement = {H\&H Lee Surgical Research Scholars Program; Veterans Affairs Office of
   Academic Affiliations through the Robert Wood Johnson Clinical Scholars
   Program},
Funding-Text = {Research and salary support was provided by funding from the H\&H Lee
   Surgical Research Scholars Program (to Aaron A. Laviana) and the
   Veterans Affairs Office of Academic Affiliations through the Robert Wood
   Johnson Clinical Scholars Program (to Hung-Jui Tan).},
Cited-References = {Bastian PJ, 2012, EUR UROL, V61, P1096, DOI 10.1016/j.eururo.2012.02.031.
   Bokhorst LP, EUR UROL IN PRESS.
   Bolenz C, 2010, EUR UROL, V57, P453, DOI 10.1016/j.eururo.2009.11.008.
   Carter SC, 2014, BJU INT, V113, pE112, DOI 10.1111/bju.12451.
   Centers for Medicare and Medicaid Services, OUTP CHARG DAT CY 20.
   Cooperberg MR, 2010, CANCER-AM CANCER SOC, V116, P5226, DOI 10.1002/cncr.25456.
   Cooperberg MR, 2010, J CLIN ONCOL, V28, P1117, DOI 10.1200/JCO.2009.26.0133.
   Daskivich TJ, 2013, ANN INTERN MED, V158, P709, DOI 10.7326/0003-4819-158-10-201305210-00005.
   de Rooij M, 2014, EUR UROL, V66, P430, DOI 10.1016/j.eururo.2013.12.012.
   Etzioni R, 2012, CANCER-AM CANCER SOC, V118, P5955, DOI 10.1002/cncr.27594.
   Kaplan AL, 2015, HEALTHCARE-J DEL SCI, V3, P43, DOI 10.1016/j.hjdsi.2014.09.007.
   Kaplan Robert S, 2014, Healthc Financ Manage, V68, P76.
   Kaplan RS, 2011, HARVARD BUS REV, V89, P46.
   Kaplan RS, 2004, HARVARD BUS REV, V82, P131, DOI 10.2139/ssrn.485443.
   Lau HK, 2010, J CLIN ANESTH, V22, P237, DOI 10.1016/j.jclinane.2009.10.005.
   Lotan Y, 2013, EUR UROL, V64, P17, DOI 10.1016/j.eururo.2012.09.026.
   Mariotto AB, 2011, JNCI-J NATL CANCER I, V103, P117, DOI 10.1093/jnci/djq495.
   Marks L, 2013, CURR OPIN UROL, V23, P43, DOI 10.1097/MOU.0b013e32835ad3ee.
   Martinez AA, 2010, AM J CLIN ONCOL-CANC, V33, P481, DOI 10.1097/COC.0b013e3181b9cd2f.
   McLaughlin N, 2014, NEUROSURG FOCUS, V37, DOI 10.3171/2014.8.FOCUS14381.
   McLaughlin N, 2014, J NEUROSURG, V121, P700, DOI 10.3171/2014.5.JNS131996.
   Mouraviev V, 2007, UROLOGY, V69, P311, DOI 10.1016/j.urology.2006.10.025.
   Musunuru HB, 2015, J CLIN ONCOL, V33, DOI 10.1200/jco.2015.33.7\_suppl.163.
   Neuner JM, 2012, CANCER-AM CANCER SOC, V118, P371, DOI 10.1002/cncr.26271.
   O'Leary MP, 2002, J UROLOGY, V168, P649, DOI 10.1016/S0022-5347(05)64706-4.
   Park KW, 2009, CURR OPIN ANESTHESIO, V22, P242, DOI 10.1097/ACO.0b013e32832798ef.
   Pate SC, 2014, UROLOGY, V83, P626, DOI 10.1016/j.urology.2013.09.066.
   Pinto PA, 2011, J UROLOGY, V186, P1281, DOI 10.1016/j.juro.2011.05.078.
   Porter ME, 2013, HARVARD BUS REV, V91, P1.
   Porter ME, 2010, NEW ENGL J MED, V363, P2477, DOI 10.1056/NEJMp1011024.
   Procter LD, 2010, J AM COLL SURGEONS, V210, P60, DOI 10.1016/j.jamcollsurg.2009.09.034.
   Russell LB, 2009, MED CARE, V47, pS89, DOI 10.1097/MLR.0b013e31819bc077.
   Shah C, 2012, BRACHYTHERAPY, V11, P441, DOI 10.1016/j.brachy.2012.04.002.
   Shappley WV, 2009, J CLIN ONCOL, V27, P4980, DOI 10.1200/JCO.2008.21.2613.
   Sher DJ, 2014, AM J CLIN ONCOL-CANC, V37, P215, DOI 10.1097/COC.0b013e31827a7d2a.
   Siegel R, 2012, CA-CANCER J CLIN, V62, P10, DOI 10.3322/caac.20138.
   Sonn GA, 2014, EUR UROL, V65, P809, DOI 10.1016/j.eururo.2013.03.025.
   Stout D. E., 2011, MANAGEMENT ACCOUNTIN, V12, P1.
   Thompson I, 2007, J UROLOGY, V177, P2106, DOI 10.1016/j.juro.2007.03.003.
   Ubel PA, 2015, HEALTH AFFAIR, V34, P239, DOI 10.1377/hlthaff.2014.0983.
   Waago-Hansen C., 2014, THEHEALTH, V5, P3.
   Wilt TJ, 2012, NEW ENGL J MED, V367, P203, DOI 10.1056/NEJMoa1113162.
   Yu HY, 2012, J UROLOGY, V187, P1392, DOI 10.1016/j.juro.2011.11.089.
   Yu JB, 2014, J CLIN ONCOL, V32, P1195, DOI 10.1200/JCO.2013.53.8652.},
Number-of-Cited-References = {44},
Times-Cited = {99},
Usage-Count-Last-180-days = {2},
Usage-Count-Since-2013 = {44},
Journal-ISO = {Cancer},
Doc-Delivery-Number = {DC9HN},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)},
Unique-ID = {WOS:000369532100018},
OA = {Bronze},
DA = {2022-05-17},
}

@article{ WOS:000561793900063,
Author = {Perkins, Nicholas R. and Hosack, Geoffrey R. and Foster, Scott D. and
   Monk, Jacquomo and Barrett, Neville S.},
Title = {Monitoring the resilience of a no-take marine reserve to a range
   extending species using benthic imagery},
Pages = {e0237257},
Journal = {PLOS ONE},
Year = {2020},
Volume = {15},
Number = {8},
Month = {AUG 12},
Abstract = {Global climate change is driving the redistribution of marine species
   and thereby potentially restructuring endemic communities. Understanding
   how localised conservation measures such as protection from additional
   human pressures can confer resilience to ecosystems is therefore an
   important area of research. Here, we examine the resilience of a no-take
   marine reserve (NTR) to the establishment of urchin barrens habitat. The
   barrens habitat is created through overgrazing of kelp by an invading
   urchin species that is expanding its range within a hotspot of rapid
   climate change. In our study region, a multi-year monitoring program
   provides a unique time-series of benthic imagery collected by an
   Autonomous Underwater Vehicle (AUV) within an NTR and nearby reference
   areas. We use a Bayesian hierarchical spatio-temporal modelling approach
   to estimate whether the NTR is associated with reduced formation of
   urchin barrens, and thereby enhances local resilience. Our approach
   controls for the important environmental covariates of depth and habitat
   complexity (quantified as rugosity derived from multibeam sonar
   mapping), as well as spatial and temporal dependence. We find evidence
   for the NTR conferring resilience with a strong reserve effect that
   suggests improved resistance to the establishment of barrens. However,
   we find a concerning and consistent trajectory of increasing barrens
   cover in both the reference areas and the NTR, with the odds of barrens
   increasing by approximately 32\% per year. Thus, whereas the reserve is
   demonstrating resilience to the initial establishment of barrens, there
   is currently no evidence of recovery once barrens are established. We
   also find that depth and rugosity covariates derived from multibeam
   mapping provide useful predictors for barrens occurrence. These results
   have important management implications as they demonstrate: (i) the
   importance of monitoring programs to inform adaptive management; (ii)
   that NTRs provide a potential local conservation management tool under
   climate change impacts, and (iii) that technologies such as AUVs and
   multibeam mapping can be harnessed to inform regional decision-making.
   Continuation of the current monitoring program is required to assess
   whether the NTR can provide long term protection from a phase shift that
   replaces kelp with urchin barrens.},
Publisher = {PUBLIC LIBRARY SCIENCE},
Address = {1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA},
Type = {Article},
Language = {English},
Affiliation = {Perkins, NR (Corresponding Author), Inst Marine \& Antarctic Studies, Hobart, Tas, Australia.
   Perkins, Nicholas R.; Monk, Jacquomo; Barrett, Neville S., Inst Marine \& Antarctic Studies, Hobart, Tas, Australia.
   Hosack, Geoffrey R.; Foster, Scott D., CSIRO, Data 61, Hobart, Tas, Australia.},
DOI = {10.1371/journal.pone.0237257},
Article-Number = {e0237257},
ISSN = {1932-6203},
Keywords-Plus = {SPATIAL AUTOCORRELATION; PROTECTED AREAS; CLIMATE-CHANGE; REEF},
Research-Areas = {Science \& Technology - Other Topics},
Web-of-Science-Categories  = {Multidisciplinary Sciences},
Author-Email = {nicholas.perkins@utas.edu.au},
Affiliations = {University of Tasmania; Commonwealth Scientific \& Industrial Research
   Organisation (CSIRO)},
ResearcherID-Numbers = {Hosack, Geoffrey R/E-8566-2010
   Foster, Scott/E-9311-2010
   },
ORCID-Numbers = {Hosack, Geoffrey R/0000-0002-6462-6817
   Foster, Scott/0000-0002-6719-8002
   Perkins, Nicholas/0000-0002-1328-2321},
Funding-Acknowledgement = {Marine Biodiversity Hub through the Australian Government's National
   Environmental Science Program (NESP); University of Tasmania; CSIRO;
   Geoscience Australia; Australian Institute of Marine Science; Museum
   Victoria; Charles Darwin University; University of Western Australia;
   Integrated Marine Observing System; NSW Office of Environment and
   Heritage; NSW Department of Primary Industries},
Funding-Text = {This work was supported by the Marine Biodiversity Hub through funding
   from the Australian Government's National Environmental Science Program
   (NESP). The NESP Marine Biodiversity Hub partners include the University
   of Tasmania; CSIRO, Geoscience Australia, Australian Institute of Marine
   Science, Museum Victoria, Charles Darwin University, The University of
   Western Australia, Integrated Marine Observing System, NSW Office of
   Environment and Heritage, and NSW Department of Primary Industries. The
   funders had no role in study design, data collection and analysis,
   decision to publish, or preparation of the manuscript.},
Cited-References = {Barrett N, 2009, MAR FRESHWATER RES, V60, P417, DOI 10.1071/MF07154.
   Barrett NS, 2009, J EXP MAR BIOL ECOL, V370, P104, DOI 10.1016/j.jembe.2008.12.005.
   Bates AE, 2019, BIOL CONSERV, V236, P305, DOI 10.1016/j.biocon.2019.05.005.
   Bates AE, 2017, P ROY SOC B-BIOL SCI, V284, DOI 10.1098/rspb.2017.0484.
   Bates AE, 2014, NAT CLIM CHANGE, V4, P62, DOI 10.1038/NCLIMATE2062.
   Bulleri F, 2009, OIKOS, V118, P269, DOI 10.1111/j.1600-0706.2008.16955.x.
   Buxton C, 2006, 1999162 FRDC TASM AC.
   Byrnes JE, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0000295.
   Carpenter S, 2001, ECOSYSTEMS, V4, P765, DOI 10.1007/s10021-001-0045-9.
   Dormann CF, 2007, GLOBAL ECOL BIOGEOGR, V16, P129, DOI 10.1111/j.1466-8238.2006.00279.x.
   Dunstan PK, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33057-y.
   Durden JM, 2016, OCEANOGR MAR BIOL, V54, P1.
   Edgar GJ, 1999, J EXP MAR BIOL ECOL, V242, P107, DOI 10.1016/S0022-0981(99)00098-2.
   Flukes EB, 2012, MAR ECOL PROG SER, V464, P179, DOI 10.3354/meps09881.
   Hayes KR, 2019, FRONTIERS MARINE SCI, V6.
   Hill NA, 2014, ESTUAR COAST SHELF S, V147, P137, DOI 10.1016/j.ecss.2014.05.019.
   Hodgson D, 2015, TRENDS ECOL EVOL, V30, P503, DOI 10.1016/j.tree.2015.06.010.
   Holling C.S., 1973, Annual Rev Ecol Syst, V4, P1, DOI 10.1146/annurev.es.04.110173.000245.
   Johnson C., 2005, ESTABLISHMENT LONG S.
   LEGENDRE P, 1993, ECOLOGY, V74, P1659, DOI 10.2307/1939924.
   Lindgren F, 2011, J R STAT SOC B, V73, P423, DOI 10.1111/j.1467-9868.2011.00777.x.
   Ling SD, 2008, OECOLOGIA, V156, P883, DOI 10.1007/s00442-008-1043-9.
   Ling SD, 2012, ECOL APPL, V22, P1232, DOI 10.1890/11-1587.1.
   Ling SD, 2009, P NATL ACAD SCI USA, V106, P22341, DOI 10.1073/pnas.0907529106.
   Ling S.D., 2018, RESURVEY LONGSPINED.
   Mellin C, 2016, ECOL LETT, V19, P629, DOI 10.1111/ele.12598.
   Nichol SL, 2009, 2009 SE TASMANIA TEM.
   Perkins N.R., 2018, AQUA CONS MAR FRESHW, V29, P59.
   Perkins NR, 2015, ESTUAR COAST SHELF S, V155, P56, DOI 10.1016/j.ecss.2015.01.014.
   Perry AL, 2005, SCIENCE, V308, P1912, DOI 10.1126/science.1111322.
   Pizarro O, 2013, IEEE UNDERWATER TECH.
   Poloczanska ES, 2013, NAT CLIM CHANGE, V3, P919, DOI {[}10.1038/NCLIMATE1958, 10.1038/nclimate1958].
   R Core Team, 2017, R LANG ENV STAT COMP.
   RIDGEWAY KR, 2007, GEOPHYS RES LETT, V34.
   Robinson LM, 2015, GLOBAL ENVIRON CHANG, V31, P28, DOI 10.1016/j.gloenvcha.2014.12.003.
   Rue H, 2009, J R STAT SOC B, V71, P319, DOI 10.1111/j.1467-9868.2008.00700.x.
   Strain EMA, 2019, DIVERS DISTRIB, V25, P9, DOI 10.1111/ddi.12838.
   Vanhatalo J, 2017, J APPL ECOL, V54, P188, DOI 10.1111/1365-2664.12710.
   Worm B, 2006, SCIENCE, V314, P787, DOI 10.1126/science.1132294.
   Yamazaki, 2019, CENTROSTEPHANUS SUBS.},
Number-of-Cited-References = {40},
Times-Cited = {3},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {6},
Journal-ISO = {PLoS One},
Doc-Delivery-Number = {ND3HD},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000561793900063},
OA = {Green Published, Green Accepted, gold, Green Submitted},
DA = {2022-05-17},
}

@article{ WOS:000263729300002,
Author = {Hayman, Nicholas W. and Karson, Jeffrey A.},
Title = {Crustal faults exposed in the Pito Deep Rift: Conduits for hydrothermal
   fluids on the southeast Pacific Rise},
Journal = {GEOCHEMISTRY GEOPHYSICS GEOSYSTEMS},
Year = {2009},
Volume = {10},
Pages = {Q02013},
Month = {FEB 25},
Abstract = {The escarpments that bound the Pito Deep Rift (northeastern Easter
   microplate) expose in situ upper oceanic crust that was accreted similar
   to 3 Ma ago at the superfast spreading (similar to 142 mm/a, full rate)
   southeast Pacific Rise (SEPR). Samples and images of these escarpments
   were taken during transects utilizing the human-occupied vehicle Alvin
   and remotely operated vehicle Jason II. The dive areas were mapped with
   a ``deformation intensity scale'' revealing that the sheeted dike
   complex and the base of the lavas contain approximately meter-wide fault
   zones surrounded by fractured ``damage zones.'' Fault zones are spaced
   several hundred meters apart, in places offset the base of the lavas,
   separate areas with differently oriented dikes, and are locally crosscut
   by (younger) dikes. Fault rocks are rich in interstitial amphibole,
   matrix and vein chlorite, prominent veins of quartz, and accessory
   grains of sulfides, oxides, and sphene. These phases form the
   fine-grained matrix materials for cataclasites and cements for breccias
   where they completely surround angular to subangular clasts of variably
   altered and deformed basalt. Bulk rock geochemical compositions of the
   fault rocks are largely governed by the abundance of quartz veins. When
   compositions are normalized to compensate for the excess silica, the
   fault rocks exhibit evidence for additional geochemical changes via
   hydrothermal alteration, including the loss of mobile elements and gain
   of some trace metals and magnesium. Microstructures and compositions
   suggest that the fault rocks developed over multiple increments of
   deformation and hydrothermal fluid flow in the subaxial environment of
   the SEPR; faults related to the opening of the Pito Deep Rift can be
   distinguished by their orientation and fault rock microstructure. Some
   subaxial deformation increments were likely linked with violent
   discharge events associated with fluid pressure fluctuations and mineral
   sealing within the fault zones. Other increments were linked with the
   influx of relatively fresh seawater. The spacing of the faults is
   consistent with fault localization occurring every 7000 to 14,000 years,
   with long-term slip rates of <3 mm/a. Once spread from the ridge axis,
   the faults were probably not active, and damage zones likely played a
   more significant role in axial flank and off-axis crustal permeability.},
Publisher = {AMER GEOPHYSICAL UNION},
Address = {2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA},
Type = {Article},
Language = {English},
Affiliation = {Hayman, NW (Corresponding Author), Univ Texas Austin, Jackson Sch Geosci, Inst Geophys, Austin, TX 78758 USA.
   Hayman, Nicholas W., Univ Texas Austin, Jackson Sch Geosci, Inst Geophys, Austin, TX 78758 USA.
   Karson, Jeffrey A., Syracuse Univ, Dept Earth Sci, Syracuse, NY 13244 USA.},
DOI = {10.1029/2008GC002319},
Article-Number = {Q02013},
EISSN = {1525-2027},
Keywords = {mid-ocean ridge; East Pacific Rise; faults; hydrothermal; Pito Deep;
   tectonic window},
Keywords-Plus = {MID-ATLANTIC RIDGE; OCEANIC-CRUST; SEA-FLOOR; PERMEABILITY; ACCRETION;
   TRANSFORM; CHEMISTRY; TRANSPORT; SYSTEMS; ZONES},
Research-Areas = {Geochemistry \& Geophysics},
Web-of-Science-Categories  = {Geochemistry \& Geophysics},
Author-Email = {hayman@ig.utexas.edu},
Affiliations = {University of Texas System; University of Texas Austin; Syracuse
   University},
ResearcherID-Numbers = {Hayman, Nicholas/A-1589-2009
   },
ORCID-Numbers = {Hayman, Nicholas/0000-0001-6743-045X},
Funding-Acknowledgement = {NSFOCE {[}0222154]; School of Geosciences and the Geology Foundation at
   the University of Texas at Austin},
Funding-Text = {We thank the officers and crew of R/V Atlantis, and the WHOI Jason II
   and Alvin pilots and technical staff, and the Pito Deep Scientific
   Party. This work benefited from the ongoing communication with Kerri
   Heft, Abigail Barker, Laurence Coogan, Kathy Gillis, Emily Klein, Meagen
   Pollock, and Lindsay Chutas. We also thank Gretchen Fruh-Green and an
   anonymous reviewer. This work was supported by NSFOCE 0222154 (to
   J.A.K.). Support for this work was provided in part by the John A. and
   Katherine G. Jackson School of Geosciences and the Geology Foundation at
   the University of Texas at Austin. University of Texas Institute for
   Geophysics contribution 2056.},
Cited-References = {Ague JJ, 2003, AM J SCI, V303, P753, DOI 10.2475/ajs.303.9.753.
   Alt J.C., 1996, PROC OCEAN DRILL SCI, P417.
   Barker AK, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2007GC001901.
   BARKER AK, 2007, EOS T AGU S, V88.
   Behn MD, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2008GC001965.
   BICKLE MJ, 1992, EARTH PLANET SC LETT, V113, P219, DOI 10.1016/0012-821X(92)90221-G.
   Bohnenstiehl DR, 2001, GEOCHEM GEOPHY GEOSY, V2, part. no..
   Buck WR, 2005, NATURE, V434, P719, DOI 10.1038/nature03358.
   CANALES J, 2008, EOS T AGU S, V89.
   Carbotte SM, 2003, GEOCHEM GEOPHY GEOSY, V4, DOI 10.1029/2002GC000337.
   CARBOTTE SM, 1994, EARTH PLANET SC LETT, V128, P85, DOI 10.1016/0012-821X(94)90137-6.
   CHUTAS L, 2007, THESIS DUKE U DURHAM.
   Coogan LA, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2007GC001787.
   Coumou D, 2008, SCIENCE, V321, P1825, DOI 10.1126/science.1159582.
   DELANEY JR, 1987, J GEOPHYS RES-SOLID, V92, P9175, DOI 10.1029/JB092iB09p09175.
   Dick HJB, 2000, EARTH PLANET SC LETT, V179, P31, DOI 10.1016/S0012-821X(00)00102-3.
   Escartin J, 2007, GEOCHEM GEOPHY GEOSY, V8, DOI 10.1029/2006GC001399.
   Fisher AT, 2000, NATURE, V403, P71, DOI 10.1038/47463.
   Fisher AT, 1998, REV GEOPHYS, V36, P143, DOI 10.1029/97RG02916.
   Fontaine FJ, 2007, GEOCHEM GEOPHY GEOSY, V8, DOI 10.1029/2007GC001601.
   Gillis KM, 2001, J GEOPHYS RES-SOL EA, V106, P26311, DOI 10.1029/2000JB000038.
   GODDARD JV, 1995, J STRUCT GEOL, V17, P533, DOI 10.1016/0191-8141(94)00068-B.
   GRANT JA, 1986, ECON GEOL, V81, P1976, DOI 10.2113/gsecongeo.81.8.1976.
   Gresens R.L., 1967, CHEM GEOL, V2, P47, DOI {[}DOI 10.1016/0009-2541(67)90004-6, 10.1016/0 0 09-2541(67) 90 0 04-6].
   Hayman NW, 2007, GEOCHEM GEOPHY GEOSY, V8, DOI 10.1029/2007GC001623.
   Hayman NW, 2006, J STRUCT GEOL, V28, P1767, DOI 10.1016/j.jsg.2006.06.017.
   Haymon RM, 2005, GEOLOGY, V33, P153, DOI 10.1130/G21058.1.
   HAYMON RM, 1991, EARTH PLANET SC LETT, V104, P513, DOI 10.1016/0012-821X(91)90226-8.
   Heft KL, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2007GC001926.
   HEY RN, 1995, NATURE, V378, P167, DOI 10.1038/378167a0.
   Hey RN, 2002, MAR GEOPHYS RES, V23, P1, DOI 10.1023/A:1021257915420.
   Hirose T, 2008, J STRUCT GEOL, V30, P1060, DOI 10.1016/j.jsg.2008.04.009.
   Ito G, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2008GC001970.
   Karson FA, 2002, ANNU REV EARTH PL SC, V30, P347, DOI 10.1146/annurev.earth.30.091201.141132.
   Karson J.A, 2005, INTERRIDGE NEWS, V14, P5.
   Karson JA, 2002, GEOCHEM GEOPHY GEOSY, V3, DOI 10.1029/2001GC000155.
   Karson JA, 2002, J GEOPHYS RES-SOL EA, V107, DOI 10.1029/2000JB000051.
   KENT GM, 1994, J GEOPHYS RES-SOL EA, V99, P9097, DOI 10.1029/93JB02872.
   Macdonald KC, 1996, NATURE, V380, P125, DOI 10.1038/380125a0.
   MOTTL MJ, 1983, GEOL SOC AM BULL, V94, P161, DOI 10.1130/0016-7606(1983)94<161:MAHSAT>2.0.CO;2.
   Perk NW, 2007, CONTRIB MINERAL PETR, V154, P575, DOI 10.1007/s00410-007-0210-z.
   POCKALNY RA, 2004, EOS T AGU S, V85.
   Pollock MA, 2009, J GEOPHYS RES-SOL EA, V114, DOI 10.1029/2007JB005436.
   SACCOCIA PJ, 1995, EARTH PLANET SC LETT, V136, P1, DOI 10.1016/0012-821X(95)00155-5.
   SACCOCIA PJ, 1994, GEOCHIM COSMOCHIM AC, V58, P567, DOI 10.1016/0016-7037(94)90489-8.
   {*}SCI PART, 1993, P OCEAN DRILL PROGRA, V147, P15.
   SEYFRIED WE, 1991, GEOCHIM COSMOCHIM AC, V55, P3559, DOI 10.1016/0016-7037(91)90056-B.
   SIBSON RH, 1990, GEOL SOC SPEC PUBL, V54, P15, DOI 10.1144/GSL.SP.1990.054.01.02.
   STRENS MR, 1982, GEOPHYS J ROY ASTR S, V71, P225, DOI 10.1111/j.1365-246X.1982.tb04995.x.
   Tominaga M, 2009, GEOCHEM GEOPHY GEOSY, V10, DOI 10.1029/2008GC002143.
   Varga RJ, 2004, J GEOPHYS RES-SOL EA, V109, DOI 10.1029/2003JB002486.
   Varga RJ, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2008GC002075.
   VONDAMM KL, 1990, ANNU REV EARTH PL SC, V18, P173, DOI 10.1146/annurev.ea.18.050190.001133.
   WELLS JT, 1991, GEOCHIM COSMOCHIM AC, V55, P2467, DOI 10.1016/0016-7037(91)90366-D.
   Wilcock WSD, 2004, GEOCHEM GEOPHY GEOSY, V5, DOI 10.1029/2004GC000701.
   Wilson DS, 2006, SCIENCE, V312, P1016, DOI 10.1126/science.1126090.},
Number-of-Cited-References = {56},
Times-Cited = {12},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {12},
Journal-ISO = {Geochem. Geophys. Geosyst.},
Doc-Delivery-Number = {412MQ},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000263729300002},
OA = {Bronze},
DA = {2022-05-17},
}

@article{ WOS:000225775400005,
Author = {Ramos, AJ and Rubio, MD and Defagot, C and Hischberg, L and Villar, MJ
   and Brusco, A},
Title = {The 5HT(1A) receptor agonist, 8-OH-DPAT, protects neurons and reduces
   astroglial reaction after ischemic damage caused by cortical
   devascularization},
Journal = {BRAIN RESEARCH},
Year = {2004},
Volume = {1030},
Number = {2},
Pages = {201-220},
Month = {DEC 31},
Abstract = {Serotonin 1A (5HT(1A)) receptor agonists have shown neuroprotective
   properties in different models of central nervous system injury.
   Activation of neuronal 5HT(1A) receptors appears to be involved in the
   neuroprotective effects. It remains to be elucidated if astroglial cells
   are responsive to the 5HT(1A) neuroprotective effects. The participation
   of astroglial S100B trophic factor has been proposed since 5HT(1A)
   activation leads to S100B release and nanomolar concentration level of
   this molecule showed pro-survival activity in neuronal cultures. Using
   the cortical devascularization model (CD; unilateral pial disruption), a
   procedure that results in localized ischemia without producing direct
   physical damage to brain tissue, we tested the effects of a full 511TIA
   agonist, 8-OH-DPAT, or the antagonist WAY-100635 on cortical neuronal
   survival, astroglial cell response and S 10013 expression. Wistar rats
   were subjected to CD lesion which consisted of a craniotomy followed by
   physical damage to the underlying pial blood vessels. Two and
   twenty-four hours after the CD lesion, animals received
   intraperitoneally 8-OH-DPAT (1 mg/kg), WAY-100635 (1 mg/kg) or vehicle
   (sterile saline). At 3, 7 or 14 days post-lesion, animals were
   sacrificed and their brains processed for immunohistochemistry to detect
   GFAP, vimentin, MAP-2, S100B and nuclear Hoechst staining. S100B level
   in the brain cortex and serum was quantified by an ELISA assay. Serum
   S100B was considered an index of S100B release. 8-OH-DPAT treatment
   reduced neuronal death, dendrite loss, astroglial hypertrophy and
   hyperplasia. In contrast, WAY-100635 treatment increased these
   parameters of damage. S100B intracellular immunoreactivity in astrocytes
   and total S100B level showed long-lasting changes after the CD lesion
   and subsequent treatments depending on the 5HT(1A) activity. The level
   of serum S100B was increased in 8-OH-DPAT-treated animals. Increased
   damage observed in WAY-100635-treated animals supports the hypothesis
   that the protective 8-OH-DPAT action may be mediated by specific 5HT(1A)
   receptors. The reduction in astroglial hypertrophy and hyperplasia as
   well as long-term changes in S100B immunoreactivity and increased S100B
   release that we observed allows us to hypothesize that astroglial cells
   may play an important role in 5HT(1A)-mediated neuroprotection. (C) 2004
   Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER SCIENCE BV},
Address = {PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Ramos, AJ (Corresponding Author), Montreal Neurol Inst, Ctr Neuronal Survival, 3801 Univ St Room MP038, Montreal, PQ H3A 2B4, Canada.
   Univ Buenos Aires, Fac Med, Inst Biol Celular \& Neurociencia, RA-1121 Buenos Aires, DF, Argentina.
   Univ Austral, Fac Ciencias Biomed, Buenos Aires, DF, Argentina.
   Sangtec Med AB, S-16102 Bromma, Sweden.},
DOI = {10.1016/j.brainres.2004.10.019},
ISSN = {0006-8993},
EISSN = {1872-6240},
Keywords = {ischemia; cortical devascularization; 5HT(1A) receptor; 8-OH-DPAT;
   S100B; astrocyte},
Keywords-Plus = {BAY X 3702; TRANSIENT FOREBRAIN ISCHEMIA; FIBRILLARY ACIDIC PROTEIN;
   GLOBAL CEREBRAL-ISCHEMIA; FIBROBLAST-GROWTH-FACTOR; TRAUMATIC BRAIN
   INJURY; SEVERE HEAD-INJURY; 5-HT1A RECEPTOR; NUCLEUS BASALIS;
   CHOLINERGIC NEURONS},
Research-Areas = {Neurosciences \& Neurology},
Web-of-Science-Categories  = {Neurosciences},
Author-Email = {alberto.ramos@mcgill.ca},
Affiliations = {University of Buenos Aires; Austral University},
ResearcherID-Numbers = {Ramos, Alberto Javier/AAR-7796-2020},
ORCID-Numbers = {Ramos, Alberto Javier/0000-0003-4009-6337},
Cited-References = {Adayev T, 2003, BBA-MOL CELL RES, V1640, P85, DOI 10.1016/S0167-4889(03)00023-5.
   Ahlemeyer B, 2000, BRAIN RES, V858, P121, DOI 10.1016/S0006-8993(99)02438-5.
   Ahlemeyer B, 1999, EUR J PHARMACOL, V370, P211, DOI 10.1016/S0014-2999(99)00136-3.
   Ahlemeyer B, 1997, BRAIN RES, V777, P179.
   Alessandri B, 1999, BRAIN RES, V845, P232, DOI 10.1016/S0006-8993(99)01948-4.
   Azmitia EC, 1996, NEUROPSYCHOPHARMACOL, V14, P35, DOI 10.1016/S0893-133X(96)80057-1.
   AZMITIA EC, 1995, BRAIN RES, V677, P181, DOI 10.1016/0006-8993(95)00051-Q.
   Azmitia EC, 2001, BRAIN RES BULL, V56, P413, DOI 10.1016/S0361-9230(01)00614-1.
   BARGER SW, 1995, BRAIN RES, V677, P167, DOI 10.1016/0006-8993(95)00160-R.
   Brewton LS, 2001, BRAIN RES, V912, P9, DOI 10.1016/S0006-8993(01)02519-7.
   Buttner T, 1997, STROKE, V28, P1961, DOI 10.1161/01.STR.28.10.1961.
   Conner JM, 1998, NEUROSCIENCE, V83, P1003, DOI 10.1016/S0306-4522(97)00449-1.
   Davey GE, 2001, J BIOL CHEM, V276, P30819, DOI 10.1074/jbc.M103541200.
   De Vry J, 1998, J PHARMACOL EXP THER, V284, P1082.
   Deumens R, 2004, NEUROSCIENCE, V125, P591, DOI 10.1016/j.neuroscience.2004.02.010.
   Doetsch F, 2003, NAT NEUROSCI, V6, P1127, DOI 10.1038/nn1144.
   Donato R, 2003, MICROSC RES TECHNIQ, V60, P540, DOI 10.1002/jemt.10296.
   Douglas R. J., 1998, SYNAPTIC ORG BRAIN, P459.
   Elting JW, 2000, J NEUROL SCI, V181, P104, DOI 10.1016/S0022-510X(00)00442-1.
   Eriksen JL, 2002, DEV BRAIN RES, V139, P97, DOI 10.1016/S0165-3806(02)00510-2.
   Eriksen JL, 2001, DEV BRAIN RES, V128, P157, DOI 10.1016/S0165-3806(01)00172-9.
   Evrard SG, 2003, DEV BRAIN RES, V147, P119, DOI 10.1016/j.devbrainres.2003.09.004.
   FAGES C, 1994, BRAIN RES, V639, P161, DOI 10.1016/0006-8993(94)91777-9.
   FIGUEIREDO BC, 1995, MOL BRAIN RES, V33, P1, DOI 10.1016/0169-328X(95)00099-E.
   FIGUEIREDO BC, 1993, NEUROSCIENCE, V56, P955.
   Ganat Y, 2002, NEUROSCIENCE, V112, P977, DOI 10.1016/S0306-4522(02)00060-X.
   Glass JD, 1999, NEUROSCIENCE, V94, P1253, DOI 10.1016/S0306-4522(99)00369-3.
   HARING JH, 1993, BRAIN RES, V631, P119, DOI 10.1016/0006-8993(93)91195-X.
   HERRERA DG, 1989, BRAIN RES, V503, P205, DOI 10.1016/0006-8993(89)91665-X.
   HERRERA DG, 1992, NEUROSCIENCE, V49, P781, DOI 10.1016/0306-4522(92)90356-7.
   Herrmann M, 2000, STROKE, V31, P2670, DOI 10.1161/01.STR.31.11.2670.
   Hu JR, 1996, BBA-MOL CELL RES, V1313, P239, DOI 10.1016/0167-4889(96)00095-X.
   Hu JR, 1997, J NEUROCHEM, V69, P2294.
   Huang J, 1997, NEUROCHEM RES, V22, P1329, DOI 10.1023/A:1022062921438.
   Huttunen HJ, 2000, J BIOL CHEM, V275, P40096, DOI 10.1074/jbc.M006993200.
   Joosten EAJ, 1997, PROG NEUROBIOL, V53, P1, DOI 10.1016/S0301-0082(97)00024-5.
   Kleindienst A, 2004, J NEUROTRAUM, V21, P541, DOI 10.1089/089771504774129874.
   KLIGMAN D, 1985, P NATL ACAD SCI USA, V82, P7136, DOI 10.1073/pnas.82.20.7136.
   Kline AE, 2001, NEUROSCIENCE, V106, P547, DOI 10.1016/S0306-4522(01)00300-1.
   Klisch J, 2003, NEUROSCI LETT, V342, P25, DOI 10.1016/S0304-3940(03)00222-2.
   Koppal T, 2001, NEUROCHEM INT, V39, P401, DOI 10.1016/S0197-0186(01)00047-X.
   Kruger H, 1999, NEUROREPORT, V10, P2651.
   Kukley M, 2001, NEUROSCIENCE, V107, P405, DOI 10.1016/S0306-4522(01)00369-4.
   Lam AGM, 2001, NEUROBIOL AGING, V22, P765, DOI 10.1016/S0197-4580(01)00233-0.
   Levison SW, 1997, J NEUROSCI RES, V48, P83, DOI 10.1002/(SICI)1097-4547(19970415)48:2<83::AID-JNR1>3.0.CO;2-8.
   LIBERINI P, 1994, BRAIN RES, V648, P1, DOI 10.1016/0006-8993(94)91897-X.
   LOIS C, 1993, P NATL ACAD SCI USA, V90, P2074, DOI 10.1073/pnas.90.5.2074.
   LUSTEP HL, 2002, CURR OPIN INVESTIG D, V3, P924.
   Mauler F, 2001, BRAIN RES, V888, P150, DOI 10.1016/S0006-8993(00)03074-2.
   McAdory BS, 1998, BRAIN RES, V813, P211, DOI 10.1016/S0006-8993(98)01014-2.
   McGraw J, 2001, J NEUROSCI RES, V63, P109, DOI 10.1002/1097-4547(20010115)63:2<109::AID-JNR1002>3.0.CO;2-J.
   Melena J, 2000, EUR J PHARMACOL, V406, P319, DOI 10.1016/S0014-2999(00)00688-9.
   Menet V, 2000, GLIA, V31, P267, DOI 10.1002/1098-1136(200009)31:3<267::AID-GLIA80>3.0.CO;2-N.
   Menet V, 2001, J NEUROSCI, V21, P6147.
   Missler U, 1997, STROKE, V28, P1956, DOI 10.1161/01.STR.28.10.1956.
   Nishi M, 1997, NEUROSCI LETT, V229, P212, DOI 10.1016/S0304-3940(97)00443-6.
   Nishi M, 1996, SYNAPSE, V23, P1, DOI 10.1002/(SICI)1098-2396(199605)23:1<1::AID-SYN1>3.0.CO;2-E.
   OBERHAMMER F, 1993, J CELL SCI, V104, P317.
   Oosterink BJ, 1998, EUR J PHARMACOL, V358, P147, DOI 10.1016/S0014-2999(98)00614-1.
   Oosterink BJ, 2003, NEUROREPORT, V14, P57, DOI 10.1097/00001756-200301200-00011.
   Petzold A, 2003, BRAIN RES BULL, V61, P281, DOI 10.1016/S0361-9230(03)00091-1.
   PIERA MJ, 1995, ARCH INT PHARMACOD T, V329, P347.
   PREHN JHM, 1991, EUR J PHARMACOL, V203, P213, DOI 10.1016/0014-2999(91)90717-5.
   Privat A, 2003, GLIA, V43, P91, DOI 10.1002/glia.10249.
   Ramos AJ, 2000, BRAIN RES, V883, P1, DOI 10.1016/S0006-8993(00)02862-6.
   Ramos AJ, 2002, BRAIN RES, V958, P112, DOI 10.1016/S0006-8993(02)03489-3.
   Ramos AJ, 2002, ANN NY ACAD SCI, V965, P343.
   RAMOS AJ, 2002, J NEUROCHEM S1, V81, pAP1.
   Ridet JL, 1997, TRENDS NEUROSCI, V20, P570, DOI 10.1016/S0166-2236(97)01139-9.
   Rothoerl RD, 2000, ACT NEUR S, V76, P97.
   Schaper C, 2000, BRAIN RES, V883, P41, DOI 10.1016/S0006-8993(00)02876-6.
   Schiffer D, 1996, J NEUROL SCI, V139, P27, DOI 10.1016/0022-510X(96)00073-1.
   Semkova I, 1998, EUR J PHARMACOL, V359, P251, DOI 10.1016/S0014-2999(98)00634-7.
   Souza TME, 2000, PHYSIOL BEHAV, V71, P29, DOI 10.1016/S0031-9384(00)00299-7.
   Stoll G, 1998, PROG NEUROBIOL, V56, P149, DOI 10.1016/S0301-0082(98)00034-3.
   Suchanek B, 1998, EUR J PHARMACOL, V355, P95, DOI 10.1016/S0014-2999(98)00469-5.
   Tagliaferro P, 1997, MOL CHEM NEUROPATHOL, V32, P195, DOI 10.1007/BF02815176.
   Tajrine D, 1997, J NEUROSCI RES, V50, P627.
   Torup L, 2000, EUR J PHARMACOL, V395, P137, DOI 10.1016/S0014-2999(00)00175-8.
   WHITAKERAZMITIA PM, 1994, PERSPECT DEV NEUROBI, V2, P233.
   WHITAKERAZMITIA PM, 1990, BRAIN RES, V528, P155, DOI 10.1016/0006-8993(90)90210-3.
   Wilson CC, 1998, BRAIN RES, V782, P235, DOI 10.1016/S0006-8993(97)01284-5.
   Woertgen C, 1997, ACTA NEUROCHIR, V139, P1161, DOI 10.1007/BF01410977.
   Zhu Y, 1998, J CEREBR BLOOD F MET, V18, P1032, DOI 10.1097/00004647-199809000-00013.},
Number-of-Cited-References = {84},
Times-Cited = {59},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {5},
Journal-ISO = {Brain Res.},
Doc-Delivery-Number = {880FW},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000225775400005},
DA = {2022-05-17},
}

@inproceedings{ WOS:000681699103028,
Author = {Dille, Michael and Nuch, Danny and Gupta, Shiven and McCabe, Steven and
   Verzic, Nicholas and Fong, Terry and Wong, Uland},
Book-Group-Author = {IEEE},
Title = {PHALANX: Expendable projectile sensor networks for planetary exploration},
Pages = {1-12},
DOI = {10.1109/AERO47225.2020.9172595},
Booktitle = {2020 IEEE AEROSPACE CONFERENCE (AEROCONF 2020)},
Series = {IEEE Aerospace Conference Proceedings},
Year = {2020},
Note = {IEEE Aerospace Conference, Big Sky, MT, MAR 06-13, 2020},
Abstract = {Technologies enabling long-term, wide-ranging measurement in
   hard-to-reach areas are a critical need for planetary science inquiry.
   Phenomena of interest include flows or variations in volatiles, gas
   composition or concentration, particulate density, or even simply
   temperature. Improved measurement of these processes enables
   understanding of exotic geologies and distributions or correlating
   indicators of trapped water or biological activity. However, such data
   is often needed in unsafe areas such as caves, lava tubes, or steep
   ravines not easily reached by current spacecraft and planetary robots.
   To address this capability gap, we have developed miniaturized,
   expendable sensors which can be ballistically lobbed from a robotic
   rover or static lander - or even dropped during a flyover. These
   projectiles can perform sensing during flight and after anchoring to
   terrain features. By augmenting exploration systems with these sensors,
   we can extend situational awareness, perform long-duration monitoring,
   and reduce utilization of primary mobility resources, all of which are
   crucial in surface missions. We call the integrated payload that
   includes a cold gas launcher, smart projectiles, planning software,
   network discovery, and science sensing: PHALANX.
   In this paper, we introduce the mission architecture for PHALANX and
   describe an exploration concept that pairs projectile sensors with a
   rover ``mothership.{''} Science use cases explored include
   reconnaissance using ballistic cameras, volatiles detection, and
   building timelapse maps of temperature and illumination conditions.
   Strategies to autonomously coordinate constellations of deployed sensors
   to self-discover and localize with peer ranging (i.e. a ``local GPS{''})
   are summarized, thus providing communications infrastructure
   beyond-line-of-sight (BLOS) of the rover. Capabilities were demonstrated
   through both simulation and physical testing with a terrestrial
   prototype.
   The approach to developing a terrestrial prototype is discussed,
   including design of the launching mechanism, projectile optimization,
   micro-electronics fabrication, and sensor selection. Results from early
   testing and characterization of commercial-off-the-shelf (COTS)
   components are reported. Nodes were subjected to successful burn-in
   tests over 48 hours at full logging duty cycle. Integrated field tests
   were conducted in the Roverscape, a half-acre planetary analog
   environment at NASA Ames, where we tested up to 10 sensor nodes
   simultaneously coordinating with an exploration rover. Ranging accuracy
   has been demonstrated to be within +/-10cm over 20m using commodity
   radios when compared to high-resolution laser scanner ground truthing.
   Evolution of the design, including progressive miniaturization of the
   electronics and iterated modifications of the enclosure housing for
   streamlining and optimized radio performance are described. Finally,
   lessons learned to date, gaps toward eventual flight mission
   implementation, and continuing future development plans are discussed.},
Publisher = {IEEE},
Address = {345 E 47TH ST, NEW YORK, NY 10017 USA},
Type = {Proceedings Paper},
Language = {English},
Affiliation = {Dille, M (Corresponding Author), NASA, KBR Inc, Ames Res Ctr, Moffett Field, CA 94035 USA.
   Dille, Michael, NASA, KBR Inc, Ames Res Ctr, Moffett Field, CA 94035 USA.
   Nuch, Danny, San Jose State Univ, San Jose, CA 95192 USA.
   Gupta, Shiven, Duke Univ, Durham, NC 27708 USA.
   McCabe, Steven, Univ Waikato, Hamilton 3216, New Zealand.
   Verzic, Nicholas, Khan Lab Sch, Mountain View, CA 94041 USA.
   Fong, Terry; Wong, Uland, NASA, Ames Res Ctr, Moffett Field, CA 94035 USA.},
ISSN = {1095-323X},
ISBN = {978-1-7281-2734-7},
Research-Areas = {Engineering},
Web-of-Science-Categories  = {Engineering, Aerospace},
Author-Email = {michael.dille@nasa.gov
   danny.nuch@sjsu.edu
   shiven.gupta@duke.edu
   stowmc@gmail.com
   nicholasverzic@gmail.com
   terry.fong@nasa.gov
   uland.wong@nasa.gov},
Affiliations = {National Aeronautics \& Space Administration (NASA); NASA Ames Research
   Center; California State University System; San Jose State University;
   Duke University; University of Waikato; National Aeronautics \& Space
   Administration (NASA); NASA Ames Research Center},
Funding-Acknowledgement = {NASA Ames Internal Research and Development Fund (IRAD); NASA Center
   Innovation Fund (CIF); San Jose State University CAARE Program},
Funding-Text = {We acknowledge the contributions of Antoine Tardy, Neelay Junnarkar,
   Arno Rogg, and Eli Zucker. We thank Dr. Steve McGuire and Prof. Nisar
   Ahmed of the University of Colorado Boulder for many fruitful
   discussions and for taking on this concept as a class project case
   study. This project was supported by the NASA Ames Internal Research and
   Development Fund (IRAD) and the NASA Center Innovation Fund (CIF). We
   thank NASA SSERVI for use of regolith simulant samples. Danny Nuch was
   supported by the San Jose State University CAARE Program.},
Cited-References = {Amundson I, 2009, LECT NOTES COMPUT SC, V5801, P235, DOI 10.1007/978-3-642-04385-7\_16.
   {[}Anonymous], 2018, 8021AE2018 IEEE, P1.
   Balaram J., 2018, 2018 AIAA Atmospheric Flight Mechanics Conference.
   Birkmeyer P, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2683, DOI 10.1109/IROS.2009.5354561.
   Bretl T, 2006, SPRINGER TRAC ADV RO, V21, P449.
   Calle L., 2019, NASA TECHNICAL PUBLI.
   Djugash J., 2010, THESIS.
   Haykin S., 2007, INTRO ANALOG DIGITAL.
   Howe S., 2012, CONCEPTS APPROACHES.
   Karras Jaakko T., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5459, DOI 10.1109/ICRA.2017.7989642.
   Kelly A, 2013, MOBILE ROBOTICS: MATHEMATICS, MODELS, AND METHODS, P1.
   Kohanbash D., 2012, P INT C AGR ENG VAL, P8.
   Liljeb<spacing diaeresis>ack T. A., 2014, SINTEF REPORT.
   Murphy W., 1995, MCS95 COL SCH MIN DE, V7, P1.
   O'Halloran D, 2005, MECH MACH THEORY, V40, P1345, DOI 10.1016/j.mechmachtheory.2005.02.004.
   Parness A, 2013, IND ROBOT, V40, P218, DOI 10.1108/01439911311309906.
   Pettersson GM, 2019, IEEE INT CONF COMPUT.
   Pfeil J., 2011, SIGGRAPH AS 2011 EM.
   Radi M, 2012, SENSORS-BASEL, V12, P650, DOI 10.3390/s120100650.
   Reiss-Bubenheim D., 2017, AGU FALL M.
   Titus T. N., 2015, LPI CONTRIBUTIONS, V1883, P9017.
   Wilcox BH, 2007, J FIELD ROBOT, V24, P421, DOI 10.1002/rob.20193.},
Number-of-Cited-References = {22},
Times-Cited = {0},
Usage-Count-Last-180-days = {0},
Usage-Count-Since-2013 = {0},
Doc-Delivery-Number = {BS0FQ},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000681699103028},
DA = {2022-05-17},
}

@inproceedings{ WOS:000290030701050,
Author = {Preece, H. J.},
Editor = {Oxley, L and Kulasiri, D},
Title = {Identifying Hotspots for Threats to Koalas Using Spatial Analysis},
Url = {https://www.mssanz.org.au/MODSIM07/papers/21_s46/IdentifyingHotspots_s46_Preece_.pdf},
Booktitle = {MODSIM 2007: INTERNATIONAL CONGRESS ON MODELLING AND SIMULATION: LAND,
   WATER AND ENVIRONMENTAL MANAGEMENT: INTEGRATED SYSTEMS FOR
   SUSTAINABILITY},
Year = {2007},
Pages = {1294-1300},
Note = {International Congress on Modelling and Simulation (MODSIM07),
   Christchurch, NEW ZEALAND, DEC 10-13, 2007},
Abstract = {Wildlife populations throughout the world are under pressure as human
   activities expand into previously natural ecosystems. Human population
   growth is resulting in the rapid development of sensitive coastal
   regions that frequently coincide with areas of high biodiversity and
   significant populations of fauna - such as koalas (Phascolarctos
   cinereus). As a consequence, these wildlife populations are increasingly
   faced with a range of threats associated with anthropogenic activity.
   While land clearing for urban development results in direct impacts on
   wildlife populations through habitat loss, the associated effects,
   including habitat fragmentation and elevated levels of anthropogenic
   mortality are indirect, insidious and much more difficult to detect or
   quantify.
   Habitat loss has long been regarded as the single biggest threat to the
   persistence of many species, and the main factor responsible for
   declining koala populations. Clearing not only results in net loss of
   habitat, but the fragmentation of the remaining habitat also contributes
   to a permanent decrease in population size and reduced long term
   population viability. Degradation of habitat is often associated with
   fragmentation through edge effects, or through logging regimes,
   thinning; destruction of mid-storey shelter trees; fire regimes;
   excessive nutrient input; or introduction of weeds (ANZECC 1998). As a
   consequence of urban development, koala populations have to contend with
   the additional threats posed by vehicles, dogs and disease, which are
   frequently regarded as the main agents of injury and mortality of koalas
   in or near urban areas (Martin and Handasyde 1999).
   This study relates the spatial pattern of threats to wildlife
   populations with landscape processes culminating in localised
   extinctions. By examining both habitat fragmentation effects and the
   major causes of koala mortality (vehicle, dog and disease) the study
   provides information and techniques to develop management options for
   wildlife populations in rapidly urbanising areas.
   In the Koala Coast region of South East Queensland, threats to koalas
   were modelled spatially by integrating a forest fragmentation model
   derived from Landsat TM satellite imagery with threat surface models
   derived from koala mortality reports. To determine whether the spatial
   patterns could be related to ecological processes, evidence of localised
   koala extinctions was also investigated.
   The fragmentation model identified and mapped six categories of
   fragmentation and also provided valuable contextual and descriptive
   information, essential for assessing potential impacts and management
   decisions. The Koala Coast was found to be highly fragmented, with only
   21\% of the study area classified as ``interior forest{''} which
   represents the most suitable habitat for koalas. By identifying
   ``hotspots{''}, or spatial concentrations of threats from the surface
   models using GIS, it was possible to estimate that the anthropogenic
   mortality risk in the high threat zone (4.5 koala 100ha(-1) yr(-1)) was
   7.5 times higher than the low threat zone. These threats are already
   impacting on koala population viability, with 18\% +/- 5\% of the Koala
   Coast affected by localised extinctions. It is concluded that
   human-influenced mortality and not habitat loss per se, is the greatest
   threat to koala population viability in these rapidly urbanising areas.
   {[}GRAPHICS]
   .},
Publisher = {MODELLING \& SIMULATION SOC AUSTRALIA \& NEW ZEALAND INC},
Address = {MSSANZ, CHRISTCHURCH, 00000, NEW ZEALAND},
Type = {Proceedings Paper},
Language = {English},
ISBN = {978-0-9758400-4-7},
Keywords = {Koala; forest fragmentation; habitat; hotspot; threatzone; GIS; spatial
   modelling},
Keywords-Plus = {FOREST FRAGMENTATION; UNITED-STATES; POPULATION},
Research-Areas = {Computer Science; Environmental Sciences \& Ecology; Science \&
   Technology - Other Topics},
Web-of-Science-Categories  = {Computer Science, Information Systems; Ecology; Environmental Sciences;
   Multidisciplinary Sciences},
Author-Email = {Harriet.Preece@epa.qld.gov.au},
ORCID-Numbers = {Preece, Harriet/0000-0002-4404-8837},
Cited-References = {{*}ANZECC, 1998, NATL KOALA CONSERVAT.
   BEGON M, 1996, ECOL BLACKWELL SCI.
   BURNLEY I, 2003, SEA CHANGE MOVEMENT.
   Civco DL, 2002, PHOTOGRAMM ENG REM S, V68, P1083.
   Dique DS, 2004, WILDLIFE RES, V31, P109, DOI 10.1071/WR02031.
   Fahrig L, 1997, J WILDLIFE MANAGE, V61, P603, DOI 10.2307/3802168.
   Gustafson EJ, 1998, ECOSYSTEMS, V1, P143, DOI 10.1007/s100219900011.
   Laurance WF, 1998, FOREST ECOL MANAG, V110, P173, DOI 10.1016/S0378-1127(98)00291-6.
   Loveland TR, 1999, PHOTOGRAMM ENG REM S, V65, P1021.
   MARTIN R, 1999, KOALA NAT HISTORY CO.
   {*}QUEENSL GOV, 2006, NAT CONSERVATION KOA.
   Queensland Government, 2005, SOUTH EAST QUEENSLAN.
   Riitters K, 2000, CONSERV ECOL, V4, DOI 10.5751/ES-00209-040203.
   Riitters KH, 2005, ENVIRON MANAGE, V35, P483, DOI 10.1007/s00267-003-0220-1.
   Silverman B., 1986, DENSITY ESTIMATION S.
   SKOLE D, 1993, SCIENCE, V260, P1905, DOI 10.1126/science.260.5116.1905.
   STAUFFER D, 1985, INT PERCOLATION THEO.
   Turner M.G., 1991, QUANTITATIVE METHODS.},
Number-of-Cited-References = {18},
Times-Cited = {6},
Usage-Count-Last-180-days = {4},
Usage-Count-Since-2013 = {51},
Doc-Delivery-Number = {BUQ25},
Web-of-Science-Index = {Conference Proceedings Citation Index - Science (CPCI-S)},
Unique-ID = {WOS:000290030701050},
DA = {2022-05-17},
}

@article{ WOS:000304687400012,
Author = {Yoshikawa, Shuro and Okino, Kyoko and Asada, Miho},
Title = {Geomorphological variations at hydrothermal sites in the southern
   Mariana Trough: Relationship between hydrothermal activity and
   topographic characteristics},
Journal = {MARINE GEOLOGY},
Year = {2012},
Volume = {303},
Pages = {172-182},
Month = {MAR 15},
Abstract = {This study presents the first detailed geomorphological characterization
   of field-scale geological features associated with hydrothermal systems
   in the southern Mariana Trough, using near-bottom swath mapping data
   collected by the autonomous underwater vehicle (AUV) Urashima during
   cruise YK09-08 and dive observation data acquired by the submersible
   Shinkai6500 during cruise YK10-11. The motivation of this study is to
   examine the relationship between geomorphological characteristics and
   hydrothermal activity, and to examine the nature of tectonic and
   volcanic controls on the hydrothermal system in this area. Two of the
   hydrothermal sites in the study area (near 12 degrees 57'N, 143 degrees
   37'E) are located on the active backarc spreading axis (the Snail and
   Yamanaka sites), one is located at the eastern foot of the axial high
   (the Archean site), and two are located on an off-axis knoll about 5 km
   from the spreading axis (the Pika and Urashima sites). The on-axis area
   is divided into tectonically dominant and volcanically dominant zones;
   volcanically dominant zones are characterized by mounds (height, 5-30 m;
   diameter, 250-320 m) cut by fissures. The Snail and Yamanaka sites are
   located adjacent to these fissures, and are possibly represented local
   activity associated with a 4th order segment-scale diking event (on the
   basis of comparisons with previously studied cases on the East Pacific
   Rise with similar on-axis geological characteristics). In contrast to
   the on-axis sites, the off-axis sites show no evidence of faulting. The
   Archean site at the foot of the axial high is characterized by a single
   mound (height, 50-100; diameter, 250-300 m), pronounced off-axis lava
   flows, and the presence of high-amplitude rugged seafloor features; the
   site is located at the top of the mound. Numerous ridge lines (height,
   mainly 2-6 m) extend radially from the top of the mound, and several
   chimney-like structures (up to approximately 6 m high) occur on the top
   and slopes of the mound. The Pika site is located on the western peak of
   an off-axis knoll, and the newly discovered Urashima site is located at
   the northern foot of the western peak of the same knoll. The western
   peak is characterized by bumpy seabed textures formed by numerous
   smaller-scale mounds and ridge lines; however, the eastern peak has a
   very smooth top and slope, and shows no signs of hydrothermal activity.
   Numerous mounds (heights, 5-75 m; diameters, 50-350 m) are developed on
   the comparatively gentle slope of the knoll, in contrast to the numerous
   ridge lines (height, mainly 1-6 m) developed on the relatively steep
   slopes of the knoll. On the basis of the associated geomorphological
   features, the three off-axis sites (Archean, Pika, and Urashima) were
   identified as localities created by relatively long-term large-scale
   hydrothermal activity, as compared with sites in the on-axis area. The
   sustained activity at off-axis sites appears closely related to an
   off-axis upwelling magma system. The three off-axis hydrothermal sites
   are composed mainly of breccia assemblages that probably originated from
   hydrothermal activity with black smoker venting. These areas are
   characterized by numerous ridge lines, conical mounds, and bumpy seabed
   texture, whereas the on-axis sites are characterized by the absence of
   ridge lines, and the presence of white smoker and shimmering observed on
   dome-shaped pillow mounds. Hence, the distribution of ridge lines, mound
   morphology, and bumpy seabed texture is likely to correlate with
   hydrothermal activity. (C) 2012 Elsevier B.V. All rights reserved.},
Publisher = {ELSEVIER},
Address = {RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS},
Type = {Article},
Language = {English},
Affiliation = {Yoshikawa, S (Corresponding Author), Univ Tokyo, Atmosphere \& Ocean Res Inst, 5-1-5 Kashiwanoha, Kashiwa, Chiba 2778564, Japan.
   Yoshikawa, Shuro; Okino, Kyoko, Univ Tokyo, Atmosphere \& Ocean Res Inst, Kashiwa, Chiba 2778564, Japan.
   Asada, Miho, JAMSTEC, Inst Res Earth Evolut, Yokosuka, Kanagawa 2370061, Japan.},
DOI = {10.1016/j.margeo.2012.02.013},
ISSN = {0025-3227},
EISSN = {1872-6151},
Keywords = {geomorphological characteristic; mound morphology; hydrothermal
   activity; high-resolution bathymetry; southern Mariana Trough},
Keywords-Plus = {EAST PACIFIC RISE; HIGH-RESOLUTION BATHYMETRY; ALVIN SCANNING SONAR;
   LAVA-FLOW MORPHOLOGY; MIDOCEAN RIDGES; SPREADING RIDGES; VENT FIELD;
   SEGMENTATION; VOLCANISM; CONSTRAINTS},
Research-Areas = {Geology; Oceanography},
Web-of-Science-Categories  = {Geosciences, Multidisciplinary; Oceanography},
Author-Email = {s-yoshikawa@aori.u-tokyo.ac.jp},
Affiliations = {University of Tokyo; Japan Agency for Marine-Earth Science \& Technology
   (JAMSTEC)},
ResearcherID-Numbers = {asada, miho/AAQ-1499-2020
   Yoshikawa, Shuro/P-3286-2015},
ORCID-Numbers = {asada, miho/0000-0002-5888-5978
   },
Funding-Acknowledgement = {Japan Society for the Promotion of Science (JSPS) {[}20109002]},
Funding-Text = {We would like to thank the crew of the RN Yokosuka and the operation
   teams of the AUV Urashima and the submersible Shinkai6500 for their
   efforts and continuous support, the scientists on the cruise YK10-11 for
   their permission to use Shinkai6500 dive data, and Dr. Yoshifumi Nogi
   and Dr. Nobutatsu Mochizuki for the constructive discussions on
   geomagnetic anomalies at hydrothermal sites. We also thank Dr. David
   J.W. Piper for his kind editorial work, and Dr. Philip Leat and an
   anonymous reviewer for their helpful comments, which led to improvements
   in the manuscript. This work was supported by a Grant-in-Aid for
   Scientific Research (20109002) awarded by the Japan Society for the
   Promotion of Science (JSPS).},
Cited-References = {Asada M, 2007, GEOCHEM GEOPHY GEOSY, V8, DOI 10.1029/2006GC001418.
   Becker NC, 2010, GEOCHEM GEOPHY GEOSY, V11, DOI 10.1029/2009GC002719.
   Bohnenstiehl DR, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2008GC002158.
   BONATTI E, 1988, J GEOPHYS RES-SOLID, V93, P2967, DOI 10.1029/JB093iB04p02967.
   Cannat M, 2004, GEOPHYS MONOGR SER, V148, P111, DOI 10.1029/148GM05.
   Carbotte SM, 2003, GEOCHEM GEOPHY GEOSY, V4, DOI 10.1029/2002GC000337.
   Crawford WC, 2010, GEOPHYS MONOGR SER, V188, P113, DOI 10.1029/2008GM000726.
   Deschamps A, 2003, GEOCHEM GEOPHY GEOSY, V4, DOI 10.1029/2003GC000537.
   Deschamps A, 2007, EARTH PLANET SC LETT, V259, P1, DOI 10.1016/j.epsl.2007.04.007.
   Ferrini VL, 2007, GEOCHEM GEOPHY GEOSY, V8, DOI 10.1029/2006GC001333.
   Ferrini VL, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2008GC002047.
   Fouquet Y, 1996, EARTH PLANET SC LETT, V144, P147, DOI 10.1016/0012-821X(96)00142-2.
   Fryer P, 1996, REV GEOPHYS, V34, P89, DOI 10.1029/95RG03476.
   German CR, 2004, GEOPHYS MONOGR SER, V148, P1, DOI 10.1029/148GM01.
   Glasby GP, 2008, ORE GEOL REV, V34, P547, DOI 10.1016/j.oregeorev.2008.09.005.
   GREGG TKP, 1995, GEOLOGY, V23, P73, DOI 10.1130/0091-7613(1995)023<0073:QOSLFM>2.3.CO;2.
   GRIFFITHS RW, 1992, J GEOPHYS RES-SOL EA, V97, P19729, DOI 10.1029/92JB01594.
   HAMMOND SR, 1990, J GEOPHYS RES-SOLID, V95, P12875, DOI 10.1029/JB095iB08p12875.
   Haymon RM, 2004, EARTH PLANET SC LETT, V226, P367, DOI 10.1016/j.epsl.2004.08.002.
   HAYMON RM, 1991, EARTH PLANET SC LETT, V104, P513, DOI 10.1016/0012-821X(91)90226-8.
   Head JW, 1996, J GEOPHYS RES-SOL EA, V101, P28265, DOI 10.1029/96JB02275.
   HEKINIAN R, 1983, SCIENCE, V219, P1321, DOI 10.1126/science.219.4590.1321.
   HEKINIAN R, 1985, ECON GEOL, V80, P221, DOI 10.2113/gsecongeo.80.2.221.
   Humphris SE, 2002, GEOCHEM GEOPHY GEOSY, V3, DOI 10.1029/2001GC000284.
   Humphris SE, 1996, GEOPHYS RES LETT, V23, P3443, DOI 10.1029/96GL03079.
   Iizasa K, 1999, SCIENCE, V283, P975, DOI 10.1126/science.283.5404.975.
   ISHIBASHI J, 2004, EOS T AGU S, V85.
   Kakegawa T, 2008, RESOUR GEOL, V58, P249, DOI 10.1111/j.1751-3928.2008.00060.x.
   Kennish MJ, 1998, EARTH-SCI REV, V43, P63, DOI 10.1016/S0012-8252(98)00006-3.
   Kitada K, 2006, GEOCHEM GEOPHY GEOSY, V7, DOI 10.1029/2005GC001119.
   Kleinrock MC, 1996, NATURE, V382, P149, DOI 10.1038/382149a0.
   Kumagai H, 2010, GEOCHEM GEOPHY GEOSY, V11, DOI 10.1029/2010GC003337.
   Kurras GJ, 1998, GEOPHYS RES LETT, V25, P1209, DOI 10.1029/98GL00721.
   Kurras GJ, 2000, MAR GEOPHYS RES, V21, P23, DOI 10.1023/A:1004792202764.
   MACDONALD KC, 1991, SCIENCE, V253, P986, DOI 10.1126/science.253.5023.986.
   Macdonald KC, 1998, GEOPH MONOG SERIES, V106, P27.
   Martinez F, 2000, J GEOPHYS RES-SOL EA, V105, P16591, DOI 10.1029/2000JB900117.
   Masaki Yuka, 2011, JAMSTEC REP RES DEV, V12, P1, DOI DOI 10.5918/JAMSTECR.12.1.
   MCCONACHY TF, 1986, GEOLOGY, V14, P295, DOI 10.1130/0091-7613(1986)14<295:GFASOA>2.0.CO;2.
   Nakamura K., 2010, MAR TECHN ENG CTR JA.
   Ondreas H, 2009, GEOCHEM GEOPHY GEOSY, V10, DOI 10.1029/2008GC002171.
   Perfit MR, 1998, GEOPH MONOG SERIES, V106, P59.
   RONA PA, 1993, ECON GEOL BULL SOC, V88, P1989, DOI 10.2113/gsecongeo.88.8.1989.
   Scheirer DS, 2000, MAR GEOPHYS RES, V21, P121, DOI 10.1023/A:1004701429848.
   SEAMA N, 2002, EOS T AGU S, V83.
   Sohn RA, 2005, GEOLOGY, V33, P93, DOI 10.1130/G21116.1.
   Soule SA, 2008, GEOCHEM GEOPHY GEOSY, V9, DOI 10.1029/2008GC002070.
   Tanaka A, 2007, EARTH PLANETS SPACE, V59, P245, DOI 10.1186/BF03353101.
   Tivey MK, 2007, OCEANOGRAPHY, V20, P50, DOI 10.5670/oceanog.2007.80.
   Tivey MA, 2010, GEOPHYS MONOGR SER, V188, P43, DOI 10.1029/2008GM000773.
   Toomey DR, 2007, NATURE, V446, P409, DOI 10.1038/nature05679.
   URABE T, 2004, EOS T AGU S, V85.
   Utsumi M., 2004, JAP GEOSC UN JAP EAR, pB002.
   Wessel P., 1995, EOS T AGU, V76, P329, DOI {[}DOI 10.1029/98E000426, 10.1029/98EO00426, DOI 10.1029/98EO00426].
   WHEAT CG, 2003, EOS T AGU S, V84.
   White SM, 2002, J GEOPHYS RES-SOL EA, V107, DOI 10.1029/2001JB000571.
   White SM, 1998, J GEOPHYS RES-SOL EA, V103, P30371, DOI 10.1029/98JB02791.
   White SM, 2002, J GEOPHYS RES-SOL EA, V107, DOI 10.1029/2001JB000483.
   White SM, 2000, J GEOPHYS RES-SOL EA, V105, P23519, DOI 10.1029/2000JB900248.},
Number-of-Cited-References = {59},
Times-Cited = {19},
Usage-Count-Last-180-days = {3},
Usage-Count-Since-2013 = {45},
Journal-ISO = {Mar. Geol.},
Doc-Delivery-Number = {950YI},
Web-of-Science-Index = {Science Citation Index Expanded (SCI-EXPANDED)},
Unique-ID = {WOS:000304687400012},
DA = {2022-05-17},
}
