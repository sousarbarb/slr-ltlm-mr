bibtex_key,title,author,journal,year,source,pages,volume,abstract,document_type,doi,url,affiliation,author_keywords,keywords,publisher,issn,language,note,selection_criteria,created_at,updated_at,created_by,updated_by,status,comments
,Vision-Aided Multi-UAV Autonomous Flocking in GPS-Denied Environment,Y. Tang and Y. Hu and J. Cui and F. Liao and M. Lao and F. Lin and R. S. H. Teo,IEEE Transactions on Industrial Electronics,2019,IEEE INSPEC Non-Controlled Terms,616--626,66,"This paper presents a sophisticated vision-aided flocking system for unmanned aerial vehicles (UAVs), which is able to operate in GPS-denied unknown environments for exploring and searching missions, and also able to adopt two types of vision sensors, day and thermal cameras, to measure relative motion between UAVs in different lighting conditions without using wireless communication. In order to realize robust vision-aided flocking, an integrated framework of tracking-learning-detection on the basis of multifeature coded correlation filter has been developed. To achieve long-term tracking, a redetector is trained online to adaptively reinitialize target for global sensing. An advanced flocking strategy is developed to address the autonomous multi-UAVs' cooperative flight. Light detection and ranging (LiDAR)-based navigation modules are developed for autonomous localization, mapping, and obstacle avoidance. Flight experiments of a team of UAVs have been conducted to verify the performance of this flocking system in a GPS-denied environment. The extensive experiments validate the robustness of the proposed vision algorithms in challenging scenarios.",,10.1109/TIE.2018.2824766,,,,Target tracking;Sensors;Cameras;Correlation;Trajectory;Robustness;Visualization;Flocking;unmanned system;visual sensing,,1557-9948,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Persistent localization and life-long mapping in changing environments using the Frequency Map Enhancement,T. Krajník and J. P. Fentanes and M. Hanheide and T. Duckett,,2016,IEEE INSPEC Non-Controlled Terms,4558--4563,,"We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.",,10.1109/IROS.2016.7759671,,,,Navigation;Two dimensional displays;Robot sensing systems;Planning;Predictive models;Robot kinematics;mobile robotics;long-term autonomy,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Long-term human affordance maps,R. Limosani and L. Y. Morales and J. Even and F. Ferreri and A. Watanabe and F. Cavallo and P. Dario and N. Hagita,,2015,IEEE INSPEC Non-Controlled Terms,5748--5754,,"This paper presents a work on mapping the use of space by humans in long periods of time. Daily geometric maps with the same coordinate frame were generated with SLAM, and in a similar manner, daily affordance density maps (places people use) were generated with the output of a human tracker running on the robot. The contribution of the paper is two-fold: an approach to detect geometric changes to cluster them in similar geometric configurations and the building of geometric and affordance composite maps on each cluster. This approach avoids the loss of long term retrieved information. Geometric similarity was computed using a normal distance approach on the maps. The analysis was performed on data collected by a mobile robot for a period of 4 months accumulating data equivalent to 70 days. Experimental results show that the system is capable of detecting geometric changes in the environment and clustering similar geometric configurations.",,10.1109/IROS.2015.7354193,,,,Robot kinematics;Buildings;Navigation;Robot sensing systems;Layout;Geometry,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Research of large-scale offline map management in visual SLAM,Q. Shen and H. Sun and P. Ye,,2017,IEEE INSPEC Non-Controlled Terms,215--219,,"This paper presents a novel method of visual simultaneous localization and mapping (SLAM), which is a method of real-time localization and mapping. It is important for a mobile robot to build a map while autonomously navigation. Due to the complexity of the robot work scene, the SLAM method proposed in this paper optimizes map management. It will cost a lot of time and space when a robot long-term works in a same large scene. Therefore, we propose a method in this paper to save a detail map as an offline map in advance. At the same time in order to facilitate the follow-up optimization, the offline map can be divided into several sub-graphs according to the similarity of the scene. Since the segmented offline map has been saved to local system, it can be loaded at any time to localization and obtain the pose of current frame.",,10.1109/ICSAI.2017.8248292,,,,Simultaneous localization and mapping;Image segmentation;Cameras;Real-time systems;Optimization;Symmetric matrices;SLAM;offline map;segment graph;normalized-cut,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships,P. Gao and H. Zhang,,2020,IEEE INSPEC Non-Controlled Terms,1070--1076,,"Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks.",,10.1109/ICRA40945.2020.9196906,,,,Visualization;Simultaneous localization and mapping;Robustness;Strain;Image recognition;Tensile stress,,2577-087X,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,"PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization",P. Egger and P. V. K. Borges and G. Catt and A. Pfrunder and R. Siegwart and R. Dubé,,2018,IEEE INSPEC Non-Controlled Terms,3430--3437,,"Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.",,10.1109/IROS.2018.8593854,,,,Simultaneous localization and mapping;Three-dimensional displays;Laser radar;Optimization;Feature extraction,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,"Sensors, SLAM and Long-term Autonomy: A Review",M. Zaffar and S. Ehsan and R. Stolkin and K. M. Maier,,2018,IEEE INSPEC Non-Controlled Terms,285--290,,"Simultaneous Localization and Mapping, commonly known as SLAM, has been an active research area in the field of Robotics over the past three decades. For solving the SLAM problem, every robot is equipped with either a single sensor or a combination of similar/different sensors. This paper attempts to review, discuss, evaluate and compare these sensors. Keeping an eye on future, this paper also assesses the characteristics of these sensors against factors critical to the long-term autonomy challenge.",,10.1109/AHS.2018.8541483,,,,Cameras;Simultaneous localization and mapping;Sensor phenomena and characterization;Laser radar;Acoustic sensors;SLAM;Long-term Autonomy;Sensors,,2471-769X,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Robust SLAM Systems: Are We There Yet?,M. Bujanca and X. Shi and M. Spear and P. Zhao and B. Lennox and M. Luján,,2021,IEEE INSPEC Non-Controlled Terms,5320--5327,,"Progress in the last decade has brought about significant improvements in the accuracy and speed of SLAM systems, broadening their mapping capabilities. Despite these advancements, long-term operation remains a major challenge, primarily due to the wide spectrum of perturbations robotic systems may encounter.Increasing the robustness of SLAM algorithms is an ongoing effort, however it usually addresses a specific perturbation. Generalisation of robustness across a large variety of challenging scenarios is not well-studied nor understood. This paper presents a systematic evaluation of the robustness of open-source state-of-the-art SLAM algorithms with respect to challenging conditions such as fast motion, non-uniform illumination, and dynamic scenes. The experiments are performed with perturbations present both independently of each other, as well as in combination in long-term deployment settings in unconstrained environments (lifelong operation).The detailed results (approx. 20,000 experiments) along with comprehensive documentation of the benchmarking tool for integrating new datasets and evaluating SLAM algorithms not studied in this work are available at https://robustslam.github.io/evaluation.",,10.1109/IROS51168.2021.9636814,,,,Simultaneous localization and mapping;Systematics;Three-dimensional displays;Heuristic algorithms;Perturbation methods;Dynamics;Lighting,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,High level assisted control mode based on SLAM for a remotely controlled robot,J.-C. Devaux and P. Nadrag and E. Colle and P. Hoppenot,,2011,IEEE INSPEC Non-Controlled Terms,186--191,,"One aim of ambient assistive technologies is to reduce long term hospitalization for elderly people, especially with pathologies such as Mild Cognitive Impairment (MCI). The smart environment assists these people and their families with safety and cognitive stimulation, so they stay as long as possible at home. The originality comes from using the robot in the elderly person's home. This robot is remote controlled by a distant user, a therapist or a relative, for determining alarming situations or for participating in stimulation exercises. Several modes are available for controlling the robot. This paper deals with an assisted control mode in which the remote user gives to the robot one goal and the robot reaches the goal by itself. During the robot movement, the user can dynamically change the current goal. An important hypothesis is that the robot has no a priori knowledge of its environment at the beginning. The knowledge will increase with time and the planned trajectory will be refreshed at two levels: a local one - faster but not always sufficient - and a global one - slower but which always finds a path if one exists. The idea is to work only with local information, using the robot sensors, the operator keeping the high level control. To assure that control, the remote operator uses video feedback and information from a laser range scanner.",,10.1109/ICAR.2011.6088615,,,,Trajectory;Planning;Simultaneous localization and mapping;Navigation,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,SemanticFusion: Dense 3D semantic mapping with convolutional neural networks,J. McCormac and A. Handa and A. Davison and S. Leutenegger,,2017,IEEE INSPEC Non-Controlled Terms,4628--4635,,"Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance - they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ?25Hz.",,10.1109/ICRA.2017.7989538,,,,Semantics;Simultaneous localization and mapping;Three-dimensional displays;Geometry;Two dimensional displays;Labeling;Cameras,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Radar-on-Lidar: metric radar localization on prior lidar maps,H. Yin and Y. Wang and L. Tang and R. Xiong,,2020,IEEE INSPEC Non-Controlled Terms,1--7,,"Radar and lidar, provided by two different range sensors, each has pros and cons of various perception tasks on mobile robots or autonomous driving. In this paper, a Monte Carlo system is used to localize the robot with a rotating radar sensor on 2D lidar maps. We first train a conditional generative adversarial network to transfer raw radar data to lidar data, and achieve reliable radar points from generator. Then an efficient radar odometry is included in the Monte Carlo system. Combining the initial guess from odometry, a measurement model is proposed to match the radar data and prior lidar maps for final 2D positioning. We demonstrate the effectiveness of the proposed localization framework on the public multisession dataset. The experimental results show that our system can achieve high accuracy for long-term localization in outdoor scenes.",,10.1109/RCAR49640.2020.9303291,,,,Laser radar;Radar;Sensors;Radar imaging;Robots;Three-dimensional displays;Two dimensional displays,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Incorporating environmental measurements in navigation,H. J. S. Feder and J. J. Leonard and C. M. Smith,,1998,IEEE INSPEC Non-Controlled Terms,115--122,,"Extended missions in unknown regions present a significant navigational challenge for autonomous underwater vehicles (AUV). This paper investigates the long-term performance of a concurrent mapping and localization (CML) algorithm for the scenario of an AUV making observations of point features in the environment with a forward look sonar. Simulation results demonstrate that position estimates with long-term bounded errors of a few meters can be achieved under realistic assumptions about the vehicle, its sensors, and the environment. Potential failure modes of the algorithm, such as divergence and map slip, are discussed. CML technology can provide a significant improvement in the navigational capabilities of AUVs and can enable new missions in unmapped regions without reliance on acoustic beacons or surfacing for GPS resets.",,10.1109/AUV.1998.744447,,,,Sonar navigation;Remotely operated vehicles;Underwater acoustics;Performance analysis;Stochastic processes;Sea measurements;Jacobian matrices;Oceans;Automotive engineering;Marine technology,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Visual topometric localization,H. Badino and D. Huber and T. Kanade,,2011,IEEE INSPEC Non-Controlled Terms,794--799,,"One of the fundamental requirements of an autonomous vehicle is the ability to determine its location on a map. Frequently, solutions to this localization problem rely on GPS information or use expensive three dimensional (3D) sensors. In this paper, we describe a method for long-term vehicle localization based on visual features alone. Our approach utilizes a combination of topological and metric mapping, which we call topometric localization, to encode the coarse topology of the route as well as detailed metric information required for accurate localization. A topometric map is created by driving the route once and recording a database of visual features. The vehicle then localizes by matching features to this database at runtime. Since individual feature matches are unreliable, we employ a discrete Bayes filter to estimate the most likely vehicle position using evidence from a sequence of images along the route. We illustrate the approach using an 8.8 km route through an urban and suburban environment. The method achieves an average localization error of 2.7 m over this route, with isolated worst case errors on the order of 10 m.",,10.1109/IVS.2011.5940504,,,,Vehicles;Visualization;Measurement;Databases;Feature extraction;Global Positioning System;Probability density function,,1931-0587,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Towards life-long mapping of dynamic environments using temporal persistence modeling,G. Tsamis and I. Kostavelis and D. Giakoumis and D. Tzovaras,,2021,IEEE INSPEC Non-Controlled Terms,10480--10485,,"The contemporary SLAM mapping systems assume a static environment and build a map that is then used for mobile robot navigation disregarding the dynamic changes in this environment. The paper at hand presents a novel solution for the problem of life-long mapping that continually updates a metric map represented as a 2D occupancy grid in large scale indoor environments with movable objects such as people, robots, objects etc. suitable for industrial applications. We formalize each cell's occupancy as a failure analysis problem and contribute temporal persistence modeling (TPM), an algorithm for probabilistic prediction of the time that a cell in an observed location is expected to be “occupied” or “empty” given sparse prior observations from a task specific mobile robot. Our work is evaluated in Gazebo simulation environment against the nominal occupancy of cells and the estimated obstacles persistence. We also show that robot navigation with life-long mapping demands less replans and leads to more efficient navigation in highly dynamic environments.",,10.1109/ICPR48806.2021.9413161,,,,Measurement;Simultaneous localization and mapping;Navigation;Service robots;Predictive models;Probabilistic logic;Prediction algorithms,,1051-4651,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Long-Term Visual Localization Using Semantically Segmented Images,E. Stenborg and C. Toft and L. Hammarstrand,,2018,IEEE INSPEC Non-Controlled Terms,6484--6490,,"Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.",,10.1109/ICRA.2018.8463150,,,,Semantics;Cameras;Roads;Image segmentation;Visualization;Robustness;Feature extraction,,2577-087X,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Onboard Detection-Tracking-Localization,D. Tang and Q. Fang and L. Shen and T. Hu,IEEE/ASME Transactions on Mechatronics,2020,IEEE INSPEC Non-Controlled Terms,1555--1565,25,"This article investigates long-term positioning of moving objects by monocular vision of a miniature fixed-wing unmanned aerial vehicle. It is challenging to perform a real-time onboard vision processing task, due to the strict payload capacity and power budget limitations of microflying vehicles. We propose a parallel onboard architecture that explicitly decouples the long-term positioning task into iteratively operated detection, tracking, and localization. The proposed approach is eventually called onboard detection-tracking-localization, namely oDTL. The detector automatically extracts and identifies the object from image frames captured at in-flight durations. A learning-based network is constructed to improve detection accuracy and robustness against ever-changing outdoor illumination conditions and flying viewpoints. The tracker follows the object within specified region-of-interest from frame to frame with lower computing consumption. To further reduce target-losing rate, a concept of blind zone is proposed and applied, and its boundaries in sequential images are also theoretically inferred. The position estimator maps the flying vehicle pose, the image coordinates, and calibration specifications into real-world positions of the moving target. An extended Kalman filter is developed for rough position estimation, and a smooth module is introduced for the refinement of the position. Three offline comparative experiments and three online experiments have been conducted respectively to testify the real-time capability of our approach. The collected experimental results also demonstrate the feasible accuracy and robustness of the overall solution within the specified flying onboard scenarios.",,10.1109/TMECH.2020.2976794,,,,Robustness;Real-time systems;Visualization;Lighting;Cameras;Three-dimensional displays;IEEE transactions;Detection;localization;miniature fixed-wing unmanned aerial vehicle (UAV);monocular;onboard vision;parallel architecture;positioning;tracking,,1941-014X,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Optical flow localisation and appearance mapping (OFLAAM) for long-term navigation,D. Pastor-Moreno and H.-S. Shin and A. Waldock,,2015,IEEE INSPEC Non-Controlled Terms,980--988,,"This paper presents a novel method to use optical flow navigation for long term navigation. Unlike standard SLAM approaches for augmented reality, OFLAAM is designed for Micro Air Vehicles (MAV). It uses a optical flow camera pointing downwards, a IMU and a monocular camera pointing frontwards. That configuration avoids the computational expensive mapping and tracking of the 3D features. It only maps these features in a vocabulary list by a localization module to tackle the optical flow drift and the lose of the navigation estimation. That module, based on the well established algorithm DBoW2, will be also used to close the loop and allow long-term navigation in previously visited areas. The combination of high speed optical flow navigation with a low rate localization algorithm allows fully autonomous navigation for MAV, at the same time it reduces the overall computational load. This framework is implemented in ROS (Robot Operating System) and tested attached to a laptop. A representative scenario is used to validate and analyze the performance of the system.",,10.1109/ICUAS.2015.7152387,,,,Cameras;Optical sensors;Optical imaging;Computers;Vehicles;Adaptive optics;High-speed optical techniques,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Long-Term Visual Inertial SLAM based on Time Series Map Prediction,B. Song and W. Chen and J. Wang and H. Wang,,2019,IEEE INSPEC Non-Controlled Terms,5364--5369,,"With the advance in the field of mobile robots, autonomous robots are required for long-term deployment in dynamic and complex environments. However, the performance of Visual Inertial SLAM systems in long-term operation is not satisfactory, and most long-term SLAM systems assumes periodic changes in the environment. This paper presents a novel solution for long-term monocular VI SLAM system in dynamic environment based on autoregression(AR) modeling and map prediction. Map points are first classified into static and semi-static map points according to a memory model. Modeling and prediction of the different states of semi-static map points are performed that are derived from time series models. The predicted map is then fused with the current map to achieve a better forecast for the next frame if the prediction is not satisfactory enough. Experiments are carried out on an embedded system. The results indicate that the map prediction is reliable and the proposed approach improves the performance of long-term localization and mapping in dynamic environments.",,10.1109/IROS40897.2019.8968017,,,,,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Long-Term Urban Vehicle Localization Using Pole Landmarks Extracted from 3-D Lidar Scans,A. Schaefer and D. Büscher and J. Vertens and L. Luft and W. Burgard,,2019,IEEE INSPEC Non-Controlled Terms,1--7,,"Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation [1]. In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15 months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy.",,10.1109/ECMR.2019.8870928,,,,Laser radar;Detectors;Reliability;Feature extraction;Urban areas;Trajectory;Roads,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Long-term 3D map maintenance in dynamic environments,F. Pomerleau and P. Krüsi and F. Colas and P. Furgale and R. Siegwart,,2014,IEEE Author Keywords,3712--3719,,"New applications of mobile robotics in dynamic urban areas require more than the single-session geometric maps that have dominated simultaneous localization and mapping (SLAM) research to date; maps must be updated as the environment changes and include a semantic layer (such as road network information) to aid motion planning in dynamic environments. We present an algorithm for long-term localization and mapping in real time using a three-dimensional (3D) laser scanner. The system infers the static or dynamic state of each 3D point in the environment based on repeated observations. The velocity of each dynamic point is estimated without requiring object models or explicit clustering of the points. At any time, the system is able to produce a most-likely representation of underlying static scene geometry. By storing the time history of velocities, we can infer the dominant motion patterns within the map. The result is an online mapping and localization system specifically designed to enable long-term autonomy within highly dynamic environments. We validate the approach using data collected around the campus of ETH Zurich over seven months and several kilometers of navigation. To the best of our knowledge, this is the first work to unify long-term map update with tracking of dynamic objects.",,10.1109/ICRA.2014.6907397,,,,Three-dimensional displays;Dynamics;Simultaneous localization and mapping;Heuristic algorithms;Laser modes;Long-term mapping;dynamic obstacles;ICP;kd-tree;registration;scan matching;robot;SLAM,,1050-4729,,,,44698.62178,44698.62178,sousarbarb,,Duplicated,
,Segmented Matching Method of Multi-Geophysics Field SLAM Data Based on LSTM,Z. Li and H. Yu and T. Shen and Z. Li,,2020,IEEE Index Terms,147--151,,"At present, simultaneous localization and mapping (SLAM) has become an important method for autonomous underwater vehicles (AUVs) to realize long-term navigation. However, using only bathymetric data in unknown environment has its own disadvantages, that are low precision and large computational load. To tackle with requirements of high-precision navigation under large-scale and long-term voyage condition, a SLAM method and corresponding matching algorithm for integrating multi-geophysical field data are proposed. By dividing the feature data and location data of geophysical field obtained into various submaps and sub-segments during AUV sailing, the dominant navigation data of each segment is identified using long short-term memory network. Validity of the proposed method is done by simulation experiments. During the simulation, the loop closure detection of each submap is used, and the matching counter is set to check the correct matching rate. Finally, the matching results with single geophysics field data under the same conditions are compared with multi-geophysics field data and analyzed. The experimental results have demonstrated the feasibility and correctness of the proposed method.",,10.1109/ICUS50048.2020.9274964,,,,Technological innovation;Underwater vehicles;Timing;Simultaneous localization and mapping;Navigation;SLAM;LSTM;navigation;multi-geophysics field data;matching,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,"Real-Time, Environmentally-Robust 3D LiDAR Localization",Y. Zhu and B. Xue and L. Zheng and H. Huang and M. Liu and R. Fan,,2019,IEEE Index Terms,1--6,,"Localization, or position fixing, is an important problem in robotics research. In this paper, we propose a novel approach for long-term localization in a changing environment using 3D LiDAR. We first create the map of a real environment using GPS and LiDAR. Then, we divide the map into several small parts as the targets for cloud registration, which can not only improve the robustness but also reduce the registration time. We proposed a localization method called PointLocalization. PointLocalization allows us to fuse different kinds of odometers, which can optimize the accuracy and frequency of localization results. We evaluate our algorithm on an unmanned ground vehicle (UGV) using LiDAR and a wheel encoder, and obtain the localization results at more than 20 Hz after fusion. The algorithm can also localize the UGV in a 180-degree field of view (FOV). Using an outdated map captured six months ago, this algorithm shows great robustness, and the test results show that it can achieve an accuracy of 10 cm. PointLocalization has been tested for a period of more than six months in a crowded factory and has operated successfully over a distance of more than 2000 km.",,10.1109/IST48021.2019.9010305,,,,Laser radar;Global Positioning System;Simultaneous localization and mapping;Wheels;Cameras;Three-dimensional displays,,1558-2809,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Migratory birds-inspired navigation system for unmanned aerial vehicles,Y. Zhang and A. Chao and B. Zhao and H. Liu and X. Zhao,,2016,IEEE Index Terms,276--281,,"Migration birds are able to navigate themselves during a long-distance journey without getting lost. They actually achieve just what is being sought for in the field of Unmanned Aerial Vehicles (UAVs): long-term autonomous navigation. This paper proposes an approach that combines the migration birds' sense principles with Micro-Electro-Mechanical System (MEMS) sensors to estimate UAVs position within GPS-denied environments. Camera, orientation and web-based maps (such as Google/Baidu Maps) are chosen to simulate the birds' localization cues: vision, earth magnetic field and mental maps. The visual odometry, Particle Filter theories are used in the proposed approach to integrate multiple sensor measurements. Real flying experiments are conducted both in indoor and outdoor environments. The results validate that the proposed migration-inspired visual odometry system can estimate the UAV localization effectively.",,10.1109/ICInfA.2016.7831835,,,,Cameras;Visualization;Unmanned aerial vehicles;Birds;Sensors;Navigation;Optical imaging;Migration birds;Unmanned Aerial Vehicles;Navigation,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-term topological localisation for service robots in dynamic environments using spectral maps,T. Krajník and J. P. Fentanes and O. M. Mozos and T. Duckett and J. Ekekrantz and M. Hanheide,,2014,IEEE Index Terms,4537--4542,,"This paper presents a new approach for topological localisation of service robots in dynamic indoor environments. In contrast to typical localisation approaches that rely mainly on static parts of the environment, our approach makes explicit use of information about changes by learning and modelling the spatio-temporal dynamics of the environment where the robot is acting. The proposed spatio-temporal world model is able to predict environmental changes in time, allowing the robot to improve its localisation capabilities during long-term operations in populated environments. To investigate the proposed approach, we have enabled a mobile robot to autonomously patrol a populated environment over a period of one week while building the proposed model representation. We demonstrate that the experience learned during one week is applicable for topological localization even after a hiatus of three months by showing that the localization error rate is significantly lower compared to static environment representations.",,10.1109/IROS.2014.6943205,,,,Mathematical model;Three-dimensional displays;Predictive models;Fourier transforms;Feature extraction;Service robots;topological localisation;mobile robotics;spatio-temporal representations,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Persistent localization and life-long mapping in changing environments using the Frequency Map Enhancement,T. Krajník and J. P. Fentanes and M. Hanheide and T. Duckett,,2016,IEEE Index Terms,4558--4563,,"We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.",,10.1109/IROS.2016.7759671,,,,Navigation;Two dimensional displays;Robot sensing systems;Planning;Predictive models;Robot kinematics;mobile robotics;long-term autonomy,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Lifelong Localization in Semi-Dynamic Environment,S. Zhu and X. Zhang and S. Guo and J. Li and H. Liu,,2021,IEEE Index Terms,14389--14395,,"Mapping and localization in non-static environments are fundamental problems in robotics. Most of previous methods mainly focus on static and highly dynamic objects in the environment, which may suffer from localization failure in semi-dynamic scenarios without considering objects with lower dynamics, such as parked cars and stopped pedestrians. In this paper, we introduce semantic mapping and lifelong localization approaches to recognize semi-dynamic objects in non-static environments. We also propose a generic framework that can integrate mainstream object detection algorithms with mapping and localization algorithms. The mapping method combines an object detection algorithm and a SLAM algorithm to detect semi-dynamic objects and constructs a semantic map that only contains semi-dynamic objects in the environment. During navigation, the localization method can classify observation corresponding to static and non-static objects respectively and evaluate whether those semi-dynamic objects have moved, to reduce the weight of invalid observation and localization fluctuation. Real-world experiments show that the proposed method can improve the localization accuracy of mobile robots in non-static scenarios.",,10.1109/ICRA48506.2021.9561584,,,,Location awareness;Simultaneous localization and mapping;Fluctuations;Navigation;Heuristic algorithms;Conferences;Semantics,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Robot-Assisted Backscatter Localization for IoT Applications,S. Zhang and W. Wang and S. Tang and S. Jin and T. Jiang,IEEE Transactions on Wireless Communications,2020,IEEE Index Terms,5807--5818,19,"Recent years have witnessed the rapid proliferation of backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such backscatter tags is crucial for IoT-based smart applications. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, which is laborious for deployment. To empower universal localization service, this paper presents Rover, an indoor localization system that localizes multiple backscatter tags without any start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing measurements from backscattered WiFi signals and inertial sensors to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues including interference among multiple tags, real-time processing, as well as the data marginalization problem in dealing with degenerated motions. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.",,10.1109/TWC.2020.2997393,,,,Wireless fidelity;Backscatter;Interference;Robot sensing systems;Receivers;Antenna arrays;Backscatter;localization;inertial sensor;channel state information,,1558-2248,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Localizing Backscatters by a Single Robot with Zero Start-Up Cost,S. Zhang and W. Wang and S. Tang and S. Jin and T. Jiang,,2019,IEEE Index Terms,1--6,,"Recent years have witnessed the rapid proliferation of low- power backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such low-power backscatter tags is crucial for IoT-based smart services. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, increasing the deployment cost. To empower universal localization service, this paper presents Rover, an indoor localization system that simultaneously localizes multiple backscatter tags with zero start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing WiFi-based positioning measurements with inertial measurements to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues such as the interference among multiple tags and the real- time processing for solving the SLAM problem. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.",,10.1109/GLOBECOM38437.2019.9013768,,,,Backscatter;Wireless fidelity;Antenna arrays;Interference;Simultaneous localization and mapping,,2576-6813,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,LLama-SLAM: Learning High-Quality Visual Landmarks for Long-Term Mapping and Localization,S. Luthardt and V. Willert and J. Adamy,,2018,IEEE Index Terms,2645--2652,,"The precise localization of vehicles is an important requirement for autonomous driving or advanced driver assistance systems. Using common GNSS the ego position can be measured but not with the reliability and precision necessary. An alternative approach to achieve precise localization is the usage of visual landmarks observed by a camera mounted in the vehicle. However, this raises the necessity of reliable visual landmarks that are easily recognizable and persistent. We propose a novel SLAM algorithm that focuses on learning and mapping such visual long-term landmarks (LLamas). The algorithm therefore processes stereo image streams from several recording sessions in the same spatial area. The key part within LLama-SLAM is the assessment of the landmarks with quality values that are inferred as viewpoint dependent probabilities from observation statistics. By adding solely landmarks of high quality to the final LLama Map, it can be kept compact while still allowing reliable localization. Due to the long-term evaluation of the GNSS measurement during the sessions, the landmarks can be positioned precisely in a global referenced coordinate system. For a first assessment of the algorithm's capabilities, we present some experimental results from the mapping process combining three sessions recorded over two months on the same route.",,10.1109/ITSC.2018.8569323,,,,Cameras;Visualization;Simultaneous localization and mapping;Global navigation satellite system;Reliability;Probability;Optimization,,2153-0017,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Lifelong localization of a mobile service-robot in everyday indoor environments using omnidirectional vision,S. Hochdorfer and M. Lutz and C. Schlegel,,2009,IEEE Index Terms,161--166,,"SLAM (Simultaneous Localization and Mapping) mechanisms are a key component towards advanced service robotics applications. Currently, a major hurdle on the way to lifelong localization is the handling of the ever growing amount of landmarks over time. Therefore, the required resources in terms of memory and processing power are also growing over time.",,10.1109/TEPRA.2009.5339626,,,,Indoor environments;Simultaneous localization and mapping;Upper bound;Clustering algorithms;Uncertainty;Robot vision systems;Robot localization;Observability;Global Positioning System;Mobile computing,,2325-0534,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Towards a robust visual SLAM approach: Addressing the challenge of life-long operation,S. Hochdorfer and C. Schlegel,,2009,IEEE Index Terms,1--6,,"Localization and mapping are fundamental problems in service robotics. Knowledge about the own pose and representations of the environment are needed for a series of high level applications. Service robots should be designed for life-long and robust operation in dynamic environments. The contribution of this paper is twofold. First, an approach to address the ever growing number of landmarks in life-long operation is presented. Typically, SLAM approaches just accumulate features over time and do not discard them anymore. Therefore, the required resources in terms of memory and processing power are growing over time. In our approach, the absolute number of landmarks can be restricted by an upper bound since we introduce a method to specifically select and replace landmarks once the upper bound has been reached. The second contribution is related to improving the robustness of the landmark assignment problem in case of image based features as needed with natural landmarks. The approach has been successfully evaluated in a real world experiment on a Pioneer-3DX platform within a complex unmodified indoor environment.",,,https://ieeexplore.ieee.org/document/5174794,,,Robustness;Simultaneous localization and mapping;Upper bound;Service robots;Computer science;Application software;Indoor environments;Collaboration;Euclidean distance,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Robust Loop-Closure Detection with a Learned Illumination Invariant Representation for Robot vSLAM,S. Chen and J. Wu and Y. Wang and L. Zhou and Q. Lu and Y. Zhang,,2019,IEEE Index Terms,342--347,,"Robust loop-closure detection plays a key role for the long-term robot visual Simultaneous Localization and Mapping (SLAM) in indoor or outdoor environment, due to illumination changes can greatly affect the accuracy of online image matching, and keypoints may fail to match between images taken at the same location but different seasons. In this paper, we propose a robust loop-closure detection method for robot visual SLAM, which adopts invariant representation as image descriptors composed of learned features and adapts to changes in illumination and seasons. We evaluate our method on real datasets and demonstrate its excellent ability to handle illumination changes.",,10.1109/ICARM.2019.8833730,,,,Visualization;Simultaneous localization and mapping;Lighting;Feature extraction;Mechatronics;Image matching;Visual SLAM;Loop Closure Detection;Visual Place Recognition;Illumination Invariant Feature;Moblie Robot;Convolutional Neural Network,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-term human affordance maps,R. Limosani and L. Y. Morales and J. Even and F. Ferreri and A. Watanabe and F. Cavallo and P. Dario and N. Hagita,,2015,IEEE Index Terms,5748--5754,,"This paper presents a work on mapping the use of space by humans in long periods of time. Daily geometric maps with the same coordinate frame were generated with SLAM, and in a similar manner, daily affordance density maps (places people use) were generated with the output of a human tracker running on the robot. The contribution of the paper is two-fold: an approach to detect geometric changes to cluster them in similar geometric configurations and the building of geometric and affordance composite maps on each cluster. This approach avoids the loss of long term retrieved information. Geometric similarity was computed using a normal distance approach on the maps. The analysis was performed on data collected by a mobile robot for a period of 4 months accumulating data equivalent to 70 days. Experimental results show that the system is capable of detecting geometric changes in the environment and clustering similar geometric configurations.",,10.1109/IROS.2015.7354193,,,,Robot kinematics;Buildings;Navigation;Robot sensing systems;Layout;Geometry,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,"PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization",P. Egger and P. V. K. Borges and G. Catt and A. Pfrunder and R. Siegwart and R. Dubé,,2018,IEEE Index Terms,3430--3437,,"Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.",,10.1109/IROS.2018.8593854,,,,Simultaneous localization and mapping;Three-dimensional displays;Laser radar;Optimization;Feature extraction,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Tightly Coupled Semantic RGB-D Inertial Odometry for Accurate Long-Term Localization and Mapping,N. Patel and F. Khorrami and P. Krishnamurthy and A. Tzes,,2019,IEEE Index Terms,523--528,,"In this paper, we utilize semantically enhanced feature matching and visual inertial bundle adjustment to improve the robustness of odometry especially in feature-sparse environments. A novel semantically enhanced feature matching algorithm is developed for robust: 1) medium and long-term tracking, and 2) loop-closing. Additionally, a semantic visual inertial bundle adjustment algorithm is introduced to robustly estimate pose in presence of ambiguous correspondences or in feature sparse environment. Our tightly coupled semantic RGB-D odometry approach is demonstrated on a real world indoor dataset collected using our unmanned ground vehicle (UGV). Our approach improves traditional visual odometry relying on low-level geometric features like corners, points, and planes for localization and mapping. Additionally, prior approaches are limited due to their sensitivity to scene geometry and changes in light intensity. The semantic inertial odometry is especially important to significantly reduce drifts in longer intervals.",,10.1109/ICAR46387.2019.8981658,,,,,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-term simultaneous localization and mapping with generic linear constraint node removal,N. Carlevaris-Bianco and R. M. Eustice,,2013,IEEE Index Terms,1034--1041,,"This paper reports on the use of generic linear constraint (GLC) node removal as a method to control the computational complexity of long-term simultaneous localization and mapping. We experimentally demonstrate that GLC provides a principled and flexible tool enabling a wide variety of complexity management schemes. Specifically, we consider two main classes: batch multi-session node removal, in which nodes are removed in a batch operation between mapping sessions, and online node removal, in which nodes are removed as the robot operates. Results are shown for 34.9 h of real-world indoor-outdoor data covering 147.4 km collected over 27 mapping sessions spanning a period of 15 months.",,10.1109/IROS.2013.6696478,,,,Simultaneous localization and mapping;Approximation methods;Computational complexity;Markov processes,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,View management for lifelong visual maps,N. Banerjee and R. C. Connolly and D. Lisin and J. Briggs and M. E. Munich,,2019,IEEE Index Terms,7871--7878,,"The time complexity of making observations and loop closures in a graph-based visual SLAM system is a function of the number of views stored [1], [2]. Clever algorithms, such as approximate nearest neighbor search, can make this function sub-linear. Despite this, over time the number of views can still grow to a point at which the speed and/or accuracy of the system becomes unacceptable, especially in computation- and memory-constrained SLAM systems. However, not all views are created equal. Some views are rarely observed, because they have been created in an unusual lighting condition, or from low quality images, or in a location whose appearance has changed. These views can be removed to improve the overall performance of a SLAM system. In this paper, we propose a method for pruning views in a visual SLAM system to maintain its speed and accuracy for long term use.",,10.1109/IROS40897.2019.8968245,,,,,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Lifelong Mapping using Adaptive Local Maps,N. Banerjee and D. Lisin and J. Briggs and M. Llofriu and M. E. Munich,,2019,IEEE Index Terms,1--8,,"Occupancy mapping enables a mobile robot to make intelligent planning decisions to accomplish its tasks. Adaptive local maps is an algorithm which represents the occupancy information as a set of overlapping local maps anchored to poses in the robot's trajectory. At any time, a global occupancy map can be rendered from the local maps to be used for path planning. The advantage of this approach is that the occupancy information stays consistent despite the changes in the pose estimates resulting from loop closures and localization updates. The disadvantage, however, is that the number of local maps grows over time. For long robot runs, or for multiple runs in the same space, this growth will result in redundant occupancy information, which will in turn increase the time it takes to render the global map, as well as the memory footprint of the system. In this paper, we propose a novel approach for the maintenance of an adaptive local maps system, which intelligently prunes redundant local maps, ensuring the robustness and stability required for lifelong mapping.",,10.1109/ECMR.2019.8870347,,,,Simultaneous localization and mapping;Uncertainty;Mobile robots;Trajectory,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,SDF-Loc: Signed Distance Field based 2D Relocalization and Map Update in Dynamic Environments,M. Zhang and Y. Chen and M. Li,,2019,IEEE Index Terms,1997--2004,,"To empower an autonomous robot to perform long-term navigation in a given area, a concurrent localization and map update algorithm is required. In this paper, we tackle this problem by providing both theoretical analysis and algorithm design for robotic systems equipped with 2D laser range finders. The first key contribution of this paper is that we propose a hybrid signed distance field (SDF) framework for laser based localization. The proposed hybrid SDF integrates two methods with complementary characteristics, namely Euclidean SDF (ESDF) and Truncated SDF (TSDF). With our framework, accurate pose estimation and fast map update can be performed simultaneously. Moreover, we introduce a novel sliding window estimator which attains better accuracy by consistently utilizing sensor and map information with both scan-to-scan and scan-to-map data association. Real-world experimental results demonstrate that the proposed algorithm can be used for commercial robots in various environments with long-term usage. Experiments also show that our approach outperforms competing approaches by a wide margin.",,10.23919/ACC.2019.8814347,,,,Optimization;Robot sensing systems;Lasers;Measurement by laser beam;Two dimensional displays;Pose estimation,,2378-5861,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Obstacle Persistent Adaptive Map Maintenance for Autonomous Mobile Robots using Spatio-temporal Reasoning,M. L. Pitschl and M. W. Pryor,,2019,IEEE Index Terms,1023--1028,,"Mobile robotic systems operate in increasingly realistic scenarios even as users have increased expectations for the duration of autonomous tasks. Mobile robots face unique challenges when operating in environments that change over time, where systems must maintain an accurate representation of the environment with respect to both spatial and temporal dimensions. This paper describes a spatio-temporal technique for extending the autonomy of a mobile robot in a changing environment. This new technique called Obstacle Persistent Adaptive Map Maintenance (OPAMM) uses navigation data collected during normal operations to perform periodic self-maintenance of its environment model. OPAMM implements a probabilistic feature persistence model to predict the survival state of obstacles and update the world model. Maintaining an accurate world model is necessary for extending the long-term autonomy of robots in realistic scenarios. Results show that robots using OPAMM had localizations scores higher than other methods, thus reducing long-term localization degradation.",,10.1109/COASE.2019.8843095,,,,Conferences;Automation;Computer aided software engineering,,2161-8089,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Predictive and adaptive maps for long-term visual navigation in changing environments,L. Halodová and E. Dvo?ráková and F. Majer and T. Vintr and O. M. Mozos and F. Dayoub and T. Krajník,,2019,IEEE Index Terms,7033--7039,,"In this paper, we compare different map management techniques for long-term visual navigation in changing environments. In this scenario, the navigation system needs to continuously update and refine its feature map in order to adapt to the environment appearance change. To achieve reliable long-term navigation, the map management techniques have to (i) select features useful for the current navigation task, (ii) remove features that are obsolete, (iii) and add new features from the current camera view to the map. We propose several map management strategies and evaluate their performance with regard to the robot localisation accuracy in long-term teach-and-repeat navigation. Our experiments, performed over three months, indicate that strategies which model cyclic changes of the environment appearance and predict which features are going to be visible at a particular time and location, outperform strategies which do not explicitly model the temporal evolution of the changes.",,10.1109/IROS40897.2019.8967994,,,,,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Learning Matchable Image Transformations for Long-Term Metric Visual Localization,L. Clement and M. Gridseth and J. Tomasi and J. Kelly,IEEE Robotics and Automation Letters,2020,IEEE Index Terms,1492--1499,5,"Long-term metric self-localization is an essential capability of autonomous mobile robots, but remains challenging for vision-based systems due to appearance changes caused by lighting, weather, or seasonal variations. While experience-based mapping has proven to be an effective technique for bridging the `appearance gap,' the number of experiences required for reliable metric localization over days or months can be very large, and methods for reducing the necessary number of experiences are needed for this approach to scale. Taking inspiration from color constancy theory, we learn a nonlinear RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature matches for images captured under different lighting and weather conditions, and use it as a pre-processing step in a conventional single-experience localization pipeline to improve its robustness to appearance change. We train this mapping by approximating the target non-differentiable localization pipeline with a deep neural network, and find that incorporating a learned low-dimensional context feature can further improve cross-appearance feature matching. Using synthetic and real-world datasets, we demonstrate substantial improvements in localization performance across day-night cycles, enabling continuous metric localization over a 30-hour period using a single mapping experience, and allowing experience-based localization to scale to long deployments with dramatically reduced data requirements.",,10.1109/LRA.2020.2967659,,,,Pipelines;Feature extraction;Visualization;Training;Measurement;Lighting;Robustness;Deep learning in robotics and automation;visual learning;visual-based navigation;localization,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Sequence-based mapping for probabilistic visual loop-closure detection,K. A. Tsintotas and L. Bampis and S. An and G. F. Fragulis and S. G. Mouroutsos and A. Gasteratos,,2021,IEEE Index Terms,1--6,,"During simultaneous localization and mapping, the robot should build a map of its surroundings and simultaneously estimate its pose in the generated map. However, a fundamental task is to detect loops, i.e., previously visited areas, allowing consistent map generation. Moreover, within long-term mapping, every autonomous system needs to address its scalability in terms of storage requirements and database search. In this paper, we present a low-complexity sequence-based visual loop-closure detection pipeline. Our system dynamically segments the traversed route through a feature matching technique in order to define sub-maps. In addition, visual words are generated incrementally for the corresponding sub-maps representation. Comparisons among these sequences-of-images are performed thanks to probabilistic scores originated from a voting scheme. When a candidate sub-map is indicated, global descriptors are utilized for image-to-image pairing. Our evaluation took place on several publicly-available datasets exhibiting the system&#x2019;s low complexity and high recall compared to other state-of-the-art approaches.",,10.1109/IST50367.2021.9651458,,,,Visualization;Vocabulary;Simultaneous localization and mapping;Databases;Pipelines;Probabilistic logic;Feature extraction,,1558-2809,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Monocular Localization in HD Maps by Combining Semantic Segmentation and Distance Transform,J.-H. Pauls and K. Petek and F. Poggenhans and C. Stiller,,2020,IEEE Index Terms,4595--4601,,"Easy, yet robust long-term localization is still an open topic in research. Existing approaches require either dense maps, expensive sensors, specialized map features or proprietary detectors.We propose using semantic segmentation on a monocular camera to localize directly in a HD map as used for automated driving. This combines lightweight, yet powerful HD maps with the simplicity of monocular vision and the flexibility of neural networks.The major challenges arising from this combination are data association and robustness against misdetections. Association is solved efficiently by applying distance transform on binary per-class images. This provides not only a fast lookup table for a smooth gradient as needed for pose-graph optimization, but also dynamic association by default.A sliding-window pose graph optimization combines single image detections with vehicle odometry, smoothing results and helping overcome even misclassifications in consecutive frames.Evaluation against a highly accurate 6D visual localization shows that our approach can achieve accuracy levels as required for automated driving, being one of the most lightweight and flexible methods to do so.",,10.1109/IROS45743.2020.9341003,,,,Location awareness;Semantics;Neural networks;Transforms;Cameras;Vehicle dynamics;Optimization,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Research on object recognition using bag of word model for mobile robot navigation,J.-F. Yang and K. Wang and M.-A. Li and L. Liu,,2011,IEEE Index Terms,1735--1740,,"Robust long term positioning for autonomous mobile robots is essential for many applications. Key to a successful visual SLAM system is correctly recognizing the objects and labeling where the robot is. Local image features are popular with constructing object recognition system, which are invariant to image scaling, translation, rotation, and partially invariant to illumination changes and affine. In this paper, we proposed an object recognition method based on the bag of word model, mainly idea includes three steps as follows: firstly, a set of local image patches are sampled using a key point detector, and each patch is a descriptor based on scale invariant feature transform. Then outliers are removed by RANSAC algorithm, and the resulting distribution of descriptors is quantified by using vector quantization against a pre-specified codebook to convert it to a histogram of votes for codebook centers. Finally, a KNN algorithm is used to classify images through the resulting global descriptor vector. The experimental results show that our proposed method has a better performance against the previous methods.",,10.1109/ICMA.2011.5986295,,,,Feature extraction;Object recognition;Computational modeling;Training;Databases;Testing;Visualization;scale invariant feature transform (SIFT);bag of word (BOW);object recognition;robot navigation,,2152-744X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-Term Map Maintenance Pipeline for Autonomous Vehicles,J. S. Berrio and S. Worrall and M. Shan and E. Nebot,IEEE Transactions on Intelligent Transportation Systems,2021,IEEE Index Terms,1--14,,"For autonomous vehicles to operate persistently in a typical urban environment, it is essential to have high accuracy position information. This requires a mapping and localisation system that can adapt to changes over time. A localisation approach based on a single-survey map will not be suitable for long-term operation as it does not incorporate variations in the environment. In this paper, we present new algorithms to maintain a featured-based map. A map maintenance pipeline is proposed that can continuously update a map with the most relevant features taking advantage of the changes in the surroundings. Our pipeline detects and removes transient features based on their geometrical relationships with the vehicle's pose. Newly identified features became part of a new feature map and are assessed by the pipeline as candidates for the localisation map. By purging out-of-date features and adding newly detected features, we continually update the prior map to more accurately represent the most recent environment. We have validated our approach using the USyd Campus Dataset, which includes more than 18 months of data. The results presented demonstrate that our maintenance pipeline produces a resilient map which can provide sustained localisation performance over time.",,10.1109/TITS.2021.3094485,,,,Feature extraction;Pipelines;Maintenance engineering;Transient analysis;Visualization;Autonomous vehicles;Task analysis;Long-term localisation;feature-based map;map update.,,1558-0016,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Updating the visibility of a feature-based map for long-term maintenance,J. S. Berrio and J. Ward and S. Worrall and E. Nebot,,2019,IEEE Index Terms,1173--1179,,"Mobile vehicles operating in urban navigation applications can achieve high integrity localisation with high accuracy by using maps of the surroundings. To accomplish this, the map should always have an accurate representation of the environment. Thus, it is necessary to detect and remove the map components that no longer exist in the current environment. This maintains the map compactness and dependability while simplifying the data association problem. This paper addresses the problem of deletion of transient map components by taking advantage of the geometric connection between the map and agent poses in order to establish and update the visibility of each feature. Once the map is created an initial visibility vector is associated with every map element and updated over time. The visibility of a map element which no longer exists is reduced and ultimately removed from the map. We demonstrate our approach in a 2D feature-based map composed of poles and corners extracted from information provided by a Iidar sensor. The experimental results show the map update using a seven-month data set collected in the University of Sydney campus.",,10.1109/IVS.2019.8814189,,,,,,2642-7214,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,SemanticFusion: Dense 3D semantic mapping with convolutional neural networks,J. McCormac and A. Handa and A. Davison and S. Leutenegger,,2017,IEEE Index Terms,4628--4635,,"Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance - they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ?25Hz.",,10.1109/ICRA.2017.7989538,,,,Semantics;Simultaneous localization and mapping;Three-dimensional displays;Geometry;Two dimensional displays;Labeling;Cameras,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Simultaneous Localization and Mapping for Inspection Robots in Water and Sewer Pipe Networks: A Review,J. M. Aitken and M. H. Evans and R. Worley and S. Edwards and R. Zhang and T. Dodd and L. Mihaylova and S. R. Anderson,IEEE Access,2021,IEEE Index Terms,140173--140198,9,"At the present time, water and sewer pipe networks are predominantly inspected manually. In the near future, smart cities will perform intelligent autonomous monitoring of buried pipe networks, using teams of small robots. These robots, equipped with all necessary computational facilities and sensors (optical, acoustic, inertial, thermal, pressure and others) will be able to inspect pipes whilst navigating, self-localising and communicating information about the pipe condition and faults such as leaks or blockages to human operators for monitoring and decision support. The predominantly manual inspection of pipe networks will be replaced with teams of autonomous inspection robots that can operate for long periods of time over a large spatial scale. Reliable autonomous navigation and reporting of faults at this scale requires effective localization and mapping, which is the estimation of the robot’s position and its surrounding environment. This survey presents an overview of state-of-the-art works on robot simultaneous localization and mapping (SLAM) with a focus on water and sewer pipe networks. It considers various aspects of the SLAM problem in pipes, from the motivation, to the water industry requirements, modern SLAM methods, map-types and sensors suited to pipes. Future challenges such as robustness for long term robot operation in pipes are discussed, including how making use of prior knowledge, e.g. geographic information systems (GIS) can be used to build map estimates, and improve multi-robot SLAM in the pipe environment.",,10.1109/ACCESS.2021.3115981,,,,Simultaneous localization and mapping;Robots;Sensors;Inspection;Service robots;Water resources;Location awareness;Water;sewer;network;pipe networks;robots;SLAM;data fusion;Bayesian estimation;visual odometry;laser and lidar scanning,,2169-3536,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Simultaneous map building and localization for an autonomous mobile robot,J. J. Leonard and H. F. Durrant-Whyte,,1991,IEEE Index Terms,1442--1447vol.3,,"Discusses a significant open problem in mobile robotics: simultaneous map building and localization, which the authors define as long-term globally referenced position estimation without a priori information. This problem is difficult because of the following paradox: to move precisely, a mobile robot must have an accurate environment map; however, to build an accurate map, the mobile robot's sensing locations must be known precisely. In this way, simultaneous map building and localization can be seen to present a question of 'which came first, the chicken or the egg?' (The map or the motion?) When using ultrasonic sensing, to overcome this issue the authors equip the vehicle with multiple servo-mounted sonar sensors, to provide a means in which a subset of environment features can be precisely learned from the robot's initial location and subsequently tracked to provide precise positioning.<>",,10.1109/IROS.1991.174711,,,,Mobile robots;Vehicles;Sonar navigation;Robot sensing systems;Stochastic resonance;Sensor phenomena and characterization;Target tracking;Testing;National electric code;Humans,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,SLAM using LTE Multipath Component Delays,J. Chen and M. Zhu and F. Tufvesson,,2020,IEEE Index Terms,1--5,,"Cellular radio based localization can be an important complement or alternative to other localization technologies, as base stations continuously transmit signals of opportunity with beneficial positioning properties. In this paper, we use the long term evolution (LTE) cell-specific reference signal for this purpose. The multipath component delays are estimated by the ESPRIT algorithm, and the estimated multipath component delays of different snapshots are associated by global nearest neighbor with a Kalman filter. Rao-Blackwellized particle filter based simultaneous localization and mapping (SLAM) is then applied to estimate the position of user equipment and that of the base station and virtual transmitters. In a measurement campaign, data from one base station was logged, and the analysis based on the data shows that, at the end of the measurement, the SLAM performance is 11 meters better than that with only inertial measurement unit (IMU).",,10.1109/VTC2020-Spring48590.2020.9128437,,,,Delays;Simultaneous localization and mapping;Kalman filters;Receivers;Global navigation satellite system;Long Term Evolution;Base stations;MPC delay;SLAM;positioning;particle filter;LTE;CRS,,2577-2465,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Vehicle Navigation by Visual Navigational Aids for Automatic Lunar Mission,I. Ostroumov and N. Kuzmenko,,2021,IEEE Index Terms,71--75,,"Nowadays the question of Moon exploration is one of the key priorities. Many Lunar robotics missions are planned in near future by different space agencies around the world. Moon has considered to be the best place for a research station with long-term human presence for finding answers on fundamental questions about the universe. Automatic navigation of starship during a landing phase on Lunar surface is already solved with a help of inertial reference system aided visual algorithms. However, questions of automatic navigation of moving and flying vehicles on the Lunar surface are still open. Inertial navigation is limited by time, self-localization and mapping algorithms require multiple unique features of relief to guarantee required accuracy for successful automatic mission complication. In the current study, we propose the deployment of a network of visual navigational aids on the Lunar surface to support ground automatic missions. A weak atmosphere of the Moon makes effective visual beacons navigation system for long areas. A network of navigational aids includes primary and secondary ground stations which are blinking synchronously. Synchronization is supported by radio waves from the primary ground station. We consider the nature of crater relief to increase operational area of the system. The Time Difference of Arrival method is used to detect vehicle position by blinking network of visual navigational aids. In the numerical application, we consider different scenarios of network configuration to support automatic vehicle navigation inside of Tycho crater. Also, deployment of visual navigational aids network will increase the number of optical features which improve performance of already used positioning methods.",,10.1109/APUAVD53804.2021.9615417,,,,Visualization;Time difference of arrival;Surface waves;Moon;Radio navigation;Unmanned aerial vehicles;Synchronization;visual navigational aids;landing and ground vehicles;automatic mission;Lunar mission;Time Difference of Arrival,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,PERSES-a vision-based interactive mobile shopping assistant,H.-M. Gross and H.-J. Boehme,,2000,IEEE Index Terms,80--85vol.1,1,"The paper describes the general idea, the application scenario, and selected methodological approaches of our long term research project PERSES (PERsonal SErvice System). The aim of the project consists of the development of an interactive mobile shopping assistant that allows a continuous and intuitively understandable interaction with a customer in a home improvement store. Typical tasks we have to tackle are to detect and contact potential users in the operation area, to guide them to desired areas or articles within the store or to follow them as a mobile information kiosk while continuously observing their behavior. Due to the specificity of the interaction-oriented scenario and the characteristics of the operation area, we have focused on vision based methods for both human-robot interaction and robot navigation. Besides some methodological approaches, we present preliminary results of experiments achieved with our mobile robot PERSES in the store with an emphasis on vision based methods for user localization, map building and self-localization.",,10.1109/ICSMC.2000.884968,,,,Navigation;Robot vision systems;Mobile robots;Robustness;Robot kinematics;Human robot interaction;Adaptation model;Context modeling;Programmable control;Adaptive control,,1062-922X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation,H. Thomas and B. Agro and M. Gridseth and J. Zhang and T. D. Barfoot,,2021,IEEE Index Terms,14047--14053,,"We present a self-supervised learning approach for the semantic segmentation of lidar frames. Our method is used to train a deep point cloud segmentation architecture without any human annotation. The annotation process is automated with the combination of simultaneous localization and mapping (SLAM) and ray-tracing algorithms. By performing multiple navigation sessions in the same environment, we are able to identify permanent structures, such as walls, and disentangle short-term and long-term movable objects, such as people and tables, respectively. New sessions can then be performed using a network trained to predict these semantic labels. We demonstrate the ability of our approach to improve itself over time, from one session to the next. With semantically filtered point clouds, our robot can navigate through more complex scenarios, which, when added to the training pool, help to improve our network predictions. We provide insights into our network predictions and show that our approach can also improve the performances of common localization techniques.",,10.1109/ICRA48506.2021.9561701,,,,Training;Laser radar;Simultaneous localization and mapping;Annotations;Semantics;Ray tracing;Prediction algorithms,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Map Updating Revisited for Navigation Map : A mathematical way to perform map updating for autonomous mobile robot,H. Chen and Z. Wang and Q. Zhu,,2021,IEEE Index Terms,505--508,,"Simultaneous localization and mapping, SLAM can product a Map for autonomous robots and self-driving vehicle in navigation. In the actual environment, the scene changes frequently, which makes the old map no long reliable. Therefore, it is necessary to update such a map by an efficient and safely way. In this paper, we review the existing map updating, long-term localization methods and discuss about the challenges in this situation. We present a Map updating method in mathematical way which can update accurately. Our proposed method are tested in five indoor dataset and demonstrated feasibility.",,10.1109/IPEC51340.2021.9421197,,,,Location awareness;Computers;Simultaneous localization and mapping;Navigation;Image processing;Conferences;Reliability;map;updating;visual;point cloud,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-term 3D map maintenance in dynamic environments,F. Pomerleau and P. Krüsi and F. Colas and P. Furgale and R. Siegwart,,2014,IEEE Index Terms,3712--3719,,"New applications of mobile robotics in dynamic urban areas require more than the single-session geometric maps that have dominated simultaneous localization and mapping (SLAM) research to date; maps must be updated as the environment changes and include a semantic layer (such as road network information) to aid motion planning in dynamic environments. We present an algorithm for long-term localization and mapping in real time using a three-dimensional (3D) laser scanner. The system infers the static or dynamic state of each 3D point in the environment based on repeated observations. The velocity of each dynamic point is estimated without requiring object models or explicit clustering of the points. At any time, the system is able to produce a most-likely representation of underlying static scene geometry. By storing the time history of velocities, we can infer the dominant motion patterns within the map. The result is an online mapping and localization system specifically designed to enable long-term autonomy within highly dynamic environments. We validate the approach using data collected around the campus of ETH Zurich over seven months and several kilometers of navigation. To the best of our knowledge, this is the first work to unify long-term map update with tracking of dynamic objects.",,10.1109/ICRA.2014.6907397,,,,Three-dimensional displays;Dynamics;Simultaneous localization and mapping;Heuristic algorithms;Laser modes;Long-term mapping;dynamic obstacles;ICP;kd-tree;registration;scan matching;robot;SLAM,,1050-4729,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,ViPR: Visual-Odometry-aided Pose Regression for 6DoF Camera Localization,F. Ott and T. Feigl and C. Löffler and C. Mutschler,,2020,IEEE Index Terms,187--198,,"Visual Odometry (VO) accumulates a positional drift in long-term robot navigation tasks. Although Convolutional Neural Networks (CNNs) improve VO in various aspects, VO still suffers from moving obstacles, discontinuous observation of features, and poor textures or visual information. While recent approaches estimate a 6DoF pose either directly from (a series of) images or by merging depth maps with optical flow (OF), research that combines absolute pose regression with OF is limited.We propose ViPR, a novel modular architecture for longterm 6DoF VO that leverages temporal information and synergies between absolute pose estimates (from PoseNet-like modules) and relative pose estimates (from FlowNet-based modules) by combining both through recurrent layers. Experiments on known datasets and on our own Industry dataset show that our modular design outperforms state ofthe art in long-term navigation tasks.",,10.1109/CVPRW50498.2020.00029,,,,Cameras;Task analysis;Pose estimation;Feature extraction;Navigation;Optical imaging;Sensors,,2160-7516,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,SRAL: Shared Representative Appearance Learning for Long-Term Visual Place Recognition,F. Han and X. Yang and Y. Deng and M. Rentschler and D. Yang and H. Zhang,IEEE Robotics and Automation Letters,2017,IEEE Index Terms,1172--1179,2,"Place recognition, or loop closure detection, is an essential component to address the problem of visual simultaneous localization and mapping (SLAM). Long-term navigation of robots in outdoor environments introduces new challenges to enable life-long SLAM, including the strong appearance change resulting from vegetation, weather, and illumination variations across various times of the day, different days, months, or even seasons. In this paper, we propose a new shared representative appearance learning (SRAL) approach to address long-term visual place recognition. Different from previous methods using a single feature modality or a concatenation of multiple features, our SRAL method autonomously learns representative features that are shared in all scene scenarios, and then fuses the features together to represent the long-term appearance of environments observed by a robot during life-long navigation. By formulating SRAL as a regularized optimization problem, we use structured sparsity-inducing norms to model interrelationships of feature modalities. In addition, an optimization algorithm is developed to efficiently solve the formulated optimization problem, which holds a theoretical convergence guarantee. Extensive empirical study was performed to evaluate the SRAL method using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have shown that our SRAL method obtains superior performance for life-long place recognition using individual images, outperforms previous single image-based methods, and is capable of estimating the importance of feature modalities.",,10.1109/LRA.2017.2662061,,,,Visualization;Image recognition;Feature extraction;Simultaneous localization and mapping;Optimization;Navigation;Loop closure detection;long-term place recognition;simultaneous localization and mapping (SLAM);visual learning,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Robust Place Recognition and Loop Closing in Laser-Based SLAM for UGVs in Urban Environments,F. Cao and Y. Zhuang and H. Zhang and W. Wang,IEEE Sensors Journal,2018,IEEE Index Terms,4242--4252,18,"Robust place recognition plays a key role for the long-term autonomy of unmanned ground vehicles (UGVs) working in indoor or outdoor environments. Although most of the state-of-the-art that approaches for place recognition are vision-based, visual sensors lack adaptability in environments with poor or dynamically changing illumination. In this paper, a 3-D-laser-based place recognition algorithm is proposed to accomplish loop closure detection for simultaneous localization and mapping. An image model named bearing angle (BA) is adopted to convert 3-D laser points to 2-D images, and then ORB features extracted from BA images are utilized to perform scene matching. Since the computational cost for matching a query BA image with all the BA images in a database is too high to meet the requirement of performing real-time place recognition, a visual bag of words approach is used to improve search efficiency. Furthermore, a speed normalization algorithm and a 3-D geometry-based verification algorithm are proposed to complete the proposed place recognition algorithm. Experiments were conducted on two self-developed UGV platforms to verify the performance of the proposed method.",,10.1109/JSEN.2018.2815956,,,,Three-dimensional displays;Lasers;Visualization;Feature extraction;Sensors;Robustness;Lighting;Laser scanning;place recognition;simultaneous localization and mapping (SLAM);unmanned ground vehicles (UGVs),,1558-1748,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-Term Visual Localization Using Semantically Segmented Images,E. Stenborg and C. Toft and L. Hammarstrand,,2018,IEEE Index Terms,6484--6490,,"Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.",,10.1109/ICRA.2018.8463150,,,,Semantics;Cameras;Roads;Image segmentation;Visualization;Robustness;Feature extraction,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Onboard Detection-Tracking-Localization,D. Tang and Q. Fang and L. Shen and T. Hu,IEEE/ASME Transactions on Mechatronics,2020,IEEE Index Terms,1555--1565,25,"This article investigates long-term positioning of moving objects by monocular vision of a miniature fixed-wing unmanned aerial vehicle. It is challenging to perform a real-time onboard vision processing task, due to the strict payload capacity and power budget limitations of microflying vehicles. We propose a parallel onboard architecture that explicitly decouples the long-term positioning task into iteratively operated detection, tracking, and localization. The proposed approach is eventually called onboard detection-tracking-localization, namely oDTL. The detector automatically extracts and identifies the object from image frames captured at in-flight durations. A learning-based network is constructed to improve detection accuracy and robustness against ever-changing outdoor illumination conditions and flying viewpoints. The tracker follows the object within specified region-of-interest from frame to frame with lower computing consumption. To further reduce target-losing rate, a concept of blind zone is proposed and applied, and its boundaries in sequential images are also theoretically inferred. The position estimator maps the flying vehicle pose, the image coordinates, and calibration specifications into real-world positions of the moving target. An extended Kalman filter is developed for rough position estimation, and a smooth module is introduced for the refinement of the position. Three offline comparative experiments and three online experiments have been conducted respectively to testify the real-time capability of our approach. The collected experimental results also demonstrate the feasible accuracy and robustness of the overall solution within the specified flying onboard scenarios.",,10.1109/TMECH.2020.2976794,,,,Robustness;Real-time systems;Visualization;Lighting;Cameras;Three-dimensional displays;IEEE transactions;Detection;localization;miniature fixed-wing unmanned aerial vehicle (UAV);monocular;onboard vision;parallel architecture;positioning;tracking,,1941-014X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,SLAMinDB: Centralized graph databases for mobile robotics,D. Fourie and S. Claassens and S. Pillai and R. Mata and J. Leonard,,2017,IEEE Index Terms,6331--6337,,"Robotic systems typically require memory recall mechanisms for a variety of tasks including localization, mapping, planning, visualization etc. We argue for a novel memory recall framework that enables more complex inference schemas by separating the computation from its associated data. In this work we propose a shared, centralized data persistence layer that maintains an ensemble of online, situationally-aware robot states. This is realized through a queryable graph-database with an accompanying key-value store for larger data. In turn, this approach is scalable and enables a multitude of capabilities such as experience-based learning and long-term autonomy. Using multi-modal simultaneous localization and mapping and a few example use-cases, we demonstrate the versatility and extensible nature that centralized persistence and SLAMinDB can provide. In order to support the notion of life-long autonomy, we envision robots to be endowed with such a persistence model, enabling them to revisit previous experiences and improve upon their existing task-specific capabilities.",,10.1109/ICRA.2017.7989749,,,,Simultaneous localization and mapping;Computer architecture;Relational databases;Navigation,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,"Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation",C. Linegar and W. Churchill and P. Newman,,2015,IEEE Index Terms,90--97,,"This paper is about life-long vast-scale localisation in spite of changes in weather, lighting and scene structure. Building upon our previous work in Experience-based Navigation [1], we continually grow and curate a visual map of the world that explicitly supports multiple representations of the same place. We refer to these representations as experiences, where a single experience captures the appearance of an environment under certain conditions. Pedagogically, an experience can be thought of as a visual memory. By accumulating experiences we are able to handle cyclic appearance change (diurnal lighting, seasonal changes, and extreme weather conditions) and also adapt to slow structural change. This strategy, although elegant and effective, poses a new challenge: In a region with many stored representations - which one(s) should we try to localise against given finite computational resources? By learning from our previous use of the experience-map, we can make predictions about which memories we should consider next, conditioned on how the robot is currently localised in the experience-map. During localisation, we prioritise the loading of past experiences in order to minimise the expected computation required. We do this in a probabilistic way and show that this memory policy significantly improves localisation efficiency, enabling long-term autonomy on robots with limited computational resources. We demonstrate and evaluate our system over three challenging datasets, totalling 206km of outdoor travel. We demonstrate the system in a diverse range of lighting and weather conditions, scene clutter, camera occlusions, and permanent structural change in the environment.",,10.1109/ICRA.2015.7138985,,,,Robots;Visualization;Cameras;Trajectory;Meteorology;Lighting;Navigation,,1050-4729,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Input Uncertainty Sensitivity Enhanced Nonsingleton Fuzzy Logic Controllers for Long-Term Navigation of Quadrotor UAVs,C. Fu and A. Sarabakha and E. Kayacan and C. Wagner and R. John and J. M. Garibaldi,IEEE/ASME Transactions on Mechatronics,2018,IEEE Index Terms,725--734,23,"Input uncertainty, e.g., noise on the on-board camera and inertial measurement unit, in vision-based control of unmanned aerial vehicles (UAVs) is an inevitable problem. In order to handle input uncertainties as well as further analyze the interaction between the input and the antecedent fuzzy sets (FSs) of nonsingleton fuzzy logic controllers (NSFLCs), an input uncertainty sensitivity enhanced NSFLC has been developed in robot operating system using the C++ programming language. Based on recent advances in nonsingleton inference, the centroid of the intersection of the input and antecedent FSs (Cen-NSFLC) is utilized to calculate the firing strength of each rule instead of the maximum of the intersection used in traditional NSFLC (Tra-NSFLC). An 8-shaped trajectory, consisting of straight and curved lines, is used for the real-time validation of the proposed controllers for a trajectory following problem. An accurate monocular keyframe-based visual-inertial simultaneous localization and mapping (SLAM) approach is used to estimate the position of the quadrotor UAV in GPS-denied unknown environments. The performance of the Cen-NSFLC is compared with a conventional proportional-integral derivative (PID) controller, a singleton FLC and a Tra-NSFLC. All controllers are evaluated for different flight speeds, thus introducing different levels of uncertainty into the control problem. Visual-inertial SLAM-based real-time quadrotor UAV flight tests demonstrate that not only does the Cen-NSFLC achieve the best control performance among the four controllers, but it also shows better control performance when compared to their singleton counterparts. Considering the bias in the use of model-based controllers, e.g., PID, for the control of UAVs, this paper advocates an alternative method, namely Cen-NSFLCs, in uncertain working environments.",,10.1109/TMECH.2018.2810947,,,,Uncertainty;Simultaneous localization and mapping;Frequency selective surfaces;Real-time systems;IEEE transactions;Mechatronics;Fuzzy logic controller (FLC);input uncertainty sensitivity enhanced nonsingleton FLC (NSFLC);monocular visual-inertial simultaneous localization and mapping (SLAM);NSFLC;unmanned aerial vehicle (UAV),,1941-014X,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-Term Visual Inertial SLAM based on Time Series Map Prediction,B. Song and W. Chen and J. Wang and H. Wang,,2019,IEEE Index Terms,5364--5369,,"With the advance in the field of mobile robots, autonomous robots are required for long-term deployment in dynamic and complex environments. However, the performance of Visual Inertial SLAM systems in long-term operation is not satisfactory, and most long-term SLAM systems assumes periodic changes in the environment. This paper presents a novel solution for long-term monocular VI SLAM system in dynamic environment based on autoregression(AR) modeling and map prediction. Map points are first classified into static and semi-static map points according to a memory model. Modeling and prediction of the different states of semi-static map points are performed that are derived from time series models. The predicted map is then fused with the current map to achieve a better forecast for the next frame if the prediction is not satisfactory enough. Experiments are carried out on an embedded system. The results indicate that the map prediction is reliable and the proposed approach improves the performance of long-term localization and mapping in dynamic environments.",,10.1109/IROS40897.2019.8968017,,,,,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-Term Urban Vehicle Localization Using Pole Landmarks Extracted from 3-D Lidar Scans,A. Schaefer and D. Büscher and J. Vertens and L. Luft and W. Burgard,,2019,IEEE Index Terms,1--7,,"Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation [1]. In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15 months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy.",,10.1109/ECMR.2019.8870928,,,,Laser radar;Detectors;Reliability;Feature extraction;Urban areas;Trajectory;Roads,,,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Long-term topological localisation for service robots in dynamic environments using spectral maps,T. Krajník and J. P. Fentanes and O. M. Mozos and T. Duckett and J. Ekekrantz and M. Hanheide,,2014,IEEE Title,4537--4542,,"This paper presents a new approach for topological localisation of service robots in dynamic indoor environments. In contrast to typical localisation approaches that rely mainly on static parts of the environment, our approach makes explicit use of information about changes by learning and modelling the spatio-temporal dynamics of the environment where the robot is acting. The proposed spatio-temporal world model is able to predict environmental changes in time, allowing the robot to improve its localisation capabilities during long-term operations in populated environments. To investigate the proposed approach, we have enabled a mobile robot to autonomously patrol a populated environment over a period of one week while building the proposed model representation. We demonstrate that the experience learned during one week is applicable for topological localization even after a hiatus of three months by showing that the localization error rate is significantly lower compared to static environment representations.",,10.1109/IROS.2014.6943205,,,,Mathematical model;Three-dimensional displays;Predictive models;Fourier transforms;Feature extraction;Service robots;topological localisation;mobile robotics;spatio-temporal representations,,2153-0866,,,,44698.62149,44698.62149,sousarbarb,,Duplicated,
,Long-Term Localization With Time Series Map Prediction for Mobile Robots in Dynamic Environments,L. Wang and W. Chen and J. Wang,,2020,IEEE Title,1--7,,"In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments.",,10.1109/IROS45743.2020.9468884,,,,Location awareness;Correlation;Time series analysis;Predictive models;Brain modeling;Information filters;Real-time systems,,2153-0866,,,,44698.62149,44698.62149,sousarbarb,,Duplicated,
,Segmented Matching Method of Multi-Geophysics Field SLAM Data Based on LSTM,Z. Li and H. Yu and T. Shen and Z. Li,,2020,IEEE Abstract,147--151,,"At present, simultaneous localization and mapping (SLAM) has become an important method for autonomous underwater vehicles (AUVs) to realize long-term navigation. However, using only bathymetric data in unknown environment has its own disadvantages, that are low precision and large computational load. To tackle with requirements of high-precision navigation under large-scale and long-term voyage condition, a SLAM method and corresponding matching algorithm for integrating multi-geophysical field data are proposed. By dividing the feature data and location data of geophysical field obtained into various submaps and sub-segments during AUV sailing, the dominant navigation data of each segment is identified using long short-term memory network. Validity of the proposed method is done by simulation experiments. During the simulation, the loop closure detection of each submap is used, and the matching counter is set to check the correct matching rate. Finally, the matching results with single geophysics field data under the same conditions are compared with multi-geophysics field data and analyzed. The experimental results have demonstrated the feasibility and correctness of the proposed method.",,10.1109/ICUS50048.2020.9274964,,,,Technological innovation;Underwater vehicles;Timing;Simultaneous localization and mapping;Navigation;SLAM;LSTM;navigation;multi-geophysics field data;matching,,,,,,44698.62117,44698.62117,sousarbarb,,Duplicated,
,"Real-Time, Environmentally-Robust 3D LiDAR Localization",Y. Zhu and B. Xue and L. Zheng and H. Huang and M. Liu and R. Fan,,2019,IEEE Abstract,1--6,,"Localization, or position fixing, is an important problem in robotics research. In this paper, we propose a novel approach for long-term localization in a changing environment using 3D LiDAR. We first create the map of a real environment using GPS and LiDAR. Then, we divide the map into several small parts as the targets for cloud registration, which can not only improve the robustness but also reduce the registration time. We proposed a localization method called PointLocalization. PointLocalization allows us to fuse different kinds of odometers, which can optimize the accuracy and frequency of localization results. We evaluate our algorithm on an unmanned ground vehicle (UGV) using LiDAR and a wheel encoder, and obtain the localization results at more than 20 Hz after fusion. The algorithm can also localize the UGV in a 180-degree field of view (FOV). Using an outdated map captured six months ago, this algorithm shows great robustness, and the test results show that it can achieve an accuracy of 10 cm. PointLocalization has been tested for a period of more than six months in a crowded factory and has operated successfully over a distance of more than 2000 km.",,10.1109/IST48021.2019.9010305,,,,Laser radar;Global Positioning System;Simultaneous localization and mapping;Wheels;Cameras;Three-dimensional displays,,1558-2809,,,,44698.62117,44698.62117,sousarbarb,,Duplicated,
,Migratory birds-inspired navigation system for unmanned aerial vehicles,Y. Zhang and A. Chao and B. Zhao and H. Liu and X. Zhao,,2016,IEEE Abstract,276--281,,"Migration birds are able to navigate themselves during a long-distance journey without getting lost. They actually achieve just what is being sought for in the field of Unmanned Aerial Vehicles (UAVs): long-term autonomous navigation. This paper proposes an approach that combines the migration birds' sense principles with Micro-Electro-Mechanical System (MEMS) sensors to estimate UAVs position within GPS-denied environments. Camera, orientation and web-based maps (such as Google/Baidu Maps) are chosen to simulate the birds' localization cues: vision, earth magnetic field and mental maps. The visual odometry, Particle Filter theories are used in the proposed approach to integrate multiple sensor measurements. Real flying experiments are conducted both in indoor and outdoor environments. The results validate that the proposed migration-inspired visual odometry system can estimate the UAV localization effectively.",,10.1109/ICInfA.2016.7831835,,,,Cameras;Visualization;Unmanned aerial vehicles;Birds;Sensors;Navigation;Optical imaging;Migration birds;Unmanned Aerial Vehicles;Navigation,,,,,,44698.62117,44698.62117,sousarbarb,,Duplicated,
,Vision-Aided Multi-UAV Autonomous Flocking in GPS-Denied Environment,Y. Tang and Y. Hu and J. Cui and F. Liao and M. Lao and F. Lin and R. S. H. Teo,IEEE Transactions on Industrial Electronics,2019,IEEE Abstract,616--626,66,"This paper presents a sophisticated vision-aided flocking system for unmanned aerial vehicles (UAVs), which is able to operate in GPS-denied unknown environments for exploring and searching missions, and also able to adopt two types of vision sensors, day and thermal cameras, to measure relative motion between UAVs in different lighting conditions without using wireless communication. In order to realize robust vision-aided flocking, an integrated framework of tracking-learning-detection on the basis of multifeature coded correlation filter has been developed. To achieve long-term tracking, a redetector is trained online to adaptively reinitialize target for global sensing. An advanced flocking strategy is developed to address the autonomous multi-UAVs' cooperative flight. Light detection and ranging (LiDAR)-based navigation modules are developed for autonomous localization, mapping, and obstacle avoidance. Flight experiments of a team of UAVs have been conducted to verify the performance of this flocking system in a GPS-denied environment. The extensive experiments validate the robustness of the proposed vision algorithms in challenging scenarios.",,10.1109/TIE.2018.2824766,,,,Target tracking;Sensors;Cameras;Correlation;Trajectory;Robustness;Visualization;Flocking;unmanned system;visual sensing,,1557-9948,,,,44698.62117,44698.62117,sousarbarb,,Duplicated,
,Long-term Localization of Mobile Robots in Dynamic Changing Environments,X. Hu and J. Wang and W. Chen,,2018,IEEE Abstract,384--389,,"Long-term localization in dynamic changing environments is still a challenge in robotics. Traditional localization algorithms typically assume that the environment is static. However, in many real-world applications, such as parking lots and industrial plants, there are always dynamic objects (e.g. moving people) and semi-dynamic objects (e.g. parked cars and placed goods). In this paper we address this challenge by introducing a long-term localization algorithm in the environments which combine dynamic objects and semi-dynamic objects. Localizability-based-updating particle filter (LU-P F) algorithm is proposed here. Not only we use localizability matric to build an updating mechanism, but also it is used for localization system. Besides, we propose the dynamic factor as long-memory information to serve as prior knowledge, which improves the robustness of updating process. Experiments in parking lots demonstrate that our approach has better localization results with a more accurate up-to-date map compared to other methods.",,10.1109/CAC.2018.8623046,,,,Heuristic algorithms;Robots;Measurement by laser beam;Laboratories;Particle filters;Hidden Markov models;Mathematical model;long-term localization;map updating mechanism;localizability;dynamic factor,,,,,,44698.62117,44698.62117,sousarbarb,,Duplicated,
,Robot-Assisted Backscatter Localization for IoT Applications,S. Zhang and W. Wang and S. Tang and S. Jin and T. Jiang,IEEE Transactions on Wireless Communications,2020,IEEE Abstract,5807--5818,19,"Recent years have witnessed the rapid proliferation of backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such backscatter tags is crucial for IoT-based smart applications. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, which is laborious for deployment. To empower universal localization service, this paper presents Rover, an indoor localization system that localizes multiple backscatter tags without any start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing measurements from backscattered WiFi signals and inertial sensors to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues including interference among multiple tags, real-time processing, as well as the data marginalization problem in dealing with degenerated motions. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.",,10.1109/TWC.2020.2997393,,,,Wireless fidelity;Backscatter;Interference;Robot sensing systems;Receivers;Antenna arrays;Backscatter;localization;inertial sensor;channel state information,,1558-2248,,,,44698.62117,44698.62117,sousarbarb,,Duplicated,
,Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition,S. Siva and H. Zhang,,2018,IEEE Abstract,5175--5181,,"Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.",,10.1109/ICRA.2018.8461042,,,,Feature extraction;Sensor phenomena and characterization;Simultaneous localization and mapping;Optimization,,2577-087X,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,How to Match Tracks of Visual Features for Automotive Long-Term SLAM,S. Luthardt and C. Ziegler and V. Willert and J. Adamy,,2019,IEEE Abstract,934--941,,"Accurate localization is a vital prerequisite for future assistance or autonomous driving functions in intelligent vehicles. To achieve the required localization accuracy and availability, long-term visual SLAM algorithms like LLama-SLAM are a promising option. In such algorithms visual feature tracks, i. e. landmark observations over several consecutive image frames, have to be matched to feature tracks recorded days, weeks or months earlier. This leads to a more challenging matching problem than in short-term visual localization and known descriptor matching methods cannot be applied directly. In this paper, we devise several approaches to compare and match feature tracks and evaluate their performance on a long-term data set. With the proposed descriptor combination and masking (""CoMa"") method the best track matching performance is achieved with minor computational cost. This method creates a single combined descriptor for each feature track and furthermore increases the robustness by capturing the appearance variations of this track in a descriptor mask.",,10.1109/ITSC.2019.8916895,,,,Visualization;Feature extraction;Optimization;Simultaneous localization and mapping;Cameras;Robustness,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Lifelong localization of a mobile service-robot in everyday indoor environments using omnidirectional vision,S. Hochdorfer and M. Lutz and C. Schlegel,,2009,IEEE Abstract,161--166,,"SLAM (Simultaneous Localization and Mapping) mechanisms are a key component towards advanced service robotics applications. Currently, a major hurdle on the way to lifelong localization is the handling of the ever growing amount of landmarks over time. Therefore, the required resources in terms of memory and processing power are also growing over time.",,10.1109/TEPRA.2009.5339626,,,,Indoor environments;Simultaneous localization and mapping;Upper bound;Clustering algorithms;Uncertainty;Robot vision systems;Robot localization;Observability;Global Positioning System;Mobile computing,,2325-0534,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Towards a robust visual SLAM approach: Addressing the challenge of life-long operation,S. Hochdorfer and C. Schlegel,,2009,IEEE Abstract,1--6,,"Localization and mapping are fundamental problems in service robotics. Knowledge about the own pose and representations of the environment are needed for a series of high level applications. Service robots should be designed for life-long and robust operation in dynamic environments. The contribution of this paper is twofold. First, an approach to address the ever growing number of landmarks in life-long operation is presented. Typically, SLAM approaches just accumulate features over time and do not discard them anymore. Therefore, the required resources in terms of memory and processing power are growing over time. In our approach, the absolute number of landmarks can be restricted by an upper bound since we introduce a method to specifically select and replace landmarks once the upper bound has been reached. The second contribution is related to improving the robustness of the landmark assignment problem in case of image based features as needed with natural landmarks. The approach has been successfully evaluated in a real world experiment on a Pioneer-3DX platform within a complex unmodified indoor environment.",,,https://ieeexplore.ieee.org/document/5174794,,,Robustness;Simultaneous localization and mapping;Upper bound;Service robots;Computer science;Application software;Indoor environments;Collaboration;Euclidean distance,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Robust Loop-Closure Detection with a Learned Illumination Invariant Representation for Robot vSLAM,S. Chen and J. Wu and Y. Wang and L. Zhou and Q. Lu and Y. Zhang,,2019,IEEE Abstract,342--347,,"Robust loop-closure detection plays a key role for the long-term robot visual Simultaneous Localization and Mapping (SLAM) in indoor or outdoor environment, due to illumination changes can greatly affect the accuracy of online image matching, and keypoints may fail to match between images taken at the same location but different seasons. In this paper, we propose a robust loop-closure detection method for robot visual SLAM, which adopts invariant representation as image descriptors composed of learned features and adapts to changes in illumination and seasons. We evaluate our method on real datasets and demonstrate its excellent ability to handle illumination changes.",,10.1109/ICARM.2019.8833730,,,,Visualization;Simultaneous localization and mapping;Lighting;Feature extraction;Mechatronics;Image matching;Visual SLAM;Loop Closure Detection;Visual Place Recognition;Illumination Invariant Feature;Moblie Robot;Convolutional Neural Network,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Relocalization With Submaps: Multi-Session Mapping for Planetary Rovers Equipped With Stereo Cameras,R. Giubilato and M. Vayugundla and M. J. Schuster and W. Stürzl and A. Wedler and R. Triebel and S. Debei,IEEE Robotics and Automation Letters,2020,IEEE Abstract,580--587,5,"To enable long term exploration of extreme environments such as planetary surfaces, heterogeneous robotic teams need the ability to localize themselves on previously built maps. While the Localization and Mapping problem for single sessions can be efficiently solved with many state of the art solutions, place recognition in natural environments still poses great challenges for the perception system of a robotic agent. In this paper we propose a relocalization pipeline which exploits both 3D and visual information from stereo cameras to detect matches across local point clouds of multiple SLAM sessions. Our solution is based on a Bag of Binary Words scheme where binarized SHOT descriptors are enriched with visual cues to recall in a fast and efficient way previously visited places. The proposed relocalization scheme is validated on challenging datasets captured using a planetary rover prototype on Mount Etna, designated as a Moon analogue environment.",,10.1109/LRA.2020.2964157,,,,Three-dimensional displays;Visualization;Simultaneous localization and mapping;Vocabulary;Pipelines;Cameras;Localization;space robotics and automation;mapping,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Research of large-scale offline map management in visual SLAM,Q. Shen and H. Sun and P. Ye,,2017,IEEE Abstract,215--219,,"This paper presents a novel method of visual simultaneous localization and mapping (SLAM), which is a method of real-time localization and mapping. It is important for a mobile robot to build a map while autonomously navigation. Due to the complexity of the robot work scene, the SLAM method proposed in this paper optimizes map management. It will cost a lot of time and space when a robot long-term works in a same large scene. Therefore, we propose a method in this paper to save a detail map as an offline map in advance. At the same time in order to facilitate the follow-up optimization, the offline map can be divided into several sub-graphs according to the similarity of the scene. Since the segmented offline map has been saved to local system, it can be loaded at any time to localization and obtain the pose of current frame.",,10.1109/ICSAI.2017.8248292,,,,Simultaneous localization and mapping;Image segmentation;Cameras;Real-time systems;Optimization;Symmetric matrices;SLAM;offline map;segment graph;normalized-cut,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition,P. Yin and L. Xu and Z. Liu and L. Li and H. Salman and Y. He and W. Xu and H. Wang and H. Choset,,2018,IEEE Abstract,1162--1167,,"Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.",,10.1109/IROS.2018.8593562,,,,Octrees;Laser radar;Task analysis;Decoding;Simultaneous localization and mapping;Generative adversarial networks,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships,P. Gao and H. Zhang,,2020,IEEE Abstract,1070--1076,,"Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks.",,10.1109/ICRA40945.2020.9196906,,,,Visualization;Simultaneous localization and mapping;Robustness;Strain;Image recognition;Tensile stress,,2577-087X,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Preventing and Correcting Mistakes in Lifelong Mapping,N. Banerjee and D. Lisin and V. Albanese and Z. Zhu and S. R. Lenser and J. Shriver and T. Ramaswamy and J. Briggs and P. Fong,,2021,IEEE Abstract,1--8,,"A Graph SLAM system is only as good as the edges in its pose graph. Critical mistakes in the generation of these edges can instantly render a map inconsistent, misleading, and ultimately unusable. For a lifelong mapping system, where the map is updated continuously, avoiding these errors altogether is infeasible. Instead, we propose a system for detection of and recovery from severe errors in edge generation. Our system remedies both edges created by view observations and edges created by an odometry motion model. For observation edges, we pair a novel method for monitoring ambiguous views with an intelligent graph-merging algorithm capable of rejecting a relocalization in progress. For motion edges, we propose a qualitative geometric approach for detecting structural aberrations characteristic of odometry failures. We conclude with an analysis of our results based on an empirical study of thousands of robot runs.",,10.1109/ECMR50962.2021.9568826,,,,Location awareness;Simultaneous localization and mapping;Image edge detection;Europe;Mobile robots;Monitoring,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,SDF-Loc: Signed Distance Field based 2D Relocalization and Map Update in Dynamic Environments,M. Zhang and Y. Chen and M. Li,,2019,IEEE Abstract,1997--2004,,"To empower an autonomous robot to perform long-term navigation in a given area, a concurrent localization and map update algorithm is required. In this paper, we tackle this problem by providing both theoretical analysis and algorithm design for robotic systems equipped with 2D laser range finders. The first key contribution of this paper is that we propose a hybrid signed distance field (SDF) framework for laser based localization. The proposed hybrid SDF integrates two methods with complementary characteristics, namely Euclidean SDF (ESDF) and Truncated SDF (TSDF). With our framework, accurate pose estimation and fast map update can be performed simultaneously. Moreover, we introduce a novel sliding window estimator which attains better accuracy by consistently utilizing sensor and map information with both scan-to-scan and scan-to-map data association. Real-world experimental results demonstrate that the proposed algorithm can be used for commercial robots in various environments with long-term usage. Experiments also show that our approach outperforms competing approaches by a wide margin.",,10.23919/ACC.2019.8814347,,,,Optimization;Robot sensing systems;Lasers;Measurement by laser beam;Two dimensional displays;Pose estimation,,2378-5861,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,"Sensors, SLAM and Long-term Autonomy: A Review",M. Zaffar and S. Ehsan and R. Stolkin and K. M. Maier,,2018,IEEE Abstract,285--290,,"Simultaneous Localization and Mapping, commonly known as SLAM, has been an active research area in the field of Robotics over the past three decades. For solving the SLAM problem, every robot is equipped with either a single sensor or a combination of similar/different sensors. This paper attempts to review, discuss, evaluate and compare these sensors. Keeping an eye on future, this paper also assesses the characteristics of these sensors against factors critical to the long-term autonomy challenge.",,10.1109/AHS.2018.8541483,,,,Cameras;Simultaneous localization and mapping;Sensor phenomena and characterization;Laser radar;Acoustic sensors;SLAM;Long-term Autonomy;Sensors,,2471-769X,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Tightly-Coupled Monocular Visual-Odometric SLAM Using Wheels and a MEMS Gyroscope,M. Quan and S. Piao and M. Tan and S.-S. Huang,IEEE Access,2019,IEEE Abstract,97374--97389,7,"In this paper, we present a novel tightly coupled probabilistic monocular visual-odometric simultaneous localization and mapping (VOSLAM) algorithm using wheels and a MEMS gyroscope, which can provide accurate, robust, and long-term localization for ground robots. First, we present a novel odometer preintegration theory on manifold; it integrates the wheel encoder measurements and gyroscope measurements to a relative motion constraint that is independent of the linearization point and carefully addresses the uncertainty propagation and gyroscope bias correction. Based on the preintegrated odometer measurement model, we also introduce the odometer error term and tightly integrate it into the visual optimization framework. Then, in order to bootstrap the VOSLAM system, we propose a simple map initialization method. Finally, we present a complete localization mechanism to maximally exploit both sensing cues, which provides different strategies for motion tracking when: 1) both measurements are available; 2) visual measurements are not available; and 3) wheel encoders experience slippage, thereby ensuring the accurate and robust motion tracking. The proposed algorithm is evaluated by performing extensive experiments, and the experimental results demonstrate the superiority of the proposed system.",,10.1109/ACCESS.2019.2930201,,,,Wheels;Visualization;Simultaneous localization and mapping;Motion measurement;Optimization;Motion estimation;sensor fusion;simultaneous localization and mapping,,2169-3536,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Map Management for Efficient Long-Term Visual Localization in Outdoor Environments,M. Bürki and M. Dymczyk and I. Gilitschenski and C. Cadena and R. Siegwart and J. Nieto,,2018,IEEE Abstract,682--688,,"We present a complete map management process for a visual localization system designed for multi-vehicle long-term operations in resource constrained outdoor environments. Outdoor visual localization generates large amounts of data that need to be incorporated into a lifelong visual map in order to allow localization at all times and under all appearance conditions. Processing these large quantities of data is non-trivial, as it is subject to limited computational and storage capabilities both on the vehicle and on the mapping backend. We address this problem with a two-fold map update paradigm capable of, either, adding new visual cues to the map, or updating co-observation statistics. The former, in combination with offline map summarization techniques, allows enhancing the appearance coverage of the lifelong map while keeping the map size limited. On the other hand, the latter is able to significantly boost the appearance-based landmark selection for efficient online localization without incurring any additional computational or storage burden. Our evaluation in challenging outdoor conditions shows that our proposed map management process allows building and maintaining maps for precise visual localization over long time spans in a tractable and scalable fashion.",,10.1109/IVS.2018.8500432,,,,Visualization;Buildings;Robot sensing systems;Autonomous automobiles;Maintenance engineering;Bandwidth;Intelligent vehicles,,1931-0587,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Robust SLAM Systems: Are We There Yet?,M. Bujanca and X. Shi and M. Spear and P. Zhao and B. Lennox and M. Luján,,2021,IEEE Abstract,5320--5327,,"Progress in the last decade has brought about significant improvements in the accuracy and speed of SLAM systems, broadening their mapping capabilities. Despite these advancements, long-term operation remains a major challenge, primarily due to the wide spectrum of perturbations robotic systems may encounter.Increasing the robustness of SLAM algorithms is an ongoing effort, however it usually addresses a specific perturbation. Generalisation of robustness across a large variety of challenging scenarios is not well-studied nor understood. This paper presents a systematic evaluation of the robustness of open-source state-of-the-art SLAM algorithms with respect to challenging conditions such as fast motion, non-uniform illumination, and dynamic scenes. The experiments are performed with perturbations present both independently of each other, as well as in combination in long-term deployment settings in unconstrained environments (lifelong operation).The detailed results (approx. 20,000 experiments) along with comprehensive documentation of the benchmarking tool for integrating new datasets and evaluating SLAM algorithms not studied in this work are available at https://robustslam.github.io/evaluation.",,10.1109/IROS51168.2021.9636814,,,,Simultaneous localization and mapping;Systematics;Three-dimensional displays;Heuristic algorithms;Perturbation methods;Dynamics;Lighting,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Long-Term Localization With Time Series Map Prediction for Mobile Robots in Dynamic Environments,L. Wang and W. Chen and J. Wang,,2020,IEEE Abstract,1--7,,"In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments.",,10.1109/IROS45743.2020.9468884,,,,Location awareness;Correlation;Time series analysis;Predictive models;Brain modeling;Information filters;Real-time systems,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Learning Matchable Image Transformations for Long-Term Metric Visual Localization,L. Clement and M. Gridseth and J. Tomasi and J. Kelly,IEEE Robotics and Automation Letters,2020,IEEE Abstract,1492--1499,5,"Long-term metric self-localization is an essential capability of autonomous mobile robots, but remains challenging for vision-based systems due to appearance changes caused by lighting, weather, or seasonal variations. While experience-based mapping has proven to be an effective technique for bridging the `appearance gap,' the number of experiences required for reliable metric localization over days or months can be very large, and methods for reducing the necessary number of experiences are needed for this approach to scale. Taking inspiration from color constancy theory, we learn a nonlinear RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature matches for images captured under different lighting and weather conditions, and use it as a pre-processing step in a conventional single-experience localization pipeline to improve its robustness to appearance change. We train this mapping by approximating the target non-differentiable localization pipeline with a deep neural network, and find that incorporating a learned low-dimensional context feature can further improve cross-appearance feature matching. Using synthetic and real-world datasets, we demonstrate substantial improvements in localization performance across day-night cycles, enabling continuous metric localization over a 30-hour period using a single mapping experience, and allowing experience-based localization to scale to long deployments with dramatically reduced data requirements.",,10.1109/LRA.2020.2967659,,,,Pipelines;Feature extraction;Visualization;Training;Measurement;Lighting;Robustness;Deep learning in robotics and automation;visual learning;visual-based navigation;localization,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Research on object recognition using bag of word model for mobile robot navigation,J.-F. Yang and K. Wang and M.-A. Li and L. Liu,,2011,IEEE Abstract,1735--1740,,"Robust long term positioning for autonomous mobile robots is essential for many applications. Key to a successful visual SLAM system is correctly recognizing the objects and labeling where the robot is. Local image features are popular with constructing object recognition system, which are invariant to image scaling, translation, rotation, and partially invariant to illumination changes and affine. In this paper, we proposed an object recognition method based on the bag of word model, mainly idea includes three steps as follows: firstly, a set of local image patches are sampled using a key point detector, and each patch is a descriptor based on scale invariant feature transform. Then outliers are removed by RANSAC algorithm, and the resulting distribution of descriptors is quantified by using vector quantization against a pre-specified codebook to convert it to a histogram of votes for codebook centers. Finally, a KNN algorithm is used to classify images through the resulting global descriptor vector. The experimental results show that our proposed method has a better performance against the previous methods.",,10.1109/ICMA.2011.5986295,,,,Feature extraction;Object recognition;Computational modeling;Training;Databases;Testing;Visualization;scale invariant feature transform (SIFT);bag of word (BOW);object recognition;robot navigation,,2152-744X,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Integration of Monte Carlo Localization and place recognition for reliable long-term robot localization,J. Pérez and F. Caballero and L. Merino,,2014,IEEE Abstract,85--91,,"This paper proposes extending Monte Carlo Localization methods with visual information in order to build a long term robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position with the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based on datasets gathered with a real robot in challenging scenarios.",,10.1109/ICARSC.2014.6849767,,,,Robot sensing systems;Semiconductor lasers;Robot kinematics;Trajectory;Navigation,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Simultaneous Localization and Mapping for Inspection Robots in Water and Sewer Pipe Networks: A Review,J. M. Aitken and M. H. Evans and R. Worley and S. Edwards and R. Zhang and T. Dodd and L. Mihaylova and S. R. Anderson,IEEE Access,2021,IEEE Abstract,140173--140198,9,"At the present time, water and sewer pipe networks are predominantly inspected manually. In the near future, smart cities will perform intelligent autonomous monitoring of buried pipe networks, using teams of small robots. These robots, equipped with all necessary computational facilities and sensors (optical, acoustic, inertial, thermal, pressure and others) will be able to inspect pipes whilst navigating, self-localising and communicating information about the pipe condition and faults such as leaks or blockages to human operators for monitoring and decision support. The predominantly manual inspection of pipe networks will be replaced with teams of autonomous inspection robots that can operate for long periods of time over a large spatial scale. Reliable autonomous navigation and reporting of faults at this scale requires effective localization and mapping, which is the estimation of the robot’s position and its surrounding environment. This survey presents an overview of state-of-the-art works on robot simultaneous localization and mapping (SLAM) with a focus on water and sewer pipe networks. It considers various aspects of the SLAM problem in pipes, from the motivation, to the water industry requirements, modern SLAM methods, map-types and sensors suited to pipes. Future challenges such as robustness for long term robot operation in pipes are discussed, including how making use of prior knowledge, e.g. geographic information systems (GIS) can be used to build map estimates, and improve multi-robot SLAM in the pipe environment.",,10.1109/ACCESS.2021.3115981,,,,Simultaneous localization and mapping;Robots;Sensors;Inspection;Service robots;Water resources;Location awareness;Water;sewer;network;pipe networks;robots;SLAM;data fusion;Bayesian estimation;visual odometry;laser and lidar scanning,,2169-3536,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Weighted Grid Partitioning for Panel-Based Bathymetric SLAM,J. Jang and J. Kim,,2019,IEEE Abstract,1--6,,"Bathymetric navigation enables the long-term operation of autonomous underwater vehicles by reducing navigation drift errors with no need for GPS position fixes. In the case that a bathymetric map is not available, the simultaneous localization and mapping (SLAM) algorithm is required, but this increases computational complexity and memory requirement. Panel-based bathymetric SLAM could considerably reduce the computational burden. However, it may suffers from incorrect update when the vehicle does not belong to the updated panel. This study proposes a new update method, called weighted grid partitioning, which considers the probability distribution of a vehicle's location, and is more effective in terms of the map accuracy, computational burden, and memory usage compared to standard update methods. The feasibility of the proposed algorithm is verified through simulations.",,10.1109/OCEANSE.2019.8867531,,,,Simultaneous localization and mapping;Navigation;Probability distribution;Signal processing algorithms;Measurement uncertainty;Uncertainty;Predictive models,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Simultaneous map building and localization for an autonomous mobile robot,J. J. Leonard and H. F. Durrant-Whyte,,1991,IEEE Abstract,1442--1447vol.3,,"Discusses a significant open problem in mobile robotics: simultaneous map building and localization, which the authors define as long-term globally referenced position estimation without a priori information. This problem is difficult because of the following paradox: to move precisely, a mobile robot must have an accurate environment map; however, to build an accurate map, the mobile robot's sensing locations must be known precisely. In this way, simultaneous map building and localization can be seen to present a question of 'which came first, the chicken or the egg?' (The map or the motion?) When using ultrasonic sensing, to overcome this issue the authors equip the vehicle with multiple servo-mounted sonar sensors, to provide a means in which a subset of environment features can be precisely learned from the robot's initial location and subsequently tracked to provide precise positioning.<>",,10.1109/IROS.1991.174711,,,,Mobile robots;Vehicles;Sonar navigation;Robot sensing systems;Stochastic resonance;Sensor phenomena and characterization;Target tracking;Testing;National electric code;Humans,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,PERSES-a vision-based interactive mobile shopping assistant,H.-M. Gross and H.-J. Boehme,,2000,IEEE Abstract,80--85vol.1,1,"The paper describes the general idea, the application scenario, and selected methodological approaches of our long term research project PERSES (PERsonal SErvice System). The aim of the project consists of the development of an interactive mobile shopping assistant that allows a continuous and intuitively understandable interaction with a customer in a home improvement store. Typical tasks we have to tackle are to detect and contact potential users in the operation area, to guide them to desired areas or articles within the store or to follow them as a mobile information kiosk while continuously observing their behavior. Due to the specificity of the interaction-oriented scenario and the characteristics of the operation area, we have focused on vision based methods for both human-robot interaction and robot navigation. Besides some methodological approaches, we present preliminary results of experiments achieved with our mobile robot PERSES in the store with an emphasis on vision based methods for user localization, map building and self-localization.",,10.1109/ICSMC.2000.884968,,,,Navigation;Robot vision systems;Mobile robots;Robustness;Robot kinematics;Human robot interaction;Adaptation model;Context modeling;Programmable control;Adaptive control,,1062-922X,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Radar-on-Lidar: metric radar localization on prior lidar maps,H. Yin and Y. Wang and L. Tang and R. Xiong,,2020,IEEE Abstract,1--7,,"Radar and lidar, provided by two different range sensors, each has pros and cons of various perception tasks on mobile robots or autonomous driving. In this paper, a Monte Carlo system is used to localize the robot with a rotating radar sensor on 2D lidar maps. We first train a conditional generative adversarial network to transfer raw radar data to lidar data, and achieve reliable radar points from generator. Then an efficient radar odometry is included in the Monte Carlo system. Combining the initial guess from odometry, a measurement model is proposed to match the radar data and prior lidar maps for final 2D positioning. We demonstrate the effectiveness of the proposed localization framework on the public multisession dataset. The experimental results show that our system can achieve high accuracy for long-term localization in outdoor scenes.",,10.1109/RCAR49640.2020.9303291,,,,Laser radar;Radar;Sensors;Radar imaging;Robots;Three-dimensional displays;Two dimensional displays,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Incorporating environmental measurements in navigation,H. J. S. Feder and J. J. Leonard and C. M. Smith,,1998,IEEE Abstract,115--122,,"Extended missions in unknown regions present a significant navigational challenge for autonomous underwater vehicles (AUV). This paper investigates the long-term performance of a concurrent mapping and localization (CML) algorithm for the scenario of an AUV making observations of point features in the environment with a forward look sonar. Simulation results demonstrate that position estimates with long-term bounded errors of a few meters can be achieved under realistic assumptions about the vehicle, its sensors, and the environment. Potential failure modes of the algorithm, such as divergence and map slip, are discussed. CML technology can provide a significant improvement in the navigational capabilities of AUVs and can enable new missions in unmapped regions without reliance on acoustic beacons or surfacing for GPS resets.",,10.1109/AUV.1998.744447,,,,Sonar navigation;Remotely operated vehicles;Underwater acoustics;Performance analysis;Stochastic processes;Sea measurements;Jacobian matrices;Oceans;Automotive engineering;Marine technology,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Visual topometric localization,H. Badino and D. Huber and T. Kanade,,2011,IEEE Abstract,794--799,,"One of the fundamental requirements of an autonomous vehicle is the ability to determine its location on a map. Frequently, solutions to this localization problem rely on GPS information or use expensive three dimensional (3D) sensors. In this paper, we describe a method for long-term vehicle localization based on visual features alone. Our approach utilizes a combination of topological and metric mapping, which we call topometric localization, to encode the coarse topology of the route as well as detailed metric information required for accurate localization. A topometric map is created by driving the route once and recording a database of visual features. The vehicle then localizes by matching features to this database at runtime. Since individual feature matches are unreliable, we employ a discrete Bayes filter to estimate the most likely vehicle position using evidence from a sequence of images along the route. We illustrate the approach using an 8.8 km route through an urban and suburban environment. The method achieves an average localization error of 2.7 m over this route, with isolated worst case errors on the order of 10 m.",,10.1109/IVS.2011.5940504,,,,Vehicles;Visualization;Measurement;Databases;Feature extraction;Global Positioning System;Probability density function,,1931-0587,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Towards life-long mapping of dynamic environments using temporal persistence modeling,G. Tsamis and I. Kostavelis and D. Giakoumis and D. Tzovaras,,2021,IEEE Abstract,10480--10485,,"The contemporary SLAM mapping systems assume a static environment and build a map that is then used for mobile robot navigation disregarding the dynamic changes in this environment. The paper at hand presents a novel solution for the problem of life-long mapping that continually updates a metric map represented as a 2D occupancy grid in large scale indoor environments with movable objects such as people, robots, objects etc. suitable for industrial applications. We formalize each cell's occupancy as a failure analysis problem and contribute temporal persistence modeling (TPM), an algorithm for probabilistic prediction of the time that a cell in an observed location is expected to be “occupied” or “empty” given sparse prior observations from a task specific mobile robot. Our work is evaluated in Gazebo simulation environment against the nominal occupancy of cells and the estimated obstacles persistence. We also show that robot navigation with life-long mapping demands less replans and leads to more efficient navigation in highly dynamic environments.",,10.1109/ICPR48806.2021.9413161,,,,Measurement;Simultaneous localization and mapping;Navigation;Service robots;Predictive models;Probabilistic logic;Prediction algorithms,,1051-4651,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Lightweight SLAM with automatic orientation correction using 2D LiDAR scans,G. Péter and B. Kiss,,2020,IEEE Abstract,1--6,,"Simultaneous localization and mapping (SLAM) is about consistent maps in the long run. Loop closing is the most popular way for ensure long-term consistency in presence of multiple measurements by the same or multiple robots. Loop closure can be executed using raw odometrical data, but a more sophisticated, yet still light-weight method is presented in this paper: a landmark descriptor-based relative displacement calculation method for diminishing unwanted orientation errors that otherwise often lead to map inconsistency. Landmark descriptors are created using light detection and ranging (LiDAR) scans and the relation is calculated using scan-matching. The novelty of this research is a method providing long-term orientation and position correction without additional overhead between landmark detections, thus enabling simple agents to do the SLAM in a cooperative way.",,10.1109/ISMCR51255.2020.9263722,,,,Manganese;SLAM;LiDAR;mapping;orientation;correction;uncertainty,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Long-term 3D map maintenance in dynamic environments,F. Pomerleau and P. Krüsi and F. Colas and P. Furgale and R. Siegwart,,2014,IEEE Abstract,3712--3719,,"New applications of mobile robotics in dynamic urban areas require more than the single-session geometric maps that have dominated simultaneous localization and mapping (SLAM) research to date; maps must be updated as the environment changes and include a semantic layer (such as road network information) to aid motion planning in dynamic environments. We present an algorithm for long-term localization and mapping in real time using a three-dimensional (3D) laser scanner. The system infers the static or dynamic state of each 3D point in the environment based on repeated observations. The velocity of each dynamic point is estimated without requiring object models or explicit clustering of the points. At any time, the system is able to produce a most-likely representation of underlying static scene geometry. By storing the time history of velocities, we can infer the dominant motion patterns within the map. The result is an online mapping and localization system specifically designed to enable long-term autonomy within highly dynamic environments. We validate the approach using data collected around the campus of ETH Zurich over seven months and several kilometers of navigation. To the best of our knowledge, this is the first work to unify long-term map update with tracking of dynamic objects.",,10.1109/ICRA.2014.6907397,,,,Three-dimensional displays;Dynamics;Simultaneous localization and mapping;Heuristic algorithms;Laser modes;Long-term mapping;dynamic obstacles;ICP;kd-tree;registration;scan matching;robot;SLAM,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,SRAL: Shared Representative Appearance Learning for Long-Term Visual Place Recognition,F. Han and X. Yang and Y. Deng and M. Rentschler and D. Yang and H. Zhang,IEEE Robotics and Automation Letters,2017,IEEE Abstract,1172--1179,2,"Place recognition, or loop closure detection, is an essential component to address the problem of visual simultaneous localization and mapping (SLAM). Long-term navigation of robots in outdoor environments introduces new challenges to enable life-long SLAM, including the strong appearance change resulting from vegetation, weather, and illumination variations across various times of the day, different days, months, or even seasons. In this paper, we propose a new shared representative appearance learning (SRAL) approach to address long-term visual place recognition. Different from previous methods using a single feature modality or a concatenation of multiple features, our SRAL method autonomously learns representative features that are shared in all scene scenarios, and then fuses the features together to represent the long-term appearance of environments observed by a robot during life-long navigation. By formulating SRAL as a regularized optimization problem, we use structured sparsity-inducing norms to model interrelationships of feature modalities. In addition, an optimization algorithm is developed to efficiently solve the formulated optimization problem, which holds a theoretical convergence guarantee. Extensive empirical study was performed to evaluate the SRAL method using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have shown that our SRAL method obtains superior performance for life-long place recognition using individual images, outperforms previous single image-based methods, and is capable of estimating the importance of feature modalities.",,10.1109/LRA.2017.2662061,,,,Visualization;Image recognition;Feature extraction;Simultaneous localization and mapping;Optimization;Navigation;Loop closure detection;long-term place recognition;simultaneous localization and mapping (SLAM);visual learning,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Robust Place Recognition and Loop Closing in Laser-Based SLAM for UGVs in Urban Environments,F. Cao and Y. Zhuang and H. Zhang and W. Wang,IEEE Sensors Journal,2018,IEEE Abstract,4242--4252,18,"Robust place recognition plays a key role for the long-term autonomy of unmanned ground vehicles (UGVs) working in indoor or outdoor environments. Although most of the state-of-the-art that approaches for place recognition are vision-based, visual sensors lack adaptability in environments with poor or dynamically changing illumination. In this paper, a 3-D-laser-based place recognition algorithm is proposed to accomplish loop closure detection for simultaneous localization and mapping. An image model named bearing angle (BA) is adopted to convert 3-D laser points to 2-D images, and then ORB features extracted from BA images are utilized to perform scene matching. Since the computational cost for matching a query BA image with all the BA images in a database is too high to meet the requirement of performing real-time place recognition, a visual bag of words approach is used to improve search efficiency. Furthermore, a speed normalization algorithm and a 3-D geometry-based verification algorithm are proposed to complete the proposed place recognition algorithm. Experiments were conducted on two self-developed UGV platforms to verify the performance of the proposed method.",,10.1109/JSEN.2018.2815956,,,,Three-dimensional displays;Lasers;Visualization;Feature extraction;Sensors;Robustness;Lighting;Laser scanning;place recognition;simultaneous localization and mapping (SLAM);unmanned ground vehicles (UGVs),,1558-1748,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Optical flow localisation and appearance mapping (OFLAAM) for long-term navigation,D. Pastor-Moreno and H.-S. Shin and A. Waldock,,2015,IEEE Abstract,980--988,,"This paper presents a novel method to use optical flow navigation for long term navigation. Unlike standard SLAM approaches for augmented reality, OFLAAM is designed for Micro Air Vehicles (MAV). It uses a optical flow camera pointing downwards, a IMU and a monocular camera pointing frontwards. That configuration avoids the computational expensive mapping and tracking of the 3D features. It only maps these features in a vocabulary list by a localization module to tackle the optical flow drift and the lose of the navigation estimation. That module, based on the well established algorithm DBoW2, will be also used to close the loop and allow long-term navigation in previously visited areas. The combination of high speed optical flow navigation with a low rate localization algorithm allows fully autonomous navigation for MAV, at the same time it reduces the overall computational load. This framework is implemented in ROS (Robot Operating System) and tested attached to a laptop. A representative scenario is used to validate and analyze the performance of the system.",,10.1109/ICUAS.2015.7152387,,,,Cameras;Optical sensors;Optical imaging;Computers;Vehicles;Adaptive optics;High-speed optical techniques,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Towards lifelong feature-based mapping in semi-static environments,D. M. Rosen and J. Mason and J. J. Leonard,,2016,IEEE Abstract,1063--1070,,"The feature-based graphical approach to robotic mapping provides a representationally rich and computationally efficient framework for an autonomous agent to learn a model of its environment. However, this formulation does not naturally support long-term autonomy because it lacks a notion of environmental change; in reality, “everything changes and nothing stands still, ” and any mapping and localization system that aims to support truly persistent autonomy must be similarly adaptive. To that end, in this paper we propose a novel feature-based model of environmental evolution over time. Our approach is based upon the development of an expressive probabilistic generative feature persistence model that describes the survival of abstract semi-static environmental features over time. We show that this model admits a recursive Bayesian estimator, the persistence filter, that provides an exact online method for computing, at each moment in time, an explicit Bayesian belief over the persistence of each feature in the environment. By incorporating this feature persistence estimation into current state-of-the-art graphical mapping techniques, we obtain a flexible, computationally efficient, and information-theoretically rigorous framework for lifelong environmental modeling in an ever-changing world.",,10.1109/ICRA.2016.7487237,,,,Feature extraction;Detectors;Computational modeling;Adaptation models;Simultaneous localization and mapping;Bayes methods,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,SLAMinDB: Centralized graph databases for mobile robotics,D. Fourie and S. Claassens and S. Pillai and R. Mata and J. Leonard,,2017,IEEE Abstract,6331--6337,,"Robotic systems typically require memory recall mechanisms for a variety of tasks including localization, mapping, planning, visualization etc. We argue for a novel memory recall framework that enables more complex inference schemas by separating the computation from its associated data. In this work we propose a shared, centralized data persistence layer that maintains an ensemble of online, situationally-aware robot states. This is realized through a queryable graph-database with an accompanying key-value store for larger data. In turn, this approach is scalable and enables a multitude of capabilities such as experience-based learning and long-term autonomy. Using multi-modal simultaneous localization and mapping and a few example use-cases, we demonstrate the versatility and extensible nature that centralized persistence and SLAMinDB can provide. In order to support the notion of life-long autonomy, we envision robots to be endowed with such a persistence model, enabling them to revisit previous experiences and improve upon their existing task-specific capabilities.",,10.1109/ICRA.2017.7989749,,,,Simultaneous localization and mapping;Computer architecture;Relational databases;Navigation,,,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Learning by Inertia: Self-supervised Monocular Visual Odometry for Road Vehicles,C. Wang and Y. Yuan and Q. Wang,,2019,IEEE Abstract,2252--2256,,"In this paper, we present iDVO (inertia-embedded deep visual odometry), a self-supervised learning based monocular visual odometry (VO) for road vehicles. When modelling the geometric consistency within adjacent frames, most deep VO methods ignore the temporal continuity of the camera pose, which results in a very severe jagged fluctuation in the velocity curves. With the observation that road vehicles tend to perform smooth dynamic characteristics in most of the time, we design the inertia loss function to describe the abnormal motion variation, which assists the model to learn the consecutiveness from long-term camera ego-motion. Based on the recurrent convolutional neural network (RCNN) architecture, our method implicitly models the dynamics of road vehicles and the temporal consecutiveness by the extended Long Short-Term Memory (LSTM) block. Furthermore, we develop the dynamic hard-edge mask to handle the non-consistency in fast camera motion by blocking the boundary part and which generates more efficiency in the whole non-consistency mask. The proposed method is evaluated on the KITTI dataset, and the results demonstrate state-of-the-art performance with respect to other monocular deep VO and SLAM approaches.",,10.1109/ICASSP.2019.8683446,,,,Inertia;Self-supervised Learning;Visual Odometry;RCNN,,2379-190X,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,"Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation",C. Linegar and W. Churchill and P. Newman,,2015,IEEE Abstract,90--97,,"This paper is about life-long vast-scale localisation in spite of changes in weather, lighting and scene structure. Building upon our previous work in Experience-based Navigation [1], we continually grow and curate a visual map of the world that explicitly supports multiple representations of the same place. We refer to these representations as experiences, where a single experience captures the appearance of an environment under certain conditions. Pedagogically, an experience can be thought of as a visual memory. By accumulating experiences we are able to handle cyclic appearance change (diurnal lighting, seasonal changes, and extreme weather conditions) and also adapt to slow structural change. This strategy, although elegant and effective, poses a new challenge: In a region with many stored representations - which one(s) should we try to localise against given finite computational resources? By learning from our previous use of the experience-map, we can make predictions about which memories we should consider next, conditioned on how the robot is currently localised in the experience-map. During localisation, we prioritise the loading of past experiences in order to minimise the expected computation required. We do this in a probabilistic way and show that this memory policy significantly improves localisation efficiency, enabling long-term autonomy on robots with limited computational resources. We demonstrate and evaluate our system over three challenging datasets, totalling 206km of outdoor travel. We demonstrate the system in a diverse range of lighting and weather conditions, scene clutter, camera occlusions, and permanent structural change in the environment.",,10.1109/ICRA.2015.7138985,,,,Robots;Visualization;Cameras;Trajectory;Meteorology;Lighting;Navigation,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,"Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age",C. Cadena and L. Carlone and H. Carrillo and Y. Latif and D. Scaramuzza and J. Neira and I. Reid and J. J. Leonard,IEEE Transactions on Robotics,2016,IEEE Abstract,1309--1332,32,"Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?",,10.1109/TRO.2016.2624754,,,,Graph theory;Simultaneous location and mapping;Service robots;Robustness;Localization;Factor graphs;localization;mapping;maximum a posteriori estimation;perception;robots;sensing;simultaneous localization and mapping (SLAM),,1941-0468,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Using UHF-RFID Signals for Robot Localization Inside Pipelines,A. Gunatilake and M. Galea and K. Thiyagarajan and S. Kodagoda and L. Piyathilaka and P. Darji,,2021,IEEE Abstract,1109--1114,,"Underground water pipes are important to any country's infrastructure. Overtime, the metallic pipes are prone to corrosion, which can lead to water leakage and pipe bursts. In order to prolong the service life of those assets, water utilities in Australia apply protective pipe linings. Long-term monitoring and timely intervention are crucial for maintaining those lining assets. However, the water utilities do not possess the comprehensive technology to achieve it. The main reasons for lacking such technology are the unavailability of sensors and accurate robot localization technologies. Feature based localization methods such as SLAM has limited use as the application of liners alters the features and the environment. Encoder based localization is not accurate enough to observe the evolution of defects over a long period of time requiring unique defect correspondence. This motivates us to explore accurate contact-less and wireless based localization methods. We propose a cost-effective localization method using UHF-RFID signals for robot localization inside pipelines based on Gaussian process combined particle filter. Experiments carried out in field extracted pipe samples from the Sydney water pipe network show that using the RSSI and Phase data together in the measurement model with particle filter algorithm improves the localization accuracy up to 15 centimeters precision.",,10.1109/ICIEA51954.2021.9516284,,,,Location awareness;Wireless communication;Wireless sensor networks;Simultaneous localization and mapping;Phase measurement;Service robots;Pipelines;infrastructure robotics;linings;localization;particle filter;pipes;robotics for smart cities;RFID;robotic inspections;UHF-RFID,,2158-2297,,,,44698.62116,44698.62116,sousarbarb,,Duplicated,
,Generic Node Removal for Factor-Graph SLAM,N. Carlevaris-Bianco and M. Kaess and R. M. Eustice,IEEE Transactions on Robotics,2014,IEEE Index Terms,1371--1385,30,"This paper reports on a generic factor-based method for node removal in factor-graph simultaneous localization and mapping (SLAM), which we call generic linear constraints (GLCs). The need for a generic node removal tool is motivated by long-term SLAM applications, whereby nodes are removed in order to control the computational cost of graph optimization. GLC is able to produce a new set of linearized factors over the elimination clique that can represent either the true marginalization (i.e., dense GLC) or a sparse approximation of the true marginalization using a ChowLiu tree (i.e., sparse GLC). The proposed algorithm improves upon commonly used methods in two key ways: First, it is not limited to graphs with strictly full-state relative-pose factors and works equally well with other low-rank factors, such as those produced by monocular vision. Second, the new factors are produced in such a way that accounts for measurement correlation, which is a problem encountered in other methods that rely strictly upon pairwise measurement composition. We evaluate the proposed method over multiple real-world SLAM graphs and show that it outperforms other recently proposed methods in terms of Kullback-Leibler divergence. Additionally, we experimentally demonstrate that the proposed GLC method provides a principled and flexible tool to control the computational complexity of long-term graph SLAM, with results shown for 34.9 h of real-world indoor-outdoor data covering 147.4 km collected over 27 mapping sessions spanning a period of 15 months.",,10.1109/TRO.2014.2347571,,,,Simultaneous localization and mapping;Optimization;Approximation methods;Correlation;Mobile robots;Factor-graphs;long-term autonomy;marginalization;mobile robotics;simultaneous localization and mapping (SLAM);Factor-graphs;long-term autonomy;marginalization;mobile robotics;simultaneous localization and mapping (SLAM),,1941-0468,,,,44698.62163,44698.62421,sousarbarb,,Duplicated,
,Geometry-based Graph Pruning for Lifelong SLAM,G. Kurz and M. Holoch and P. Biber,,2021,IEEE Index Terms,3313--3320,,"Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case).",,10.1109/IROS51168.2021.9636530,,,,Simultaneous localization and mapping;Three-dimensional displays;Costs;Density functional theory;Trajectory;Standards;Intelligent robots,,2153-0866,,,,44698.62163,44698.62426,sousarbarb,,Duplicated,
,FreMEn: Frequency Map Enhancement for Long-Term Mobile Robot Autonomy in Changing Environments,T. Krajník and J. P. Fentanes and J. M. Santos and T. Duckett,IEEE Transactions on Robotics,2017,IEEE Index Terms,964--977,33,"We present a new approach to long-term mobile robot mapping in dynamic indoor environments. Unlike traditional world models that are tailored to represent static scenes, our approach explicitly models environmental dynamics. We assume that some of the hidden processes that influence the dynamic environment states are periodic and model the uncertainty of the estimated state variables by their frequency spectra. The spectral model can represent arbitrary timescales of environment dynamics with low memory requirements. Transformation of the spectral model to the time domain allows for the prediction of the future environment states, which improves the robot's long-term performance in changing environments. Experiments performed over time periods of months to years demonstrate that the approach can efficiently represent large numbers of observations and reliably predict future environment states. The experiments indicate that the model's predictive capabilities improve mobile robot localization and navigation in changing environments.",,10.1109/TRO.2017.2665664,,,,Hidden Markov models;Mobile robots;Uncertainty;Robustness;Harmonic analysis;Navigation;Localization;long-term autonomy;mapping,,1941-0468,,,,44698.62163,44698.62414,sousarbarb,,Duplicated,
,ExMaps: Long-Term Localization in Dynamic Scenes using Exponential Decay,A. Rotsidis and C. Lutteroth and P. Hall and C. Richardt,,2021,IEEE Index Terms,2866--2875,,"Visual camera localization using offline maps is widespread in robotics and mobile applications. Most state-of-the-art localization approaches assume static scenes, so maps are often reconstructed once and then kept constant. However, many scenes are dynamic and as changes in the scene happen, future localization attempts may struggle or fail entirely. Therefore, it is important for successful long-term localization to update and maintain maps as new observations of the scene, and changes in it, arrive. We propose a novel method for automatically discovering which points in a map remain stable over time, and which are due to transient changes. To this end, we calculate a stability store for each point based on its visibility over time, weighted by an exponential decay over time. This allows us to consider the impact of time when scoring points, and to distinguish which points are useful for long-term localization. We evaluate our method on the CMU Extended Seasons dataset (outdoors) and a new indoor dataset of a retail shop, and show the benefit of maintaining a `live map' that integrates updates over time using our exponential decay based method over a static `base map'.",,10.1109/WACV48630.2021.00291,,,,Location awareness;Visualization;Computer vision;Conferences;Robot vision systems;Cameras;Mobile applications,,2642-9381,,,,44698.62163,44698.62412,sousarbarb,,Duplicated,
,Evaluation of Long-term LiDAR Place Recognition,J. Peltomäki and F. Alijani and J. Puura and H. Huttunen and E. Rahtu and J.-K. Kämäräinen,,2021,IEEE Index Terms,4487--4492,,"We compare a state-of-the-art deep image retrieval and a deep place recognition method for place recognition using LiDAR data. Place recognition aims to detect previously visited locations and thus provides an important tool for navigation, mapping, and localisation. Experimental comparisons are conducted using challenging outdoor and indoor datasets, Oxford Radar RobotCar and COLD, in the ""long-term"" setting where the test conditions differ substantially from the training and gallery data. Based on our results the image retrieval methods using LiDAR depth images can achieve accurate localization (the single best match recall 80%) within 5.00 m in urban outdoors. In office indoors the comparable accuracy is 50 cm but is more sensitive to changes in the environment.",,10.1109/IROS51168.2021.9636320,,,,Training;Meters;Location awareness;Laser radar;Image recognition;Image retrieval;Radar imaging,,2153-0866,,,,44698.62163,44698.62411,sousarbarb,,Duplicated,
,Erasing bad memories: Agent-side summarization for long-term mapping,M. Dymczyk and T. Schneider and I. Gilitschenski and R. Siegwart and E. Stumm,,2016,IEEE Index Terms,4572--4579,,"Precisely estimating the pose of an agent in a global reference frame is a crucial goal that unlocks a multitude of robotic applications, including autonomous navigation and collaboration. In order to achieve this, current state-of-the-art localization approaches collect data provided by one or more agents and create a single, consistent localization map, maintained over time. However, with the introduction of lengthier sorties and the growing size of the environments, data transfers between the backend server where the global map is stored and the agents are becoming prohibitively large. While some existing methods partially address this issue by building compact summary maps, the data transfer from the agents to the backend can still easily become unmanageable. In this paper, we propose a method that is designed to reduce the amount of data that needs to be transferred from the agent to the backend, functioning in large-scale, multi-session mapping scenarios. Our approach is based upon a landmark selection method that exploits information coming from multiple, possibly weak and correlated, landmark utility predictors; fused using learned feature coefficients. Such a selection yields a drastic reduction in data transfer while maintaining localization performance and the ability to efficiently summarize environments over time. We evaluate our approach on a data set that was autonomously collected in a dynamic indoor environment over a period of several months.",,10.1109/IROS.2016.7759673,,,,Robots;Measurement;Bandwidth;Lighting;Data transfer;Servers;Reliability,,2153-0866,,,,44698.62163,44698.62409,sousarbarb,,Duplicated,
,Episodic non-Markov localization: Reasoning about short-term and long-term features,J. Biswas and M. Veloso,,2014,IEEE INSPEC Non-Controlled Terms,3969--3974,,"Markov localization and its variants are widely used for localization of mobile robots. These methods assume Markov independence of observations, implying that observations made by a robot correspond to a static map. However, in real human environments, observations include occlusions due to unmapped objects like chairs and tables, and dynamic objects like humans. We introduce an episodic non-Markov localization algorithm that maintains estimates of the belief over the trajectory of the robot while explicitly reasoning about observations and their correlations arising from unmapped static objects, moving objects, as well as objects from the static map. Observations are classified as arising from long-term features, short-term features, or dynamic features, which correspond to mapped objects, unmapped static objects, and unmapped dynamic objects respectively. By detecting time steps along the robot's trajectory where unmapped observations prior to such time steps are unrelated to those afterwards, non-Markov localization limits the history of observations and pose estimates to “episodes” over which the belief is computed. We demonstrate non-Markov localization in challenging real world indoor and outdoor environments over multiple datasets, comparing it with alternative state-of-the-art approaches, showing it to be robust as well as accurate.",,10.1109/ICRA.2014.6907435,,,,Markov processes;Cost function;Correlation;Maximum likelihood estimation;Robot kinematics;History,,1050-4729,,,,44698.62201,44698.62404,sousarbarb,,Duplicated,
,Dynamic pose graph SLAM: Long-term mapping in low dynamic environments,A. Walcott-Bryant and M. Kaess and H. Johannsson and J. J. Leonard,,2012,IEEE INSPEC Non-Controlled Terms,1871--1878,,"Maintaining a map of an environment that changes over time is a critical challenge in the development of persistently autonomous mobile robots. Many previous approaches to mapping assume a static world. In this work we incorporate the time dimension into the mapping process to enable a robot to maintain an accurate map while operating in dynamical environments. This paper presents Dynamic Pose Graph SLAM (DPG-SLAM), an algorithm designed to enable a robot to remain localized in an environment that changes substantially over time. Using incremental smoothing and mapping (iSAM) as the underlying SLAM state estimation engine, the Dynamic Pose Graph evolves over time as the robot explores new places and revisits previously mapped areas. The approach has been implemented for planar indoor environments, using laser scan matching to derive constraints for SLAM state estimation. Laser scans for the same portion of the environment at different times are compared to perform change detection; when sufficient change has occurred in a location, the dynamic pose graph is edited to remove old poses and scans that no longer match the current state of the world. Experimental results are shown for two real-world dynamic indoor laser data sets, demonstrating the ability to maintain an up-to-date map despite long-term environmental changes.",,10.1109/IROS.2012.6385561,,,,Simultaneous localization and mapping;Measurement by laser beam;Mobile robots;Heuristic algorithms;Lasers,,2153-0866,,,,44698.62201,44698.62398,sousarbarb,,Duplicated,
,Dynamic pose graph SLAM: Long-term mapping in low dynamic environments,A. Walcott-Bryant and M. Kaess and H. Johannsson and J. J. Leonard,,2012,IEEE Index Terms,1871--1878,,"Maintaining a map of an environment that changes over time is a critical challenge in the development of persistently autonomous mobile robots. Many previous approaches to mapping assume a static world. In this work we incorporate the time dimension into the mapping process to enable a robot to maintain an accurate map while operating in dynamical environments. This paper presents Dynamic Pose Graph SLAM (DPG-SLAM), an algorithm designed to enable a robot to remain localized in an environment that changes substantially over time. Using incremental smoothing and mapping (iSAM) as the underlying SLAM state estimation engine, the Dynamic Pose Graph evolves over time as the robot explores new places and revisits previously mapped areas. The approach has been implemented for planar indoor environments, using laser scan matching to derive constraints for SLAM state estimation. Laser scans for the same portion of the environment at different times are compared to perform change detection; when sufficient change has occurred in a location, the dynamic pose graph is edited to remove old poses and scans that no longer match the current state of the world. Experimental results are shown for two real-world dynamic indoor laser data sets, demonstrating the ability to maintain an up-to-date map despite long-term environmental changes.",,10.1109/IROS.2012.6385561,,,,Simultaneous localization and mapping;Measurement by laser beam;Mobile robots;Heuristic algorithms;Lasers,,2153-0866,,,,44698.62163,44698.62397,sousarbarb,,Duplicated,
,Domain-Invariant Similarity Activation Map Contrastive Learning for Retrieval-Based Long-Term Visual Localization,H. Hu and H. Wang and Z. Liu and W. Chen,IEEE/CAA Journal of Automatica Sinica,2022,IEEE Index Terms,313--328,9,"Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the contrastive learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.",,10.1109/JAS.2021.1003907,,,,Location awareness;Visualization;Measurement;Feature extraction;Image recognition;Pipelines;Training;Deep representation learning;place recognition;visual localization,,2329-9274,,,,44698.62163,44698.62395,sousarbarb,,Duplicated,
,Episodic non-Markov localization: Reasoning about short-term and long-term features,J. Biswas and M. Veloso,,2014,IEEE Index Terms,3969--3974,,"Markov localization and its variants are widely used for localization of mobile robots. These methods assume Markov independence of observations, implying that observations made by a robot correspond to a static map. However, in real human environments, observations include occlusions due to unmapped objects like chairs and tables, and dynamic objects like humans. We introduce an episodic non-Markov localization algorithm that maintains estimates of the belief over the trajectory of the robot while explicitly reasoning about observations and their correlations arising from unmapped static objects, moving objects, as well as objects from the static map. Observations are classified as arising from long-term features, short-term features, or dynamic features, which correspond to mapped objects, unmapped static objects, and unmapped dynamic objects respectively. By detecting time steps along the robot's trajectory where unmapped observations prior to such time steps are unrelated to those afterwards, non-Markov localization limits the history of observations and pose estimates to “episodes” over which the belief is computed. We demonstrate non-Markov localization in challenging real world indoor and outdoor environments over multiple datasets, comparing it with alternative state-of-the-art approaches, showing it to be robust as well as accurate.",,10.1109/ICRA.2014.6907435,,,,Markov processes;Cost function;Correlation;Maximum likelihood estimation;Robot kinematics;History,,1050-4729,,,,44698.62163,44698.62403,sousarbarb,,Duplicated,
,Efficient Long-term Mapping in Dynamic Environments,M. T. Lázaro and R. Capobianco and G. Grisetti,,2018,IEEE Index Terms,153--160,,"As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.",,10.1109/IROS.2018.8594310,,,,Simultaneous localization and mapping;Cloud computing;Three-dimensional displays;Two dimensional displays;Merging;Optimization,,2153-0866,,,,44698.62163,44698.62399,sousarbarb,,Duplicated,
,Distributed real-time cooperative localization and mapping using an uncertainty-aware expectation maximization approach,J. Dong and E. Nelson and V. Indelman and N. Michael and F. Dellaert,,2015,IEEE Index Terms,5807--5814,,"We demonstrate distributed, online, and real-time cooperative localization and mapping between multiple robots operating throughout an unknown environment using indirect measurements. We present a novel Expectation Maximization (EM) based approach to efficiently identify inlier multi-robot loop closures by incorporating robot pose uncertainty, which significantly improves the trajectory accuracy over long-term navigation. An EM and hypothesis based method is used to determine a common reference frame. We detail a 2D laser scan correspondence method to form robust correspondences between laser scans shared amongst robots. The implementation is experimentally validated using teams of aerial vehicles, and analyzed to determine its accuracy, computational efficiency, scalability to many robots, and robustness to varying environments. We demonstrate through multiple experiments that our method can efficiently build maps of large indoor and outdoor environments in a distributed, online, and real-time setting.",,10.1109/ICRA.2015.7140012,,,,Trajectory;Robot kinematics;Robot sensing systems;Lasers;Robustness;Uncertainty,,1050-4729,,,,44698.62163,44698.62382,sousarbarb,,Duplicated,
,Distributed real-time cooperative localization and mapping using an uncertainty-aware expectation maximization approach,J. Dong and E. Nelson and V. Indelman and N. Michael and F. Dellaert,,2015,IEEE INSPEC Non-Controlled Terms,5807--5814,,"We demonstrate distributed, online, and real-time cooperative localization and mapping between multiple robots operating throughout an unknown environment using indirect measurements. We present a novel Expectation Maximization (EM) based approach to efficiently identify inlier multi-robot loop closures by incorporating robot pose uncertainty, which significantly improves the trajectory accuracy over long-term navigation. An EM and hypothesis based method is used to determine a common reference frame. We detail a 2D laser scan correspondence method to form robust correspondences between laser scans shared amongst robots. The implementation is experimentally validated using teams of aerial vehicles, and analyzed to determine its accuracy, computational efficiency, scalability to many robots, and robustness to varying environments. We demonstrate through multiple experiments that our method can efficiently build maps of large indoor and outdoor environments in a distributed, online, and real-time setting.",,10.1109/ICRA.2015.7140012,,,,Trajectory;Robot kinematics;Robot sensing systems;Lasers;Robustness;Uncertainty,,1050-4729,,,,44698.62201,44698.62381,sousarbarb,,Duplicated,
,"Automating answers to ""where am i?""",P. Newman,,2005,IEEE Index Terms,7pp.--,,"In many situations, large-scale, long term deployment of an autonomous vehicle requires an ability to navigate in arbitrary workspaces and must be able to establish ""where am I what surrounds me?"". This paper describe simultaneous localisation and mapping (SLAM)techniques and implementations in which an autonomous vehicle explores its workspace using onboard sensors and inextricably binds together the tasks of mapping and localisation.",,10.1049/ic:20050473,,,,,,0537-9989,,,,44698.62163,44698.62358,sousarbarb,,Duplicated,
,Approximating Marginalization with Sparse Global Priors for Sliding Window SLAM-Graphs,D. Wilbers and L. Rumberg and C. Stachniss,,2019,IEEE INSPEC Non-Controlled Terms,25--31,,"Most autonomous vehicles rely on some kind of map for localization or navigation. Outdated maps however are a risk to the performance of any map-based localization system applied in autonomous vehicles. It is necessary to update the used maps to ensure stable and long-term operation. We address the problem of computing landmark updates live in the vehicle, which requires efficient use of the computational resources. In particular, we employ a graph-based sliding window approach for simultaneous localization and incremental map refinement. We propose a novel method that approximates sliding window marginalization without inducing fill-in. Our method maintains the exact same sparsity pattern as without performing marginalization, but simultaneously improves the landmark estimates. The main novelty of this work is the derivation of sparse global priors that approximate dense marginalization. In comparison to state-of-the-art work, our approach utilizes global instead of local linearization points, but still minimizes linearization errors. We first approximate marginalization via Kullback-Leibler divergence and then recalculate the mean to compensate linearization errors. We evaluate our approach on simulated and real data from a prototype vehicle and compare our approach to state-of-the-art sliding window marginalization.",,10.1109/IRC.2019.00013,,,,Microsoft Windows;Optimization;Autonomous vehicles;Jacobian matrices;Robots;Navigation;Trajectory;SLAM;Sensor Fusion;Incremental Mapping;Localization;Automated Driving,,,,,,44698.62201,44698.62351,sousarbarb,,Duplicated,
,Are We Ready for Service Robots? The OpenLORIS-Scene Datasets for Lifelong SLAM,X. Shi and D. Li and P. Zhao and Q. Tian and Y. Tian and Q. Long and C. Zhu and J. Song and F. Qiao and L. Song and Y. Guo and Z. Wang and Y. Zhang and B. Qin and W. Yang and F. Wang and R. H. M. Chan and Q. She,,2020,IEEE Title,3139--3145,,"Service robots should be able to operate autonomously in dynamic and daily changing environments over an extended period of time. While Simultaneous Localization And Mapping (SLAM) is one of the most fundamental problems for robotic autonomy, most existing SLAM works are evaluated with data sequences that are recorded in a short period of time. In real-world deployment, there can be out-of-sight scene changes caused by both natural factors and human activities. For example, in home scenarios, most objects may be movable, replaceable or deformable, and the visual features of the same place may be significantly different in some successive days. Such out-of-sight dynamics pose great challenges to the robustness of pose estimation, and hence a robot’s long-term deployment and operation. To differentiate the forementioned problem from the conventional works which are usually evaluated in a static setting in a single run, the term lifelong SLAM is used here to address SLAM problems in an ever-changing environment over a long period of time. To accelerate lifelong SLAM research, we release the OpenLORIS-Scene datasets. The data are collected in real-world indoor scenes, for multiple times in each place to include scene changes in real life. We also design benchmarking metrics for lifelong SLAM, with which the robustness and accuracy of pose estimation are evaluated separately. The datasets and benchmark are available online at lifelong-robotic-vision.github.io/dataset/scene.",,10.1109/ICRA40945.2020.9196638,,,,Simultaneous localization and mapping;Robot kinematics;Cameras;Synchronization;Trajectory,,2577-087X,,,,44698.62149,44698.62353,sousarbarb,,Duplicated,
,Approximating Marginalization with Sparse Global Priors for Sliding Window SLAM-Graphs,D. Wilbers and L. Rumberg and C. Stachniss,,2019,IEEE Index Terms,25--31,,"Most autonomous vehicles rely on some kind of map for localization or navigation. Outdated maps however are a risk to the performance of any map-based localization system applied in autonomous vehicles. It is necessary to update the used maps to ensure stable and long-term operation. We address the problem of computing landmark updates live in the vehicle, which requires efficient use of the computational resources. In particular, we employ a graph-based sliding window approach for simultaneous localization and incremental map refinement. We propose a novel method that approximates sliding window marginalization without inducing fill-in. Our method maintains the exact same sparsity pattern as without performing marginalization, but simultaneously improves the landmark estimates. The main novelty of this work is the derivation of sparse global priors that approximate dense marginalization. In comparison to state-of-the-art work, our approach utilizes global instead of local linearization points, but still minimizes linearization errors. We first approximate marginalization via Kullback-Leibler divergence and then recalculate the mean to compensate linearization errors. We evaluate our approach on simulated and real data from a prototype vehicle and compare our approach to state-of-the-art sliding window marginalization.",,10.1109/IRC.2019.00013,,,,Microsoft Windows;Optimization;Autonomous vehicles;Jacobian matrices;Robots;Navigation;Trajectory;SLAM;Sensor Fusion;Incremental Mapping;Localization;Automated Driving,,,,,,44698.62163,44698.62351,sousarbarb,,Duplicated,
,Appearance-based landmark selection for efficient long-term visual localization,M. Bürki and I. Gilitschenski and E. Stumm and R. Siegwart and J. Nieto,,2016,IEEE Index Terms,4137--4143,,"In this paper, we present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments. Sharing a common map for online localization provides a fleet of autonomous vehicles with the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offers the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks are to be observable under the prevailing appearance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. Evaluation is performed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme transition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.",,10.1109/IROS.2016.7759609,,,,Vehicles;Visualization;Servers;Bandwidth;Robots;Redundancy;Mobile computing,,2153-0866,,,,44698.62163,44698.62348,sousarbarb,,Duplicated,
,An adaptive appearance-based map for long-term topological localization of mobile robots,F. Dayoub and T. Duckett,,2008,IEEE INSPEC Non-Controlled Terms,3364--3369,,"This work considers a mobile service robot which uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the internal representation may become out of date after some time. To solve this problem the robot needs to be able to adapt its internal representation continually to the changes in the environment. This paper presents a method for creating an adaptive map for long-term appearance-based localization of a mobile robot using long-term and short-term memory concepts, with omni-directional vision as the external sensor.",,10.1109/IROS.2008.4650701,,,,Feature extraction;Robots;Robot sensing systems;Noise;Approximation algorithms;Robot vision systems;Cameras,,2153-0866,,,,44698.62201,44698.62344,sousarbarb,,Duplicated,
,An adaptive appearance-based map for long-term topological localization of mobile robots,F. Dayoub and T. Duckett,,2008,IEEE Title,3364--3369,,"This work considers a mobile service robot which uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the internal representation may become out of date after some time. To solve this problem the robot needs to be able to adapt its internal representation continually to the changes in the environment. This paper presents a method for creating an adaptive map for long-term appearance-based localization of a mobile robot using long-term and short-term memory concepts, with omni-directional vision as the external sensor.",,10.1109/IROS.2008.4650701,,,,Feature extraction;Robots;Robot sensing systems;Noise;Approximation algorithms;Robot vision systems;Cameras,,2153-0866,,,,44698.62149,44698.62343,sousarbarb,,Duplicated,
,An adaptive appearance-based map for long-term topological localization of mobile robots,F. Dayoub and T. Duckett,,2008,IEEE Index Terms,3364--3369,,"This work considers a mobile service robot which uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the internal representation may become out of date after some time. To solve this problem the robot needs to be able to adapt its internal representation continually to the changes in the environment. This paper presents a method for creating an adaptive map for long-term appearance-based localization of a mobile robot using long-term and short-term memory concepts, with omni-directional vision as the external sensor.",,10.1109/IROS.2008.4650701,,,,Feature extraction;Robots;Robot sensing systems;Noise;Approximation algorithms;Robot vision systems;Cameras,,2153-0866,,,,44698.62163,44698.62346,sousarbarb,,Duplicated,
,An Optimization Technique for Positioning Multiple Maps for Self-Driving Car's Autonomous Navigation,S. Dominguez and B. Khomutenko and G. Garcia and P. Martinet,,2015,IEEE Index Terms,2694--2699,,"Self-driving car's navigation requires a very precise localization covering wide areas and long distances. Moreover, they have to do it at faster speeds than conventional mobile robots. This paper reports on an efficient technique to optimize the position of a sequence of maps along a journey. We take advantage of the short-term precision and reduced space on disk of the localization using 2D occupancy grid maps, from now on called sub-maps, as well as, the long-term global consistency of a Kalman filter that fuses odometry and GPS measurements. In our approach, horizontal planar LiDARs and odometry measurements are used to perform 2D-SLAM generating the sub-maps, and the EKF to generate the trajectory followed by the car in global coordinates. During the trip, after finishing each sub-map, a relaxation process is applied to a set of the last sub-maps to position them globally using both, global and map's local path. The importance of this method lies on its performance, expending low computing resources, so it can work in real time on a computer with conventional characteristics and on its robustness which makes it suitable for being used on a self-driving car as it doesn't depend excessively on the availability of GPS signal or the eventual appearance of moving objects around the car. Extensive testing has been performed in the suburbs and in the down-town of Nantes (France) covering a distance of 25 kilometers with different traffic conditions obtaining satisfactory results for autonomous driving.",,10.1109/ITSC.2015.433,,,,Laser radar;Global Positioning System;Splines (mathematics);Force;Trajectory;Simultaneous localization and mapping;Buildings,,2153-0017,,,,44698.62163,44698.62339,sousarbarb,,Duplicated,
,An Optimization Technique for Positioning Multiple Maps for Self-Driving Car's Autonomous Navigation,S. Dominguez and B. Khomutenko and G. Garcia and P. Martinet,,2015,IEEE INSPEC Non-Controlled Terms,2694--2699,,"Self-driving car's navigation requires a very precise localization covering wide areas and long distances. Moreover, they have to do it at faster speeds than conventional mobile robots. This paper reports on an efficient technique to optimize the position of a sequence of maps along a journey. We take advantage of the short-term precision and reduced space on disk of the localization using 2D occupancy grid maps, from now on called sub-maps, as well as, the long-term global consistency of a Kalman filter that fuses odometry and GPS measurements. In our approach, horizontal planar LiDARs and odometry measurements are used to perform 2D-SLAM generating the sub-maps, and the EKF to generate the trajectory followed by the car in global coordinates. During the trip, after finishing each sub-map, a relaxation process is applied to a set of the last sub-maps to position them globally using both, global and map's local path. The importance of this method lies on its performance, expending low computing resources, so it can work in real time on a computer with conventional characteristics and on its robustness which makes it suitable for being used on a self-driving car as it doesn't depend excessively on the availability of GPS signal or the eventual appearance of moving objects around the car. Extensive testing has been performed in the suburbs and in the down-town of Nantes (France) covering a distance of 25 kilometers with different traffic conditions obtaining satisfactory results for autonomous driving.",,10.1109/ITSC.2015.433,,,,Laser radar;Global Positioning System;Splines (mathematics);Force;Trajectory;Simultaneous localization and mapping;Buildings,,2153-0017,,,,44698.62201,44698.62339,sousarbarb,,Duplicated,
,An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory,Y. Furuta and K. Okada and Y. Kakiuchi and M. Inaba,,2018,IEEE Index Terms,1--7,,"To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.",,10.1109/IROS.2018.8594481,,,,Task analysis;Probabilistic logic;Semantics;Planning;Robot sensing systems;Solid modeling;Service Robots;Learning and Adaptive Systems;Big Data in Robotics and Automation,,2153-0866,,,,44698.62163,44698.62337,sousarbarb,,Duplicated,
,A framework for RF-Visual SLAM,S. Anwar and Q. Zhao and N. Qadeer and S. I. Khan,,2013,IEEE Index Terms,103--108,,"Simultaneous Localization and Mapping, SLAM, is an important topic in the field of robotics and autonomous navigation. The metric SLAM suffers from sensor inaccuracies and thus cannot be used for long-term navigation. In such case, Visual SLAM or a Hybrid SLAM based on both metric and visual approach is a good alternative. In this paper, in order to speed up a Visual SLAM, we propose a novel concept of dynamic dictionary generated on the results of triangulation done on RF, radio frequency, signals from nearest cell towers of a cellular network. This dynamic dictionary efficiently manages the scalability of a Visual SLAM and make it possible to work in a large-scale environment. A framework is proposed along with triangulation data of a city and with simulations to support the concept.",,10.1109/IBCAST.2013.6512139,,,,Dictionaries;Simultaneous localization and mapping;Poles and towers;Navigation;Hybrid power systems,,,,,,44698.62163,44698.62328,sousarbarb,,Duplicated,
,A framework for RF-Visual SLAM,S. Anwar and Q. Zhao and N. Qadeer and S. I. Khan,,2013,IEEE INSPEC Non-Controlled Terms,103--108,,"Simultaneous Localization and Mapping, SLAM, is an important topic in the field of robotics and autonomous navigation. The metric SLAM suffers from sensor inaccuracies and thus cannot be used for long-term navigation. In such case, Visual SLAM or a Hybrid SLAM based on both metric and visual approach is a good alternative. In this paper, in order to speed up a Visual SLAM, we propose a novel concept of dynamic dictionary generated on the results of triangulation done on RF, radio frequency, signals from nearest cell towers of a cellular network. This dynamic dictionary efficiently manages the scalability of a Visual SLAM and make it possible to work in a large-scale environment. A framework is proposed along with triangulation data of a city and with simulations to support the concept.",,10.1109/IBCAST.2013.6512139,,,,Dictionaries;Simultaneous localization and mapping;Poles and towers;Navigation;Hybrid power systems,,,,,,44698.62201,44698.62328,sousarbarb,,Duplicated,
,A Life-Long SLAM Approach Using Adaptable Local Maps Based on Rasterized LIDAR Images,W. Ali and P. Liu and R. Ying and Z. Gong,IEEE Sensors Journal,2021,IEEE INSPEC Non-Controlled Terms,21740--21749,21,"Most real-time autonomous robot applications require a robot to traverse through a dynamic space for a long time. In some cases, a robot needs to work in the same environment. Such applications give rise to the problem of a life-long SLAM system. Life-long SLAM presents two main challenges i.e. the tracking should not fail in a dynamic environment and the need for a robust and efficient mapping strategy. The system should update maps with new information; while also keeping track of older observations. But, mapping for a long time can require higher computational requirements. In this paper, we propose a solution to the problem of life-long SLAM. We represent the global map as a set of rasterized images of local maps along with a map management system responsible for updating local maps and keeping track of older values. We also present an efficient approach of using the bag of visual words method for loop closure detection and relocalization. We evaluate the performance of our system on the KITTI dataset and an indoor dataset. Our loop closure system reported recall and precision of above 90 percent. The computational cost of our system is much lower as compared to state-of-the-art methods. Our method reports lower computational requirements even for long-term operation.",,10.1109/JSEN.2021.3100882,,,,Simultaneous localization and mapping;Three-dimensional displays;Feature extraction;Robots;Databases;Laser radar;Sensors;Laser scanning;place recognition;bag of words;rasterization;mapping;simultaneous localization;mapping,,1558-1748,,,,44698.62201,44698.62324,sousarbarb,,Duplicated,
,A Life-Long SLAM Approach Using Adaptable Local Maps Based on Rasterized LIDAR Images,W. Ali and P. Liu and R. Ying and Z. Gong,IEEE Sensors Journal,2021,IEEE Index Terms,21740--21749,21,"Most real-time autonomous robot applications require a robot to traverse through a dynamic space for a long time. In some cases, a robot needs to work in the same environment. Such applications give rise to the problem of a life-long SLAM system. Life-long SLAM presents two main challenges i.e. the tracking should not fail in a dynamic environment and the need for a robust and efficient mapping strategy. The system should update maps with new information; while also keeping track of older observations. But, mapping for a long time can require higher computational requirements. In this paper, we propose a solution to the problem of life-long SLAM. We represent the global map as a set of rasterized images of local maps along with a map management system responsible for updating local maps and keeping track of older values. We also present an efficient approach of using the bag of visual words method for loop closure detection and relocalization. We evaluate the performance of our system on the KITTI dataset and an indoor dataset. Our loop closure system reported recall and precision of above 90 percent. The computational cost of our system is much lower as compared to state-of-the-art methods. Our method reports lower computational requirements even for long-term operation.",,10.1109/JSEN.2021.3100882,,,,Simultaneous localization and mapping;Three-dimensional displays;Feature extraction;Robots;Databases;Laser radar;Sensors;Laser scanning;place recognition;bag of words;rasterization;mapping;simultaneous localization;mapping,,1558-1748,,,,44698.62163,44698.62319,sousarbarb,,Duplicated,
,A General Framework for Lifelong Localization and Mapping in Changing Environment,M. Zhao and X. Guo and L. Song and B. Qin and X. Shi and G. H. Lee and G. Sun,,2021,IEEE Index Terms,3305--3312,,"The environment of most real-world scenarios such as malls and supermarkets changes at all times. A pre-built map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-to-date model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efficient map updating strategy that includes map building, pose graph refinement and sparsification. To mitigate the unbounded increase of memory usage, we propose a map-trimming method based on the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.",,10.1109/IROS51168.2021.9635985,,,,Location awareness;Simultaneous localization and mapping;Buildings;Intelligent robots,,2153-0866,,,,44698.62163,44698.62318,sousarbarb,,Duplicated,
,A General Framework for Lifelong Localization and Mapping in Changing Environment,M. Zhao and X. Guo and L. Song and B. Qin and X. Shi and G. H. Lee and G. Sun,,2021,IEEE INSPEC Non-Controlled Terms,3305--3312,,"The environment of most real-world scenarios such as malls and supermarkets changes at all times. A pre-built map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-to-date model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efficient map updating strategy that includes map building, pose graph refinement and sparsification. To mitigate the unbounded increase of memory usage, we propose a map-trimming method based on the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.",,10.1109/IROS51168.2021.9635985,,,,Location awareness;Simultaneous localization and mapping;Buildings;Intelligent robots,,2153-0866,,,,44698.62201,44698.62316,sousarbarb,,Duplicated,
,A B-Spline Mapping Framework for Long-Term Autonomous Operations,R. T. Rodrigues and A. P. Aguiar and A. Pascoal,,2018,IEEE INSPEC Non-Controlled Terms,3204--3209,,"This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.",,10.1109/IROS.2018.8594456,,,,Splines (mathematics);Simultaneous localization and mapping;Three-dimensional displays;Robot kinematics;Two dimensional displays,,2153-0866,,,,44698.62201,44698.62314,sousarbarb,,Duplicated,
,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,L. Sun and Z. Yan and S. M. Mellado and M. Hanheide and T. Duckett,,2018,IEEE Index Terms,5942--5948,,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",,10.1109/ICRA.2018.8461228,,,,Trajectory;Cameras;Robot kinematics;Robot vision systems;Two dimensional displays;Mobile robots,,2577-087X,,,,44698.62163,44698.62311,sousarbarb,,Duplicated,
,"3D localization, mapping and path planning for search and rescue operations",R. Dubé and A. Gawel and C. Cadena and R. Siegwart and L. Freda and M. Gianni,,2016,IEEE Index Terms,272--273,,"This work presents our results on 3D robot localization, mapping and path planning for the latest joint exercise of the European project “Long-Term Human-Robot Teaming for Robots Assisted Disaster Response” (TRADR)1. The full system is operated and evaluated by firemen end-users in real-world search and rescue experiments. We demonstrate that the system is able to plan a path to a goal position desired by the fireman operator in the TRADR Operational Control Unit (OCU), using a persistent 3D map created by the robot during previous sorties.",,10.1109/SSRR.2016.7784311,,,,Three-dimensional displays;Path planning;Simultaneous localization and mapping;Navigation;Lasers,,,,,,44698.62163,44698.62309,sousarbarb,,Duplicated,
,"1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image",G. Kim and B. Park and A. Kim,IEEE Robotics and Automation Letters,2019,IEEE Index Terms,1948--1955,4,"In this letter, we present a long-term localization method that effectively exploits the structural information of an environment via an image format. The proposed method presents a robust year-round localization performance even when learned in just a single day. The proposed localizer learns a point cloud descriptor, named Scan Context Image (SCI), and performs robot localization on a grid map by formulating the place recognition problem as place classification using a convolutional neural network. Our method is faster than existing methods proposed for place recognition because it avoids a pairwise comparison between a query and scans in a database. In addition, we provide thorough validations using publicly available long-term datasets, the NCLT dataset and the Oxford RobotCar dataset, and show that the Scan Context Image (SCI) localization attains consistent performance over a year and outperforms existing methods.",,10.1109/LRA.2019.2897340,,,,Three-dimensional displays;Training;Laser radar;Entropy;Databases;Robot localization;Localization;range sensing;SLAM,,2377-3766,,,,44698.62163,44698.62302,sousarbarb,,Duplicated,
,Appearance-based landmark selection for efficient long-term visual localization,M. Bürki and I. Gilitschenski and E. Stumm and R. Siegwart and J. Nieto,,2016,IEEE INSPEC Non-Controlled Terms,4137--4143,,"In this paper, we present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments. Sharing a common map for online localization provides a fleet of autonomous vehicles with the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offers the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks are to be observable under the prevailing appearance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. Evaluation is performed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme transition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.",,10.1109/IROS.2016.7759609,,,,Vehicles;Visualization;Servers;Bandwidth;Robots;Redundancy;Mobile computing,,2153-0866,,,,44698.62201,44698.62347,sousarbarb,,Duplicated,
,An 879GOPS 243mW 80fps VGA Fully Visual CNN-SLAM Processor for Wide-Range Autonomous Exploration,Z. Li and Y. Chen and L. Gong and L. Liu and D. Sylvester and D. Blaauw and H.-S. Kim,,2019,IEEE INSPEC Non-Controlled Terms,134--136,,"Simultaneous localization and mapping (SLAM) estimates an agent's trajectory for all six degrees of freedom (6 DoF) and constructs a 3D map of an unknown surrounding. It is a fundamental kernel that enables head-mounted augmented/virtual reality devices and autonomous navigation of micro aerial vehicles. A noticeable recent trend in visual SLAM is to apply computationand memory-intensive convolutional neural networks (CNNs) that outperform traditional hand-designed feature-based methods [1]. For each video frame, CNN-extracted features are matched with stored keypoints to estimate the agent's 6-DoF pose by solving a perspective-n-points (PnP) non-linear optimization problem (Fig. 7.3.1, left). The agent's long-term trajectory over multiple frames is refined by a bundle adjustment process (BA, Fig. 7.3.1 right), which involves a large-scale (~120 variables) non-linear optimization. Visual SLAM requires massive computation (>250GOP/s) in the CNN-based feature extraction and matching, as well as datadependent dynamic memory access and control flow with high-precision operations, creating significant low-power design challenges. Software implementations are impractical, resulting in 0.2s runtime with a ~3GHz CPU+ GPU system with >100MB memory footprint and >100W power consumption. Prior ASICs have implemented either an incomplete SLAM system [2,3] that lacks estimation of ego-motion or employed a simplified (non-CNN) feature extraction and tracking [2,4,5] that limits SLAM quality and range. A recent ASIC [5] augments visual SLAM with an off-chip high-precision inertial measurement unit (IMU), simplifying the computational complexity, but incurring additional power and cost overhead.",,10.1109/ISSCC.2019.8662397,,,,Simultaneous localization and mapping;Engines;Three-dimensional displays;Two dimensional displays;Feature extraction;Visualization;Trajectory,,2376-8606,,,,44698.62201,44698.62333,sousarbarb,,Duplicated,
,Segmented Matching Method of Multi-Geophysics Field SLAM Data Based on LSTM,Z. Li and H. Yu and T. Shen and Z. Li,,2020,IEEE INSPEC Non-Controlled Terms,147--151,,"At present, simultaneous localization and mapping (SLAM) has become an important method for autonomous underwater vehicles (AUVs) to realize long-term navigation. However, using only bathymetric data in unknown environment has its own disadvantages, that are low precision and large computational load. To tackle with requirements of high-precision navigation under large-scale and long-term voyage condition, a SLAM method and corresponding matching algorithm for integrating multi-geophysical field data are proposed. By dividing the feature data and location data of geophysical field obtained into various submaps and sub-segments during AUV sailing, the dominant navigation data of each segment is identified using long short-term memory network. Validity of the proposed method is done by simulation experiments. During the simulation, the loop closure detection of each submap is used, and the matching counter is set to check the correct matching rate. Finally, the matching results with single geophysics field data under the same conditions are compared with multi-geophysics field data and analyzed. The experimental results have demonstrated the feasibility and correctness of the proposed method.",,10.1109/ICUS50048.2020.9274964,,,,Technological innovation;Underwater vehicles;Timing;Simultaneous localization and mapping;Navigation;SLAM;LSTM;navigation;multi-geophysics field data;matching,,,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,"Real-Time, Environmentally-Robust 3D LiDAR Localization",Y. Zhu and B. Xue and L. Zheng and H. Huang and M. Liu and R. Fan,,2019,IEEE INSPEC Non-Controlled Terms,1--6,,"Localization, or position fixing, is an important problem in robotics research. In this paper, we propose a novel approach for long-term localization in a changing environment using 3D LiDAR. We first create the map of a real environment using GPS and LiDAR. Then, we divide the map into several small parts as the targets for cloud registration, which can not only improve the robustness but also reduce the registration time. We proposed a localization method called PointLocalization. PointLocalization allows us to fuse different kinds of odometers, which can optimize the accuracy and frequency of localization results. We evaluate our algorithm on an unmanned ground vehicle (UGV) using LiDAR and a wheel encoder, and obtain the localization results at more than 20 Hz after fusion. The algorithm can also localize the UGV in a 180-degree field of view (FOV). Using an outdated map captured six months ago, this algorithm shows great robustness, and the test results show that it can achieve an accuracy of 10 cm. PointLocalization has been tested for a period of more than six months in a crowded factory and has operated successfully over a distance of more than 2000 km.",,10.1109/IST48021.2019.9010305,,,,Laser radar;Global Positioning System;Simultaneous localization and mapping;Wheels;Cameras;Three-dimensional displays,,1558-2809,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Migratory birds-inspired navigation system for unmanned aerial vehicles,Y. Zhang and A. Chao and B. Zhao and H. Liu and X. Zhao,,2016,IEEE INSPEC Non-Controlled Terms,276--281,,"Migration birds are able to navigate themselves during a long-distance journey without getting lost. They actually achieve just what is being sought for in the field of Unmanned Aerial Vehicles (UAVs): long-term autonomous navigation. This paper proposes an approach that combines the migration birds' sense principles with Micro-Electro-Mechanical System (MEMS) sensors to estimate UAVs position within GPS-denied environments. Camera, orientation and web-based maps (such as Google/Baidu Maps) are chosen to simulate the birds' localization cues: vision, earth magnetic field and mental maps. The visual odometry, Particle Filter theories are used in the proposed approach to integrate multiple sensor measurements. Real flying experiments are conducted both in indoor and outdoor environments. The results validate that the proposed migration-inspired visual odometry system can estimate the UAV localization effectively.",,10.1109/ICInfA.2016.7831835,,,,Cameras;Visualization;Unmanned aerial vehicles;Birds;Sensors;Navigation;Optical imaging;Migration birds;Unmanned Aerial Vehicles;Navigation,,,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory,Y. Furuta and K. Okada and Y. Kakiuchi and M. Inaba,,2018,IEEE INSPEC Non-Controlled Terms,1--7,,"To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.",,10.1109/IROS.2018.8594481,,,,Task analysis;Probabilistic logic;Semantics;Planning;Robot sensing systems;Solid modeling;Service Robots;Learning and Adaptive Systems;Big Data in Robotics and Automation,,2153-0866,,,,44698.62201,44698.62336,sousarbarb,,Duplicated,
,Bathymetric factor graph SLAM with sparse point cloud alignment,V. Bichucher and J. M. Walls and P. Ozog and K. A. Skinner and R. M. Eustice,,2015,IEEE INSPEC Non-Controlled Terms,1--7,,"This paper reports on a factor graph simultaneous localization and mapping framework for autonomous underwater vehicle localization based on terrain-aided navigation. The method requires no prior bathymetric map and only assumes that the autonomous underwater vehicle has the ability to sparsely sense the local water column depth, such as with a bottom-looking Doppler velocity log. Since dead-reckoned navigation is accurate in short time windows, the vehicle accumulates several water column depth point clouds- or submaps-during the course of its survey. We propose an xy-alignment procedure between these submaps in order to enforce consistent bathymetric structure over time, and therefore attempt to bound long-term navigation drift. We evaluate the submap alignment method in simulation and present performance results from multiple autonomous underwater vehicle field trials.",,10.23919/OCEANS.2015.7404433,,,,Simultaneous localization and mapping;Three-dimensional displays;Vehicles;Trajectory;Smoothing methods;Global Positioning System,,,,,,44698.62201,44698.62365,sousarbarb,,Duplicated,
,Long-term topological localisation for service robots in dynamic environments using spectral maps,T. Krajník and J. P. Fentanes and O. M. Mozos and T. Duckett and J. Ekekrantz and M. Hanheide,,2014,IEEE INSPEC Non-Controlled Terms,4537--4542,,"This paper presents a new approach for topological localisation of service robots in dynamic indoor environments. In contrast to typical localisation approaches that rely mainly on static parts of the environment, our approach makes explicit use of information about changes by learning and modelling the spatio-temporal dynamics of the environment where the robot is acting. The proposed spatio-temporal world model is able to predict environmental changes in time, allowing the robot to improve its localisation capabilities during long-term operations in populated environments. To investigate the proposed approach, we have enabled a mobile robot to autonomously patrol a populated environment over a period of one week while building the proposed model representation. We demonstrate that the experience learned during one week is applicable for topological localization even after a hiatus of three months by showing that the localization error rate is significantly lower compared to static environment representations.",,10.1109/IROS.2014.6943205,,,,Mathematical model;Three-dimensional displays;Predictive models;Fourier transforms;Feature extraction;Service robots;topological localisation;mobile robotics;spatio-temporal representations,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Robot-Assisted Backscatter Localization for IoT Applications,S. Zhang and W. Wang and S. Tang and S. Jin and T. Jiang,IEEE Transactions on Wireless Communications,2020,IEEE INSPEC Non-Controlled Terms,5807--5818,19,"Recent years have witnessed the rapid proliferation of backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such backscatter tags is crucial for IoT-based smart applications. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, which is laborious for deployment. To empower universal localization service, this paper presents Rover, an indoor localization system that localizes multiple backscatter tags without any start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing measurements from backscattered WiFi signals and inertial sensors to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues including interference among multiple tags, real-time processing, as well as the data marginalization problem in dealing with degenerated motions. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.",,10.1109/TWC.2020.2997393,,,,Wireless fidelity;Backscatter;Interference;Robot sensing systems;Receivers;Antenna arrays;Backscatter;localization;inertial sensor;channel state information,,1558-2248,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Lifelong localization of a mobile service-robot in everyday indoor environments using omnidirectional vision,S. Hochdorfer and M. Lutz and C. Schlegel,,2009,IEEE INSPEC Non-Controlled Terms,161--166,,"SLAM (Simultaneous Localization and Mapping) mechanisms are a key component towards advanced service robotics applications. Currently, a major hurdle on the way to lifelong localization is the handling of the ever growing amount of landmarks over time. Therefore, the required resources in terms of memory and processing power are also growing over time.",,10.1109/TEPRA.2009.5339626,,,,Indoor environments;Simultaneous localization and mapping;Upper bound;Clustering algorithms;Uncertainty;Robot vision systems;Robot localization;Observability;Global Positioning System;Mobile computing,,2325-0534,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Towards a robust visual SLAM approach: Addressing the challenge of life-long operation,S. Hochdorfer and C. Schlegel,,2009,IEEE INSPEC Non-Controlled Terms,1--6,,"Localization and mapping are fundamental problems in service robotics. Knowledge about the own pose and representations of the environment are needed for a series of high level applications. Service robots should be designed for life-long and robust operation in dynamic environments. The contribution of this paper is twofold. First, an approach to address the ever growing number of landmarks in life-long operation is presented. Typically, SLAM approaches just accumulate features over time and do not discard them anymore. Therefore, the required resources in terms of memory and processing power are growing over time. In our approach, the absolute number of landmarks can be restricted by an upper bound since we introduce a method to specifically select and replace landmarks once the upper bound has been reached. The second contribution is related to improving the robustness of the landmark assignment problem in case of image based features as needed with natural landmarks. The approach has been successfully evaluated in a real world experiment on a Pioneer-3DX platform within a complex unmodified indoor environment.",,,https://ieeexplore.ieee.org/document/5174794,,,Robustness;Simultaneous localization and mapping;Upper bound;Service robots;Computer science;Application software;Indoor environments;Collaboration;Euclidean distance,,,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Robust Loop-Closure Detection with a Learned Illumination Invariant Representation for Robot vSLAM,S. Chen and J. Wu and Y. Wang and L. Zhou and Q. Lu and Y. Zhang,,2019,IEEE INSPEC Non-Controlled Terms,342--347,,"Robust loop-closure detection plays a key role for the long-term robot visual Simultaneous Localization and Mapping (SLAM) in indoor or outdoor environment, due to illumination changes can greatly affect the accuracy of online image matching, and keypoints may fail to match between images taken at the same location but different seasons. In this paper, we propose a robust loop-closure detection method for robot visual SLAM, which adopts invariant representation as image descriptors composed of learned features and adapts to changes in illumination and seasons. We evaluate our method on real datasets and demonstrate its excellent ability to handle illumination changes.",,10.1109/ICARM.2019.8833730,,,,Visualization;Simultaneous localization and mapping;Lighting;Feature extraction;Mechatronics;Image matching;Visual SLAM;Loop Closure Detection;Visual Place Recognition;Illumination Invariant Feature;Moblie Robot;Convolutional Neural Network,,,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Relocalization With Submaps: Multi-Session Mapping for Planetary Rovers Equipped With Stereo Cameras,R. Giubilato and M. Vayugundla and M. J. Schuster and W. Stürzl and A. Wedler and R. Triebel and S. Debei,IEEE Robotics and Automation Letters,2020,IEEE INSPEC Non-Controlled Terms,580--587,5,"To enable long term exploration of extreme environments such as planetary surfaces, heterogeneous robotic teams need the ability to localize themselves on previously built maps. While the Localization and Mapping problem for single sessions can be efficiently solved with many state of the art solutions, place recognition in natural environments still poses great challenges for the perception system of a robotic agent. In this paper we propose a relocalization pipeline which exploits both 3D and visual information from stereo cameras to detect matches across local point clouds of multiple SLAM sessions. Our solution is based on a Bag of Binary Words scheme where binarized SHOT descriptors are enriched with visual cues to recall in a fast and efficient way previously visited places. The proposed relocalization scheme is validated on challenging datasets captured using a planetary rover prototype on Mount Etna, designated as a Moon analogue environment.",,10.1109/LRA.2020.2964157,,,,Three-dimensional displays;Visualization;Simultaneous localization and mapping;Vocabulary;Pipelines;Cameras;Localization;space robotics and automation;mapping,,2377-3766,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,"Automating answers to ""where am i?""",P. Newman,,2005,IEEE INSPEC Non-Controlled Terms,7pp.--,,"In many situations, large-scale, long term deployment of an autonomous vehicle requires an ability to navigate in arbitrary workspaces and must be able to establish ""where am I what surrounds me?"". This paper describe simultaneous localisation and mapping (SLAM)techniques and implementations in which an autonomous vehicle explores its workspace using onboard sensors and inextricably binds together the tasks of mapping and localisation.",,10.1049/ic:20050473,,,,,,0537-9989,,,,44698.62201,44698.62359,sousarbarb,,Duplicated,
,View management for lifelong visual maps,N. Banerjee and R. C. Connolly and D. Lisin and J. Briggs and M. E. Munich,,2019,IEEE INSPEC Non-Controlled Terms,7871--7878,,"The time complexity of making observations and loop closures in a graph-based visual SLAM system is a function of the number of views stored [1], [2]. Clever algorithms, such as approximate nearest neighbor search, can make this function sub-linear. Despite this, over time the number of views can still grow to a point at which the speed and/or accuracy of the system becomes unacceptable, especially in computation- and memory-constrained SLAM systems. However, not all views are created equal. Some views are rarely observed, because they have been created in an unusual lighting condition, or from low quality images, or in a location whose appearance has changed. These views can be removed to improve the overall performance of a SLAM system. In this paper, we propose a method for pruning views in a visual SLAM system to maintain its speed and accuracy for long term use.",,10.1109/IROS40897.2019.8968245,,,,,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Lifelong Mapping using Adaptive Local Maps,N. Banerjee and D. Lisin and J. Briggs and M. Llofriu and M. E. Munich,,2019,IEEE INSPEC Non-Controlled Terms,1--8,,"Occupancy mapping enables a mobile robot to make intelligent planning decisions to accomplish its tasks. Adaptive local maps is an algorithm which represents the occupancy information as a set of overlapping local maps anchored to poses in the robot's trajectory. At any time, a global occupancy map can be rendered from the local maps to be used for path planning. The advantage of this approach is that the occupancy information stays consistent despite the changes in the pose estimates resulting from loop closures and localization updates. The disadvantage, however, is that the number of local maps grows over time. For long robot runs, or for multiple runs in the same space, this growth will result in redundant occupancy information, which will in turn increase the time it takes to render the global map, as well as the memory footprint of the system. In this paper, we propose a novel approach for the maintenance of an adaptive local maps system, which intelligently prunes redundant local maps, ensuring the robustness and stability required for lifelong mapping.",,10.1109/ECMR.2019.8870347,,,,Simultaneous localization and mapping;Uncertainty;Mobile robots;Trajectory,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,SDF-Loc: Signed Distance Field based 2D Relocalization and Map Update in Dynamic Environments,M. Zhang and Y. Chen and M. Li,,2019,IEEE INSPEC Non-Controlled Terms,1997--2004,,"To empower an autonomous robot to perform long-term navigation in a given area, a concurrent localization and map update algorithm is required. In this paper, we tackle this problem by providing both theoretical analysis and algorithm design for robotic systems equipped with 2D laser range finders. The first key contribution of this paper is that we propose a hybrid signed distance field (SDF) framework for laser based localization. The proposed hybrid SDF integrates two methods with complementary characteristics, namely Euclidean SDF (ESDF) and Truncated SDF (TSDF). With our framework, accurate pose estimation and fast map update can be performed simultaneously. Moreover, we introduce a novel sliding window estimator which attains better accuracy by consistently utilizing sensor and map information with both scan-to-scan and scan-to-map data association. Real-world experimental results demonstrate that the proposed algorithm can be used for commercial robots in various environments with long-term usage. Experiments also show that our approach outperforms competing approaches by a wide margin.",,10.23919/ACC.2019.8814347,,,,Optimization;Robot sensing systems;Lasers;Measurement by laser beam;Two dimensional displays;Pose estimation,,2378-5861,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Efficient Long-term Mapping in Dynamic Environments,M. T. Lázaro and R. Capobianco and G. Grisetti,,2018,IEEE INSPEC Non-Controlled Terms,153--160,,"As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.",,10.1109/IROS.2018.8594310,,,,Simultaneous localization and mapping;Cloud computing;Three-dimensional displays;Two dimensional displays;Merging;Optimization,,2153-0866,,,,44698.62201,44698.624,sousarbarb,,Duplicated,
,Obstacle Persistent Adaptive Map Maintenance for Autonomous Mobile Robots using Spatio-temporal Reasoning,M. L. Pitschl and M. W. Pryor,,2019,IEEE INSPEC Non-Controlled Terms,1023--1028,,"Mobile robotic systems operate in increasingly realistic scenarios even as users have increased expectations for the duration of autonomous tasks. Mobile robots face unique challenges when operating in environments that change over time, where systems must maintain an accurate representation of the environment with respect to both spatial and temporal dimensions. This paper describes a spatio-temporal technique for extending the autonomy of a mobile robot in a changing environment. This new technique called Obstacle Persistent Adaptive Map Maintenance (OPAMM) uses navigation data collected during normal operations to perform periodic self-maintenance of its environment model. OPAMM implements a probabilistic feature persistence model to predict the survival state of obstacles and update the world model. Maintaining an accurate world model is necessary for extending the long-term autonomy of robots in realistic scenarios. Results show that robots using OPAMM had localizations scores higher than other methods, thus reducing long-term localization degradation.",,10.1109/COASE.2019.8843095,,,,Conferences;Automation;Computer aided software engineering,,2161-8089,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Erasing bad memories: Agent-side summarization for long-term mapping,M. Dymczyk and T. Schneider and I. Gilitschenski and R. Siegwart and E. Stumm,,2016,IEEE INSPEC Non-Controlled Terms,4572--4579,,"Precisely estimating the pose of an agent in a global reference frame is a crucial goal that unlocks a multitude of robotic applications, including autonomous navigation and collaboration. In order to achieve this, current state-of-the-art localization approaches collect data provided by one or more agents and create a single, consistent localization map, maintained over time. However, with the introduction of lengthier sorties and the growing size of the environments, data transfers between the backend server where the global map is stored and the agents are becoming prohibitively large. While some existing methods partially address this issue by building compact summary maps, the data transfer from the agents to the backend can still easily become unmanageable. In this paper, we propose a method that is designed to reduce the amount of data that needs to be transferred from the agent to the backend, functioning in large-scale, multi-session mapping scenarios. Our approach is based upon a landmark selection method that exploits information coming from multiple, possibly weak and correlated, landmark utility predictors; fused using learned feature coefficients. Such a selection yields a drastic reduction in data transfer while maintaining localization performance and the ability to efficiently summarize environments over time. We evaluate our approach on a data set that was autonomously collected in a dynamic indoor environment over a period of several months.",,10.1109/IROS.2016.7759673,,,,Robots;Measurement;Bandwidth;Lighting;Data transfer;Servers;Reliability,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Long-Term Localization With Time Series Map Prediction for Mobile Robots in Dynamic Environments,L. Wang and W. Chen and J. Wang,,2020,IEEE INSPEC Non-Controlled Terms,1--7,,"In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments.",,10.1109/IROS45743.2020.9468884,,,,Location awareness;Correlation;Time series analysis;Predictive models;Brain modeling;Information filters;Real-time systems,,2153-0866,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Learning Matchable Image Transformations for Long-Term Metric Visual Localization,L. Clement and M. Gridseth and J. Tomasi and J. Kelly,IEEE Robotics and Automation Letters,2020,IEEE INSPEC Non-Controlled Terms,1492--1499,5,"Long-term metric self-localization is an essential capability of autonomous mobile robots, but remains challenging for vision-based systems due to appearance changes caused by lighting, weather, or seasonal variations. While experience-based mapping has proven to be an effective technique for bridging the `appearance gap,' the number of experiences required for reliable metric localization over days or months can be very large, and methods for reducing the necessary number of experiences are needed for this approach to scale. Taking inspiration from color constancy theory, we learn a nonlinear RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature matches for images captured under different lighting and weather conditions, and use it as a pre-processing step in a conventional single-experience localization pipeline to improve its robustness to appearance change. We train this mapping by approximating the target non-differentiable localization pipeline with a deep neural network, and find that incorporating a learned low-dimensional context feature can further improve cross-appearance feature matching. Using synthetic and real-world datasets, we demonstrate substantial improvements in localization performance across day-night cycles, enabling continuous metric localization over a 30-hour period using a single mapping experience, and allowing experience-based localization to scale to long deployments with dramatically reduced data requirements.",,10.1109/LRA.2020.2967659,,,,Pipelines;Feature extraction;Visualization;Training;Measurement;Lighting;Robustness;Deep learning in robotics and automation;visual learning;visual-based navigation;localization,,2377-3766,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Research on object recognition using bag of word model for mobile robot navigation,J.-F. Yang and K. Wang and M.-A. Li and L. Liu,,2011,IEEE INSPEC Non-Controlled Terms,1735--1740,,"Robust long term positioning for autonomous mobile robots is essential for many applications. Key to a successful visual SLAM system is correctly recognizing the objects and labeling where the robot is. Local image features are popular with constructing object recognition system, which are invariant to image scaling, translation, rotation, and partially invariant to illumination changes and affine. In this paper, we proposed an object recognition method based on the bag of word model, mainly idea includes three steps as follows: firstly, a set of local image patches are sampled using a key point detector, and each patch is a descriptor based on scale invariant feature transform. Then outliers are removed by RANSAC algorithm, and the resulting distribution of descriptors is quantified by using vector quantization against a pre-specified codebook to convert it to a histogram of votes for codebook centers. Finally, a KNN algorithm is used to classify images through the resulting global descriptor vector. The experimental results show that our proposed method has a better performance against the previous methods.",,10.1109/ICMA.2011.5986295,,,,Feature extraction;Object recognition;Computational modeling;Training;Databases;Testing;Visualization;scale invariant feature transform (SIFT);bag of word (BOW);object recognition;robot navigation,,2152-744X,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Updating the visibility of a feature-based map for long-term maintenance,J. S. Berrio and J. Ward and S. Worrall and E. Nebot,,2019,IEEE INSPEC Non-Controlled Terms,1173--1179,,"Mobile vehicles operating in urban navigation applications can achieve high integrity localisation with high accuracy by using maps of the surroundings. To accomplish this, the map should always have an accurate representation of the environment. Thus, it is necessary to detect and remove the map components that no longer exist in the current environment. This maintains the map compactness and dependability while simplifying the data association problem. This paper addresses the problem of deletion of transient map components by taking advantage of the geometric connection between the map and agent poses in order to establish and update the visibility of each feature. Once the map is created an initial visibility vector is associated with every map element and updated over time. The visibility of a map element which no longer exists is reduced and ultimately removed from the map. We demonstrate our approach in a 2D feature-based map composed of poles and corners extracted from information provided by a Iidar sensor. The experimental results show the map update using a seven-month data set collected in the University of Sydney campus.",,10.1109/IVS.2019.8814189,,,,,,2642-7214,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Simultaneous Localization and Mapping for Inspection Robots in Water and Sewer Pipe Networks: A Review,J. M. Aitken and M. H. Evans and R. Worley and S. Edwards and R. Zhang and T. Dodd and L. Mihaylova and S. R. Anderson,IEEE Access,2021,IEEE INSPEC Non-Controlled Terms,140173--140198,9,"At the present time, water and sewer pipe networks are predominantly inspected manually. In the near future, smart cities will perform intelligent autonomous monitoring of buried pipe networks, using teams of small robots. These robots, equipped with all necessary computational facilities and sensors (optical, acoustic, inertial, thermal, pressure and others) will be able to inspect pipes whilst navigating, self-localising and communicating information about the pipe condition and faults such as leaks or blockages to human operators for monitoring and decision support. The predominantly manual inspection of pipe networks will be replaced with teams of autonomous inspection robots that can operate for long periods of time over a large spatial scale. Reliable autonomous navigation and reporting of faults at this scale requires effective localization and mapping, which is the estimation of the robot’s position and its surrounding environment. This survey presents an overview of state-of-the-art works on robot simultaneous localization and mapping (SLAM) with a focus on water and sewer pipe networks. It considers various aspects of the SLAM problem in pipes, from the motivation, to the water industry requirements, modern SLAM methods, map-types and sensors suited to pipes. Future challenges such as robustness for long term robot operation in pipes are discussed, including how making use of prior knowledge, e.g. geographic information systems (GIS) can be used to build map estimates, and improve multi-robot SLAM in the pipe environment.",,10.1109/ACCESS.2021.3115981,,,,Simultaneous localization and mapping;Robots;Sensors;Inspection;Service robots;Water resources;Location awareness;Water;sewer;network;pipe networks;robots;SLAM;data fusion;Bayesian estimation;visual odometry;laser and lidar scanning,,2169-3536,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Weighted Grid Partitioning for Panel-Based Bathymetric SLAM,J. Jang and J. Kim,,2019,IEEE INSPEC Non-Controlled Terms,1--6,,"Bathymetric navigation enables the long-term operation of autonomous underwater vehicles by reducing navigation drift errors with no need for GPS position fixes. In the case that a bathymetric map is not available, the simultaneous localization and mapping (SLAM) algorithm is required, but this increases computational complexity and memory requirement. Panel-based bathymetric SLAM could considerably reduce the computational burden. However, it may suffers from incorrect update when the vehicle does not belong to the updated panel. This study proposes a new update method, called weighted grid partitioning, which considers the probability distribution of a vehicle's location, and is more effective in terms of the map accuracy, computational burden, and memory usage compared to standard update methods. The feasibility of the proposed algorithm is verified through simulations.",,10.1109/OCEANSE.2019.8867531,,,,Simultaneous localization and mapping;Navigation;Probability distribution;Signal processing algorithms;Measurement uncertainty;Uncertainty;Predictive models,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Simultaneous map building and localization for an autonomous mobile robot,J. J. Leonard and H. F. Durrant-Whyte,,1991,IEEE INSPEC Non-Controlled Terms,1442--1447vol.3,,"Discusses a significant open problem in mobile robotics: simultaneous map building and localization, which the authors define as long-term globally referenced position estimation without a priori information. This problem is difficult because of the following paradox: to move precisely, a mobile robot must have an accurate environment map; however, to build an accurate map, the mobile robot's sensing locations must be known precisely. In this way, simultaneous map building and localization can be seen to present a question of 'which came first, the chicken or the egg?' (The map or the motion?) When using ultrasonic sensing, to overcome this issue the authors equip the vehicle with multiple servo-mounted sonar sensors, to provide a means in which a subset of environment features can be precisely learned from the robot's initial location and subsequently tracked to provide precise positioning.<>",,10.1109/IROS.1991.174711,,,,Mobile robots;Vehicles;Sonar navigation;Robot sensing systems;Stochastic resonance;Sensor phenomena and characterization;Target tracking;Testing;National electric code;Humans,,,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Vehicle Navigation by Visual Navigational Aids for Automatic Lunar Mission,I. Ostroumov and N. Kuzmenko,,2021,IEEE INSPEC Non-Controlled Terms,71--75,,"Nowadays the question of Moon exploration is one of the key priorities. Many Lunar robotics missions are planned in near future by different space agencies around the world. Moon has considered to be the best place for a research station with long-term human presence for finding answers on fundamental questions about the universe. Automatic navigation of starship during a landing phase on Lunar surface is already solved with a help of inertial reference system aided visual algorithms. However, questions of automatic navigation of moving and flying vehicles on the Lunar surface are still open. Inertial navigation is limited by time, self-localization and mapping algorithms require multiple unique features of relief to guarantee required accuracy for successful automatic mission complication. In the current study, we propose the deployment of a network of visual navigational aids on the Lunar surface to support ground automatic missions. A weak atmosphere of the Moon makes effective visual beacons navigation system for long areas. A network of navigational aids includes primary and secondary ground stations which are blinking synchronously. Synchronization is supported by radio waves from the primary ground station. We consider the nature of crater relief to increase operational area of the system. The Time Difference of Arrival method is used to detect vehicle position by blinking network of visual navigational aids. In the numerical application, we consider different scenarios of network configuration to support automatic vehicle navigation inside of Tycho crater. Also, deployment of visual navigational aids network will increase the number of optical features which improve performance of already used positioning methods.",,10.1109/APUAVD53804.2021.9615417,,,,Visualization;Time difference of arrival;Surface waves;Moon;Radio navigation;Unmanned aerial vehicles;Synchronization;visual navigational aids;landing and ground vehicles;automatic mission;Lunar mission;Time Difference of Arrival,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,PERSES-a vision-based interactive mobile shopping assistant,H.-M. Gross and H.-J. Boehme,,2000,IEEE INSPEC Non-Controlled Terms,80--85vol.1,1,"The paper describes the general idea, the application scenario, and selected methodological approaches of our long term research project PERSES (PERsonal SErvice System). The aim of the project consists of the development of an interactive mobile shopping assistant that allows a continuous and intuitively understandable interaction with a customer in a home improvement store. Typical tasks we have to tackle are to detect and contact potential users in the operation area, to guide them to desired areas or articles within the store or to follow them as a mobile information kiosk while continuously observing their behavior. Due to the specificity of the interaction-oriented scenario and the characteristics of the operation area, we have focused on vision based methods for both human-robot interaction and robot navigation. Besides some methodological approaches, we present preliminary results of experiments achieved with our mobile robot PERSES in the store with an emphasis on vision based methods for user localization, map building and self-localization.",,10.1109/ICSMC.2000.884968,,,,Navigation;Robot vision systems;Mobile robots;Robustness;Robot kinematics;Human robot interaction;Adaptation model;Context modeling;Programmable control;Adaptive control,,1062-922X,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Domain-Invariant Similarity Activation Map Contrastive Learning for Retrieval-Based Long-Term Visual Localization,H. Hu and H. Wang and Z. Liu and W. Chen,IEEE/CAA Journal of Automatica Sinica,2022,IEEE INSPEC Non-Controlled Terms,313--328,9,"Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the contrastive learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.",,10.1109/JAS.2021.1003907,,,,Location awareness;Visualization;Measurement;Feature extraction;Image recognition;Pipelines;Training;Deep representation learning;place recognition;visual localization,,2329-9274,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Map Updating Revisited for Navigation Map : A mathematical way to perform map updating for autonomous mobile robot,H. Chen and Z. Wang and Q. Zhu,,2021,IEEE INSPEC Non-Controlled Terms,505--508,,"Simultaneous localization and mapping, SLAM can product a Map for autonomous robots and self-driving vehicle in navigation. In the actual environment, the scene changes frequently, which makes the old map no long reliable. Therefore, it is necessary to update such a map by an efficient and safely way. In this paper, we review the existing map updating, long-term localization methods and discuss about the challenges in this situation. We present a Map updating method in mathematical way which can update accurately. Our proposed method are tested in five indoor dataset and demonstrated feasibility.",,10.1109/IPEC51340.2021.9421197,,,,Location awareness;Computers;Simultaneous localization and mapping;Navigation;Image processing;Conferences;Reliability;map;updating;visual;point cloud,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Lightweight SLAM with automatic orientation correction using 2D LiDAR scans,G. Péter and B. Kiss,,2020,IEEE INSPEC Non-Controlled Terms,1--6,,"Simultaneous localization and mapping (SLAM) is about consistent maps in the long run. Loop closing is the most popular way for ensure long-term consistency in presence of multiple measurements by the same or multiple robots. Loop closure can be executed using raw odometrical data, but a more sophisticated, yet still light-weight method is presented in this paper: a landmark descriptor-based relative displacement calculation method for diminishing unwanted orientation errors that otherwise often lead to map inconsistency. Landmark descriptors are created using light detection and ranging (LiDAR) scans and the relation is calculated using scan-matching. The novelty of this research is a method providing long-term orientation and position correction without additional overhead between landmark detections, thus enabling simple agents to do the SLAM in a cooperative way.",,10.1109/ISMCR51255.2020.9263722,,,,Manganese;SLAM;LiDAR;mapping;orientation;correction;uncertainty,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Geometry-based Graph Pruning for Lifelong SLAM,G. Kurz and M. Holoch and P. Biber,,2021,IEEE INSPEC Non-Controlled Terms,3313--3320,,"Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case).",,10.1109/IROS51168.2021.9636530,,,,Simultaneous localization and mapping;Three-dimensional displays;Costs;Density functional theory;Trajectory;Standards;Intelligent robots,,2153-0866,,,,44698.62201,44698.62426,sousarbarb,,Duplicated,
,Long-term 3D map maintenance in dynamic environments,F. Pomerleau and P. Krüsi and F. Colas and P. Furgale and R. Siegwart,,2014,IEEE INSPEC Non-Controlled Terms,3712--3719,,"New applications of mobile robotics in dynamic urban areas require more than the single-session geometric maps that have dominated simultaneous localization and mapping (SLAM) research to date; maps must be updated as the environment changes and include a semantic layer (such as road network information) to aid motion planning in dynamic environments. We present an algorithm for long-term localization and mapping in real time using a three-dimensional (3D) laser scanner. The system infers the static or dynamic state of each 3D point in the environment based on repeated observations. The velocity of each dynamic point is estimated without requiring object models or explicit clustering of the points. At any time, the system is able to produce a most-likely representation of underlying static scene geometry. By storing the time history of velocities, we can infer the dominant motion patterns within the map. The result is an online mapping and localization system specifically designed to enable long-term autonomy within highly dynamic environments. We validate the approach using data collected around the campus of ETH Zurich over seven months and several kilometers of navigation. To the best of our knowledge, this is the first work to unify long-term map update with tracking of dynamic objects.",,10.1109/ICRA.2014.6907397,,,,Three-dimensional displays;Dynamics;Simultaneous localization and mapping;Heuristic algorithms;Laser modes;Long-term mapping;dynamic obstacles;ICP;kd-tree;registration;scan matching;robot;SLAM,,1050-4729,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,ViPR: Visual-Odometry-aided Pose Regression for 6DoF Camera Localization,F. Ott and T. Feigl and C. Löffler and C. Mutschler,,2020,IEEE INSPEC Non-Controlled Terms,187--198,,"Visual Odometry (VO) accumulates a positional drift in long-term robot navigation tasks. Although Convolutional Neural Networks (CNNs) improve VO in various aspects, VO still suffers from moving obstacles, discontinuous observation of features, and poor textures or visual information. While recent approaches estimate a 6DoF pose either directly from (a series of) images or by merging depth maps with optical flow (OF), research that combines absolute pose regression with OF is limited.We propose ViPR, a novel modular architecture for longterm 6DoF VO that leverages temporal information and synergies between absolute pose estimates (from PoseNet-like modules) and relative pose estimates (from FlowNet-based modules) by combining both through recurrent layers. Experiments on known datasets and on our own Industry dataset show that our modular design outperforms state ofthe art in long-term navigation tasks.",,10.1109/CVPRW50498.2020.00029,,,,Cameras;Task analysis;Pose estimation;Feature extraction;Navigation;Optical imaging;Sensors,,2160-7516,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,SRAL: Shared Representative Appearance Learning for Long-Term Visual Place Recognition,F. Han and X. Yang and Y. Deng and M. Rentschler and D. Yang and H. Zhang,IEEE Robotics and Automation Letters,2017,IEEE INSPEC Non-Controlled Terms,1172--1179,2,"Place recognition, or loop closure detection, is an essential component to address the problem of visual simultaneous localization and mapping (SLAM). Long-term navigation of robots in outdoor environments introduces new challenges to enable life-long SLAM, including the strong appearance change resulting from vegetation, weather, and illumination variations across various times of the day, different days, months, or even seasons. In this paper, we propose a new shared representative appearance learning (SRAL) approach to address long-term visual place recognition. Different from previous methods using a single feature modality or a concatenation of multiple features, our SRAL method autonomously learns representative features that are shared in all scene scenarios, and then fuses the features together to represent the long-term appearance of environments observed by a robot during life-long navigation. By formulating SRAL as a regularized optimization problem, we use structured sparsity-inducing norms to model interrelationships of feature modalities. In addition, an optimization algorithm is developed to efficiently solve the formulated optimization problem, which holds a theoretical convergence guarantee. Extensive empirical study was performed to evaluate the SRAL method using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have shown that our SRAL method obtains superior performance for life-long place recognition using individual images, outperforms previous single image-based methods, and is capable of estimating the importance of feature modalities.",,10.1109/LRA.2017.2662061,,,,Visualization;Image recognition;Feature extraction;Simultaneous localization and mapping;Optimization;Navigation;Loop closure detection;long-term place recognition;simultaneous localization and mapping (SLAM);visual learning,,2377-3766,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Robust Place Recognition and Loop Closing in Laser-Based SLAM for UGVs in Urban Environments,F. Cao and Y. Zhuang and H. Zhang and W. Wang,IEEE Sensors Journal,2018,IEEE INSPEC Non-Controlled Terms,4242--4252,18,"Robust place recognition plays a key role for the long-term autonomy of unmanned ground vehicles (UGVs) working in indoor or outdoor environments. Although most of the state-of-the-art that approaches for place recognition are vision-based, visual sensors lack adaptability in environments with poor or dynamically changing illumination. In this paper, a 3-D-laser-based place recognition algorithm is proposed to accomplish loop closure detection for simultaneous localization and mapping. An image model named bearing angle (BA) is adopted to convert 3-D laser points to 2-D images, and then ORB features extracted from BA images are utilized to perform scene matching. Since the computational cost for matching a query BA image with all the BA images in a database is too high to meet the requirement of performing real-time place recognition, a visual bag of words approach is used to improve search efficiency. Furthermore, a speed normalization algorithm and a 3-D geometry-based verification algorithm are proposed to complete the proposed place recognition algorithm. Experiments were conducted on two self-developed UGV platforms to verify the performance of the proposed method.",,10.1109/JSEN.2018.2815956,,,,Three-dimensional displays;Lasers;Visualization;Feature extraction;Sensors;Robustness;Lighting;Laser scanning;place recognition;simultaneous localization and mapping (SLAM);unmanned ground vehicles (UGVs),,1558-1748,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Towards lifelong feature-based mapping in semi-static environments,D. M. Rosen and J. Mason and J. J. Leonard,,2016,IEEE INSPEC Non-Controlled Terms,1063--1070,,"The feature-based graphical approach to robotic mapping provides a representationally rich and computationally efficient framework for an autonomous agent to learn a model of its environment. However, this formulation does not naturally support long-term autonomy because it lacks a notion of environmental change; in reality, “everything changes and nothing stands still, ” and any mapping and localization system that aims to support truly persistent autonomy must be similarly adaptive. To that end, in this paper we propose a novel feature-based model of environmental evolution over time. Our approach is based upon the development of an expressive probabilistic generative feature persistence model that describes the survival of abstract semi-static environmental features over time. We show that this model admits a recursive Bayesian estimator, the persistence filter, that provides an exact online method for computing, at each moment in time, an explicit Bayesian belief over the persistence of each feature in the environment. By incorporating this feature persistence estimation into current state-of-the-art graphical mapping techniques, we obtain a flexible, computationally efficient, and information-theoretically rigorous framework for lifelong environmental modeling in an ever-changing world.",,10.1109/ICRA.2016.7487237,,,,Feature extraction;Detectors;Computational modeling;Adaptation models;Simultaneous localization and mapping;Bayes methods,,,,,,44698.62201,44698.62201,sousarbarb,,Duplicated,
,Development of an Autonomous Robotic System Using the Graph-based SPLAM Algorithm,D. Kozlov and V. Myasnikov,,2021,IEEE INSPEC Non-Controlled Terms,1--5,,"For long-term planning, localization and mapping, the robot must constantly update the map by the changing environment and new areas that the robot is exploring. At the same time, this map should not take up too much of the robot’s memory, since the robot’s performance is limited due to the small size of the robot and increased performance requirements. The robot must interact with the map on time, updating its location to build a further route to explore areas that have not been visited. In addition to compiling a map, when solving the problem of exploration rooms, the following steps are also important: forming a plan for bypassing an unknown room, calculating the trajectory, resolving collisions with obstacles, and following the trajectory. In the course of this work, an autonomous robotic system was developed, the task of which is to map previously unknown premises. For this, SPLAM algorithms, algorithms for building map and working with graphs, algorithms for following a trajectory were used.",,10.1109/ITNT52450.2021.9649028,,,,Measurement;Space vehicles;Memory management;Robot vision systems;Production;Real-time systems;Trajectory;SPLAM;SLAM;robot;ROS;RTABMap;Voronoi diagram;bang-bang controller;Jetson;Zed;point cloud;odometry;Dijkstra algorithm,,,,,,44698.62201,44698.62378,sousarbarb,,Duplicated,
,SLAMinDB: Centralized graph databases for mobile robotics,D. Fourie and S. Claassens and S. Pillai and R. Mata and J. Leonard,,2017,IEEE INSPEC Non-Controlled Terms,6331--6337,,"Robotic systems typically require memory recall mechanisms for a variety of tasks including localization, mapping, planning, visualization etc. We argue for a novel memory recall framework that enables more complex inference schemas by separating the computation from its associated data. In this work we propose a shared, centralized data persistence layer that maintains an ensemble of online, situationally-aware robot states. This is realized through a queryable graph-database with an accompanying key-value store for larger data. In turn, this approach is scalable and enables a multitude of capabilities such as experience-based learning and long-term autonomy. Using multi-modal simultaneous localization and mapping and a few example use-cases, we demonstrate the versatility and extensible nature that centralized persistence and SLAMinDB can provide. In order to support the notion of life-long autonomy, we envision robots to be endowed with such a persistence model, enabling them to revisit previous experiences and improve upon their existing task-specific capabilities.",,10.1109/ICRA.2017.7989749,,,,Simultaneous localization and mapping;Computer architecture;Relational databases;Navigation,,,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,"Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation",C. Linegar and W. Churchill and P. Newman,,2015,IEEE INSPEC Non-Controlled Terms,90--97,,"This paper is about life-long vast-scale localisation in spite of changes in weather, lighting and scene structure. Building upon our previous work in Experience-based Navigation [1], we continually grow and curate a visual map of the world that explicitly supports multiple representations of the same place. We refer to these representations as experiences, where a single experience captures the appearance of an environment under certain conditions. Pedagogically, an experience can be thought of as a visual memory. By accumulating experiences we are able to handle cyclic appearance change (diurnal lighting, seasonal changes, and extreme weather conditions) and also adapt to slow structural change. This strategy, although elegant and effective, poses a new challenge: In a region with many stored representations - which one(s) should we try to localise against given finite computational resources? By learning from our previous use of the experience-map, we can make predictions about which memories we should consider next, conditioned on how the robot is currently localised in the experience-map. During localisation, we prioritise the loading of past experiences in order to minimise the expected computation required. We do this in a probabilistic way and show that this memory policy significantly improves localisation efficiency, enabling long-term autonomy on robots with limited computational resources. We demonstrate and evaluate our system over three challenging datasets, totalling 206km of outdoor travel. We demonstrate the system in a diverse range of lighting and weather conditions, scene clutter, camera occlusions, and permanent structural change in the environment.",,10.1109/ICRA.2015.7138985,,,,Robots;Visualization;Cameras;Trajectory;Meteorology;Lighting;Navigation,,1050-4729,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,Input Uncertainty Sensitivity Enhanced Nonsingleton Fuzzy Logic Controllers for Long-Term Navigation of Quadrotor UAVs,C. Fu and A. Sarabakha and E. Kayacan and C. Wagner and R. John and J. M. Garibaldi,IEEE/ASME Transactions on Mechatronics,2018,IEEE INSPEC Non-Controlled Terms,725--734,23,"Input uncertainty, e.g., noise on the on-board camera and inertial measurement unit, in vision-based control of unmanned aerial vehicles (UAVs) is an inevitable problem. In order to handle input uncertainties as well as further analyze the interaction between the input and the antecedent fuzzy sets (FSs) of nonsingleton fuzzy logic controllers (NSFLCs), an input uncertainty sensitivity enhanced NSFLC has been developed in robot operating system using the C++ programming language. Based on recent advances in nonsingleton inference, the centroid of the intersection of the input and antecedent FSs (Cen-NSFLC) is utilized to calculate the firing strength of each rule instead of the maximum of the intersection used in traditional NSFLC (Tra-NSFLC). An 8-shaped trajectory, consisting of straight and curved lines, is used for the real-time validation of the proposed controllers for a trajectory following problem. An accurate monocular keyframe-based visual-inertial simultaneous localization and mapping (SLAM) approach is used to estimate the position of the quadrotor UAV in GPS-denied unknown environments. The performance of the Cen-NSFLC is compared with a conventional proportional-integral derivative (PID) controller, a singleton FLC and a Tra-NSFLC. All controllers are evaluated for different flight speeds, thus introducing different levels of uncertainty into the control problem. Visual-inertial SLAM-based real-time quadrotor UAV flight tests demonstrate that not only does the Cen-NSFLC achieve the best control performance among the four controllers, but it also shows better control performance when compared to their singleton counterparts. Considering the bias in the use of model-based controllers, e.g., PID, for the control of UAVs, this paper advocates an alternative method, namely Cen-NSFLCs, in uncertain working environments.",,10.1109/TMECH.2018.2810947,,,,Uncertainty;Simultaneous localization and mapping;Frequency selective surfaces;Real-time systems;IEEE transactions;Mechatronics;Fuzzy logic controller (FLC);input uncertainty sensitivity enhanced nonsingleton FLC (NSFLC);monocular visual-inertial simultaneous localization and mapping (SLAM);NSFLC;unmanned aerial vehicle (UAV),,1941-014X,,,,44698.62201,44698.62201,sousarbarb,,Unclassified,
,A B-Spline Mapping Framework for Long-Term Autonomous Operations,R. T. Rodrigues and A. P. Aguiar and A. Pascoal,,2018,IEEE Index Terms,3204--3209,,"This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.",,10.1109/IROS.2018.8594456,,,,Splines (mathematics);Simultaneous localization and mapping;Three-dimensional displays;Robot kinematics;Two dimensional displays,,2153-0866,,,,44698.62163,44698.62314,sousarbarb,,Duplicated,
,"3D localization, mapping and path planning for search and rescue operations",R. Dubé and A. Gawel and C. Cadena and R. Siegwart and L. Freda and M. Gianni,,2016,IEEE INSPEC Non-Controlled Terms,272--273,,"This work presents our results on 3D robot localization, mapping and path planning for the latest joint exercise of the European project “Long-Term Human-Robot Teaming for Robots Assisted Disaster Response” (TRADR)1. The full system is operated and evaluated by firemen end-users in real-world search and rescue experiments. We demonstrate that the system is able to plan a path to a goal position desired by the fireman operator in the TRADR Operational Control Unit (OCU), using a persistent 3D map created by the robot during previous sorties.",,10.1109/SSRR.2016.7784311,,,,Three-dimensional displays;Path planning;Simultaneous localization and mapping;Navigation;Lasers,,,,,,44698.62201,44698.62309,sousarbarb,,Duplicated,
,"1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image",G. Kim and B. Park and A. Kim,IEEE Robotics and Automation Letters,2019,IEEE INSPEC Non-Controlled Terms,1948--1955,4,"In this letter, we present a long-term localization method that effectively exploits the structural information of an environment via an image format. The proposed method presents a robust year-round localization performance even when learned in just a single day. The proposed localizer learns a point cloud descriptor, named Scan Context Image (SCI), and performs robot localization on a grid map by formulating the place recognition problem as place classification using a convolutional neural network. Our method is faster than existing methods proposed for place recognition because it avoids a pairwise comparison between a query and scans in a database. In addition, we provide thorough validations using publicly available long-term datasets, the NCLT dataset and the Oxford RobotCar dataset, and show that the Scan Context Image (SCI) localization attains consistent performance over a year and outperforms existing methods.",,10.1109/LRA.2019.2897340,,,,Three-dimensional displays;Training;Laser radar;Entropy;Databases;Robot localization;Localization;range sensing;SLAM,,2377-3766,,,,44698.62201,44698.62302,sousarbarb,,Duplicated,
,SLAM using LTE Multipath Component Delays,J. Chen and M. Zhu and F. Tufvesson,,2020,IEEE INSPEC Controlled Terms,1--5,,"Cellular radio based localization can be an important complement or alternative to other localization technologies, as base stations continuously transmit signals of opportunity with beneficial positioning properties. In this paper, we use the long term evolution (LTE) cell-specific reference signal for this purpose. The multipath component delays are estimated by the ESPRIT algorithm, and the estimated multipath component delays of different snapshots are associated by global nearest neighbor with a Kalman filter. Rao-Blackwellized particle filter based simultaneous localization and mapping (SLAM) is then applied to estimate the position of user equipment and that of the base station and virtual transmitters. In a measurement campaign, data from one base station was logged, and the analysis based on the data shows that, at the end of the measurement, the SLAM performance is 11 meters better than that with only inertial measurement unit (IMU).",,10.1109/VTC2020-Spring48590.2020.9128437,,,,Delays;Simultaneous localization and mapping;Kalman filters;Receivers;Global navigation satellite system;Long Term Evolution;Base stations;MPC delay;SLAM;positioning;particle filter;LTE;CRS,,2577-2465,,,,44698.6219,44698.6219,sousarbarb,,Unclassified,
,Generic Node Removal for Factor-Graph SLAM,N. Carlevaris-Bianco and M. Kaess and R. M. Eustice,IEEE Transactions on Robotics,2014,IEEE Author Keywords,1371--1385,30,"This paper reports on a generic factor-based method for node removal in factor-graph simultaneous localization and mapping (SLAM), which we call generic linear constraints (GLCs). The need for a generic node removal tool is motivated by long-term SLAM applications, whereby nodes are removed in order to control the computational cost of graph optimization. GLC is able to produce a new set of linearized factors over the elimination clique that can represent either the true marginalization (i.e., dense GLC) or a sparse approximation of the true marginalization using a ChowLiu tree (i.e., sparse GLC). The proposed algorithm improves upon commonly used methods in two key ways: First, it is not limited to graphs with strictly full-state relative-pose factors and works equally well with other low-rank factors, such as those produced by monocular vision. Second, the new factors are produced in such a way that accounts for measurement correlation, which is a problem encountered in other methods that rely strictly upon pairwise measurement composition. We evaluate the proposed method over multiple real-world SLAM graphs and show that it outperforms other recently proposed methods in terms of Kullback-Leibler divergence. Additionally, we experimentally demonstrate that the proposed GLC method provides a principled and flexible tool to control the computational complexity of long-term graph SLAM, with results shown for 34.9 h of real-world indoor-outdoor data covering 147.4 km collected over 27 mapping sessions spanning a period of 15 months.",,10.1109/TRO.2014.2347571,,,,Simultaneous localization and mapping;Optimization;Approximation methods;Correlation;Mobile robots;Factor-graphs;long-term autonomy;marginalization;mobile robotics;simultaneous localization and mapping (SLAM);Factor-graphs;long-term autonomy;marginalization;mobile robotics;simultaneous localization and mapping (SLAM),,1941-0468,,,,44698.62178,44698.62178,sousarbarb,,Unclassified,
,Accurate Dynamic SLAM Using CRF-Based Long-Term Consistency,Z.-J. Du and S.-S. Huang and T.-J. Mu and Q. Zhao and R. R. Martin and K. Xu,IEEE Transactions on Visualization and Computer Graphics,2022,IEEE Index Terms,1745--1757,28,"Accurate camera pose estimation is essential and challenging for real world dynamic 3D reconstruction and augmented reality applications. In this article, we present a novel RGB-D SLAM approach for accurate camera pose tracking in dynamic environments. Previous methods detect dynamic components only across a short time-span of consecutive frames. Instead, we provide a more accurate dynamic 3D landmark detection method, followed by the use of long-term consistency via conditional random fields, which leverages long-term observations from multiple frames. Specifically, we first introduce an efficient initial camera pose estimation method based on distinguishing dynamic from static points using graph-cut RANSAC. These static/dynamic labels are used as priors for the unary potential in the conditional random fields, which further improves the accuracy of dynamic 3D landmark detection. Evaluation using the TUM and Bonn RGB-D dynamic datasets shows that our approach significantly outperforms state-of-the-art methods, providing much more accurate camera trajectory estimation in a variety of highly dynamic environments. We also show that dynamic 3D reconstruction can benefit from the camera poses estimated by our RGB-D SLAM approach.",,10.1109/TVCG.2020.3028218,,,,"Cameras;Simultaneous localization and mapping;Three-dimensional displays;Visualization;Pose estimation;Dynamics;Robustness;RGB-D SLAM;dynamic SLAM;long-term consistency;conditional random fields,graph-cut RANSAC",,1941-0506,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Visual place recognition with CNNs: From global to partial,Z. Xin and X. Cui and J. Zhang and Y. Yang and Y. Wang,,2017,IEEE Index Terms,1--6,,"Visual place recognition is one of the most challenging problems in computer vision, due to the large diversities that real-world places can represent. Recently, visual place recognition has become a key part of loop closure detection and topological localization in long-term mobile robot autonomy. In this work, we build up a novel visual place recognition pipeline composed of a first filtering stage followed by a partial reranking process. In the filtering stage, image-wise features are utilized to find a small set of potential places. Afterwards, stable region-wise landmarks are extracted for more accurate matching in the partial reranking process. All global and partial image representations are derived from pre-trained Convolutional Neural Networks (CNNs), and the landmarks are extracted by object proposal techniques. Moreover, a new similarity measurement is provided by considering both spatial and scale distribution of landmarks. Compared with current methods only considering scale distribution, the presented similarity measurement can benefit recognition precision and robustness effectively. Experiments with varied viewpoints and environmental conditions demonstrate that the proposed method achieves superior performance against state-of-the-art methods.",,10.1109/IPTA.2017.8310121,,,,Feature extraction;Visualization;Robustness;Proposals;Lighting;Pipelines;Convolutional neural networks;visual place recognition;localization;convolutional neural networks;long-term environment,,2154-512X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,An 879GOPS 243mW 80fps VGA Fully Visual CNN-SLAM Processor for Wide-Range Autonomous Exploration,Z. Li and Y. Chen and L. Gong and L. Liu and D. Sylvester and D. Blaauw and H.-S. Kim,,2019,IEEE Index Terms,134--136,,"Simultaneous localization and mapping (SLAM) estimates an agent's trajectory for all six degrees of freedom (6 DoF) and constructs a 3D map of an unknown surrounding. It is a fundamental kernel that enables head-mounted augmented/virtual reality devices and autonomous navigation of micro aerial vehicles. A noticeable recent trend in visual SLAM is to apply computationand memory-intensive convolutional neural networks (CNNs) that outperform traditional hand-designed feature-based methods [1]. For each video frame, CNN-extracted features are matched with stored keypoints to estimate the agent's 6-DoF pose by solving a perspective-n-points (PnP) non-linear optimization problem (Fig. 7.3.1, left). The agent's long-term trajectory over multiple frames is refined by a bundle adjustment process (BA, Fig. 7.3.1 right), which involves a large-scale (~120 variables) non-linear optimization. Visual SLAM requires massive computation (>250GOP/s) in the CNN-based feature extraction and matching, as well as datadependent dynamic memory access and control flow with high-precision operations, creating significant low-power design challenges. Software implementations are impractical, resulting in 0.2s runtime with a ~3GHz CPU+ GPU system with >100MB memory footprint and >100W power consumption. Prior ASICs have implemented either an incomplete SLAM system [2,3] that lacks estimation of ego-motion or employed a simplified (non-CNN) feature extraction and tracking [2,4,5] that limits SLAM quality and range. A recent ASIC [5] augments visual SLAM with an off-chip high-precision inertial measurement unit (IMU), simplifying the computational complexity, but incurring additional power and cost overhead.",,10.1109/ISSCC.2019.8662397,,,,Simultaneous localization and mapping;Engines;Three-dimensional displays;Two dimensional displays;Feature extraction;Visualization;Trajectory,,2376-8606,,,,44698.62163,44698.62332,sousarbarb,,Duplicated,
,Learning Context Flexible Attention Model for Long-Term Visual Place Recognition,Z. Chen and L. Liu and I. Sa and Z. Ge and M. Chli,IEEE Robotics and Automation Letters,2018,IEEE Index Terms,4015--4022,3,"Identifying regions of interest in an image has long been of great importance in a wide range of tasks, including place recognition. In this letter, we propose a novel attention mechanism with flexible context, which can be incorporated into existing feedforward network architecture to learn image representations for long-term place recognition. In particular, in order to focus on regions that contribute positively to place recognition, we introduce a multiscale context-flexible network to estimate the importance of each spatial region in the feature map. Our model is trained end-to-end for place recognition and can detect regions of interest of arbitrary shape. Extensive experiments have been conducted to verify the effectiveness of our approach and the results demonstrate that our model can achieve consistently better performance than the state of the art on standard benchmark datasets. Finally, we visualize the learned attention maps to generate insights into what attention the network has learned.",,10.1109/LRA.2018.2859916,,,,Feature extraction;Visualization;Image recognition;Task analysis;Context modeling;Shape;Data mining;Localization;deep learning in robotics and automation;visual-based navigation,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Day and Night Collaborative Dynamic Mapping in Unstructured Environment Based on Multimodal Sensors,Y. Yue and C. Yang and J. Zhang and M. Wen and Z. Wu and H. Zhang and D. Wang,,2020,IEEE Index Terms,2981--2987,,"Enabling long-term operation during day and night for collaborative robots requires a comprehensive understanding of the unstructured environment. Besides, in the dynamic environment, robots must be able to recognize dynamic objects and collaboratively build a global map. This paper proposes a novel approach for dynamic collaborative mapping based on multimodal environmental perception. For each mission, robots first apply heterogeneous sensor fusion model to detect humans and separate them to acquire static observations. Then, the collaborative mapping is performed to estimate the relative position between robots and local 3D maps are integrated into a globally consistent 3D map. The experiment is conducted in the day and night rainforest with moving people. The results show the accuracy, robustness, and versatility in 3D map fusion missions.",,10.1109/ICRA40945.2020.9197072,,,,Collaboration;Three-dimensional displays;Simultaneous localization and mapping;Cameras;Robot vision systems,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Vision-Aided Multi-UAV Autonomous Flocking in GPS-Denied Environment,Y. Tang and Y. Hu and J. Cui and F. Liao and M. Lao and F. Lin and R. S. H. Teo,IEEE Transactions on Industrial Electronics,2019,IEEE Index Terms,616--626,66,"This paper presents a sophisticated vision-aided flocking system for unmanned aerial vehicles (UAVs), which is able to operate in GPS-denied unknown environments for exploring and searching missions, and also able to adopt two types of vision sensors, day and thermal cameras, to measure relative motion between UAVs in different lighting conditions without using wireless communication. In order to realize robust vision-aided flocking, an integrated framework of tracking-learning-detection on the basis of multifeature coded correlation filter has been developed. To achieve long-term tracking, a redetector is trained online to adaptively reinitialize target for global sensing. An advanced flocking strategy is developed to address the autonomous multi-UAVs' cooperative flight. Light detection and ranging (LiDAR)-based navigation modules are developed for autonomous localization, mapping, and obstacle avoidance. Flight experiments of a team of UAVs have been conducted to verify the performance of this flocking system in a GPS-denied environment. The extensive experiments validate the robustness of the proposed vision algorithms in challenging scenarios.",,10.1109/TIE.2018.2824766,,,,Target tracking;Sensors;Cameras;Correlation;Trajectory;Robustness;Visualization;Flocking;unmanned system;visual sensing,,1557-9948,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Structure-SLAM: Low-Drift Monocular SLAM in Indoor Environments,Y. Li and N. Brasch and Y. Wang and N. Navab and F. Tombari,IEEE Robotics and Automation Letters,2020,IEEE Index Terms,6583--6590,5,"In this letter a low-drift monocular SLAM method is proposed targeting indoor scenarios, where monocular SLAM often fails due to the lack of textured surfaces. Our approach decouples rotation and translation estimation of the tracking process to reduce the long-term drift in indoor environments. In order to take full advantage of the available geometric information in the scene, surface normals are predicted by a convolutional neural network from each input RGB image in real-time. First, a drift-free rotation is estimated based on lines and surface normals using spherical mean-shift clustering, leveraging the weak Manhattan World assumption. Then translation is computed from point and line features. Finally, the estimated poses are refined with a map-to-frame optimization strategy. The proposed method outperforms the state of the art on common SLAM benchmarks such as ICL-NUIM and TUM RGB-D.",,10.1109/LRA.2020.3015456,,,,Simultaneous localization and mapping;Feature extraction;Pose estimation;Indoor environments;Cameras;Three-dimensional displays;SLAM;visual learning,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Keyframes retrieval for robust long-term visual localization in changing conditions,Y. Bouaziz and E. Royer and G. Bresson and M. Dhome,,2021,IEEE Index Terms,000093--000100,,"Appearance changes are a challenge for visual localization in outdoor environments. Revisiting familiar places but retrieving keyframes that were taken under different environmental condition can result in inaccurate localization. To overcome this difficulty, we propose a localization approach able to take advantage of a visual landmark map composed of N sequences gathered at different times and conditions. During this localization process, we exploit information collected in the beginning of the trajectory to compute a ranking function which will be used in the rest of the trajectory to retrieve from the map the keyframes that maximise the number of matched points. The retrieval depends on the geometric distance between the pose of the keyframe and the current pose of the vehicle, and the similarity of this keyframe with the current environmental condition. The results demonstrate that our approach has significantly improved localization performance in challenging conditions (snow, rain, change of season ...).",,10.1109/SAMI50585.2021.9378614,,,,Location awareness;Visualization;Rain;Navigation;Snow;Probabilistic logic;Trajectory;Visual-Based Navigation;Computer Vision for Transportation;SLAM,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Long-term Localization of Mobile Robots in Dynamic Changing Environments,X. Hu and J. Wang and W. Chen,,2018,IEEE Index Terms,384--389,,"Long-term localization in dynamic changing environments is still a challenge in robotics. Traditional localization algorithms typically assume that the environment is static. However, in many real-world applications, such as parking lots and industrial plants, there are always dynamic objects (e.g. moving people) and semi-dynamic objects (e.g. parked cars and placed goods). In this paper we address this challenge by introducing a long-term localization algorithm in the environments which combine dynamic objects and semi-dynamic objects. Localizability-based-updating particle filter (LU-P F) algorithm is proposed here. Not only we use localizability matric to build an updating mechanism, but also it is used for localization system. Besides, we propose the dynamic factor as long-memory information to serve as prior knowledge, which improves the robustness of updating process. Experiments in parking lots demonstrate that our approach has better localization results with a more accurate up-to-date map compared to other methods.",,10.1109/CAC.2018.8623046,,,,Heuristic algorithms;Robots;Measurement by laser beam;Laboratories;Particle filters;Hidden Markov models;Mathematical model;long-term localization;map updating mechanism;localizability;dynamic factor,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Communication constrained cloud-based long-term visual localization in real time,X. Ding and Y. Wang and L. Tang and H. Yin and R. Xiong,,2019,IEEE Index Terms,2159--2166,,"Visual localization is one of the primary capabilities for mobile robots. Long-term visual localization in real time is particularly challenging, in which the robot is required to efficiently localize itself using visual data where appearance may change significantly over time. In this paper, we propose a cloud-based visual localization system targeting at long-term localization in real time. On the robot, we employ two estimators to achieve accurate and real-time performance. One is a sliding-window based visual inertial odometry, which integrates constraints from consecutive observations and self-motion measurements, as well as the constraints induced by localization results from the cloud. This estimator builds a local visual submap as the virtual observation which is then sent to the cloud as new localization constraints. The other one is a delayed state Extended Kalman Filter to fuse the pose of the robot localized from the cloud, the local odometry and the high-frequency inertial measurements. On the cloud, we propose a longer sliding-window based localization method to aggregate the virtual observations for larger field of view, leading to more robust alignment between virtual observations and the map. Under this architecture, the robot can achieve drift-free and real-time localization using onboard resources even in a network with limited bandwidth, high latency and existence of package loss, which enables the autonomous navigation in real-world environment. We evaluate the effectiveness of our system on a dataset with challenging seasonal and illuminative variations. We further validate the robustness of the system under challenging network conditions.",,10.1109/IROS40897.2019.8968550,,,,,,2153-0866,,,,44698.62163,44698.62374,sousarbarb,,Duplicated,
,Bathymetric factor graph SLAM with sparse point cloud alignment,V. Bichucher and J. M. Walls and P. Ozog and K. A. Skinner and R. M. Eustice,,2015,IEEE Index Terms,1--7,,"This paper reports on a factor graph simultaneous localization and mapping framework for autonomous underwater vehicle localization based on terrain-aided navigation. The method requires no prior bathymetric map and only assumes that the autonomous underwater vehicle has the ability to sparsely sense the local water column depth, such as with a bottom-looking Doppler velocity log. Since dead-reckoned navigation is accurate in short time windows, the vehicle accumulates several water column depth point clouds- or submaps-during the course of its survey. We propose an xy-alignment procedure between these submaps in order to enforce consistent bathymetric structure over time, and therefore attempt to bound long-term navigation drift. We evaluate the submap alignment method in simulation and present performance results from multiple autonomous underwater vehicle field trials.",,10.23919/OCEANS.2015.7404433,,,,Simultaneous localization and mapping;Three-dimensional displays;Vehicles;Trajectory;Smoothing methods;Global Positioning System,,,,,,44698.62163,44698.62366,sousarbarb,,Duplicated,
,Scalable Change Detection from 3D Point Cloud Maps: Invariant Map Coordinate for Joint Viewpoint-Change Localization,T. Yoshiki and T. Kanji and Y. Naiming,,2018,IEEE Index Terms,1115--1121,,"This study addresses the problem of visual change detection using a 3D point cloud (PC) map acquired by a car-like robot. With recent advances in long-term autonomous navigation, change detection under global viewpoint uncertainty has become a topic of considerable interest. In our study, we extend the traditional two-level pipeline of change detection: (1) scene registration and (2) scene comparison, to enable scalable and efficient change detection. In the traditional pipeline, the registration stage is required to align a given scene pair (i.e., query and reference PC maps) that are taken at different times into the same coordinate system, before comparing the two PCs. However, the registration stage is a time-consuming step, which makes it harder to realize a scalable change detection. Our key concept is to transform every query or reference PC beforehand into an invariant coordinate system, which should be predefined and invariant to environment changes (e.g., dynamic objects, clutters, the mapper vehicle's trajectories), so as to enable a direct comparison of spatial layout between the two different maps. The proposed framework employs an efficient bag-of-local-features (BoLF) scene model and realizes a scalable joint viewpoint-change detection. Change detection experiments using a publicly available cross-season NCLT dataset validate the efficacy of the approach.",,10.1109/ITSC.2018.8569294,,,,Three-dimensional displays;Task analysis;Layout;Visualization;Feature extraction;Uncertainty;Robots,,2153-0017,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Semantics-aware visual localization under challenging perceptual conditions,T. Naseer and G. L. Oliveira and T. Brox and W. Burgard,,2017,IEEE Index Terms,2614--2620,,"Visual place recognition under difficult perceptual conditions remains a challenging problem due to changing weather conditions, illumination and seasons. Long-term visual navigation approaches for robot localization should be robust to these dynamics of the environment. Existing methods typically leverage feature descriptions of whole images or image regions from Deep Convolutional Neural Networks. Some approaches also exploit sequential information to alleviate the problem of spatially inconsistent and non-perfect image matches. In this paper, we propose a novel approach for learning a discriminative holistic image representation which exploits the image content to create a dense and salient scene description. These salient descriptions are learnt over a variety of datasets under large perceptual changes. Such an approach enables us to precisely segment the regions of an image which are geometrically stable over large time lags. We combine features from these salient regions and an off-the-shelf holistic representation to form a more robust scene descriptor. We also introduce a semantically labeled dataset which captures extreme perceptual and structural scene dynamics over the course of 3 years. We evaluated our approach with extensive experiments on data collected over several kilometers in Freiburg and show that our learnt image representation outperforms off-the-shelf features from the deep networks and hand-crafted features.",,10.1109/ICRA.2017.7989305,,,,Robustness;Image segmentation;Visualization;Training;Feature extraction;Semantics;Computer architecture,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Mining visual phrases for long-term visual SLAM,T. Kanji and C. Yuuto and A. Masatoshi,,2014,IEEE Index Terms,136--142,,"We propose a discriminative and compact scene descriptor for single-view place recognition that facilitates long-term visual SLAM in familiar, semi-dynamic and partially changing environments. In contrast to popular bag-of-words scene descriptors, which rely on a library of vector quantized visual features, our proposed scene descriptor is based on a library of raw image data (such as an available visual experience, images shared by other colleague robots, and publicly available image data on the web) and directly mine it to find visual phrases (VPs) that discriminatively and compactly explain an input query / database image. Our mining approach is motivated by recent success in the field of common pattern discovery-specifically mining of common visual patterns among scenes-and requires only a single library of raw images that can be acquired at different time or day. Experimental results show that even though our scene descriptor is significantly more compact than conventional descriptors it has a relatively higher recognition performance.",,10.1109/IROS.2014.6942552,,,,Visualization;Libraries;Simultaneous localization and mapping;Computational modeling;Vectors;Visual databases,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Duplicated,
,Detection-by-Localization: Maintenance-Free Change Object Detector,T. Kanji,,2019,IEEE Index Terms,4348--4355,,"Recent researches demonstrate that selflocalization performance is a very useful measure of likelihood-of-change (LoC) for change detection. In this paper, this “detection-by-localization” scheme is studied in a novel generalized task of object-level change detection. In our framework, a given query image is segmented into object-level subimages (termed “scene parts”), which are then converted to subimagelevel pixel-wise LoC maps via the detection-by-localization scheme. Our approach models a self-localization system as a ranking function, outputting a ranked list of reference images, without requiring relevance score. Thanks to this new setting, we can generalize our approach to a broad class of selflocalization systems. We further propose an aggregation of different self-localization results from different queries so as to achieve higher precision. Our ranking based self-localization model allows to fuse self-localization results from different modalities via an unsupervised rank fusion derived from a field of multi-modal information retrieval (MMR). Our framework does not rely on the raw-score-merging hypothesis. Challenging experiments of cross-season change detection using the publicly available North Campus Long-Term (NCLT) dataset validates the efficacy of our proposed method.",,10.1109/ICRA.2019.8793482,,,,Image segmentation;Task analysis;Robots;Computational modeling;Visualization;Databases;Real-time systems,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition,S. Siva and H. Zhang,,2018,IEEE Index Terms,5175--5181,,"Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.",,10.1109/ICRA.2018.8461042,,,,Feature extraction;Sensor phenomena and characterization;Simultaneous localization and mapping;Optimization,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,How to Match Tracks of Visual Features for Automotive Long-Term SLAM,S. Luthardt and C. Ziegler and V. Willert and J. Adamy,,2019,IEEE Index Terms,934--941,,"Accurate localization is a vital prerequisite for future assistance or autonomous driving functions in intelligent vehicles. To achieve the required localization accuracy and availability, long-term visual SLAM algorithms like LLama-SLAM are a promising option. In such algorithms visual feature tracks, i. e. landmark observations over several consecutive image frames, have to be matched to feature tracks recorded days, weeks or months earlier. This leads to a more challenging matching problem than in short-term visual localization and known descriptor matching methods cannot be applied directly. In this paper, we devise several approaches to compare and match feature tracks and evaluate their performance on a long-term data set. With the proposed descriptor combination and masking (""CoMa"") method the best track matching performance is achieved with minor computational cost. This method creates a single combined descriptor for each feature track and furthermore increases the robustness by capturing the appearance variations of this track in a descriptor mask.",,10.1109/ITSC.2019.8916895,,,,Visualization;Feature extraction;Optimization;Simultaneous localization and mapping;Cameras;Robustness,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Scale-preserving long-term visual odometry for indoor navigation,S. Hilsenbeck and A. Möller and R. Huitl and G. Schroth and M. Kranz and E. Steinbach,,2012,IEEE Index Terms,1--10,,"We present a visual odometry system for indoor navigation with a focus on long-term robustness and consistency. As our work is targeting mobile phones, we employ monocular SLAM to jointly estimate a local map and the device's trajectory. We specifically address the problem of estimating the scale factor of both, the map and the trajectory. State-of-the-art solutions approach this problem with an Extended Kalman Filter (EKF), which estimates the scale by fusing inertial and visual data, but strongly relies on good initialization and takes time to converge. Each visual tracking failure introduces a new arbitrary scale factor, forcing the filter to re-converge. We propose a fast and robust method for scale initialization that exploits basic geometric properties of the learned local map. Using random projections, we efficiently compute geometric properties from the feature point cloud produced by the visual SLAM system. From these properties (e.g., corridor width or height) we estimate scale changes caused by tracking failures and update the EKF accordingly. As a result, previously achieved convergence is preserved despite re-initializations of the map. To minimize the time required to continue tracking after failure, we perform recovery and re-initialization in parallel. This increases the time available for recovery and hence the likelihood for success, thus allowing almost seamless tracking. Moreover, fewer re-initializations are necessary. We evaluate our approach using extensive and diverse indoor datasets. Results demonstrate that errors and convergence times for scale estimation are considerably reduced, thus ensuring consistent and accurate scale estimation. This enables long-term odometry despite of tracking failures which are inevitable in realistic scenarios.",,10.1109/IPIN.2012.6418934,,,,Visualization;Buildings;Cameras;Estimation;Navigation;Measurement;Robustness,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Lingodroids: Cross-Situational Learning for Episodic Elements,S. Heath and D. Ball and J. Wiles,IEEE Transactions on Cognitive and Developmental Systems,2016,IEEE Index Terms,3--14,8,"For robots to effectively bootstrap the acquisition of language, they must handle referential uncertainty-the problem of deciding what meaning to ascribe to a given word. Typically when socially grounding terms for space and time, the underlying sensor or representation was specified within the grammar of a conversation, which constrained language learning to words for innate features. In this paper, we demonstrate that cross-situational learning resolves the issues of referential uncertainty for bootstrapping a language for episodic space and time; therefore removing the need to specify the underlying sensors or representations a priori. The requirements for robots to be able to link words to their designated meanings are presented and analyzed within the Lingodroids-language learning robots-framework. We present a study that compares predetermined associations given a priori against unconstrained learning using cross-situational learning. This study investigates the long-term coherence, immediate usability and learning time for each condition. Results demonstrate that for unconstrained learning, the long-term coherence is unaffected, though at the cost of increased learning time and hence decreased immediate usability.",,10.1109/TAMD.2015.2442619,,,,Grounding;Cognition;Uncertainty;Context;Simultaneous localization and mapping;Cross-situational learning;episodic;language learning;Lingodroids;robots;space;symbol grounding;time,,2379-8939,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Monitoring of Benthic Reference Sites: Using an Autonomous Underwater Vehicle,S. B. Williams and O. R. Pizarro and M. V. Jakuba and C. R. Johnson and N. S. Barrett and R. C. Babcock and G. A. Kendrick and P. D. Steinberg and A. J. Heyward and P. J. Doherty and I. Mahon and M. Johnson-Roberson and D. Steinberg and A. Friedman,IEEE Robotics Automation Magazine,2012,IEEE Index Terms,73--84,19,"We have established an Australia-wide observation program that exhibits recent developments in autonomous underwater vehicle (AUV) systems to deliver precisely navigated time series benthic imagery at selected reference stations on Australia's continental shelf. These observations are designed to help characterize changes in benthic assemblage composition and cover derived from precisely registered maps collected at regular intervals. This information will provide researchers with the baseline ecological data necessary to make quantitative inferences about the long-term effects of climate change and human activities on the benthos. Incorporating a suite of observations that capitalize on the unique capabilities of AUVs into Australia's integrated marine observation system (IMOS) [1] is providing a critical link between oceanographic and benthic processes. IMOS is a nationally coordinated program designed to establish and maintain the research infrastructure required to support Australia's marine science research. It has, and will maintain, a strategic focus on the impact of major boundary currents on continental shelf environments, ecosystems, and biodiversity. The IMOS AUV facility observation program is designed to generate physical and biological observations of benthic variables that cannot be cost effectively obtained by other means.",,10.1109/MRA.2011.2181772,,,,Ecosystems;Navigation;Australia;Simultaneous localization and mapping;Oceans;Biodiversity;Underwater vehicles;Meteorology;Human factors,,1558-223X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Online global loop closure detection for large-scale multi-session graph-based SLAM,M. Labbé and F. Michaud,,2014,IEEE Abstract,2661--2666,,"For large-scale and long-term simultaneous localization and mapping (SLAM), a robot has to deal with unknown initial positioning caused by either the kidnapped robot problem or multi-session mapping. This paper addresses these problems by tying the SLAM system with a global loop closure detection approach, which intrinsically handles these situations. However, online processing for global loop closure detection approaches is generally influenced by the size of the environment. The proposed graph-based SLAM system uses a memory management approach that only consider portions of the map to satisfy online processing requirements. The approach is tested and demonstrated using five indoor mapping sessions of a building using a robot equipped with a laser rangefinder and a Kinect.",,10.1109/IROS.2014.6942926,,,,Optimization;Simultaneous localization and mapping;Memory management;Visualization;Lasers;Three-dimensional displays,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Obstacle Persistent Adaptive Map Maintenance for Autonomous Mobile Robots using Spatio-temporal Reasoning,M. L. Pitschl and M. W. Pryor,,2019,IEEE Abstract,1023--1028,,"Mobile robotic systems operate in increasingly realistic scenarios even as users have increased expectations for the duration of autonomous tasks. Mobile robots face unique challenges when operating in environments that change over time, where systems must maintain an accurate representation of the environment with respect to both spatial and temporal dimensions. This paper describes a spatio-temporal technique for extending the autonomy of a mobile robot in a changing environment. This new technique called Obstacle Persistent Adaptive Map Maintenance (OPAMM) uses navigation data collected during normal operations to perform periodic self-maintenance of its environment model. OPAMM implements a probabilistic feature persistence model to predict the survival state of obstacles and update the world model. Maintaining an accurate world model is necessary for extending the long-term autonomy of robots in realistic scenarios. Results show that robots using OPAMM had localizations scores higher than other methods, thus reducing long-term localization degradation.",,10.1109/COASE.2019.8843095,,,,Conferences;Automation;Computer aided software engineering,,2161-8089,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Self Localization Based On Neighborhood Probability Mapping for Humanoid Robot,M. Jiono and Y. D. Mahandi and S. N. Mustika and S. Sendari and A. M. Dzikri,,2020,IEEE Abstract,355--359,,"The humanoid robot competition is an autonomous robot with a human-like body platform with a single camera as a vision sensor and balancing sensor to support them to play soccer in the specific field. The technical challenges in this competition such following the ball, running during search the ball, dynamic walking, kicking while maintaining the balance body condition, decision making with other robot, localization and mapping as research issues investigated in the Humanoid competition. Localization and mapping still big challenges in humanoid competition, it was only single camera is used in competition rule and no others sensor to support the position and orientation during playing the game. The proposed system was developed is neighborhood probability mapping. The long-term goal of this research is to realize an ideal system to accelerate the redesign field condition and implementation process in a humanoid robot that can be monitored in real-time. The aim of this research is to take the opportunities: (a) increasing the robot's performance of vision and intelligence on the humanoid robot; (b) with this SLAM method the robot can distinguish between the balls that are in the field and outside the field; (c) able to distinguish the enemy goal from the goal itself based on goal detection and line detection; (d) the goal keeper robot capable of acting as an attacker and scanning the kick towards the enemy goal. The testing condition was implemented between simulation testing and real testing in same times. Based on the data experimental result, the robot can estimate their position and orientation during searching the ball position, goal position and obstacle coordinate with high real time accuracy. The result shows that the proposed system can be applied to the humanoid soccer robot in the real time directly and it worked with less error.",,10.1109/ICOVET50258.2020.9230237,,,,Robots;Robot kinematics;Image color analysis;Humanoid robots;Sports;Robot sensing systems;Feature extraction;humanoid robot;localization and mapping;neighborhood propability;single camera based,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Multi-robot 6D graph SLAM connecting decoupled local reference filters,M. J. Schuster and C. Brand and H. Hirschmüller and M. Suppa and M. Beetz,,2015,IEEE Abstract,5093--5100,,"Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.",,10.1109/IROS.2015.7354094,,,,Simultaneous localization and mapping;Robot kinematics;Optimization;Visualization;Real-time systems,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Checkout my map: Version control for fleetwide visual localisation,M. Gadd and P. Newman,,2016,IEEE Abstract,5729--5736,,"This paper is about underpinning long-term operations of fleets of vehicles using visual localisation. In particular it examines ways in which vehicles, considered as independent agents, can share, update and leverage each others' visual experiences in a mutually beneficial way. We draw on our previous work in Experience-based Navigation (EBN) [1], in which a visual map supporting multiple representations of the same place is built, yielding real-time localisation capability for a solitary vehicle. We now consider how any number of such agents might operate in concert via data sharing policies that are germane to the shared task of lifelong localisation. We rapidly construct considerable maps by the conjoining of work distributed to asynchronous processes, and share expertise amongst the team by the selective dispensing of mission-specific map contents. We demonstrate and evaluate our system against 100km of data collected in North Oxford over a period of a month featuring diverse deviation in appearance due to atmospheric, lighting, and structural dynamics. We show that our framework is capable of creating maps in a fraction of the time required by single-agent EBN, with no significant loss in localisation robustness, and is able to furnish robots on real-world forays with maps which require much less storage.",,10.1109/IROS.2016.7759843,,,,Robot sensing systems;Servers;Databases;Visualization;Robustness;Vehicles,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Autonomous Navigation: Achievements in Complex Environments,M. E. Adams,,2006,IEEE Abstract,nil19--nil19,,"Over the past decade, challenging applications for autonomous robots have been identified, in the areas of servicing crowded, built-up areas, mining, search and rescue operations, underwater exploration and airborne surveillance. Autonomous navigation arguably remains the key enabling issue behind any realistic commercial success in these areas. Consequently, autonomous robotic research has focused on large scale and long term navigation algorithms, sensing technologies, robust sensor data interpretation and map building. The recent breakthroughs which contribute to the success of outdoor field robotics, and remaining fundamental research issues involved, will be the theme of this presentation. The most successful robot navigation algorithms to-date, have been derived from a probabilistic perspective, which takes into account vehicle motion and terrain uncertainty and sensor noise. Over the past decade, an explosion of interest in the estimation of an autonomous robot's location state, and that of its surroundings, known as simultaneous localisation and map building (SLAM), is evident. New algorithms which represent uncertain information based on particle filters and Gaussian mixture models, as well as the more classical Kalman filter based techniques, are advancing the progress of a robot's long term navigation abilities. This has been significantly aided by recently affordable sensor technologies, including GPS and inertial measurement units (IMUs) as well as fast and reliable laser range finders.",,10.1109/ROBIO.2006.340225,,,,Navigation;Robot sensing systems;Surveillance;Large-scale systems;Robustness;Remotely operated vehicles;Uncertainty;Explosions;State estimation;Simultaneous localization and mapping,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,PHALANX: Expendable projectile sensor networks for planetary exploration,M. Dille and D. Nuch and S. Gupta and S. McCabe and N. Verzic and T. Fong and U. Wong,,2020,IEEE Abstract,1--12,,"Technologies enabling long-term, wide-ranging measurement in hard-to-reach areas are a critical need for planetary science inquiry. Phenomena of interest include flows or variations in volatiles, gas composition or concentration, particulate density, or even simply temperature. Improved measurement of these processes enables understanding of exotic geologies and distributions or correlating indicators of trapped water or biological activity. However, such data is often needed in unsafe areas such as caves, lava tubes, or steep ravines not easily reached by current spacecraft and planetary robots. To address this capability gap, we have developed miniaturized, expendable sensors which can be ballistically lobbed from a robotic rover or static lander - or even dropped during a flyover. These projectiles can perform sensing during flight and after anchoring to terrain features. By augmenting exploration systems with these sensors, we can extend situational awareness, perform long-duration monitoring, and reduce utilization of primary mobility resources, all of which are crucial in surface missions. We call the integrated payload that includes a cold gas launcher, smart projectiles, planning software, network discovery, and science sensing: PHALANX. In this paper, we introduce the mission architecture for PHALANX and describe an exploration concept that pairs projectile sensors with a rover “mothership.” Science use cases explored include reconnaissance using ballistic cameras, volatiles detection, and building timelapse maps of temperature and illumination conditions. Strategies to autonomously coordinate constellations of deployed sensors to self-discover and localize with peer ranging (i.e. a “local GPS”) are summarized, thus providing communications infrastructure beyond-line-of-sight (BLOS) of the rover. Capabilities were demonstrated through both simulation and physical testing with a terrestrial prototype. The approach to developing a terrestrial prototype is discussed, including design of the launching mechanism, projectile optimization, micro-electronics fabrication, and sensor selection. Results from early testing and characterization of commercial-off-the-shelf (COTS) components are reported. Nodes were subjected to successful burn-in tests over 48 hours at full logging duty cycle. Integrated field tests were conducted in the Roverscape, a half-acre planetary analog environment at NASA Ames, where we tested up to 10 sensor nodes simultaneously coordinating with an exploration rover. Ranging accuracy has been demonstrated to be within +/-10cm over 20m using commodity radios when compared to high-resolution laser scanner ground truthing. Evolution of the design, including progressive miniaturization of the electronics and iterated modifications of the enclosure housing for streamlining and optimized radio performance are described. Finally, lessons learned to date, gaps toward eventual flight mission implementation, and continuing future development plans are discussed.",,10.1109/AERO47225.2020.9172595,,,,,,1095-323X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Appearance-based landmark selection for efficient long-term visual localization,M. Bürki and I. Gilitschenski and E. Stumm and R. Siegwart and J. Nieto,,2016,IEEE Abstract,4137--4143,,"In this paper, we present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments. Sharing a common map for online localization provides a fleet of autonomous vehicles with the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offers the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks are to be observable under the prevailing appearance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. Evaluation is performed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme transition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.",,10.1109/IROS.2016.7759609,,,,Vehicles;Visualization;Servers;Bandwidth;Robots;Redundancy;Mobile computing,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Active airborne localisation and exploration in unknown environments using inertial SLAM,M. Bryson and S. Sukkarieh,,2006,IEEE Abstract,13pp.--,,"Future unmanned aerial vehicle (UAV) applications will require high-accuracy localisation in environments in which navigation infrastructure such as the Global Positioning System (GPS) and prior terrain maps may be unavailable or unreliable. In these applications, long-term operation requires the vehicle to build up a spatial map of the environment while simultaneously localising itself within the map, a task known as simultaneous localisation and mapping (SLAM). In the first part of this paper we present an architecture for performing inertial-sensor based SLAM on an aerial vehicle. We demonstrate an on-line path planning scheme that intelligently plans the vehicle's trajectory while exploring unknown terrain in order to maximise the quality of both the resulting SLAM map and localisation estimates necessary for the autonomous control of the UAV. Two important performance properties and their relationship to the dynamic motion and path planning systems on-board the UAV are analysed. Firstly we analyse information-based measures such as entropy. Secondly we perform an observability analysis of inertial SLAM by recasting the algorithms into an indirect error model form. Qualitative knowledge gained from the observability analysis is used to assist in the design of an information-based trajectory planner for the UAV. Results of the online path planning algorithm are presented using a high-fidelity 6-DoF simulation of a UAV during a simulated navigation and mapping task.",,10.1109/AERO.2006.1655801,,,,Simultaneous localization and mapping;Unmanned aerial vehicles;Path planning;Navigation;Global Positioning System;Remotely operated vehicles;Performance analysis;Information analysis;Observability;Terrain mapping;Navigation;Mapping;SLAM;Autonomous Vehicles;Observability,,1095-323X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data,L. Sun and Z. Yan and S. M. Mellado and M. Hanheide and T. Duckett,,2018,IEEE Abstract,5942--5948,,"This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.",,10.1109/ICRA.2018.8461228,,,,Trajectory;Cameras;Robot kinematics;Robot vision systems;Two dimensional displays;Mobile robots,,2577-087X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Incremental unsupervised topological place discovery,L. Murphy and G. Sibley,,2014,IEEE Abstract,1312--1318,,"This paper describes an online place discovery and recognition engine that fuses information over time to create topologically distinct places. A key motivation is the recognition that a single image may be a poor exemplar of what constitutes a place. Images are not `places' nor are they `documents'. Instead, by treating image-sequences as a multimodal distribution over topics - and by discovering topics incrementally and online - it is possible to both reduce the memory footprint of place recognition systems, and to improve precision and recall. Distinctive key-places are represented by a cluster topics found from the covisibility graph of a relative simultaneous localization and mapping engine - key-places inherently span many images. A dynamic vocabulary of visual words and density based clustering is used to continually estimate a set of visual topics, changes in which drive the place-recognition process. The system is evaluated using an indoor robot sequence, a standard outdoor robot sequence and a long-term sequence from a static camera. Experiments demonstrate qualitatively distinct themes associated with discovered places - from common place types such as `hallway', or `desk-area', to temporal concepts such as `dusk', `dawn' or `mid-day'. Compared to traditional image-based place-recognition, this reduces the information that must be stored without reducing place-recognition performance.",,10.1109/ICRA.2014.6907022,,,,Vocabulary;Visualization;Robots;Semantics;Streaming media;Image recognition;Engines,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Predictive and adaptive maps for long-term visual navigation in changing environments,L. Halodová and E. Dvo?ráková and F. Majer and T. Vintr and O. M. Mozos and F. Dayoub and T. Krajník,,2019,IEEE Abstract,7033--7039,,"In this paper, we compare different map management techniques for long-term visual navigation in changing environments. In this scenario, the navigation system needs to continuously update and refine its feature map in order to adapt to the environment appearance change. To achieve reliable long-term navigation, the map management techniques have to (i) select features useful for the current navigation task, (ii) remove features that are obsolete, (iii) and add new features from the current camera view to the map. We propose several map management strategies and evaluate their performance with regard to the robot localisation accuracy in long-term teach-and-repeat navigation. Our experiments, performed over three months, indicate that strategies which model cyclic changes of the environment appearance and predict which features are going to be visible at a particular time and location, outperform strategies which do not explicitly model the temporal evolution of the changes.",,10.1109/IROS40897.2019.8967994,,,,,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,MIT Advanced Vehicle Technology Study: Large-Scale Naturalistic Driving Study of Driver Behavior and Interaction With Automation,L. Fridman and D. E. Brown and M. Glazer and W. Angell and S. Dodd and B. Jenik and J. Terwilliger and A. Patsekin and J. Kindelsberger and L. Ding and S. Seaman and A. Mehler and A. Sipperley and A. Pettinato and B. D. Seppelt and L. Angell and B. Mehler and B. Reimer,IEEE Access,2019,IEEE Abstract,102021--102038,7,"Today, and possibly for a long time to come, the full driving task is too complex an activity to be fully formalized as a sensing-acting robotics system that can be explicitly solved through model-based and learning-based approaches in order to achieve full unconstrained vehicle autonomy. Localization, mapping, scene perception, vehicle control, trajectory optimization, and higher-level planning decisions associated with autonomous vehicle development remain full of open challenges. This is especially true for unconstrained, real-world operation where the margin of allowable error is extremely small and the number of edge-cases is extremely large. Until these problems are solved, human beings will remain an integral part of the driving task, monitoring the AI system as it performs anywhere from just over 0% to just under 100% of the driving. The governing objectives of the MIT Advanced Vehicle Technology (MIT-AVT) study are to 1) undertake large-scale real-world driving data collection that includes high-definition video to fuel the development of deep learning-based internal and external perception systems; 2) gain a holistic understanding of how human beings interact with vehicle automation technology by integrating video data with vehicle state data, driver characteristics, mental models, and self-reported experiences with technology; and 3) identify how technology and other factors related to automation adoption and use can be improved in ways that save lives. In pursuing these objectives, we have instrumented 23 Tesla Model S and Model X vehicles, 2 Volvo S90 vehicles, 2 Range Rover Evoque, and 2 Cadillac CT6 vehicles for both long-term (over a year per driver) and medium-term (one month per driver) naturalistic driving data collection. Furthermore, we are continually developing new methods for the analysis of the massive-scale dataset collected from the instrumented vehicle fleet. The recorded data streams include IMU, GPS, and CAN messages, and high-definition video streams of the driver's face, the driver cabin, the forward roadway, and the instrument cluster (on select vehicles). The study is on-going and growing. To date, we have 122 participants, 15610 days of participation, 511638 mi, and 7.1 billion video frames. This paper presents the design of the study, the data collection hardware, the processing of the data, and the computer vision algorithms currently being used to extract actionable knowledge from the data.",,10.1109/ACCESS.2019.2926040,,,,Task analysis;Autonomous vehicles;Automation;Instruments;Roads;Sensors;Artificial intelligence;automation;human factors;autonomous vehicles;human-robot interaction;computer vision;machine learning;neural networks,,2169-3536,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Appearance-Based Loop Closure Detection via Locality-Driven Accurate Motion Field Learning,K. Zhang and X. Jiang and J. Ma,IEEE Transactions on Intelligent Transportation Systems,2022,IEEE Abstract,2350--2365,23,"Loop closure detection (LCD) is of significant importance in simultaneous localization and mapping. It represents the robot’s ability to recognize whether the current surrounding corresponds to a previously observed one. In this paper, we conduct this task in a two-step strategy: candidate frame selection and loop closure verification. The first step aims to search semantically similar images for the query one using features obtained by Key.Net with HardNet. Instead of adopting the traditional Bag-of-Words strategy, we utilize the aggregated selective match kernel to calculate the similarity between images. Subsequently, based on the potential property of motion field in the LCD scene, we propose a novel feature matching method, i.e., exploiting the smoothness prior and learning the motion field for an image pair in a reproducing kernel Hilbert space (RKHS), to implement loop closure verification. Concretely, we formulate the learning problem into a Bayesian framework with latent variables indicating the true/false correspondences and a mixture model accounting for the distribution of data. Furthermore, we propose a locality-driven mechanism to enhance the local relevance of motion vectors and term the algorithm as locality-driven accurate motion field learning (LAL). To satisfy the requirement of efficiency in the LCD task, we use a sparse approximation and search a suboptimal solution for the motion field in the RKHS, termed as LAL*. Extensive experiments are conducted on public datasets for feature matching and LCD tasks. The quantitative results demonstrate the effectiveness of our method over the current state-of-the-art, meanwhile showing its potential for long-term visual localization. The codes of LAL and LAL* are publicly available at https://github.com/KN-Zhang/LAL.",,10.1109/TITS.2021.3086822,,,,Feature extraction;Liquid crystal displays;Visualization;Task analysis;Robots;Simultaneous localization and mapping;Kernel;SLAM;loop closure detection;place recognition;feature matching;autonomous vehicle,,1558-0016,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Obstacle avoidance and path planning for humanoid robots using stereo vision,K. Sabe and M. Fukuchi and J.-S. Gutmann and T. Ohashi and K. Kawamoto and T. Yoshigahara,,2004,IEEE Abstract,592--597Vol.1,1,"This work presents methods for path planning and obstacle avoidance for the humanoid robot QRIO, allowing the robot to autonomously walk around in a home environment. For an autonomous robot, obstacle detection and localization as well as representing them in a map are crucial tasks for the success of the robot. Our approach is based on plane extraction from data captured by a stereo-vision system that has been developed specifically for QRIO. We briefly overview the general software architecture composed of perception, short and long term memory, behavior control, and motion control, and emphasize on our methods for obstacle detection by plane extraction, occupancy grid mapping, and path planning. Experimental results complete the description of our system.",,10.1109/ROBOT.2004.1307213,,,,Path planning;Humanoid robots;Stereo vision;Service robots;Legged locomotion;Robot vision systems;Motion control;Data mining;Mobile robots;Robot sensing systems,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Model-aided monocular visual-inertial state estimation and dense mapping,K. Qiu and S. Shen,,2017,IEEE Abstract,1783--1789,,"Robust state estimation and real-time dense mapping are two core capabilities for autonomous navigation of mobile robots. Global Navigation Satellite System (GNSS) and visual odometry/SLAM are popular methods for state estimation. However, when working between tall buildings or in indoor environments, GNSS fails due to limited sky view or obstruction from buildings. Visual odometry/SLAM are prone to long-term drifting in the absence of reliable loop closure detection. A state estimation method with global-consistent guarantee is desirable for navigation applications. As for real-time mapping, SLAM methods usually get a sparse map that is not good enough for obstacle avoidance and path-planning, and high-quality dense mapping is often computationally too demanding for mobile devices. Realizing the availability of city-scale 3D models, in this work, we improve our previous work on model-based global localization, and propose a model-aided monocular visual-inertial state estimation and dense mapping solution. We first develop a global-consistent state estimator by fusing visual-inertial odometry with the model-based localization results. Utilizing depth prior from the model, we perform motion stereo with semi-global disparity smoothing. Our dense mapping pipeline is capable of online detection of obstacles that are originally not included in the offline 3D model. Our method runs onboard an embedded computer in real-time. We validate both the state estimation and mapping accuracy in real-world experiments.",,10.1109/IROS.2017.8205992,,,,Solid modeling;Cameras;Three-dimensional displays;Computational modeling;Image edge detection;State estimation;Real-time systems,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Visual robot localization using compact binary landmarks,K. Ikeda and K. Tanaka,,2010,IEEE Abstract,4397--4403,,"This paper is concerned with the problem of mobile robot localization using a novel compact representation of visual landmarks. With recent progress in lifelong map-learning as well as in information sharing networks, compact representation of a large-size landmark database has become crucial. In this paper, we propose a compact binary code (e.g. 32bit code) landmark representation by employing the semantic hashing technique from web-scale image retrieval. We show how well such a binary representation achieves compactness of a landmark database while maintaining efficiency of the localization system. In our contribution, we investigate the cost-performance, the semantic gap, the saliency evaluation using the presented techniques as well as challenge to further reduce the resources (#bits) per landmark. Experiments using a high-speed car-like robot show promising results.",,10.1109/ROBOT.2010.5509579,,,,Robot localization;Visual databases;Binary codes;Mobile robots;Image databases;Vocabulary;Costs;Image retrieval;Information retrieval;Graphical models,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Continuous localization in changing environments,K. Graves and W. Adams and A. Schultz,,1997,IEEE Abstract,28--33,,"Continuous localization is a technique that allows a robot to maintain an accurate estimate of its location by performing regular small corrections to its odometry. Continuous localization uses an evidence grid representation, a common representation scheme that is used by other map-dependent processes, such as path planning. Although techniques exist for building evidence grid maps, most are not adaptive to changes in the environment. In this research, we extend the continuous localization technique by adding a learning component. This allows continuous localization to update the long-term map (evidence grid) with current sensor readings. Results show that the addition of the learning behavior to continuous localization allows the system to adapt to changes in its environment without a loss in its ability to remain localized. This system was tested on a Nomad 200 mobile robot.",,10.1109/CIRA.1997.613834,,,,Path planning;Error correction;Mobile robots;Navigation;Computer science;Artificial intelligence;Laboratories;Intelligent robots;State estimation;System testing,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Characterising an indoor environment with a mobile robot and uncalibrated stereo,K. B. Sarachik,,1989,IEEE Abstract,984--989vol.2,,"The author shows how it is possible for a mobile robot to exploit the visual information obtained by scanning a room to determine its size and shape, and to orient itself continually within it. The equipment used is a very simple camera setup whose detailed initial configuration is not known but can be deduced as the algorithm runs. The approach does not require any special environment, nor is it sensitive to changes in the physical aspect of the room being inspected such as moved furniture or roaming people. The long-term goal of the project is for the robot to use the information thus acquired in order to build maps of its environment, presumed to be a single floor of an office building, and to localize itself within this framework.<>",,10.1109/ROBOT.1989.100109,,,,Indoor environments;Mobile robots;Cameras;Robot vision systems;Artificial intelligence;Floors;Contracts;Strips;Shape;Robot sensing systems,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Sequence-based mapping for probabilistic visual loop-closure detection,K. A. Tsintotas and L. Bampis and S. An and G. F. Fragulis and S. G. Mouroutsos and A. Gasteratos,,2021,IEEE Abstract,1--6,,"During simultaneous localization and mapping, the robot should build a map of its surroundings and simultaneously estimate its pose in the generated map. However, a fundamental task is to detect loops, i.e., previously visited areas, allowing consistent map generation. Moreover, within long-term mapping, every autonomous system needs to address its scalability in terms of storage requirements and database search. In this paper, we present a low-complexity sequence-based visual loop-closure detection pipeline. Our system dynamically segments the traversed route through a feature matching technique in order to define sub-maps. In addition, visual words are generated incrementally for the corresponding sub-maps representation. Comparisons among these sequences-of-images are performed thanks to probabilistic scores originated from a voting scheme. When a candidate sub-map is indicated, global descriptors are utilized for image-to-image pairing. Our evaluation took place on several publicly-available datasets exhibiting the system&#x2019;s low complexity and high recall compared to other state-of-the-art approaches.",,10.1109/IST50367.2021.9651458,,,,Visualization;Vocabulary;Simultaneous localization and mapping;Databases;Pipelines;Probabilistic logic;Feature extraction,,1558-2809,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Monocular Localization in HD Maps by Combining Semantic Segmentation and Distance Transform,J.-H. Pauls and K. Petek and F. Poggenhans and C. Stiller,,2020,IEEE Abstract,4595--4601,,"Easy, yet robust long-term localization is still an open topic in research. Existing approaches require either dense maps, expensive sensors, specialized map features or proprietary detectors.We propose using semantic segmentation on a monocular camera to localize directly in a HD map as used for automated driving. This combines lightweight, yet powerful HD maps with the simplicity of monocular vision and the flexibility of neural networks.The major challenges arising from this combination are data association and robustness against misdetections. Association is solved efficiently by applying distance transform on binary per-class images. This provides not only a fast lookup table for a smooth gradient as needed for pose-graph optimization, but also dynamic association by default.A sliding-window pose graph optimization combines single image detections with vehicle odometry, smoothing results and helping overcome even misclassifications in consecutive frames.Evaluation against a highly accurate 6D visual localization shows that our approach can achieve accuracy levels as required for automated driving, being one of the most lightweight and flexible methods to do so.",,10.1109/IROS45743.2020.9341003,,,,Location awareness;Semantics;Neural networks;Transforms;Cameras;Vehicle dynamics;Optimization,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,BiCamSLAM: Two times mono is more than stereo,J. Sola and A. Monin and M. Devy,,2007,IEEE Abstract,4795--4800,,"This paper is an invitation to use mono-vision techniques on stereo-vision equipped robots. By using monocular algorithms on both cameras, the advantages of mono-vision (bearing-only, with infinity range but no 3D instant information) and stereo-vision (3D information only up to a limited range) naturally add up to provide interesting possibilities, that are here developed and demonstrated using an EKF-based monocular SLAM algorithm. Mainly we obtain: a) fast 3D mapping with long term, absolute angular references; b) great landmark updating flexibility; and c) the possibility of stereo rig extrinsic self-calibration, providing a much more robust and accurate sensor. Experimental results show the pertinence of the proposed ideas, which should be easily exportable (and we encourage to do so) to other, more performing, vision-based SLAM algorithms.",,10.1109/ROBOT.2007.364218,,,,MONOS devices;Simultaneous localization and mapping;Signal processing algorithms;Cameras;Robustness;Robot vision systems;Observability;Robotics and automation;Robot sensing systems;Delay estimation,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-Term Map Maintenance Pipeline for Autonomous Vehicles,J. S. Berrio and S. Worrall and M. Shan and E. Nebot,IEEE Transactions on Intelligent Transportation Systems,2021,IEEE Abstract,1--14,,"For autonomous vehicles to operate persistently in a typical urban environment, it is essential to have high accuracy position information. This requires a mapping and localisation system that can adapt to changes over time. A localisation approach based on a single-survey map will not be suitable for long-term operation as it does not incorporate variations in the environment. In this paper, we present new algorithms to maintain a featured-based map. A map maintenance pipeline is proposed that can continuously update a map with the most relevant features taking advantage of the changes in the surroundings. Our pipeline detects and removes transient features based on their geometrical relationships with the vehicle's pose. Newly identified features became part of a new feature map and are assessed by the pipeline as candidates for the localisation map. By purging out-of-date features and adding newly detected features, we continually update the prior map to more accurately represent the most recent environment. We have validated our approach using the USyd Campus Dataset, which includes more than 18 months of data. The results presented demonstrate that our maintenance pipeline produces a resilient map which can provide sustained localisation performance over time.",,10.1109/TITS.2021.3094485,,,,Feature extraction;Pipelines;Maintenance engineering;Transient analysis;Visualization;Autonomous vehicles;Task analysis;Long-term localisation;feature-based map;map update.,,1558-0016,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Identifying robust landmarks in feature-based maps,J. S. Berrio and J. Ward and S. Worrall and E. Nebot,,2019,IEEE Abstract,1166--1172,,"To operate in an urban environment, an automated vehicle must be capable of accurately estimating its position within a global map reference frame. This is necessary for optimal path planning and safe navigation. To accomplish this over an extended period of time, the global map requires long term maintenance. This includes the addition of newly observable features and the removal of transient features belonging to dynamic objects. The latter is especially important for the long-term use of the map as matching against a map with features that no longer exist can result in incorrect data associations, and consequently erroneous localisation. This paper addresses the problem of removing features from the map that correspond to objects that are no longer observable/present in the environment. This is achieved by assigning a single score which depends on the geometric distribution and characteristics when the features are re-detected (or not) on different occasions. Our approach not only eliminates ephemeral features, but can also be used as a reduction algorithm for highly dense maps. We tested our approach using half a year of weekly drives over the same 500 metre section of road in an urban environment. The results presented demonstrate the validity of the long term approach to map maintenance.",,10.1109/IVS.2019.8814289,,,,Feature extraction;Navigation;Maintenance engineering;Vehicle dynamics;Meters;Reliability;Trajectory,,2642-7214,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Evaluation of Long-term LiDAR Place Recognition,J. Peltomäki and F. Alijani and J. Puura and H. Huttunen and E. Rahtu and J.-K. Kämäräinen,,2021,IEEE Abstract,4487--4492,,"We compare a state-of-the-art deep image retrieval and a deep place recognition method for place recognition using LiDAR data. Place recognition aims to detect previously visited locations and thus provides an important tool for navigation, mapping, and localisation. Experimental comparisons are conducted using challenging outdoor and indoor datasets, Oxford Radar RobotCar and COLD, in the ""long-term"" setting where the test conditions differ substantially from the training and gallery data. Based on our results the image retrieval methods using LiDAR depth images can achieve accurate localization (the single best match recall 80%) within 5.00 m in urban outdoors. In office indoors the comparable accuracy is 50 cm but is more sensitive to changes in the environment.",,10.1109/IROS51168.2021.9636320,,,,Training;Meters;Location awareness;Laser radar;Image recognition;Image retrieval;Radar imaging,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Martian Fetch: Finding and retrieving sample-tubes on the surface of mars,J. Papon and R. Detry and P. Vieira and S. Brooks and T. Srinivasan and A. Peterson and E. Kulczycki,,2017,IEEE Abstract,1--9,,"Mars Sample Return (MSR) was identified by the 2011 planetary science decadal survey as a high priority long-term goal for NASA. A three-mission campaign concept is currently being investigated. The Mars 2020 rover mission is intended to core and collect samples. These samples will be sealed in tubes and left on the surface for potential return to Earth. In the current MSR campaign concept, a Sample Retrieval and Launch (SRL) mission would collect the sample tubes left by the Mars 2020 rover and load them into a Mars Ascent Vehicle (MAV) to be launched into orbit. The third mission concept involves a spacecraft capturing the samples in Martian orbit and returning them to Earth. This paper focuses on the SRL mission concept to collect the sample tubes, addressing the problem of autonomously detecting, localizing, and grasping sample tubes deposited on the Martian surface. We employ two approaches: The first one is context-based. It would use a high precision map computed from images captured during tube release, to locate the tubes without directly observing them. The second approach directly detects the sample tubes visually and estimates their 6-DoF pose onboard from dense stereo data.",,10.1109/AERO.2017.7943649,,,,Electron tubes;Earth;Cameras;Surface treatment;Rocks;Feature extraction;Orbits,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,SemanticFusion: Dense 3D semantic mapping with convolutional neural networks,J. McCormac and A. Handa and A. Davison and S. Leutenegger,,2017,IEEE Abstract,4628--4635,,"Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance - they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ?25Hz.",,10.1109/ICRA.2017.7989538,,,,Semantics;Simultaneous localization and mapping;Three-dimensional displays;Geometry;Two dimensional displays;Labeling;Cameras,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Underwater robot visual place recognition in the presence of dramatic appearance change,J. Li and R. M. Eustice and M. Johnson-Roberson,,2015,IEEE Abstract,1--6,,"This paper reports on an algorithm for underwater visual place recognition in the presence of dramatic appearance change. Long-term visual place recognition is challenging underwater due to biofouling, corrosion, and other effects that lead to dramatic visual appearance change, which often causes traditional point-based feature methods to perform poorly. Building upon the authors' earlier work, this paper presents an algorithm for underwater vehicle place recognition and relocalization that enables an autonomous underwater vehicle (AUV) to relocalize itself to a previously-built simultaneous localization and mapping (SLAM) graph. High-level structural features are learned using a supervised learning framework that retains features that have a high potential to persist in the underwater environment. Combined with a particle filtering framework, these features are used to provide a probabilistic representation of localization confidence. The algorithm is evaluated on real data, from multiple years, collected by a Hovering Autonomous Underwater Vehicle (HAUV) for ship hull inspection.",,10.23919/OCEANS.2015.7404369,,,,Visualization;Feature extraction;Atmospheric measurements;Particle measurements;Support vector machines;Vehicles;Image segmentation,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Topographic SLAM Using a Single Terrain Altimeter in GNSS-Restricted Environment,J. Jang and J. Kim,IEEE Access,2022,IEEE Abstract,10806--10815,10,"In a Global Navigation Satellite System (GNSS)-restricted area, a mobile robot navigation system exploits surrounding environment information. For an aerial or underwater vehicle, undulating terrain of a land or seabed surface is a valuable information resource that leads to the development of terrain-referenced navigation (TRN) algorithms. However, due to the vast amount of a vehicle’s activity area, surveying all the regions to obtain a high-resolution terrain map is impractical and requires simultaneous localization and mapping (SLAM) as a highly desirable capability. This paper presents a topographic SLAM algorithm using only a single terrain altimeter, which is low-cost, computationally efficient, and sufficiently stable for long-term operation. The proposed rectangular panel map structure and update method enable robust and efficient SLAM. As terrain elevation changes are inherently nonlinear, an extended Kalman filter (EKF)-based SLAM filter is adopted. The feasibility and validity of the proposed algorithm are demonstrated through simulations using terrain elevation data from a real-world undersea environment.",,10.1109/ACCESS.2022.3145978,,,,Simultaneous localization and mapping;Navigation;Global navigation satellite system;Sensors;Surface topography;Kalman filters;Sea measurements;Terrain-referenced navigation;simultaneous localization and mapping;extended Kalman filter;topography;bathymetry;autonomous underwater vehicle,,2169-3536,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Mapping and Localization using Semantic Road Marking with Centimeter-level Accuracy in Indoor Parking Lots,J. Hu and M. Yang and H. Xu and Y. He and C. Wang,,2019,IEEE Abstract,4068--4073,,"Accurate localization is one of the fundamental tasks of vehicles visual navigation in parking lots. In this paper, we propose a practical and novel solution, which exploits road marking semantic segmentation to attack the problem of long-term and high-precision visual localization. Based on the semantic data association derived from road markings segmentation, point cloud fusion and loop detection strategies are designed to improve the performance of semantic map building. Applying the generated map, we present a point cloud registration algorithm combining semantic and geometric inference to improve the localization precision. Experiments on real-world indoor parking lots prove that the semantic map created by the proposed method reveals more accurate and consistent performance. Moreover, localization error is no more than 10cm, while running in real-time performance.",,10.1109/ITSC.2019.8917529,,,,Semantics;Three-dimensional displays;Roads;Image segmentation;Visualization;Cameras;Iterative closest point algorithm,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Global Alignment of Deep Features for Robot Localization in Changing Environment,J. H. Oh and H.-J. Lee,,2019,IEEE Abstract,72--75,,"Localization is an elemental requirement for autonomous navigation, simultaneous localization and mapping for mobile robots. As robots can perform long-term and large-scale tasks, finding locations in changing environment is a crucial problem. To resolve the problem, we present a robust localization system under severe appearance changes. The system consists of two stages. First, a robust feature extraction method using a deep convolutional auto-encoder is proposed. Then, global alignment of extracted feature sequences is proposed to find the actual robot's locations. Since the proposed method not only uses the condition-robust features but also considers the actual trajectory of the robot by aligning features sequences, it can show accurate localization performances in changing environments. Experiments were conducted to prove the effective of the proposed method, and the results showed that our method outperformed than existing methods.",,10.1109/EECS49779.2019.00026,,,,Robots;Feature extraction;Visualization;Image coding;Simultaneous localization and mapping;Trajectory;Image reconstruction;robotics;localization;sequence alignment;place recognition;deep learning;auto-encoder,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Distributed real-time cooperative localization and mapping using an uncertainty-aware expectation maximization approach,J. Dong and E. Nelson and V. Indelman and N. Michael and F. Dellaert,,2015,IEEE Abstract,5807--5814,,"We demonstrate distributed, online, and real-time cooperative localization and mapping between multiple robots operating throughout an unknown environment using indirect measurements. We present a novel Expectation Maximization (EM) based approach to efficiently identify inlier multi-robot loop closures by incorporating robot pose uncertainty, which significantly improves the trajectory accuracy over long-term navigation. An EM and hypothesis based method is used to determine a common reference frame. We detail a 2D laser scan correspondence method to form robust correspondences between laser scans shared amongst robots. The implementation is experimentally validated using teams of aerial vehicles, and analyzed to determine its accuracy, computational efficiency, scalability to many robots, and robustness to varying environments. We demonstrate through multiple experiments that our method can efficiently build maps of large indoor and outdoor environments in a distributed, online, and real-time setting.",,10.1109/ICRA.2015.7140012,,,,Trajectory;Robot kinematics;Robot sensing systems;Lasers;Robustness;Uncertainty,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Episodic non-Markov localization: Reasoning about short-term and long-term features,J. Biswas and M. Veloso,,2014,IEEE Abstract,3969--3974,,"Markov localization and its variants are widely used for localization of mobile robots. These methods assume Markov independence of observations, implying that observations made by a robot correspond to a static map. However, in real human environments, observations include occlusions due to unmapped objects like chairs and tables, and dynamic objects like humans. We introduce an episodic non-Markov localization algorithm that maintains estimates of the belief over the trajectory of the robot while explicitly reasoning about observations and their correlations arising from unmapped static objects, moving objects, as well as objects from the static map. Observations are classified as arising from long-term features, short-term features, or dynamic features, which correspond to mapped objects, unmapped static objects, and unmapped dynamic objects respectively. By detecting time steps along the robot's trajectory where unmapped observations prior to such time steps are unrelated to those afterwards, non-Markov localization limits the history of observations and pose estimates to “episodes” over which the belief is computed. We demonstrate non-Markov localization in challenging real world indoor and outdoor environments over multiple datasets, comparing it with alternative state-of-the-art approaches, showing it to be robust as well as accurate.",,10.1109/ICRA.2014.6907435,,,,Markov processes;Cost function;Correlation;Maximum likelihood estimation;Robot kinematics;History,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Ascending stairway modeling from dense depth imagery for traversability analysis,J. A. Delmerico and D. Baran and P. David and J. Ryde and J. J. Corso,,2013,IEEE Abstract,2283--2290,,"Localization and modeling of stairways by mobile robots can enable multi-floor exploration for those platforms capable of stair traversal. Existing approaches focus on either stairway detection or traversal, but do not address these problems in the context of path planning for the autonomous exploration of multi-floor buildings. We propose a system for detecting and modeling ascending stairways while performing simultaneous localization and mapping, such that the traversability of each stairway can be assessed by estimating its physical properties. The long-term objective of our approach is to enable exploration of multiple floors of a building by allowing stairways to be considered during path planning as traversable portals to new frontiers. We design a generative model of a stairway as a single object. We localize these models with respect to the map, and estimate the dimensions of the stairway as a whole, as well as its steps. With these estimates, a robot can determine if the stairway is traversable based on its climbing capabilities. Our system consists of two parts: a computationally efficient detector that leverages geometric cues from dense depth imagery to detect sets of ascending stairs, and a stairway modeler that uses multiple detections to infer the location and parameters of a stairway that is discovered during exploration. We demonstrate the performance of this system when deployed on several mobile platforms using a Microsoft Kinect sensor.",,10.1109/ICRA.2013.6630886,,,,Robot sensing systems;Computational modeling;Legged locomotion;Cameras;Navigation;Green products,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Vehicle Navigation by Visual Navigational Aids for Automatic Lunar Mission,I. Ostroumov and N. Kuzmenko,,2021,IEEE Abstract,71--75,,"Nowadays the question of Moon exploration is one of the key priorities. Many Lunar robotics missions are planned in near future by different space agencies around the world. Moon has considered to be the best place for a research station with long-term human presence for finding answers on fundamental questions about the universe. Automatic navigation of starship during a landing phase on Lunar surface is already solved with a help of inertial reference system aided visual algorithms. However, questions of automatic navigation of moving and flying vehicles on the Lunar surface are still open. Inertial navigation is limited by time, self-localization and mapping algorithms require multiple unique features of relief to guarantee required accuracy for successful automatic mission complication. In the current study, we propose the deployment of a network of visual navigational aids on the Lunar surface to support ground automatic missions. A weak atmosphere of the Moon makes effective visual beacons navigation system for long areas. A network of navigational aids includes primary and secondary ground stations which are blinking synchronously. Synchronization is supported by radio waves from the primary ground station. We consider the nature of crater relief to increase operational area of the system. The Time Difference of Arrival method is used to detect vehicle position by blinking network of visual navigational aids. In the numerical application, we consider different scenarios of network configuration to support automatic vehicle navigation inside of Tycho crater. Also, deployment of visual navigational aids network will increase the number of optical features which improve performance of already used positioning methods.",,10.1109/APUAVD53804.2021.9615417,,,,Visualization;Time difference of arrival;Surface waves;Moon;Radio navigation;Unmanned aerial vehicles;Synchronization;visual navigational aids;landing and ground vehicles;automatic mission;Lunar mission;Time Difference of Arrival,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Use of classification and segmentation of sidescan sonar images for long term registration,I. Leblond and M. Legris and B. Solaiman,,2005,IEEE Abstract,322--327Vol.1,1,"This article handles the possibility of using classification and segmentation of sidescan sonar images for long term registration. In our case, long term registration means to find the displacement between two images which can have been mapped with many weeks or many months between them. The aim of this study is to help AUVs (autonomous underwater vehicles) to navigate, in particular to correct the drift of navigation sensors. This type of positioning raises two sorts of problems, which come from image properties: spatial variability and temporal variability. The first one is caused above all by the sonar geometry and appears for example like a modification of the shape or the position of the shadow according to the point of view. This effect can also be seen in textures, for example on megaripples of sand, which can be more or less visible depending on the point of view of the sonar. The second one is more the consequence of the seafloor physics: between two images, mapped at different times, some elements may have changed. An obvious example is the presence of evanescent ""objects"" like fishes but this variability can also be seen on sediments, which borders can move due to local bottom dynamics. With the aim to solve these problems and to provide reliable landmarks for matching, we decided to classify and segment the images. The data have first been corrected from TVG (time varying gain) effects and despeckelised in order to process images which are more representative of the seafloor. The basis idea is to use a supervised method of classification. To do that, we consider some parameters which are coming from a decomposition by Gabor filters, in order to segment with linear discriminant analysis and use of the nearest neighbour method. Registration needs accurately localised landmarks: so, this operation is split in several stages, refining step by step the classification, in order to obtain a map which describes the seafloor with the most possible detailed frontiers. Then, we present the obtained results considering five texture classes: rocks, megaripples, sand, mud and shadow. These several areas and their frontiers are the basis landmarks to match the images. However, before using the segmentation, we must check its reliability. So, it appears that the frontiers, though they are realistic, are not accurate enough to make a registration precise to few pixels, especially in rock areas. Similarly, according to the orientation of the ripples, they may be seen as ripples or sand. These observations are due to the directivity of the sonar, which caused these effects on the segmentation. To do registration, we must take into account these problems. So, the results of the segmentation will be used only for a coarse registration, in order to find quickly the area of interest but also to assess the reliability of our registration (matching on ripples areas is a priori less reliable than on rocks areas). The results of registration are shown, proving the good adequacy between reference image and test image. Others methods, more quantitative, will be able to be tested, to refine the results.",,10.1109/OCEANSE.2005.1511734,,,,Image segmentation;Sonar navigation;Sea floor;Testing;Underwater vehicles;Geometry;Shape;Physics;Marine animals;Sediments,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Laser-only road-vehicle localization with dual 2D push-broom LIDARS and 3D priors,I. Baldwin and P. Newman,,2012,IEEE Abstract,2490--2497,,"We demonstrate the viability of using 2D LIDAR data as the sole means for accurate, robust, long-term road-vehicle localization within a prior map in a complex, dynamic real-world setting. We utilize a dual-LIDAR system - one oriented horizontally, in order to infer vehicle linear and rotational velocity, and one declined to capture a dense view of the surrounds - that allows us to estimate both velocity and position within a prior map. We show how probabilistically modelling the noisy local velocity estimates from the horizontal laser feed, fusing these estimates with data from the declined LIDAR to form a dense 3D swathe and matching this swathe statistically within a map will allow for robust, long-term position estimation. We accommodate estimation errors induced by passing vehicles, pedestrians, ground-strike etc., by learning a positional-dependent sensor model - that is, a sensor-model that varies spatially - and show that learning such a model for LIDAR data allows us to deal gracefully with the complexities of realworld data. We validate the concept over more than 9 kilometres of driven distance in and around the town of Woodstock, Oxfordshire.",,10.1109/IROS.2012.6385677,,,,Vehicles;Laser radar;Robustness;Probabilistic logic;Noise measurement;Equations;Measurement by laser beam,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"Contribution to vision-based localization, tracking and navigation methods for an interactive mobile service-robot",H.-M. Gross and H.-J. Boehme and T. Wilhelm,,2001,IEEE Abstract,672--677vol.2,2,"Presents vision-based robot navigation and user localization techniques of our long-term research project PERSES (personal service system), which aims to develop an interactive mobile shopping assistant that allows a continuous and intuitively understandable interaction with customers in a home store. Against this background, the paper describes a number of new or improved approaches, addressing challenges arising from the characteristics of the operation area, and from the need to continuously interact with users in a complex environment. With our approaches to vision-based or visually-controlled map building, self-localization and navigation as well as user localization and tracking, we want to make a contribution to the real-world suitability of interactive mobile service-robots in non-trivial application areas and demanding human-robot interaction scenarios.",,10.1109/ICSMC.2001.972991,,,,Navigation;Robot vision systems;Infrared sensors;Mobile robots;Color;Robot sensing systems;Cameras;Sonar equipment;Sensor systems;Service robots,,1062-922X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,ShopBot: Progress in developing an interactive mobile shopping assistant for everyday use,H.-M. Gross and H.-J. Boehme and C. Schroeter and S. Mueller and A. Koenig and C. Martin and M. Merten and A. Bley,,2008,IEEE Abstract,3471--3478,,"The paper describes progress achieved in our long-term research project ShopBot, which aims at the development of an intelligent and interactive mobile shopping assistant for everyday use in shopping centers or home improvement stores. It is focusing on recent progress concerning two important methodological aspects: (i) the on-line building of maps of the operation area by means of advanced Rao-Blackwellized SLAM approaches using both sonar-based gridmaps as well as vision-based graph maps as representations, and (ii) a probabilistic approach to multi-modal user detection and tracking during the guidance tour. Experimental results of both the map building characteristics and the person tracking behavior achieved in an ordinary home improvement store demonstrate the reliability of both approaches. Moreover, we present first very encouraging results of long-term field trials which have been executed with three robotic shopping assistants in another home improvement store in Bavaria since March 2008. In this field test, the robots could demonstrate their suitability for this challenging real-world application, as well as the necessary user acceptance.",,10.1109/ICSMC.2008.4811835,,,,Robot sensing systems;Sensor phenomena and characterization;Mobile robots;Simultaneous localization and mapping;Sonar detection;Cognitive robotics;Intelligent robots;Testing;Robot vision systems;Navigation,,1062-922X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,3D LiDAR-Based Global Localization Using Siamese Neural Network,H. Yin and Y. Wang and X. Ding and L. Tang and S. Huang and R. Xiong,IEEE Transactions on Intelligent Transportation Systems,2020,IEEE Abstract,1380--1392,21,"Global localization in 3D point clouds is a challenging task for mobile vehicles in outdoor scenarios, which requires the vehicle to localize itself correctly in a given map without prior knowledge of its pose. This is a critical component of autonomous vehicles or robots on the road for handling localization failures. In this paper, based on reduced dimension scan representations learned from neural networks, a solution to global localization is proposed by achieving place recognition first and then metric pose estimation in the global prior map. Specifically, we present a semi-handcrafted feature learning method for 3D Light detection and ranging (LiDAR) point clouds using artificial statistics and siamese network, which transforms the place recognition problem into a similarity modeling problem. Additionally, the sensor data using dimension reduced representations require less storage space and make the searching easier. With the learned representations by networks and the global poses, a prior map is built and used in the localization framework. In the localization step, position only observations obtained by place recognition are used in a particle filter algorithm to achieve precise pose estimation. To demonstrate the effectiveness of our place recognition and localization approach, KITTI benchmark and our multi-session datasets are employed for comparison with other geometric-based algorithms. The results show that our system can achieve both high accuracy and efficiency for long-term autonomy.",,10.1109/TITS.2019.2905046,,,,Three-dimensional displays;Laser radar;Pose estimation;Neural networks;Task analysis;Robot sensing systems;Measurement;Mobile vehicles;place recognition;siamese network;global localization,,1558-0016,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation,H. Thomas and B. Agro and M. Gridseth and J. Zhang and T. D. Barfoot,,2021,IEEE Abstract,14047--14053,,"We present a self-supervised learning approach for the semantic segmentation of lidar frames. Our method is used to train a deep point cloud segmentation architecture without any human annotation. The annotation process is automated with the combination of simultaneous localization and mapping (SLAM) and ray-tracing algorithms. By performing multiple navigation sessions in the same environment, we are able to identify permanent structures, such as walls, and disentangle short-term and long-term movable objects, such as people and tables, respectively. New sessions can then be performed using a network trained to predict these semantic labels. We demonstrate the ability of our approach to improve itself over time, from one session to the next. With semantically filtered point clouds, our robot can navigate through more complex scenarios, which, when added to the training pool, help to improve our network predictions. We provide insights into our network predictions and show that our approach can also improve the performances of common localization techniques.",,10.1109/ICRA48506.2021.9561701,,,,Training;Laser radar;Simultaneous localization and mapping;Annotations;Semantics;Ray tracing;Prediction algorithms,,2577-087X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Efficient information-theoretic graph pruning for graph-based SLAM with laser range finders,H. Kretzschmar and C. Stachniss and G. Grisetti,,2011,IEEE Abstract,865--871,,"In graph-based SLAM, the pose graph encodes the poses of the robot during data acquisition as well as spatial constraints between them. The size of the pose graph has a substantial influence on the runtime and the memory requirements of a SLAM system, which hinders long-term mapping. In this paper, we address the problem of efficient information-theoretic compression of pose graphs. Our approach estimates the expected information gain of laser measurements with respect to the resulting occupancy grid map. It allows for restricting the size of the pose graph depending on the information that the robot acquires about the environment or based on a given memory limit, which results in an any-space SLAM system. When discarding laser scans, our approach marginalizes out the corresponding pose nodes from the graph. To avoid a densely connected pose graph, which would result from exact marginalization, we propose an approximation to marginalization that is based on local Chow-Liu trees and maintains a sparse graph. Real world experiments suggest that our approach effectively reduces the growth of the pose graph while minimizing the loss of information in the resulting grid map.",,10.1109/IROS.2011.6094414,,,,Measurement by laser beam;Simultaneous localization and mapping;Approximation methods;Lasers;Mutual information;Laser beams,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Map Updating Revisited for Navigation Map : A mathematical way to perform map updating for autonomous mobile robot,H. Chen and Z. Wang and Q. Zhu,,2021,IEEE Abstract,505--508,,"Simultaneous localization and mapping, SLAM can product a Map for autonomous robots and self-driving vehicle in navigation. In the actual environment, the scene changes frequently, which makes the old map no long reliable. Therefore, it is necessary to update such a map by an efficient and safely way. In this paper, we review the existing map updating, long-term localization methods and discuss about the challenges in this situation. We present a Map updating method in mathematical way which can update accurately. Our proposed method are tested in five indoor dataset and demonstrated feasibility.",,10.1109/IPEC51340.2021.9421197,,,,Location awareness;Computers;Simultaneous localization and mapping;Navigation;Image processing;Conferences;Reliability;map;updating;visual;point cloud,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,The Autonomous City Explorer (ACE) project — mobile robot navigation in highly populated urban environments,G. Lidoris and F. Rohrmuller and D. Wollherr and M. Buss,,2009,IEEE Abstract,1416--1422,,"One of the greatest challenges nowadays in robotics is the advancement of robots from industrial tools to companions and helpers of humans, operating in natural, populated environments. In this respect, the Autonomous City Explorer (ACE) project aims to combine the research fields of autonomous mobile robot navigation and human robot interaction. A robot has been created that is capable of navigating in an unknown, highly populated, urban environment, based only on information extracted through interaction with passers-by and its local perception capabilities. This paper describes the algorithms and architecture that make up the navigation subsystem of ACE. More specifically, the algorithms used for Simultaneous Localization and Mapping (SLAM), path planning in dynamic environments and behavior selection are presented, as well as the system architecture that integrates them to a complete working system. Results from an extended field experiment, where the robot navigated autonomously through the downtown city area of Munich, are analyzed and show that the robot is capable of long-term, safe navigation in real-world settings.",,10.1109/ROBOT.2009.5152534,,,,Cities and towns;Mobile robots;Navigation;Robot kinematics;Service robots;Robotics and automation;Human robot interaction;Data mining;Simultaneous localization and mapping;Robot vision systems,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Geometry-based Graph Pruning for Lifelong SLAM,G. Kurz and M. Holoch and P. Biber,,2021,IEEE Abstract,3313--3320,,"Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case).",,10.1109/IROS51168.2021.9636530,,,,Simultaneous localization and mapping;Three-dimensional displays;Costs;Density functional theory;Trajectory;Standards;Intelligent robots,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image",G. Kim and B. Park and A. Kim,IEEE Robotics and Automation Letters,2019,IEEE Abstract,1948--1955,4,"In this letter, we present a long-term localization method that effectively exploits the structural information of an environment via an image format. The proposed method presents a robust year-round localization performance even when learned in just a single day. The proposed localizer learns a point cloud descriptor, named Scan Context Image (SCI), and performs robot localization on a grid map by formulating the place recognition problem as place classification using a convolutional neural network. Our method is faster than existing methods proposed for place recognition because it avoids a pairwise comparison between a query and scans in a database. In addition, we provide thorough validations using publicly available long-term datasets, the NCLT dataset and the Oxford RobotCar dataset, and show that the Scan Context Image (SCI) localization attains consistent performance over a year and outperforms existing methods.",,10.1109/LRA.2019.2897340,,,,Three-dimensional displays;Training;Laser radar;Entropy;Databases;Robot localization;Localization;range sensing;SLAM,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Hough$^2$Map – Iterative Event-Based Hough Transform for High-Speed Railway Mapping,F. Tschopp and C. V. Einem and A. Cramariuc and D. Hug and A. W. Palmer and R. Siegwart and M. Chli and J. Nieto,IEEE Robotics and Automation Letters,2021,IEEE Abstract,2745--2752,6,"To cope with the growing demand for transportation on the railway system, accurate, robust, and high-frequency positioning is required to enable a safe and efficient utilization of the existing railway infrastructure. As a basis for a localization system we propose a complete on-board mapping pipeline able to map robust meaningful landmarks, such as poles from power lines, in the vicinity of the vehicle. Such poles are good candidates for reliable and long term landmarks even through difficult weather conditions or seasonal changes. To address the challenges of motion blur and illumination changes in railway scenarios we employ a Dynamic Vision Sensor, a novel event-based camera. Using a sideways oriented on-board camera, poles appear as vertical lines. To map such lines in a real-time event stream, we introduce Hough2Map, a novel consecutive iterative event-based Hough transform framework capable of detecting, tracking, and triangulating close-by structures. We demonstrate the mapping reliability and accuracy of Hough2Map on real-world data in typical usage scenarios and evaluate using surveyed infrastructure ground truth maps. Hough2Map achieves a detection reliability of up to $92\,\%$ and a mapping root mean square error accuracy of 1.1518 m.11The code is available at https://github.com/ethz-asl/Hough2Map.",,10.1109/LRA.2021.3061404,,,,Real-time systems;Rail transportation;Cameras;Voltage control;Tracking;Location awareness;Reliability;Computer vision for transportation;object detection;segmentation and categorization;mapping,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,LCPF: A Particle Filter Lidar SLAM System With Loop Detection and Correction,F. Nie and W. Zhang and Z. Yao and Y. Shi and F. Li and Q. Huang,IEEE Access,2020,IEEE Abstract,20401--20412,8,"A globally consistent map is the basis of indoor robot localization and navigation. However, map built by Rao-Blackwellized Particle Filter (RBPF) doesn’t have high global consistency which is not suitable for long-term application in large scene. To address the problem, we present an improved RBPF Lidar SLAM system with loop detection and correction named LCPF. The efficiency and accuracy of loop detection depend on the segmentation of submaps. Instead of dividing the submap at fixed number of laser scan like existing method, Dynamic Submap Segmentation is proposed in LCPF. This segmentation algorithm decreases the error inside the submap by splitting the submap where there is high scan match error and later rectifies the error by an improved pose graph optimization between submaps. In order to segment the submap at appropriate point, when to create a new submap is determined by both the accumulation of scan match error and the particle distribution. Furthermore, LCPF uses branch and bound algorithm as basic detector for loop detection and multiple criteria to judge the reliability of a loop. In the criteria, a novel parameter called usable ratio was proposed to measure the useful information that a laser scan containing. Finally, comparisons to existing 2D-Lidar mapping algorithm are performed with a series of open dataset simulations and real robot experiments to demonstrate the effectiveness of LCPF.",,10.1109/ACCESS.2020.2968353,,,,Simultaneous localization and mapping;Lasers;Laser radar;Particle filters;Heuristic algorithms;Optimization;Simultaneous localization and mapping;mobile robots;indoor navigation;particle filter;loop detection;dynamic submap segementation,,2169-3536,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Robust SLAM Systems: Are We There Yet?,M. Bujanca and X. Shi and M. Spear and P. Zhao and B. Lennox and M. Luján,,2021,IEEE Index Terms,5320--5327,,"Progress in the last decade has brought about significant improvements in the accuracy and speed of SLAM systems, broadening their mapping capabilities. Despite these advancements, long-term operation remains a major challenge, primarily due to the wide spectrum of perturbations robotic systems may encounter.Increasing the robustness of SLAM algorithms is an ongoing effort, however it usually addresses a specific perturbation. Generalisation of robustness across a large variety of challenging scenarios is not well-studied nor understood. This paper presents a systematic evaluation of the robustness of open-source state-of-the-art SLAM algorithms with respect to challenging conditions such as fast motion, non-uniform illumination, and dynamic scenes. The experiments are performed with perturbations present both independently of each other, as well as in combination in long-term deployment settings in unconstrained environments (lifelong operation).The detailed results (approx. 20,000 experiments) along with comprehensive documentation of the benchmarking tool for integrating new datasets and evaluating SLAM algorithms not studied in this work are available at https://robustslam.github.io/evaluation.",,10.1109/IROS51168.2021.9636814,,,,Simultaneous localization and mapping;Systematics;Three-dimensional displays;Heuristic algorithms;Perturbation methods;Dynamics;Lighting,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Rotation invariant features from omnidirectional camera images using a polar higher-order local autocorrelation feature extractor,F. Linaker and M. Ishikawa,,2004,IEEE Abstract,4026--4031vol.4,4,"Proposed in this paper is a component for extracting low-dimensional rotation invariant feature vectors directly from omnidirectional camera images. The component is based on higher-order local autocorrelation (HLAC) functions, but with a modification that makes the extraction result in rotation invariant representations. As the component provides a static mapping to feature vectors, it requires no setup or learning phase and is well-suited for lifelong learning scenarios where input distributions can be nonstationary. Experiments with an actual robot system are presented and results show that the extracted feature vectors manage to capture structures in the environment. When used as the perceptual component of a sequential Monte Carlo localizer, the location of the robot can be tracked without access to long-range distance sensors. Important limitations and suitable uses for the extracted representations are also discussed.",,10.1109/IROS.2004.1390045,,,,Cameras;Autocorrelation;Feature extraction;Robot vision systems;Data mining;Robot sensing systems;Monte Carlo methods;Mobile robots;Image storage;Continuing professional development,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Review of underwater SLAM techniques,F. Hidalgo and T. Bräunl,,2015,IEEE Abstract,306--311,,"SLAM (Simultaneous Localization and Mapping) for underwater vehicles is a challenging research topic due to the limitations of underwater localization sensors and error accumulation over long-term operations. Furthermore, acoustic sensors for mapping often provide noisy and distorted images or low-resolution ranging, while video images provide highly detailed images but are often limited due to turbidity and lighting. This paper presents a review of the approaches used in state-of-the-art SLAM techniques: Extended Kalman Filter SLAM (EKF-SLAM), FastSLAM, GraphSLAM and its application in underwater environments.",,10.1109/ICARA.2015.7081165,,,,Simultaneous localization and mapping;Feature extraction;Estimation;Vehicles;Simultaneous Localization and Mapping (SLAM);Extended Kalman Filter (EKF);Particle Filter (PF);FastSLAM;GraphSLAM;Underwater Vehicle;AUV,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"Visual Odometry : Part II: Matching, Robustness, Optimization, and Applications",F. Fraundorfer and D. Scaramuzza,IEEE Robotics Automation Magazine,2012,IEEE Abstract,78--90,19,"Part II of the tutorial has summarized the remaining building blocks of the VO pipeline: specifically, how to detect and match salient and repeatable features across frames and robust estimation in the presence of outliers and bundle adjustment. In addition, error propagation, applications, and links to publicly available code are included. VO is a well understood and established part of robotics. VO has reached a maturity that has allowed us to successfully use it for certain classes of applications: space, ground, aerial, and underwater. In the presence of loop closures, VO can be used as a building block for a complete SLAM algorithm to reduce motion drift. Challenges that still remain are to develop and demonstrate large-scale and long-term implementations, such as driving autonomous cars for hundreds of miles. Such systems have recently been demonstrated using Lidar and Radar sensors [86]. However, for VO to be used in such systems, technical issues regarding robustness and, especially, long-term stability have to be resolved. Eventually, VO has the potential to replace Lidar-based systems for egomotion estimation, which are currently leading the state of the art in accuracy, robustness, and reliability. VO offers a cheaper and mechanically easier-to-manufacture solution for egomotion estimation, while, additionally, being fully passive. Furthermore, the ongoing miniaturization of digital cameras offers the possibility to develop smaller and smaller robotic systems capable of ego-motion estimation.",,10.1109/MRA.2012.2182810,,,,Tutorials;Robust control;Optimization;VIsualization;Odemtry;Feature extraction;Cameras;Computer vision;Estimation,,1558-223X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Deep Supervised Hashing with Similar Hierarchy for Place Recognition,L. Wu and Y. Wu,,2019,IEEE Index Terms,3781--3786,,"Place recognition as one of the most significant requirements for long-term simultaneous localization and mapping (SLAM) has been developed rapidly in recent years. Also, deep learning is proved to be more capable than traditional methods to extract features under some complex environments. However, in real-world environments, there are many challenging problems such as viewpoint changes and illumination changes. The existing deep learning-based place recognition in extracting feature phases and matching process is both time-consuming. Moreover, features extracted from convolution neural network (CNN) are floating-point type with high dimension. In this paper, we propose deep supervised hashing for place recognition, where we design a similar hierarchy loss function to learn a model. The model can distinguish the similar images more accurately which is well suitable to place recognition. Besides the model can learn high quality hash codes by maximizing the likelihood of triplet labels. Experiments on several benchmark datasets for place recognition show that our approach is robust to viewpoints, illuminations and season changes with high accuracy. Furthermore, the trained model can extract features and match in real time on CPU with less memory consumption.",,10.1109/IROS40897.2019.8968599,,,,,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,An adaptive appearance-based map for long-term topological localization of mobile robots,F. Dayoub and T. Duckett,,2008,IEEE Abstract,3364--3369,,"This work considers a mobile service robot which uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the internal representation may become out of date after some time. To solve this problem the robot needs to be able to adapt its internal representation continually to the changes in the environment. This paper presents a method for creating an adaptive map for long-term appearance-based localization of a mobile robot using long-term and short-term memory concepts, with omni-directional vision as the external sensor.",,10.1109/IROS.2008.4650701,,,,Feature extraction;Robots;Robot sensing systems;Noise;Approximation algorithms;Robot vision systems;Cameras,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-term Ground Robot Localization Architecture for Mixed Indoor-Outdoor Scenarios,F. Caballero and J. Perez and L. Merino,,2014,IEEE Abstract,1--8,,"This paper summarizes the validation and experimental results of an architecture for six degree-of-freedom robot localization developed in the framework of the EC funded project FROG (FP7-ICT-2011.2.1). Two main localization issues are considered; one is accuracy, required by the Augmented Reality application, and the second is robustness, in order to achieve long-term autonomy of the robot. The experiments were carried out mainly at the Lisbon Zoo (Portugal), a low GPS visibility area with more than 40,000 square meters and non-planar routes as long as 1 kilometer. The approach considers an offline SLAM and multi-sensor data fusion for map building, and a Rao-Blackwellized filter for online robot localization based on previously computed map. The approach also considers localization failures and provides a method for robot re-localization based on visual place recognition.",,,https://ieeexplore.ieee.org/document/6840104,,,,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Map updating in dynamic environments,F. Abrate and B. Bona and M. Indri and S. Rosa and F. Tibaldi,,2010,IEEE Abstract,1--8,,"While building maps when robot poses are known is a tractable problem requiring limited computational complexity, the simultaneous estimation of the trajectory and the map of the environment (known as SLAM) is much more complex and requires many computational resources. Moreover, SLAM is generally peformed in environments that do not vary over time (called static environments), whereas real applications commonly require navigation services in changing environments (called dynamic environments). Many real robotic applications require updated maps of the environment that vary over time, starting from a given known initial condition. In this context classical SLAM approaches are generally not directly applicable: such approaches only apply in static environments or in dynamic environments where it is possible to model the environment dynamics. We are interested here in long-term mapping operativity in presence of variations in the map, as in the case of robotic applications in logistic spaces, where rovers have to track the presence of goods in given areas. In this paper we propose a methodology that is able to detect variations in the environment, generate a local map containing only the persistent variations and finally merge the local map with the global one used for localization.",,,https://ieeexplore.ieee.org/document/5756810,,,Simultaneous localization and mapping;Correlation;Robot kinematics;Turning;Pixel;Merging,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-Term Visual Localization Using Semantically Segmented Images,E. Stenborg and C. Toft and L. Hammarstrand,,2018,IEEE Abstract,6484--6490,,"Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.",,10.1109/ICRA.2018.8463150,,,,Semantics;Cameras;Roads;Image segmentation;Visualization;Robustness;Feature extraction,,2577-087X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Robotic Discovery of the Auditory Scene,E. Martinson and A. Schultz,,2007,IEEE Abstract,435--440,,"In this work, we describe an autonomous mobile robotic system for finding and investigating ambient noise sources in the environment. Motivated by the large negative effect of ambient noise sources on robot audition, the long-term goal is to provide awareness of the auditory scene to a robot, so that it may more effectively act to filter out the interference or re-position itself to increase the signal-to-noise ratio. Here, we concentrate on the discovery of new sources of sound through the use of mobility and directed investigation. This is performed in a two-step process. In the first step, a mobile robot first explores the surrounding acoustical environment, creating evidence grid representations to localize the most influential sound sources in the auditory scene. Then in the second step, the robot investigates each potential sound source location in the environment so as to improve the localization result, and identify volume and directionality characteristics of the sound source. Once every source has been investigated, a noise map of the entire auditory scene is created for use by the robot in avoiding areas of loud ambient noise when performing an auditory task.",,10.1109/ROBOT.2007.363825,,,,Layout;Acoustic noise;Robotics and automation;Working environment noise;Mobile robots;Microphone arrays;Signal to noise ratio;Filters;Interference;Position measurement;Sound Source Localization;Evidence Grid;Mobile Robots;Sound Mapping,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Approximating Marginalization with Sparse Global Priors for Sliding Window SLAM-Graphs,D. Wilbers and L. Rumberg and C. Stachniss,,2019,IEEE Abstract,25--31,,"Most autonomous vehicles rely on some kind of map for localization or navigation. Outdated maps however are a risk to the performance of any map-based localization system applied in autonomous vehicles. It is necessary to update the used maps to ensure stable and long-term operation. We address the problem of computing landmark updates live in the vehicle, which requires efficient use of the computational resources. In particular, we employ a graph-based sliding window approach for simultaneous localization and incremental map refinement. We propose a novel method that approximates sliding window marginalization without inducing fill-in. Our method maintains the exact same sparsity pattern as without performing marginalization, but simultaneously improves the landmark estimates. The main novelty of this work is the derivation of sparse global priors that approximate dense marginalization. In comparison to state-of-the-art work, our approach utilizes global instead of local linearization points, but still minimizes linearization errors. We first approximate marginalization via Kullback-Leibler divergence and then recalculate the mean to compensate linearization errors. We evaluate our approach on simulated and real data from a prototype vehicle and compare our approach to state-of-the-art sliding window marginalization.",,10.1109/IRC.2019.00013,,,,Microsoft Windows;Optimization;Autonomous vehicles;Jacobian matrices;Robots;Navigation;Trajectory;SLAM;Sensor Fusion;Incremental Mapping;Localization;Automated Driving,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Efficient Map Compression for Collaborative Visual SLAM,D. V. Opdenbosch and T. Aykut and N. Alt and E. Steinbach,,2018,IEEE Abstract,992--1000,,"Swarm robotics is receiving increasing interest, because the collaborative completion of tasks, such as the exploration of unknown environments, leads to improved performance and reduced effort. The ability to exchange map information is an essential requirement for collaborative exploration. When moving to large-scale environments, where the communication data rate between the swarm participants is typically limited, efficient compression algorithms and an approach for discarding less informative parts of the map are key for a successful long-term operation. In this paper, we present a novel compression approach for environment maps obtained from a visual SLAM system. We apply feature coding to the visual information to compress the map efficiently. We make use of a minimum spanning tree to connect all features that serve as observations of a single map point. Thereby, we can exploit inter-feature dependencies and obtain an optimal coding order. Additionally, we add a map sparsification step to keep only useful map points by solving a linear integer programming problem, which preserves the map points that exhibit both good compression properties and high observability. We evaluate the proposed method on a standard dataset and show that our approach outperforms state-of-the-art techniques.",,10.1109/WACV.2018.00114,,,,Visualization;Encoding;Simultaneous localization and mapping;Feature extraction;Trajectory;Optimization,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Onboard Detection-Tracking-Localization,D. Tang and Q. Fang and L. Shen and T. Hu,IEEE/ASME Transactions on Mechatronics,2020,IEEE Abstract,1555--1565,25,"This article investigates long-term positioning of moving objects by monocular vision of a miniature fixed-wing unmanned aerial vehicle. It is challenging to perform a real-time onboard vision processing task, due to the strict payload capacity and power budget limitations of microflying vehicles. We propose a parallel onboard architecture that explicitly decouples the long-term positioning task into iteratively operated detection, tracking, and localization. The proposed approach is eventually called onboard detection-tracking-localization, namely oDTL. The detector automatically extracts and identifies the object from image frames captured at in-flight durations. A learning-based network is constructed to improve detection accuracy and robustness against ever-changing outdoor illumination conditions and flying viewpoints. The tracker follows the object within specified region-of-interest from frame to frame with lower computing consumption. To further reduce target-losing rate, a concept of blind zone is proposed and applied, and its boundaries in sequential images are also theoretically inferred. The position estimator maps the flying vehicle pose, the image coordinates, and calibration specifications into real-world positions of the moving target. An extended Kalman filter is developed for rough position estimation, and a smooth module is introduced for the refinement of the position. Three offline comparative experiments and three online experiments have been conducted respectively to testify the real-time capability of our approach. The collected experimental results also demonstrate the feasible accuracy and robustness of the overall solution within the specified flying onboard scenarios.",,10.1109/TMECH.2020.2976794,,,,Robustness;Real-time systems;Visualization;Lighting;Cameras;Three-dimensional displays;IEEE transactions;Detection;localization;miniature fixed-wing unmanned aerial vehicle (UAV);monocular;onboard vision;parallel architecture;positioning;tracking,,1941-014X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Robust sound source mapping using three-layered selective audio rays for mobile robots,D. Su and K. Nakamura and K. Nakadai and J. V. Miro,,2016,IEEE Abstract,2771--2777,,"This paper investigates sound source mapping in a real environment using a mobile robot. Our approach is based on audio ray tracing which integrates occupancy grids and sound source localization using a laser range finder and a microphone array. Previous audio ray tracing approaches rely on all observed rays and grids. As such observation errors caused by sound reflection, sound occlusion, wall occlusion, sounds at misdetected grids, etc. can significantly degrade the ability to locate sound sources in a map. A three-layered selective audio ray tracing mechanism is proposed in this work. The first layer conducts frame-based unreliable ray rejection (sensory rejection) considering sound reflection and wall occlusion. The second layer introduces triangulation and audio tracing to detect falsely detected sound sources, rejecting audio rays associated to these misdetected sounds sources (short-term rejection). A third layer is tasked with rejecting rays using the whole history (long-term rejection) to disambiguate sound occlusion. Experimental results under various situations are presented, which proves the effectiveness of our method.",,10.1109/IROS.2016.7759430,,,,Robot kinematics;Ray tracing;Lasers;Simultaneous localization and mapping;Two dimensional displays,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,NYU-VPR: Long-Term Visual Place Recognition Benchmark with View Direction and Data Anonymization Influences,D. Sheng and Y. Chai and X. Li and C. Feng and J. Lin and C. Silva and J.-R. Rizzo,,2021,IEEE Abstract,9773--9779,,"Visual place recognition (VPR) is critical in not only localization and mapping for autonomous driving vehicles, but also assistive navigation for the visually impaired population. To enable a long-term VPR system on a large scale, several challenges need to be addressed. First, different applications could require different image view directions, such as front views for self-driving cars while side views for the low vision people. Second, VPR in metropolitan scenes can often cause privacy concerns due to the imaging of pedestrian and vehicle identity information, calling for the need for data anonymization before VPR queries and database construction. Both factors could lead to VPR performance variations that are not well understood yet. To study their influences, we present the NYU-VPR dataset that contains more than 200,000 images over a 2km×2km area near the New York University campus, taken within the whole year of 2016. We present benchmark results on several popular VPR algorithms showing that side views are significantly more challenging for current VPR methods while the influence of data anonymization is almost negligible, together with our hypothetical explanations and in-depth analysis.",,10.1109/IROS51168.2021.9636640,,,,Location awareness;Visualization;Data privacy;Navigation;Databases;Sociology;Imaging,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Development of an Autonomous Robotic System Using the Graph-based SPLAM Algorithm,D. Kozlov and V. Myasnikov,,2021,IEEE Abstract,1--5,,"For long-term planning, localization and mapping, the robot must constantly update the map by the changing environment and new areas that the robot is exploring. At the same time, this map should not take up too much of the robot’s memory, since the robot’s performance is limited due to the small size of the robot and increased performance requirements. The robot must interact with the map on time, updating its location to build a further route to explore areas that have not been visited. In addition to compiling a map, when solving the problem of exploration rooms, the following steps are also important: forming a plan for bypassing an unknown room, calculating the trajectory, resolving collisions with obstacles, and following the trajectory. In the course of this work, an autonomous robotic system was developed, the task of which is to map previously unknown premises. For this, SPLAM algorithms, algorithms for building map and working with graphs, algorithms for following a trajectory were used.",,10.1109/ITNT52450.2021.9649028,,,,Measurement;Space vehicles;Memory management;Robot vision systems;Production;Real-time systems;Trajectory;SPLAM;SLAM;robot;ROS;RTABMap;Voronoi diagram;bang-bang controller;Jetson;Zed;point cloud;odometry;Dijkstra algorithm,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Towards exteroceptive based localisation,D. J. Spero and R. A. Jarvis,,2004,IEEE Abstract,822--827vol.2,2,"The intelligent application of a mobile robot, outside the experimental laboratory, requires a robust locomotive strategy that is rarely conducive to stringent kinematic modeling. Localisation methods that rely upon such modeling often fail, as model boundaries succumb to unpredictable events. This paper presents the development of a self-contained localisation system that purposely obviates the need for odometric information, and an associated kinematic model, to provide robot anonymity. Without odometry, the system is oblivious to the non-systematic vagaries of the robotic platform interacting with a natural domain. The proposed system hypothesises about the robot's absolute pose by algorithmically solving the kidnapped robot problem using exteroceptive based perception. Since no a priori information is assumed, long-term pose fixes are derived within a simultaneous localisation and mapping (SLAM) framework. Preliminary results were gathered using a skid steering mobile robot, equipped with a scanning laser rangefinder, in an outdoor environment. This novel localisation approach was found to be efficient and robust, while exhibiting the capacity for widespread applicability.",,10.1109/RAMECH.2004.1438024,,,,Mobile robots;Robustness;Intelligent robots;Simultaneous localization and mapping;Wheels;Kinematics;Steering systems;Australia;Laboratories;Fires,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,A visual bag of words method for interactive qualitative localization and mapping,D. Filliat,,2007,IEEE Abstract,3921--3926,,Localization for low cost humanoid or animal-like personal robots has to rely on cheap sensors and has to be robust to user manipulations of the robot. We present a visual localization and map-learning system that relies on vision only and that is able to incrementally learn to recognize the different rooms of an apartment from any robot position. This system is inspired by visual categorization algorithms called bag of words methods that we modified to make fully incremental and to allow a user-interactive training. Our system is able to reliably recognize the room in which the robot is after a short training time and is stable for long term use. Empirical validation on a real robot and on an image database acquired in real environments are presented.,,10.1109/ROBOT.2007.364080,,,,Robot sensing systems;Humanoid robots;Robot vision systems;Simultaneous localization and mapping;Robotics and automation;Human robot interaction;Robustness;Shape control;Costs;Image databases,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,A study on wearable robotics — Comfort is in the context,D. C. Herath and T. Chapman and A. Tomkins and L. Elliott and M. David and A. Cooper and D. Burnham and S. Kodagoda,,2011,IEEE Abstract,2969--2974,,"WITU (Wearable Indoor Tracking Unit) is a wearable robotic device that aids indoor navigation by building maps and localizing the user within them. Applications of such a device include search and rescue, travel aid in large and complex buildings, museum guides among others where external localization information such as from a GPS is not available. However, WITU relies on human intelligence both to maintain long term consistency of its location estimates and to efficiently manage its limited memory and processing capacity. This alludes to a symbiotic relationship between the user and the device and here we look at this symbiotic relationship from an end user perspective. Thus, in order to have a successful interaction, we argue that the user needs to feel comfortable wearing the device while carrying out the intended tasks. We hypothesize that this perceived comfort is dependent on the context in which the device is used. We test our hypothesis on three different scenarios; search and rescue worker, dementia patient in a long care facility and a person at a party which acts as the baseline. Results indicate an important consequence for the development of such wearable robotic systems.",,10.1109/ROBIO.2011.6181757,,,,Dementia;Humans;Context;Robots;Audio recording;Loading;Educational institutions,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Mobile robotics in the long term-exploring the fourth dimension,D. Austin and L. Fletcher and A. Zelinsky,,2001,IEEE Abstract,613--618vol.2,2,"Explores the issues involved in deployment of mobile robots in real-world situations and presents solutions and approaches under development at the Australian National University. For deployment of mobile robots outside of the laboratory, long-term operation is required. Hence, we have developed an automatic recharging system. In addition, a Web-based teleoperation system is used to provide missions to test the long-term reliability of the robot. The final aspect of real-world operation that is explored here is operations in dynamic environments. To date, researchers have assumed static environments for mapping and localisation. We propose methods to avoid this restriction.",,10.1109/IROS.2001.976237,,,,Mobile robots;Robotics and automation;Robot sensing systems;Laboratories;Batteries;Motion detection;Hardware;System testing;Path planning;Object detection,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Map As the Hidden Sensor: Fast Odometry-Based Global Localization,C. Peng and D. Weikersdorfer,,2020,IEEE Abstract,2317--2323,,"Accurate and robust global localization is essential to robotics applications. We propose a novel global localization method that employs the map traversability as a hidden observation. The resulting map-corrected odometry localization is able to provide an accurate belief tensor of the robot state. Our method can be used for blind robots in dark or highly reflective areas. In contrast to odometry drift in the long-term, our method using only odometry and the map converges in long-term. Our method can also be integrated with other sensors to boost the localization performance. The algorithm does not have any initial state assumption and tracks all possible robot states at all times. Therefore, our method is global and is robust in the event of ambiguous observations. We parallel each step of our algorithm such that it can be performed in real-time (up to ~300 Hz) using GPU. We validate our algorithm in different publicly available floor-plans and show that it is able to converge to the ground truth fast while being robust to ambiguities.",,10.1109/ICRA40945.2020.9197225,,,,Robot sensing systems;Tensile stress;Trajectory;Robustness;Uncertainty;Real-time systems,,2577-087X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Comparison of Two Image and Inertial Sensor Fusion Techniques for Navigation in Unmapped Environments,C. N. Taylor and M. J. Veth and J. F. Raquet and M. M. Miller,IEEE Transactions on Aerospace and Electronic Systems,2011,IEEE Abstract,946--958,47,"To enable navigation of miniature aerial vehicles (MAVs) with a low-quality inertial measurement unit (IMU), external sensors are typically fused with the information generated by the low-quality IMU. Most commercial systems for MAVs currently fuse GPS measurements with IMU information to navigate the MAV. However there are many scenarios in which an MAV might prove useful, but GPS is not available (e.g., indoors, urban terrain, etc.). Therefore several approaches have recently been introduced that couple information from an IMU with visual information (usually captured by an electro-optical camera). In general the methods for fusing visual information with an IMU utilizes one of two techniques: 1) applying rigid body constraints on where landmarks should appear in a set of two images (constraint-based fusion) or 2) simultaneously estimating the location of features that are observed by the camera (mapping) and the location of the camera (simultaneous localization and mapping-SLAM-based fusion). While each technique has some nuances associated with its implementation in a true MAV environment (i.e., computational requirements, real-time implementation, feature tracking, etc.), this paper focuses solely on answering the question ""Which fusion technique (constraint- or SLAM-based) enables more accurate long-term MAV navigation?"" To answer this question, specific implementations of a constraint- and SLAM-based fusion technique, with novel modifications for improved results on MAVs, are described. A basic simulation environment is used to perform a comparison of the constraint- and SLAM-based fusion methods. We demonstrate the superiority of SLAM-based techniques in specific MAV flight scenarios and discuss the relative weaknesses and strengths of each fusion approach.",,10.1109/TAES.2011.5751236,,,,Cameras;Visualization;Force;Global Positioning System;Kalman filters;Velocity measurement,,1557-9603,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Active SLAM in structured environments,C. Leung and S. Huang and G. Dissanayake,,2008,IEEE Abstract,1898--1903,,This paper considers the trajectory planning problem for line-feature based SLAM in structured indoor environments. The robot poses and line features are estimated using Smooth and Mapping (SAM) which is found to provide more consistent estimates than the Extended Kalman Filter (EKF). The objective of trajectory planning is to minimise the uncertainty of the estimates and to maximise coverage. Trajectory planning is performed using Model Predictive Control (MPC) with an attractor incorporating long term goals. This planning is demonstrated both in simulation and in a real-time experiment with a Pioneer2DX robot.,,10.1109/ROBOT.2008.4543484,,,,Simultaneous localization and mapping;Robots;Trajectory;Strategic planning;Large-scale systems;Predictive models;Predictive control;Indoor environments;Laser noise;Covariance matrix,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,A Geodetic Normal Distribution Map for Long-Term LiDAR Localization on Earth,C. Kim and S. Cho and M. Sunwoo and P. Resende and B. Bradaï and K. Jo,IEEE Access,2021,IEEE Abstract,470--484,9,"Light detection and ranging (LiDAR) sensors enable a vehicle to estimate a pose by matching their measurements with a point cloud (PCD) map. However, the PCD map structure, widely used in robot fields, has some problems to be applied for mass production in automotive fields. First, the PCD map is too big to store all map data at in-vehicle units or download the map data from a wireless network according to the vehicle location. Second, the PCD map, represented by a single origin in the Cartesian coordinates, causes coordinate conversion errors due to an inaccurate plane-orb projection, when the vehicle estimate the geodetic pose on Earth. To solve two problems, this paper presents a geodetic normal distribution (GND) map structure. The GND map structure supports a geodetic quad-tree tiling system with multiple origins to minimize the coordinate conversion errors. The map data managed by the GND map structure are compressed by using Cartesian probabilistic distributions of points as map features. The truncation errors by heterogeneous coordinates between the geodetic tiling system and Cartesian distributions are compensated by the Cartesian voxelization rule. In order to match the LiDAR measurements with the GND map structure, the paper proposes map-matching approaches based on Monte-Carlo and optimization. The paper performed some experiments to evaluate the map size compression and the long-term localization on Earth: comparison with the PCD map structure, localization in various continents, and long-term localization.",,10.1109/ACCESS.2020.3047421,,,,Laser radar;Sensors;Three-dimensional displays;Gaussian distribution;Semantics;Cameras;Roads;World-scale map management;map compression;normal distribution map;registration,,2169-3536,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,NASA Space Robotics Challenge 2 Qualification Round: An Approach to Autonomous Lunar Rover Operations,C. Kilic and B. M. R.  and C. A. Tatsch and J. Beard and J. Strader and S. Das and D. Ross and Y. Gu and G. A. S. Pereira and J. N. Gross,IEEE Aerospace and Electronic Systems Magazine,2021,IEEE Abstract,24--41,36,"Plans for establishing a long-term human presence on the Moon will require substantial increases in robot autonomy and multirobot coordination to support establishing a lunar outpost. To achieve these objectives, algorithm design choices for the software developments need to be tested and validated for expected scenarios such as autonomous in situ resource utilization, localization in challenging environments, and multirobot coordination. However, real-world experiments are extremely challenging and limited for extraterrestrial environment. Also, realistic simulation demonstrations in these environments are still rare and demanded for initial algorithm testing capabilities. To help some of these needs, the NASA Centennial Challenges program established the Space Robotics Challenge Phase 2 (SRC2), which consist of virtual robotic systems in a realistic lunar simulation environment, where a group of mobile robots were tasked with reporting volatile locations within a global map, excavating and transporting these resources, and detecting and localizing a target of interest. The main goal of this article is to share our team's experiences on the design tradeoffs to perform autonomous robotic operations in a virtual lunar environment and to share strategies to complete the mission requirements posed by NASA SRC2 competition during the qualification round. Of the 114 teams that registered for participation in the NASA SRC2, team Mountaineers finished as one of only six teams to receive the top qualification round prize.",,10.1109/MAES.2021.3115897,,,,NASA;Space vehicles;Robot kinematics;Moon;Software algorithms;Multi-robot systems;Resource management,,1557-959X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models,B. Wen and K. Bekris,,2021,IEEE Abstract,8067--8074,,"Tracking the 6D pose of objects in video sequences is important for robot manipulation. Most prior efforts, however, often assume that the target object's CAD model, at least at a category-level, is available for offline training or during online template matching. This work proposes BundleTrack, a general framework for 6D pose tracking of novel objects, which does not depend upon 3D models, either at the instance or category-level. It leverages the complementary attributes of recent advances in deep learning for segmentation and robust feature extraction, as well as memory-augmented pose graph optimization for spatiotemporal consistency. This enables long-term, low-drift tracking under various challenging scenarios, including significant occlusions and object motions. Comprehensive experiments given two public benchmarks demonstrate that the proposed approach significantly outperforms state-of-art, category-level 6D tracking or dynamic SLAM methods. When compared against state-of-art methods that rely on an object instance CAD model, comparable performance is achieved, despite the proposed method’s reduced information requirements. An efficient implementation in CUDA provides a real-time performance of 10Hz for the entire framework. Code is available at: https://github.com/wenbowen123/BundleTrack",,10.1109/IROS51168.2021.9635991,,,,Training;Solid modeling;Target tracking;Three-dimensional displays;Simultaneous localization and mapping;Motion segmentation;Video sequences,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-Term Visual Inertial SLAM based on Time Series Map Prediction,B. Song and W. Chen and J. Wang and H. Wang,,2019,IEEE Abstract,5364--5369,,"With the advance in the field of mobile robots, autonomous robots are required for long-term deployment in dynamic and complex environments. However, the performance of Visual Inertial SLAM systems in long-term operation is not satisfactory, and most long-term SLAM systems assumes periodic changes in the environment. This paper presents a novel solution for long-term monocular VI SLAM system in dynamic environment based on autoregression(AR) modeling and map prediction. Map points are first classified into static and semi-static map points according to a memory model. Modeling and prediction of the different states of semi-static map points are performed that are derived from time series models. The predicted map is then fused with the current map to achieve a better forecast for the next frame if the prediction is not satisfactory enough. Experiments are carried out on an embedded system. The results indicate that the map prediction is reliable and the proposed approach improves the performance of long-term localization and mapping in dynamic environments.",,10.1109/IROS40897.2019.8968017,,,,,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Information-based Active SLAM via topological feature graphs,B. Mu and M. Giamou and L. Paull and A.-A. Agha-mohammadi and J. Leonard and J. How,,2016,IEEE Abstract,5583--5590,,"Exploring an unknown space and building maps is a fundamental capability for mobile robots. For fully autonomous systems, the robot would further need to actively plan its paths during exploration. The problem of designing robot trajectories to actively explore an unknown environment and minimize the map error is referred to as active simultaneous localization and mapping (active SLAM). Existing work has focused on planning paths with occupancy grid maps, which do not scale well and suffer from long term drift. This work proposes a Topological Feature Graph (TFG) representation that scales well and develops an active SLAM algorithm with it. The TFG uses graphical models, which utilize independences between variables, and enables a unified quantification of exploration and exploitation gains with a single entropy metric. Hence, it facilitates a natural and principled balance between map exploration and refinement. A probabilistic roadmap path-planner is used to generate robot paths in real time. Experimental results demonstrate that the proposed approach achieves better accuracy than a standard grid-map based approach while requiring orders of magnitude less computation and memory resources.",,10.1109/CDC.2016.7799127,,,,Simultaneous localization and mapping;Trajectory;Uncertainty;Planning;Entropy;Measurement,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"DynaSLAM: Tracking, Mapping, and Inpainting in Dynamic Scenes",B. Bescos and J. M. Fácil and J. Civera and J. Neira,IEEE Robotics and Automation Letters,2018,IEEE Abstract,4076--4083,3,"The assumption of scene rigidity is typical in SLAM algorithms. Such a strong assumption limits the use of most visual SLAM systems in populated real-world environments, which are the target of several relevant applications like service robotics or autonomous vehicles. In this letter we present DynaSLAM, a visual SLAM system that, building on ORB-SLAM2, adds the capabilities of dynamic object detection and background inpainting. DynaSLAM is robust in dynamic scenarios for monocular, stereo, and RGB-D configurations. We are capable of detecting the moving objects either by multiview geometry, deep learning, or both. Having a static map of the scene allows inpainting the frame background that has been occluded by such dynamic objects. We evaluate our system in public monocular, stereo, and RGB-D datasets. We study the impact of several accuracy/speed trade-offs to assess the limits of the proposed methodology. DynaSLAM outperforms the accuracy of standard visual SLAM baselines in highly dynamic scenarios. And it also estimates a map of the static parts of the scene, which is a must for long-term applications in real-world environments.",,10.1109/LRA.2018.2860039,,,,Vehicle dynamics;Simultaneous localization and mapping;Heuristic algorithms;Image segmentation;Cameras;Visualization;Geometry;SLAM;visual-based navigation;localization,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Natural landmark-based monocular localization for MAVs,A. Wendel and A. Irschara and H. Bischof,,2011,IEEE Abstract,5792--5799,,"Highly accurate localization of a micro aerial vehicle (MAV) with respect to a scene is important for a wide range of applications, in particular surveillance and inspection. Most existing approaches to visual localization focus on indoor environments, while such tasks require outdoor navigation. Within this work, we introduce a novel algorithm for monocular visual localization for MAVs based on the concept of virtual views in 3D space. Under the assumption that significant parts of the scene do not alter their geometry and serve as natural landmarks, the accuracy of our visual approach outperforms consumer grade GPS systems. In an experimental setup we compare our approach to a state-of-the-art visual SLAM algorithm and evaluate the performance by geometric validation from an observer's view. As our method directly allows global registration, it is neither prone to drift nor bias. This makes it well suited for long-term autonomous navigation.",,10.1109/ICRA.2011.5980317,,,,Cameras;Three dimensional displays;Visualization;Image reconstruction;Feature extraction;Geometry;Simultaneous localization and mapping,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Dynamic pose graph SLAM: Long-term mapping in low dynamic environments,A. Walcott-Bryant and M. Kaess and H. Johannsson and J. J. Leonard,,2012,IEEE Abstract,1871--1878,,"Maintaining a map of an environment that changes over time is a critical challenge in the development of persistently autonomous mobile robots. Many previous approaches to mapping assume a static world. In this work we incorporate the time dimension into the mapping process to enable a robot to maintain an accurate map while operating in dynamical environments. This paper presents Dynamic Pose Graph SLAM (DPG-SLAM), an algorithm designed to enable a robot to remain localized in an environment that changes substantially over time. Using incremental smoothing and mapping (iSAM) as the underlying SLAM state estimation engine, the Dynamic Pose Graph evolves over time as the robot explores new places and revisits previously mapped areas. The approach has been implemented for planar indoor environments, using laser scan matching to derive constraints for SLAM state estimation. Laser scans for the same portion of the environment at different times are compared to perform change detection; when sufficient change has occurred in a location, the dynamic pose graph is edited to remove old poses and scans that no longer match the current state of the world. Experimental results are shown for two real-world dynamic indoor laser data sets, demonstrating the ability to maintain an up-to-date map despite long-term environmental changes.",,10.1109/IROS.2012.6385561,,,,Simultaneous localization and mapping;Measurement by laser beam;Mobile robots;Heuristic algorithms;Lasers,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Enabling persistent autonomy for underwater gliders through terrain based navigation,A. Stuntz and D. Liebel and R. N. Smith,,2015,IEEE Abstract,1--10,,"To effectively examine ocean processes we must often sample over the duration of long (weeks to months) oscillation patterns. Such sampling requires persistent autonomous underwater vehicles, that have a similarly long deployment duration. Actively actuated (propeller-driven) underwater vehicles have proven effective in multiple sampling scenarios, however they have limited deployment endurance. The emergence of less actuated vehicles, i.e., underwater gliders, has enabled greater energy savings and thus increased endurance. Due to reduced actuation, these vehicles are more susceptible to external forces, e.g., ocean currents, causing them to have poor navigational and localization accuracy underwater. This is exacerbated in coastal regions, where current velocities are the same order of magnitude as the vehicle velocity. In this paper, we examine a method of reducing navigation and localization error, not only for navigation, but more so for more accurately reconstructing the path that the glider traversed to contextualize the gathered data, with respect to the science question at hand. We present a set of algorithms for offline processing that accurately localizes the traversed path of an underwater glider over long-term, ocean deployments. The proposed method utilizes terrain-based navigation with only depth, altimeter and compass data compared to local bathymetry maps to provide accurate reconstructions of traversed paths in the ocean.",,10.1109/OCEANS-Genova.2015.7271751,,,,Navigation;Vehicles;Accuracy;Sea measurements;Sea surface;Trajectory,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Graph Optimization Methods for Large-Scale Crowdsourced Mapping,A. Stoven-Dubois and A. Dziri and B. Leroy and R. Chapuis,,2020,IEEE Abstract,1--8,,"Automotive players have recently shown an increasing interest in high-precision mapping, with the aim of enhancing vehicles safety and autonomy. Nevertheless, the acquisition, processing, and updates of accurate maps remains an economic challenge. Collaborative mapping through vehicles crowdsourcing represents a promising solution to tackle this problem. However, the potential scalability and accuracy provided by such an approach have yet to be studied and assessed. In this paper, we study the use of graph optimization in the scope of collaborative mapping. We build a map of geo-localized landmarks by crowdsourcing observations from multiple vehicles, and applying several successive map updates. We present different strategies to adapt graph optimization to the crowdsourced approach, and compare their performances in terms of map quality and scalability on simulation data. We show the critical requirement, in a long-term context, to ensure consistency of the map updates, and we propose a scalable solution which is able to build an accurate map of geolocalized landmarks.",,10.23919/FUSION45008.2020.9190292,,,,Simultaneous localization and mapping;Optimization;Geology;Trajectory;Estimation;Scalability;Crowdsourced Mapping;Collaborative Mapping;Graph Optimization;High-Precision Mapping;Geolocal-ization,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-Term Urban Vehicle Localization Using Pole Landmarks Extracted from 3-D Lidar Scans,A. Schaefer and D. Büscher and J. Vertens and L. Luft and W. Burgard,,2019,IEEE Abstract,1--7,,"Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation [1]. In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15 months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy.",,10.1109/ECMR.2019.8870928,,,,Laser radar;Detectors;Reliability;Feature extraction;Urban areas;Trajectory;Roads,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,ExMaps: Long-Term Localization in Dynamic Scenes using Exponential Decay,A. Rotsidis and C. Lutteroth and P. Hall and C. Richardt,,2021,IEEE Abstract,2866--2875,,"Visual camera localization using offline maps is widespread in robotics and mobile applications. Most state-of-the-art localization approaches assume static scenes, so maps are often reconstructed once and then kept constant. However, many scenes are dynamic and as changes in the scene happen, future localization attempts may struggle or fail entirely. Therefore, it is important for successful long-term localization to update and maintain maps as new observations of the scene, and changes in it, arrive. We propose a novel method for automatically discovering which points in a map remain stable over time, and which are due to transient changes. To this end, we calculate a stability store for each point based on its visibility over time, weighted by an exponential decay over time. This allows us to consider the impact of time when scoring points, and to distinguish which points are useful for long-term localization. We evaluate our method on the CMU Extended Seasons dataset (outdoors) and a new indoor dataset of a retail shop, and show the benefit of maintaining a `live map' that integrates updates over time using our exponential decay based method over a static `base map'.",,10.1109/WACV48630.2021.00291,,,,Location awareness;Visualization;Computer vision;Conferences;Robot vision systems;Cameras;Mobile applications,,2642-9381,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-Term Localization With Time Series Map Prediction for Mobile Robots in Dynamic Environments,L. Wang and W. Chen and J. Wang,,2020,IEEE Index Terms,1--7,,"In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments.",,10.1109/IROS45743.2020.9468884,,,,Location awareness;Correlation;Time series analysis;Predictive models;Brain modeling;Information filters;Real-time systems,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,An Adaptive Gaussian Particle Filter based Simultaneous Localization and Mapping with dynamic process model noise bias compensation,A. Rao and W. Han,,2015,IEEE Abstract,210--215,,"Simultaneous Localization and Mapping (SLAM) is a fundamental component of all autonomous robotics systems, which probabilisticaly fuses information from an exteroceptive sensor and a proprioceptive sensor to simultaneously estimate the robot's trajectory and the map. Inputs from the pro-prioceptive sensor are fed into the estimation algorithm via a process model corresponding with the vehicle kinematics, while a measurement model is used to process inputs from the exteroceptive sensor. Most SLAM algorithms assume known, fixed model estimate bias. This assumption does not hold true for systems with wrongly modeled estimate bias, or those affected by component fatigue due to applications requiring long term autonomy. This paper will display the adverse effects of mismodeled process model bias using a simulation. An adaptive algorithm employing Adaptive Gaussian Particle Filter based process model bias compensation will be deployed in tandem with a particle filter based FastSLAM algorithm. The algorithm will be compared favourably with existing state of the art SLAM algorithms in controlled simulations. Experimental data from a marine environment will be used to validate the efficacy of the algorithm.",,10.1109/ICCIS.2015.7274622,,,,Simultaneous localization and mapping;Adaptation models;Noise;Trajectory;Estimation;Kalman filters,,2326-8239,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Loop closure detection by compressed sensing for exploration of mobile robots in outdoor environments,A. N. Ravari and H. D. Taghirad,,2015,IEEE Abstract,511--516,,"In the problem of simultaneously localization and mapping (SLAM) for a mobile robot, it is required to detect previously visited locations so the estimation error shall be reduced. Sensor observations are compared by a similarity metric to detect loops. In long term navigation or exploration, the number of observations increases and so the complexity of the loop closure detection. Several techniques are proposed in order to reduce the complexity of loop closure detection. Few algorithms have considered the loop closure detection from a subset of sensor observations. In this paper, the compressed sensing approach is exploited to detect loops from few sensor measurements. In the basic compressed sensing it is assumed that a signal has a sparse representation is a basis which means that only a few elements of the signal are non-zero. Based on the compressed sensing approach a sparse signal can be recovered from few linear noisy projections by l1 minimization. The difference matrix which is widely used for loop detection has a sparse structure, where similar observations are shown by zero distance and different locations are indicated by ones. Based on the multiple measurement vector technique which is an extension of the basic compressed sensing, the loop closure detection is performed by comparison of few sensor observations. The applicability of the proposed algorithm is investigated in some outdoor environments through some publicly available data sets. It has been shown by some experiments that the proposed method can detect loops effectively.",,10.1109/ICRoM.2015.7367836,,,,Robot sensing systems;Complexity theory;Sparse matrices;Compressed sensing;Cameras;Information theory;Feature extraction,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Dense multi-planar scene estimation from a sparse set of images,A. Argiles and J. Civera and L. Montesano,,2011,IEEE Abstract,4448--4454,,"Ego-motion estimation and 3D scene reconstruction from image data has been a long term aim both in the Robotics and Computer Vision communities. Nevertheless, while both visual SLAM and Structure from Motion already provide an accurate ego-motion estimation, visual scene estimation does not offer yet such a satisfactory result; being in most cases limited to a sparse set of salient points. In this paper we propose an algorithm to densify a sparse point-based reconstruction into a dense multi-plane based one, from the only input of a set of sparse images.",,10.1109/IROS.2011.6094458,,,,Three dimensional displays;Cameras;Image reconstruction;Estimation;Feature extraction;Visualization;Silicon,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Active Vision for Door Localization and Door Opening using Playbot: A Computer Controlled Wheelchair for People with Mobility Impairments,A. Andreopoulos and J. K. Tsotsos,,2008,IEEE Abstract,3--10,,"Playbot is a long-term, large-scale research project, whose goal is to provide a vision-based computer controlled wheelchair that enables children and adults with mobility impairments to become more independent. Within this context, we show how Playbot can actively search an indoor environment to localize a door, approach the door, use a mounted robotic arm to open the door, and go through the door, using exclusively vision-based sensors and without using a map of the environment. We demonstrate the effectiveness of active vision for localizing objects that are too large to fall within a single camerapsilas field of view and show that well-calibrated vision-based sensors are sufficient to safely pass through a door frame that is narrow enough to tolerate a wheelchair localization error of at most a few centimetres. We provide experimental results demonstrating near perfect performance in an indoor environment.",,10.1109/CRV.2008.23,,,,Computer vision;Wheelchairs;Robot sensing systems;Mobile robots;Robot vision systems;Visual system;Manipulators;Robot kinematics;Force sensors;Indoor environments;active vision;visually guided robotics;object localization;assistive technology,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Recurrent-OctoMap: Learning State-Based Map Refinement for Long-Term Semantic Mapping With 3-D-Lidar Data,L. Sun and Z. Yan and A. Zaganidis and C. Zhao and T. Duckett,IEEE Robotics and Automation Letters,2018,IEEE Index Terms,3749--3756,3,"This letter presents a novel semantic mapping approach, Recurrent-OctoMap, learned from long-term three-dimensional (3-D) Lidar data. Most existing semantic mapping approaches focus on improving semantic understanding of single frames, rather than 3-D refinement of semantic maps (i.e. fusing semantic observations). The most widely used approach for the 3-D semantic map refinement is “Bayes update,” which fuses the consecutive predictive probabilities following a Markov-chain model. Instead, we propose a learning approach to fuse the semantic features, rather than simply fusing predictions from a classifier. In our approach, we represent and maintain our 3-D map as an OctoMap, and model each cell as a recurrent neural network, to obtain a Recurrent-OctoMap. In this case, the semantic mapping process can be formulated as a sequence-to-sequence encoding-decoding problem. Moreover, in order to extend the duration of observations in our Recurrent-OctoMap, we developed a robust 3-D localization and mapping system for successively mapping a dynamic environment using more than two weeks of data, and the system can be trained and deployed with arbitrary memory length. We validate our approach on the ETH long-term 3-D Lidar dataset. The experimental results show that our proposed approach outperforms the conventional “Bayes update” approach.",,10.1109/LRA.2018.2856268,,,,Semantics;Three-dimensional displays;Laser radar;Two dimensional displays;Simultaneous localization and mapping;Feature extraction;Recurrent neural networks;Mapping;simultaneous localization and mapping (SLAM);deep learning in robotics and automation;object detection;segmentation and categorization,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Collaborative Augmented Reality on Smartphones via Life-long City-scale Maps,L. Platinsky and M. Szabados and F. Hlasek and R. Hemsley and L. D. Pero and A. Pancik and B. Baum and H. Grimmett and P. Ondruska,,2020,IEEE Index Terms,533--541,,"In this paper we present the first published end-to-end production computer-vision system for powering city-scale shared augmented reality experiences on mobile devices. In doing so we propose a new formulation for an experience-based mapping framework as an effective solution to the key issues of city-scale SLAM scalability, robustness, map updates and all-time all-weather performance required by a production system. Furthermore, we propose an effective way of synchronising SLAM systems to deliver seamless real-time localisation of multiple edge devices at the same time. All this in the presence of network latency and bandwidth limitations. The resulting system is deployed and tested at scale in San Francisco where it delivers AR experiences in a mapped area of several hundred kilometers. To foster further development of this area we offer the data set to the public, constituting the largest of this kind to date.",,10.1109/ISMAR50242.2020.00081,,,,Production systems;Simultaneous localization and mapping;Scalability;Collaboration;Robustness;Augmented reality;Smart phones;Computer vision;Augmented reality;Structure from motion;Large-scale SLAM;Computing methodologies;Artificial intelligence;Computer vision;Tracking and Reconstruction;Computing methodologies-Mixed/augmented Reality,,1554-7868,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Tightly-Coupled Multi-Sensor Fusion for Localization with LiDAR Feature Maps,L. Pan and K. Ji and J. Zhao,,2021,IEEE Index Terms,5215--5221,,"Robust and accurate pose estimation in long-term localization is crucial to autonomous driving. In this paper, we dealt with absolute localization with a LiDAR feature map and multi-sensor measurements. We proposed a tightly-coupled fusion method with fixed-lag smoothing. A sliding window of recently maintained states is estimated by minimizing a joint cost function. This cost function includes residuals of global LiDAR registration and relative kinematic constraints from an IMU and wheel encoders. In addition, we enhance the robustness of our method by improving LiDAR registration. To achieve this goal, LiDAR feature maps with a hybrid of geometric and normal distribution features are constructed and exploited. The effectiveness of the proposed method is verified in several challenging test sequences over 200km. The experimental results demonstrate that the proposed method achieves accurate localization and high robustness in challenging scenarios even when the LiDAR observation is degraded.",,10.1109/ICRA48506.2021.9561547,,,,Location awareness;Laser radar;Smoothing methods;Pose estimation;Wheels;Kinematics;Gaussian distribution,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A Unified Framework for Mutual Improvement of SLAM and Semantic Segmentation,K. Wang and Y. Lin and L. Wang and L. Han and M. Hua and X. Wang and S. Lian and B. Huang,,2019,IEEE Index Terms,5224--5230,,"This paper presents a novel framework for simultaneously implementing localization and segmentation, which are two of the most important vision-based tasks for robotics. While the goals and techniques used for them were considered to be different previously, we show that by making use of the intermediate results of the two modules, their performance can be enhanced at the same time. Our framework is able to handle both the instantaneous motion and long-term changes of instances in localization with the help of the segmentation result, which also benefits from the refined 3D pose information. We conduct experiments on various datasets, and prove that our framework works effectively on improving the precision and robustness of the two tasks and outperforms existing localization and segmentation algorithms.",,10.1109/ICRA.2019.8793499,,,,Image segmentation;Task analysis;Robot sensing systems;Motion segmentation;Feature extraction;Three-dimensional displays,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Simultaneous Localization and Change Detection for Long-Term Map Learning: A Scalable Scene Retrieval Approach,K. Tanaka,,2018,IEEE Index Terms,1039--1045,,"This paper addresses the problem of change detection from a novel perspective of long-term map learning. We are particularly interested in designing an approach that can scale to large maps and that can function under global uncertainty in the viewpoint (i.e., GPS-denied situations). Our approach, which utilizes a compact bag-of-words (BoW) scene model, makes several contributions to the problem: (1) Two kinds of prior information are extracted from the view sequence map and used for change detection. Further, we propose a novel type of prior, called motion prior, to predict the relative motions of stationary objects and anomaly ego-motion detection. The proposed prior is also useful for distinguishing stationary from non-stationary objects. (2) A small set of good reference images (e.g., 10) are efficiently retrieved from the view sequence map by employing the recently developed Bag-of-Local-Convolutional-Features (BoLCF) scene model. (3) Change detection is reformulated as a scene retrieval over these reference images to find changed objects using a novel spatial Bag-of-Words (SBoW) scene model. Evaluations conducted of individual techniques and also their combinations on a challenging dataset of highly dynamic scenes in the publicly available Malaga dataset verify their efficacy.",,10.1109/SCIS-ISIS.2018.00173,,,,Task analysis;Uncertainty;Robots;Three-dimensional displays;Feature extraction;Solid modeling;Visualization;mobile robot;change detection;global localization,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,High level assisted control mode based on SLAM for a remotely controlled robot,J.-C. Devaux and P. Nadrag and E. Colle and P. Hoppenot,,2011,IEEE Index Terms,186--191,,"One aim of ambient assistive technologies is to reduce long term hospitalization for elderly people, especially with pathologies such as Mild Cognitive Impairment (MCI). The smart environment assists these people and their families with safety and cognitive stimulation, so they stay as long as possible at home. The originality comes from using the robot in the elderly person's home. This robot is remote controlled by a distant user, a therapist or a relative, for determining alarming situations or for participating in stimulation exercises. Several modes are available for controlling the robot. This paper deals with an assisted control mode in which the remote user gives to the robot one goal and the robot reaches the goal by itself. During the robot movement, the user can dynamically change the current goal. An important hypothesis is that the robot has no a priori knowledge of its environment at the beginning. The knowledge will increase with time and the planned trajectory will be refreshed at two levels: a local one - faster but not always sufficient - and a global one - slower but which always finds a path if one exists. The idea is to work only with local information, using the robot sensors, the operator keeping the high level control. To assure that control, the remote operator uses video feedback and information from a laser range scanner.",,10.1109/ICAR.2011.6088615,,,,Trajectory;Planning;Simultaneous localization and mapping;Navigation,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Bioinspired Environmental Coordination in Spatial Computing Systems,J. Werfel and Y. Bar-Yam and D. Ingber,,2008,IEEE Index Terms,338--343,,"Spatial computing systems are characterized by the extended physical environment in which they exist and function. Often this environment can be manipulated in various ways by the computing agents. We argue that it is important to consider the potential use of the environment for coordination and indirect communication in such systems. For inherently spatial problems, it can be more effective to store spatially relevant information in the environment rather than in the computing devices, as in the case of mobile agents or long-term physical structures. In scientific settings, considering the role of the environment can illuminate mechanisms or processes that might otherwise be overlooked; in engineering problems, it can provide simpler and more effective solutions than could be achieved by relying on the computing devices alone. We give as examples problems related to foraging, collective construction, simultaneous localization and mapping, object tracking, and behaviors of living tissues. We suggest in closing a classification scheme for capabilities of environmental elements, relevant to the design of physically embodied spatial computing systems.",,10.1109/SASOW.2008.15,,,,Physics computing;USA Councils;Biology computing;Chemical sensors;Biomedical engineering;Engineering in medicine and biology;Simultaneous localization and mapping;Distributed computing;Mobile robots;Computer networks;foraging;collective construction;SLAM;object tracking;tissues;stormones,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Integration of Monte Carlo Localization and place recognition for reliable long-term robot localization,J. Pérez and F. Caballero and L. Merino,,2014,IEEE Index Terms,85--91,,"This paper proposes extending Monte Carlo Localization methods with visual information in order to build a long term robot localization system. This system is aimed to work in crowded and non-planar scenarios, where 2D laser rangefinders may not always be enough to match the robot position with the map. Thus, visual place recognition will be used in order to obtain robot position clues that can be used to detect when the robot is lost and also to reset its positions to the right one. The paper presents experimental results based on datasets gathered with a real robot in challenging scenarios.",,10.1109/ICARSC.2014.6849767,,,,Robot sensing systems;Semiconductor lasers;Robot kinematics;Trajectory;Navigation,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Visual SLAM With Drift-Free Rotation Estimation in Manhattan World,J. Liu and Z. Meng,IEEE Robotics and Automation Letters,2020,IEEE Index Terms,6512--6519,5,"This letter presents an efficient and accurate simultaneous localization and mapping (SLAM) system in man-made environments. The Manhattan world assumption is imposed, with which the global orientation is obtained. The drift-free rotational motion estimation is derived from the structural regularities using line features. In particular, a two-stage vanishing points (VPs) estimation method is developed, which consists of a short-term tracking module to track the clustered line features and a long-term searching module to generate abundant sets of VPs candidates and retrieve the optimal one. A least square problem is constructed and solved to provide refined VPs with the clusters of structural line features every frame. We make full use of the absolute orientation estimation to benefit the whole SLAM process. In particular, we utilize the absolute orientation estimation to increase the localization accuracy in the front end, and formulate a linear batch camera pose refinement problem with the known rotations to improve the real time performance in the back end. Experiments on both synthesized and real-world scenes reveal results with high-precision in the real time camera pose estimation process and high-speed in pose graph optimization process compared with the existing state-of-the-art methods.",,10.1109/LRA.2020.3014648,,,,Cameras;Estimation;Simultaneous localization and mapping;Optimization;Feature extraction;Three-dimensional displays;Tracking;SLAM;localization;visual-based navigation,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Weighted Grid Partitioning for Panel-Based Bathymetric SLAM,J. Jang and J. Kim,,2019,IEEE Index Terms,1--6,,"Bathymetric navigation enables the long-term operation of autonomous underwater vehicles by reducing navigation drift errors with no need for GPS position fixes. In the case that a bathymetric map is not available, the simultaneous localization and mapping (SLAM) algorithm is required, but this increases computational complexity and memory requirement. Panel-based bathymetric SLAM could considerably reduce the computational burden. However, it may suffers from incorrect update when the vehicle does not belong to the updated panel. This study proposes a new update method, called weighted grid partitioning, which considers the probability distribution of a vehicle's location, and is more effective in terms of the map accuracy, computational burden, and memory usage compared to standard update methods. The feasibility of the proposed algorithm is verified through simulations.",,10.1109/OCEANSE.2019.8867531,,,,Simultaneous localization and mapping;Navigation;Probability distribution;Signal processing algorithms;Measurement uncertainty;Uncertainty;Predictive models,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Tightly-Coupled Magneto-Visual-Inertial Fusion for Long Term Localization in Indoor Environment,J. Coulin and R. Guillemard and V. Gay-Bellile and C. Joly and A. D. L. Fortelle,IEEE Robotics and Automation Letters,2022,IEEE Index Terms,952--959,7,"We propose in this letter a tightly-coupled fusion of visual, inertial and magnetic data for long-term localization in indoor environment. Unlike state-of-the-art Visual-Inertial SLAM (VISLAM) solutions that reuse visual map to prevent drift, we present in this letter an extension of the Multi-State Constraint Kalman Filter (MSCKF) that takes advantage of a magnetic map. It makes our solution more robust to variations of the environment appearance. The experimental results demonstrate that the localization accuracy of the proposed approach is almost the same over time periods longer than a year.",,10.1109/LRA.2021.3136241,,,,Bibliographies;Uniform resource locators;Standards;Databases;Documentation;Codes;Patents;Localization;sensor fusion;visual-inertial SLAM;indoor magnetic field;MSCKF,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Direct RGB-D Visual Odometry Based on Hybrid Strategy,J. Cai and L. Luo and Q. Yu and B. Liu and S. Hu,IEEE Sensors Journal,2021,IEEE Index Terms,23278--23288,21,"Edge-based Direct Visual Odometry (E-DVO) plays a crucial role in robot navigation across the low-texture and rich-texture scenes, however, two essential factors are overlooked in the traditional E-DVO methods. (1) Traditional E-DVO methods seriously rely on photometric or geometric cost, thereby generating the non-robust performance under the light changing or structure-less conditions; (2) EDVO methods generally suffer drift issue mainly derived from inaccurate rotation estimation for the long term visual odometry task. In this article, a novel hybrid cost function leveraging the photometric and geometric cost within a bi-direction framework is proposed to facilitate the addressed the former issue. While the latter issue is approached through hybridization of a simple yet effective switching strategy which can guarantee both robustness and accuracy by combining the global Manhattan model and direct edge alignment. We carry out various experiments on TUM RGB-D and ICL-NUIM datasets for performance evaluation. Results show that our method has the advantage of strong robustness and high accuracy compared with state-of-the-art methods, e.g., Canny-VO and ORB-SLAM2.",,10.1109/JSEN.2021.3109413,,,,Visual odometry;Estimation;Image edge detection;Feature extraction;Sensors;Cost function;Robustness;Visual odometry (VO);RGB-D camera;edge feature;global Manhattan model,,1558-1748,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Robust vision-aided navigation using Sliding-Window Factor graphs,H.-P. Chiu and S. Williams and F. Dellaert and S. Samarasekera and R. Kumar,,2013,IEEE Index Terms,46--53,,"This paper proposes a navigation algorithm that provides a low-latency solution while estimating the full nonlinear navigation state. Our approach uses Sliding-Window Factor Graphs, which extend existing incremental smoothing methods to operate on the subset of measurements and states that exist inside a sliding time window. We split the estimation into a fast short-term smoother, a slower but fully global smoother, and a shared map of 3D landmarks. A novel three-stage visual feature model is presented that takes advantage of both smoothers to optimize the 3D landmark map, while minimizing the computation required for processing tracked features in the short-term smoother. This three-stage model is formulated based on the maturity of the estimation of the 3D location of the underlying landmark in the map. Long-range associations are used as global measurements from matured landmarks in the short-term smoother and loop closure constraints in the long-term smoother. Experimental results demonstrate our approach provides highly-accurate solutions on large-scale real data sets using multiple sensors in GPS-denied settings.",,10.1109/ICRA.2013.6630555,,,,Three-dimensional displays;Navigation;Smoothing methods;Estimation;Sensors;Solid modeling;Current measurement,,1050-4729,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Radar-on-Lidar: metric radar localization on prior lidar maps,H. Yin and Y. Wang and L. Tang and R. Xiong,,2020,IEEE Index Terms,1--7,,"Radar and lidar, provided by two different range sensors, each has pros and cons of various perception tasks on mobile robots or autonomous driving. In this paper, a Monte Carlo system is used to localize the robot with a rotating radar sensor on 2D lidar maps. We first train a conditional generative adversarial network to transfer raw radar data to lidar data, and achieve reliable radar points from generator. Then an efficient radar odometry is included in the Monte Carlo system. Combining the initial guess from odometry, a measurement model is proposed to match the radar data and prior lidar maps for final 2D positioning. We demonstrate the effectiveness of the proposed localization framework on the public multisession dataset. The experimental results show that our system can achieve high accuracy for long-term localization in outdoor scenes.",,10.1109/RCAR49640.2020.9303291,,,,Laser radar;Radar;Sensors;Radar imaging;Robots;Three-dimensional displays;Two dimensional displays,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Incorporating environmental measurements in navigation,H. J. S. Feder and J. J. Leonard and C. M. Smith,,1998,IEEE Index Terms,115--122,,"Extended missions in unknown regions present a significant navigational challenge for autonomous underwater vehicles (AUV). This paper investigates the long-term performance of a concurrent mapping and localization (CML) algorithm for the scenario of an AUV making observations of point features in the environment with a forward look sonar. Simulation results demonstrate that position estimates with long-term bounded errors of a few meters can be achieved under realistic assumptions about the vehicle, its sensors, and the environment. Potential failure modes of the algorithm, such as divergence and map slip, are discussed. CML technology can provide a significant improvement in the navigational capabilities of AUVs and can enable new missions in unmapped regions without reliance on acoustic beacons or surfacing for GPS resets.",,10.1109/AUV.1998.744447,,,,Sonar navigation;Remotely operated vehicles;Underwater acoustics;Performance analysis;Stochastic processes;Sea measurements;Jacobian matrices;Oceans;Automotive engineering;Marine technology,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Visual topometric localization,H. Badino and D. Huber and T. Kanade,,2011,IEEE Index Terms,794--799,,"One of the fundamental requirements of an autonomous vehicle is the ability to determine its location on a map. Frequently, solutions to this localization problem rely on GPS information or use expensive three dimensional (3D) sensors. In this paper, we describe a method for long-term vehicle localization based on visual features alone. Our approach utilizes a combination of topological and metric mapping, which we call topometric localization, to encode the coarse topology of the route as well as detailed metric information required for accurate localization. A topometric map is created by driving the route once and recording a database of visual features. The vehicle then localizes by matching features to this database at runtime. Since individual feature matches are unreliable, we employ a discrete Bayes filter to estimate the most likely vehicle position using evidence from a sequence of images along the route. We illustrate the approach using an 8.8 km route through an urban and suburban environment. The method achieves an average localization error of 2.7 m over this route, with isolated worst case errors on the order of 10 m.",,10.1109/IVS.2011.5940504,,,,Vehicles;Visualization;Measurement;Databases;Feature extraction;Global Positioning System;Probability density function,,1931-0587,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Towards life-long mapping of dynamic environments using temporal persistence modeling,G. Tsamis and I. Kostavelis and D. Giakoumis and D. Tzovaras,,2021,IEEE Index Terms,10480--10485,,"The contemporary SLAM mapping systems assume a static environment and build a map that is then used for mobile robot navigation disregarding the dynamic changes in this environment. The paper at hand presents a novel solution for the problem of life-long mapping that continually updates a metric map represented as a 2D occupancy grid in large scale indoor environments with movable objects such as people, robots, objects etc. suitable for industrial applications. We formalize each cell's occupancy as a failure analysis problem and contribute temporal persistence modeling (TPM), an algorithm for probabilistic prediction of the time that a cell in an observed location is expected to be “occupied” or “empty” given sparse prior observations from a task specific mobile robot. Our work is evaluated in Gazebo simulation environment against the nominal occupancy of cells and the estimated obstacles persistence. We also show that robot navigation with life-long mapping demands less replans and leads to more efficient navigation in highly dynamic environments.",,10.1109/ICPR48806.2021.9413161,,,,Measurement;Simultaneous localization and mapping;Navigation;Service robots;Predictive models;Probabilistic logic;Prediction algorithms,,1051-4651,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Hierarchical Loop Closure Detection for Long-term Visual SLAM with Semantic-Geometric Descriptors,G. Singh and M. Wu and S. Lam and D. V. Minh,,2021,IEEE Index Terms,2909--2916,,"Modern visual Simultaneous Localization and Mapping (SLAM) systems rely on loop closure detection methods for correcting drifts in maps and poses. Existing loop closure detection methods mainly employ conventional feature descriptors to create vocabulary for describing places using bag-of-words (BOW). Such methods do not perform well in long-term SLAM applications as the scene content may change over time due to the presence of dynamic objects, even though the locations are revisited with the same viewpoint. This work enhances the loop closure detection capability of long-term visual SLAM by reducing the number of false matches through the use of location semantics. We extend a semantic visual SLAM framework to build compact global semantic-geometric location descriptors and local semantic vocabulary trees, by leveraging on the already available features and semantics. The local semantic vocabulary trees support incremental vocabulary learning, which is well-suited for long-term SLAM scenarios where the scenes encountered are not known beforehand. A novel hierarchical place recognition method that leverages the global and local location semantics is proposed to enable fast and accurate loop closure detection. The proposed method outperforms recent state-of-the-art methods (i.e., FABMAP2, SeqSLAM, iBOW-LCD, and HTMap) on all datasets considered (i.e., KITTI, Synthia, and CBD), with highest loop closure detection accuracy and lowest query time.",,10.1109/ITSC48978.2021.9564866,,,,Measurement;Location awareness;Vocabulary;Visualization;Simultaneous localization and mapping;Conferences;Semantics,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Lightweight SLAM with automatic orientation correction using 2D LiDAR scans,G. Péter and B. Kiss,,2020,IEEE Index Terms,1--6,,"Simultaneous localization and mapping (SLAM) is about consistent maps in the long run. Loop closing is the most popular way for ensure long-term consistency in presence of multiple measurements by the same or multiple robots. Loop closure can be executed using raw odometrical data, but a more sophisticated, yet still light-weight method is presented in this paper: a landmark descriptor-based relative displacement calculation method for diminishing unwanted orientation errors that otherwise often lead to map inconsistency. Landmark descriptors are created using light detection and ranging (LiDAR) scans and the relation is calculated using scan-matching. The novelty of this research is a method providing long-term orientation and position correction without additional overhead between landmark detections, thus enabling simple agents to do the SLAM in a cooperative way.",,10.1109/ISMCR51255.2020.9263722,,,,Manganese;SLAM;LiDAR;mapping;orientation;correction;uncertainty,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Deep Visual Odometry With Adaptive Memory,F. Xue and X. Wang and J. Wang and H. Zha,IEEE Transactions on Pattern Analysis and Machine Intelligence,2022,IEEE Index Terms,940--954,44,"We propose a novel deep visual odometry (VO) method that considers global information by selecting memory and refining poses. Existing learning-based methods take the VO task as a pure tracking problem via recovering camera poses from image snippets, leading to severe error accumulation. Global information is crucial for alleviating accumulated errors. However, it is challenging to effectively preserve such information for end-to-end systems. To deal with this challenge, we design an adaptive memory module, which progressively and adaptively saves the information from local to global in a neural analogue of memory, enabling our system to process long-term dependency. Benefiting from global information in the memory, previous results are further refined by an additional refining module. With the guidance of previous outputs, we adopt a spatial-temporal attention to select features for each view based on the co-visibility in feature domain. Specifically, our architecture consisting of Tracking, Remembering and Refining modules works beyond tracking. Experiments on the KITTI and TUM-RGBD datasets demonstrate that our approach outperforms state-of-the-art methods by large margins and produces competitive results against classic approaches in regular scenes. Moreover, our model achieves outstanding performance in challenging scenarios such as texture-less regions and abrupt motions, where classic algorithms tend to fail.",,10.1109/TPAMI.2020.3014100,,,,Cameras;Task analysis;Tracking;Simultaneous localization and mapping;Pose estimation;History;Visual odometry;recurrent neural networks;memory;attention,,1939-3539,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Learning of Holism-Landmark Graph Embedding for Place Recognition in Long-Term Autonomy,F. Han and S. E. Beleidy and H. Wang and C. Ye and H. Zhang,IEEE Robotics and Automation Letters,2018,IEEE Index Terms,3669--3676,3,"Place recognition plays an important role to perform loop closure detection of large-scale, long-term simultaneous localization and mapping in loopy environments. The long-term place recognition problem is challenging because the environment appearance exhibits significant long-term variations across various times of the day, months, and seasons. In this letter, we introduce a novel place representation approach that simultaneously integrates semantic landmarks and holistic information to achieve place recognition in long-term autonomy. First, a graph is constructed for each place. The graph nodes encode all landmarks and the holistic image of the place scene recorded in different scenarios. The edges connecting the nodes indicate that these nodes represent the same landmark or place, even though places and landmarks encoded by the nodes may exhibit different appearances in the long-term periods. Then, a graph embedding is learned to preserve the locality in the feature descriptor space, i.e., finding a projection such that the same landmark and place have the identical representation in the new projected descriptor space, no matter in what scenarios they are recorded. We formulate the embedding learning as an optimization problem and implement a new solver that provides a theoretical convergence guarantee. Extensive evaluations are conducted using large-scale benchmark datasets of place recognition in long-term autonomy, which has shown our approach's promising performance.",,10.1109/LRA.2018.2856274,,,,Semantics;Simultaneous localization and mapping;Robustness;Image edge detection;Optimization;Convergence;Visual learning;recognition;SLAM;localization,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Season-Invariant and Viewpoint-Tolerant LiDAR Place Recognition in GPS-Denied Environments,F. Cao and F. Yan and S. Wang and Y. Zhuang and W. Wang,IEEE Transactions on Industrial Electronics,2021,IEEE Index Terms,563--574,68,"Place recognition remains a challenging problem under various perceptual conditions, e.g., all weather, times of day, seasons, and viewpoint shifts. Different from most of the existing place recognition methods using pure vision, this article studies light detection and ranging (LiDAR) based approaches. Point clouds have some benefits for place recognition since they do not suffer from illumination changes. On the other hand, they are dramatically affected by structural changes from different viewpoints or across seasons. In this article, a novel LiDAR-based place recognition system is proposed to achieve long-term robust localization, even under severe seasonal changes and viewpoint shifts. To improve the efficiency, a compact cylindrical image model is designed to convert three-dimensional point clouds to two-dimensional images representing the prominent geometric relationships of scenes. The contexts (buildings, trees, road structures, etc.) of scenes are utilized for efficient place recognition. A sequence-based temporal consistency check is also introduced for postverification. Extensive real experiments on three datasets (Oxford RobotCar [1], NCLT [2], and DUT-AS) show that the proposed system outperforms both state-of-the-art visual and LiDAR-based methods, verifying its robust performance in challenging scenarios.",,10.1109/TIE.2019.2962416,,,,Three-dimensional displays;Laser radar;Visualization;Buildings;Lighting;Deep learning;Two dimensional displays;Across season;light detection and ranging (LiDAR) sensors;long-term localization;mobile robots;place recognition,,1557-9948,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Using Image Sequences for Long-Term Visual Localization,E. Stenborg and T. Sattler and L. Hammarstrand,,2020,IEEE Index Terms,938--948,,"Estimating the pose of a camera in a known scene, i.e., visual localization, is a core task for applications such as self-driving cars. In many scenarios, image sequences are available and existing work on combining single-image localization with odometry offers to unlock their potential for improving localization performance. Still, the largest part of the literature focuses on single-image localization and ignores the availability of sequence data. The goal of this paper is to demonstrate the potential of image sequences in challenging scenarios, e.g., under day-night or seasonal changes. Combining ideas from the literature, we describe a sequence-based localization pipeline that combines odometry with both a coarse and a fine localization module. Experiments on long-term localization datasets show that combining single-image global localization against a prebuilt map with a visual odometry/SLAM pipeline improves performance to a level where the extended CMU Seasons dataset can be considered solved. We show that SIFT features can perform on par with modern state-of-the-art features in our framework, despite being much weaker and a magnitude faster to compute. Our code is publicly available at github.com/rulllars.",,10.1109/3DV50981.2020.00104,,,,Location awareness;Visualization;Three-dimensional displays;Cameras;Trajectory;Simultaneous localization and mapping;Pose estimation,,2475-7888,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Generic 2D/3D SLAM with NDT maps for lifelong application,E. Einhorn and H.-M. Gross,,2013,IEEE Index Terms,240--247,,"In this paper, we present a new, generic approach for Simultaneous Localization and Mapping (SLAM). First of all, we propose an abstraction of the underlying sensor data using Normal Distribution Transform (NDT) maps that are suitable for making our approach independent from the used sensor and the dimension of the generated maps. We present some modifications for the original NDT mapping to handle free-space measurements explicitly and to enable its usage in dynamic environments with moving obstacles and persons. In the second part of this paper we describe our graph-based SLAM approach that is designed for lifelong usage. Therefore, the memory and computational complexity is limited by pruning the pose graph in an appropriate way.",,10.1109/ECMR.2013.6698849,,,,Simultaneous localization and mapping;Gaussian distribution;Three-dimensional displays;Computer architecture;Microprocessors,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Optical flow localisation and appearance mapping (OFLAAM) for long-term navigation,D. Pastor-Moreno and H.-S. Shin and A. Waldock,,2015,IEEE Index Terms,980--988,,"This paper presents a novel method to use optical flow navigation for long term navigation. Unlike standard SLAM approaches for augmented reality, OFLAAM is designed for Micro Air Vehicles (MAV). It uses a optical flow camera pointing downwards, a IMU and a monocular camera pointing frontwards. That configuration avoids the computational expensive mapping and tracking of the 3D features. It only maps these features in a vocabulary list by a localization module to tackle the optical flow drift and the lose of the navigation estimation. That module, based on the well established algorithm DBoW2, will be also used to close the loop and allow long-term navigation in previously visited areas. The combination of high speed optical flow navigation with a low rate localization algorithm allows fully autonomous navigation for MAV, at the same time it reduces the overall computational load. This framework is implemented in ROS (Robot Operating System) and tested attached to a laptop. A representative scenario is used to validate and analyze the performance of the system.",,10.1109/ICUAS.2015.7152387,,,,Cameras;Optical sensors;Optical imaging;Computers;Vehicles;Adaptive optics;High-speed optical techniques,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Towards lifelong feature-based mapping in semi-static environments,D. M. Rosen and J. Mason and J. J. Leonard,,2016,IEEE Index Terms,1063--1070,,"The feature-based graphical approach to robotic mapping provides a representationally rich and computationally efficient framework for an autonomous agent to learn a model of its environment. However, this formulation does not naturally support long-term autonomy because it lacks a notion of environmental change; in reality, “everything changes and nothing stands still, ” and any mapping and localization system that aims to support truly persistent autonomy must be similarly adaptive. To that end, in this paper we propose a novel feature-based model of environmental evolution over time. Our approach is based upon the development of an expressive probabilistic generative feature persistence model that describes the survival of abstract semi-static environmental features over time. We show that this model admits a recursive Bayesian estimator, the persistence filter, that provides an exact online method for computing, at each moment in time, an explicit Bayesian belief over the persistence of each feature in the environment. By incorporating this feature persistence estimation into current state-of-the-art graphical mapping techniques, we obtain a flexible, computationally efficient, and information-theoretically rigorous framework for lifelong environmental modeling in an ever-changing world.",,10.1109/ICRA.2016.7487237,,,,Feature extraction;Detectors;Computational modeling;Adaptation models;Simultaneous localization and mapping;Bayes methods,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Development of an Autonomous Robotic System Using the Graph-based SPLAM Algorithm,D. Kozlov and V. Myasnikov,,2021,IEEE Index Terms,1--5,,"For long-term planning, localization and mapping, the robot must constantly update the map by the changing environment and new areas that the robot is exploring. At the same time, this map should not take up too much of the robot’s memory, since the robot’s performance is limited due to the small size of the robot and increased performance requirements. The robot must interact with the map on time, updating its location to build a further route to explore areas that have not been visited. In addition to compiling a map, when solving the problem of exploration rooms, the following steps are also important: forming a plan for bypassing an unknown room, calculating the trajectory, resolving collisions with obstacles, and following the trajectory. In the course of this work, an autonomous robotic system was developed, the task of which is to map previously unknown premises. For this, SPLAM algorithms, algorithms for building map and working with graphs, algorithms for following a trajectory were used.",,10.1109/ITNT52450.2021.9649028,,,,Measurement;Space vehicles;Memory management;Robot vision systems;Production;Real-time systems;Trajectory;SPLAM;SLAM;robot;ROS;RTABMap;Voronoi diagram;bang-bang controller;Jetson;Zed;point cloud;odometry;Dijkstra algorithm,,,,,,44698.62163,44698.62377,sousarbarb,,Duplicated,
,Part-based SLAM for partially changing environments,C. Yuuto and T. Kanji and A. Masatoshi,,2013,IEEE Index Terms,1629--1634,,"We consider the task of long-term visual SLAM, i.e., simultaneous localization and mapping, in a partially changing environment (SLAM-PCE). The main problem we face is how to obtain discriminative and compact visual landmarks, which are necessary to cope with changes in appearance in an environment and with a large amount of visual information. We address this issue by proposing the use of common object patterns, which are inherent in typical environments (e.g., indoor, street, forests, suburban, etc.), as visual landmarks for a SLAM-PCE task. In our contributions, we describe our approach, “part-based SLAM”, and validate its effectiveness within a standard problem of view image retrieval. The main novelty of this approach lies in that the common landmark objects are extracted in an unsupervised manner via common pattern discovery, and can be used for compact characterization and efficient retrieval of view images. Our method is also innovative in its use of traditional bounding box-based part annotation: an image is represented in a compact form, “bag-of-bounding-boxes (BoBB)” and then, the scene matching can be solved efficiently as a low dimensional problem of matching bounding boxes. The results of challenging experiments show that it is possible to have high retrieval performance with compact image representation with only 16 words per image.",,10.1109/ROBIO.2013.6739700,,,,Visualization;Simultaneous localization and mapping;Libraries;Computational modeling;Databases;Dictionaries,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A DenseNet feature-based loop closure method for visual SLAM system,C. Yu and Z. Liu and X.-J. Liu and F. Qiao and Y. Wang and F. Xie and Q. Wei and Y. Yang,,2019,IEEE Index Terms,258--265,,"Loop closure is a crucial part in SLAM, especially for large and long-term scenes. Utilizing off-the-shelf networks’ features in loop closure becomes a hot spot. However, what kind of network is more suitable in loop closure and how to use their features have not been well-studied. In this paper, DenseNet is introduced in this field according to its own characters. The features of DenseNet preserve both semantic information and structure details and outweigh other popular networks’ features significantly. Based on this, a DenseNet feature-based framework, named Dense-Loop, is proposed to address the loop closure problem. Weighted Vector of Locally Aggregated Descriptor (WVLAD) method is used to encode the local descriptors as the final global descriptor, which could resist geometry structure and viewpoint changes. Furthermore, 4 max-pooling by channel and locality-sensitive hashing (LSH) are adopted to accelerate the search process. Extensive experiments are conducted on public datasets and the results demonstrate Dense-Loop could achieve state-of-the-art performance.",,10.1109/ROBIO49542.2019.8961714,,,,Training;Visualization;Simultaneous localization and mapping;Semantics;Lighting;Resists;Feature extraction;Convolutional Neural Network;loop closure;DenseNet;SLAM,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Robust Method for Static 3D Point Cloud Map Building using Multi-View Images with Multi-Resolution,C. Yao and H. Zhu and S. Lv and D. Zhang and Z. Jia,,2021,IEEE Index Terms,782--787,,"Robots can perform various missions in multiple changing environments. The dynamic objects have significant influence on the long-term autonomy and 3D map construction, because “ghost tracks” inevitably exist due to the continuous error-accumulation of the input data. So it is critical to keep only static subsets and exclude noisy obstacles to mitigate the influence on mapping and navigation. We propose a robust static map building method, which compares the discrepancies between single scan data against the noisy map. This method focuses on the advantages of most dynamic objects of different views with unique attribution and will be easily detected in these views. Accordingly, we present the novel “Multi-View and Multi-Resolution” image-based method with BEV-RV (Bird's Eye View-Range View) modules to discriminate static/dynamic point clouds. Through two stages of iteration with different image window sizes of point level, we first collect more static points of some inevitably wrong judgments and then remove such completely unreliable dynamic points at a later stage. Experimental evaluations are conducted by using the KITTI dataset as ground truth. Qualitative analysis indicates that the proposed method is robust and reliable against state-of-the-art methodsin some dynamic regions.",,10.1109/RCAR52367.2021.9517646,,,,Three-dimensional displays;Navigation;Heuristic algorithms;Buildings;Object detection;Real-time systems;Windows,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Learning by Inertia: Self-supervised Monocular Visual Odometry for Road Vehicles,C. Wang and Y. Yuan and Q. Wang,,2019,IEEE Index Terms,2252--2256,,"In this paper, we present iDVO (inertia-embedded deep visual odometry), a self-supervised learning based monocular visual odometry (VO) for road vehicles. When modelling the geometric consistency within adjacent frames, most deep VO methods ignore the temporal continuity of the camera pose, which results in a very severe jagged fluctuation in the velocity curves. With the observation that road vehicles tend to perform smooth dynamic characteristics in most of the time, we design the inertia loss function to describe the abnormal motion variation, which assists the model to learn the consecutiveness from long-term camera ego-motion. Based on the recurrent convolutional neural network (RCNN) architecture, our method implicitly models the dynamics of road vehicles and the temporal consecutiveness by the extended Long Short-Term Memory (LSTM) block. Furthermore, we develop the dynamic hard-edge mask to handle the non-consistency in fast camera motion by blocking the boundary part and which generates more efficiency in the whole non-consistency mask. The proposed method is evaluated on the KITTI dataset, and the results demonstrate state-of-the-art performance with respect to other monocular deep VO and SLAM approaches.",,10.1109/ICASSP.2019.8683446,,,,Inertia;Self-supervised Learning;Visual Odometry;RCNN,,2379-190X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Long-Term 3D Localization and Pose from Semantic Labellings,C. Toft and C. Olsson and F. Kahl,,2017,IEEE Index Terms,650--659,,"One of the major challenges in camera pose estimation and 3D localization is identifying features that are approximately invariant across seasons and in different weather and lighting conditions. In this paper, we present a method for performing accurate and robust six degrees-of-freedom camera pose estimation based only on the pixelwise semantic labelling of a single query image. Localization is performed using a sparse 3D model consisting of semantically labelled points and curves, and an error function based on how well these project onto corresponding curves in the query image is developed. The method is evaluated on the recently released Oxford Robotcar dataset, showing that by minimizing this error function, the pose can be recovered with decimeter accuracy in many cases.",,10.1109/ICCVW.2017.83,,,,Three-dimensional displays;Semantics;Solid modeling;Roads;Cameras;Labeling;Meteorology,,2473-9944,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Robust Photogeometric Localization Over Time for Map-Centric Loop Closure,C. Park and S. Kim and P. Moghadam and J. Guo and S. Sridharan and C. Fookes,IEEE Robotics and Automation Letters,2019,IEEE Index Terms,1768--1775,4,"Map-centric Simultaneous Localization And Mapping (SLAM) is emerging as an alternative of conventional graph-based SLAM for its accuracy and efficiency in long-term mapping problems. However, in map-centric SLAM, the process of loop closure differs from that of conventional SLAM and the result of incorrect loop closure is more destructive and is not reversible. In this letter, we present a tightly coupled photogeometric metric localization for the loop closure problem in map-centric SLAM. In particular, our method combines complementary constraints from LiDAR and camera sensors, and validates loop closure candidates with sequential observations. The proposed method provides a visual evidence-based outlier rejection where failures caused by either place recognition or localization outliers can be effectively removed. We demonstrate that the proposed method is not only more accurate than the conventional global ICP methods but is also robust to incorrect initial pose guesses.",,10.1109/LRA.2019.2895262,,,,Trajectory;Uncertainty;Visualization;Laser radar;Simultaneous localization and mapping;Cameras;Measurement;Loop closure;SLAM;sensor fusion;metric localization;mapping,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,"Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age",C. Cadena and L. Carlone and H. Carrillo and Y. Latif and D. Scaramuzza and J. Neira and I. Reid and J. J. Leonard,IEEE Transactions on Robotics,2016,IEEE Index Terms,1309--1332,32,"Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors' take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?",,10.1109/TRO.2016.2624754,,,,Graph theory;Simultaneous location and mapping;Service robots;Robustness;Localization;Factor graphs;localization;mapping;maximum a posteriori estimation;perception;robots;sensing;simultaneous localization and mapping (SLAM),,1941-0468,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,SolarSLAM: Battery-free Loop Closure for Indoor Localisation,B. Wei and W. Xu and C. Luo and G. Zoppi and D. Ma and S. Wang,,2020,IEEE Index Terms,4485--4490,,"In this paper, we propose SolarSLAM, a batteryfree loop closure method for indoor localisation. Inertial Measurement Unit (IMU) based indoor localisation method has been widely used due to its ubiquity in mobile devices, such as mobile phones, smartwatches and wearable bands. However, it suffers from the unavoidable long term drift. To mitigate the localisation error, many loop closure solutions have been proposed using sophisticated sensors, such as cameras, laser, etc. Despite achieving high-precision localisation performance, these sensors consume a huge amount of energy. Different from those solutions, the proposed SolarSLAM takes advantage of an energy harvesting solar cell as a sensor and achieves effective battery-free loop closure method. The proposed method suggests the key-point dynamic time warping for detecting loops and uses robust simultaneous localisation and mapping (SLAM) as the optimiser to remove falsely recognised loop closures. Extensive evaluations in the real environments have been conducted to demonstrate the advantageous photocurrent characteristics for indoor localisation and good localisation accuracy of the proposed method.",,10.1109/IROS45743.2020.9340962,,,,Performance evaluation;Simultaneous localization and mapping;Photovoltaic cells;Sensor phenomena and characterization;Mobile handsets;Sensor systems;Photoconductivity;Indoor localisation;SLAM;Solar cell,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A Flexible and Efficient Loop Closure Detection Based on Motion Knowledge,B. Liu and F. Tang and Y. Fu and Y. Yang and Y. Wu,,2021,IEEE Index Terms,11241--11247,,"Loop closure detection (LCD) is an essential module for simultaneous localization and mapping (SLAM), which can correct accumulated errors after long-term explorations. The widely used bag-of-words (BoW) model can not satisfy well the requirements of both low time consumption and high accuracy for a mobile platform. In this paper, we propose a novel LCD algorithm based on motion knowledge. We give a flexible and efficient detection strategy and also give flexible and efficient combinations of a global binary feature extracted by convolutional neural network (CNN) and a hand-crafted local binary feature. We take a continuous motion model, grid-based motion statistics (GMS) and motion states as motion knowledge. Furthermore, we fuse the proposed LCD with a visual-inertial odometry (VIO) system to correct localization errors by a pose graph optimization. Comparative experiments with state-of-the-art LCD algorithms on typical datasets have been carried out, and the results demonstrate that our proposed method achieves quite high recall rates and quite high speed at 100% precision. Moreover, experimental results from VIO further validate the effectiveness of the proposed method.",,10.1109/ICRA48506.2021.9561126,,,,Location awareness;Simultaneous localization and mapping;Automation;Fuses;Conferences;Feature extraction;Liquid crystal displays,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Multi-layer VI-GNSS Global Positioning Framework with Numerical Solution aided MAP Initialization,B. Han and Z. Xiao and S. Huang and T. Zhang,,2021,IEEE Index Terms,5448--5455,,"Motivated by the goal of achieving long-term drift-free camera pose estimation in complex scenarios, we propose a global positioning framework fusing visual, inertial and Global Navigation Satellite System (GNSS) measurements in multiple layers. Different from previous loosely- and tightly-coupled methods, the proposed multi-layer fusion allows us to delicately correct the drift of visual odometry and keep reliable positioning while GNSS degrades. In particular, local motion estimation is conducted in the inner-layer, solving the problem of scale drift and inaccurate bias estimation in visual odometry by fusing the velocity of GNSS, pre-integration of Inertial Measurement Unit (IMU) and camera measurement in a tightly-coupled way. The global localization is achieved in the outer-layer, where the local motion is further fused with GNSS position and course in a long-term period in a loosely-coupled way. Furthermore, a dedicated initialization method is proposed to guarantee fast and accurate estimation for all state variables and parameters. We give exhaustive tests of the proposed framework on indoor and outdoor public datasets. The mean localization error is reduced up to 63%, with a promotion of 69% in initialization accuracy compared with state-of-the-art works. We have applied the algorithm to Augmented Reality (AR) navigation, crowd sourcing high-precision map update and other large-scale applications.",,10.1109/IROS51168.2021.9636871,,,,Location awareness;Global navigation satellite system;Visualization;Atmospheric measurements;Particle measurements;Cameras;Real-time systems,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Improving Visual SLAM in Car-Navigated Urban Environments with Appearance Maps,A. Jaenal and D. Zuñiga-Nöel and R. Gomez-Ojeda and J. Gonzalez-Jimenez,,2020,IEEE Index Terms,4679--4685,,"This paper describes a method that corrects errors of a VSLAM-estimated trajectory for cars driving in GPS-denied environments, by applying constraints from public databases of geo-tagged images (Google Street View, Mapillary, etc). The method, dubbed Appearance-based Geo-Alignment for Simultaneous Localisation and Mapping (AGA-SLAM), encodes the available image database as an appearance map, which represents the space with a compact holistic descriptor for each image plus its associated geo-tag. The VSLAM trajectory is corrected on-line by incorporating constraints from the recognized places along the trajectory into a position-based optimization framework. The paper presents a seamless formulation to combine local and absolute metric observations with associations from Visual Place Recognition. The robustness of the holistic image descriptor to changes due to weather or illumination variations ensures a long-term consistent method to improve car localization. The proposed method has been extensively evaluated on more than 70 sequences from 4 different datasets, proving out its effectiveness and endurance to appearance challenges.",,10.1109/IROS45743.2020.9341451,,,,Measurement;Visualization;Image databases;Visual systems;Trajectory;Internet;Automobiles,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,FAB-MAP + RatSLAM: Appearance-based SLAM for multiple times of day,A. J. Glover and W. P. Maddern and M. J. Milford and G. F. Wyeth,,2010,IEEE Index Terms,3507--3512,,"Appearance-based mapping and localisation is especially challenging when separate processes of mapping and localisation occur at different times of day. The problem is exacerbated in the outdoors where continuous change in sun angle can drastically affect the appearance of a scene. We confront this challenge by fusing the probabilistic local feature based data association method of FAB-MAP with the pose cell filtering and experience mapping of RatSLAM. We evaluate the effectiveness of our amalgamation of methods using five datasets captured throughout the day from a single camera driven through a network of suburban streets. We show further results when the streets are re-visited three weeks later, and draw conclusions on the value of the system for lifelong mapping.",,10.1109/ROBOT.2010.5509547,,,,Simultaneous localization and mapping;Layout;Cameras;Lighting;Filtering;Robustness;Probability;Sun;Robotics and automation;USA Councils,,1050-4729,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Using UHF-RFID Signals for Robot Localization Inside Pipelines,A. Gunatilake and M. Galea and K. Thiyagarajan and S. Kodagoda and L. Piyathilaka and P. Darji,,2021,IEEE Index Terms,1109--1114,,"Underground water pipes are important to any country's infrastructure. Overtime, the metallic pipes are prone to corrosion, which can lead to water leakage and pipe bursts. In order to prolong the service life of those assets, water utilities in Australia apply protective pipe linings. Long-term monitoring and timely intervention are crucial for maintaining those lining assets. However, the water utilities do not possess the comprehensive technology to achieve it. The main reasons for lacking such technology are the unavailability of sensors and accurate robot localization technologies. Feature based localization methods such as SLAM has limited use as the application of liners alters the features and the environment. Encoder based localization is not accurate enough to observe the evolution of defects over a long period of time requiring unique defect correspondence. This motivates us to explore accurate contact-less and wireless based localization methods. We propose a cost-effective localization method using UHF-RFID signals for robot localization inside pipelines based on Gaussian process combined particle filter. Experiments carried out in field extracted pipe samples from the Sydney water pipe network show that using the RSSI and Phase data together in the measurement model with particle filter algorithm improves the localization accuracy up to 15 centimeters precision.",,10.1109/ICIEA51954.2021.9516284,,,,Location awareness;Wireless communication;Wireless sensor networks;Simultaneous localization and mapping;Phase measurement;Service robots;Pipelines;infrastructure robotics;linings;localization;particle filter;pipes;robotics for smart cities;RFID;robotic inspections;UHF-RFID,,2158-2297,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A hybrid topological mapping and navigation method for large area robot mapping,A. A. Ravankar and A. Ravankar and T. Emaru and Y. Kobayashi,,2017,IEEE Index Terms,1104--1107,,"In this paper, we present a hybrid topological mapping and navigation method for mobile robots. The proposed method combines metric and topological information to create map and generate navigation plan for the robot. As compared to traditional approaches of robot mapping, the method is lightweight and can be used for mapping and navigation in large areas which is particularly useful for service robots operating in large buildings. The method only uses local information for navigation while maintaining the global topological graph nodes. The topological nodes are used effectively for navigation and can also be used to store semantic information of the scene such as robot poses, scans and scene properties for complete long term robot autonomy. By combining the information from the two maps (topological and grid map), autonomous navigation and mapping in large areas for robots is possible.",,10.23919/SICE.2017.8105770,,,,Navigation;Measurement;Simultaneous localization and mapping;Mobile robots;Robot Mapping;Topological Mapping;Navigation;Graph Theory;SLAM;Mobile Robot,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Pole-like Objects Mapping and Long-Term Robot Localization in Dynamic Urban Scenarios,Z. Wang and S. Li and M. Cao and H. Chen and Y. Liu,,2021,IEEE Title,998--1003,,"Localization on 3D data is a challenging task for unmanned vehicles, especially in long-term dynamic urban scenarios. Due to the generality and long-term stability, the pole-like objects are very suitable as landmarks for unmanned vehicle localization in time-varying scenarios. In this paper, a long-term LiDAR-only localization algorithm based on semantic cluster map is proposed. At first, the Convolutional Neural Network(CNN) is used to infer the semantics of LiDAR point clouds. Combined with the point cloud segmentation, the static objects pole/trunk are extracted and registered into global semantic cluster map. When the unmanned vehicle re-enters the environment again, the relocalization is completed by matching the clusters of current scan with the clusters of the global map. Furthermore, the matching between the local and global maps stably outputs the global pose at 2Hz to correct the drift of the 3D LiDAR odometry. The experimental results on our campus dataset demonstrate that the proposed approach performs better in localization accuracy compared with the current state-of-the-art methods. The source of this paper is available at: http://www.github.com/HITSZ-NRSL/long-term-localization.",,10.1109/ROBIO54168.2021.9739599,,,,Location awareness;Point cloud compression;Laser radar;Three-dimensional displays;Heuristic algorithms;Semantics;Clustering algorithms,,,,,,44698.62149,44698.62149,sousarbarb,,Duplicated,
,Landmark rating and selection according to localization coverage: Addressing the challenge of lifelong operation of SLAM in service robots,S. Hochdorfer and C. Schlegel,,2009,IEEE Title,382--387,,"Acting in everyday-life environments is still a great challenge in service robotics. Although algorithms and solutions already exist for many relevant subproblems, in particular the aspect of robustness and suitability for everyday use has been neglected so far very often. Robustness and suitability for everyday use are features affecting not only the overall system design but have impact on each single algorithm of each component.",,10.1109/IROS.2009.5354433,,,,Simultaneous localization and mapping;Service robots;Orbital robotics;Intelligent robots;Robustness;Uncertainty;USA Councils;Computer science;Environmental management;Resource management,,2153-0866,,,,44698.62149,44698.62149,sousarbarb,,Unclassified,
,A real-time visual-inertial mapping and localization method by fusing unstable GPS,Z. Zhang and H. Wang and W. Chen,,2018,IEEE Abstract,1397--1402,,"This paper presents a novel method which fuse visual, IMU and GPS tightly to realize high-precision real-time localization and mapping simultaneously (SLAM). Our method is based on the bundle adjustment (BA). The confidence of the GPS signal is used to determine the window size in the local mapping thread and judge whether the keyframe is reliable. The long-term unreliable keyframe linking with large uncertainty of GPS which called GPS-restricted or GPS-denied situation will cause the drift when mapping. To eliminate the drift, in contrast to use the closed-loop detection and global optimization which will increase the computational burden extremely with the size of the map enlarged, a semi-global optimization method is proposed to relieve the burden, which make the localization estimated by this method possible to be used to navigate for unmanned vehicles. In our method, the confidence of the GPS signal is significantly important, however, the covariance supplied by the GPS receiver may not be trustworthy sometimes, which cause some unnecessary mistake when optimizing, thus a semi-supervised clustering method taking the information of GPS and IMU into account synthetically is introduced to get that confidence more robustly.",,10.1109/WCICA.2018.8630513,,,,Global Positioning System;Simultaneous localization and mapping;Cameras;Receivers;Real-time systems;Fuses,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,I am Not Afraid of the GPS Jammer: Resilient Navigation via Signals of Opportunity in GPS-Denied Environments,Z. Z. Kassas and J. Khalife and A. Abdallah and C. Lee,IEEE Aerospace and Electronic Systems Magazine,2022,IEEE Abstract,1--1,,"In environments where GPS signals are denied, signals of opportunity (SOPs) could serve as an alternative positioning, navigation, and timing (PNT) source to GPS, and more generally, to global navigation satellite systems (GNSS). This paper presents a radio simultaneous localization and mapping (radio SLAM) approach that enables the exploitation of SOPs for resilient and accurate PNT. Radio SLAM estimates the states of the navigator-mounted receiver simultaneously with the SOPs states. This paper presents the first published experimental results evaluating the efficacy of radio SLAM in a real GPS-denied environment. These experiments took place at Edwards Air Force Base, California, USA, during which GPS was intentionally jammed with jamming-to-signal (J/S) ratio as high as 90 dB. The paper evaluates the timing of two cellular long-term evolution (LTE) SOPs located in the jammed environment. Moreover, the paper presents navigation results showcasing a ground vehicle traversing a trajectory of about 5 km in 180 seconds in the GPS-jammed environment. The vehicles GPS-IMU system drifted from the vehicles ground truth trajectory, resulting in a position root mean-squared error (RMSE) of 238 m. In contrast, the radio SLAM approach with a single cellular LTE SOP whose position was poorly known achieved a position RMSE of 32 m.",,10.1109/MAES.2022.3154110,,,,Radio navigation;Global navigation satellite system;Simultaneous localization and mapping;Jamming;Navigation;Global Positioning System;Sensors,,1557-959X,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Pole-like Objects Mapping and Long-Term Robot Localization in Dynamic Urban Scenarios,Z. Wang and S. Li and M. Cao and H. Chen and Y. Liu,,2021,IEEE Abstract,998--1003,,"Localization on 3D data is a challenging task for unmanned vehicles, especially in long-term dynamic urban scenarios. Due to the generality and long-term stability, the pole-like objects are very suitable as landmarks for unmanned vehicle localization in time-varying scenarios. In this paper, a long-term LiDAR-only localization algorithm based on semantic cluster map is proposed. At first, the Convolutional Neural Network(CNN) is used to infer the semantics of LiDAR point clouds. Combined with the point cloud segmentation, the static objects pole/trunk are extracted and registered into global semantic cluster map. When the unmanned vehicle re-enters the environment again, the relocalization is completed by matching the clusters of current scan with the clusters of the global map. Furthermore, the matching between the local and global maps stably outputs the global pose at 2Hz to correct the drift of the 3D LiDAR odometry. The experimental results on our campus dataset demonstrate that the proposed approach performs better in localization accuracy compared with the current state-of-the-art methods. The source of this paper is available at: http://www.github.com/HITSZ-NRSL/long-term-localization.",,10.1109/ROBIO54168.2021.9739599,,,,Location awareness;Point cloud compression;Laser radar;Three-dimensional displays;Heuristic algorithms;Semantics;Clustering algorithms,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Towards background flow based AUV localization,Z. Song and K. Mohseni,,2014,IEEE Abstract,6945--6950,,"Underwater localization faces many constrains and long-term persistent global localization for autonomous underwater vehicles (AUVs) is very difficult. In this paper, we propose a novel AUV localization method taking advantage of the recent progress in ocean general circulation models (OGCMs). During navigation, the AUV performs intermittent local background flow velocity measurements or estimates using on-board sensors. A series of preloaded flow velocity forecast maps generated by OGCMs are referred by a particle filter in updating particle weights based on resemblance between forecasts and local estimation. A rigorous derivation of the problem in probability theory is presented to reveal the recursive structure of the target distribution function. Simulations in a simple double-gyre velocity field exhibit satisfactory converging localization error. Further simulations in a flow field with local flow fluctuations that are not resolved by OGCMs show similar convergent localization error with a slower converging rate. As a first step towards a new set of underwater localization methods, this work presents promising results and reveals the possibility of realizing converging global underwater localization through partial utilization of the background flow information that is easily accessible.",,10.1109/CDC.2014.7040480,,,,Oceans;Vehicles;Velocity measurement;Vectors;Navigation;Robots;Sensors,,0191-2216,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Consistent Cuboid Detection for Semantic Mapping,Z. S. Hashemifar and K. W. Lee and N. Napp and K. Dantu,,2017,IEEE Abstract,526--531,,"Building and storing efficient maps is an essential feature for long-term autonomy of robots. Modern sensors (such as Kinect) tend to produce a lot of data. However, long-term autonomy requires us to store this information in a succinct manner. One way to reduce dimensionality of information is to attribute semantics. Most indoor objects are cuboidal in nature. We conjecture that cuboids are a suitable semantic feature to attribute to indoor objects for efficient mapping. We adapt a cuboid fitting algorithm previously proposedfor object recognition, for indoor mapping. Our work stems from the observation that landmark detection for mappingrequires consistent detection of those landmarks. We implement several modifications to this cuboid detection algorithm that lead to consistent detection such as emptiness, orientation, surface coverage, distance from edges, and others. We incorporate these in the identification of the cuboid candidates in a scene, as well as an optimization algorithm for finding the best set of consistent cubes to cover a given scene. Our experiments show that in comparison, the set of cuboids detected by our algorithm are at least 50% more consistent based on our metrics.SLAM.",,10.1109/ICSC.2017.78,,,,Image segmentation;Simultaneous localization and mapping;Semantics;Object recognition;Image edge detection;Optimization;Image color analysis,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,An 879GOPS 243mW 80fps VGA Fully Visual CNN-SLAM Processor for Wide-Range Autonomous Exploration,Z. Li and Y. Chen and L. Gong and L. Liu and D. Sylvester and D. Blaauw and H.-S. Kim,,2019,IEEE Abstract,134--136,,"Simultaneous localization and mapping (SLAM) estimates an agent's trajectory for all six degrees of freedom (6 DoF) and constructs a 3D map of an unknown surrounding. It is a fundamental kernel that enables head-mounted augmented/virtual reality devices and autonomous navigation of micro aerial vehicles. A noticeable recent trend in visual SLAM is to apply computationand memory-intensive convolutional neural networks (CNNs) that outperform traditional hand-designed feature-based methods [1]. For each video frame, CNN-extracted features are matched with stored keypoints to estimate the agent's 6-DoF pose by solving a perspective-n-points (PnP) non-linear optimization problem (Fig. 7.3.1, left). The agent's long-term trajectory over multiple frames is refined by a bundle adjustment process (BA, Fig. 7.3.1 right), which involves a large-scale (~120 variables) non-linear optimization. Visual SLAM requires massive computation (>250GOP/s) in the CNN-based feature extraction and matching, as well as datadependent dynamic memory access and control flow with high-precision operations, creating significant low-power design challenges. Software implementations are impractical, resulting in 0.2s runtime with a ~3GHz CPU+ GPU system with >100MB memory footprint and >100W power consumption. Prior ASICs have implemented either an incomplete SLAM system [2,3] that lacks estimation of ego-motion or employed a simplified (non-CNN) feature extraction and tracking [2,4,5] that limits SLAM quality and range. A recent ASIC [5] augments visual SLAM with an off-chip high-precision inertial measurement unit (IMU), simplifying the computational complexity, but incurring additional power and cost overhead.",,10.1109/ISSCC.2019.8662397,,,,Simultaneous localization and mapping;Engines;Three-dimensional displays;Two dimensional displays;Feature extraction;Visualization;Trajectory,,2376-8606,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Bio-inspired Relocalization for Indoor Robots in Visual Ambiguous Scenarios,Y. Long and R. Jiang and F. Ye,,2022,IEEE Abstract,685--689,,"In recent years, robots have been widely used in the service industry to improve work efficiency. An indoor service robot should have long-term autonomous adaptability and this is achieved by performing lifelong simultaneous localization and mapping (SLAM). However, when a robot wakes up to SLAM, it needs to relocate itself first. In real-world applications, the visual ambiguous environment which contains multiple locations with similar appearances or features is a challenging scenario for localization. Considering the insufficient expression ability of a single sensor, this paper proposes a bio-inspired relocalization method to deal with this problem. The local view cells model maintains multi-hypotheses to provide visual-based coarse relocalization. Then, an obstacle cell model converts the self-centered lidar information into allocentric representation. And it serves as the fine relocalization. A continuous attractor neural network (CANN) is applied to integrate the candidates obtained through the above two stages. Finally, the result of relocalization is selected by a double-checking mechanism. In the experiments, the success rate of the proposed method reaches 95 % in total and 75% in the most challenging scene. The translation error in all scenes is less than 0.15m.",,10.1109/ICCECE54139.2022.9712794,,,,Location awareness;Visualization;Simultaneous localization and mapping;Uncertainty;Laser radar;Service robots;Biological system modeling;relocalization;bio-inspired;indoor robots;visual ambiguous scene;RatSLAM,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,"Realizing, reversing, recovering: Incremental robust loop closing over time using the iRRR algorithm",Y. Latif and C. Cadena and J. Neira,,2012,IEEE Abstract,4211--4217,,"The ability to reconsider information over time allows to detect failures and is crucial for long term robust autonomous robot applications. This applies to loop closure decisions in localization and mapping systems. This paper describes a method to analyze all available information up to date in order to robustly remove past incorrect loop closures from the optimization process. The main novelties of our algorithm are: 1. incrementally reconsidering loop closures and 2. handling multi-session, spatially related or unrelated experiments. We validate our proposal in real multi-session experiments showing better results than those obtained by state of the art methods.",,10.1109/IROS.2012.6385879,,,,Robustness;Clustering algorithms;Proposals;Optimization;Robots;Trajectory;Estimation,,2153-0866,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,"2-Entity Random Sample Consensus for Robust Visual Localization: Framework, Methods, and Verifications",Y. Jiao and Y. Wang and X. Ding and B. Fu and S. Huang and R. Xiong,IEEE Transactions on Industrial Electronics,2021,IEEE Abstract,4519--4528,68,"Robust and efficient visual localization is essential for numerous robotic applications. However, it remains a challenging problem especially when significant environmental or perspective changes are present, as there are high percentage of outliers, i.e., incorrect feature matches between the query image and the map. In this article, we propose a novel 2-entity random sample consensus (RANSAC) framework using three-dimensional-two-dimensional point and line feature matches for visual localization with the aid of inertial measurements and derive minimal closed-form solutions using only 1 point 1 line or 2 point matches for both monocular and multi-camera system. The proposed 2-entity RANSAC can achieve higher robustness against outliers as multiple types of features are utilized and the number of matches needed to compute a pose is reduced. Furthermore, we propose a learning-based sampling strategy selection mechanism and a feature scoring network to be adaptive to different environmental characteristics such as structured and unstructured. Finally, both simulation and real-world experiments are performed to validate the robustness and effectiveness of the proposed method in scenarios with long-term and perspective changes.",,10.1109/TIE.2020.2984970,,,,Cameras;Visualization;Robustness;Robot vision systems;Pose estimation;Closed-form solutions;Computational modeling;Camera pose estimation;random sample consensus (RANSAC);robust localization,,1557-9948,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory,Y. Furuta and K. Okada and Y. Kakiuchi and M. Inaba,,2018,IEEE Abstract,1--7,,"To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.",,10.1109/IROS.2018.8594481,,,,Task analysis;Probabilistic logic;Semantics;Planning;Robot sensing systems;Solid modeling;Service Robots;Learning and Adaptive Systems;Big Data in Robotics and Automation,,2153-0866,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,DiSCO: Differentiable Scan Context With Orientation,X. Xu and H. Yin and Z. Chen and Y. Li and Y. Wang and R. Xiong,IEEE Robotics and Automation Letters,2021,IEEE Abstract,2791--2798,6,"Global localization is essential for robot navigation, of which the first step is to retrieve a query from the map database. This problem is called place recognition. In recent years, LiDAR scan based place recognition has drawn attention as it is robust against the appearance change. In this letter, we propose a LiDAR-based place recognition method, named Differentiable Scan Context with Orientation (DiSCO), which simultaneously finds the scan at a similar place and estimates their relative orientation. The orientation can further be used as the initial value for the down-stream local optimal metric pose estimation, improving the pose estimation especially when a large orientation between the current scan and retrieved scan exists. Our key idea is to transform the feature into the frequency domain. We utilize the magnitude of the spectrum as the place descriptor, which is theoretically rotation-invariant. In addition, based on the differentiable phase correlation, we can efficiently estimate the global optimal relative orientation using the spectrum. With such structural constraints, the network can be learned in an end-to-end manner, and the backbone is fully shared by the two tasks, achieving better interpretability and lightweight. Finally, DiSCO is validated on three datasets with long-term outdoor conditions, showing better performance than the compared methods. Codes are released at https://github.com/MaverickPeter/DiSCO-pytorch.",,10.1109/LRA.2021.3060741,,,,Three-dimensional displays;Feature extraction;Laser radar;Pose estimation;Visualization;Transforms;Location awareness;Localization;range sensing;SLAM,,2377-3766,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Are We Ready for Service Robots? The OpenLORIS-Scene Datasets for Lifelong SLAM,X. Shi and D. Li and P. Zhao and Q. Tian and Y. Tian and Q. Long and C. Zhu and J. Song and F. Qiao and L. Song and Y. Guo and Z. Wang and Y. Zhang and B. Qin and W. Yang and F. Wang and R. H. M. Chan and Q. She,,2020,IEEE Abstract,3139--3145,,"Service robots should be able to operate autonomously in dynamic and daily changing environments over an extended period of time. While Simultaneous Localization And Mapping (SLAM) is one of the most fundamental problems for robotic autonomy, most existing SLAM works are evaluated with data sequences that are recorded in a short period of time. In real-world deployment, there can be out-of-sight scene changes caused by both natural factors and human activities. For example, in home scenarios, most objects may be movable, replaceable or deformable, and the visual features of the same place may be significantly different in some successive days. Such out-of-sight dynamics pose great challenges to the robustness of pose estimation, and hence a robot’s long-term deployment and operation. To differentiate the forementioned problem from the conventional works which are usually evaluated in a static setting in a single run, the term lifelong SLAM is used here to address SLAM problems in an ever-changing environment over a long period of time. To accelerate lifelong SLAM research, we release the OpenLORIS-Scene datasets. The data are collected in real-world indoor scenes, for multiple times in each place to include scene changes in real life. We also design benchmarking metrics for lifelong SLAM, with which the robustness and accuracy of pose estimation are evaluated separately. The datasets and benchmark are available online at lifelong-robotic-vision.github.io/dataset/scene.",,10.1109/ICRA40945.2020.9196638,,,,Simultaneous localization and mapping;Robot kinematics;Cameras;Synchronization;Trajectory,,2577-087X,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Persistent Stereo Visual Localization on Cross-Modal Invariant Map,X. Ding and Y. Wang and R. Xiong and D. Li and L. Tang and H. Yin and L. Zhao,IEEE Transactions on Intelligent Transportation Systems,2020,IEEE Abstract,4646--4658,21,"Autonomous mobile vehicles are expected to perform persistent and accurate localization with low-cost equipment. To achieve this goal, we propose a stereo camera based visual localization method using a modified laser map, which takes the advantage of both the low cost of camera, and high geometric precision of laser data to achieve long-term performance. Considering that LiDAR and camera give measurements of the same environment in different modalities, the cross-modal invariance is investigated to modify the laser map for visual localization. Specifically, a map learning algorithm is introduced to sample the robust subsets in laser maps that are useful for visual localization using multi-session visual and laser data. Further, a generative map model is derived to describe this cross-modal invariance, based on which two types of measurements are defined to model the laser map points as appropriate visual observations. Tightly coupling these measurements within the local bundle adjustment during online sliding-window based visual odometry, the vehicle can achieve robust localization even one year after the map was built. The effectiveness of the proposed method is evaluated on both the public KITTI datasets and self-collected datasets in our campus, which include seasonal, illumination and object variations. On all experimental localization sessions, our method provides satisfactory results, even when the direction is opposite to that in the mapping session, verifying the superior performance of the laser map based visual localization method.",,10.1109/TITS.2019.2942760,,,,Visualization;Cameras;Measurement by laser beam;Laser modes;Maintenance engineering;Laser stability;Visual localization;persistent autonomy;map maintenance;map incorporated bundle adjustment,,1558-0016,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Communication constrained cloud-based long-term visual localization in real time,X. Ding and Y. Wang and L. Tang and H. Yin and R. Xiong,,2019,IEEE Abstract,2159--2166,,"Visual localization is one of the primary capabilities for mobile robots. Long-term visual localization in real time is particularly challenging, in which the robot is required to efficiently localize itself using visual data where appearance may change significantly over time. In this paper, we propose a cloud-based visual localization system targeting at long-term localization in real time. On the robot, we employ two estimators to achieve accurate and real-time performance. One is a sliding-window based visual inertial odometry, which integrates constraints from consecutive observations and self-motion measurements, as well as the constraints induced by localization results from the cloud. This estimator builds a local visual submap as the virtual observation which is then sent to the cloud as new localization constraints. The other one is a delayed state Extended Kalman Filter to fuse the pose of the robot localized from the cloud, the local odometry and the high-frequency inertial measurements. On the cloud, we propose a longer sliding-window based localization method to aggregate the virtual observations for larger field of view, leading to more robust alignment between virtual observations and the map. Under this architecture, the robot can achieve drift-free and real-time localization using onboard resources even in a network with limited bandwidth, high latency and existence of package loss, which enables the autonomous navigation in real-world environment. We evaluate the effectiveness of our system on a dataset with challenging seasonal and illuminative variations. We further validate the robustness of the system under challenging network conditions.",,10.1109/IROS40897.2019.8968550,,,,,,2153-0866,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Active vision for wearables,W. W. Mayol and B. J. Tordoff and T. E. D. Campos and A. J. Davison and D. W. Murray,,2003,IEEE Abstract,99--104,,"In this paper we report on our ongoing research on wearable active vision, where we have iteratively prototyped a wearable visual robot - a body mounted robot for which the main sensor is a camera. Two main areas have been studied: robot design and visual algorithms. In the design stage, we have analysed sensor placement through the computation of the field of view and body motion using a 3D model of the human form. A design methodology for the robot morphology was developed with the help of an optimisation algorithm based on the Pareto front. The wearability of the device has progressed over several iterations as have the sensor and control architectures. In terms of visual algorithms, we have studied methods of visual tracking fused with inertial sensors, real-time template tracking, human head pose recovery and more recently real-time simultaneous ego-localisation and autonomous 3D map building. Our main long-term application areas are enhanced remote collaboration and autonomous wearable assistants that use vision.",,10.1049/ic:20030154,,,,,,0537-9989,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,A Life-Long SLAM Approach Using Adaptable Local Maps Based on Rasterized LIDAR Images,W. Ali and P. Liu and R. Ying and Z. Gong,IEEE Sensors Journal,2021,IEEE Abstract,21740--21749,21,"Most real-time autonomous robot applications require a robot to traverse through a dynamic space for a long time. In some cases, a robot needs to work in the same environment. Such applications give rise to the problem of a life-long SLAM system. Life-long SLAM presents two main challenges i.e. the tracking should not fail in a dynamic environment and the need for a robust and efficient mapping strategy. The system should update maps with new information; while also keeping track of older observations. But, mapping for a long time can require higher computational requirements. In this paper, we propose a solution to the problem of life-long SLAM. We represent the global map as a set of rasterized images of local maps along with a map management system responsible for updating local maps and keeping track of older values. We also present an efficient approach of using the bag of visual words method for loop closure detection and relocalization. We evaluate the performance of our system on the KITTI dataset and an indoor dataset. Our loop closure system reported recall and precision of above 90 percent. The computational cost of our system is much lower as compared to state-of-the-art methods. Our method reports lower computational requirements even for long-term operation.",,10.1109/JSEN.2021.3100882,,,,Simultaneous localization and mapping;Three-dimensional displays;Feature extraction;Robots;Databases;Laser radar;Sensors;Laser scanning;place recognition;bag of words;rasterization;mapping;simultaneous localization;mapping,,1558-1748,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Performance Analysis of Feature Detectors and Descriptors in Underwater and Polar Environments,V. Shah and J. Nir and P. Kaveti and H. Singh,,2021,IEEE Abstract,1--7,,"Many scientific mapping surveys that deploy robotic platforms in underwater and polar environments perform Visual Simultaneous Localization and Mapping (VSLAM), Structure for Motion (SfM), and Image Mosaicking. These techniques heavily rely on robust and reliable feature-based vision front ends. The job of a vision front end is to provide correspondence information between different camera views which is then directly fed into a bundle adjustment step. Although the atomic steps involved in constructing a vision front end are well-known, many of the popular choices of the features and their parameters do not perform reliably in a variety of visually degraded underwater and polar environments that are characterized by low texture and contrast, and by unevenly lit and low-overlap imagery. In this paper, we develop novel metrics and quantitative analysis methods which can measure the impact of image pre-processing steps such as Contrast Limited Adaptive Histogram Equalization (CLAHE) on the improvement of vision front-end outputs. Our metrics and quantitative analysis can guide the selection between different feature detectors and descriptors to develop a reliable and robust vision front end that can operate in a wider range of underwater and polar environments. We showcase how CLAHE improves the saliency of features and feature track length on a visually degraded dataset underwater, resulting in a substantial increase in correspondence information for the SfM solution. Finally, we perform an end-to-end SfM analysis that shows reduced accumulated drift over the long term and improved accuracy.",,10.23919/OCEANS44145.2021.9705975,,,,Measurement;Visualization;Sea surface;Simultaneous localization and mapping;Statistical analysis;Detectors;Feature extraction;Robust visual perception;Underwater and Polar environments Low texture and contrast;SLAM;CLAHE,,0197-7385,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Bathymetric factor graph SLAM with sparse point cloud alignment,V. Bichucher and J. M. Walls and P. Ozog and K. A. Skinner and R. M. Eustice,,2015,IEEE Abstract,1--7,,"This paper reports on a factor graph simultaneous localization and mapping framework for autonomous underwater vehicle localization based on terrain-aided navigation. The method requires no prior bathymetric map and only assumes that the autonomous underwater vehicle has the ability to sparsely sense the local water column depth, such as with a bottom-looking Doppler velocity log. Since dead-reckoned navigation is accurate in short time windows, the vehicle accumulates several water column depth point clouds- or submaps-during the course of its survey. We propose an xy-alignment procedure between these submaps in order to enforce consistent bathymetric structure over time, and therefore attempt to bound long-term navigation drift. We evaluate the submap alignment method in simulation and present performance results from multiple autonomous underwater vehicle field trials.",,10.23919/OCEANS.2015.7404433,,,,Simultaneous localization and mapping;Three-dimensional displays;Vehicles;Trajectory;Smoothing methods;Global Positioning System,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Mining DCNN landmarks for long-term visual SLAM,T. Taisho and T. Kanji,,2016,IEEE Abstract,570--576,,"Long-term visual SLAM, in familiar, semi-dynamic, and partially changing environments is an important area of research in robotics. The main problem we faced is the question of how to describe a scene discriminatively and compactly-both of which are necessary in order to cope with changes in appearance and a large amount of visual information. In this study, we address the above issues by mining visual experience. Our strategy is to mine a library of raw visual images, termed visual experience, to find the relevant visual patterns to effectively explain the input scene. From a practical point of view, our work offers three main contributions over the previous work. First, it is the first application of discriminative visual features from deep convolutional neural networks (DCNN) to the task of visual landmark mining. Second, we show how to interpret a high-dimensional DCNN feature to a compact semantic representation of visual word. Third, we show that our approach can turn the scene description task with any feature (including the DCNN feature) into the task of mining visual experience. Experiments on a challenging cross-domain visual place recognition validate efficacy of the proposed approach.",,10.1109/ROBIO.2016.7866383,,,,Visualization;Libraries;Feature extraction;Databases;Principal component analysis;Simultaneous localization and mapping,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,AVP-SLAM: Semantic Visual Mapping and Localization for Autonomous Vehicles in the Parking Lot,T. Qin and T. Chen and Y. Chen and Q. Su,,2020,IEEE Abstract,5939--5945,,"Autonomous valet parking is a specific application for autonomous vehicles. In this task, vehicles need to navigate in narrow, crowded and GPS-denied parking lots. Accurate localization ability is of great importance. Traditional visual-based methods suffer from tracking lost due to texture-less regions, repeated structures, and appearance changes. In this paper, we exploit robust semantic features to build the map and localize vehicles in parking lots. Semantic features contain guide signs, parking lines, speed bumps, etc, which typically appear in parking lots. Compared with traditional features, these semantic features are long-term stable and robust to the perspective and illumination change. We adopt four surround-view cameras to increase the perception range. Assisting by an IMU (Inertial Measurement Unit) and wheel encoders, the proposed system generates a global visual semantic map. This map is further used to localize vehicles at the centimeter level. We analyze the accuracy and recall of our system and compare it against other methods in real experiments. Furthermore, we demonstrate the practicability of the proposed system by the autonomous parking application.",,10.1109/IROS45743.2020.9340939,,,,Location awareness;Visualization;Navigation;Semantics;Wheels;Cameras;Autonomous vehicles,,2153-0866,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Vision-based Markov localization across large perceptual changes,T. Naseer and B. Suger and M. Ruhnke and W. Burgard,,2015,IEEE Abstract,1--6,,"Recently, there has been significant progress towards lifelong, autonomous operation of mobile robots, especially in the field of localization and mapping. One important challenge in this context is visual localization under substantial perceptual changes, for example, coming from different seasons. In this paper, we present an approach to localize a mobile robot with a low frequency camera with respect to an image sequence, recorded previously within a different season. Our approach uses a discrete Bayes filter and a sensor model based on whole image descriptors. Thereby it exploits sequential information to model the dynamics of the system. Since we compute a probability distribution over the whole state space, our approach can handle more complex trajectories that may include same season loop-closures as well as fragmented sub-sequences. Throughout an extensive experimental evaluation on challenging datasets, we demonstrate that our approach outperforms state-of-the-art techniques.",,10.1109/ECMR.2015.7324181,,,,Databases;Robot sensing systems;Context;Lead;Cameras;Matched filters,,,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Multiple map hypotheses for planning and navigating in non-stationary environments,T. Morris and F. Dayoub and P. Corke and G. Wyeth and B. Upcroft,,2014,IEEE Abstract,2765--2770,,"This paper presents a method to enable a mobile robot working in non-stationary environments to plan its path and localize within multiple map hypotheses simultaneously. The maps are generated using a long-term and short-term memory mechanism that ensures only persistent configurations in the environment are selected to create the maps. In order to evaluate the proposed method, experimentation is conducted in an office environment. Compared to navigation systems that use only one map, our system produces superior path planning and navigation in a non-stationary environment where paths can be blocked periodically, a common scenario which poses significant challenges for typical planners.",,10.1109/ICRA.2014.6907255,,,,Navigation;Three-dimensional displays;Planning;Robot sensing systems;Switches;Current measurement,,1050-4729,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Persistent localization and life-long mapping in changing environments using the Frequency Map Enhancement,T. Krajník and J. P. Fentanes and M. Hanheide and T. Duckett,,2016,IEEE Abstract,4558--4563,,"We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.",,10.1109/IROS.2016.7759671,,,,Navigation;Two dimensional displays;Robot sensing systems;Planning;Predictive models;Robot kinematics;mobile robotics;long-term autonomy,,2153-0866,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,FreMEn: Frequency Map Enhancement for Long-Term Mobile Robot Autonomy in Changing Environments,T. Krajník and J. P. Fentanes and J. M. Santos and T. Duckett,IEEE Transactions on Robotics,2017,IEEE Abstract,964--977,33,"We present a new approach to long-term mobile robot mapping in dynamic indoor environments. Unlike traditional world models that are tailored to represent static scenes, our approach explicitly models environmental dynamics. We assume that some of the hidden processes that influence the dynamic environment states are periodic and model the uncertainty of the estimated state variables by their frequency spectra. The spectral model can represent arbitrary timescales of environment dynamics with low memory requirements. Transformation of the spectral model to the time domain allows for the prediction of the future environment states, which improves the robot's long-term performance in changing environments. Experiments performed over time periods of months to years demonstrate that the approach can efficiently represent large numbers of observations and reliably predict future environment states. The experiments indicate that the model's predictive capabilities improve mobile robot localization and navigation in changing environments.",,10.1109/TRO.2017.2665664,,,,Hidden Markov models;Mobile robots;Uncertainty;Robustness;Harmonic analysis;Navigation;Localization;long-term autonomy;mapping,,1941-0468,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Mining visual phrases for long-term visual SLAM,T. Kanji and C. Yuuto and A. Masatoshi,,2014,IEEE Abstract,136--142,,"We propose a discriminative and compact scene descriptor for single-view place recognition that facilitates long-term visual SLAM in familiar, semi-dynamic and partially changing environments. In contrast to popular bag-of-words scene descriptors, which rely on a library of vector quantized visual features, our proposed scene descriptor is based on a library of raw image data (such as an available visual experience, images shared by other colleague robots, and publicly available image data on the web) and directly mine it to find visual phrases (VPs) that discriminatively and compactly explain an input query / database image. Our mining approach is motivated by recent success in the field of common pattern discovery-specifically mining of common visual patterns among scenes-and requires only a single library of raw images that can be acquired at different time or day. Experimental results show that even though our scene descriptor is significantly more compact than conventional descriptors it has a relatively higher recognition performance.",,10.1109/IROS.2014.6942552,,,,Visualization;Libraries;Simultaneous localization and mapping;Computational modeling;Vectors;Visual databases,,2153-0866,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Lifelong Localization in Semi-Dynamic Environment,S. Zhu and X. Zhang and S. Guo and J. Li and H. Liu,,2021,IEEE Abstract,14389--14395,,"Mapping and localization in non-static environments are fundamental problems in robotics. Most of previous methods mainly focus on static and highly dynamic objects in the environment, which may suffer from localization failure in semi-dynamic scenarios without considering objects with lower dynamics, such as parked cars and stopped pedestrians. In this paper, we introduce semantic mapping and lifelong localization approaches to recognize semi-dynamic objects in non-static environments. We also propose a generic framework that can integrate mainstream object detection algorithms with mapping and localization algorithms. The mapping method combines an object detection algorithm and a SLAM algorithm to detect semi-dynamic objects and constructs a semantic map that only contains semi-dynamic objects in the environment. During navigation, the localization method can classify observation corresponding to static and non-static objects respectively and evaluate whether those semi-dynamic objects have moved, to reduce the weight of invalid observation and localization fluctuation. Real-world experiments show that the proposed method can improve the localization accuracy of mobile robots in non-static scenarios.",,10.1109/ICRA48506.2021.9561584,,,,Location awareness;Simultaneous localization and mapping;Fluctuations;Navigation;Heuristic algorithms;Conferences;Semantics,,2577-087X,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Localizing Backscatters by a Single Robot with Zero Start-Up Cost,S. Zhang and W. Wang and S. Tang and S. Jin and T. Jiang,,2019,IEEE Abstract,1--6,,"Recent years have witnessed the rapid proliferation of low- power backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such low-power backscatter tags is crucial for IoT-based smart services. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, increasing the deployment cost. To empower universal localization service, this paper presents Rover, an indoor localization system that simultaneously localizes multiple backscatter tags with zero start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing WiFi-based positioning measurements with inertial measurements to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues such as the interference among multiple tags and the real- time processing for solving the SLAM problem. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.",,10.1109/GLOBECOM38437.2019.9013768,,,,Backscatter;Wireless fidelity;Antenna arrays;Interference;Simultaneous localization and mapping,,2576-6813,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,Simultaneous localisation and mapping on the Great Barrier Reef,S. Williams and I. Mahon,,2004,IEEE Abstract,1771--1776Vol.2,2,"This paper presents results of the application of the simultaneous localisation and mapping algorithm to data collected by an unmanned underwater vehicle operating on the Great Barrier Reef in Australia. By fusing information from the vehicle's on-board sonar and vision systems, it is possible to use the highly textured reef to provide estimates of the vehicle motion as well as to generate models of the gross structure of the underlying reefs. Terrain-aided navigation promises to revolutionise the ability of marine systems to track underwater bodies in many applications. This work represents a crucial step in the development of underwater technologies capable of long-term, reliable deployment. Results of the application of this technique to the tracking of the vehicle position are shown.",,10.1109/ROBOT.2004.1308080,,,,Simultaneous localization and mapping;Underwater vehicles;Monitoring;Australia;Underwater tracking;Sonar navigation;Remotely operated vehicles;Robots;Underwater technology;Aerospace engineering,,1050-4729,,,,44698.62117,44698.62117,sousarbarb,,Unclassified,
,FLAME: Feature-Likelihood Based Mapping and Localization for Autonomous Vehicles,S. Pang and D. Kent and D. Morris and H. Radha,,2019,IEEE Abstract,5312--5319,,"Accurate vehicle localization is arguably the most critical and fundamental task for autonomous vehicle navigation. While dense 3D point-cloud-based maps enable precise localization, they impose significant storage and transmission burdens when used in city-scale environments. In this paper, we propose a highly compressed representation for LiDAR maps, along with an efficient and robust real-time alignment algorithm for on-vehicle LiDAR scans. The proposed mapping framework, which we refer to as Feature Likelihood Acquisition Map Emulation (FLAME), requires less than 0.1% of the storage space of the original 3D point cloud map. In essence, FLAME emulates an original map through feature likelihood functions. In particular, FLAME models planar, pole and curb features. These three feature classes are long-term stable, distinct and common among vehicular roadways. Multiclass feature points are extracted from LiDAR scans through feature detection. A new multiclass-based point-to-distribution alignment method is proposed to find the association and alignment between the multiclass feature points and the FLAME map. The experimental results show that the proposed framework can achieve the same level of accuracy (less than 10cm) as the 3D point cloud based localization.",,10.1109/IROS40897.2019.8968082,,,,,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Curating Long-Term Vector Maps,S. Nashed and J. Biswas,,2016,IEEE Abstract,4643--4648,,"Autonomous service mobile robots need to consistently, accurately, and robustly localize in human environments despite changes to such environments over time. Episodic non-Markov Localization addresses the challenge of localization in such changing environments by classifying observations as arising from Long-Term, Short-Term, or Dynamic Features. However, in order to do so, EnML relies on an estimate of the Long-Term Vector Map (LTVM) that does not change over time. In this paper, we introduce a recursive algorithm to build and update the LTVM over time by reasoning about visibility constraints of objects observed over multiple robot deployments. We use a signed distance function (SDF) to filter out observations of short-term and dynamic features from multiple deployments of the robot. The remaining long-term observations are used to build a vector map by robust local linear regression. The uncertainty in the resulting LTVM is computed via Monte Carlo resampling the observations arising from long-term features. By combining occupancy-grid based SDF filtering of observations with continuous space regression of the filtered observations, our proposed approach builds, updates, and amends LTVMs over time, reasoning about all observations from all robot deployments in an environment. We present experimental results demonstrating the accuracy, robustness, and compact nature of the extracted LTVMs from several long-term robot datasets.",,10.1109/IROS.2016.7759683,,,,Robots;Uncertainty;Robustness;Feature extraction;Heuristic algorithms;Monte Carlo methods;Laser noise,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,LLama-SLAM: Learning High-Quality Visual Landmarks for Long-Term Mapping and Localization,S. Luthardt and V. Willert and J. Adamy,,2018,IEEE Abstract,2645--2652,,"The precise localization of vehicles is an important requirement for autonomous driving or advanced driver assistance systems. Using common GNSS the ego position can be measured but not with the reliability and precision necessary. An alternative approach to achieve precise localization is the usage of visual landmarks observed by a camera mounted in the vehicle. However, this raises the necessity of reliable visual landmarks that are easily recognizable and persistent. We propose a novel SLAM algorithm that focuses on learning and mapping such visual long-term landmarks (LLamas). The algorithm therefore processes stereo image streams from several recording sessions in the same spatial area. The key part within LLama-SLAM is the assessment of the landmarks with quality values that are inferred as viewpoint dependent probabilities from observation statistics. By adding solely landmarks of high quality to the final LLama Map, it can be kept compact while still allowing reliable localization. Due to the long-term evaluation of the GNSS measurement during the sessions, the landmarks can be positioned precisely in a global referenced coordinate system. For a first assessment of the algorithm's capabilities, we present some experimental results from the mapping process combining three sessions recorded over two months on the same route.",,10.1109/ITSC.2018.8569323,,,,Cameras;Visualization;Simultaneous localization and mapping;Global navigation satellite system;Reliability;Probability;Optimization,,2153-0017,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,6 DoF SLAM using a ToF camera: The challenge of a continuously growing number of landmarks,S. Hochdorfer and C. Schlegel,,2010,IEEE Abstract,3981--3986,,"Localization and mapping are fundamental problems in service robotics since representations of the environment and knowledge about the own pose significantly simplify the implementation of a series of high-level applications. ToF (time-of-flight) cameras are a relatively new kind of sensors in robotics. They enable the real-time capture of the distance and the grayscale information of a scene. Due to the increase of the image resolution of ToF cameras, now highlevel computer vision algorithms for visual feature extraction (e.g. SIFT or SURF) can be applied to the captured images. These visual features combined with the corresponding distance information give a full measurement of 3D landmarks. An obvious problem to be solved is the continuously growing number of landmarks. So far, all ever seen landmarks are just accumulated irrespective of their utility and the then required resources. Rather, one should keep only really useful landmarks, e.g. such that localization quality in the whole operational area is kept above a given threshold. In fact a lifelong running SLAM approach is dependent on means to select and discard landmarks. That is even more acute in case of feature-rich sensor data as provided with high update rates by sensors like a ToF camera. We run our SLAM approach in a real-world experiment within an indoor environment. The experiment was performed on a P3DX-platform equipped with a PMD CamCube 2.0 and a Xsens IMU.",,10.1109/IROS.2010.5651229,,,,Cameras;Three dimensional displays;Robot kinematics;Simultaneous localization and mapping;Robot vision systems,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Uncalibrated monocular based simultaneous localization and mapping for indoor autonomous mobile robot navigation,S. Fu and G. Yang,,2009,IEEE Abstract,663--668,,"This paper describes a an SLAM algorithm for the navigation for an indoor autonomous mobile robot. The main emphasis of this paper is on the ability of line extraction. A recognition method based on straight line extraction is proposed for extracting the key features on the office ceiling, in an effort to estimate the pose of mobile robot. Random Sample Consensus (RANSAC) paradigm is used to group the line segments. During the navigation, onboard odometry is used at the beginning stage to estimate the information of environment for visual reckoning, while lamps on the ceiling act as beacons for positioning to eliminate accumulation of errors after a long-term run. The data captured from infrared sensors is used for constructing a map. The proposed method scales well with respect to the size of the input image and the number and size of the shapes within the data. Moreover the algorithm is conceptually simple and easy to implement. Simulation and experimental results show that good recognition and localization can be achieved using the proposed method, allowing for the interested region correspondence matching and mapping between images from different sensors or the same sensor indifferent time phrase.",,10.1109/ICNSC.2009.4919356,,,,Simultaneous localization and mapping;Mobile robots;Navigation;Data mining;Image sensors;Feature extraction;Lamps;Infrared sensors;Shape;Image recognition,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,An Optimization Technique for Positioning Multiple Maps for Self-Driving Car's Autonomous Navigation,S. Dominguez and B. Khomutenko and G. Garcia and P. Martinet,,2015,IEEE Abstract,2694--2699,,"Self-driving car's navigation requires a very precise localization covering wide areas and long distances. Moreover, they have to do it at faster speeds than conventional mobile robots. This paper reports on an efficient technique to optimize the position of a sequence of maps along a journey. We take advantage of the short-term precision and reduced space on disk of the localization using 2D occupancy grid maps, from now on called sub-maps, as well as, the long-term global consistency of a Kalman filter that fuses odometry and GPS measurements. In our approach, horizontal planar LiDARs and odometry measurements are used to perform 2D-SLAM generating the sub-maps, and the EKF to generate the trajectory followed by the car in global coordinates. During the trip, after finishing each sub-map, a relaxation process is applied to a set of the last sub-maps to position them globally using both, global and map's local path. The importance of this method lies on its performance, expending low computing resources, so it can work in real time on a computer with conventional characteristics and on its robustness which makes it suitable for being used on a self-driving car as it doesn't depend excessively on the availability of GPS signal or the eventual appearance of moving objects around the car. Extensive testing has been performed in the suburbs and in the down-town of Nantes (France) covering a distance of 25 kilometers with different traffic conditions obtaining satisfactory results for autonomous driving.",,10.1109/ITSC.2015.433,,,,Laser radar;Global Positioning System;Splines (mathematics);Force;Trajectory;Simultaneous localization and mapping;Buildings,,2153-0017,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Robustifying Visual Place Recognition with Semantic Scene Categorization,S. Arshad and G.-W. Kim,,2020,IEEE Index Terms,467--469,,"This research proposes an accurate loop closure detection method for the real-time robot navigation in changing light, viewpoint and weather conditions. It focuses on enhancing the accuracy performance of visual place recognition by integrating the semantics of image scenes with handcrafted features. This method reduces the computational cost of the feature matching process by segmentation of the dataset. The results presented depicts that scene recognition can improve the place recognition even in the large viewpoint, weather and light changes.",,10.1109/BigComp48618.2020.00-24,,,,Semantics;Feature extraction;Visualization;Navigation;Robots;Meteorology;Real-time systems;visual place recognition;scene recognition;semantic labelling;feature descriptors;long term autonomy;visual navigation;hierarchical structure;data segmentation,,2375-9356,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Self help: Seeking out perplexing images for ever improving navigation,R. Paul and P. Newman,,2011,IEEE Index Terms,445--451,,"This paper is a demonstration of how a robot can, through introspection and then targeted data retrieval, improve its own performance. It is a step in the direction of lifelong learning and adaptation and is motivated by the desire to build robots that have plastic competencies which are not baked in. They should react to and benefit from use. We consider a particular instantiation of this problem in the context of place recognition. Based on a topic based probabilistic model of images, we use a measure of perplexity to evaluate how well a working set of background images explain the robot's online view of the world. Offline, the robot then searches an external resource to seek out additional background images that bolster its ability to localise in its environment when used next. In this way the robot adapts and improves performance through use.",,10.1109/ICRA.2011.5980404,,,,Robots;Biological system modeling;Mathematical model;Visualization;Convergence;Databases;Redundancy,,1050-4729,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,ORB-SLAM: A Versatile and Accurate Monocular SLAM System,R. Mur-Artal and J. M. M. Montiel and J. D. Tardós,IEEE Transactions on Robotics,2015,IEEE Index Terms,1147--1163,31,"This paper presents ORB-SLAM, a feature-based monocular simultaneous localization and mapping (SLAM) system that operates in real time, in small and large indoor and outdoor environments. The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization. Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks: tracking, mapping, relocalization, and loop closing. A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets. ORB-SLAM achieves unprecedented performance with respect to other state-of-the-art monocular SLAM approaches. For the benefit of the community, we make the source code public.",,10.1109/TRO.2015.2463671,,,,Simultaneous localization and mapping;Cameras;Optimization;Feature extraction;Visualization;Real-time systems;Computational modeling;Lifelong mapping;localization;monocular vision;recognition;simultaneous localization and mapping (SLAM);Lifelong mapping;localization;monocular vision;recognition;simultaneous localization and mapping (SLAM),,1941-0468,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A framework for RF-Visual SLAM,S. Anwar and Q. Zhao and N. Qadeer and S. I. Khan,,2013,IEEE Abstract,103--108,,"Simultaneous Localization and Mapping, SLAM, is an important topic in the field of robotics and autonomous navigation. The metric SLAM suffers from sensor inaccuracies and thus cannot be used for long-term navigation. In such case, Visual SLAM or a Hybrid SLAM based on both metric and visual approach is a good alternative. In this paper, in order to speed up a Visual SLAM, we propose a novel concept of dynamic dictionary generated on the results of triangulation done on RF, radio frequency, signals from nearest cell towers of a cellular network. This dynamic dictionary efficiently manages the scalability of a Visual SLAM and make it possible to work in a large-scale environment. A framework is proposed along with triangulation data of a city and with simulations to support the concept.",,10.1109/IBCAST.2013.6512139,,,,Dictionaries;Simultaneous localization and mapping;Poles and towers;Navigation;Hybrid power systems,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,A B-Spline Mapping Framework for Long-Term Autonomous Operations,R. T. Rodrigues and A. P. Aguiar and A. Pascoal,,2018,IEEE Abstract,3204--3209,,"This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.",,10.1109/IROS.2018.8594456,,,,Splines (mathematics);Simultaneous localization and mapping;Three-dimensional displays;Robot kinematics;Two dimensional displays,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Pole-based localization for autonomous vehicles in urban scenarios,R. Spangenberg and D. Goehring and R. Rojas,,2016,IEEE Abstract,2161--2166,,"Localization is a key capability for autonomous vehicles especially in urban scenarios. We propose the use of pole-like landmarks as primary features in these environments, as they are distinct, long-term stable and can be detected reliably with a stereo camera system. Furthermore, the resulting map representation is memory efficient, allowing for easy storage and on-line updates. The localization is performed in real-time by a stereo camera system as a main sensor, using vehicle odometry and an off-the-shelf GPS as secondary information sources. Localization is performed by a particle filter approach, coupled with an Kalman filter for robustness and sensor fusion. This leads to a lateral accuracy below 20 cm in various urban test areas. The system has been included in our autonomous test vehicle and successfully demonstrated the full loop from mapping to autonomous driving.",,10.1109/IROS.2016.7759339,,,,Vehicles;Cameras;Global Positioning System;Atmospheric measurements;Particle measurements;Kalman filters;Robustness,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-term place recognition using multi-level words of spatial densities,R. Maffei and V. A. M. Jorge and V. F. Rey and M. Kolberg and E. Prestes,,2016,IEEE Abstract,3269--3274,,"Proper place recognition on an environment that can change over time is fundamental for long-term SLAM. In such scenarios the observations obtained in the same region can drastically differ due to changes caused by semi-static objects, such as doors, furniture, etc. In this work, we extend a strategy that represents environment regions using words, based on spatial density information extracted from laser readings. This time, in order to deal with changes in the environment, our method not only builds words representing the real observations made by the robot, but also alternative multi-level words to account for possible changes in a place's observations generated by non-static objects. Place recognition is made by searching matches of sequences of N consecutive words (both real or alternatives). Experiments performed in real and simulated scenarios are shown, and demonstrate the advantages associated to the use of multi-level words.",,10.1109/IROS.2016.7759504,,,,Buildings;Simultaneous localization and mapping;Kernel;Trajectory;Lasers,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-term human affordance maps,R. Limosani and L. Y. Morales and J. Even and F. Ferreri and A. Watanabe and F. Cavallo and P. Dario and N. Hagita,,2015,IEEE Abstract,5748--5754,,"This paper presents a work on mapping the use of space by humans in long periods of time. Daily geometric maps with the same coordinate frame were generated with SLAM, and in a similar manner, daily affordance density maps (places people use) were generated with the output of a human tracker running on the robot. The contribution of the paper is two-fold: an approach to detect geometric changes to cluster them in similar geometric configurations and the building of geometric and affordance composite maps on each cluster. This approach avoids the loss of long term retrieved information. Geometric similarity was computed using a normal distance approach on the maps. The analysis was performed on data collected by a mobile robot for a period of 4 months accumulating data equivalent to 70 days. Experimental results show that the system is capable of detecting geometric changes in the environment and clustering similar geometric configurations.",,10.1109/IROS.2015.7354193,,,,Robot kinematics;Buildings;Navigation;Robot sensing systems;Layout;Geometry,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Ground Enhanced RGB-D SLAM for Dynamic Environments,R. Guo and X. Liu,,2021,IEEE Abstract,1171--1177,,"Robust pose estimation and map reconstruction are the basic requirements of the robotics autonomous. In this paper, a static ground feature enhanced SLAM system is proposed for dynamic environments with RGB-D sensors. Compared with the typical point-based SLAM, our designed system extra introduce the ground and other plane constraints to solve the dynamic SLAM. In the front-end, the ground as a special plane feature is detected and tracked, which can provide realiable constraint for the pose estimation in dynamic environments. In the back-end, a point-ground based factor graph is constructed and optimized for more accurate map. Moreover, plane structure is exploited to repair the keyframe dynamic regions, new synthesized keyframes are used to reconstruct the static map for long-term applications. Real world dataset tests demonstrate the effectiveness of our proposed system.",,10.1109/ROBIO54168.2021.9739362,,,,Simultaneous localization and mapping;Conferences;Biomimetics;Pose estimation;Pipelines;Object detection;Maintenance engineering,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"3D localization, mapping and path planning for search and rescue operations",R. Dubé and A. Gawel and C. Cadena and R. Siegwart and L. Freda and M. Gianni,,2016,IEEE Abstract,272--273,,"This work presents our results on 3D robot localization, mapping and path planning for the latest joint exercise of the European project “Long-Term Human-Robot Teaming for Robots Assisted Disaster Response” (TRADR)1. The full system is operated and evaluated by firemen end-users in real-world search and rescue experiments. We demonstrate that the system is able to plan a path to a goal position desired by the fireman operator in the TRADR Operational Control Unit (OCU), using a persistent 3D map created by the robot during previous sorties.",,10.1109/SSRR.2016.7784311,,,,Three-dimensional displays;Path planning;Simultaneous localization and mapping;Navigation;Lasers,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Deep Samplable Observation Model for Global Localization and Kidnapping,R. Chen and H. Yin and Y. Jiao and G. Dissanayake and Y. Wang and R. Xiong,IEEE Robotics and Automation Letters,2021,IEEE Abstract,2296--2303,6,"Global localization and kidnapping are two challenging problems in robot localization. The popular method, Monte Carlo Localization (MCL) addresses the problem by iteratively updating a set of particles with a “sampling-weighting” loop. Sampling is decisive to the performance of MCL [1]. However, traditional MCL can only sample from a uniform distribution over the state space. Although variants of MCL propose different sampling models, they fail to provide an accurate distribution or generalize across scenes. To better deal with these problems, we present a distribution proposal model named Deep Samplable Observation Model (DSOM). DSOM takes a map and a 2D laser scan as inputs and outputs a conditional multimodal probability distribution of the pose, making the samples more focusing on the regions with higher likelihood. With such samples, the convergence is expected to be more effective and efficient. Considering that the learning-based sampling model may fail to capture the accurate pose sometimes, we furthermore propose the Adaptive Mixture MCL (AdaM MCL), which deploys a trusty mechanism to adaptively select updating mode for each particle to tolerate this situation. Equipped with DSOM, AdaM MCL can achieve more accurate estimation, faster convergence and better scalability than previous methods in both synthetic and real scenes. Even in real environments with long-term changes, AdaM MCL is able to localize the robot using DSOM trained only by simulation observations from a SLAM map or a blueprint map. Source code for this paper is available here: https://github.com/Runjian-Chen/AdaM_MCL.",,10.1109/LRA.2021.3061339,,,,Robots;Location awareness;Proposals;Probability distribution;Adaptation models;Feature extraction;Two dimensional displays;Global localization;multimodal;samplable observation model,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,OpenABLE: An open-source toolbox for application in life-long visual localization of autonomous vehicles,R. Arroyo and P. F. Alcantarilla and L. M. Bergasa and E. Romera,,2016,IEEE Abstract,965--970,,"Visual information is a valuable asset in any perception scheme designed for an intelligent transportation system. In this regard, the camera-based recognition of locations provides a higher situational awareness of the environment, which is very useful for varied localization solutions typically needed in long-term autonomous navigation, such as loop closure detection and visual odometry or SLAM correction. In this paper we present OpenABLE, an open-source toolbox contributed to the community with the aim of helping researchers in the application of these kinds of life-long localization algorithms. The implementation follows the philosophy of the topological place recognition method named ABLE, including several new features and improvements. These functionalities allow to match locations using different global image description methods and several configuration options, which enable the users to control varied parameters in order to improve the performance of place recognition depending on their specific problem requisites. The applicability of our toolbox in visual localization purposes for intelligent vehicles is validated in the presented results, jointly with comparisons to the main state-of-the-art methods.",,10.1109/ITSC.2016.7795672,,,,Visualization;Open source software;Autonomous vehicles;Context;Cameras;Navigation,,2153-0017,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Towards life-long visual localization using an efficient matching of binary sequences from images,R. Arroyo and P. F. Alcantarilla and L. M. Bergasa and E. Romera,,2015,IEEE Abstract,6328--6335,,"Life-long visual localization is one of the most challenging topics in robotics over the last few years. The difficulty of this task is in the strong appearance changes that a place suffers due to dynamic elements, illumination, weather or seasons. In this paper, we propose a novel method (ABLE-M) to cope with the main problems of carrying out a robust visual topological localization along time. The novelty of our approach resides in the description of sequences of monocular images as binary codes, which are extracted from a global LDB descriptor and efficiently matched using FLANN for fast nearest neighbor search. Besides, an illumination invariant technique is applied. The usage of the proposed binary description and matching method provides a reduction of memory and computational costs, which is necessary for long-term performance. Our proposal is evaluated in different life-long navigation scenarios, where ABLE-M outperforms some of the main state-of-the-art algorithms, such as WI-SURF, BRIEF-Gist, FAB-MAP or SeqSLAM. Tests are presented for four public datasets where a same route is traversed at different times of day or night, along the months or across all four seasons.",,10.1109/ICRA.2015.7140088,,,,Visualization;Lighting;Robustness;Proposals;Binary codes;Cameras;Computational efficiency,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Loop-Closure Detection With a Multiresolution Point Cloud Histogram Mode in Lidar Odometry and Mapping for Intelligent Vehicles,Q. Meng and H. Guo and X. Zhao and D. Cao and H. Chen,IEEE/ASME Transactions on Mechatronics,2021,IEEE Abstract,1307--1317,26,"Precise positioning is the basic condition for intelligent vehicles to complete perception, decision making and control tasks. In response to this challenge, in this article, lidar simultaneous localization and mapping (SLAM) is taken as the research object, and a SLAM system is designed that integrates motion compensation and ground information removal functions, and can construct a real-time environment map and determine its own position on the map while the vehicle is driving. A loop-closure detection method with a multiresolution point cloud histogram mode is proposed, which can effectively detect whether the vehicle passes through the same position and perform optimization to obtain globally consistent pose and map information in the urban conditions with more driving loops. We conduct experiments on the well-known KITTI dataset and compare the results with those of state-of-the-art systems. The experiments confirm that the lidar SLAM system designed in this article can provide accurate and effective positioning information for intelligent vehicles. The proposed loop-closure detection algorithm has an excellent real-time performance and accuracy, which can guarantee the long-term driving operation of these vehicles.",,10.1109/TMECH.2021.3062647,,,,Three-dimensional displays;Laser radar;Intelligent vehicles;Simultaneous localization and mapping;Histograms;Trajectory;Feature extraction;KITTI dataset;lidar simultaneous localization and mapping (SLAM);loop-closure detection;multiresolution histogram;pose estimation,,1941-014X,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Relocalization With Submaps: Multi-Session Mapping for Planetary Rovers Equipped With Stereo Cameras,R. Giubilato and M. Vayugundla and M. J. Schuster and W. Stürzl and A. Wedler and R. Triebel and S. Debei,IEEE Robotics and Automation Letters,2020,IEEE Index Terms,580--587,5,"To enable long term exploration of extreme environments such as planetary surfaces, heterogeneous robotic teams need the ability to localize themselves on previously built maps. While the Localization and Mapping problem for single sessions can be efficiently solved with many state of the art solutions, place recognition in natural environments still poses great challenges for the perception system of a robotic agent. In this paper we propose a relocalization pipeline which exploits both 3D and visual information from stereo cameras to detect matches across local point clouds of multiple SLAM sessions. Our solution is based on a Bag of Binary Words scheme where binarized SHOT descriptors are enriched with visual cues to recall in a fast and efficient way previously visited places. The proposed relocalization scheme is validated on challenging datasets captured using a planetary rover prototype on Mount Etna, designated as a Moon analogue environment.",,10.1109/LRA.2020.2964157,,,,Three-dimensional displays;Visualization;Simultaneous localization and mapping;Vocabulary;Pipelines;Cameras;Localization;space robotics and automation;mapping,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A Novel Global Relocalization Method Based on Hierarchical Registration of 3D Point Cloud Map for Mobile Robot,Q. Tian and Y. Gao and G. Li and J. Song,,2019,IEEE Index Terms,68--73,,"Indoor service mobile robots need to relocate when they are kidnapped, powered off, or lost in long-term work, thus unable to perform daily tasks. Solving this problem is challenging, especially for 3D maps due to the computational complexity. In order to solve this issue, a novel relocalization algorithm based on hierarchical registration is proposed for a known 3D map in this paper. For 3D point cloud maps, the algorithm obtains multi-layer information in the vertical direction through hierarchical registration at the robot's current position. To obtain the best 3D pose for relocalization, we fuse the poses calculated by the multi-layered point cloud into one and use it as the initial pose of the iterative closest point algorithm. The hierarchical registration based algorithm solves the problem of unknown initial value for registration between two large point clouds, improves the recall rate, and ensures the accuracy of algorithm at the same time. The related relocalization experiments are carried out in the indoor environment and the results verify the effectiveness and robustness of the algorithm.",,10.1109/ICCAR.2019.8813720,,,,visual SLAM;relocalization;mobile robot;point cloud registration,,2251-2446,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Multi-Robot Joint Visual-Inertial Localization and 3-D Moving Object Tracking,P. Zhu and W. Ren,,2020,IEEE Abstract,11573--11580,,"In this paper, we present a novel distributed algorithm to track a moving object's state by utilizing a heterogenous mobile robot network in a three-dimensional (3-D) environment, wherein the robots' poses (positions and orientations) are unknown. Each robot is equipped with a monocular camera and an inertial measurement unit (IMU), and has the ability to communicate with its neighbors. Rather than assuming a known common global frame for all the robots (which is often the case in the literature regarding multi-robot systems), we allow each robot to perform motion estimation locally. For localization, we propose a multi-robot visual-inertial navigation systems (VINS) where one robot builds a prior map and then the map is used to bound the long-term drifts of the visual-inertial odometry (VIO) running on the other robots. Moreover, a novel distributed Kalman filter is introduced and employed to cooperatively track the six degree-of-freedom (6-DoF) motion of the object which is represented as a point cloud. Further, the object can be totally invisible to some robots during the tracking period. The proposed algorithm is extensively validated in Monte-Carlo simulations.",,10.1109/IROS45743.2020.9341393,,,,Location awareness;Monte Carlo methods;Three-dimensional displays;Target tracking;Robot vision systems;Sensors;Robots,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,On the Redundancy Detection in Keyframe-Based SLAM,P. Schmuck and M. Chli,,2019,IEEE Abstract,594--603,,"Egomotion and scene estimation is a key component in automating robot navigation, as well as in virtual reality applications for mobile phones or head-mounted displays. It is well known, however, that with long exploratory trajectories and multi-session mapping for long-term autonomy or collaborative applications, the maintenance of the ever-increasing size of these maps quickly becomes a bottleneck. With the explosion of data resulting in increasing runtime of the optimization algorithms ensuring the accuracy of the Simultaneous Localization And Mapping (SLAM) estimates, the large quantity of collected experiences is imposing hard limits on the scalability of such techniques. Considering the keyframe-based paradigm of SLAM techniques, this paper investigates the redundancy inherent in SLAM maps, by quantifying the information of different experiences of the scene as encoded in keyframes. Here we propose and evaluate different information-theoretic and heuristic metrics to remove dispensable scene measurements with minimal impact on the accuracy of the SLAM estimates. Evaluating the proposed metrics in two state-of-the-art centralized collaborative SLAM systems, we provide our key insights into how to identify redundancy in keyframe-based SLAM.",,10.1109/3DV.2019.00071,,,,Simultaneous localization and mapping;Redundancy;Collaboration;Visualization;Three-dimensional displays;Optimization;SLAM;Collaborative SLAM;Redundancy Detection;Keyframe Selection;Multi Robot Systems;Graph Compression,,2475-7888,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Automated Crack Detection on Concrete Bridges,P. Prasanna and K. J. Dana and N. Gucunski and B. B. Basily and H. M. La and R. S. Lim and H. Parvardeh,IEEE Transactions on Automation Science and Engineering,2016,IEEE Abstract,591--599,13,"Detection of cracks on bridge decks is a vital task for maintaining the structural health and reliability of concrete bridges. Robotic imaging can be used to obtain bridge surface image sets for automated on-site analysis. We present a novel automated crack detection algorithm, the STRUM (spatially tuned robust multifeature) classifier, and demonstrate results on real bridge data using a state-of-the-art robotic bridge scanning system. By using machine learning classification, we eliminate the need for manually tuning threshold parameters. The algorithm uses robust curve fitting to spatially localize potential crack regions even in the presence of noise. Multiple visual features that are spatially tuned to these regions are computed. Feature computation includes examining the scale-space of the local feature in order to represent the information and the unknown salient scale of the crack. The classification results are obtained with real bridge data from hundreds of crack regions over two bridges. This comprehensive analysis shows a peak STRUM classifier performance of 95% compared with 69% accuracy from a more typical image-based approach. In order to create a composite global view of a large bridge span, an image sequence from the robot is aligned computationally to create a continuous mosaic. A crack density map for the bridge mosaic provides a computational description as well as a global view of the spatial patterns of bridge deck cracking. The bridges surveyed for data collection and testing include Long-Term Bridge Performance program's (LTBP) pilot project bridges at Haymarket, VA, USA, and Sacramento, CA, USA.",,10.1109/TASE.2014.2354314,,,,Bridges;Robots;Robustness;Laplace equations;Visualization;Concrete;Image segmentation;Adaboost;bridge deck inspection;bridge maintenance;computer vision;concrete;crack detection;crack pattern recognition;homography;image mosaic;image stitching;Laplacian pyramid;machine learning;random forest;robotic imaging;robotic inspection;Seekur robot;structural health monitoring;structure from motion;STRUM classifier;support vector machine,,1558-3783,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Research of large-scale offline map management in visual SLAM,Q. Shen and H. Sun and P. Ye,,2017,IEEE Index Terms,215--219,,"This paper presents a novel method of visual simultaneous localization and mapping (SLAM), which is a method of real-time localization and mapping. It is important for a mobile robot to build a map while autonomously navigation. Due to the complexity of the robot work scene, the SLAM method proposed in this paper optimizes map management. It will cost a lot of time and space when a robot long-term works in a same large scene. Therefore, we propose a method in this paper to save a detail map as an offline map in advance. At the same time in order to facilitate the follow-up optimization, the offline map can be divided into several sub-graphs according to the similarity of the scene. Since the segmented offline map has been saved to local system, it can be loaded at any time to localization and obtain the pose of current frame.",,10.1109/ICSAI.2017.8248292,,,,Simultaneous localization and mapping;Image segmentation;Cameras;Real-time systems;Optimization;Symmetric matrices;SLAM;offline map;segment graph;normalized-cut,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,MRS-VPR: a multi-resolution sampling based global visual place recognition method,P. Yin and R. A. Srivatsan and Y. Chen and X. Li and H. Zhang and L. Xu and L. Li and Z. Jia and J. Ji and Y. He,,2019,IEEE Index Terms,7137--7142,,"Place recognition and loop closure detection are challenging for long-term visual navigation tasks. SeqSLAM is considered to be one of the most successful approaches to achieve long-term localization under varying environmental conditions and changing viewpoints. SeqSLAM uses a brute-force sequential matching method, which is computationally intensive. In this work, we introduce a multi-resolution sampling-based global visual place recognition method (MRS-VPR), which can significantly improve the matching efficiency and accuracy in sequential matching. The novelty of this method lies in the coarse-to-fine searching pipeline and a particle filter-based global sampling scheme, that can balance the matching efficiency and accuracy in the long-term navigation task. Moreover, our model works much better than SeqSLAM when the testing sequence is over a much smaller time scale than the reference sequence. Our experiments demonstrate that MRSVPR is efficient in locating short temporary trajectories within long-term reference ones without compromising on the accuracy compared to SeqSLAM.",,10.1109/ICRA.2019.8793853,,,,Testing;Feature extraction;Indexes;Task analysis;Trajectory;Visualization;Robots,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Stabilize an Unsupervised Feature Learning for LiDAR-based Place Recognition,P. Yin and L. Xu and Z. Liu and L. Li and H. Salman and Y. He and W. Xu and H. Wang and H. Choset,,2018,IEEE Index Terms,1162--1167,,"Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.",,10.1109/IROS.2018.8593562,,,,Octrees;Laser radar;Task analysis;Decoding;Simultaneous localization and mapping;Generative adversarial networks,,2153-0866,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,FusionVLAD: A Multi-View Deep Fusion Networks for Viewpoint-Free 3D Place Recognition,P. Yin and L. Xu and J. Zhang and H. Choset,IEEE Robotics and Automation Letters,2021,IEEE Index Terms,2304--2310,6,"Real-time 3D place recognition is a crucial technology to recover from localization failure in applications like autonomous driving, last-mile delivery, and service robots. However, it is challenging for 3D place retrieval methods to be accurate, efficient, and robust to the variant viewpoints differences. In this letter, we propose FusionVLAD, a fusion-based network that encodes a multi-view representation of sparse 3D point clouds into viewpoint-free global descriptors. The system consists of two parallel branches: a spherical-view branch for orientation-invariant feature extraction, and the top-down view branch for translation-insensitive feature extraction. Furthermore, we design a parallel fusion module to enhance the combination of region-wise feature connection between the two branches. Experiments on two public datasets and two generated datasets show that our method outperforms state-of-the-art with robust place recognition accuracy and efficient inference time. Besides, FusionVLAD requires limited computation resources and makes it extremely suitable for low-cost robots' long-term place recognition task.",,10.1109/LRA.2021.3061375,,,,Three-dimensional displays;Feature extraction;Robots;Laser radar;Encoding;Task analysis;Geometry;Recognition;SLAM;visual learning,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Appearance change prediction for long-term navigation across seasons,P. Neubert and N. Sünderhauf and P. Protzel,,2013,IEEE Index Terms,198--203,,"Changing environments pose a serious problem to current robotic systems aiming at long term operation. While place recognition systems perform reasonably well in static or low-dynamic environments, severe appearance changes that occur between day and night, between different seasons or different local weather conditions remain a challenge. In this paper we propose to learn to predict the changes in an environment. Our key insight is that the occurring appearance changes are in part systematic, repeatable and therefore predictable. The goal of our work is to support existing approaches to place recognition by learning how the visual appearance of an environment changes over time and by using this learned knowledge to predict its appearance under different environmental conditions. We describe the general idea of appearance change prediction (ACP) and a novel implementation based on vocabularies of superpixels (SP-ACP). Despite its simplicity, we can further show that the proposed approach can improve the performance of SeqSLAM and BRIEF-Gist for place recognition on a large-scale dataset that traverses an environment under extremely different conditions in winter and summer.",,10.1109/ECMR.2013.6698842,,,,Vocabulary;Dictionaries;Visualization;Training;Image color analysis;Image segmentation;Meteorology,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A Linear-Complexity EKF for Visual-Inertial Navigation with Loop Closures,P. Geneva and K. Eckenhoff and G. Huang,,2019,IEEE Index Terms,3535--3541,,"Enabling real-time visual-inertial navigation in unknown environments while achieving bounded-error performance holds great potentials in robotic applications. To this end, in this paper, we propose a novel linear-complexity EKF for visual-inertial localization, which can efficiently utilize loop closure constraints, thus allowing for long-term persistent navigation. The key idea is to adapt the Schmidt-Kalman formulation within the multi-state constraint Kalman filter (MSCKF) framework, in which we selectively include keyframes as nuisance parameters in the state vector for loop closures but do not update their estimates and covariance in order to save computations while still tracking their cross-correlations with the current navigation states. As a result, the proposed Schmidt-MSCKF has only O(n) computational complexity while still incorporating loop closures into the system. The proposed approach is validated extensively on large-scale real-world experiments, showing significant performance improvements when compared to the standard MSCKF, while only incurring marginal computational overhead.",,10.1109/ICRA.2019.8793836,,,,Navigation;Microsoft Windows;Standards;Current measurement;Real-time systems;Trajectory;Three-dimensional displays,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships,P. Gao and H. Zhang,,2020,IEEE Index Terms,1070--1076,,"Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks.",,10.1109/ICRA40945.2020.9196906,,,,Visualization;Simultaneous localization and mapping;Robustness;Strain;Image recognition;Tensile stress,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Air-SSLAM: A Visual Stereo Indoor SLAM for Aerial Quadrotors,P. Araújo and R. Miranda and D. Carmo and R. Alves and L. Oliveira,IEEE Geoscience and Remote Sensing Letters,2017,IEEE Index Terms,1643--1647,14,"In this letter, we introduce a novel method for visual simultaneous localization and mapping (SLAM)-so-called Air-SSLAM-which exploits a stereo camera configuration. In contrast to monocular SLAM, scale definition and 3-D information are issues that can be more easily dealt with in stereo cameras. Air-SSLAM starts from computing keypoints and the correspondent descriptors over the pair of images, using good features-to-track and rotated-binary robust-independent elementary features, respectively. Then a map is created by matching each pair of right and left frames. The long-term map maintenance is continuously performed by analyzing the quality of each matching, as well as by inserting new keypoints into uncharted areas of the environment. Three main contributions can be highlighted in our method: (1) a novel method to match keypoints efficiently; (2) three quality indicators with the aim of speeding up the mapping process; and (3) map maintenance with uniform distribution performed by image zones. By using a drone equipped with a stereo camera, flying indoor, the translational average error with respect to a marked ground truth was computed, demonstrating promising results.",,10.1109/LGRS.2017.2730883,,,,Cameras;Simultaneous localization and mapping;Drones;Feature extraction;Visualization;Robot vision systems;Estimation;Drone;stereo vision;visual simultaneous localization and mapping (SLAM),,1558-0571,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,HybVIO: Pushing the Limits of Real-time Visual-inertial Odometry,O. Seiskari and P. Rantalankila and J. Kannala and J. Ylilammi and E. Rahtu and A. Solin,,2022,IEEE Index Terms,287--296,,"We present HybVIO, a novel hybrid approach for combining filtering-based visual-inertial odometry (VIO) with optimization-based SLAM. The core of our method is highly robust, independent VIO with improved IMU bias modeling, outlier rejection, stationarity detection, and feature track selection, which is adjustable to run on embedded hardware. Long-term consistency is achieved with a loosely-coupled SLAM module. In academic benchmarks, our solution yields excellent performance in all categories, especially in the real-time use case, where we outperform the current state-of-the-art. We also demonstrate the feasibility of VIO for vehicular tracking on consumer-grade hardware using a custom dataset, and show good performance in comparison to current commercial VISLAM alternatives.",,10.1109/WACV51458.2022.00036,,,,Computer vision;Simultaneous localization and mapping;Benchmark testing;Feature extraction;Real-time systems;Hardware;3D Computer Vision Stereo Processing; Vision for Aerial/Drone/Underwater/Ground Vehicles,,2642-9381,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Learning Scene Geometry for Visual Localization in Challenging Conditions,N. Piasco and D. Sidibé and V. Gouet-Brunet and C. Demonceaux,,2019,IEEE Index Terms,9094--9100,,"We propose a new approach for outdoor large scale image based localization that can deal with challenging scenarios like cross-season, cross-weather, day/night and long-term localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We are able to increase recall@1 performances by 2.15% on cross-weather and long-term localization scenario and by 4.24% points on a challenging winter/summer localization sequence versus state-of-the-art methods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images.",,10.1109/ICRA.2019.8794221,,,,Training;Decoding;Feature extraction;Robots;Image reconstruction;Geometry;Visualization,,2577-087X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,An EKF-Based Fusion of Visual-Inertial Odometry and GPS for Global Robot Pose Estimation,N. H. K. Tran and V.-H. Nguyen,,2021,IEEE Index Terms,1--5,6,"Globally accurate and drift-free pose estimation is essential for long-term navigation of autonomous robots. In this paper, we present an efficient method to fuse visual-inertial odometry and GPS measurements using the Extended Kalman Filter (EKF). The filter state is propagated by relative visual-inertial estimates and updated by absolute GPS readings to eliminate the accumulated drift on position and heading. We built the sensor hardware and implemented the algorithm on an embedded computer for real-time computation. The experimental datasets were collected in an outdoor environment with 6-degree-of-freedom ground truth. Evaluation results showed that the proposed algorithm achieved consistent and accurate pose estimation with different motion trajectories.",,10.1109/ICRAIE52900.2021.9703965,,,,Technological innovation;Three-dimensional displays;Navigation;Pose estimation;Robot sensing systems;Real-time systems;Trajectory;multi-sensor fusion;robot localization;extended Kalman filter;visual-inertial odometry;GPS,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Robust Long-Term Registration of UAV Images of Crop Fields for Precision Agriculture,N. Chebrolu and T. Läbe and C. Stachniss,IEEE Robotics and Automation Letters,2018,IEEE Index Terms,3097--3104,3,"Continuous crop monitoring is an important aspect of precision agriculture and requires the registration of sensor data over longer periods of time. Often, fields are monitored using cameras mounted on unmanned aerial vehicles (UAVs) but strong changes in the visual appearance of the growing crops and the field itself poses serious challenges to conventional image registration methods. In this letter, we present a method for registering images of agricultural fields taken by an UAV over the crop season and present a complete pipeline for computing temporally aligned three-dimensional (3-D) point clouds of the field. Our approach exploits the inherent geometry of the crop arrangement in the field, which remains mostly static over time. This allows us to register the images even in the presence of strong visual changes. To this end, we propose a scale invariant, geometric feature descriptor that encodes the local plant arrangement geometry. The experiments suggest that we are able to register images taken over the crop season, including situations where matching with an off-the-shelf visual descriptor fails. We evaluate the accuracy of our matching system with respect to manually labeled ground truth. We furthermore illustrate that the reconstructed 3-D models are qualitatively correct and the registration results allow for monitoring growth parameters at a per plant level.",,10.1109/LRA.2018.2849603,,,,Agriculture;Visualization;Three-dimensional displays;Monitoring;Geometry;Robustness;Cameras;Robotics in agriculture and forestry;SLAM,,2377-3766,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Preventing and Correcting Mistakes in Lifelong Mapping,N. Banerjee and D. Lisin and V. Albanese and Z. Zhu and S. R. Lenser and J. Shriver and T. Ramaswamy and J. Briggs and P. Fong,,2021,IEEE Index Terms,1--8,,"A Graph SLAM system is only as good as the edges in its pose graph. Critical mistakes in the generation of these edges can instantly render a map inconsistent, misleading, and ultimately unusable. For a lifelong mapping system, where the map is updated continuously, avoiding these errors altogether is infeasible. Instead, we propose a system for detection of and recovery from severe errors in edge generation. Our system remedies both edges created by view observations and edges created by an odometry motion model. For observation edges, we pair a novel method for monitoring ambiguous views with an intelligent graph-merging algorithm capable of rejecting a relocalization in progress. For motion edges, we propose a qualitative geometric approach for detecting structural aberrations characteristic of odometry failures. We conclude with an analysis of our results based on an empirical study of thousands of robot runs.",,10.1109/ECMR50962.2021.9568826,,,,Location awareness;Simultaneous localization and mapping;Image edge detection;Europe;Mobile robots;Monitoring,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,"Sensors, SLAM and Long-term Autonomy: A Review",M. Zaffar and S. Ehsan and R. Stolkin and K. M. Maier,,2018,IEEE Index Terms,285--290,,"Simultaneous Localization and Mapping, commonly known as SLAM, has been an active research area in the field of Robotics over the past three decades. For solving the SLAM problem, every robot is equipped with either a single sensor or a combination of similar/different sensors. This paper attempts to review, discuss, evaluate and compare these sensors. Keeping an eye on future, this paper also assesses the characteristics of these sensors against factors critical to the long-term autonomy challenge.",,10.1109/AHS.2018.8541483,,,,Cameras;Simultaneous localization and mapping;Sensor phenomena and characterization;Laser radar;Acoustic sensors;SLAM;Long-term Autonomy;Sensors,,2471-769X,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,A continuously learning feature-based map using a bernoulli filtering approach,M. Stübler and S. Reuter and K. Dietmayer,,2017,IEEE Index Terms,1--6,,"One of the huge challenges of map-based localization is a rapidly changing environment. The present contribution addresses this problem by first constructing a new framework for feature-based long-term mapping using a Bernoulli filter. This framework is then applied to construct a continuously learning map. It is based on Simultaneous Localization and Mapping (SLAM) to create a short-term map which provides a momentary image of the environment during one mapping run. The proposed fusion algorithm then estimates the landmark map on a long-term basis by incorporating those short-term maps. Landmarks in the long-term map that reach a negligible spatial uncertainty can then be used again as a prior for the short-term mapping process. Since a Bernoulli filter can only handle a single object, independent groups of landmarks are constructed where only those with exactly one landmark are updated. As a result, landmarks that are part of the long-term map are quite distinct. By incorporating additional but probably outdated a priori information, the proposed method is able to restrict the inevitable error propagation of SLAM algorithms. The long-term mapping process is further distributable to several agents: every agent simultaneously localizes itself while it generates a new snapshot that is fused into the long-term map afterwards. An evaluation using real-world data completes this contribution.",,10.1109/SDF.2017.8126353,,,,Simultaneous localization and mapping;Markov processes;Time measurement;Mathematical model;Atmospheric measurements;Particle measurements,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Tightly-Coupled Monocular Visual-Odometric SLAM Using Wheels and a MEMS Gyroscope,M. Quan and S. Piao and M. Tan and S.-S. Huang,IEEE Access,2019,IEEE Index Terms,97374--97389,7,"In this paper, we present a novel tightly coupled probabilistic monocular visual-odometric simultaneous localization and mapping (VOSLAM) algorithm using wheels and a MEMS gyroscope, which can provide accurate, robust, and long-term localization for ground robots. First, we present a novel odometer preintegration theory on manifold; it integrates the wheel encoder measurements and gyroscope measurements to a relative motion constraint that is independent of the linearization point and carefully addresses the uncertainty propagation and gyroscope bias correction. Based on the preintegrated odometer measurement model, we also introduce the odometer error term and tightly integrate it into the visual optimization framework. Then, in order to bootstrap the VOSLAM system, we propose a simple map initialization method. Finally, we present a complete localization mechanism to maximally exploit both sensing cues, which provides different strategies for motion tracking when: 1) both measurements are available; 2) visual measurements are not available; and 3) wheel encoders experience slippage, thereby ensuring the accurate and robust motion tracking. The proposed algorithm is evaluated by performing extensive experiments, and the experimental results demonstrate the superiority of the proposed system.",,10.1109/ACCESS.2019.2930201,,,,Wheels;Visualization;Simultaneous localization and mapping;Motion measurement;Optimization;Motion estimation;sensor fusion;simultaneous localization and mapping,,2169-3536,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Appearance-Based Loop Closure Detection for Online Large-Scale and Long-Term Operation,M. Labbé and F. Michaud,IEEE Transactions on Robotics,2013,IEEE Index Terms,734--745,29,"In appearance-based localization and mapping, loop-closure detection is the process used to determinate if the current observation comes from a previously visited location or a new one. As the size of the internal map increases, so does the time required to compare new observations with all stored locations, eventually limiting online processing. This paper presents an online loop-closure detection approach for large-scale and long-term operation. The approach is based on a memory management method, which limits the number of locations used for loop-closure detection so that the computation time remains under real-time constraints. The idea consists of keeping the most recent and frequently observed locations in a working memory (WM) that is used for loop-closure detection, and transferring the others into a long-term memory (LTM). When a match is found between the current location and one stored in WM, associated locations that are stored in LTM can be updated and remembered for additional loop-closure detections. Results demonstrate the approach's adaptability and scalability using ten standard datasets from other appearance-based loop-closure approaches, one custom dataset using real images taken over a 2-km loop of our university campus, and one custom dataset (7 h) using virtual images from the racing video game “Need for Speed: Most Wanted”.",,10.1109/TRO.2013.2242375,,,,Vocabulary;Feature extraction;Robots;Memory management;Real-time systems;Bayesian methods;Visualization;Appearance-based localization and mapping;bag-of-words approach;dynamic Bayes filtering;place recognition,,1941-0468,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,"Toward long-term, automated ship hull inspection with visual SLAM, explicit surface optimization, and generic graph-sparsification",P. Ozog and R. M. Eustice,,2014,IEEE Abstract,3832--3839,,"This paper reports on a method for an autonomous underwater vehicle to perform real-time visual simultaneous localization and mapping (SLAM) on large ship hulls over multiple sessions. Along with a monocular camera, our method uses a piecewise-planar model to explicitly optimize the ship hull surface in our factor-graph framework, and anchor nodes to co-register multiple surveys. To enable realtime performance for long-term SLAM, we use the recent Generic Linear Constraints (GLC) framework to sparsify our factor-graph. This paper analyzes how our single-session SLAM techniques can be used in the GLC framework, and describes a particle filter reacquisition algorithm so that an underwater session can be automatically re-localized to a previously built SLAM graph. We provide real-world experimental results involving automated ship hull inspection, and show that our localization filter out-performs Fast Appearance-Based Mapping (FAB-MAP), a popular place-recognition system. Using our approach, we can automatically align surveys that were taken days, months, and even years apart.",,10.1109/ICRA.2014.6907415,,,,Simultaneous localization and mapping;Marine vehicles;Visualization;Cameras;Sonar navigation,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,SLAM-Loop Closing with Visually Salient Features,P. Newman and K. Ho,,2005,IEEE Abstract,635--642,,"Within the context of Simultaneous Localisation and Mapping (SLAM), “loop closing” is the task of deciding whether or not a vehicle has, after an excursion of arbitrary length, returned to a previously visited area. Reliable loop closing is both essential and hard. It is without doubt one of the greatest impediments to long term, robust SLAM. This paper illustrates how visual features, used in conjunction with scanning laser data, can be used to a great advantage. We use the notion of visual saliency to focus the selection of suitable (affine invariant) image-feature descriptors for storage in a database. When queried with a recently taken image the database returns the capture time of matching images. This time information is used to discover loop closing events. Crucially this is achieved independently of estimated map and vehicle location. We integrate the above technique into a SLAM algorithm using delayed vehicle states and scan matching to form interpose geometric constraints. We present initial results using this system to close loops (around 100m) in an indoor environment.",,10.1109/ROBOT.2005.1570189,,,,Simultaneous localization and mapping;Vehicles;Image storage;Image databases;Spatial databases;Visual databases;Impedance;Robustness;Focusing;Delay;Mobile Robotics;SLAM;Loop Closing;Saliency;Visual Features,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"Automating answers to ""where am i?""",P. Newman,,2005,IEEE Abstract,7pp.--,,"In many situations, large-scale, long term deployment of an autonomous vehicle requires an ability to navigate in arbitrary workspaces and must be able to establish ""where am I what surrounds me?"". This paper describe simultaneous localisation and mapping (SLAM)techniques and implementations in which an autonomous vehicle explores its workspace using onboard sensors and inextricably binds together the tasks of mapping and localisation.",,10.1049/ic:20050473,,,,,,0537-9989,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Network Uncertainty Informed Semantic Feature Selection for Visual SLAM,P. Ganti and S. L. Waslander,,2019,IEEE Abstract,121--128,,"In order to facilitate long-term localization using a visual simultaneous localization and mapping (SLAM) algorithm, careful feature selection can help ensure that reference points persist over long durations and the runtime and storage complexity of the algorithm remain consistent. We present SIVO (Semantically Informed Visual Odometry and Mapping), a novel information-theoretic feature selection method for visual SLAM which incorporates semantic segmentation and neural network uncertainty into the feature selection pipeline. Our algorithm selects points which provide the highest reduction in Shannon entropy between the entropy of the current state and the joint entropy of the state, given the addition of the new feature with the classification entropy of the feature from a Bayesian neural network. Each selected feature significantly reduces the uncertainty of the vehicle state and has been detected to be a static object (building, traffic sign, etc.) repeatedly with a high confidence. This selection strategy generates a sparse map which can facilitate long-term localization. The KITTI odometry dataset is used to evaluate our method, and we also compare our results against ORB_SLAM2. Overall, SIVO performs comparably to the baseline method while reducing the map size by almost 70%.",,10.1109/CRV.2019.00024,,,,Simultaneous localization and mapping;Feature extraction;Uncertainty;Artificial neural networks;Semantics;Entropy;Visualization;Localization;Mapping;SLAM;Deep Learning;Information Theory;Semantic Segmentation,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,"PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization",P. Egger and P. V. K. Borges and G. Catt and A. Pfrunder and R. Siegwart and R. Dubé,,2018,IEEE Abstract,3430--3437,,"Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.",,10.1109/IROS.2018.8593854,,,,Simultaneous localization and mapping;Three-dimensional displays;Laser radar;Optimization;Feature extraction,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Switchable constraints vs. max-mixture models vs. RRR - A comparison of three approaches to robust pose graph SLAM,N. Sünderhauf and P. Protzel,,2013,IEEE Abstract,5198--5203,,"SLAM algorithms that can infer a correct map despite the presence of outliers have recently attracted increasing attention. In the context of SLAM, outlier constraints are typically caused by a failed place recognition due to perceptional aliasing. If not handled correctly, they can have catastrophic effects on the inferred map. Since robust robotic mapping and SLAM are among the key requirements for autonomous long-term operation, inference methods that can cope with such data association failures are a hot topic in current research. Our paper compares three very recently published approaches to robust pose graph SLAM, namely switchable constraints, max-mixture models and the RRR algorithm. All three methods were developed as extensions to existing factor graph-based SLAM back-ends and aim at improving the overall system's robustness to false positive loop closure constraints. Due to the novelty of the three proposed algorithms, no direct comparison has been conducted so far.",,10.1109/ICRA.2013.6631320,,,,Switches;Simultaneous localization and mapping;Trajectory;Robustness;Optimization;Measurement;Cities and towns,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,A metric approach for environments mapping,N. Slimane and M. S. Khireddine and K. Chafaa,,2013,IEEE Abstract,647--652,,"One of the main issues in mobile robotics is the autonomous navigation of a mobile robot in an unknown environment. Concurrent mapping and localisation or simultaneous localisation and mapping is a stochastic map building method which permits consistent robot navigation without requiring an a priori map. The governing idea which guides autonomous robotics consists in saying that the vehicle builds its chart progressively during exploration enabling it to evolve in the long term in unknown places in advance. When the robot environment chart is not known a priori, a generation module of incremental chart must obligatorily be integrated into the navigation system. The map is built incrementally as the robot observes the environment with its on-board sensors and, at the same time, is used to localise the robot. Unfortunately, the inaccuracy of the odometric sensors does not allow a sufficiently correct positioning of the robot. In this paper, simultaneous localisation and map building is performed with a metric approach which permits both precision and robustness. The most important innovation of the approach is the way how errors in the robot localisation control are handled by map building using the landmarks localisation information. The method uses data from a laser scanner to extract distances and orientations of landmarks and combines control localisation and metric paradigm. The metric approach, based on the Kalman filter, uses a new concept to avoid the problem of the drift in odometry. The simulation section will validate the maps representation approach and presents different aspect of environments.",,10.1109/CoDIT.2013.6689619,,,,Robot sensing systems;Covariance matrices;Measurement;Vehicles;Vectors;Buildings;Map building;metric chart;real-time control;mobile robot localisation;extended Kalman filter;landmarks detection,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Tightly Coupled Semantic RGB-D Inertial Odometry for Accurate Long-Term Localization and Mapping,N. Patel and F. Khorrami and P. Krishnamurthy and A. Tzes,,2019,IEEE Abstract,523--528,,"In this paper, we utilize semantically enhanced feature matching and visual inertial bundle adjustment to improve the robustness of odometry especially in feature-sparse environments. A novel semantically enhanced feature matching algorithm is developed for robust: 1) medium and long-term tracking, and 2) loop-closing. Additionally, a semantic visual inertial bundle adjustment algorithm is introduced to robustly estimate pose in presence of ambiguous correspondences or in feature sparse environment. Our tightly coupled semantic RGB-D odometry approach is demonstrated on a real world indoor dataset collected using our unmanned ground vehicle (UGV). Our approach improves traditional visual odometry relying on low-level geometric features like corners, points, and planes for localization and mapping. Additionally, prior approaches are limited due to their sensitivity to scene geometry and changes in light intensity. The semantic inertial odometry is especially important to significantly reduce drifts in longer intervals.",,10.1109/ICAR46387.2019.8981658,,,,,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Long-term simultaneous localization and mapping with generic linear constraint node removal,N. Carlevaris-Bianco and R. M. Eustice,,2013,IEEE Abstract,1034--1041,,"This paper reports on the use of generic linear constraint (GLC) node removal as a method to control the computational complexity of long-term simultaneous localization and mapping. We experimentally demonstrate that GLC provides a principled and flexible tool enabling a wide variety of complexity management schemes. Specifically, we consider two main classes: batch multi-session node removal, in which nodes are removed in a batch operation between mapping sessions, and online node removal, in which nodes are removed as the robot operates. Results are shown for 34.9 h of real-world indoor-outdoor data covering 147.4 km collected over 27 mapping sessions spanning a period of 15 months.",,10.1109/IROS.2013.6696478,,,,Simultaneous localization and mapping;Approximation methods;Computational complexity;Markov processes,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Lifelong Mapping using Adaptive Local Maps,N. Banerjee and D. Lisin and J. Briggs and M. Llofriu and M. E. Munich,,2019,IEEE Abstract,1--8,,"Occupancy mapping enables a mobile robot to make intelligent planning decisions to accomplish its tasks. Adaptive local maps is an algorithm which represents the occupancy information as a set of overlapping local maps anchored to poses in the robot's trajectory. At any time, a global occupancy map can be rendered from the local maps to be used for path planning. The advantage of this approach is that the occupancy information stays consistent despite the changes in the pose estimates resulting from loop closures and localization updates. The disadvantage, however, is that the number of local maps grows over time. For long robot runs, or for multiple runs in the same space, this growth will result in redundant occupancy information, which will in turn increase the time it takes to render the global map, as well as the memory footprint of the system. In this paper, we propose a novel approach for the maintenance of an adaptive local maps system, which intelligently prunes redundant local maps, ensuring the robustness and stability required for lifelong mapping.",,10.1109/ECMR.2019.8870347,,,,Simultaneous localization and mapping;Uncertainty;Mobile robots;Trajectory,,,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,A General Framework for Lifelong Localization and Mapping in Changing Environment,M. Zhao and X. Guo and L. Song and B. Qin and X. Shi and G. H. Lee and G. Sun,,2021,IEEE Abstract,3305--3312,,"The environment of most real-world scenarios such as malls and supermarkets changes at all times. A pre-built map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-to-date model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efficient map updating strategy that includes map building, pose graph refinement and sparsification. To mitigate the unbounded increase of memory usage, we propose a map-trimming method based on the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.",,10.1109/IROS51168.2021.9635985,,,,Location awareness;Simultaneous localization and mapping;Buildings;Intelligent robots,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Efficient Long-term Mapping in Dynamic Environments,M. T. Lázaro and R. Capobianco and G. Grisetti,,2018,IEEE Abstract,153--160,,"As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.",,10.1109/IROS.2018.8594310,,,,Simultaneous localization and mapping;Cloud computing;Three-dimensional displays;Two dimensional displays;Merging;Optimization,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Bridging the appearance gap: Multi-experience localization for long-term visual teach and repeat,M. Paton and K. MacTavish and M. Warren and T. D. Barfoot,,2016,IEEE Abstract,1918--1925,,"Vision-based, route-following algorithms enable autonomous robots to repeat manually taught paths over long distances using inexpensive vision sensors. However, these methods struggle with long-term, outdoor operation due to the challenges of environmental appearance change caused by lighting, weather, and seasons. While techniques exist to address appearance change by using multiple experiences over different environmental conditions, they either provide topological-only localization, require several manually taught experiences in different conditions, or require extensive offline mapping to produce metric localization. For real-world use, we would like to localize metrically to a single manually taught route and gather additional visual experiences during autonomous operations. Accordingly, we propose a novel multi-experience localization (MEL) algorithm developed specifically for route-following applications; it provides continuous, six-degree-of-freedom (6DoF) localization with relative uncertainty to a privileged (manually taught) path using several experiences simultaneously. We validate our algorithm through two experiments: i) an offline performance analysis on a 9km subset of a challenging 27km route-traversal dataset and ii) an online field trial where we demonstrate autonomy on a small 250m loop over the course of a sunny day. Both exhibit significant appearance change due to lighting variation. Through these experiments we show that safe localization can be achieved by bridging the appearance gap.",,10.1109/IROS.2016.7759303,,,,Measurement;Visualization;Lighting;Uncertainty;Sensors;Robot kinematics,,2153-0866,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,R-LOAM: Improving LiDAR Odometry and Mapping With Point-to-Mesh Features of a Known 3D Reference Object,M. Oelsch and M. Karimi and E. Steinbach,IEEE Robotics and Automation Letters,2021,IEEE Abstract,2068--2075,6,"LiDAR-based odometry and mapping is used in many robotic applications to retrieve the robot's position in an unknown environment and allows for autonomous operation in GPS-denied (e.g., indoor) environments. With a 3D LiDAR sensor, highly accurate localization becomes possible, which enables high quality 3D reconstruction of the environment. In this letter we extend the well-known LOAM framework by leveraging prior knowledge about a reference object in the environment to further improve the localization accuracy. This requires a known 3D model of the reference object and its known position in a global coordinate frame. Instead of only relying on the point features in the mapping module of LOAM, we also include mesh features extracted from the 3D triangular mesh of the reference object in the optimization problem. For fast correspondence computation of mesh features, we use the Axis-Aligned-Bounding-Box-Tree (AABB) structure. Essentially, our approach not only makes use of the previously built map for absolute localization in the environment, but also takes the relative position to the reference object into account, effectively reducing long-term drift. To validate the proposed concept, we generated datasets using the Gazebo simulation environment in exemplary visual inspection scenarios of an airplane inside a hangar and the Eiffel Tower. An actuated 3D LiDAR sensor is mounted via a 1-DoF gimbal on a UAV capturing 360° scans. We benchmark our approach against the state-of-the-art open-source LOAM framework. The results show that the proposed joint optimization using both point and mesh features yields a significant reduction in Absolute Pose Error (APE) and therefore improves the map and 3D reconstruction quality during long-term operations.",,10.1109/LRA.2021.3060413,,,,Three-dimensional displays;Location awareness;Laser radar;Robot sensing systems;Optimization;Simultaneous localization and mapping;Feature extraction;SLAM;localization;mapping;range sensing,,2377-3766,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Will It Last? Learning Stable Features for Long-Term Visual Localization,M. Dymczyk and E. Stumm and J. Nieto and R. Siegwart and I. Gilitschenski,,2016,IEEE Index Terms,572--581,,"An increasing number of simultaneous localization and mapping (SLAM) systems are using appearance-based localization to improve the quality of pose estimates. However, with the growing time-spans and size of the areas we want to cover, appearance-based maps are often becoming too large to handle and are consisting of features that are not always reliable for localization purposes. This paper presents a method for selecting map features that are persistent over time and thus suited for long-term localization. Our methodology relies on a CNN classifier based on image patches and depth maps for recognizing which features are suitable for life-long matchability. Thus, the classifier not only considers the appearance of a feature but also takes into account its expected lifetime. As a result, our feature selection approach produces more compact maps with a high fraction of temporally-stable features compared to the current state-of-the-art, while rejecting unstable features that typically harm localization. Our approach is validated on indoor and outdoor datasets, that span over a period of several months.",,10.1109/3DV.2016.66,,,,Feature extraction;Three-dimensional displays;Simultaneous localization and mapping;Training;Reliability;Visualization;Buildings;localization;place recognition;feature selection;SLAM;CNN;machine learning;mapping,,,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Environment selection and hierarchical place recognition,M. Mohan and D. Gálvez-López and C. Monteleoni and G. Sibley,,2015,IEEE Abstract,5487--5494,,"As robots continue to create long-term maps, the amount of information that they need to handle increases over time. In terms of place recognition, this implies that the number of images being considered may increase until exceeding the computational resources of the robot. In this paper we consider a scenario where, given multiple independent large maps, possibly from different cities or locations, a robot must effectively and in real time decide whether it can localize itself in one of those known maps. Since the number of images to be handled by such a system is likely to be extremely large, we find that it is beneficial to decompose the set of images into independent groups or environments. This raises a new question: Given a query image, how do we select the best environment? This paper proposes a similarity criterion that can be used to solve this problem. It is based on the observation that, if each environment is described in terms of its co-occurrent features, similarity between environments can be established by comparing their co-occurrence matrices. We show that this leads to a novel place recognition algorithm that divides the collection of images into environments and arranges them in a hierarchy of inverted indices. By selecting first the relevant environment for the operating robot, we can reduce the number of images to perform the actual loop detection, reducing the execution time while preserving the accuracy. The practicality of this approach is shown through experimental results on several large datasets covering a combined distance of more than 750Km.",,10.1109/ICRA.2015.7139966,,,,Indexes;Vocabulary;Kernel;Accuracy;Visualization;Robots,,1050-4729,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
,Map Management for Efficient Long-Term Visual Localization in Outdoor Environments,M. Bürki and M. Dymczyk and I. Gilitschenski and C. Cadena and R. Siegwart and J. Nieto,,2018,IEEE Index Terms,682--688,,"We present a complete map management process for a visual localization system designed for multi-vehicle long-term operations in resource constrained outdoor environments. Outdoor visual localization generates large amounts of data that need to be incorporated into a lifelong visual map in order to allow localization at all times and under all appearance conditions. Processing these large quantities of data is non-trivial, as it is subject to limited computational and storage capabilities both on the vehicle and on the mapping backend. We address this problem with a two-fold map update paradigm capable of, either, adding new visual cues to the map, or updating co-observation statistics. The former, in combination with offline map summarization techniques, allows enhancing the appearance coverage of the lifelong map while keeping the map size limited. On the other hand, the latter is able to significantly boost the appearance-based landmark selection for efficient online localization without incurring any additional computational or storage burden. Our evaluation in challenging outdoor conditions shows that our proposed map management process allows building and maintaining maps for precise visual localization over long time spans in a tractable and scalable fashion.",,10.1109/IVS.2018.8500432,,,,Visualization;Buildings;Robot sensing systems;Autonomous automobiles;Maintenance engineering;Bandwidth;Intelligent vehicles,,1931-0587,,,,44698.62163,44698.62163,sousarbarb,,Unclassified,
,Global localization using multiple hypothesis tracking: A real-world approach,M. Lutz and S. Hochdorfer and C. Schlegel,,2011,IEEE Abstract,127--132,,"Life-long and robust operation are important challenges to be solved towards everyday usability of service robots. Global localization is of particular interest for real-world applications. If a robot would not be able to relocalize itself within a known map, all positions stored by the robot (rooms, objects, etc.) would become obsolete. Although Simultaneous Localization and Mapping (SLAM) allows to initially map new and unknown environments and to keep track of environmental changes, it does not solve the global localization problem. Each time SLAM is restarted at different locations, it introduces a new map and a new frame of reference. In this paper, we propose a solution to the global localization problem which uses a SLAM generated feature map. The approach is demonstrated with an omnicam and bearing-only features. A new way to weight hypotheses and to sort out false hypotheses results in fast convergence even with arbitrary relocalization paths. The combined approach is a further step towards life-long operation of service robots and covers every part of a robot lifecycle, ranging from a setup via SLAM to efficient global localization for reuse of maps and object poses after restart.",,10.1109/TEPRA.2011.5753494,,,,Simultaneous localization and mapping;Uncertainty;Robot kinematics;Kalman filters;Estimation,,2325-0534,,,,44698.62116,44698.62116,sousarbarb,,Unclassified,
