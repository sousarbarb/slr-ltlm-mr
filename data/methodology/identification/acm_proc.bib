@ARTICLE{10.1287/opre.1120.1076,
  journal = {Oper. Res.},
  title = {Contributors},
  volume = {60},
  number = {2},
  pages = {501--504},
  doi = {10.1287/opre.1120.1076},
  publisher = {INFORMS},
  address = {Linthicum, MD, USA},
  year = {2012},
  month = {3},
  abstract = {Ivo Adan (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/475">Exact FCFS Matching Rates for Two Infinite Multitype Sequences</ext-link>”) is a full professor of manufacturing networks in the Department of Mechanical Engineering at the Eindhoven University of Technology. His current research focuses on the modeling, analysis, and design of manufacturing, warehousing, and healthcare systems, and more specifically, the analysis of multidimensional Markov processes and queueing models.Alper Atamt\"{u}rk (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/366">A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems</ext-link>”) is a Chancellor's Professor in the Industrial Engineering and Operations Research Department at the University of California, Berkeley. His current research interests are in optimization, integer programming, optimization under uncertainty with applications to energy, finance, operations, cancer therapy, and defense. He was appointed a National Security Fellow by the United States Department of Defense in 2010.Rami Atar (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/490">A Diffusion Regime with Nondegenerate Slowdown</ext-link>”) is a professor in the Department of Electrical Engineering, Technion, Israel. His research interests are in stochastic processes. These include asymptotic analysis of queueing and stochastic network models in diffusion and large deviation regimes, PDE techniques in stochastic control and differential games, filtering, and estimation.Derek Atkins (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/249">A Simulation Optimization Approach to Long-Term Care Capacity Planning</ext-link>”) is a professor in the Sauder School of Business at the University of British Columbia, Canada. His research interests are in supply chains and healthcare operations. He was formerly director of the Centre for Operations Excellence at Sauder, which undertook a project for a local health authority that triggered the need for the paper presented in this issue. Gemma Berenguer (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/366">A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems</ext-link>”) is a Ph.D. candidate in the Industrial Engineering and Operations Research Department at the University of California, Berkeley. She is doing research on integrated supply chain design problems, nonprofit supply chain management problems, and the design of regulatory mechanisms for environmental policies.Ya Ping Fang (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/398">Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization</ext-link>”) is an associate professor in the Department of Mathematics at Sichuan University. His research interests are in the area of optimization problems, equilibrium problems, and variational inequalities.Michael C. Fu (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/447">A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives</ext-link>”) is the Ralph J. Tyser Professor of Management Science in the Robert H. Smith School of Business at the University of Maryland. His research interests include simulation and applied probability modeling, particularly with applications toward manufacturing systems, supply chain management, and financial engineering. He is a Fellow of INFORMS and IEEE.David Gamarnik (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/410">Belief Propagation for Min-Cost Network Flow: Convergence and Correctness</ext-link>”) is an associate professor of operations research at the Sloan School of Management at the Massachusetts Institute of Technology. His research interests include applied probability and stochastic processes, theory of random graphs and algorithms, combinatorial optimization, statistical learning theory, and various applications. He is a recipient of the Erlang Prize from the INFORMS Applied Probability Society, IBM Faculty Partnership Award, and several NSF-sponsored grants.Nir Halman (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/429">Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle</ext-link>”) is a lecturer of operations research in the school of business administration at the Hebrew University of Jerusalem. His research focuses on optimization methods that yield efficient algorithms in combinatorial optimization.Jonathan Kluberg (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/335">Generalized Quantity Competition for Multiple Products and Loss of Efficiency</ext-link>”) is an investment analyst at High Vista Strategies.Yuri Levin (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/351">Cargo Capacity Management with Allotments and Spot Market Demand</ext-link>”) is a Distinguished Professor of Operations Management at Queen's School of Business in Kingston, Ontario, Canada. His research interests include revenue management, dynamic pricing, numerical optimization, and machine learning applications.Qing Li (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/286">On the Quasiconcavity of Lost-Sales Inventory Models with Fixed Costs</ext-link>”) is an associate professor at the School of Business and Management, Hong Kong University of Science and Technology. His research interests include supply chain management, marketing/operations interfaces, stochastic dynamic inventory models, and economics of waste. Steven I. Marcus (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/447">A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives</ext-link>”) is a professor in the Department of Electrical and Computer Engineering and the Institute for Systems Research at the University of Maryland. His research focuses on stochastic control and estimation, with applications in manufacturing and telecommunication networks.Kaiwen Meng (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/398">Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization</ext-link>”) holds a Ph.D. degree (2011) in optimization and operations research from the Hong Kong Polytechnic University. His research interests are in the areas of variational analysis, optimization theory, and operations research. S. Michel (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/382">A Column-Generation Based Tactical Planning Method for Inventory Routing</ext-link>”) is an assistant professor of operations research at Le Havre University. She is a member of the Laboratory of Applied Mathematics and the Logistics Engineering Institute and an associate member of the INRIA research team REALOPT. Her research projects concern sea ship and vehicle routing, as well as generic primal heuristics.Anton Molyboha (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/292">Stochastic Optimization of Sensor Placement for Diver Detection</ext-link>”) is a quantitative analyst at Teza Technologies. He holds a Ph.D. degree in mathematics with concentration in stochastic systems (2009) from the Department of Mathematical Sciences at Stevens Institute of Technology.Mikhail Nediak (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/351">Cargo Capacity Management with Allotments and Spot Market Demand</ext-link>”) is an assistant professor in the School of Business at Queen's University in Kingston, Ontario, Canada. His research focuses on new models in revenue management and dynamic pricing.Matthew Nelson (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/249">A Simulation Optimization Approach to Long-Term Care Capacity Planning</ext-link>”) is a project lead in the Centre for Research in Healthcare Engineering at the University of Toronto. He received his master's degree from the Centre for Operations Excellence in the Sauder School of Business at the University of British Columbia. James B. Orlin (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/429">Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle</ext-link>”) is the Edward Pennell Brooks Professor of Operations Research in the Sloan School of Management at the Massachusetts Institute of Technology. His research focuses on optimization methods, especially in combinatorial and network optimization. He is a coauthor of Network Flows: Theory, Algorithms, and Applications (Prentice-Hall, 1993), for which he was awarded the Lanchester Prize in 1993. He is an INFORMS Fellow.Georgia Perakis (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/335">Generalized Quantity Competition for Multiple Products and Loss of Efficiency</ext-link>”) is the William F. Pounds Professor at the Sloan School of Management at Massachusetts Institute of Technology.Dzung T. Phan (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/275">Lagrangian Duality and Branch-and-Bound Algorithms for Optimal Power Flow</ext-link>”) is a research staff member in the Mathematical Sciences Department at IBM T. J. Watson Research Center, Yorktown Heights, New York, where he spent one year as a postdoctoral researcher. His research interests lie in the field of optimization theory and algorithms. Recently at IBM, he developed several numerical algorithms for optimization problems arising from power system analysis. Martin L. Puterman (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/249">A Simulation Optimization Approach to Long-Term Care Capacity Planning</ext-link>”) is Advisory Board Professor of Operations in the Sauder School of Business at the University of British Columbia, Canada. He was founder and director of the Centre for Operations Excellence (in Sauder), the UBC Centre for Health Care Management, and the Biostatistical Consulting Service at BC Children's Hospital. He received the INFORMS Lanchester Prize for his book Markov Decision Processes: Discrete Stochastic Dynamic Programming (Wiley-Interscience, 2005). He is an INFORMS Fellow and recipient of the Canadian Operations Research Society (CORS) Award of Merit, the CORS Practice Prize, and the INFORMS case prize. Richard Ratliff (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/313">Estimating Primary Demand for Substitutable Products from Sales Transaction Data</ext-link>”) is the Senior Research Scientist at Sabre Research. His primary focus is on applied research and development in travel revenue management. His work has included prototyping new technologies applicable to travel distribution, as well as major travel suppliers.Devavrat Shah (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/410">Belief Propagation for Min-Cost Network Flow: Convergence and Correctness</ext-link>”) is a Jamieson career development associate professor in the Department of Electrical Engineering and Computer Science at Massachusetts Institute of Technology. He is a member of the Laboratory for Information and Decision Systems and Operations Research Center. His research focus is on theory of large complex networks and includes network algorithms, stochastic networks, network information theory, and large-scale statistical inference. He received the George B. Dantzig Dissertation Award from INFORMS in 2005, the ACM SIGMETRICS Rising Star Award in 2008, and the Erlang Prize from INFORMS in 2010.Zuo-Jun (Max) Shen (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/366">A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems</ext-link>”) is a Chancellors Professor of Industrial Engineering and Operations Research at the University of California, Berkeley. He has been active in the following research areas: integrated supply chain design and management, market mechanism design, marketing-operations management interface issues, and decision making with limited information. David Simchi-Levi (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/429">Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle</ext-link>”) is a professor of engineering systems at Massachusetts Institute of Technology. The work described in this paper is part of a larger research project that deals with effective supply chain and procurement strategies that improve supply chain performance.James E. Smith (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/262">Technology Adoption with Uncertain Future Costs and Quality</ext-link>”) is J. B. Fuqua Professor of Business Administration at the Fuqua School of Business, Duke University. His research interests are primarily in decision analysis and focus on developing methods for formulating and solving dynamic decision problems and valuing risky investments. He is an INFORMS Fellow and past president of the Decision Analysis Society.Huseyin Topaloglu (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/351">Cargo Capacity Management with Allotments and Spot Market Demand</ext-link>”) is an associate professor in the School of Operations Research and Information Engineering at Cornell University. His research interests include stochastic programming and optimal control with applications in revenue management, pricing, and inventory control.Canan Ulu (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/262">Technology Adoption with Uncertain Future Costs and Quality</ext-link>”) is an assistant professor in the Department of Information, Risk, and Operations Management (IROM) at the McCombs School of Business, University of Texas at Austin. Her research interests include Bayesian learning in sequential decision problems and the impact of behavioral decision theory on decision analysis methods. F. Vanderbeck (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/382">A Column-Generation Based Tactical Planning Method for Inventory Routing</ext-link>”) is a professor in the Department of Mathematics at the University of Bordeaux. He is a affiliated with the Institute of Mathematics of Bordeaux and the INRIA research center where he leads the research team REALOPT specializing in reformulation and algorithms for combinatorial optimization. His main activity is in decomposition approaches in integer programming with applications in routing and operation planning. He develops a branch-and-price platform named BAPCOD.Johan S. H. van Leeuwaarden (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/461">Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics</ext-link>”) is an associate professor of probability theory and stochastic networks at the Eindhoven University of Technology and a research fellow at the research institute EURANDOM. He received the INFORMS Telecommunication Dissertation Award (2008), a Veni Grant (2006--2009) from the Netherlands Organisation for Scientific Research, and a Starting Grant (2010--2015) from the European Research Council.Garrett van Ryzin (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/313">Estimating Primary Demand for Substitutable Products from Sales Transaction Data</ext-link>”) is Paul M. Montrone Professor of Business and Chair of the Decision, Risk, and Operations Division at Columbia Business School. His research interests include revenue management, consumer behavior modeling, operations management, and stochastic optimization.Gustavo Vulcano (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/313">Estimating Primary Demand for Substitutable Products from Sales Transaction Data</ext-link>”) is an associate professor at the Leonard N. Stern School of Business at New York University. His research interests are primarily in revenue management, including pricing mechanisms and capacity control. This paper is part of his current research on customer choice and strategic consumer behavior.Yongqiang Wang (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/447">A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives</ext-link>”) is a research associate in the Department of Electrical and Computer Engineering and the Institute for Systems Research at the University of Maryland. He received the 2010 INFORMS Computing Society Student Paper Award and the 2010 Winter Simulation Best Student Paper Award. His research interests lie in the areas of simulation optimization, Markov decision process, and stochastic control, with applications toward supply chain management and financial engineering.Yehua Wei (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/410">Belief Propagation for Min-Cost Network Flow: Convergence and Correctness</ext-link>”) is a Ph.D student in the Operations Research Center at the Massachusetts Institute of Technology. His research interests include the design of process flexibility and optimization of supply chains. He has also worked in the area of distributed algorithms, including belief propagation and divide and conquer algorithms.Gideon Weiss (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/475">Exact FCFS Matching Rates for Two Infinite Multitype Sequences</ext-link>”) is a professor of statistics and operations research in the Department of Statistics at the University of Haifa, Israel. His current research focuses on scheduling and control of processing networks, with applications to manufacturing, communications, and service systems. In particular, he is studying fluid approximations to queueing networks, and simplex algorithms for continuous, infinite dimensional linear programs.Xiao Qi Yang (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/398">Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization</ext-link>”) is a professor in the Department of Applied Mathematics at the Hong Kong Polytechnic University. His research interests are in the areas of variational analysis, multicriteria optimization, and financial optimization.Peiwen Yu (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/286">On the Quasiconcavity of Lost-Sales Inventory Models with Fixed Costs</ext-link>”) is a Ph.D. candidate in the School of Business and Management at the Hong Kong University of Science and Technology. His main research interests include inventory management and optimization. He received a B.S. degree in mathematics from the University of Science and Technology of China.Michael Zabarankin (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/292">Stochastic Optimization of Sensor Placement for Diver Detection</ext-link>”) is an associate professor in the Department of Mathematical Sciences at Stevens Institute of Technology.Bo Zhang (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/461">Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics</ext-link>”) received his Ph.D. degree from Georgia Institute of Technology in 2011 and is a research staff member in the Business Analytics and Mathematical Sciences Department at the IBM T. J. Watson Research Center. He is broadly interested in decision making under uncertainty in various application domains, with an emphasis on stochastic modeling, analysis, and optimization. His research has won the first place in the 2010 INFORMS Nicholson Student Paper Competition and the Best Student Paper award at the 28th International Symposium on Computer Performance, Modeling, Measurements, and Evaluation.Yue Zhang (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/249">A Simulation Optimization Approach to Long-Term Care Capacity Planning</ext-link>”) is an assistant professor of operations management in the College of Business and Innovation at the University of Toledo. His research interests include service and healthcare operations, location analysis and network design, logistics and transportation, and simulation optimization. The paper in this issue is part of his postdoctoral research at the Sauder School of Business, University of British Columbia. Bert Zwart (“<ext-link ext-link-type="uri" xmlns:xlink="http://www.w3.org/1999/xlink" xlink="http://or.journal.informs.org/cgi/content/abstract/60/2/461">Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics</ext-link>”) is with the Center of Mathematics and Computer Science in Amsterdam, where he leads the Probability and Stochastic Networks Group. He is a professor at VU University Amsterdam. His honors include an IBM Faculty Award, the Erlang Prize, and VENI and VIDI awards from the Dutch Science Foundation.},
  authors = {},
  issn = {0030-364X},
  issue_date = {03-04 2012},
  numpages = {4},
  url = {https://doi.org/10.1287/opre.1120.1076},
}

@INPROCEEDINGS{andreopoulos-tsotsos:2008:23,
  author = {A. Andreopoulos and J. K. Tsotsos},
  booktitle = {Proceedings of the 2008 Canadian Conference on Computer and Robot Vision},
  title = {Active Vision for Door Localization and Door Opening Using Playbot: A Computer Controlled Wheelchair for People with Mobility Impairments},
  pages = {3--10},
  doi = {10.1109/CRV.2008.23},
  publisher = {IEEE Computer Society},
  address = {USA},
  year = {2008},
  abstract = {Playbot [1, 13] is a long-term, large-scale research project, whose goal is to provide a vision-based computer controlled wheelchair that enables children and adults with mobility impairments to become more independent. Within this context, we show how Playbot can actively search an indoor environment to localize a door, approach the door, use a mounted robotic arm to open the door, and go through the door, using exclusively vision-based sensors and without using a map of the environment. We demonstrate the effectiveness of active vision for localizing objects that are too large to fall within a single camera’s field of view and show that well-calibrated vision-based sensors are sufficient to safely pass through a door frame that is narrow enough to tolerate a wheelchair localization error of at most a few centimetres. We provide experimental results demonstrating near perfect performance in an indoor environment.},
  isbn = {9780769531533},
  keywords = {active vision, visually guided robotics, object localization, assistive technology},
  numpages = {8},
  series = {CRV '08},
  url = {https://doi.org/10.1109/CRV.2008.23},
}

@ARTICLE{guerrero-gonz\'{a}lez-et-al:2016:0,
  author = {A. Guerrero-Gonz\'{a}lez and F. Garc\'{\i}a-C\'{o}rdova and F. J. Ortiz and D. Alonso and J. Gilabert},
  journal = {Auton. Robots},
  title = {A Multirobot Platform Based on Autonomous Surface and Underwater Vehicles with Bio-Inspired Neurocontrollers for Long-Term Oil Spills Monitoring},
  volume = {40},
  number = {7},
  pages = {1321--1342},
  doi = {10.1007/s10514-016-9602-0},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2016},
  month = {10},
  abstract = {This paper describes the BUSCAMOS-Oil monitoring system, which is a robotic platform consisting of an autonomous surface vessel combined with an underwater vehicle. The system has been designed for the long-term monitoring of oil spills, including the search for the spill, and transmitting information on its location, extent, direction and speed. Both vehicles are controlled by two different types of bio-inspired neural networks: a Self-Organization Direction Mapping Network for trajectory generation and a Neural Network for Avoidance Behaviour for avoiding obstacles. The systems' resilient capabilities are provided by bio-inspired algorithms implemented in a modular software architecture and controlled by redundant devices to give the necessary robustness to operate in the difficult conditions typically found in long-term oil-spill operations. The efficacy of the vehicles' adaptive navigation system and long-term mission capabilities are shown in the experimental results.},
  issn = {0929-5593},
  issue_date = {October   2016},
  keywords = {Multi-vehicle cooperation, Artificial neural networks, ASV, Component based software architecture, UUV, Bio-inspired control, Oil spills monitoring, Autonomous long-term navigation},
  numpages = {22},
  url = {https://doi.org/10.1007/s10514-016-9602-0},
}

@PHDTHESIS{ali-et-al:2021,
  author = {A. J. B. Ali and S. K. Y.  and D. Murat},
  title = {Edge-Assisted, Concurrent Localization and Mapping Systems for Mobile Devices},
  pages = {},
  note = {AAI28497642},
  publisher = {State University of New York at Buffalo},
  address = {USA},
  year = {2021},
  abstract = {Localization in urban environments is becoming increasingly important and used in tools such as ARCore, ARKit, and others. One popular mechanism to achieve accurate indoor localization and a map of the space is Visual Simultaneous Localization and Mapping (Visual-SLAM). However, Visual-SLAM is known to be resource-intensive in memory and processing time. Further, some of the operations grow in complexity over time, making it challenging to run on mobile devices continuously. Edge computing provides additional compute and memory resources to mobile devices to offload some tasks without the large latencies seen when offloading to the cloud. Many applications such as multi-user augmented reality or multi-robot search will also require the system to handle images from multiple mobile devices and/or multiple maps. Therefore, in this dissertation, we develop edge-assisted, concurrent localization and mapping systems for mobile devices. To this end, first, we propose Edge-SLAM. This system uses edge computing resources to offload parts of the Visual-SLAM pipeline. Second, we propose Atlas. This end-to-end edge-assisted Visual-SLAM system works with multiple mobile devices concurrently.Edge-SLAM presents a general split architecture of the Visual-SLAM pipeline between the mobile device and the edge. In this architecture, we keep the tracking computation on the mobile device and move the rest of the computation, i.e., local mapping and loop closing, to the edge. The mobile device only works with a local map that corresponds to the current location. At the same time, the edge builds and maintains the global map. Our results show that our split architecture can allow the Visual-SLAM system's long-term functioning with limited resources without affecting operation accuracy. It also keeps the computation and memory cost on the mobile device constant, which would allow for the deployment of other end applications that use Visual-SLAM.Atlas extends Edge-SLAM's design and implementation to support multiple mobile devices, work with multiple maps, and fuse overlapping maps. From Atlas evaluation, we observe that its performance is comparable to Edge-SLAM with no additional overhead. We also show that Atlas scales well to work with multiple mobile devices despite the tightly coupled nature of the edge operation.},
  advisor = {Karthik, Dantu,},
  isbn = {9798516936081},
  url = {https://www.proquest.com/openview/ef44c828daffaeb859ba23efc39f1289/},
}

@ARTICLE{kawewong-et-al:2011:0278364910371855,
  author = {A. Kawewong and N. Tongprasit and S. Tangruamsub and O. Hasegawa},
  journal = {Int. J. Rob. Res.},
  title = {Online and Incremental Appearance-Based SLAM in Highly Dynamic Environments},
  volume = {30},
  number = {1},
  pages = {33--55},
  doi = {10.1177/0278364910371855},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2011},
  month = {1},
  abstract = {In this paper we present a novel method for online and incremental appearance-based localization and mapping in a highly dynamic environment. Using position-invariant robust features (PIRFs), the method can achieve a high rate of recall with 100% precision. It can handle both strong perceptual aliasing and dynamic changes of places efficiently. Its performance also extends beyond conventional images; it is applicable to omnidirectional images for which the major portions of scenes are similar for most places. The proposed PIRF-based Navigation method named PIRF-Nav is evaluated by testing it on two standard datasets in a similar manner as in FAB-MAP and on an additional omnidirectional image dataset that we collected. This extra dataset was collected on 2 days with different specific events, i.e. an open-campus event, to present challenges related to illumination variance and strong dynamic changes, and to test assessment of dynamic scene changes. Results show that PIRF-Nav outperforms FAB-MAP; PIRF-Nav at precision-1 yields a recall rate about twice as high (approximately 80% increase) than that of FAB-MAP. Its computation time is sufficiently short for real-time applications. The method is fully incremental, and requires no offline process for dictionary creation. Additional testing using combined datasets proves that PIRF-Nav can function over the long term and can solve the kidnapped robot problem.},
  issn = {0278-3649},
  issue_date = {January   2011},
  keywords = {Appearance-based localization and mapping, invariant robust feature, topological SLAM},
  numpages = {23},
  url = {https://doi.org/10.1177/0278364910371855},
}

@PHDTHESIS{walcott:2011,
  author = {A. N. Walcott},
  title = {Long-Term Robot Mapping in Dynamic Environments},
  pages = {},
  note = {AAI0823852},
  publisher = {Massachusetts Institute of Technology},
  address = {USA},
  year = {2011},
  abstract = {One of the central goals in mobile robotics is to develop a mobile robot that can construct a map of an initially unknown dynamic environment. This is often referred to as the Simultaneous Localization and Mapping (SLAM) problem. A number of approaches to the SLAM problem have been successfully developed and applied, particularly to a mobile robot constructing a map of a 2D static indoor environment. While these methods work well for static environments, they are not robust to dynamic environments which are complex and composed of numerous objects that move at wide-varying time-scales, such as people or office furniture. The problem of maintaining a map of a dynamic environment is important for both real-world applications and for the advancement of robotics. A mobile robot executing extended missions, such as autonomously collecting data underwater for months or years, must be able to reliably know where it is, update its map as the environment changes, and recover from mistakes. From a fundamental perspective, this work is important in order to understand and determine the problems that occur with existing mapping techniques for persistent long-term operation.The primary contribution of the thesis is Dynamic Pose Graph SLAM (DPG-SLAM), a novel algorithm that addresses two core challenges of the long-term mapping problem. The first challenge is to ensure that the robot is able to remain localized in a changing environment over great lengths of time. The second challenge is to be able to maintain an up-to-date map over time in a computationally efficient manner. DPG-SLAM directly addresses both of these issues to enable long-term mobile robot navigation and map maintenance in changing environments. Using Kaess and Dellaert's incremental Smoothing and Mapping (iSAM) as the underlying SLAM state estimation engine, the dynamic pose graph evolves over time as the robot explores new areas and revisits previously mapped areas. The algorithm is demonstrated on two real-world dynamic indoor laser data sets, demonstrating the ability to maintain an efficient, up-to-date map despite long-term environmental changes. Future research issues, such as the integration of adaptive exploration with dynamic map maintenance, are identified. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)},
  advisor = {Leonard, John J.},
  url = {http://dspace.mit.edu/handle/1721.1/7582},
}

@ARTICLE{taniguchi-et-al:2020:0,
  author = {A. Taniguchi and Y. Hagiwara and T. Taniguchi and T. Inamura},
  journal = {Auton. Robots},
  title = {Improved and Scalable Online Learning of Spatial Concepts and Language Models with Mapping},
  volume = {44},
  number = {6},
  pages = {927--946},
  doi = {10.1007/s10514-020-09905-0},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2020},
  month = {7},
  abstract = {We propose a novel online learning algorithm, called SpCoSLAM 2.0, for spatial concepts and lexical acquisition with high accuracy and scalability. Previously, we proposed SpCoSLAM as an online learning algorithm based on unsupervised Bayesian probabilistic model that integrates multimodal place categorization, lexical acquisition, and SLAM. However, our original algorithm had limited estimation accuracy owing to the influence of the early stages of learning, and increased computational complexity with added training data. Therefore, we introduce techniques such as fixed-lag rejuvenation to reduce the calculation time while maintaining an accuracy higher than that of the original algorithm. The results show that, in terms of estimation accuracy, the proposed algorithm exceeds the original algorithm and is comparable to batch learning. In addition, the calculation time of the proposed algorithm does not depend on the amount of training data and becomes constant for each step of the scalable algorithm. Our approach will contribute to the realization of long-term spatial language interactions between humans and robots.},
  issn = {0929-5593},
  issue_date = {Jul 2020},
  keywords = {Lexical acquisition, Unsupervised Bayesian probabilistic model, Scalability, Semantic mapping, Online learning, Place categorization},
  numpages = {20},
  url = {https://doi.org/10.1007/s10514-020-09905-0},
}

@INPROCEEDINGS{bacca-et-al:2010,
  author = {B. Bacca and J. Salv\'{\i} and X. Cuf\'{\i}},
  booktitle = {Proceedings of the 2010 Conference on Artificial Intelligence Research and Development: Proceedings of the 13th International Conference of the Catalan Association for Artificial Intelligence},
  title = {Mapping and Localization for Mobile Robots through Environment Appearance Update},
  pages = {291--300},
  publisher = {IOS Press},
  address = {NLD},
  year = {2010},
  abstract = {The strength of appearance-based mapping models lies in their ability to represent the environment through high-level image features; and provide humanreadable information. However, developing localization and mapping methods with these models could be very challenging, especially if robots must deal with long-term mapping, localization, navigation, occlusions, and dynamic environments. This paper proposes an appearance-based mapping and localization method based on the human memory model, which is used to build a Feature Stability Histogram (FSH) at each node in the robot topological map, these FSH register local feature stability over time through a voting scheme, and most stable features are considered for mapping and Bayesian localization. Experimental results are presented using omnidirectional images acquired through long-term acquisition considering: illumination changes (day time and seasons), occlusions, random removal of features, and perceptual aliasing. This method is able to adapt the internal node's representation through time to achieve global and local robot localization.},
  isbn = {9781607506423},
  numpages = {10},
  url = {https://dl.acm.org/doi/abs/10.5555/1893268.1893306},
}

@INPROCEEDINGS{bacca-et-al:2009:55,
  author = {B. Bacca and J. Salvi and X. Cuf\'{\i}},
  booktitle = {Proceedings of the 2009 Conference on Artificial Intelligence Research and Development: Proceedings of the 12th International Conference of the Catalan Association for Artificial Intelligence},
  title = {Appearance-Based SLAM for Mobile Robots},
  pages = {55--64},
  doi = {10.3233/978-1-60750-061-2-55},
  publisher = {IOS Press},
  address = {NLD},
  year = {2009},
  abstract = {This paper reviews new challenges in the area of long-term navigation, and new approaches to environment representation and robots capable of coping with dynamic environments. As a result of this review, we propose an appearancebased simultaneous localization and mapping (SLAM) solution which represents the robot environment using an appearance-based topological map. Dynamic environment changes are dealt with using human memory and fixed action pattern concepts. The former is used to build a histogram to register local feature stability, the latter for robot navigation purposes. We take omnidirectional vision and laser range data to extract textured 2D scans as global features, and textured-vertical edges as local features for map updating and robot localization. From the navigational point of view, we consider visual potential field-based behavior to adjust high level motion commands.},
  isbn = {8887666665554},
  numpages = {10},
}

@INPROCEEDINGS{bacca-et-al:2009:55,
  author = {B. Bacca and J. Salvi and X. Cuf\'{\i}},
  booktitle = {Proceedings of the 2009 Conference on Artificial Intelligence Research and Development: Proceedings of the 12th International Conference of the Catalan Association for Artificial Intelligence},
  title = {Appearance-Based SLAM for Mobile Robots},
  pages = {55--64},
  doi = {10.3233/978-1-60750-061-2-55},
  publisher = {IOS Press},
  address = {NLD},
  year = {2009},
  abstract = {This paper reviews new challenges in the area of long-term navigation, and new approaches to environment representation and robots capable of coping with dynamic environments. As a result of this review, we propose an appearancebased simultaneous localization and mapping (SLAM) solution which represents the robot environment using an appearance-based topological map. Dynamic environment changes are dealt with using human memory and fixed action pattern concepts. The former is used to build a histogram to register local feature stability, the latter for robot navigation purposes. We take omnidirectional vision and laser range data to extract textured 2D scans as global features, and textured-vertical edges as local features for map updating and robot localization. From the navigational point of view, we consider visual potential field-based behavior to adjust high level motion commands.},
  isbn = {9781607500612},
  keywords = {Mapping, Localization, Computer Vision},
  numpages = {10},
}

@INPROCEEDINGS{mu-et-al:2016:7799127,
  author = {B. Mu and M. Giamou and L. Paull and A.-A. Agha-mohammadi and J. Leonard and J. How},
  booktitle = {2016 IEEE 55th Conference on Decision and Control (CDC)},
  title = {Information-Based Active SLAM via Topological Feature Graphs},
  pages = {5583--5590},
  doi = {10.1109/CDC.2016.7799127},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Exploring an unknown space and building maps is a fundamental capability for mobile robots. For fully autonomous systems, the robot would further need to actively plan its paths during exploration. The problem of designing robot trajectories to actively explore an unknown environment and minimize the map error is referred to as active simultaneous localization and mapping (active SLAM). Existing work has focused on planning paths with occupancy grid maps, which do not scale well and suffer from long term drift. This work proposes a Topological Feature Graph (TFG) representation that scales well and develops an active SLAM algorithm with it. The TFG uses graphical models, which utilize independences between variables, and enables a unified quantification of exploration and exploitation gains with a single entropy metric. Hence, it facilitates a natural and principled balance between map exploration and refinement. A probabilistic roadmap path-planner is used to generate robot paths in real time. Experimental results demonstrate that the proposed approach achieves better accuracy than a standard grid-map based approach while requiring orders of magnitude less computation and memory resources.},
  location = {Las Vegas, NV, USA},
  numpages = {8},
  url = {https://doi.org/10.1109/CDC.2016.7799127},
}

@INPROCEEDINGS{wallace-et-al:2015:93,
  author = {B. Wallace and R. Goubran and F. Knoefel and S. Marshall and M. Porter and M. Harlow and A. Puli},
  booktitle = {Proceedings of the 2015 IEEE International Congress on Big Data},
  title = {Automation of the Validation, Anonymization, and Augmentation of Big Data from a Multi-Year Driving Study},
  pages = {608--614},
  doi = {10.1109/BigDataCongress.2015.93},
  publisher = {IEEE Computer Society},
  address = {USA},
  year = {2015},
  abstract = {The Candrive/Ozcandrive project is a long term study that is now entering its sixth year focused on improving the safety of older drivers. The study includes 256 older drivers in the Ottawa area and is an example of a longitudinal study that generates big data sensor information recorded from the participant vehicles. This paper uses the Can drive data and proposes solutions that would enable differential privacy including a theoretical open access model for the data using k anonymity techniques for any combination of 7 parameters that have identifiable attributes. The dataset includes an in-vehicle sensor that captures Global Positioning System (GPS) and On Board Diagnostics II (OBDII) data for every second that the vehicle is operating. The resulting data set includes hundreds to thousands of hours of data for each of the study vehicles. The paper discusses methods to address the challenge of transitioning a large data set of GPS and other raw sensor samples to data ready to analyze. Automated methods to detect and correct any issues in the individual data samples along with the needed tools to adapt the raw sensor data into formats that can be easily processed are shown. The paper provides solutions to ensure k anonymity based privacy of the study participant's identity for seven parameters including location of their home through vehicle location information or through a combination of the sensor information. The paper presents mechanisms to augment the captured sensor data through fusion with external data resources to bring added information to the data set including weather information, road information from mapping sources and day/night status. The paper will present the performance applicability for analysis of the resulting dataset within a cloud computing architecture.},
  isbn = {9781467372787},
  keywords = {Differential Privacy, Global Positioning System (GPS), data analytics, driving, k-Anonymity},
  numpages = {7},
  series = {BIGDATACONGRESS '15},
  url = {https://doi.org/10.1109/BigDataCongress.2015.93},
}

@INPROCEEDINGS{wen-bekris:2021:9635991,
  author = {B. Wen and K. Bekris},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models},
  pages = {8067--8074},
  doi = {10.1109/IROS51168.2021.9635991},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {Tracking the 6D pose of objects in video sequences is important for robot manipulation. Most prior efforts, however, often assume that the target object's CAD model, at least at a category-level, is available for offline training or during online template matching. This work proposes BundleTrack, a general framework for 6D pose tracking of novel objects, which does not depend upon 3D models, either at the instance or category-level. It leverages the complementary attributes of recent advances in deep learning for segmentation and robust feature extraction, as well as memory-augmented pose graph optimization for spatiotemporal consistency. This enables long-term, low-drift tracking under various challenging scenarios, including significant occlusions and object motions. Comprehensive experiments given two public benchmarks demonstrate that the proposed approach significantly outperforms state-of-art, category-level 6D tracking or dynamic SLAM methods. When compared against state-of-art methods that rely on an object instance CAD model, comparable performance is achieved, despite the proposed method’s reduced information requirements. An efficient implementation in CUDA provides a real-time performance of 10Hz for the entire framework. Code is available at: https://github.com/wenbowen123/BundleTrack},
  location = {Prague, Czech Republic},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS51168.2021.9635991},
}

@INPROCEEDINGS{ba-gueye:2020:24,
  author = {C. Ba and A. Gueye},
  booktitle = {Algorithms and Architectures for Parallel Processing: 20th International Conference, ICA3PP 2020, New York City, NY, USA, October 2–4, 2020, Proceedings, Part I},
  title = {A BSP Based Approach for NFAs Intersection},
  pages = {344--354},
  doi = {10.1007/978-3-030-60245-1_24},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  year = {2020},
  abstract = {Large NFAs are automata that cannot fit in a single computer, or the computations would not fit within the computer RAM, or may take a long time. We describe and implement a BSP solution of such large NFAs intersection. Our method avoids producing unreachable states of the product automaton, contrary to previous solutions. These solutions, based on MapReduce for instance, process all the Cartesian product of inputs NFAs. A running example is provided with execution details. Finally, complexity analysis is given. This work will help in bringing out relevant programming artifacts for our long term goal that consists of a high level distributed graph language.},
  isbn = {978-3-030-60244-4},
  keywords = {Complexity, Large NFAs intersection, MapReduce, BSP},
  location = {New York, NY, USA},
  numpages = {11},
  url = {https://doi.org/10.1007/978-3-030-60245-1_24},
}

@ARTICLE{cadena-et-al:2016:2624754,
  author = {C. Cadena and L. Carlone and H. Carrillo and Y. Latif and D. Scaramuzza and J. Neira and I. Reid and J. J. Leonard},
  journal = {Trans. Rob.},
  title = {Past, Present, and Future of Simultaneous Localization and Mapping: Toward the Robust-Perception Age},
  volume = {32},
  number = {6},
  pages = {1309--1332},
  doi = {10.1109/TRO.2016.2624754},
  publisher = {IEEE Press},
  year = {2016},
  month = {12},
  abstract = {Simultaneous localization and mapping (SLAM) consists in the concurrent construction of a model of the environment (the map), and the estimation of the state of the robot moving within it. The SLAM community has made astonishing progress over the last 30 years, enabling large-scale real-world applications and witnessing a steady transition of this technology to industry. We survey the current state of SLAM and consider future directions. We start by presenting what is now the de-facto standard formulation for SLAM. We then review related work, covering a broad set of topics including robustness and scalability in long-term mapping, metric and semantic representations for mapping, theoretical performance guarantees, active SLAM and exploration, and other new frontiers. This paper simultaneously serves as a position paper and tutorial to those who are users of SLAM. By looking at the published research with a critical eye, we delineate open challenges and new research issues, that still deserve careful scientific investigation. The paper also contains the authors’ take on two questions that often animate discussions during robotics conferences: Do robots need SLAM? and Is SLAM solved?},
  issn = {1552-3098},
  issue_date = {December 2016},
  numpages = {24},
  url = {https://doi.org/10.1109/TRO.2016.2624754},
}

@PHDTHESIS{gifford:2009,
  author = {C. M. Gifford},
  title = {Collective Machine Learning: Team Learning and Classification in Multi-Agent Systems},
  pages = {},
  note = {AAI3380463},
  publisher = {University of Kansas},
  address = {USA},
  year = {2009},
  abstract = {This dissertation focuses on the collaboration of multiple heterogeneous, intelligent agents (hardware or software) which collaborate to learn a task and are capable of sharing knowledge. The concept of collaborative learning in multi-agent and multi-robot systems is largely under studied, and represents an area where further research is needed to gain a deeper understanding of team learning. This work presents experimental results which illustrate the importance of heterogeneous teams of collaborative learning agents, as well as outlines heuristics which govern successful construction of teams of classifiers. A number of application domains are studied in this dissertation. One approach is focused on the effects of sharing knowledge and collaboration of multiple heterogeneous, intelligent agents (hardware or software) which work together to learn a task. As each agent employs a different machine learning technique, the system consists of multiple knowledge sources and their respective heterogeneous knowledge representations. Collaboration between agents involves sharing knowledge to both speed up team learning, as well as to refine the team's overall performance and group behavior. Experiments have been performed that vary the team composition in terms of machine learning algorithms, learning strategies employed by the agents, and sharing frequency for a predator-prey cooperative pursuit task. For lifelong learning, heterogeneous learning teams were more successful compared to homogeneous learning counterparts. Interestingly, sharing increased the learning rate, but sharing with higher frequency showed diminishing results. Lastly, knowledge conflicts are reduced over time, as more sharing takes place. These results support further investigation of the merits of heterogeneous learning.This dissertation also focuses on discovering heuristics for constructing successful teams of heterogeneous classifiers, including many aspects of team learning and collaboration. In one application, multi-agent machine learning and classifier combination are utilized to learn rock facies sequences from wireline well log data. Gas and oil reservoirs have been the focus of modeling efforts for many years as an attempt to locate zones with high volumes. Certain subsurface layers and layer sequences, such as those containing shale, are known to be impermeable to gas and/or liquid. Oil and natural gas then become trapped by these layers, making it possible to drill wells to reach the supply, and extract for use. The drilling of these wells, however, is costly. Here, the focus is on how to construct a successful set of classifiers, which periodically collaborate, to increase the classification accuracy. Utilizing multiple, heterogeneous collaborative learning agents is shown to be successful for this classification problem. We were able to obtain 84.5% absolute accuracy using the Multi- Agent Collaborative Learning Architecture, an improvement of about 6.5% over the best results achieved by Kansas Geological Survey with the same data set. Several heuristics are presented for constructing teams of multiple collaborative classifiers for predicting rock facies.Another application utilizes multi-agent machine learning and classifier combination to learn water presence using airborne polar radar data acquired from Greenland in 1999 and 2007. Ground and airborne depth-soundings of the Greenland and Antarctic ice sheets have been used for many years to determine characteristics such as ice thickness, subglacial topography, and mass balance of large bodies of ice. Ice coring efforts have supported these radar data to provide ground truth for validation of the state (wet or frozen) of the interface between the bottom of the ice sheet and the underlying bedrock. Subglacial state governs the friction, flow speed, transport of material, and overall change of the ice sheet. In this dissertation, we focus on how to construct a successful set of classifiers which periodically collaborate to increase classification accuracy. The underlying method results in radar independence, allowing model transfer from 1999 to 2007 to produce water presence maps of the Greenland ice sheet with differing radars. We were able to obtain 86% accuracy using the Multi-Agent Collaborative Learning Architecture with this data set. Utilizing multiple, heterogeneous collaborative learning agents is shown to be successful for this classification problem as well. Several heuristics, some of which agree with those found in the other applications, are presented for constructing teams of multiple collaborative classifiers for predicting subglacial water presence. (Abstract shortened by UMI.)},
  advisor = {Agah, Arvin},
  isbn = {9781109514070},
  url = {https://www.proquest.com/openview/c8ef5825f8c555488b25ce3b61a93f73/},
}

@ARTICLE{sung-et-al:2022:2,
  author = {C. Sung and S. Jeon and H. Lim and H. Myung},
  journal = {Intell. Serv. Robot.},
  title = {What If There Was No Revisit? Large-Scale Graph-Based SLAM with Traffic Sign Detection in an HD Map Using LiDAR Inertial Odometry},
  volume = {15},
  number = {2},
  pages = {161--170},
  doi = {10.1007/s11370-021-00395-2},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  year = {2022},
  month = {4},
  abstract = {Accurate localization and mapping in a large-scale environment is an essential system of an autonomous vehicle. The difficulty of the previous LiDAR or LiDAR-inertial simultaneous localization and mapping (SLAM) methods is correcting long-term drift error in a large-scale environment. This paper proposes a novel approach of a large-scale, graph-based SLAM with traffic sign data involved in a high-definition (HD) map. The graph of the system is structured with the inertial measurement unit (IMU) factor, LiDAR-inertial odometry factor, map-matching factor, and loop closure factor. The local sliding window-based optimization method is employed for real-time processing. As a result, the proposed method improves the accuracy of the localization and mapping compared with the state-of-the-art LiDAR or LiDAR-inertial SLAM methods. In addition, the proposed method can localize accurately without revisit, required for conventional graph-based SLAM for graph optimization, unlike previous studies. The proposed method is intensively validated with a data set collected in a city where the Global Navigation Satellite System (GNSS) signal is unreliable and on a university campus.},
  issn = {1861-2776},
  issue_date = {Apr 2022},
  keywords = {HD map, 3D LiDAR SLAM, Autonomous vehicle, 3D point cloud map},
  numpages = {10},
  url = {https://doi.org/10.1007/s11370-021-00395-2},
}

@INPROCEEDINGS{fourie-et-al:2017:7989749,
  author = {D. Fourie and S. Claassens and S. Pillai and R. Mata and J. Leonard},
  booktitle = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {SLAMinDB: Centralized Graph Databases for Mobile Robotics},
  pages = {6331--6337},
  doi = {10.1109/ICRA.2017.7989749},
  publisher = {IEEE Press},
  year = {2017},
  abstract = {Robotic systems typically require memory recall mechanisms for a variety of tasks including localization, mapping, planning, visualization etc. We argue for a novel memory recall framework that enables more complex inference schemas by separating the computation from its associated data. In this work we propose a shared, centralized data persistence layer that maintains an ensemble of online, situationally-aware robot states. This is realized through a queryable graph-database with an accompanying key-value store for larger data. In turn, this approach is scalable and enables a multitude of capabilities such as experience-based learning and long-term autonomy. Using multi-modal simultaneous localization and mapping and a few example use-cases, we demonstrate the versatility and extensible nature that centralized persistence and SLAMinDB can provide. In order to support the notion of life-long autonomy, we envision robots to be endowed with such a persistence model, enabling them to revisit previous experiences and improve upon their existing task-specific capabilities.},
  location = {Singapore, Singapore},
  numpages = {7},
  url = {https://doi.org/10.1109/ICRA.2017.7989749},
}

@INPROCEEDINGS{rosen-et-al:2016:7487237,
  author = {D. M. Rosen and J. Mason and J. J. Leonard},
  booktitle = {2016 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {Towards Lifelong Feature-Based Mapping in Semi-Static Environments},
  pages = {1063--1070},
  doi = {10.1109/ICRA.2016.7487237},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {The feature-based graphical approach to robotic mapping provides a representationally rich and computationally efficient framework for an autonomous agent to learn a model of its environment. However, this formulation does not naturally support long-term autonomy because it lacks a notion of environmental change; in reality, “everything changes and nothing stands still, ” and any mapping and localization system that aims to support truly persistent autonomy must be similarly adaptive. To that end, in this paper we propose a novel feature-based model of environmental evolution over time. Our approach is based upon the development of an expressive probabilistic generative feature persistence model that describes the survival of abstract semi-static environmental features over time. We show that this model admits a recursive Bayesian estimator, the persistence filter, that provides an exact online method for computing, at each moment in time, an explicit Bayesian belief over the persistence of each feature in the environment. By incorporating this feature persistence estimation into current state-of-the-art graphical mapping techniques, we obtain a flexible, computationally efficient, and information-theoretically rigorous framework for lifelong environmental modeling in an ever-changing world.},
  location = {Stockholm, Sweden},
  numpages = {8},
  url = {https://doi.org/10.1109/ICRA.2016.7487237},
}

@INPROCEEDINGS{sheng-et-al:2021:9636640,
  author = {D. Sheng and Y. Chai and X. Li and C. Feng and J. Lin and C. Silva and J.-R. Rizzo},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {NYU-VPR: Long-Term Visual Place Recognition Benchmark with View Direction and Data Anonymization Influences},
  pages = {9773--9779},
  doi = {10.1109/IROS51168.2021.9636640},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {Visual place recognition (VPR) is critical in not only localization and mapping for autonomous driving vehicles, but also assistive navigation for the visually impaired population. To enable a long-term VPR system on a large scale, several challenges need to be addressed. First, different applications could require different image view directions, such as front views for self-driving cars while side views for the low vision people. Second, VPR in metropolitan scenes can often cause privacy concerns due to the imaging of pedestrian and vehicle identity information, calling for the need for data anonymization before VPR queries and database construction. Both factors could lead to VPR performance variations that are not well understood yet. To study their influences, we present the NYU-VPR dataset that contains more than 200,000 images over a 2km\texttimes{}2km area near the New York University campus, taken within the whole year of 2016. We present benchmark results on several popular VPR algorithms showing that side views are significantly more challenging for current VPR methods while the influence of data anonymization is almost negligible, together with our hypothetical explanations and in-depth analysis.},
  location = {Prague, Czech Republic},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS51168.2021.9636640},
}

@INPROCEEDINGS{su-et-al:2016:7759430,
  author = {D. Su and K. Nakamura and K. Nakadai and J. V. Miro},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Robust Sound Source Mapping Using Three-Layered Selective Audio Rays for Mobile Robots},
  pages = {2771--2777},
  doi = {10.1109/IROS.2016.7759430},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {This paper investigates sound source mapping in a real environment using a mobile robot. Our approach is based on audio ray tracing which integrates occupancy grids and sound source localization using a laser range finder and a microphone array. Previous audio ray tracing approaches rely on all observed rays and grids. As such observation errors caused by sound reflection, sound occlusion, wall occlusion, sounds at misdetected grids, etc. can significantly degrade the ability to locate sound sources in a map. A three-layered selective audio ray tracing mechanism is proposed in this work. The first layer conducts frame-based unreliable ray rejection (sensory rejection) considering sound reflection and wall occlusion. The second layer introduces triangulation and audio tracing to detect falsely detected sound sources, rejecting audio rays associated to these misdetected sounds sources (short-term rejection). A third layer is tasked with rejecting rays using the whole history (long-term rejection) to disambiguate sound occlusion. Experimental results under various situations are presented, which proves the effectiveness of our method.},
  location = {Daejeon, South Korea},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS.2016.7759430},
}

@ARTICLE{einhorn-gross:2015:008,
  author = {E. Einhorn and H.-M. Gross},
  journal = {Robot. Auton. Syst.},
  title = {Generic NDT Mapping in Dynamic Environments and Its Application for Lifelong SLAM},
  volume = {69},
  number = {C},
  pages = {28--39},
  doi = {10.1016/j.robot.2014.08.008},
  publisher = {North-Holland Publishing Co.},
  address = {NLD},
  year = {2015},
  month = {7},
  abstract = {In this paper, we present a new, generic approach for Simultaneous Localization and Mapping (SLAM). First of all, we propose an abstraction of the underlying sensor data using Normal Distribution Transform (NDT) maps that are suitable for making our approach independent from the used sensor and the dimension of the generated maps. We present several modifications for the original NDT mapping to handle free-space measurements explicitly. We additionally describe a method to detect and handle dynamic objects such as moving persons. This enables the usage of the proposed approach in highly dynamic environments. In the second part of this paper we describe our graph-based SLAM approach that is designed for lifelong usage. Therefore, the memory and computational complexity is limited by pruning the pose graph in an appropriate way. We present a new mapping approach that combines normal distribution transform (NDT) and occupancy mapping.The mapping approach is fully generic and suitable for 2D and 3D mapping with different sensors.We describe a method for detecting and handling dynamic objects to allow mapping in highly dynamic environments.Based on the mapping algorithm a graph based SLAM algorithm is described.The presented SLAM approach allows lifelong mapping and localization in real world applications.},
  issn = {0921-8890},
  issue_date = {July 2015},
  keywords = {Occupancy mapping, Detection and tracking of moving objects, Map registration, Lifelong SLAM, 2D and 3D mapping, Normal Distribution Transform, Mobile robots},
  numpages = {12},
  url = {https://doi.org/10.1016/j.robot.2014.08.008},
}

@INPROCEEDINGS{stenborg-et-al:2018:8463150,
  author = {E. Stenborg and C. Toft and L. Hammarstrand},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {Long-Term Visual Localization Using Semantically Segmented Images},
  pages = {6484--6490},
  doi = {10.1109/ICRA.2018.8463150},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.},
  location = {Brisbane, Australia},
  numpages = {7},
  url = {https://doi.org/10.1109/ICRA.2018.8463150},
}

@ARTICLE{dayoub-et-al:2011:013,
  author = {F. Dayoub and G. Cielniak and T. Duckett},
  journal = {Robot. Auton. Syst.},
  title = {Long-Term Experiments with an Adaptive Spherical View Representation for Navigation in Changing Environments},
  volume = {59},
  number = {5},
  pages = {285--295},
  doi = {10.1016/j.robot.2011.02.013},
  publisher = {North-Holland Publishing Co.},
  address = {NLD},
  year = {2011},
  month = {5},
  abstract = {Real-world environments such as houses and offices change over time, meaning that a mobile robot's map will become out of date. In this work, we introduce a method to update the reference views in a hybrid metric-topological map so that a mobile robot can continue to localize itself in a changing environment. The updating mechanism, based on the multi-store model of human memory, incorporates a spherical metric representation of the observed visual features for each node in the map, which enables the robot to estimate its heading and navigate using multi-view geometry, as well as representing the local 3D geometry of the environment. A series of experiments demonstrate the persistence performance of the proposed system in real changing environments, including analysis of the long-term stability.},
  issn = {0921-8890},
  issue_date = {May, 2011},
  keywords = {Persistent mapping, Omnidirectional vision, Mobile robot navigation},
  numpages = {11},
  url = {https://doi.org/10.1016/j.robot.2011.02.013},
}

@ARTICLE{nobre-heckman:2019:0278364919844824,
  author = {F. Nobre and C. Heckman},
  journal = {Int. J. Rob. Res.},
  title = {Learning to Calibrate: Reinforcement Learning for Guided Calibration of Visual–Inertial Rigs},
  volume = {38},
  number = {12–13},
  pages = {1388--1402},
  doi = {10.1177/0278364919844824},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2019},
  month = {10},
  abstract = {We present a new approach to assisted intrinsic and extrinsic calibration with an observability-aware visual–inertial calibration system that guides the user through the calibration procedure by suggesting easy-to-perform motions that render the calibration parameters observable. This is done by identifying which subset of the parameter space is rendered observable with a rank-revealing decomposition of the Fisher information matrix, modeling calibration as a Markov decision process and using reinforcement learning to establish which discrete sequence of motions optimizes for the regression of the desired parameters. The goal is to address the assumption common to most calibration solutions: that sufficiently informative motions are provided by the operator. We do not make use of a process model and instead leverage an experience-based approach that is broadly applicable to any platform in the context of simultaneous localization and mapping. This is a step in the direction of long-term autonomy and “power-on-and-go” robotic systems, making repeatable and reliable calibration accessible to the non-expert operator.},
  issn = {0278-3649},
  issue_date = {Oct 2019},
  keywords = {observability, extrinsic, Calibration, reinforcement learning, intrinsic},
  numpages = {15},
  url = {https://doi.org/10.1177/0278364919844824},
}

@INPROCEEDINGS{cecchini-et-al:2017:8292687,
  author = {G. Cecchini and A. Bazzi and B. M. Masini and A. Zanella},
  booktitle = {2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)},
  title = {MAP-RP: Map-Based Resource Reselection Procedure for Autonomous LTE-V2V},
  pages = {1--6},
  doi = {10.1109/PIMRC.2017.8292687},
  publisher = {IEEE Press},
  year = {2017},
  abstract = {Vehicle-to-everything (V2X) communications may radically change the transportation system allowing a real-time and highly reliable exchange of information, which can be processed by vehicles in the neighborhood or by the road-side infrastructure to enable safety, mobility and environmental applications. In this context, 3GPP-based cellular networks, and especially long term evolution (LTE), are offering progressively higher performance and enabling a wider set of operations. To this aim, vehicle-to-vehicle (V2V) has been recently added as a new feature to LTE, but the usage of radio resources still needs to be optimized and is subject of extensive research activities. In this work, we focus on autonomous V2V resource reselection schemes, which allow communications also in out-of-coverage areas, we propose MAP-RP, a reselection procedure based on the embedding of a map of resources, as detected by each receiving vehicle, in the broadcasted packet, and we compare it to two sensing-based benchmark algorithms found in the literature. Results are achieved through simulations performed on a realistic highway scenario and demonstrate that the proposed solution guarantees a lower update delay and allows to achieve up to 20% of improvement in terms of packet reception ratio, with respect to the best-performing benchmark algorithm.},
  isbn = {978-1-5386-3529-2},
  location = {Montreal, QC, Canada},
  numpages = {6},
  url = {https://doi.org/10.1109/PIMRC.2017.8292687},
}

@ARTICLE{tipaldi-et-al:2013:0278364913502830,
  author = {G. D. Tipaldi and D. Meyer-Delius and W. Burgard},
  journal = {Int. J. Rob. Res.},
  title = {Lifelong Localization in Changing Environments},
  volume = {32},
  number = {14},
  pages = {1662--1678},
  doi = {10.1177/0278364913502830},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2013},
  month = {12},
  abstract = {Robot localization systems typically assume that the environment is static, ignoring the dynamics inherent in most real-world settings. Corresponding scenarios include households, offices, warehouses and parking lots, where the location of certain objects such as goods, furniture or cars can change over time. These changes typically lead to inconsistent observations with respect to previously learned maps and thus decrease the localization accuracy or even prevent the robot from globally localizing itself. In this paper we present a sound probabilistic approach to lifelong localization in changing environments using a combination of a Rao-Blackwellized particle filter with a hidden Markov model. By exploiting several properties of this model, we obtain a highly efficient map management approach for dynamic environments, which makes it feasible to run our algorithm online. Extensive experiments with a real robot in a dynamically changing environment demonstrate that our algorithm reliably adapts to changes in the environment and also outperforms the popular Monte-Carlo localization approach.},
  issn = {0278-3649},
  issue_date = {December  2013},
  keywords = {localization, mapping, Mobile and distributed robotics SLAM, cognitive robotics, learning and adaptive systems},
  numpages = {17},
  url = {https://doi.org/10.1177/0278364913502830},
}

@PHDTHESIS{huang:2013,
  author = {G. Huang},
  title = {Improving the Consistency of Nonlinear Estimators: Analysis, Algorithms, and Applications},
  pages = {},
  note = {AAI3556089},
  publisher = {University of Minnesota},
  address = {USA},
  year = {2013},
  abstract = {Autonomous robots are emerging as candidates for performing increasingly complex tasks, such as surveillance and environment monitoring, search and rescue, and planetary exploration. Nonlinear estimation (i.e., estimating the state of a nonlinear system from noisy measurements) arises in all these applications. For instance, robot localization - which is considered as one of the fundamental problems in robotics - seeks to determine the robot's pose (position and orientation) using measurements from onboard sensors (e.g., an odometer and a camera). Another closely-related and important example is target tracking, where the objective is to estimate the target's state using remote sensor observations. Even though many different algorithms, such as the extended Kalman filter (EKF) and the batch maximum a posteriori (MAP) estimator, have been developed for solving these problems, substantial empirical evidence shows that most existing nonlinear estimators tend to become inconsistent (i.e., the state estimates are biased and the error covariance estimates are smaller than the true ones). Moreover, a significant limitation is that the causes of inconsistency have not been sufficiently studied in the literature; if an estimator is inconsistent, the accuracy of its estimates is unknown, which makes the estimator unreliable. The objective of this dissertation is to investigate the main causes of inconsistency of nonlinear estimation and develop new algorithms for improving consistency. As one of the main research thrusts, we study in depth the inconsistency problem in robot localization, including simultaneous localization and mapping (SLAM) and multi-robot cooperative localization (CL). In particular, we show for the first time ever that one fundamental cause of inconsistency is the mismatch between the observability properties of the underlying nonlinear system and the linearized system used by the estimator. By performing observability analysis, we prove that the linearized error-state system used by standard filtering/smoothing algorithms—the EKF, the unscented Kalman filter (UKF), and the sliding-window filter (SWF)—has an observable subspace of higher dimension than that of the underlying nonlinear system. This implies that these estimators gain spurious information (more specifically, about the global orientation) from the measurements, which unjustifiably reduces the uncertainty of the state estimates and causes inconsistency. Based on this key insight, for unobservable nonlinear systems, we propose a novel methodology for designing consistent linearized estimators. Specifically, we develop a family of Observability-Constrained (OC)-estimators—including the OC-EKF, the OC-UKF, and the OC-SWF—whose Jacobians are computed in a way to ensure that the estimator's linearized system model has an observable subspace of the same dimension as that of the underlying nonlinear system. Furthermore, we investigate the inconsistency of estimators for observable nonlinear systems, such as target tracking using distance or bearing measurements, whose cost functions are non-convex and often have multiple local minima. In such cases, we discover that the inconsistency of a standard linearized estimator, such as the EKF, is primarily due to the fact that the estimator is able to find and track only one local minimum. To address this issue, we convert the estimator's nonlinear cost function into polynomial form and employ algebraic geometry techniques to analytically compute all its local minima. These local minima are used as initial estimates by a bank of MAP estimators to efficiently track the most probable hypotheses for the entire state trajectory. Moreover, we adapt this idea to particle filters (PFs) and develop an Analytically-Guided-Sampling (AGS)-PF. Specifically, the AGS-PF employs an analytically-determined Gaussian mixture as proposal distribution which not only takes into account the most recent measurement but also matches all the modes of the posterior (optimal proposal) distribution. As a result, the AGS-PF samples the most probable regions of the state space and hence significantly reduces the number of particles required. As precise long-term localization and tracking are essential for a variety of robotic applications, by introducing a solid theoretical framework for improving the consistency of nonlinear estimators, this work offers significant benefits for robots employed in these tasks. Moreover, the proposed solutions constitute novel paradigms for engineers to follow when designing consistent estimators for other nonlinear systems, and hence have the potential to benefit applications beyond robotics.},
  advisor = {Roumeliotis, Stergios},
  isbn = {9781267978141},
  url = {https://hdl.handle.net/11299/146717},
}

@INPROCEEDINGS{kurz-et-al:2021:9636530,
  author = {G. Kurz and M. Holoch and P. Biber},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Geometry-Based Graph Pruning for Lifelong SLAM},
  pages = {3313--3320},
  doi = {10.1109/IROS51168.2021.9636530},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case).},
  location = {Prague, Czech Republic},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS51168.2021.9636530},
}

@INPROCEEDINGS{lidoris-et-al:2009:5152534,
  author = {G. Lidoris and F. Rohrm\"{u}ller and D. Wollherr and M. Buss},
  booktitle = {Proceedings of the 2009 IEEE International Conference on Robotics and Automation},
  title = {The Autonomous City Explorer (ACE) Project: Mobile Robot Navigation in Highly Populated Urban Environments},
  pages = {2238--2244},
  doi = {10.1109/ROBOT.2009.5152534},
  publisher = {IEEE Press},
  year = {2009},
  abstract = {One of the greatest challenges nowadays in robotics is the advancement of robots from industrial tools to companions and helpers of humans, operating in natural, populated environments. In this respect, the Autonomous City Explorer (ACE) project aims to combine the research fields of autonomous mobile robot navigation and human robot interaction. A robot has been created that is capable of navigating in an unknown, highly populated, urban environment, based only on information extracted through interaction with passers-by and its local perception capabilities.This paper describes the algorithms and architecture that make up the navigation subsystem of ACE. More specifically, the algorithms used for Simultaneous Localization and Mapping (SLAM), path planning in dynamic environments and behavior selection are presented, as well as the system architecture that integrates them to a complete working system. Results from an extended field experiment, where the robot navigated autonomously through the downtown city area of Munich, are analyzed and show that the robot is capable of long-term, safe navigation in real-world settings.},
  isbn = {9781424427888},
  location = {Kobe, Japan},
  numpages = {7},
  series = {ICRA'09},
}

@ARTICLE{kretzschmar-stachniss:2012:0278364912455072,
  author = {H. Kretzschmar and C. Stachniss},
  journal = {Int. J. Rob. Res.},
  title = {Information-Theoretic Compression of Pose Graphs for Laser-Based SLAM},
  volume = {31},
  number = {11},
  pages = {1219--1230},
  doi = {10.1177/0278364912455072},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2012},
  month = {9},
  abstract = {In graph-based simultaneous localization and mapping (SLAM), the pose graph grows over time as the robot gathers information about the environment. An ever growing pose graph, however, prevents long-term mapping with mobile robots. In this paper, we address the problem of efficient information-theoretic compression of pose graphs. Our approach estimates the mutual information between the laser measurements and the map to discard the measurements that are expected to provide only a small amount of information. Our method subsequently marginalizes out the nodes from the pose graph that correspond to the discarded laser measurements. To maintain a sparse pose graph that allows for efficient map optimization, our approach applies an approximate marginalization technique that is based on Chow-Liu trees. Our contributions allow the robot to effectively restrict the size of the pose graph. Alternatively, the robot is able to maintain a pose graph that does not grow unless the robot explores previously unobserved parts of the environment. Real-world experiments demonstrate that our approach to pose graph compression is well suited for long-term mobile robot mapping.},
  issn = {0278-3649},
  issue_date = {September 2012},
  keywords = {SLAM, long-term, compression, pose graph, mutual information},
  numpages = {12},
  url = {https://doi.org/10.1177/0278364912455072},
}

@INPROCEEDINGS{murwantara-et-al:2019:3365264,
  author = {I. M. Murwantara and B. Hardjono and A. S. Putra and H. Tjahyadi},
  booktitle = {Proceedings of the 2019 2nd International Conference on Sensors, Signal and Image Processing},
  title = {Towards Elderly Assistance Identification for Service Robot Using Combination of Mappings},
  pages = {62--66},
  doi = {10.1145/3365245.3365264},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  year = {2019},
  abstract = {Identifying request or task for assistance in an elderly or retirement home is a challenge for service robot. It is an essential task for service robot to give their services along with human. Identifying human position in an environment, such as elderly home, is the most challenging task, as it involves static and dynamic object. During its operation, a service robot must avoid collision to objects, and also prepares path for its journey. This work makes use of RGB-D camera, such as Kinect, to identify the static and dynamic object via 3D maps. To manage its path finding, the prediction of people location and position is enabled via Long Term and Short Term Memory been implemented in Real-Time Appearance Based Mapping. The loop closure detection with real time constraints wrapping the collected information that uses RGB-D SLAM method. To identify the human position and flow, a technique of pedestrian detection is added to find group of people, which will gain more understanding on how human will interact to robot. We have demonstrated the work of this initial work by generating 3D point cloud for specific environment through an intensive mapping experiments.},
  isbn = {9781450372435},
  keywords = {RTAB-Map, localization, Service robot, identify request, elderly},
  location = {Prague, Czech Republic},
  numpages = {5},
  series = {SSIP 2019},
  url = {https://doi.org/10.1145/3365245.3365264},
}

@ARTICLE{biswas-veloso:2013:0278364913503892,
  author = {J. Biswas and M. M. Veloso},
  journal = {Int. J. Rob. Res.},
  title = {Localization and Navigation of the CoBots over Long-Term Deployments},
  volume = {32},
  number = {14},
  pages = {1679--1694},
  doi = {10.1177/0278364913503892},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2013},
  month = {12},
  abstract = {For the last three years, we have developed and researched multiple collaborative robots, CoBots, which have been autonomously traversing our multi-floor buildings. We pursue the goal of long-term autonomy for indoor service mobile robots as the ability for them to be deployed indefinitely while they perform tasks in an evolving environment. The CoBots include several levels of autonomy, and in this paper we focus on their localization and navigation algorithms. We present the Corrective Gradient Refinement (CGR) algorithm, which refines the proposal distribution of the particle filter used for localization with sensor observations using analytically computed state space derivatives on a vector map. We also present the Fast Sampling Plane Filtering algorithm that extracts planar regions from depth images in real time. These planar regions are then projected onto the 2D vector map of the building, and along with the laser rangefinder observations, used with CGR for localization. For navigation, we present a hierarchical planner, which computes a topological policy using a graph representation of the environment, computes motion commands based on the topological policy, and then modifies the motion commands to side-step perceived obstacles. We started logging the deployments of the CoBots one and a half years ago, and have since collected logs of the CoBots traversing more than 130 km over 1082 deployments and a total run time of 182 h, which we publish as a dataset consisting of more than 10 million laser scans. The logs show that although there have been continuous changes in the environment, the robots are robust to most of them, and there exist only a few locations where changes in the environment cause increased uncertainty in localization.},
  issn = {0278-3649},
  issue_date = {December  2013},
  keywords = {navigation, long-term autonomy, indoor mobile robots, Localization, autonomous robots},
  numpages = {16},
  url = {https://doi.org/10.1177/0278364913503892},
}

@INPROCEEDINGS{butterworth-et-al:2019:3321995,
  author = {J. Butterworth and R. Savani and K. Tuyls},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  title = {Evolving Indoor Navigational Strategies Using Gated Recurrent Units in NEAT},
  pages = {111--112},
  doi = {10.1145/3319619.3321995},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  year = {2019},
  abstract = {Simultaneous Localisation and Mapping (SLAM) algorithms are expensive to run on smaller robotic platforms such as Micro-Aerial Vehicles. Bug algorithms are an alternative that use relatively little processing power, and avoid high memory consumption by not building an explicit map of the environment. In this work we explore the performance of Neuroevolution - specifically NEAT - at evolving control policies for simulated differential drive robots carrying out generalised maze navigation. We compare this performance with respect to one particular bug algorithm known as I-Bug. We extend NEAT to include Gated Recurrent Units (GRUs) to help deal with long term dependencies. We show that both NEAT and our NEAT-GRU can repeatably generate controllers that outperform I-Bug on a test set of 209 indoor maze like environments. We show that NEAT-GRU is superior to NEAT in this task. Moreover, we show that out of the 2 systems, only NEAT-GRU can continuously evolve successful controllers for a much harder task in which no bearing information about the target is provided to the agent.},
  isbn = {9781450367486},
  keywords = {neuroevolution, memory, NEAT, gated recurrent units, genetic algorithms, maze solving, navigation},
  location = {Prague, Czech Republic},
  numpages = {2},
  series = {GECCO '19},
  url = {https://doi.org/10.1145/3319619.3321995},
}

@ARTICLE{chudoba-et-al:2016:8,
  author = {J. Chudoba and M. Kulich and M. Saska and T. B\'{a}\u{a}\'{z}A and L. P\v{r}eu\u{a}\'{z}Il},
  journal = {J. Intell. Robotics Syst.},
  title = {Exploration and Mapping Technique Suited for Visual-Features Based Localization of MAVs},
  volume = {84},
  number = {1–4},
  pages = {351--369},
  doi = {10.1007/s10846-016-0358-8},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2016},
  month = {12},
  abstract = {An approach for long term localization, stabilization, and navigation of micro-aerial vehicles (MAVs) in unknown environment is presented in this paper. The proposed method relies strictly on onboard sensors of employed MAVs and does not require any external positioning system. The core of the method consists in extraction of information from pictures consequently captured using a camera carried by the particular MAV. Visual features are obtained from images of the surface under the MAV, and stored into a map that is represented by these features. The position of the MAV is then obtained through matching with previously stored features. An important part of the proposed system is a novel approach for exploration and mapping of the workspace of robots. This method enables efficient exploring of the unknown environment, while keeping the iteratively built map of features consistent. The proposed algorithm is suitable for mapping of surfaces, both outdoor and indoor, with various density of the image features. The sufficient precision and long term persistence of the method allows its utilization for stabilization of large MAV groups that work in formations with small relative distances between particular vehicles. Numerous experiments with quadrotor helicopters and various numerical simulations have been realized for verification of the entire system and its components.},
  issn = {0921-0296},
  issue_date = {December  2016},
  keywords = {MAV localization, Mapping, MAV stabilization, Exploration, Visual-features, MAVs},
  numpages = {19},
  url = {https://doi.org/10.1007/s10846-016-0358-8},
}

@INPROCEEDINGS{hu-et-al:2019:8917529,
  author = {J. Hu and M. Yang and H. Xu and Y. He and C. Wang},
  booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
  title = {Mapping and Localization Using Semantic Road Marking with Centimeter-Level Accuracy in Indoor Parking Lots},
  pages = {4068--4073},
  doi = {10.1109/ITSC.2019.8917529},
  publisher = {IEEE Press},
  year = {2019},
  abstract = {Accurate localization is one of the fundamental tasks of vehicles visual navigation in parking lots. In this paper, we propose a practical and novel solution, which exploits road marking semantic segmentation to attack the problem of long-term and high-precision visual localization. Based on the semantic data association derived from road markings segmentation, point cloud fusion and loop detection strategies are designed to improve the performance of semantic map building. Applying the generated map, we present a point cloud registration algorithm combining semantic and geometric inference to improve the localization precision. Experiments on real-world indoor parking lots prove that the semantic map created by the proposed method reveals more accurate and consistent performance. Moreover, localization error is no more than 10cm, while running in real-time performance.},
  location = {Auckland, New Zealand},
  numpages = {6},
  url = {https://doi.org/10.1109/ITSC.2019.8917529},
}

@INPROCEEDINGS{kiam-schulte:2018:00062,
  author = {J. J. Kiam and A. Schulte},
  booktitle = {2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title = {Multilateral Mission Planning in a Time-Varying Vector Field with Dynamic Constraints},
  pages = {305--310},
  doi = {10.1109/SMC.2018.00062},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {Navigating in a vector field is a challenging problem for many autonomous vehicles. This article focuses on a High-Altitude Pseudo-Satellite (HAPS) operating in a wind field with wind magnitude comparable to its airspeed. In addition to navigating from a start to a goal point, the HAPS is expected to carry out patrolling missions spanning long hours/ days, within which the physical environment (e.g. wind field, weather-critical no-go areas, fly zones etc.) vary, resulting in either an improvement or a deterioration of mission fulfillment. A time-dependent hybrid mission planning framework is proposed in this work which consists firstly of a hierarchical strategic planner that produces very quickly multiple sequences of tasks (or rather "premature plans") that are ranked with roughly estimated objective or penalty values, and secondly of a tactical planner that refines the values of each premature plan to help the operator assess the plans better. The framework was implemented on the long-term offline planner for HAPS in patrolling missions. Test results using an independent six degrees-of-freedoms HAPS simulator and historical weather data are provided and analyzed.},
  location = {Miyazaki, Japan},
  numpages = {6},
  url = {https://doi.org/10.1109/SMC.2018.00062},
}

@ARTICLE{blanco-et-al:2009:002,
  author = {J. L. Blanco and J. Gonz\'{a}lez and J.-A. Fern\'{a}ndez-Madrigal},
  journal = {Robot. Auton. Syst.},
  title = {Subjective Local Maps for Hybrid Metric-Topological SLAM},
  volume = {57},
  number = {1},
  pages = {64--74},
  doi = {10.1016/j.robot.2008.02.002},
  publisher = {North-Holland Publishing Co.},
  address = {NLD},
  year = {2009},
  month = {1},
  abstract = {Hybrid maps where local metric submaps are kept in the nodes of a graph-based topological structure are gaining relevance as the focus of robot Simultaneous Localization and Mapping (SLAM) shifts towards spatial scalability and long-term operation. In this paper we examine the applicability of spectral graph partitioning techniques to the automatic generation of metric submaps by establishing groups in the sequence of observations gathered by the robot. One of the main aims of this work is to provide a probabilistically grounded interpretation of such a partitioning technique in the context of generating local maps. We also discuss how to apply it to different kinds of sensory data (landmarks extracted from stereo images and laser range scans) and how to consider them simultaneously. An important feature of our approach is that the partitioning takes into account the intrinsic characteristics of the sensors, such as the sensor field of view, instead of applying heuristics supplied by a human as in other works. Thus the robot builds ''subjective'' local maps whose size will be determined by the nature of the sensors. The ideas presented here are supported by experimental results from a real mobile robot as well as simulations for statistical analysis. We discuss the effects of considering different combinations of sensors in the resulting clustering of the environment.},
  issn = {0921-8890},
  issue_date = {January, 2009},
  keywords = {Hybrid maps, Map building, Simultaneous Localization and Mapping (SLAM), Graph partitioning},
  numpages = {11},
  url = {https://doi.org/10.1016/j.robot.2008.02.002},
}

@INPROCEEDINGS{mccormac-et-al:2017:7989538,
  author = {J. McCormac and A. Handa and A. Davison and S. Leutenegger},
  booktitle = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {SemanticFusion: Dense 3D Semantic Mapping with Convolutional Neural Networks},
  pages = {4628--4635},
  doi = {10.1109/ICRA.2017.7989538},
  publisher = {IEEE Press},
  year = {2017},
  abstract = {Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance — they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ≈25Hz.},
  location = {Singapore, Singapore},
  numpages = {8},
  url = {https://doi.org/10.1109/ICRA.2017.7989538},
}

@INPROCEEDINGS{oliveira-et-al:2021:11,
  author = {J. Oliveira and F. Mutz and A. Forechi and P. Azevedo and T. Oliveira-Santos and A. F. D. Souza and C. Badue},
  booktitle = {Intelligent Systems: 10th Brazilian Conference, BRACIS 2021, Virtual Event, November 29 – December 3, 2021, Proceedings, Part II},
  title = {Long-Term Map Maintenance in&nbsp;Complex Environments},
  pages = {146--161},
  doi = {10.1007/978-3-030-91699-2_11},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  year = {2021},
  abstract = {As changes in external environments are inevitable, a lifelong mapping system is desirable for autonomous robots that aim at long-term operation. Capturing external environment changes into internal representations (for example, maps) is crucial for proper behavior and safety, especially in the case of autonomous vehicles. In this work, we propose a new large-scale mapping system for our autonomous vehicle or any other. The new mapping system is based on the Graph SLAM algorithm, with extensions to deal with the calibration of odometry directly in the optimization of the graph and to address map merging for long-term map maintenance. The mapping system can use sensor data from one or more robots to build and merge different types of occupancy grid maps. The system’s performance is evaluated in a series of experiments carried out with data captured in complex real-world scenarios. The experimental results indicate that the new large-scale mapping system can provide high-quality occupancy grid maps for later navigation and localization of autonomous vehicles that use occupancy grid maps.},
  isbn = {978-3-030-91698-5},
  keywords = {SLAM, Mapping, Map maintenance, Map merging, Autonomous vehicles},
  numpages = {16},
  url = {https://doi.org/10.1007/978-3-030-91699-2_11},
}

@INPROCEEDINGS{peltom\"{a}ki-et-al:2021:9636320,
  author = {J. Peltom\"{a}ki and F. Alijani and J. Puura and H. Huttunen and E. Rahtu and J.-K. K\"{a}m\"{a}r\"{a}inen},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Evaluation of Long-Term LiDAR Place Recognition},
  pages = {4487--4492},
  doi = {10.1109/IROS51168.2021.9636320},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {We compare a state-of-the-art deep image retrieval and a deep place recognition method for place recognition using LiDAR data. Place recognition aims to detect previously visited locations and thus provides an important tool for navigation, mapping, and localisation. Experimental comparisons are conducted using challenging outdoor and indoor datasets, Oxford Radar RobotCar and COLD, in the "long-term" setting where the test conditions differ substantially from the training and gallery data. Based on our results the image retrieval methods using LiDAR depth images can achieve accurate localization (the single best match recall 80%) within 5.00 m in urban outdoors. In office indoors the comparable accuracy is 50 cm but is more sensitive to changes in the environment.},
  location = {Prague, Czech Republic},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS51168.2021.9636320},
}

@INPROCEEDINGS{berrio-et-al:2019:8814289,
  author = {J. S. Berrio and J. Ward and S. Worrall and E. Nebot},
  booktitle = {2019 IEEE Intelligent Vehicles Symposium (IV)},
  title = {Identifying Robust Landmarks in Feature-Based Maps},
  pages = {1166--1172},
  doi = {10.1109/IVS.2019.8814289},
  publisher = {IEEE Press},
  year = {2019},
  abstract = {To operate in an urban environment, an automated vehicle must be capable of accurately estimating its position within a global map reference frame. This is necessary for optimal path planning and safe navigation. To accomplish this over an extended period of time, the global map requires long term maintenance. This includes the addition of newly observable features and the removal of transient features belonging to dynamic objects. The latter is especially important for the long-term use of the map as matching against a map with features that no longer exist can result in incorrect data associations, and consequently erroneous localisation. This paper addresses the problem of removing features from the map that correspond to objects that are no longer observable/present in the environment. This is achieved by assigning a single score which depends on the geometric distribution and characteristics when the features are re-detected (or not) on different occasions. Our approach not only eliminates ephemeral features, but can also be used as a reduction algorithm for highly dense maps. We tested our approach using half a year of weekly drives over the same 500 metre section of road in an urban environment. The results presented demonstrate the validity of the long term approach to map maintenance.},
  location = {Paris, France},
  numpages = {7},
  url = {https://doi.org/10.1109/IVS.2019.8814289},
}

@BOOK{wind-et-al:2001,
  author = {J. Wind and V. Mahajan and J. Hagel},
  title = {Convergence Marketing: Strategies for Reaching the New Hybrid Consumer},
  pages = {},
  doi = {},
  publisher = {Financial Times/Prentice Hall},
  year = {2001},
  abstract = {From the Book: Preface: Running with the Centaur A businessman is a hybrid of a dancer and a calculator. —Paul Valery, French Poet and Philosopher The Internet revolution didn't turn out to be anything like we thought it would be. At the end of the 1990s, the discussion of many observers, we among them, focused on the rise of the cyberconsumer and the emergence of Internet marketing. At the extreme, the image of this cyberconsumer was humorously caricatured in a series of Sprint commercials introducing its wireless web, in which people hunched over their computers in dark rooms were invited at long last to step out into the sunlit world. The business model designed for the cyberconsumer was the pure play Internet firm, either a separate dot-com or a stand-alone division of a larger company. But the cyberconsumer was largely a myth. Consumers didn't behave anything like we thought they would. Today, we are entering the age of the centaur. Consumers act across multiple channels. They combine timeless human needs and behaviors with new online activities. They are like the centaur of Greek mythology--half human and half horse—running with the rapid feet of new technology, yet carrying the same ancient and unpredictable human heart. This consumer is a combination of traditional and cyber, rational and emotional, wired and physical. This consumer is not eitheror, but both. The authors came to this center from opposite directions. Jerry Wind was an early champion of digital marketing, highlighting the revolutionary changes of the Internet on consumer behavior, marketing and business strategy. He urged executives to consider the potential of this new technology to transform their businesses. Vijay Mahajan pointed out that not everything had changed, and that many aspects of consumer behavior and marketing remained the same. He urged executives to consider the enduring human characteristics that would continue to shape marketing and business strategy. As we discussed the issue from these two viewpoints, working on a series of projects that led to this book, we came to the conclusion that we were both right: the reality was the hybrid consumer. This is not to suggest that there are three separate segments (traditional, cyberconsumer and centaur). The reality is convergence. The entire market is becoming centaurs, either directly or indirectly (even if someone is not online, their behavior will still be affected by new technologies, channels and products, and service offerings). This is why we focus so much on the centaur. The centaurs, in turn, are heterogeneous, so there will be many segments among these hybrid consumers. Even the most tech savvy of U.S. consumers—the 18 to 25 year olds of Generation Y—are not strictly cyberconsumers. A recent survey of more than 600 Gen-Y respondents (51 percent of whom had made online purchases in the past year) found that nearly 40 percent learned about the product online, but bought at a physical store, whereas only 9.3 percent began and ended their search online. When asked where they would prefer to shop, nearly three-quarters chose a store rather than online. Across the spectrum, consumers are combining various channels and approaches, searching online to buy offline, searching offline to buy online—and everything in between. Charles Schwab found that while about 90 percent of all trades are handled online, 60-70 percent of new accounts are set up in branch offices. People want to be able to see whom they are working with when they turn over their money. Benefits of Convergence The power of hybrid models can be seen in the success of Tesco, which raced past pioneers such as Peapod and Webvan to become the largest online grocer in the world. Tesco, using its century-old platform of retail stores in the U.K. as the launching pad for its online service, created a profitable online business that was handling 70,000 orders per week by mid 2001 and had racked up more than $400 million in sales the year before. Tesco could set up its online grocery business for a fraction of the investment of Webvan because it was able to build off its existing infrastructure. Tesco has moved into the U.S. market, purchasing a 35 percent investment in Safeway's online grocery service in June 2001, and announcing plans for expansion into South Korea. The power and profit of the hybrid model can also be seen in the success of Staples.com, which expected to grow online revenues to $1 billion in 2001, nearly 10 percent of company sales. Even more significant, Staples found that the addition of the new channel is not cannibalistic, but synergistic. Overall, customers who shop in the store and catalog spend twice as much as those who shop in the store alone, and customers that shop using the store, catalog, and online channels spend an average of $2,500, nearly four times as much as store shoppers. The results achieved by Staples and other firms offer a sense of the potential return on investment from meeting the centaur. Convergence strategies offer a variety of opportunities for generating new revenues, reducing costs and creating valuable options for the future. Changing Mind Sets There is emerging evidence of the immediate benefits of convergence strategies, if investments are made strategically, but these short-term gains are not the only opportunity. Our focus is to look at the opportunities, both short- and long-term, created by the emergence of the hybrid consumer and how companies can capitalize on these opportunities. The last category may be the most important: the options that convergence strategies create for the future. This book takes a broader view of the strategic impact of the centaur for marketing and business strategy, and the architecture of the organization. If you believe, as we do, that the centaur is the future of our markets, then the ability to succeed in the future depends on understanding and running with the centaur. Failure to understand these changes creates the risk of significant lost opportunities. What can the integration of the offline marketplace and the online marketspace do for consumers that neither can do alone What business principles will guide the integration How is marketing changing How do these shifts affect short-term and long-term profitability and growth What Is Converging Convergence, as we discuss it here, means more than the fusion of different technologies (television, computers, wireless, PDAs) or the combination of channels (such as Tesco's or Staple's bricks-and-clicks model). We focus on a more basic convergence within the consumer—the new possibilities created by the technology and the enduring behaviors of human beings. This convergence will shape how the Internet and other new technologies unfold, and the opportunities created for companies. What can consumers do with the technology that they could not do in the past When will they continue to do things in the way they always have Although most of the focus in this book is on business-to-consumer interactions, many of the insights apply equally to business-to-business strategy. The line between B2B and B2C is already blurring. In an environment in which Sun Microsystems is selling products on eBay, is this B2B or B2C In an environment in which a customer may soon be able to click an order button for an automobile and set in motion a global supply chain to deliver that car, where does B2C end and B2B begin Lessons from the Dot-Coms This book examines the practices of a variety of companies, but we must stress at the outset that these firms are not held up as ultimate models. They all have something to teach us, but many of the successful companies of a year or two ago are now fighting for their lives. And some companies that were all but written off are back in force. We suspect the same unpredictable dynamic will be seen in the future. This is a particularly dangerous time to engage in benchmarking or to search for excellence. It is not a time for simple recipes. Instead, it is far more important to gain a deeper understanding of how consumers are changing and how they are remaining the same. The actions of these hybrid consumers will shape the way technology is adopted and, ultimately, the future of your markets. We should take a balanced view of dot-com failures. Mark Twain once said, We should be careful to get out of an experience only the wisdom that is in it. Twain gives the example of a cat who sits on a hot stove, and learns not to sit on a hot stove again—but also won't sit on a cold stove. The failures of the first wave of dot-coms offer many lessons about what to do, and what not to do, but we need to be careful in taking lessons from them. Although some of the companies that failed had weak business models, some actually had brilliant marketing strategies and business models. The failure of the business is not necessarily an indictment of the idea. Some may have arrived slightly ahead of their time. Some may have suffered from poor execution. It may be that the time is now right for these ideas to flourish. During the Internet bubble, we have engaged in one of the most extensive, investor-financed experiments in new business models and paradigms. There has been an explosion of experimentation. Although many of these experiments proved to be unprofitable, many new ideas were developed and tested. Incumbent companies and startups that are still alive can benefit greatly from the acceleration of knowledge from this dot-com school of hard knocks. Pick through the wreckage and look carefully at what happened. Then take away the lessons that you can use. The Implications of the Centaur In this book, we offer insights to top executives and key organizational change agents on the characteristics and behavior of these hybrid centaurs and how we need to reshape our marketing and business strategy to meet them. The book explores different intersections between the consumer, technology and company and their implications for marketing and business strategy and organizational design. We examine the emergence of the centaur, and the marketing, business and organizational challenges and opportunities created. Part I offers a portrait of this centaur, what has changed and what remains the same. We also discuss how the focus on the customer has often been lost in the emphasis on technology. These centaurs are complex beings, with a love-hate relationship with the technology, buying books from Amazon.com one day and relaxing in an armchair sipping cappuccino at Barnes &amp; Noble the next. Part II explores issues at the intersection between the consumer and technology. We consider five key issues at the core of addressing these new hybrid consumers—customerization, communities, channel options, new competitive value propositions, and choice tools. Although these issues have been discussed in the context of the cyberconsumer, they are quite different from the perspective of the centaur. Sometimes consumers want customerization (customized products and services as well as customized marketing), but other times they want to pull standard products off the shelf and receive mass marketing messages. Consumers are members of both physical and virtual communities. The hybrid consumers want to be able—in the words of Fidelity—to call, click, or visit. They are redefining the traditional sources of value, buying products by auction or fixed price or name-your-own price depending on their mood and purchase situation, creating a new value equation. Finally, the Internet offers powerful tools to find information, make decisions, and manage one's life. These tools empower consumers, changing the way they interact with the company. How can you create convergence strategies to address these interrelated issues Part III examines the impact of the centaur on marketing and business strategies. As the consumer connects much more directly to companies, marketing has a deeper role to play. Marketing creates new opportunities for growth and rethinking the company's offering, pricing and market boundaries. The centaur has also transformed the traditional 4 Ps of marketing, along with strategies for segmentation, positioning, customer relationships, branding, and marketing research. As these changes send shockwaves through the organization, another type of convergence is called for—in organizational design. Part IV explores some of the fundamental transformations established organizations need to undergo to meet the centaur. To navigate the whitewater rapids of convergence and change, organizations need new organizational architectures. They need to change their architectures, creating a broader c-change to facilitate convergence across the organization and its ecosystem. The overall objective is to suggest a new consumer-centric mental model through which to examine the entire business. The kind of shift we are talking about is what Bill Gates describes in the transformation of Microsoft's original mission of a PC on every desk to its current mission to empower people through great software, any time, any place and on any device. The focus is on the convergence of technology and consumer needs. This book is designed to be an interactive experience. Each chapter begins with a dialogue representing different viewpoints on convergence. Callouts highlight key convergence questions that you can use to challenge yourself and to assess your company's progress. Finally, the close of every chapter offers an action memo, a set of illustrative hands-on experiments for exploring and applying convergence strategies. We have found the only way to master these new technologies and strategies is to actually experience them and apply them to your own business. These action memos are not intended to be exhaustive or to summarize key themes of the chapter, but represent a starting point for your own experiments. We encourage you to share those experiments with us, and other readers, at the Convergence Marketing Forum (convergencemarketingforum.com). The Relentless March of the Centaur As Internet penetration increases—and new technologies emerge—we are seeing a relentless march of these new hybrid centaurs. We cannot judge the potential of the Internet and other technologies by their current primitive level of development. John Hagel, author of Net Gain and Net Worth, says if we compare the Internet to a ballgame, we are still waiting for the national anthem to finish. Michael Nelson, Director of Internet Technology and Strategy at IBM, estimated in 2000 that we were maybe 3 percent of the way into the Internet revolution. He also points out that increased speed of connection, which has been a central focus of attention in the evolution of the Internet, is only a small part of the power of the emerging online world. In addition to raw speed, the fact that the Internet will be always on, everywhere, natural, intelligent, easy, and trusted, will deepen the role of the Internet in our lives. Nelson compares the development of the Internet to the early days of the electric grid. The Internet right now is at the light bulb stage, Nelson said. The light bulb is very useful, but it is only one of thousands of uses of electricity. Similarly, when the next-generation Internet is fully deployed, we will use it in thousands of different ways, many of which we can't even imagine now. It will just be part of everyday life—like electricity or plumbing is today. We'll know we've achieved this when we stop talking about 'going on the Internet.' When you blow dry your hair, you don't talk about 'going on' the electric grid. There will be naysayers who will use the limitations of the current state of technology as a reason for inaction. Customization is often neither cheap nor simple. Early interfaces with online sites were clunky at best and many home connections remain slow. Throughout this book, we look at the current and future potential of technology and explore how the consumer will interact with it. We won't waste your time giving you a repair manual for a Model T, but instead explore how motor vehicles (particularly newer, more reliable versions) create opportunities for activities such as commerce and family vacations by car. While we must be realistic, we cannot become too mired in the past when the future is so rapidly emerging. Children of Centaurs: In the Forests of the North It is clear that we are just getting started with the Internet, and we are even earlier on the learning curve for the new wireless consumers beginning to emerge. Even as businesses are scurrying to absorb the revolution of the Internet, teenagers in Europe and Asia are already shaping the next revolution in mobile communication and commerce. This revolution will play out differently in different parts of the world, and it will probably play out differently than we expect, unless we truly understand the new hybrid consumer. It poses new convergence challenges, but raises the same timeless questions: How will consumers interact with the technology Again, this interaction between people and technology will not always be as businesses anticipated. Helsinki teenager Lauri Taehtinen, speaking on a panel of Finnish teenagers at the Wharton Fellows in e-Business Program, said that when he goes out on a Friday night, he doesn't make plans anymore. Instead the 19-year-old goes downtown and starts sending short messages on his mobile phone, pinging his friends to see who's out there. They connect by cell phone and then decide where they want to go for the evening. While companies are excited about developing mobile information services that might help customers identify night clubs or order fast food, Taehtinen and his peers are more interested in connection. In an environment in which virtually every teenager carries a mobile phone (Finnish market penetration of 78 percent means almost every citizen above the age of 10 carries at least one mobile phone), the mobile conversation is continuous and ubiquitous. Among U.K. teens, short messages outnumber phone conversations three to one, and the parallel phenomenon of instant messaging is one of the most popular applications of teenagers on the PC in the United States and other parts of the world. The very fact that short messages (SMS) are the top application of mobile phones in Finland is, at first, a surprising thing. The handsets, designed for voice, are not friendly to the process of messaging. Users tap out their 160-word messages on numeric keyboards through complex, rapid-fire keystrokes, smart systems, and creative workarounds. With users paying a charge to send each message on most systems, it would seem unlikely that SMS would be a central part of the mobile phone business. But these young centaurs want to communicate, and they don't let the technology get in their way. It was only in the interaction between consumers and technology that that power of short messages became apparent. Just as email has been the killer application of the Internet, mobile technology is being bent to the human desire to communicate and connect. People don't want to be entertained, Taehtinen bluntly states. They don't want information. If you go into Internet cafes, you see people are not reading the news; they are all sending email or chatting online. They are willing to pay for social interaction. People want to belong to something. Enduring Lessons While communications and information technology may be ephemeral and uncertain, there are at least two enduring lessons: The first is that the new technologies, as much as their proponents may want them to, do not replace the old. They live side by side, and they converge. The second is that people are complex, retaining the same enduring human needs even as they adapt to new technologies and behaviors. These may seem like fairly obvious, even simplistic, statements. But they have been overlooked more often than recognized in the mad rush to adopt new technology. These realities have fundamental implications for marketing and business strategy. What they mean is that there needs to be a convergence of the old technology and the new to create a portfolio of technologies and channels. The storefront and catalog don't go away when you add the Internet. And, even more important, there is an interaction between humans and technology that changes both. There is a convergence of old consumer behaviors and new behaviors that affects the trajectory of technology, the strategies for marketing and, ultimately, the design of the business. More Human The wonderful thing about our interactions with machines is not in the ways machines can be made to behave in more human ways, but in the way these interactions make it easier for us to see what distinguishes us as humans. The more we move to machine-mediated interactions, the more we see the fundamental and enduring behaviors that are at the core of marketing and business strategy. It is this interaction between man and machine that is changing us, transforming the practice of marketing and our organizations. In this book, we examine how we need to transform our thinking about the nature of these emerging consumers. We explore how to reach these centaurs and establish long-lasting relationships with them. We look at the ways that they remain the same and the ways that they are fundamentally different in their expectations and behaviors. And we consider how they have irrevocably changed—and continue to change—the theory and practice of marketing, and the design of our organizations.},
  isbn = {0130650757},
}

@INPROCEEDINGS{pauls-et-al:2020:9341003,
  author = {J.-H. Pauls and K. Petek and F. Poggenhans and C. Stiller},
  booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Monocular Localization in HD Maps by Combining Semantic Segmentation and Distance Transform},
  pages = {4595--4601},
  doi = {10.1109/IROS45743.2020.9341003},
  publisher = {IEEE Press},
  year = {2020},
  abstract = {Easy, yet robust long-term localization is still an open topic in research. Existing approaches require either dense maps, expensive sensors, specialized map features or proprietary detectors.We propose using semantic segmentation on a monocular camera to localize directly in a HD map as used for automated driving. This combines lightweight, yet powerful HD maps with the simplicity of monocular vision and the flexibility of neural networks.The major challenges arising from this combination are data association and robustness against misdetections. Association is solved efficiently by applying distance transform on binary per-class images. This provides not only a fast lookup table for a smooth gradient as needed for pose-graph optimization, but also dynamic association by default.A sliding-window pose graph optimization combines single image detections with vehicle odometry, smoothing results and helping overcome even misclassifications in consecutive frames.Evaluation against a highly accurate 6D visual localization shows that our approach can achieve accuracy levels as required for automated driving, being one of the most lightweight and flexible methods to do so.},
  location = {Las Vegas, NV, USA},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS45743.2020.9341003},
}

@ARTICLE{lee-chung:2010:1,
  author = {J.-S. Lee and W. K. Chung},
  journal = {Auton. Robots},
  title = {Robust Mobile Robot Localization in Highly Non-Static Environments},
  volume = {29},
  number = {1},
  pages = {1--16},
  doi = {10.1007/s10514-010-9184-1},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2010},
  month = {7},
  abstract = {In this paper, we propose a robust pose tracking method for mobile robot localization with an incomplete map in a highly non-static environment. This algorithm will work with a simple map that does not include complete information about the non-static environment. With only an initial incomplete map, a mobile robot cannot estimate its pose because of the inconsistency between the real observations from the environment and the predicted observations on the incomplete map. The proposed localization algorithm uses the approach of sampling from a non-corrupted window, which allows the mobile robot to estimate its pose more robustly in a non-static environment even when subjected to severe corruption of observations. The algorithm sequence involves identifying the corruption by comparing the real observations with the corresponding predicted observations of all particles, sampling particles from a non-corrupted window that consists of multiple non-corrupted sets, and filtering sensor measurements to provide weights to particles in the corrupted sets. After localization, the estimated path may still contain some errors due to long-term corruption. These errors can be corrected using nonlinear constrained least-squares optimization. The incomplete map is then updated using both the corrected path and the stored sensor information. The performance of the proposed algorithm was verified via simulations and experiments in various highly non-static environments. Our localization algorithm can increase the success rate of tracking its pose to more than 95% compared to estimates made without its use. After that, the initial incomplete map is updated based on the localization result.},
  issn = {0929-5593},
  issue_date = {July      2010},
  keywords = {Monte Carlo localization (MCL), Non-static environment, Pose tracking, Localization, Mobile robot},
  numpages = {16},
  url = {https://doi.org/10.1007/s10514-010-9184-1},
}

@INPROCEEDINGS{tsintotas-et-al:2021:9651458,
  author = {K. A. Tsintotas and L. Bampis and S. An and G. F. Fragulis and S. G. Mouroutsos and A. Gasteratos},
  booktitle = {2021 IEEE International Conference on Imaging Systems and Techniques (IST)},
  title = {Sequence-Based Mapping for Probabilistic Visual Loop-Closure Detection},
  pages = {1--6},
  doi = {10.1109/IST50367.2021.9651458},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {During simultaneous localization and mapping, the robot should build a map of its surroundings and simultaneously estimate its pose in the generated map. However, a fundamental task is to detect loops, i.e., previously visited areas, allowing consistent map generation. Moreover, within long-term mapping, every autonomous system needs to address its scalability in terms of storage requirements and database search. In this paper, we present a low-complexity sequence-based visual loop-closure detection pipeline. Our system dynamically segments the traversed route through a feature matching technique in order to define sub-maps. In addition, visual words are generated incrementally for the corresponding sub-maps representation. Comparisons among these sequences-of-images are performed thanks to probabilistic scores originated from a voting scheme. When a candidate sub-map is indicated, global descriptors are utilized for image-to-image pairing. Our evaluation took place on several publicly-available datasets exhibiting the system’s low complexity and high recall compared to other state-of-the-art approaches.},
  location = {Kaohsiung, Taiwan},
  numpages = {6},
  url = {https://doi.org/10.1109/IST50367.2021.9651458},
}

@TECHREPORT{sarachik:1989,
  author = {K. B. Sarachik},
  title = {Visual Navigation: Constructing and Utilizing Simple Maps of an Indoor Environment},
  pages = {},
  publisher = {Massachusetts Institute of Technology},
  address = {USA},
  year = {1989},
  abstract = {The goal of this work is to navigate through an office environment using only visual information gathered from four cameras placed onboard a mobile robot. The method is insensitive to physical changes within the room it is inspecting, such as moving objects. Forward and rotational motion vision are used to find doors and rooms, and these can be used to build topological maps. The map is built without the use of odometry or trajectory integration. The long term goal of the project described here is for the robot to build simple maps of its environment and to localize itself within this framework.},
  url = {http://hdl.handle.net/1721.1/6829},
}

@INPROCEEDINGS{graves-et-al:1997:613834,
  author = {K. Graves and W. Adams and A. Schultz},
  booktitle = {Proceedings of the 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation},
  title = {Continuous Localization in Changing Environments},
  pages = {28--33},
  doi = {10.1109/CIRA.1997.613834},
  publisher = {IEEE Computer Society},
  address = {USA},
  year = {1997},
  abstract = {Continuous localization is a technique that allows a robot to maintain an accurate estimate of its location by performing regular, small corrections to its odometry. Continuous localization uses an evidence grid representation, a common representation scheme that is used by other map-dependent processes, such as path planning. Although techniques exist for building evidence grid maps, most are not adaptive to changes in the environment. In this research, we extend the continuous localization technique by adding a learning component. This allows continuous localization to update the long-term map (evidence grid) with current sensor readings. Results show that the addition of the learning behavior to continuous localization allows the system to adapt to changes in its environment without a loss in its ability to remain localized. This system was tested on a Nomad 200 mobile robot.},
  isbn = {0818681381},
  keywords = {Continuous Localization, Evidence Grids, Map Learning},
  series = {CIRA '97},
}

@INPROCEEDINGS{oliver-burnett:2008:1409254,
  author = {K. J. Oliver and G. E. Burnett},
  booktitle = {Proceedings of the 10th International Conference on Human Computer Interaction with Mobile Devices and Services},
  title = {Learning-Oriented Vehicle Navigation Systems: A Preliminary Investigation in a Driving Simulator},
  pages = {119--126},
  doi = {10.1145/1409240.1409254},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  year = {2008},
  abstract = {Vehicle navigation systems aim to reduce the mental workload for drivers by automating elements of the driving task. Concern has been raised, however, that their long-term use may cause unforeseen problems, including suppressing cognitive map development.A driving simulator study was conducted to discover if this effect could be ameliorated by the use of a novel, learning-oriented, navigation system. The user-interface of this system provided a range of additional features including landmarks, compass bearings and previously driven routes within the visual and auditory guidance instructions.It was found that the users of the learning-oriented system displayed better memory for driven routes, when compared with those using a basic guidance system. It is also suggested that they had developed a better cognitive map of the area. Glance analysis demonstrated that the learning-oriented system was no more visually demanding than the basic system.},
  isbn = {9781595939524},
  keywords = {vehicle guidance, vehicle navigation, satellite navigation, driver distraction, cognitive map, driver workload},
  location = {Amsterdam, The Netherlands},
  numpages = {8},
  series = {MobileHCI '08},
  url = {https://doi.org/10.1145/1409240.1409254},
}

@ARTICLE{lenac-et-al:2018:0278364918767756,
  author = {K. Lenac and J. ?esi\'{c} and I. Markovi\'{c} and I. Petrovi\'{c}},
  journal = {Int. J. Rob. Res.},
  title = {Exactly Sparse Delayed State Filter on Lie Groups for Long-Term Pose Graph SLAM},
  volume = {37},
  number = {6},
  pages = {585--610},
  doi = {10.1177/0278364918767756},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2018},
  month = {5},
  abstract = {In this paper we propose a simultaneous localization and mapping SLAM back-end solution called the exactly sparse delayed state filter on Lie groups LG-ESDSF. We derive LG-ESDSF and demonstrate that it retains all the good characteristics of the classic Euclidean ESDSF, the main advantage being the exact sparsity of the information matrix. The key advantage of LG-ESDSF in comparison with the classic ESDSF lies in the ability to respect the state space geometry by negotiating uncertainties and employing filtering equations directly on Lie groups. We also exploit the special structure of the information matrix in order to allow long-term operation while the robot is moving repeatedly through the same environment. To prove the effectiveness of the proposed SLAM solution, we conducted extensive experiments on two different publicly available datasets, namely the KITTI and EuRoC datasets, using two front-ends: one based on the stereo camera and the other on the 3D LIDAR. We compare LG-ESDSF with the general graph optimization framework g 2 o when coupled with the same front-ends. Similarly to g 2 o the proposed LG-ESDSF is front-end agnostic and the comparison demonstrates that our solution can match the accuracy of g 2 o , while maintaining faster computation times. Furthermore, the proposed back-end coupled with the stereo camera front-end forms a complete visual SLAM solution dubbed LG-SLAM. Finally, we evaluated LG-SLAM using the online KITTI protocol and at the time of writing it achieved the second best result among the stereo odometry solutions and the best result among the tested SLAM algorithms.},
  issn = {0278-3649},
  issue_date = {5 2018},
  keywords = {Lie groups, exactly sparse delayed state filter, SLAM, graph optimization},
  numpages = {26},
  url = {https://doi.org/10.1177/0278364918767756},
}

@INPROCEEDINGS{liu-et-al:2019:33018034,
  author = {K. Liu and H. Wang and F. Han and H. Zhang},
  booktitle = {Proceedings of the Thirty-Third AAAI Conference on Artificial Intelligence and Thirty-First Innovative Applications of Artificial Intelligence Conference and Ninth AAAI Symposium on Educational Advances in Artificial Intelligence},
  title = {Visual Place Recognition via Robust ℓ2-Norm Distance Based Holism and Landmark Integration},
  pages = {8034--8041},
  doi = {10.1609/aaai.v33i01.33018034},
  publisher = {AAAI Press},
  year = {2019},
  abstract = {Visual place recognition is essential for large-scale simultaneous localization and mapping (SLAM). Long-term robot operations across different time of the days, months, and seasons introduce new challenges from significant environment appearance variations. In this paper, we propose a novel method to learn a location representation that can integrate the semantic landmarks of a place with its holistic representation. To promote the robustness of our new model against the drastic appearance variations due to long-term visual changes, we formulate our objective to use non-squared ℓ2-norm distances, which leads to a difficult optimization problem that minimizes the ratio of the ℓ2,1 -norms of matrices. To solve our objective, we derive a new efficient iterative algorithm, whose convergence is rigorously guaranteed by theory. In addition, because our solution is strictly orthogonal, the learned location representations can have better place recognition capabilities. We evaluate the proposed method using two large-scale benchmark data sets, the CMU-VL and Nord-land data sets. Experimental results have validated the effectiveness of our new method in long-term visual place recognition applications.},
  articleno = {985},
  isbn = {978-1-57735-809-1},
  location = {Honolulu, Hawaii, USA},
  numpages = {8},
  series = {AAAI'19/IAAI'19/EAAI'19},
  url = {https://doi.org/10.1609/aaai.v33i01.33018034},
}

@INPROCEEDINGS{qiu-shen:2017:8205992,
  author = {K. Qiu and S. Shen},
  booktitle = {2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Model-Aided Monocular Visual-Inertial State Estimation and Dense Mapping},
  pages = {1783--1789},
  doi = {10.1109/IROS.2017.8205992},
  publisher = {IEEE Press},
  year = {2017},
  abstract = {Robust state estimation and real-time dense mapping are two core capabilities for autonomous navigation of mobile robots. Global Navigation Satellite System (GNSS) and visual odometry/SLAM are popular methods for state estimation. However, when working between tall buildings or in indoor environments, GNSS fails due to limited sky view or obstruction from buildings. Visual odometry/SLAM are prone to long-term drifting in the absence of reliable loop closure detection. A state estimation method with global-consistent guarantee is desirable for navigation applications. As for real-time mapping, SLAM methods usually get a sparse map that is not good enough for obstacle avoidance and path-planning, and high-quality dense mapping is often computationally too demanding for mobile devices. Realizing the availability of city-scale 3D models, in this work, we improve our previous work on model-based global localization, and propose a model-aided monocular visual-inertial state estimation and dense mapping solution. We first develop a global-consistent state estimator by fusing visual-inertial odometry with the model-based localization results. Utilizing depth prior from the model, we perform motion stereo with semi-global disparity smoothing. Our dense mapping pipeline is capable of online detection of obstacles that are originally not included in the offline 3D model. Our method runs onboard an embedded computer in real-time. We validate both the state estimation and mapping accuracy in real-world experiments.},
  location = {Vancouver, BC, Canada},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS.2017.8205992},
}

@PHDTHESIS{shamaei-et-al:2020,
  author = {K. Shamaei and L. Swindlehurst and E. Ayanoglu},
  title = {Exploiting Cellular Signals for Navigation: 4G to 5G},
  pages = {},
  note = {AAI27743565},
  publisher = {University of California, Irvine},
  year = {2020},
  abstract = {Global navigation satellite systems (GNSS) have been the main technology used in aerial and ground vehicle navigation systems. As vehicles approach full autonomy, the requirements on the accuracy, reliability, and availability of their navigation systems become very stringent. Due to the limitations of GNSS, namely severe attenuation in deep urban canyons and susceptibility to interference, jamming, and spoofing, alternative sensors and signals are sought. The most common approach to address the limitations of GNSS-based navigation in urban environments is to fuse GNSS receivers with inertial navigation systems (INSs), lidars, cameras, and map matching algorithms. An alternative approach has emerged over the past decade, which is to exploit ambient signals of opportunity (SOPs), such as cellular, digital television, AM/FM, WiFi, and low Earth orbit (LEO) satellite signals. Among SOPs, cellular signals have attracted significant attention due to their inherently desirable attributes, including: abundance, geometric diversity, high received power, and large transmission bandwidth. Cellular systems have gone through five generations. Long-term-evolution (LTE) and new radio (NR) are the standards of the last two generations of wireless technology, namely 4th generation (4G) and 5th generation (5G), respectively. LTE has been developed and standardized in most countries over the past few years and currently has more than four billion users. The structure of NR signals has been finalized in 2019 and since then cellular providers have started rolling 5G out in major cities around the world. Cellular signals are not designed for navigation. In order to exploit cellular signals for navigation purposes, several challenges must be addressed: (1) specialized receivers are required to extract navigation observables from cellular signals, (2) cellular towers typically transmit from low elevation angles, causing multipath signals to be received alongside line-of-sight signals. Multipath can introduce error on the estimated navigation observables, which must be alleviated, (3) the achievable ranging accuracy in multipath-free and multipath-rich environments must be characterized, (4) navigation framework must be developed to localize the receiver using the derived navigation observables, and (5) cellular signals base stations' clock biases must be estimated, since they are not available to the receiver. This dissertation aims to address all of the above challenges for cellular LTE and NR signals. In particular, for LTE, first, a software-defined receiver (SDR) is proposed that is capable of (1) extracting the essential parameters for navigation from received LTE signals, (2) acquiring and tracking LTE signals transmitted from multiple eNodeBs, and (3) producing navigation observables from LTE signals including code and carrier phase and Doppler frequency measurements. Second, the accuracy of the produced measurements are derived as a function of carrier-to-noise ratio and signal transmission bandwidth. It is shown that LTE cell-specific reference signal (CRS) can provide higher precision compared to the LTE secondary synchronization signal (SSS) due to its high transmission bandwidth. Third, standalone and non-standalone navigation frameworks are proposed to localize the receiver using the generated navigation observables. Fourth, it is proposed to exploit the received LTE signal's time-of-arrival (TOA) and direction-of-arrival (DOA) to produce a navigation solution in cold-start applications, where there is no estimate of the receiver's initial state. For this purpose, an SDR is designed to jointly acquire and track TOA and DOA of LTE signals. For NR, first, an SDR is proposed that is capable of (1) acquiring synchronization signal (SS), physical broadcast channel (PBCH) signal, and its associated demodulation reference signal (DM-RS), which are transmitted on a block called SS/PBCH block and (2) tracking SS/PBCH block to produce code and carrier phase and Doppler frequency measurements from NR signals. Second, the precision of the derived code and carrier phase measurements are analyzed as a function of carrier-to-noise ratio and NR numerology. Finally, the statistics of the NR position estimation error are derived for different propagation channels. Throughout the dissertation, numerical and experimental results are provided to validate the theoretical contributions.},
  advisor = {Zak, Kassas, Zaher},
  isbn = {9798662416833},
  url = {https://escholarship.org/uc/item/7nf4c00g},
}

@ARTICLE{lee-kwon:2008:035,
  author = {K.-C. Lee and S. Kwon},
  journal = {Expert Syst. Appl.},
  title = {CAKES-NEGO: Causal Knowledge-Based Expert System for B2B Negotiation},
  volume = {35},
  number = {1–2},
  pages = {459--471},
  doi = {10.1016/j.eswa.2007.07.035},
  publisher = {Pergamon Press, Inc.},
  address = {USA},
  year = {2008},
  month = {7},
  abstract = {As the advent of the Internet, B2B negotiation process on the Internet has been given attention from both researchers and practitioners. Therefore, B2B ecommerce decision making will be a challenge for organizations in the foreseeable future. Some literature shows that important issues to reduce uncertainty in the development of long-term relationships among B2B commerce partners. In this sense, this paper proposes a new negotiation support system to incorporate causal relationships of negotiation terms in the process of B2B negotiation, on the basis of a cognitive map. The proposed a CAKES-NEGO (CAusal Knowledge-driven Expert System) suggests that causal relationships of negotiation terms could be explicitly represented by using the cognitive map as knowledge representation vehicle as well as inference engine. Cognitive maps can illustrate causal relationships among the factors describing a given object and/or problem, and it can also describe experts' tacit knowledge about a certain object. A fuzzy cognitive map (FCM) is an extension of a cognitive map with the additional capability of representing feedback through weighted causal links. FCM, a fuzzy signed digraph with causal relationships between concept variables found in a specific application domain, is used for the causal knowledge acquisition. The objectives of this paper are to (1) suggest a fuzzy cognitive mapping based expert system that support decision process of decision makers and (2) apply it to the illustrative examples, which are B2B negotiation problems, to show the validity of our proposed system. In addition, statistical tests proved that the proposed negotiation mechanism could improve decision performance significantly in B2B negotiations.},
  issn = {0957-4174},
  issue_date = {July, 2008},
  keywords = {Negotiation terms, Cognitive map, Inference, Causal knowledge, Tacit knowledge, Fuzzy cognitive map, Expert system, B2B negotiation},
  numpages = {13},
  url = {https://doi.org/10.1016/j.eswa.2007.07.035},
}

@INPROCEEDINGS{boccanfuso-et-al:2016:7745198,
  author = {L. Boccanfuso and Q. Wang and I. Leite and B. Li and C. Torres and L. Chen and N. Salomons and C. Foster and E. Barney and Y. A. Ahn and B. Scassellati and F. Shic},
  booktitle = {2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title = {A Thermal Emotion Classifier for Improved Human-Robot Interaction},
  pages = {718--723},
  doi = {10.1109/ROMAN.2016.7745198},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {In their expanding role as tutors, home and healthcare assistants, robots must effectively interact with individuals of varying ability and temperament. Indeed, deploying robots in long-term social engagements will almost certainly require robots to reliably detect and adapt to changes in the demeanor of social partners to promote trust and more productive collaboration. However, the recognition of emotional state typically relies on the interpretation of very subtle cues, often varying from one person to the next. In addition, while facial expressions, body posture and features of speech have been used to detect affective changes, the robustness of these measures is often hindered by cultural and age differences. Recently, infrared thermography has shown promise in detecting guilt, fear and stress, indicating that it may be a viable sensing modality for improved human-robot interaction. In this study, we evaluated the efficacy of using a far infrared (FIR) camera for detecting robot-elicited affective response compared to video-elicited affective response by tracking thermal changes in five areas of the face. Further, we analyzed localized changes in the face to assess whether thermal and electrodermal responses to emotions elicited by traditional video techniques and by robots are similar. Finally, we performed principal component analysis to reduce the dimensionality of data and evaluated the performance using machine learning techniques for classifying thermal data by emotion state, resulting in a thermal classifier with a performance accuracy of 77.5%.},
  location = {New York, NY, USA},
  numpages = {6},
  url = {https://doi.org/10.1109/ROMAN.2016.7745198},
}

@PHDTHESIS{clement-et-al:2020,
  author = {L. E. Clement and A. Schoellig and T. Barfoot},
  title = {On Learning Models of Appearance for Robust Long-Term Visual Navigation},
  pages = {},
  note = {AAI27668337},
  publisher = {University of Toronto (Canada)},
  year = {2020},
  abstract = {Simultaneous localization and mapping (SLAM) is a class of techniques that allow robots to navigate unknown environments using onboard sensors. With inexpensive commercial cameras as the primary sensor, visual SLAM has become an important and widely used approach to enabling mobile robot autonomy. However, traditional visual SLAM algorithms use only a fraction of the information available from conventional cameras: in addition to the basic geometric cues typically used in visual SLAM, colour images encode information about the camera itself, environmental illumination, surface materials, vehicle motion, and other factors influencing the image formation process. Moreover, visual localization performance degrades quickly in long-term deployments due to environmental appearance changes caused by lighting, weather, or seasonal effects. This is especially problematic when continuous metric localization is required to drive vision-in-the-loop systems such as autonomous route following. This thesis explores several novel approaches to exploiting additional information from cameras to improve the accuracy and reliability of metric visual SLAM algorithms in short- and long-term deployments. First, we develop a technique for reducing drift error in visual odometry (VO) by estimating the position of a known light source such as the sun using indirect illumination cues available from existing image streams. We build and evaluate hand-engineered and learned models for single-image sun detection and achieve significant reductions in drift error over 30~km of driving in urban and planetary analogue environments. Second, we explore deep image-to-image translation as a means of improving metric visual localization under time-varying illumination. Using images captured under different illumination conditions in a common environment, we demonstrate that localization accuracy and reliability can be substantially improved by learning a many-to-one mapping to a user-selected canonical appearance condition. Finally, we develop a self-supervised method for learning a canonical appearance optimized for high-quality localization. By defining a differentiable surrogate loss function related to the performance of a non-differentiable localization pipeline, we train an optimal RGB-to-grayscale mapping for a given environment, sensor, and pipeline. Using synthetic and real-world long-term vision datasets, we demonstrate significant improvements in localization performance compared to standard grayscale images, enabling continuous metric localization over day-night cycles using a single mapping experience.},
  advisor = {S, Kelly, Jonathan},
  isbn = {9798662389434},
  url = {https://hdl.handle.net/1807/100925},
}

@INPROCEEDINGS{perrussel-charrel:2001:974451,
  author = {L. Perrussel and P.-J. Charrel},
  booktitle = {Proceedings of the 13th IEEE International Conference on Tools with Artificial Intelligence},
  title = {Inconsistent Requirements: An Argumentation View},
  pages = {79--86},
  doi = {10.1109/ICTAI.2001.974451},
  publisher = {IEEE Computer Society},
  address = {USA},
  year = {2001},
  abstract = {In this article, we present a logical framework for reasoning about inconsistent requirements in the context of multi-viewpoint requirements engineering process. In order to analyse the sources of inconsistencies and to reason with inconsistent requirements, we present an argumentation view of the requirements. Intuitively, argumentation is a tool for reasoning with inconsistent knowledge: requirements are defined in terms of arguments (a conclusion with its support); then, a class of acceptable arguments is built (arguments with no counterarguments). We propose to characterize different classes of requirements which are ordered: from weakly confident to strongly confident (i.e. consistent). In the paper, we present inference rules to build intra and inter-viewpoint reasoning. Inference rules are issued from the classes of requirements. We show how this work is useful for the requirements engineers to analyse inconsistent fragments of requirements.A Multi-Agent System to the Common Management of a Renewable Resource: Application to Water Sharing M. Le Bars a,b and J.M. Attonaty b a LAMSADE laboratory Universit\'{e} Paris-Dauphine 75775 Paris Cedex 16. France. bINRA Station d'\'{e}conomie rurale, BP 01 78850 Grignon France. {lebarsm@aol.com;attonaty@grigon.inra.fr} Abstract. Water sharing has become an important problem in France. A lot of negotiations are taking place at a local level between farmers, water suppliers, public services and environmentalists to allocate water resources between users. The problem is to share water with respect of different criteria like economic (global output) ethical (disparities between actors) environmental (water savings). Different approaches have been already taken using linear programming or game theory, but they are always based on the hypothesis that decision-makers are completely rational, take into account few players and are often monoperiodic. We suggest that an Agent-Based Modelling (ABM) built with a Multi-Agent approach could help negotiations between different players by showing the consequences of water allocation rules and taking in consideration the players 'respective attitudes and their ability to change their behaviour. In this paper we will first present the model structure with the different types of agents modelled, how the model runs over a number of years and the first results of simulations. Keywords. Distributed Artificial Intelligence; Multi-Agent Systems Title: A new hybrid method for solving constraint optimization problems in anytime contexts Authors: Samir Loudni and Patrice Boizumault Affiliation: Ecole Des Mines de Nantes Abstract: In this paper, we present a new hybrid method for solving constraint optimization problems in anytime contexts. We use the Valued Constraint Satisfaction Problem (VCSP) framework to model numerous discrete optimization problems. Our method (VNS/LDS+CP) combines a Variable Neighborhood Search (VNS) scheme with Limited Discrepancy Search (LDS) using Constraint Propagation (CP) to evaluate cost and legality of moves made by VNS. Our experimental results on real-word problem instances demonstrate that our method clearly outperforms both LNS/CP/GR (another hybrid method which also relies on the VCSP framework) and other standard local search methods as Simulated-Annealing. This confirm the benefit of the use, in a local search, of the LDS partial search with constraint propagation. keywords: Anytime Problems, Constraint-Satisfaction, Constraint-Optimization, Local Search Methods, Hybrid Methods. Using Software Agents to avoid Collisions among Multiple Robots Markus J\"{a}ger Corporate Technology, Information and Communications Siemens AG 81739 Munich, Germany markus.jaeger@mchp.siemens.de AI Algorithms Collaborative Software Agents Cooperating Robots This paper describes a method where collaborative software agents are used to coordinate the independently planned trajectories of multiple mobile robots to avoid collisions and deadlocks among them. Whenever the distance between two robots drops below a certain value, the agents exchange information about the planned trajectories of the robots and determine whether they are in danger of a collision. If a possible collision is detected, the agents monitor the robots movements and, if necessary, insert idle times between certain segments of the trajectories in order to avoid the collision. Deadlocks among two or more robots occur if a number of robots block each other in a way such that none of them is able to continue along its trajectory without causing a collision. These deadlocks are reliably detected by the agents. After a deadlock is detected, alternative trajectories for each of the involved robots are successively planned until the deadlock is resolved. The agents use a combination of three fully distributed algorithms to reliably solve the task. They do not use any global synchronization. ----------- Authors Affiliations: - Cooperating Software Agents - Cooperating Robots - Collision Avoidance among multiple Robots - Area Partitioning - Area Coverage The title : Successive Search Method for Valued Constraint Satisfaction and Optimization Problems. Authors Names : Mohamed TOUNSI and Philippe DAVID Email Adresses : mohamed.tounsi@emn.fr and philippe.david@emn.fr Affiliation : Computer Science Department, Ecole des Mines de Nantes , 4 Rue Alfred Kastler 44307 Nantes, FRANCE. Abstract : In this paper we introduce a new method based on Russian Doll Search (RDS) for solving optimization problems expressed as Valued Constraint Satisfaction Problems (VCSPs). The RDS method solves problems of size n (where n is the number of variables) by replacing one search by n successive searches on nested subproblems using the results of each search to produce a better lower bound. The main idea of our method is to introduce the variables through the successive searches not one by one but by sets of k variables. We present two variants of our method: the first one where the number k is fixed, noted kfRDS; the second one, kvRDS, where k can be variable. Finally, we show that our method improves RDS on daily management of an earth observation satellite. Keywords : Constraint Satisfaction, VCSP, Optimization Problems. B-Course: A Web Service for Bayesian Data Analysis Petri Myllymaki, Tomi Silander, Henry Tirri, Pekka Uronen Complex Systems Computation Group (CoSCo) P.O.Box 26, Department of Computer Science FIN-00014 University of Helsinki, Finland URL: http://www.cs.Helsinki.FI/research/cosco/ B-Course (http://b-course.cs.helsinki.fi) is a free web-based online data analysis tool, which allows the users to analyze their data for multivariate probabilistic dependencies. These dependencies are represented as Bayesian network models. In addition to this, B-Course also offers facilities for inferring certain type of causal dependencies from the data. The software uses a novel "tutorial style" user-friendly interface which intertwines the steps in the data analysis with support material that gives an informal introduction to the Bayesian approach adopted. Although the analysis methods, modeling assumptions and restrictions are totally transparent to the user, this transparency is not achieved at the expense of analysis power: with the restrictions stated in the support material, B-Course is a powerful analysis tool exploiting several theoretically elaborate results developed recently in the fields of Bayesian and causal modeling. B-Course can be used with most web-browsers (even Lynx), and the facilities include features such as automatic missing data handling and discretization, a flexible graphical interface for probabilistic inference on the constructed Bayesian network models (for Java enabled browsers), automatic pretty-printed layout for the networks, exportation of the models, and analysis of the importance of the derived dependencies. In this paper we discuss both the theoretical design principles underlying the B-Course tool, and the pragmatic methods adopted in the implementation of the software. Artificial Neural Networks in Hydrological Watershed Modeling: Surface Flow Contribution from the Ungaged Parts of a Catchment Richard Chibanga1, Jean Berlamont2 and Joos Vandewalle3 1PhD student in the Civil Eng. Dept. and 2Prof. Civil Eng. Dept., and Head of Hydraulics Laboratory, 3 Prof. Head of Electrical Engineering Dept - SISTA/COSIC, Katholieke Universiteit, Kasteelpark Arenberg 40, 3001 Heverlee (Leuven), Belgium Abstract Watershed modeling is often faced with the difficulty of determining the flow contribution from the ungaged sections of the catchment. Where the main concern is making accurate streamflow forecasts at specific watershed locations, it is cost-effective and efficient to implement a simple system theoretic model. In this paper Artificial Neural Networks (ANNs) are used as system theoretic models to model the ungaged flows. Using data from the Kafue River sub-catchment in Zambia and a simple reservoir routing model, an estimate of the flow contribution from the ungaged sections is derived. Inputs: rainfall, evaporation, previous-time-step flow are fed to a series of Feedforward-Backpropagation ANNs with target-output the current derived flow. Selected best- performing ANNs are compared with Autoregressive Moving Average models with exogenous inputs (ARMAX) and they give accurate and more robust forecasts over long term than the best performing ARMAXs thereby making ANNs a viable alternative in time-series forecasting. Keywords: semi conceptual-system theoretic; Artificial neural networks; subsystem; tributary-runoff; forecasting; mapping. Title: Generation of Propagation Rules for Intentionally Defined Constraints Authors: Slim Abdennadher Computer Science Department, University of Munich Oettingenstr. 67, 80538 Munich, Germany Slim.Abdennadher@informatik.uni-muenchen.de Christophe Rigotti Laboratoire d'Ingenierie des Systemes d'Information Batiment 501, INSA Lyon, 69621 Villeurbanne Cedex, France Christophe.Rigotti@insa-lyon.fr Abstract: A general approach to implement propagation and simplification of constraints consists of applying rules over these constraints. However, a difficulty that arises frequently when writing a constraint solver is to determine the constraint propagation algorithm. In previous work, different methods for automatic generation of propagation rules for constraints defined over finite domains have been proposed. In this paper, we present a method for generating propagation rules for constraint predicates defined by means of a constraint logic program. Keywords: Constraint solving, Machine learning, Rule-based programming Title : "Data Flow Coherence Criteria in ILP Tools" Authors : Smaranda Muresan Department of Computer Science, Columbia University, New York, USA smara@cs.columbia.edu Tudor Muresan Department of Computer Science, Technical Univ. of Cluj-Napoca, Cluj-Napoca, Romania tmuresan@cs.utcluj.ro Rodica Potolea Department of Computer Science, Technical Univ. of Cluj-Napoca, Cluj-Napoca, Romania potolea@cs.utcluj.ro Keywords : Inductive Logic Programming, Automatic Program Generation, Data Flow Coherence Criteria, Pruning the Search Space Abstract: In this paper we present a new method that uses data-flow coherence criteria in definite logic program generation. We outline three main advantages of these criteria supported by our results: i) drastically pruning the search space (around 90%), ii) reducing the set of positive examples and reducing or even removing the need for the set of negative examples, and iii) allowing the induction of predicates that are difficult or even impossible to generate by other methods. Besides these criteria, the approach takes into consideration the program termination condition for recursive predicates. The paper outlines some theoretical issues and implementation aspects of our system for automatic logic program induction. Title: An Expert Recommendation System using Concept-based Relevance Discernment Authors: Takashi Yukawa NTT Corporation NTT Communication Science Laboratories 2-4 Hikaridai, Seika-cho, Kyoto, Japan yukawa@cslab.kecl.ntt.co.jp Kaname Kasahara NTT Corporation NTT Communication Science Laboratories 2-4 Hikaridai, Seika-cho, Kyoto, Japan kaname@cslab.kecl.ntt.co.jp Tsuneaki Kato The University of Tokyo Graduate School of Arts and Science Dept. of Language and Information Science 3-1-8 Komaba, Meguro-ku, Tokyo, Japan kato@boz.c.u-tokyo.ac.jp Toshiro Kita NTT Communications Corporation Solution Business Division Yamato Seimei Bldg. 1-1-7, Uchisaiwai-cho Chiyoda-ku, Tokyo, Japan toshiro.kita@ntt.com Keywords: information retrieval, recommendation system, vector space model, concept base, knowledge management Abstract: An expert recommendation system using concept-based relevance discernment is proposed. This system processes the description of a technical topic as input and then finds engineers who have a high level of expertise in that area. The technique employed is an extended vector space model that locates both technical topics and engineers in the same multi-dimensional space, and then calculates their relevance. This system can also retrieve engineers or documents that are related to a field matching a given engineer's technical interests. Such a system can be expected to play the role of a person's professional network, and be a valuable tool for knowledge management among several organizations. Paper Title: Combinatorial Optimization through Statistical Instance-Based Learning Keywords: constructive search, heuristics, optimization, instance-based learning Authors: Orestis Telelis, Panagiotis Stamatopoulos Department of Informatics and Telecommunications University of Athens 157 84 Athens, Greece {telelis,takis}@di.uoa.gr Abstract: Different successful heuristic approaches have been proposed for solving combinatorial optimization problems. Commonly, each of them is specialized to serve a different purpose or address specific difficulties. However, most combinatorial problems that model real world applications have a priori well known measurable properties. Embedded machine learning methods may aid towards the recognition and utilization of these properties for the achievement of satisfactory solutions. In this paper, we present a heuristic methodology which employs the instance-based machine learning paradigm. This methodology can be adequately configured for several types of optimization problems which are known to have certain properties. Experimental results are discussed concerning two well known problems, namely the knapsack problem and the set partitioning problem. These results show that the proposed approach is able to find significantly better solutions compared to intuitive search methods based on heuristics which are usually applied to the specific problems. TITLE: Interleaved Backtracking in Distributed Constraint Networks &gt; AUTHOR: Youssef Hamadi &gt; AFFILIATION: Hewlett Packards Labs Filton road, Stoke Gifford, &gt; Bristol BS34 8QZ, United Kingdom &gt; EMAIL: yh@hplb.hpl.hp.com &gt; &gt; &gt; Abstract &gt; The adaptation of software technology to distributed &gt; environments is an important challenge today. In this &gt; work we combine parallel and distributed search. By &gt; this way we add the potential speed up of a parallel &gt; exploration in the processing of distributed problems. &gt; This paper extends DIBT, a distributed search proce &gt; dure operating in distributed constraint networks [6]. &gt; The extension is twofold. First the procedure is up &gt; dated to face delayed information problems upcoming &gt; in heterogeneous systems. Second, the search is ex &gt; tended to simultaneously explore independent parts of &gt; a distributed search tree. By this way we introduce &gt; parallelism into distributed search, which brings to In &gt; terleaved Distributed Intelligent BackTracking (IDIBT). &gt; Our results show that 1) insoluble problems do not &gt; greatly degrade performance over DIBT and 2) super &gt; linear speed up can be achieved when the distribution &gt; of solution is nonuniform. &gt; &gt; Keywords: Distributed Constraint Satisfaction, Distributed AI, &gt; Collaborative Software Agents, Search},
  isbn = {0769514170},
  series = {ICTAI '01},
}

@INPROCEEDINGS{sun-et-al:2018:8461228,
  author = {L. Sun and Z. Yan and S. M. Mellado and M. Hanheide and T. Duckett},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {3DOF Pedestrian Trajectory Prediction Learned from Long-Term Autonomous Mobile Robot Deployment Data},
  pages = {1--7},
  doi = {10.1109/ICRA.2018.8461228},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {This paper presents a novel 3DOF pedestrian trajectory prediction approach for autonomous mobile service robots. While most previously reported methods are based on learning of 2D positions in monocular camera images, our approach uses range-finder sensors to learn and predict 3DOF pose trajectories (i.e. 2D position plus 1D rotation within the world coordinate system). Our approach, T-Pose-LSTM (Temporal 3DOF-Pose Long-Short-Term Memory), is trained using long-term data from real-world robot deployments and aims to learn context-dependent (environment- and time-specific) human activities. Our approach incorporates long-term temporal information (i.e. date and time) with short-term pose observations as input. A sequence-to-sequence LSTM encoder-decoder is trained, which encodes observations into LSTM and then decodes the resulting predictions. On deployment, the approach can perform on-the-fly prediction in real-time. Instead of using manually annotated data, we rely on a robust human detection, tracking and SLAM system, providing us with examples in a global coordinate system. We validate the approach using more than 15 km of pedestrian trajectories recorded in a care home environment over a period of three months. The experiments show that the proposed T-Pose-LSTM model outperforms the state-of-the-art 2D-based method for human trajectory prediction in long-term mobile robot deployments.},
  location = {Brisbane, Australia},
  numpages = {7},
  url = {https://doi.org/10.1109/ICRA.2018.8461228},
}

@ARTICLE{tang-et-al:2019:7,
  author = {L. Tang and Y. Wang and X. Ding and H. Yin and R. Xiong and S. Huang},
  journal = {Auton. Robots},
  title = {Topological Local-Metric Framework for Mobile Robots Navigation: A Long Term Perspective},
  volume = {43},
  number = {1},
  pages = {197--211},
  doi = {10.1007/s10514-018-9724-7},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2019},
  month = {1},
  abstract = {Long term mapping and localization are the primary components for mobile robots in real world application deployment, of which the crucial challenge is the robustness and stability. In this paper, we introduce a topological local-metric framework (TLF), aiming at dealing with environmental changes, erroneous measurements and achieving constant complexity. TLF organizes the sensor data collected by the robot in a topological graph, of which the geometry is only encoded in the edge, i.e. the relative poses between adjacent nodes, relaxing the global consistency to local consistency. Therefore the TLF is more robust to unavoidable erroneous measurements from sensor information matching since the error is constrained in the local. Based on TLF, as there is no global coordinate, we further propose the localization and navigation algorithms by switching across multiple local metric coordinates. Besides, a lifelong memorizing mechanism is presented to memorize the environmental changes in the TLF with constant complexity, as no global optimization is required. In experiments, the framework and algorithms are evaluated on 21-session data collected by stereo cameras, which are sensitive to illumination, and compared with the state-of-art global consistent framework. The results demonstrate that TLF can achieve similar localization accuracy with that from global consistent framework, but brings higher robustness with lower cost. The localization performance can also be improved from sessions because of the memorizing mechanism. Finally, equipped with TLF, the robot navigates itself in a 1 km session autonomously.},
  issn = {0929-5593},
  issue_date = {January   2019},
  keywords = {Lifelong learning, Mobile robot, Localization, Navigation},
  numpages = {15},
  url = {https://doi.org/10.1007/s10514-018-9724-7},
}

@INPROCEEDINGS{b\"{u}rki-et-al:2016:7759609,
  author = {M. B\"{u}rki and I. Gilitschenski and E. Stumm and R. Siegwart and J. Nieto},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Appearance-Based Landmark Selection for Efficient Long-Term Visual Localization},
  pages = {4137--4143},
  doi = {10.1109/IROS.2016.7759609},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {In this paper, we present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments. Sharing a common map for online localization provides a fleet of autonomous vehicles with the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offers the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks are to be observable under the prevailing appearance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. Evaluation is performed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme transition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.},
  location = {Daejeon, South Korea},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS.2016.7759609},
}

@INPROCEEDINGS{b\"{u}rki-et-al:2018:8500432,
  author = {M. B\"{u}rki and M. Dymczyk and I. Gilitschenski and C. Cadena and R. Siegwart and J. Nieto},
  booktitle = {2018 IEEE Intelligent Vehicles Symposium (IV)},
  title = {Map Management for Efficient Long-Term Visual Localization in Outdoor Environments},
  pages = {682--688},
  doi = {10.1109/IVS.2018.8500432},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {We present a complete map management process for a visual localization system designed for multi-vehicle long-term operations in resource constrained outdoor environments. Outdoor visual localization generates large amounts of data that need to be incorporated into a lifelong visual map in order to allow localization at all times and under all appearance conditions. Processing these large quantities of data is non-trivial, as it is subject to limited computational and storage capabilities both on the vehicle and on the mapping backend. We address this problem with a two-fold map update paradigm capable of, either, adding new visual cues to the map, or updating co-observation statistics. The former, in combination with offline map summarization techniques, allows enhancing the appearance coverage of the lifelong map while keeping the map size limited. On the other hand, the latter is able to significantly boost the appearance-based landmark selection for efficient online localization without incurring any additional computational or storage burden. Our evaluation in challenging outdoor conditions shows that our proposed map management process allows building and maintaining maps for precise visual localization over long time spans in a tractable and scalable fashion.},
  location = {Changshu, Suzhou, China},
  numpages = {7},
  url = {https://doi.org/10.1109/IVS.2018.8500432},
}

@ARTICLE{bosse-zlot:2009:009,
  author = {M. Bosse and R. Zlot},
  journal = {Robot. Auton. Syst.},
  title = {Keypoint Design and Evaluation for Place Recognition in 2D Lidar Maps},
  volume = {57},
  number = {12},
  pages = {1211--1224},
  doi = {10.1016/j.robot.2009.07.009},
  publisher = {North-Holland Publishing Co.},
  address = {NLD},
  year = {2009},
  month = {12},
  abstract = {We address the place recognition problem, which we define as the problem of establishing whether an observed location has been previously seen, and if so, determining the transformation aligning the current observations to an existing map. In the contexts of robot navigation and mapping, place recognition amounts to globally localizing a robot or map segment without being given any prior estimate. An efficient method of solving this problem involves first selecting a set of keypoints in the scene which store an encoding of their local region, and then utilizing a sublinear-time search into a database of keypoints previously generated from the global map to identify places with common features. We present an algorithm to embed arbitrary keypoint descriptors in a reduced-dimension metric space, in order to frame the problem as an efficient nearest neighbor search. Given that there are a multitude of possibilities for keypoint design, we propose a general methodology for comparing keypoint location selection heuristics and descriptor models that describe the region around the keypoint. With respect to selecting keypoint locations, we introduce a metric that encodes how likely it is that the keypoint will be found in the presence of noise and occlusions during mapping passes. Metrics for keypoint descriptors are used to assess the distinguishability between the distributions of matches and non-matches and the probability the correct match will be found in an approximate k-nearest neighbors search. Verification of the test outcomes is done by comparing the various keypoint designs on a kilometers-scale place recognition problem. We apply our design evaluation methodology to three keypoint selection heuristics and six keypoint descriptor models. A full place recognition system is presented, including a series of match verification algorithms which effectively filter out false positives. Results from city-scale and long-term mapping problems illustrate our approach for both offline and online SLAM, map merging, and global localization and demonstrate that our algorithm is able to produce accurate maps over trajectories of hundreds of kilometers.},
  issn = {0921-8890},
  issue_date = {December, 2009},
  keywords = {Dimension reduction, Data association, SLAM, Regional point descriptor, Mapping, Localization, Place recognition},
  numpages = {14},
  url = {https://doi.org/10.1016/j.robot.2009.07.009},
}

@INPROCEEDINGS{bujanca-et-al:2021:9636814,
  author = {M. Bujanca and X. Shi and M. Spear and P. Zhao and B. Lennox and M. Luj\'{a}n},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Robust SLAM Systems: Are We There Yet?},
  pages = {5320--5327},
  doi = {10.1109/IROS51168.2021.9636814},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {Progress in the last decade has brought about significant improvements in the accuracy and speed of SLAM systems, broadening their mapping capabilities. Despite these advancements, long-term operation remains a major challenge, primarily due to the wide spectrum of perturbations robotic systems may encounter.Increasing the robustness of SLAM algorithms is an ongoing effort, however it usually addresses a specific perturbation. Generalisation of robustness across a large variety of challenging scenarios is not well-studied nor understood. This paper presents a systematic evaluation of the robustness of open-source state-of-the-art SLAM algorithms with respect to challenging conditions such as fast motion, non-uniform illumination, and dynamic scenes. The experiments are performed with perturbations present both independently of each other, as well as in combination in long-term deployment settings in unconstrained environments (lifelong operation).The detailed results (approx. 20,000 experiments) along with comprehensive documentation of the benchmarking tool for integrating new datasets and evaluating SLAM algorithms not studied in this work are available at https://robustslam.github.io/evaluation.},
  location = {Prague, Czech Republic},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS51168.2021.9636814},
}

@ARTICLE{chen-et-al:2021:106237,
  author = {M. Chen and Y. Tang and X. Zou and Z. Huang and H. Zhou and S. Chen},
  journal = {Comput. Electron. Agric.},
  title = {3D Global Mapping of Large-Scale Unstructured Orchard Integrating Eye-in-Hand Stereo Vision and SLAM},
  volume = {187},
  number = {C},
  pages = {106237},
  doi = {10.1016/j.compag.2021.106237},
  publisher = {Elsevier Science Publishers B. V.},
  address = {NLD},
  year = {2021},
  month = {8},
  issn = {0168-1699},
  issue_date = {Aug 2021},
  keywords = {Stereo matching, 3D mapping, Fruit-picking robot, Stereo vision, SLAM},
  numpages = {16},
  url = {https://doi.org/10.1016/j.compag.2021.106237},
}

@ARTICLE{cornick-et-al:2016:21605,
  author = {M. Cornick and J. Koechling and B. Stanley and B. Zhang},
  journal = {J. Field Robot.},
  title = {Localizing Ground Penetrating RADAR: A Step Toward Robust Autonomous Ground Vehicle Localization},
  volume = {33},
  number = {1},
  pages = {82--102},
  doi = {10.1002/rob.21605},
  publisher = {John Wiley and Sons Ltd.},
  address = {GBR},
  year = {2016},
  month = {1},
  abstract = {Autonomous ground vehicles navigating on road networks require robust and accurate localization over long-term operation and in a wide range of adverse weather and environmental conditions. GPS/INS inertial navigation system solutions, which are insufficient alone to maintain a vehicle within a lane, can fail because of significant radio frequency noise or jamming, tall buildings, trees, and other blockage or multipath scenarios. LIDAR and camera map-based vehicle localization can fail when optical features become obscured, such as with snow or dust, or with changes to gravel or dirt road surfaces. Localizing ground penetrating radar LGPR is a new mode of a priori map-based vehicle localization designed to complement existing approaches with a low sensitivity to failure modes of LIDAR, camera, and GPS/INS sensors due to its low-frequency RF energy, which couples deep into the ground. Most subsurface features detected are inherently stable over time. Significant research, discussed herein, remains to prove general utility. We have developed a novel low-profile ultra-low power LGPR system and demonstrated real-time operation underneath a passenger vehicle. A correlation maximizing optimization technique was developed to allow real-time localization at 126\"{\i} Hz. Here we present the detailed design and results from highway testing, which uses a simple heuristic for fusing LGPR estimates with a GPS/INS system. Cross-track localization accuracies of 4.3\"{\i} cm RMS relative to a "truth" RTK GPS/INS unit at speeds up to 100\"{\i} km/h 60\"{\i} mph are demonstrated. These results, if generalizable, introduce a widely scalable real-time localization method with cross-track accuracy as good as or better than current localization methods.},
  issn = {1556-4959},
  issue_date = {January 2016},
  numpages = {21},
  url = {https://doi.org/10.1002/rob.21605},
}

@INPROCEEDINGS{gadd-newman:2016:7759843,
  author = {M. Gadd and P. Newman},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Checkout My Map: Version Control for Fleetwide Visual Localisation},
  pages = {5729--5736},
  doi = {10.1109/IROS.2016.7759843},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {This paper is about underpinning long-term operations of fleets of vehicles using visual localisation. In particular it examines ways in which vehicles, considered as independent agents, can share, update and leverage each others' visual experiences in a mutually beneficial way. We draw on our previous work in Experience-based Navigation (EBN) [1], in which a visual map supporting multiple representations of the same place is built, yielding real-time localisation capability for a solitary vehicle. We now consider how any number of such agents might operate in concert via data sharing policies that are germane to the shared task of lifelong localisation. We rapidly construct considerable maps by the conjoining of work distributed to asynchronous processes, and share expertise amongst the team by the selective dispensing of mission-specific map contents. We demonstrate and evaluate our system against 100km of data collected in North Oxford over a period of a month featuring diverse deviation in appearance due to atmospheric, lighting, and structural dynamics. We show that our framework is capable of creating maps in a fraction of the time required by single-agent EBN, with no significant loss in localisation robustness, and is able to furnish robots on real-world forays with maps which require much less storage.},
  location = {Daejeon, South Korea},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS.2016.7759843},
}

@INPROCEEDINGS{schuster-et-al:2015:7354094,
  author = {M. J. Schuster and C. Brand and H. Hirschmuller and M. Suppa and M. Beetz},
  booktitle = {2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Multi-Robot 6D Graph SLAM Connecting Decoupled Local Reference Filters},
  pages = {5093--5100},
  doi = {10.1109/IROS.2015.7354094},
  publisher = {IEEE Press},
  year = {2015},
  abstract = {Teams of mobile robots can be deployed in search and rescue missions to explore previously unknown environments. Methods for joint localization and mapping constitute the basis for (semi-)autonomous cooperative action, in particular when navigating in GPS-denied areas. As communication losses may occur, a decentralized solution is required. With these challenges in mind, we designed a submap-based SLAM system that relies on inertial measurements and stereo-vision to create multi-robot dense 3D maps. For online pose and map estimation, we integrate the results of keyframe-based local reference filters through incremental graph SLAM. To the best of our knowledge, we are the first to combine these two methods to benefit from their particular advantages for 6D multi-robot localization and mapping: Local reference filters on each robot provide real-time, long-term stable state estimates that are required for stabilization, control and fast obstacle avoidance, whereas online graph optimization provides global multi-robot pose and map estimates needed for cooperative planning. We propose a novel graph topology for a decoupled integration of local filter estimates from multiple robots into a SLAM graph according to the filters' uncertainty estimates and independence assumptions and evaluated its benefits on two different robots in indoor, outdoor and mixed scenarios. Further, we performed two extended experiments in a multi-robot setup to evaluate the full SLAM system, including visual robot detections and submap matches as inter-robot loop closure constraints.},
  location = {Hamburg, Germany},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS.2015.7354094},
}

@INPROCEEDINGS{pitschl-pryor:2019:8843095,
  author = {M. L. Pitschl and M. W. Pryor},
  booktitle = {2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)},
  title = {Obstacle Persistent Adaptive Map Maintenance for Autonomous Mobile Robots Using Spatio-Temporal Reasoning*},
  pages = {1023--1028},
  doi = {10.1109/COASE.2019.8843095},
  publisher = {IEEE Press},
  year = {2019},
  abstract = {Mobile robotic systems operate in increasingly realistic scenarios even as users have increased expectations for the duration of autonomous tasks. Mobile robots face unique challenges when operating in environments that change over time, where systems must maintain an accurate representation of the environment with respect to both spatial and temporal dimensions. This paper describes a spatio-temporal technique for extending the autonomy of a mobile robot in a changing environment. This new technique called Obstacle Persistent Adaptive Map Maintenance (OPAMM) uses navigation data collected during normal operations to perform periodic self-maintenance of its environment model. OPAMM implements a probabilistic feature persistence model to predict the survival state of obstacles and update the world model. Maintaining an accurate world model is necessary for extending the long-term autonomy of robots in realistic scenarios. Results show that robots using OPAMM had localizations scores higher than other methods, thus reducing long-term localization degradation.},
  location = {Vancouver, BC, Canada},
  numpages = {6},
  url = {https://doi.org/10.1109/COASE.2019.8843095},
}

@ARTICLE{labb\'{e}-michaud:2018:5,
  author = {M. Labb\'{e} and F. Michaud},
  journal = {Auton. Robots},
  title = {Long-Term Online Multi-Session Graph-Based SPLAM with Memory Management},
  volume = {42},
  number = {6},
  pages = {1133--1150},
  doi = {10.1007/s10514-017-9682-5},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2018},
  month = {8},
  abstract = {For long-term simultaneous planning, localization and mapping (SPLAM), a robot should be able to continuously update its map according to the dynamic changes of the environment and the new areas explored. With limited onboard computation capabilities, a robot should also be able to limit the size of the map used for online localization and mapping. This paper addresses these challenges using a memory management mechanism, which identifies locations that should remain in a Working Memory (WM) for online processing from locations that should be transferred to a Long-Term Memory (LTM). When revisiting previously mapped areas that are in LTM, the mechanism can retrieve these locations and place them back in WM for online SPLAM. The approach is tested on a robot equipped with a short-range laser rangefinder and a RGB-D camera, patrolling autonomously 10.5 km in an indoor environment over 11 sessions while having encountered 139 people.},
  issn = {0929-5593},
  issue_date = {August    2018},
  keywords = {Path planning, SLAM, Loop closure detection, Pose graph, Multi-session},
  numpages = {18},
  url = {https://doi.org/10.1007/s10514-017-9682-5},
}

@INPROCEEDINGS{matamoros-et-al:2018:18,
  author = {M. Matamoros and K. Harbusch and D. Paulus},
  booktitle = {RoboCup 2018: Robot World Cup XXII},
  title = {From Commands to Goal-Based Dialogs: A Roadmap to Achieve Natural Language Interaction in RoboCup@Home},
  pages = {217--229},
  doi = {10.1007/978-3-030-27544-0_18},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  year = {2018},
  abstract = {On the one hand, speech is a key aspect to people’s communication. On the other, it is widely acknowledged that language proficiency is related to intelligence. Therefore, intelligent robots should be able to understand, at least, people’s orders within their application domain. These insights are not new in RoboCup@Home, but we lack of a long-term plan to evaluate this approach.In this paper we conduct a brief review of the achievements on automated speech recognition and natural language understanding in RoboCup@Home. Furthermore, we discuss main challenges to tackle in spoken human-robot interaction within the scope of this competition. Finally, we contribute by presenting a pipelined road map to engender research in the area of natural language understanding applied to domestic service robotics.},
  isbn = {978-3-030-27543-3},
  keywords = {Artificial intelligence and robotics, Robotic competitions, Natural language understanding},
  location = {Montr\'{e}al, QC, Canada},
  numpages = {13},
  url = {https://doi.org/10.1007/978-3-030-27544-0_18},
}

@INPROCEEDINGS{paton-et-al:2016:7759303,
  author = {M. Paton and K. MacTavish and M. Warren and T. D. Barfoot},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Bridging the Appearance Gap: Multi-Experience Localization for Long-Term Visual Teach and Repeat},
  pages = {1918--1925},
  doi = {10.1109/IROS.2016.7759303},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Vision-based, route-following algorithms enable autonomous robots to repeat manually taught paths over long distances using inexpensive vision sensors. However, these methods struggle with long-term, outdoor operation due to the challenges of environmental appearance change caused by lighting, weather, and seasons. While techniques exist to address appearance change by using multiple experiences over different environmental conditions, they either provide topological-only localization, require several manually taught experiences in different conditions, or require extensive offline mapping to produce metric localization. For real-world use, we would like to localize metrically to a single manually taught route and gather additional visual experiences during autonomous operations. Accordingly, we propose a novel multi-experience localization (MEL) algorithm developed specifically for route-following applications; it provides continuous, six-degree-of-freedom (6DoF) localization with relative uncertainty to a privileged (manually taught) path using several experiences simultaneously. We validate our algorithm through two experiments: i) an offline performance analysis on a 9km subset of a challenging 27km route-traversal dataset and ii) an online field trial where we demonstrate autonomy on a small 250m loop over the course of a sunny day. Both exhibit significant appearance change due to lighting variation. Through these experiments we show that safe localization can be achieved by bridging the appearance gap.},
  location = {Daejeon, South Korea},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS.2016.7759303},
}

@INPROCEEDINGS{l\'{a}zaro-et-al:2018:8594310,
  author = {M. T. L\'{a}zaro and R. Capobianco and G. Grisetti},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Efficient Long-Term Mapping in Dynamic Environments},
  pages = {153--160},
  doi = {10.1109/IROS.2018.8594310},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.},
  location = {Madrid, Spain},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS.2018.8594310},
}

@INPROCEEDINGS{zhao-et-al:2021:9635985,
  author = {M. Zhao and X. Guo and L. Song and B. Qin and X. Shi and G. H. Lee and G. Sun},
  booktitle = {2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {A General Framework for Lifelong Localization and Mapping in Changing Environment},
  pages = {3305--3312},
  doi = {10.1109/IROS51168.2021.9635985},
  publisher = {IEEE Press},
  year = {2021},
  abstract = {The environment of most real-world scenarios such as malls and supermarkets changes at all times. A pre-built map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-to-date model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efficient map updating strategy that includes map building, pose graph refinement and sparsification. To mitigate the unbounded increase of memory usage, we propose a map-trimming method based on the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.},
  location = {Prague, Czech Republic},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS51168.2021.9635985},
}

@ARTICLE{carlevaris-bianco-et-al:2016:0278364915614638,
  author = {N. Carlevaris-Bianco and A. K. Ushani and R. M. Eustice},
  journal = {Int. J. Rob. Res.},
  title = {University of Michigan North Campus Long-Term Vision and Lidar Dataset},
  volume = {35},
  number = {9},
  pages = {1023--1035},
  doi = {10.1177/0278364915614638},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2016},
  month = {8},
  abstract = {This paper documents a large scale, long-term autonomy dataset for robotics research collected on the University of Michigan's North Campus. The dataset consists of omnidirectional imagery, 3D lidar, planar lidar, GPS, and proprioceptive sensors for odometry collected using a Segway robot. The dataset was collected to facilitate research focusing on long-term autonomous operation in changing environments. The dataset is composed of 27 sessions spaced approximately biweekly over the course of 15 months. The sessions repeatedly explore the campus, both indoors and outdoors, on varying trajectories, and at different times of the day across all four seasons. This allows the dataset to capture many challenging elements including: moving obstacles e.g. pedestrians, bicyclists and cars, changing lighting, varying viewpoint, seasonal and weather changes e.g. falling leaves and snow, and long-term structural changes caused by construction projects. To further facilitate research, we also provide ground-truth pose for all sessions in a single frame of reference.},
  issn = {0278-3649},
  issue_date = {8 2016},
  keywords = {Long-term SLAM, lidar, place recognition, field and service robotics, computer vision},
  numpages = {13},
  url = {https://doi.org/10.1177/0278364915614638},
}

@ARTICLE{dong-et-al:2022:013,
  author = {N. Dong and M. Qin and J. Chang and C. H. Wu and W. H. Ip and K. L. Yung},
  journal = {Comput. Commun.},
  title = {Weighted Triplet Loss Based on Deep Neural Networks for Loop Closure Detection in VSLAM},
  volume = {186},
  number = {C},
  pages = {153--165},
  doi = {10.1016/j.comcom.2022.01.013},
  publisher = {Elsevier Science Publishers B. V.},
  address = {NLD},
  year = {2022},
  month = {3},
  issn = {0140-3664},
  issue_date = {Mar 2022},
  keywords = {Smart living, Loop closure detection, SLAM, Triplet loss, Smart space, Metric learning},
  numpages = {13},
  url = {https://doi.org/10.1016/j.comcom.2022.01.013},
}

@ARTICLE{piasco-et-al:2021:6,
  author = {N. Piasco and D. Sidib\'{e} and V. Gouet-Brunet and C. Demonceaux},
  journal = {Int. J. Comput. Vision},
  title = {Improving Image Description with Auxiliary Modality for Visual Localization in Challenging Conditions},
  volume = {129},
  number = {1},
  pages = {185--202},
  doi = {10.1007/s11263-020-01363-6},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2021},
  month = {1},
  abstract = {Image indexing for lifelong localization is a key component for a large panel of applications, including robot navigation, autonomous driving or cultural heritage valorization. The principal difficulty in long-term localization arises from the dynamic changes that affect outdoor environments. In this work, we propose a new approach for outdoor large scale image-based localization that can deal with challenging scenarios like cross-season, cross-weather and day/night localization. The key component of our method is a new learned global image descriptor, that can effectively benefit from scene geometry information during training. At test time, our system is capable of inferring the depth map related to the query image and use it to increase localization accuracy. We show through extensive evaluation that our method can improve localization performances, especially in challenging scenarios when the visual appearance of the scene has changed. Our method is able to leverage both visual and geometric clues from monocular images to create discriminative descriptors for cross-season localization and effective matching of images acquired at different time periods. Our method can also use weakly annotated data to localize night images across a reference dataset of daytime images. Finally we extended our method to reflectance modality and we compare multi-modal descriptors respectively based on geometry, material reflectance and a combination of both.},
  issn = {0920-5691},
  issue_date = {Jan 2021},
  keywords = {Localization, Side modality learning, Image retrieval, Global image descriptor, Depth from monocular},
  numpages = {18},
  url = {https://doi.org/10.1007/s11263-020-01363-6},
}

@PHDTHESIS{pradhan:2013,
  author = {N. Pradhan},
  title = {Mobile Robot Navigation for Person Following in Indoor Environments},
  pages = {},
  note = {AAI3592524},
  publisher = {Clemson University},
  address = {USA},
  year = {2013},
  abstract = {Service robotics is a rapidly growing area of interest in robotics research. Service robots inhabit human-populated environments and carry out specific tasks. The goal of this dissertation is to develop a service robot capable of following a human leader around populated indoor environments. A classification system for person followers is proposed such that it clearly defines the expected interaction between the leader and the robotic follower. In populated environments, the robot needs to be able to detect and identify its leader and track the leader through occlusions, a common characteristic of populated spaces. An appearance-based person descriptor, which augments the Kinect skeletal tracker, is developed and its performance in detecting and overcoming short and long-term leader occlusions is demonstrated. While following its leader, the robot has to ensure that it does not collide with stationary and moving obstacles, including other humans, in the environment. This requirement necessitates the use of a systematic navigation algorithm. A modified version of navigation function path planning, called the predictive fields path planner, is developed. This path planner models the motion of obstacles, uses a simplified representation of practical workspaces, and generates bounded, stable control inputs which guide the robot to its desired position without collisions with obstacles. The predictive fields path planner is experimentally verified on a non-person follower system and then integrated into the robot navigation module of the person follower system. To navigate the robot, it is necessary to localize it within its environment. A mapping approach based on depth data from the Kinect RGB-D sensor is used in generating a local map of the environment. The map is generated by combining inter-frame rotation and translation estimates based on scan generation and dead reckoning respectively. Thus, a complete mobile robot navigation system for person following in indoor environments is presented.},
  advisor = {Burg, Timothy and Birchfield, Stan},
  isbn = {9781303336904},
  url = {https://tigerprints.clemson.edu/all_dissertations/1186},
}

@ARTICLE{lamarre-et-al:2020:0278364920908922,
  author = {O. Lamarre and O. Limoyo and F. Mari\'{c} and J. Kelly},
  journal = {Int. J. Rob. Res.},
  title = {The Canadian Planetary Emulation Terrain Energy-Aware Rover Navigation Dataset},
  volume = {39},
  number = {6},
  pages = {641--650},
  doi = {10.1177/0278364920908922},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2020},
  month = {5},
  abstract = {Future exploratory missions to the Moon and to Mars will involve solar-powered rovers; careful vehicle energy management is critical to the success of such missions. This article describes a unique dataset gathered by a small, four-wheeled rover at a planetary analog test facility in Canada. The rover was equipped with a suite of sensors designed to enable the study of energy-aware navigation and path planning algorithms. The sensors included a colour omnidirectional stereo camera, a monocular camera, an inertial measurement unit, a pyranometer, drive power consumption monitors, wheel encoders, and a GPS receiver. In total, the rover drove more than 1.2 km over varied terrain at the analog test site. All data is presented in human-readable text files and as standard-format images; additional Robot Operating System (ROS) parsing tools and several georeferenced aerial maps of the test environment are also included. A series of potential research use cases is described.},
  issn = {0278-3649},
  issue_date = {May 2020},
  keywords = {terrain assessment, energy-aware path planning, long-term autonomy, localization and mapping, Planetary robotics},
  numpages = {10},
  url = {https://doi.org/10.1177/0278364920908922},
}

@ARTICLE{biber-duckett:2009:0278364908096286,
  author = {P. Biber and T. Duckett},
  journal = {Int. J. Rob. Res.},
  title = {Experimental Analysis of Sample-Based Maps for Long-Term SLAM},
  volume = {28},
  number = {1},
  pages = {20--33},
  doi = {10.1177/0278364908096286},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2009},
  month = {1},
  abstract = {This paper presents a system for long-term SLAM (simultaneous localization and mapping) by mobile service robots and its experimental evaluation in a real dynamic environment. To deal with the stability-plasticity dilemma (the trade-off between adaptation to new patterns and preservation of old patterns), the environment is represented by multiple timescales simultaneously (five in our experiments). A sample-based representation is proposed, where older memories fade at different rates depending on the timescale and robust statistics are used to interpret the samples. The dynamics of this representation are analyzed in a five-week experiment, measuring the relative influence of short- and long-term memories over time and further demonstrating the robustness of the approach.},
  issn = {0278-3649},
  issue_date = {January   2009},
  keywords = {mobile robot navigation, lifelong learning, multi-timescale representations, dynamic environments, simultaneous localization and mapping},
  numpages = {14},
  url = {https://doi.org/10.1177/0278364908096286},
}

@ARTICLE{duckworth-et-al:2019:005,
  author = {P. Duckworth and D. C. Hogg and A. G. Cohn},
  journal = {Artif. Intell.},
  title = {Unsupervised Human Activity Analysis for Intelligent Mobile Robots},
  volume = {270},
  number = {C},
  pages = {67--92},
  doi = {10.1016/j.artint.2018.12.005},
  publisher = {Elsevier Science Publishers Ltd.},
  address = {GBR},
  year = {2019},
  month = {5},
  issn = {0004-3702},
  issue_date = {May 2019},
  keywords = {Mobile robotics, Human activity analysis, Latent Dirichlet allocation, Probabilistic machine learning, Low-rank approximations, Qualitative spatio-temporal representation},
  numpages = {26},
  url = {https://doi.org/10.1016/j.artint.2018.12.005},
}

@INPROCEEDINGS{egger-et-al:2018:8593854,
  author = {P. Egger and P. V. K. Borges and G. Catt and A. Pfrunder and R. Siegwart and R. Dub\'{e}},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization},
  pages = {3430--3437},
  doi = {10.1109/IROS.2018.8593854},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.},
  location = {Madrid, Spain},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS.2018.8593854},
}

@PHDTHESIS{stone-veloso:1998,
  author = {P. H. Stone and M. M. Veloso},
  title = {Layered Learning in Multiagent Systems},
  pages = {},
  note = {AAI9918612},
  publisher = {Carnegie Mellon University},
  address = {USA},
  year = {1998},
  abstract = {Multi-agent systems in complex, real-time domains require agents to act effectively both autonomously and as part of a team. This dissertation addresses multi-agent systems consisting of teams of autonomous agents acting in real-time, noisy, collaborative, and adversarial environments. Because of the inherent complexity of this type of multi-agent system, this thesis investigates the use of machine learning within multi-agent systems. The dissertation makes four main contributions to the fields of Machine Learning and Multi-Agent Systems. First, the thesis defines a team member agent architecture within which a flexible team structure is presented, allowing agents to decompose the task space into flexible roles and allowing them to smoothly switch roles while acting. Team organization is achieved by the introduction of a locker-room agreement as a collection of conventions followed by all team members. It defines agent roles, team formations, and pre-compiled multi-agent plans. In addition, the team member agent architecture includes a communication paradigm for domains with single-channel, low-bandwidth, unreliable communication. The communication paradigm facilitates team coordination while being robust to lost messages and active interference from opponents. Second, the thesis introduces layered learning, a general-purpose machine learning paradigm for complex domains in which learning a mapping directly from agents' sensors to their actuators is intractable. Given a hierarchical task decomposition, layered learning allows for learning at each level of the hierarchy, with learning at each level directly affecting learning at the next higher level. Third, the thesis introduces a new multi-agent reinforcement learning algorithm, namely team-partitioned, opaque-transition reinforcement learning (TPOT-RL). TPOT-RL is designed for domains in which agents cannot necessarily observe the state changes when other team members act. It exploits local, action-dependent features to aggressively generalize its input representation for learning and partitions the task among the agents, allowing them to simultaneously learn collaborative policies by observing the long-term effects of their actions. Fourth, the thesis contributes a fully functioning multi-agent system that incorporates learning in a real-time, noisy domain with teammates and adversaries. Detailed algorithmic descriptions of the agents' behaviors as well as their source code are included in the thesis. Empirical results validate all four contributions within the simulated robotic soccer domain. The generality of the contributions is verified by applying them to the real robotic soccer, and network routing domains. Ultimately, this dissertation demonstrates that by learning portions of their cognitive processes, selectively communicating, and coordinating their behaviors via common knowledge, a group of independent agents can work towards a common goal in a complex, real-time, noisy, collaborative, and adversarial environment.},
  isbn = {0599172215},
  url = {https://www.proquest.com/openview/93f51fc6759a1d5683340399f5189ec3/},
}

@ARTICLE{m\"{u}hlfellner-et-al:2016:21595,
  author = {P. M\"{u}hlfellner and M. B\"{u}rki and M. Bosse and W. Derendarz and R. Philippsen and P. Furgale},
  journal = {J. Field Robot.},
  title = {Summary Maps for Lifelong Visual Localization},
  volume = {33},
  number = {5},
  pages = {561--590},
  doi = {10.1002/rob.21595},
  publisher = {John Wiley and Sons Ltd.},
  address = {GBR},
  year = {2016},
  month = {8},
  abstract = {Robots that use vision for localization need to handle environments that are subject to seasonal and structural change, and operate under changing lighting and weather conditions. We present a framework for lifelong localization and mapping designed to provide robust and metrically accurate online localization in these kinds of changing environments. Our system iterates between offline map building, map summary, and online localization. The offline mapping fuses data from multiple visually varied datasets, thus dealing with changing environments by incorporating new information. Before passing these data to the online localization system, the map is summarized, selecting only the landmarks that are deemed useful for localization. This Summary Map enables online localization that is accurate and robust to the variation of visual information in natural environments while still being computationally efficient. We present a number of summary policies for selecting useful features for localization from the multisession map, and we explore the tradeoff between localization performance and computational complexity. The system is evaluated on 77 recordings, with a total length of 30 kilometers, collected outdoors over 16 months. These datasets cover all seasons, various times of day, and changing weather such as sunshine, rain, fog, and snow. We show that it is possible to build consistent maps that span data collected over an entire year, and cover day-to-night transitions. Simple statistics computed on landmark observations are enough to produce a Summary Map that enables robust and accurate localization over a wide range of seasonal, lighting, and weather conditions.},
  issn = {1556-4959},
  issue_date = {August 2016},
  numpages = {30},
  url = {https://doi.org/10.1002/rob.21595},
}

@ARTICLE{ozog-et-al:2016:21582,
  author = {P. Ozog and N. Carlevaris-Bianco and A. Kim and R. M. Eustice},
  journal = {J. Field Robot.},
  title = {Long-Term Mapping Techniques for Ship Hull Inspection and Surveillance Using an Autonomous Underwater Vehicle},
  volume = {33},
  number = {3},
  pages = {265--289},
  doi = {10.1002/rob.21582},
  publisher = {John Wiley and Sons Ltd.},
  address = {GBR},
  year = {2016},
  month = {5},
  abstract = {This paper reports on a system for an autonomous underwater vehicle to perform in situ, multiple session hull inspection using long-term simultaneous localization and mapping SLAM. Our method assumes very little a priori knowledge, and it does not require the aid of acoustic beacons for navigation, which is a typical mode of navigation in this type of application. Our system combines recent techniques in underwater saliency-informed visual SLAM and a method for representing the ship hull surface as a collection of many locally planar surface features. This methodology produces accurate maps that can be constructed in real-time on consumer-grade computing hardware. A single-session SLAM result is initially used as a prior map for later sessions, where the robot automatically merges the multiple surveys into a common hull-relative reference frame. To perform the relocalization step, we use a particle filter that leverages the locally planar representation of the ship hull surface, and a fast visual descriptor matching algorithm. Finally, we apply the recently developed graph sparsification tool, generic linear constraints, as a way to manage the computational complexity of the SLAM system as the robot accumulates information across multiple sessions. We show results for 20 SLAM sessions for two large vessels over the course of days, months, and even up to three years, with a total path length of approximately 10.2 km.},
  issn = {1556-4959},
  issue_date = {May 2016},
  numpages = {25},
  url = {https://doi.org/10.1002/rob.21582},
}

@INPROCEEDINGS{yin-et-al:2018:8593562,
  author = {P. Yin and L. Xu and Z. Liu and L. Li and H. Salman and Y. He and W. Xu and H. Wang and H. Choset},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Stabilize an Unsupervised Feature Learning for LiDAR-Based Place Recognition},
  pages = {1162--1167},
  doi = {10.1109/IROS.2018.8593562},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {Place recognition is one of the major challenges for the LiDAR-based effective localization and mapping task. Traditional methods are usually relying on geometry matching to achieve place recognition, where a global geometry map need to be restored. In this paper, we accomplish the place recognition task based on an end-to-end feature learning framework with the LiDAR inputs. This method consists of two core modules, a dynamic octree mapping module that generates local 2D maps with the consideration of the robot's motion; and an unsupervised place feature learning module which is an improved adversarial feature learning network with additional assistance for the long-term place recognition requirement. More specially, in place feature learning, we present an additional Generative Adversarial Network with a designed Conditional Entropy Reduction module to stabilize the feature learning process in an unsupervised manner. We evaluate the proposed method on the Kitti dataset and North Campus Long-Term LiDAR dataset. Experimental results show that the proposed method outperforms state-of-the-art in place recognition tasks under long-term applications. What's more, the feature size and inference efficiency in the proposed method are applicable in real-time performance on practical robotic platforms.},
  location = {Madrid, Spain},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS.2018.8593562},
}

@INPROCEEDINGS{zhu-ren:2020:9341393,
  author = {P. Zhu and W. Ren},
  booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Multi-Robot Joint Visual-Inertial Localization and 3-D Moving Object Tracking},
  pages = {11573--11580},
  doi = {10.1109/IROS45743.2020.9341393},
  publisher = {IEEE Press},
  year = {2020},
  abstract = {In this paper, we present a novel distributed algorithm to track a moving object’s state by utilizing a heterogenous mobile robot network in a three-dimensional (3-D) environment, wherein the robots’ poses (positions and orientations) are unknown. Each robot is equipped with a monocular camera and an inertial measurement unit (IMU), and has the ability to communicate with its neighbors. Rather than assuming a known common global frame for all the robots (which is often the case in the literature regarding multi-robot systems), we allow each robot to perform motion estimation locally. For localization, we propose a multi-robot visual-inertial navigation systems (VINS) where one robot builds a prior map and then the map is used to bound the long-term drifts of the visual-inertial odometry (VIO) running on the other robots. Moreover, a novel distributed Kalman filter is introduced and employed to cooperatively track the six degree-of-freedom (6-DoF) motion of the object which is represented as a point cloud. Further, the object can be totally invisible to some robots during the tracking period. The proposed algorithm is extensively validated in Monte-Carlo simulations.},
  location = {Las Vegas, NV, USA},
  numpages = {8},
  url = {https://doi.org/10.1109/IROS45743.2020.9341393},
}

@INPROCEEDINGS{arroyo-et-al:2016:7795672,
  author = {R. Arroyo and P. F. Alcantarilla and L. M. Bergasa and E. Romera},
  booktitle = {2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)},
  title = {OpenABLE: An Open-Source Toolbox for Application in Life-Long Visual Localization of Autonomous Vehicles},
  pages = {965--970},
  doi = {10.1109/ITSC.2016.7795672},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Visual information is a valuable asset in any perception scheme designed for an intelligent transportation system. In this regard, the camera-based recognition of locations provides a higher situational awareness of the environment, which is very useful for varied localization solutions typically needed in long-term autonomous navigation, such as loop closure detection and visual odometry or SLAM correction. In this paper we present OpenABLE, an open-source toolbox contributed to the community with the aim of helping researchers in the application of these kinds of life-long localization algorithms. The implementation follows the philosophy of the topological place recognition method named ABLE, including several new features and improvements. These functionalities allow to match locations using different global image description methods and several configuration options, which enable the users to control varied parameters in order to improve the performance of place recognition depending on their specific problem requisites. The applicability of our toolbox in visual localization purposes for intelligent vehicles is validated in the presented results, jointly with comparisons to the main state-of-the-art methods.},
  location = {Rio de Janeiro, Brazil},
  numpages = {6},
  url = {https://doi.org/10.1109/ITSC.2016.7795672},
}

@INPROCEEDINGS{dub\'{e}-et-al:2016:7784311,
  author = {R. Dub\'{e} and A. Gawel and C. Cadena and R. Siegwart and L. Freda and M. Gianni},
  booktitle = {2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
  title = {3D Localization, Mapping and Path Planning for Search and Rescue Operations},
  pages = {272--273},
  doi = {10.1109/SSRR.2016.7784311},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {This work presents our results on 3D robot localization, mapping and path planning for the latest joint exercise of the European project “Long-Term Human-Robot Teaming for Robots Assisted Disaster Response” (TRADR)<sup>1</sup>. The full system is operated and evaluated by firemen end-users in real-world search and rescue experiments. We demonstrate that the system is able to plan a path to a goal position desired by the fireman operator in the TRADR Operational Control Unit (OCU), using a persistent 3D map created by the robot during previous sorties.},
  location = {Lausanne, Switzerland},
  numpages = {2},
  url = {https://doi.org/10.1109/SSRR.2016.7784311},
}

@INPROCEEDINGS{guo-liu:2022:9739362,
  author = {R. Guo and X. Liu},
  booktitle = {2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  title = {Ground Enhanced RGB-D SLAM for Dynamic Environments},
  pages = {1171--1177},
  doi = {10.1109/ROBIO54168.2021.9739362},
  publisher = {IEEE Press},
  year = {2022},
  abstract = {Robust pose estimation and map reconstruction are the basic requirements of the robotics autonomous. In this paper, a static ground feature enhanced SLAM system is proposed for dynamic environments with RGB-D sensors. Compared with the typical point-based SLAM, our designed system extra introduce the ground and other plane constraints to solve the dynamic SLAM. In the front-end, the ground as a special plane feature is detected and tracked, which can provide realiable constraint for the pose estimation in dynamic environments. In the back-end, a point-ground based factor graph is constructed and optimized for more accurate map. Moreover, plane structure is exploited to repair the keyframe dynamic regions, new synthesized keyframes are used to reconstruct the static map for long-term applications. Real world dataset tests demonstrate the effectiveness of our proposed system.},
  location = {Sanya, China},
  numpages = {7},
  url = {https://doi.org/10.1109/ROBIO54168.2021.9739362},
}

@INPROCEEDINGS{limosani-et-al:2015:7354193,
  author = {R. Limosani and L. Y. Morales and J. Even and F. Ferreri and A. Watanabe and F. Cavallo and P. Dario and N. Hagita},
  booktitle = {2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Long-Term Human Affordance Maps},
  pages = {5748--5754},
  doi = {10.1109/IROS.2015.7354193},
  publisher = {IEEE Press},
  year = {2015},
  abstract = {This paper presents a work on mapping the use of space by humans in long periods of time. Daily geometric maps with the same coordinate frame were generated with SLAM, and in a similar manner, daily affordance density maps (places people use) were generated with the output of a human tracker running on the robot. The contribution of the paper is two-fold: an approach to detect geometric changes to cluster them in similar geometric configurations and the building of geometric and affordance composite maps on each cluster. This approach avoids the loss of long term retrieved information. Geometric similarity was computed using a normal distance approach on the maps. The analysis was performed on data collected by a mobile robot for a period of 4 months accumulating data equivalent to 70 days. Experimental results show that the system is capable of detecting geometric changes in the environment and clustering similar geometric configurations.},
  location = {Hamburg, Germany},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS.2015.7354193},
}

@INPROCEEDINGS{maffei-et-al:2016:7759504,
  author = {R. Maffei and V. A. M. Jorge and V. F. Rey and M. Kolberg and E. Prestes},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Long-Term Place Recognition Using Multi-Level Words of Spatial Densities},
  pages = {3269--3274},
  doi = {10.1109/IROS.2016.7759504},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Proper place recognition on an environment that can change over time is fundamental for long-term SLAM. In such scenarios the observations obtained in the same region can drastically differ due to changes caused by semi-static objects, such as doors, furniture, etc. In this work, we extend a strategy that represents environment regions using words, based on spatial density information extracted from laser readings. This time, in order to deal with changes in the environment, our method not only builds words representing the real observations made by the robot, but also alternative multi-level words to account for possible changes in a place's observations generated by non-static objects. Place recognition is made by searching matches of sequences of N consecutive words (both real or alternatives). Experiments performed in real and simulated scenarios are shown, and demonstrate the advantages associated to the use of multi-level words.},
  location = {Daejeon, South Korea},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS.2016.7759504},
}

@INPROCEEDINGS{senanayake-et-al:2017:7989294,
  author = {R. Senanayake and S. O'Callaghan and F. Ramos},
  booktitle = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {Learning Highly Dynamic Environments with Stochastic Variational Inference},
  pages = {2532--2539},
  doi = {10.1109/ICRA.2017.7989294},
  publisher = {IEEE Press},
  year = {2017},
  abstract = {Understanding the dynamics of urban environments is crucial for path planning and safe navigation. However, the dynamics might be extremely complex making learning the environment an unfathomable task. Within the methods available for learning dynamic environments, dynamic Gaussian process occupancy maps (DGPOM) are very attractive because they can produce spatially-continuous occupancy maps taking into account neighborhood information, and provide probabilistic estimates, naturally inferring the uncertainty of predictions. Despite these properties, they are extremely slow, especially in dynamic mapping where the parameters of the map have to be updated as new data arrive from range sensors such as LiDARs. In this work, we leverage recent advancements in stochastic variational inference (SVI) to quickly learn dynamic areas in an online fashion. Further, we propose an information-driven technique to “intelligently” select inducing points required for SVI without relying on any object trackers which essentially improves computational time as well as robustness. These long-term occupancy maps entertain all attractive properties of DGPOM while the learning process is significantly faster, yet accurate. Our experiments with both simulation and real robot data on road intersections show a significant improvement in speed while maintaining a comparable or better accuracy.},
  location = {Singapore, Singapore},
  numpages = {8},
  url = {https://doi.org/10.1109/ICRA.2017.7989294},
}

@INPROCEEDINGS{spangenberg-et-al:2016:7759339,
  author = {R. Spangenberg and D. Goehring and R. Rojas},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Pole-Based Localization for Autonomous Vehicles in Urban Scenarios},
  pages = {2161--2166},
  doi = {10.1109/IROS.2016.7759339},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Localization is a key capability for autonomous vehicles especially in urban scenarios. We propose the use of pole-like landmarks as primary features in these environments, as they are distinct, long-term stable and can be detected reliably with a stereo camera system. Furthermore, the resulting map representation is memory efficient, allowing for easy storage and on-line updates. The localization is performed in real-time by a stereo camera system as a main sensor, using vehicle odometry and an off-the-shelf GPS as secondary information sources. Localization is performed by a particle filter approach, coupled with an Kalman filter for robustness and sensor fusion. This leads to a lateral accuracy below 20 cm in various urban test areas. The system has been included in our autonomous test vehicle and successfully demonstrated the full loop from mapping to autonomous driving.},
  location = {Daejeon, South Korea},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS.2016.7759339},
}

@INPROCEEDINGS{rodrigues-et-al:2018:8594456,
  author = {R. T. Rodrigues and A. P. Aguiar and A. Pascoal},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {A B-Spline Mapping Framework for Long-Term Autonomous Operations},
  pages = {3204--3209},
  doi = {10.1109/IROS.2018.8594456},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.},
  location = {Madrid, Spain},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS.2018.8594456},
}

@INPROCEEDINGS{v\'{a}zquez-mart\'{\i}n-et-al:2006,
  author = {R. V\'{a}zquez-Mart\'{\i}n and J. Martinez and J. C. D. Toro and P. N\'{u}\~{n}ez and F. Sandoval},
  booktitle = {Proceedings of the 7th WSEAS International Conference on Automation &amp; Information},
  title = {An Active Perception Control Architecture for Autonomous Robots},
  pages = {144--149},
  publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
  address = {Stevens Point, Wisconsin, USA},
  year = {2006},
  abstract = {Operating environments for autonomous mobile robots are characterized by short-term and long-term changes or moving obstacles that make it very difficult for the robot to acquire and maintain an exact model of the world. For robots to operate successfully under such conditions, they have to use any knowledge that is available. In order to continuously perceive information about the environment and update its model of the world, an autonomous robot is typically equipped with several sensor systems. In this paper, we present a control architecture where perceptions are also capable of directly activating robot behaviour. The control architecture scheme follows the hybrid guidelines and it maintains an environment representation where the highest level is built from perception outcomes. These perceptions are organized into a set of modules that perform different levels of sensory representation: primitives, such as localization or landmark detection, and compound perceptions, such as feature maps (local SLAM). The low reactive layer of the architecture is based on a set of behaviours which only provide the robot with navigation capabilities. Finally, the deliberative layer builds a symbolic representation of the environment (topological map) and integrates suitable algorithms to accomplish the execution of the task.},
  isbn = {9608457467},
  keywords = {hybrid control architecture, design patterns, framework, active perception, autonomous robot},
  location = {Cavtat, Croatia},
  numpages = {6},
  series = {ICAI'06},
  url = {https://dl.acm.org/doi/abs/10.5555/1362937.1362964},
}

@INPROCEEDINGS{dominguez-et-al:2015:433,
  author = {S. Dominguez and B. Khomutenko and G. Garcia and P. Martinet},
  booktitle = {Proceedings of the 2015 IEEE 18th International Conference on Intelligent Transportation Systems},
  title = {An Optimization Technique for Positioning Multiple Maps for Self-Driving Car's Autonomous Navigation},
  pages = {2694--2699},
  doi = {10.1109/ITSC.2015.433},
  publisher = {IEEE Computer Society},
  address = {USA},
  year = {2015},
  abstract = {Self-driving car's navigation requires a very precise localization covering wide areas and long distances. Moreover, they have to do it at faster speeds than conventional mobile robots. This paper reports on an efficient technique to optimize the position of a sequence of maps along a journey. We take advantage of the short-term precision and reduced space on disk of the localization using 2D occupancy grid maps, from now on called sub-maps, as well as, the long-term global consistency of a Kalman filter that fuses odometry and GPS measurements. In our approach, horizontal planar LiDARs and odometry measurements are used to perform 2D-SLAM generating the sub-maps, and the EKF to generate the trajectory followed by the car in global coordinates. During the trip, after finishing each sub-map, a relaxation process is applied to a set of the last sub-maps to position them globally using both, global and map's local path. The importance of this method lies on its performance, expending low computing resources, so it can work in real time on a computer with conventional characteristics and on its robustness which makes it suitable for being used on a self-driving car as it doesn't depend excessively on the availability of GPS signal or the eventual appearance of moving objects around the car. Extensive testing has been performed in the suburbs and in the down-town of Nantes (France) covering a distance of 25 kilometers with different traffic conditions obtaining satisfactory results for autonomous driving.},
  isbn = {9781467365963},
  numpages = {6},
  series = {ITSC '15},
  url = {https://doi.org/10.1109/ITSC.2015.433},
}

@INPROCEEDINGS{hochdorfer-schlegel:2009:5354433,
  author = {S. Hochdorfer and C. Schlegel},
  booktitle = {Proceedings of the 2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title = {Landmark Rating and Selection According to Localization Coverage: Addressing the Challenge of Lifelong Operation of SLAM in Service Robots},
  pages = {382--387},
  doi = {10.1109/IROS.2009.5354433},
  publisher = {IEEE Press},
  year = {2009},
  abstract = {Acting in everyday-life environments is still a great challenge in service robotics. Although algorithms and solutions already exist for many relevant subproblems, in particular the aspect of robustness and suitability for everyday use has been neglected so far very often. Robustness and suitability for everyday use are features affecting not only the overall system design but have impact on each single algorithm of each component.Although an overwhelming amount of work is available to address the SLAM problem, the challenge of applying a SLAM algorithm over the whole lifecycle of a service robot, perhaps even in different environments, has not been brought into focus very often. An obvious problem to be solved is the continuously growing number of landmarks. A lifelong running SLAM approach requires means to select landmarks such that they best cover the working environment given bounded SLAM resources like the maximum number of manageable landmarks. This paper proposes a novel solution for selecting appropriate landmarks to limit the number of landmarks. The idea is to quantify the contribution of a landmark to the ability of the robot to localize itself in its working environment. Thus, the core contribution is to base the landmark selection process upon the landmarks' coverage of the working environment.Real-world experiments on a P3DX-platform with a bearing-only SLAM approach and an omnicam confirm that the addressed question and the proposed first approach might be another step towards the overall goal of suitability for everyday use.},
  isbn = {9781424438037},
  location = {St. Louis, MO, USA},
  numpages = {6},
  series = {IROS'09},
}

@PHDTHESIS{armentrout:1995,
  author = {S. L. Armentrout},
  title = {A Computational Theory of Map Reorganization},
  pages = {},
  note = {UMI Order No. GAX95-14488},
  publisher = {University of Maryland at College Park},
  address = {USA},
  year = {1995},
  abstract = {Feature maps are an important class of neural networks able to encode within their organizational structure the spatial or functional relationships of an input space. Although originally inspired by the topographic maps found in mammalian cortex, feature maps have found widespread use as computational tools in such applications as speech recognition, robotic arm manipulation, and optimization. Self-organization of feature maps has received much attention not only because of this computational applicability, but also because of the desire to understand how such maps may self-organize in the brain. This dissertation studies how feature maps reorganize following sudden focal damage. The motivations are to gain a deeper understanding of the fundamental processes governing reorganization in feature maps, to examine the much cited but rarely studied claim of fault tolerance in neural networks, and to shed light on recovery processes in the brain. This work contains the first demonstration of spontaneous reorganization in topographic feature maps following focal map damage. Comparable results are obtained using either competitive or traditional non-competitive activation mechanisms.A computational theory of map reorganization is proposed, supported by both theoretical and experimental evidence. This theory is comprised of three principles: (1) post-damage reorganization consists of two distinct phases: immediate and long-term; (2) increased excitability near the damaged map triggers subsequent more distant reorganization; and (3) the extent of reorganization is limited by the degree to which output nodes can move their functional receptive fields within their structural boundaries. Further evidence for these principles is presented by examining the effects of model perturbations such as variations in input frequency distribution and learning signal strength.To examine difficulties encountered while developing non-competitive versions of the aforementioned reorganizational model, mathematical and numerical analysis of a canonical lateral inhibitory model of peristimulus inhibition were undertaken. The results define preconditions necessary for focal stimuli to induce unimodal activation islands in lateral inhibition models. The resulting constraints together with the above principles greatly limit the class of non-competitive models which can form maps capable of reorganizing.},
  url = {},
}

@INPROCEEDINGS{luthardt-et-al:2019:8916895,
  author = {S. Luthardt and C. Ziegler and V. Willert and J. Adamy},
  booktitle = {2019 IEEE Intelligent Transportation Systems Conference (ITSC)},
  title = {How to Match Tracks of Visual Features for Automotive Long-Term SLAM},
  pages = {934--941},
  doi = {10.1109/ITSC.2019.8916895},
  publisher = {IEEE Press},
  year = {2019},
  abstract = {Accurate localization is a vital prerequisite for future assistance or autonomous driving functions in intelligent vehicles. To achieve the required localization accuracy and availability, long-term visual SLAM algorithms like LLama-SLAM are a promising option. In such algorithms visual feature tracks, i. e. landmark observations over several consecutive image frames, have to be matched to feature tracks recorded days, weeks or months earlier. This leads to a more challenging matching problem than in short-term visual localization and known descriptor matching methods cannot be applied directly. In this paper, we devise several approaches to compare and match feature tracks and evaluate their performance on a long-term data set. With the proposed descriptor combination and masking ("CoMa") method the best track matching performance is achieved with minor computational cost. This method creates a single combined descriptor for each feature track and furthermore increases the robustness by capturing the appearance variations of this track in a descriptor mask.},
  location = {Auckland, New Zealand},
  numpages = {8},
  url = {https://doi.org/10.1109/ITSC.2019.8916895},
}

@INPROCEEDINGS{luthardt-et-al:2018:8569323,
  author = {S. Luthardt and V. Willert and J. Adamy},
  booktitle = {2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
  title = {LLama-SLAM: Learning High-Quality Visual Landmarks for Long-Term Mapping and Localization},
  pages = {2645--2652},
  doi = {10.1109/ITSC.2018.8569323},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {The precise localization of vehicles is an important requirement for autonomous driving or advanced driver assistance systems. Using common GNSS the ego position can be measured but not with the reliability and precision necessary. An alternative approach to achieve precise localization is the usage of visual landmarks observed by a camera mounted in the vehicle. However, this raises the necessity of reliable visual landmarks that are easily recognizable and persistent. We propose a novel SLAM algorithm that focuses on learning and mapping such visual long-term landmarks (LLamas). The algorithm therefore processes stereo image streams from several recording sessions in the same spatial area. The key part within LLama-SLAM is the assessment of the landmarks with quality values that are inferred as viewpoint dependent probabilities from observation statistics. By adding solely landmarks of high quality to the final LLama Map, it can be kept compact while still allowing reliable localization. Due to the long-term evaluation of the GNSS measurement during the sessions, the landmarks can be positioned precisely in a global referenced coordinate system. For a first assessment of the algorithm's capabilities, we present some experimental results from the mapping process combining three sessions recorded over two months on the same route.},
  isbn = {978-1-7281-0321-1},
  location = {Maui, HI, USA},
  numpages = {8},
  url = {https://doi.org/10.1109/ITSC.2018.8569323},
}

@ARTICLE{chaves-et-al:2016:6,
  author = {S. M. Chaves and A. Kim and E. Galceran and R. M. Eustice},
  journal = {Auton. Robots},
  title = {Opportunistic Sampling-Based Active Visual SLAM for Underwater Inspection},
  volume = {40},
  number = {7},
  pages = {1245--1265},
  doi = {10.1007/s10514-016-9597-6},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2016},
  month = {10},
  abstract = {This paper reports on an active SLAM framework for performing large-scale inspections with an underwater robot. We propose a path planning algorithm integrated with visual SLAM that plans loop-closure paths in order to decrease navigation uncertainty. While loop-closing revisit actions bound the robot's uncertainty, they also lead to redundant area coverage and increased path length. Our proposed opportunistic framework leverages sampling-based techniques and information filtering to plan revisit paths that are coverage efficient. We employ Gaussian process regression for modeling the prediction of camera registrations and use a two-step optimization procedure for selecting revisit actions. We show that the proposed method offers many benefits over existing solutions and good performance for bounding navigation uncertainty in long-term autonomous operations with hybrid simulation experiments and real-world field trials performed by an underwater inspection robot.},
  issn = {0929-5593},
  issue_date = {October   2016},
  keywords = {Gaussian processes, Underwater robotics, Active SLAM, Sampling-based planning},
  numpages = {21},
  url = {https://doi.org/10.1007/s10514-016-9597-6},
}

@INPROCEEDINGS{nashed-biswas:2016:7759683,
  author = {S. Nashed and J. Biswas},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Curating Long-Term Vector Maps},
  pages = {4643--4648},
  doi = {10.1109/IROS.2016.7759683},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Autonomous service mobile robots need to consistently, accurately, and robustly localize in human environments despite changes to such environments over time. Episodic non-Markov Localization addresses the challenge of localization in such changing environments by classifying observations as arising from Long-Term, Short-Term, or Dynamic Features. However, in order to do so, EnML relies on an estimate of the Long-Term Vector Map (LTVM) that does not change over time. In this paper, we introduce a recursive algorithm to build and update the LTVM over time by reasoning about visibility constraints of objects observed over multiple robot deployments. We use a signed distance function (SDF) to filter out observations of short-term and dynamic features from multiple deployments of the robot. The remaining long-term observations are used to build a vector map by robust local linear regression. The uncertainty in the resulting LTVM is computed via Monte Carlo resampling the observations arising from long-term features. By combining occupancy-grid based SDF filtering of observations with continuous space regression of the filtered observations, our proposed approach builds, updates, and amends LTVMs over time, reasoning about all observations from all robot deployments in an environment. We present experimental results demonstrating the accuracy, robustness, and compact nature of the extracted LTVMs from several long-term robot datasets.},
  location = {Daejeon, South Korea},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS.2016.7759683},
}

@ARTICLE{nuske-et-al:2009:20306,
  author = {S. Nuske and J. Roberts and G. Wyeth},
  journal = {J. Field Robot.},
  title = {Robust Outdoor Visual Localization Using a Three-Dimensional-Edge Map},
  volume = {26},
  number = {9},
  pages = {728--756},
  doi = {10.1002/rob.20306},
  publisher = {John Wiley and Sons Ltd.},
  address = {GBR},
  year = {2009},
  month = {9},
  abstract = {Visual localization systems that are practical for autonomous vehicles in outdoor industrial applications must perform reliably in a wide range of conditions. Changing outdoor conditions cause difficulty by drastically altering the information available in the camera images. To confront the problem, we have developed a visual localization system that uses a surveyed three-dimensional (3D)-edge map of permanent structures in the environment. The map has the invariant properties necessary to achieve long-term robust operation. Previous 3D-edge map localization systems usually maintain a single pose hypothesis, making it difficult to initialize without an accurate prior pose estimate and also making them susceptible to misalignment with unmapped edges detected in the camera image. A multihypothesis particle filter is employed here to perform the initialization procedure with significant uncertainty in the vehicle's initial pose. A novel observation function for the particle filter is developed and evaluated against two existing functions. The new function is shown to further improve the abilities of the particle filter to converge given a very coarse estimate of the vehicle's initial pose. An intelligent exposure control algorithm is also developed that improves the quality of the pertinent information in the image. Results gathered over an entire sunny day and also during rainy weather illustrate that the localization system can operate in a wide range of outdoor conditions. The conclusion is that an invariant map, a robust multihypothesis localization algorithm, and an intelligent exposure control algorithm all combine to enable reliable visual localization through challenging outdoor conditions. © 2009 Wiley Periodicals, Inc.},
  issn = {1556-4959},
  issue_date = {September 2009},
  numpages = {29},
}

@INPROCEEDINGS{siva-zhang:2018:8461042,
  author = {S. Siva and H. Zhang},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title = {Omnidirectional Multisensory Perception Fusion for Long-Term Place Recognition},
  pages = {1--9},
  doi = {10.1109/ICRA.2018.8461042},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {Over the recent years, long-term place recognition has attracted an increasing attention to detect loops for largescale Simultaneous Localization and Mapping (SLAM) in loopy environments during long-term autonomy. Almost all existing methods are designed to work with traditional cameras with a limited field of view. Recent advances in omnidirectional sensors offer a robot an opportunity to perceive the entire surrounding environment. However, no work has existed thus far to research how omnidirectional sensors can help long-term place recognition, especially when multiple types of omnidirectional sensory data are available. In this paper, we propose a novel approach to integrate observations obtained from multiple sensors from different viewing angles in the omnidirectional observation in order to perform multi-directional place recognition in longterm autonomy. Our approach also answers two new questions when omnidirectional multisensory data is available for place recognition, including whether it is possible to recognize a place with long-term appearance variations when robots approach it from various directions, and whether observations from various viewing angles are the same informative. To evaluate our approach and hypothesis, we have collected the first large-scale dataset that consists of omnidirectional multisensory (intensity and depth) data collected in urban and suburban environments across a year. Experimental results have shown that our approach is able to achieve multi-directional long-term place recognition, and identifies the most discriminative viewing angles from the omnidirectional observation.},
  location = {Brisbane, Australia},
  numpages = {9},
  url = {https://doi.org/10.1109/ICRA.2018.8461042},
}

@INPROCEEDINGS{zhang-et-al:2019:9013768,
  author = {S. Zhang and W. Wang and S. Tang and S. Jin and T. Jiang},
  booktitle = {2019 IEEE Global Communications Conference (GLOBECOM)},
  title = {Localizing Backscatters by a Single Robot with Zero Start-Up Cost},
  pages = {1--6},
  doi = {10.1109/GLOBECOM38437.2019.9013768},
  publisher = {IEEE Press},
  year = {2019},
  abstract = {Recent years have witnessed the rapid proliferation of low- power backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such low-power backscatter tags is crucial for IoT-based smart services. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, increasing the deployment cost. To empower universal localization service, this paper presents Rover, an indoor localization system that simultaneously localizes multiple backscatter tags with zero start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing WiFi-based positioning measurements with inertial measurements to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues such as the interference among multiple tags and the real- time processing for solving the SLAM problem. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.},
  location = {Waikoloa, HI, USA},
  numpages = {6},
  url = {https://doi.org/10.1109/GLOBECOM38437.2019.9013768},
}

@ARTICLE{an-et-al:2016:0,
  author = {S.-Y. An and L.-K. Lee and S.-Y. Oh},
  journal = {Auton. Robots},
  title = {Ceiling Vision-Based Active SLAM Framework for Dynamic and Wide-Open Environments},
  volume = {40},
  number = {2},
  pages = {291--324},
  doi = {10.1007/s10514-015-9453-0},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2016},
  month = {2},
  abstract = {A typical indoor environment can be divided into three categories; office (or room), hallway, and wide-open space such as lobby and hall. There have been numerous approaches for solving simultaneous localization and mapping (SLAM) problem in office (or room) and hallway. However, direct application of the existing approaches to wide-open space may be failed, because it has some distinguished features compared to other indoor places. To solve this problem, this paper proposes a new ceiling vision-based active SLAM framework, with an emphasis on practical deployment of service robot for commercial use in dynamically changing and wide-open environments by adopting the ceiling vision. First, for defining ceiling feature which can be extracted regardless of complexity of ceiling pattern we introduce a model-free landmark, i.e., visual node descriptor, which consists of edge points and their orientations in image space. Second, a recursive `explore and exploit' is proposed for autonomous mapping. It is recursively performed by spreading out mapped area gradually while the robot is actively localized in the map. It can improve map accuracy due to frequent small loop closing. Third, a dynamic edge link (DEL) is proposed to cope with environmental changes in the map. Owing to DEL, we do not need to filter out corrupted sensor data and to distinguish moving object from static one. Also, a self-repairing map mechanism is introduced to deal with unexpected installation or removal of inner structures. We therefore achieve long-term navigation. Several simulations and real experiments in various places show that the proposed active SLAM framework could build a topologically consistent map, and demonstrated that it can be applied well to real environments such as wide-open space in a city hall and railway station.},
  issn = {0929-5593},
  issue_date = {February  2016},
  keywords = {Ceiling vision, SLAM, Dynamic environment, Wide-open area, Mobile robot},
  numpages = {34},
  url = {https://doi.org/10.1007/s10514-015-9453-0},
}

@ARTICLE{krajn\'{\i}k-et-al:2017:2665664,
  author = {T. Krajn\'{\i}k and J. P. Fentanes and J. M. Santos and T. Duckett},
  journal = {Trans. Rob.},
  title = {FreMEn: Frequency Map Enhancement for Long-Term Mobile Robot Autonomy in Changing Environments},
  volume = {33},
  number = {4},
  pages = {964--977},
  doi = {10.1109/TRO.2017.2665664},
  publisher = {IEEE Press},
  year = {2017},
  month = {8},
  abstract = {We present a new approach to long-term mobile robot mapping in dynamic indoor environments. Unlike traditional world models that are tailored to represent static scenes, our approach explicitly models environmental dynamics. We assume that some of the hidden processes that influence the dynamic environment states are periodic and model the uncertainty of the estimated state variables by their frequency spectra. The spectral model can represent arbitrary timescales of environment dynamics with low memory requirements. Transformation of the spectral model to the time domain allows for the prediction of the future environment states, which improves the robot's long-term performance in changing environments. Experiments performed over time periods of months to years demonstrate that the approach can efficiently represent large numbers of observations and reliably predict future environment states. The experiments indicate that the model's predictive capabilities improve mobile robot localization and navigation in changing environments.},
  issn = {1552-3098},
  issue_date = {Aug. 2017},
  numpages = {14},
  url = {https://doi.org/10.1109/TRO.2017.2665664},
}

@INPROCEEDINGS{krajn\'{\i}k-et-al:2016:7759671,
  author = {T. Krajn\'{\i}k and J. P. Fentanes and M. Hanheide and T. Duckett},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {Persistent Localization and Life-Long Mapping in Changing Environments Using the Frequency Map Enhancement},
  pages = {4558--4563},
  doi = {10.1109/IROS.2016.7759671},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.},
  location = {Daejeon, South Korea},
  numpages = {6},
  url = {https://doi.org/10.1109/IROS.2016.7759671},
}

@INPROCEEDINGS{silva-et-al:2014:0004891700520059,
  author = {T. L. C. D. Silva and A. C. A. Neto and R. P. Magalh\~{a}es and V. A. E. D. Farias and J. A. F. D. Mac\^{e}do and J. C. Machado},
  booktitle = {Proceedings of the 16th International Conference on Enterprise Information Systems - Volume 1},
  title = {Efficient and Distributed DBScan Algorithm Using MapReduce to Detect Density Areas on Traffic Data},
  pages = {52--59},
  doi = {10.5220/0004891700520059},
  publisher = {SCITEPRESS - Science and Technology Publications, Lda},
  address = {Setubal, PRT},
  year = {2014},
  abstract = {Traf\"{\i} c information in big cities can be collected by GPS in vehicles or traf\"{\i} c radar, or even gathered fromtweets. This information can be used to complement information generated by cameras and physical sensors in order to guide the actions of public agents in the short and long term. It is also useful to support decisions of drivers related to displacement through the city in real time or near-real time. Through these data it is possible to analyze where the density areas are within the city in order to discover portions of the city that has more probability to have traf\"{\i} c jams. Such discovery may help the search for effective reengineering traf\"{\i} c solutions in the context of smart cities. This paper presents a new distributed and ef\"{\i} cient strategy of the DBScan algorithm that uses MapReduce to detect which are the density areas. Experiment results con\"{\i} rm that our strategy is scalable and ef\"{\i} cient to deal with a great amount of data than others competitors},
  isbn = {9789897580277},
  keywords = {MapReduce, DBScan, Traffic Data},
  location = {Lisbon, Portugal},
  numpages = {8},
  series = {ICEIS 2014},
  url = {https://doi.org/10.5220/0004891700520059},
}

@INPROCEEDINGS{taisho-kanji:2016:7866383,
  author = {T. Taisho and T. Kanji},
  booktitle = {2016 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  title = {Mining DCNN Landmarks for Long-Term Visual SLAM},
  pages = {570--576},
  doi = {10.1109/ROBIO.2016.7866383},
  publisher = {IEEE Press},
  year = {2016},
  abstract = {Long-term visual SLAM, in familiar, semi-dynamic, and partially changing environments is an important area of research in robotics. The main problem we faced is the question of how to describe a scene discriminatively and compactly-both of which are necessary in order to cope with changes in appearance and a large amount of visual information. In this study, we address the above issues by mining visual experience. Our strategy is to mine a library of raw visual images, termed visual experience, to find the relevant visual patterns to effectively explain the input scene. From a practical point of view, our work offers three main contributions over the previous work. First, it is the first application of discriminative visual features from deep convolutional neural networks (DCNN) to the task of visual landmark mining. Second, we show how to interpret a high-dimensional DCNN feature to a compact semantic representation of visual word. Third, we show that our approach can turn the scene description task with any feature (including the DCNN feature) into the task of mining visual experience. Experiments on a challenging cross-domain visual place recognition validate efficacy of the proposed approach.},
  location = {Qingdao, China},
  numpages = {7},
  url = {https://doi.org/10.1109/ROBIO.2016.7866383},
}

@PHDTHESIS{navalpakkam:2006,
  author = {V. Navalpakkam},
  title = {Integrating Top-down and Bottom-up Visual Attention},
  pages = {},
  note = {AAI3257814},
  publisher = {University of Southern California},
  address = {USA},
  year = {2006},
  abstract = {Visual attention---the brain's mechanism for selecting important visual information---is influenced by a combination of bottom-up (sudden, unexpected visual events that are spatiotemporally different from the surroundings) and top-down (goal-relevant) factors. Although both are crucial for real-world applications like robot navigation or visual surveillance, most existing models are either purely bottom-up or top-down. In this thesis, we present a new model that integrates top-down and bottom-up attention. We begin with a wide perspective of how a task specification (e.g., "who is doing what to whom") influences attention during scene understanding. We propose and partially implement a general-purpose architecture illustrating how different bottom-up and top-down components of visual processing such as the gist, saliency map, object detection and recognition modules, working memory, long term memory, task-relevance map may interact and interface with each other to guide attention to salient and relevant scene locations. Next, we investigate the specifics of how bottom-up and top-down influences may integrate while searching for a target in a distracting background. We probe the granularity of information integration within feature dimensions such as color, size, luminance. Results of our eye tracking experiments assert that bottom-up responses encoding feature dimensions can be modulated by not just one, but several top-down gain control signals, thus revealing high granularity of integration. Finally, we investigate the computational principles underlying the integration. We derive a formal theory of optimal integration of bottom-up salience with top-down knowledge about target and distractor features, such that the target's salience relative to the distractors is maximized, thereby accelerating search speed. Our theory makes a surprising prediction that traditional approaches of boosting neurons favoring the target features are sub-optimal. Instead, we show that in some cases, the optimal approach is to boost neurons favoring a non-target feature. We provide experimental evidence supporting this prediction. Results of testing on artificial and natural images show that the theory successfully accounts for several effects in human visual search behavior (including pop-out, target-distractor discriminability, distractor heterogeneity, linear separability, feature priming, target uncertainty). In summary, this thesis provides insight into how bottom-up and top-down attention may be integrated in the primate brain.},
  advisor = {Itti, Laurent},
  url = {https://www.proquest.com/openview/789c2091e56a8a679eb35584575e476b/},
}

@ARTICLE{maddern-et-al:2017:0278364916679498,
  author = {W. Maddern and G. Pascoe and C. Linegar and P. Newman},
  journal = {Int. J. Rob. Res.},
  title = {1 Year, 1000 Km: The Oxford RobotCar Dataset},
  volume = {36},
  number = {1},
  pages = {3--15},
  doi = {10.1177/0278364916679498},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2017},
  month = {1},
  abstract = {We present a challenging new dataset for autonomous driving: the Oxford RobotCar Dataset. Over the period of May 2014 to December 2015 we traversed a route through central Oxford twice a week on average using the Oxford RobotCar platform, an autonomous Nissan LEAF. This resulted in over 1000 km of recorded driving with almost 20 million images collected from 6 cameras mounted to the vehicle, along with LIDAR, GPS and INS ground truth. Data was collected in all weather conditions, including heavy rain, night, direct sunlight and snow. Road and building works over the period of a year significantly changed sections of the route from the beginning to the end of data collection. By frequently traversing the same route over the period of a year we enable research investigating long-term localization and mapping for autonomous vehicles in real-world, dynamic urban environments. The full dataset is available for download at:},
  issn = {0278-3649},
  issue_date = {Jan 2017},
  keywords = {autonomous vehicles, stereo, mapping, GPS, RobotCar, computer vision, localization, SLAM, LIDAR, mobile robotics, cameras, Dataset, long-term autonomy},
  numpages = {13},
  url = {https://doi.org/10.1177/0278364916679498},
}

@INPROCEEDINGS{zhou-et-al:2019:13,
  author = {X. Zhou and S. Chan and J. Li and S. Chen and H. Liu},
  booktitle = {Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part I},
  title = {Dictionary Learning and Confidence Map Estimation-Based Tracker for Robot-Assisted Therapy System},
  pages = {147--159},
  doi = {10.1007/978-3-030-31654-9_13},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  year = {2019},
  abstract = {In this paper, we propose a new tracker based on dictionary learning and confidence map estimation for a robot-assisted therapy system. We first over-segment the image into superpixel patches, and then employ color and depth cues to estimate the object confidence of each superpixel patch. We build two Bag-of-Word (BoW) models from initial frames to encode foreground/background appearance, and compute object confidence at superpixel level using BoW model in both foreground and background. We further refine target confidence by depth-based statistical features to mitigate noise interference and the uncertainty of visual cues. We derive the global confidence of each target candidate at bag level, and incorporate the confidence estimations to determine the posterior probability of each candidate within the Bayesian framework. Experimental results demonstrate the superior performance of the proposed method, especially in long-term tracking and occlusion handling.},
  isbn = {978-3-030-31653-2},
  keywords = {Bag-of-Word, RGB-D, Object tracking, Occlusion handling},
  location = {Xi'an, China},
  numpages = {13},
  url = {https://doi.org/10.1007/978-3-030-31654-9_13},
}

@INPROCEEDINGS{furuta-et-al:2018:8594481,
  author = {Y. Furuta and K. Okada and Y. Kakiuchi and M. Inaba},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title = {An Everyday Robotic System That Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory},
  pages = {1--7},
  doi = {10.1109/IROS.2018.8594481},
  publisher = {IEEE Press},
  year = {2018},
  abstract = {To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.},
  location = {Madrid, Spain},
  numpages = {7},
  url = {https://doi.org/10.1109/IROS.2018.8594481},
}

@INPROCEEDINGS{guihua-et-al:2019:3378089,
  author = {Y. Guihua and L. Zhiyi and T. Weiwei},
  booktitle = {Proceedings of the 2019 4th International Conference on Intelligent Information Processing},
  title = {Simultaneous Positioning And Map Construction of Mobile Robots Based on The Cartographer Algorithm},
  pages = {122--126},
  doi = {10.1145/3378065.3378089},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  year = {2019},
  abstract = {At present, mobile robots have been more and more widely used, in order to enable mobile robots to achieve autonomous localization and mapping (SLAM), and to solve the problem of cumulative errors caused by long-term movement of robots; The current mainstream filtering method does not solve the accumulated error caused by the mileage meter. In order to correct the accumulated error caused by the mileage meter, this design uses Cartographer algorithm to build the map, and correct the accumulated error of mileage to achieve the accurate positioning of the robot. Taking ROS system as the operating platform, the experimental results show that the mobile robot corrects the accumulated error of mileage very well, and achieves more accurate positioning and better environmental map construction.},
  isbn = {9781450361910},
  keywords = {Independent Positioning, Cartographer Algorithms, Mapping},
  location = {China, China},
  numpages = {5},
  series = {ICIIP 2019},
  url = {https://doi.org/10.1145/3378065.3378089},
}

@ARTICLE{yang-et-al:2019:0,
  author = {Y. Yang and Y. Wu and N. Chen},
  journal = {Multimedia Tools Appl.},
  title = {Explorations on Visual Localization from Active to Passive},
  volume = {78},
  number = {2},
  pages = {2269--2309},
  doi = {10.1007/s11042-018-6347-0},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2019},
  month = {1},
  abstract = {In this paper, we novelly consider visual localization in active and passive two ways, with simple definition that active localization assists device to estimate location of its interest while passive localization aids device to estimate its own location in environment. Expecting to indicate some insights into visual localization, we specifically performed two explorations on active localization and more importantly explored to upgrade them from active to passive localization with extra geometry information available. In order to produce unconstrained and accurate 2D location estimation of interested object, we constructed an active localization system by fusing detection, tracking and recognition. Based on recognition, we proposed a collaborative strategy making mutual enhancement between detection and tracking possible to obtain better performance on 2D location estimation. Meanwhile, to actively estimate semantic location of interested visual region, we employed latest state-of-the-art light weight CNN models specifically designed for efficiency and trained two of them with large place dataset in perspective of scene recognition. What's more, using depth information available from RGB-D camera, we improved the active system for 2D location of interested object to a passive system for relative 3D location of device to the interested object. Firstly estimated was the 3D location of the interested object in the coordinate system of device, then relative location of device to the interested object in world coordinate system was deduced with appropriate assumption. Evaluations both subjectively on a RGB-D sequence obtained in a lab environment and practically on a robotic platform in an office environment indicated that the improved system was suitable for autonomous following robot. As well, the active system for rough semantic location estimation of interested visual region was promoted to a passive system for fine location estimation of device, with available 3D map describing the visited environment. In perspective of place recognition, we first adopted one of the efficient CNN models previously trained for semantic location estimation as a base to generate CNN features for both retrieval of candidate loops in the map and geometrical consistency checking of retrieved loops, then true loops were used to deduce fine location of device itself in environment. Comparison with state-of-the-art results reflected that the promoted system was adequate for long-term robotic autonomy. Achieving favorable performances, the presented four explorations have implied adequacy for elaborating on some insights into visual localization.},
  issn = {1380-7501},
  issue_date = {January   2019},
  keywords = {Loop closure detection, Long-term robotic autonomy, Visual localization, Following robot},
  numpages = {41},
  url = {https://doi.org/10.1007/s11042-018-6347-0},
}

@PHDTHESIS{yu:2021:991013039228303412,
  author = {Y. Yu},
  title = {Localization for Autonomous Navigation Systems in Large-Scale Outdoor Environments},
  pages = {},
  doi = {10.14711/thesis-991013039228303412},
  note = {AAI29221682},
  publisher = {Hong Kong University of Science and Technology (Hong Kong)},
  year = {2021},
  abstract = {Accurate localization is the most fundamental abilities of fully autonomous robots, including unmanned aerial vehicles (UAVs) [90, 46, 22], unmanned ground vehicles (UGVs) [121, 116, 98], and unmanned surface vehicles (USVs) [122, 109, 10]. Although numerous approaches have been adopted to achieve attractive performance on Simultaneous Localization and Mapping (SLAM) tasks in static and indoor scenarios, these tasks in large-scale and appearance-changing environments with robust performance are still challenging. For example, practical applications of mobile robots usually suffer from ineffective observations due to appearance changes, limitations of sensors, insufficient computational resources in large-scale environments, and accumulated drifts after long-term operation. To conquer these challenges, multiple sensors systems with sensor fusion can provide denser, higher frequency, and more dimensional measurements. Cameras, light detection and rangings (LiDARs), inertial measurement units (IMUs), and wheel encoders are common sensors for autonomous systems, especially for UGVs.In this thesis, I propose sensor fusion-based state estimators and localization systems, especially in large-scale outdoor environments. The thesis is divided into visual-based and LiDAR-based chapters. In the visual-based localization chapter, an omnidirectional visual-inertial state estimator is firstly proposed. It adopts panoramic images and inertial measurements to achieve not only robust performance with robot pose estimation but also online calibration of multiple sensors, robot velocity, and sensor bias. Then, I propose a complete visual localization system in the large-scale outdoor port scene. It combines learning-based semantic segmentation results with the prior map to implement robust and high-accuracy localization. I also utilize the proposed visual state estimator to compensate for the wheel odometry. In the multi-LiDAR localization chapter, I start with an automatic multi-LiDAR calibration method. Motion-based and appearance-based calibration methods are utilized for a novel calibration performance without any extra sensors, calibration target, or prior knowledge about surroundings. Based on that, I introduce a LiDAR-based localization approach without a 3D prebuild map, which is also considered to be suitable in challenging port scenes. In this localization approach, I also introduce LiDAR-wheel-encoder odometry with a four-wheel steering model. By conducting a series of experiments both in simulated and real-world large-scale challenging environments, I show proposed approaches with robust and accurate performance in indoor and outdoor mobile robot localization scenarios.},
  advisor = {Ming, Liu,},
  isbn = {9798438718482},
}

@ARTICLE{yu-et-al:2010:2038895,
  author = {Y. Yu and G. K. I. Mann and R. G. Gosine},
  journal = {Trans. Sys. Man Cyber. Part B},
  title = {An Object-Based Visual Attention Model for Robotic Applications},
  volume = {40},
  number = {5},
  pages = {1398--1412},
  doi = {10.1109/TSMCB.2009.2038895},
  publisher = {IEEE Press},
  year = {2010},
  month = {10},
  abstract = {By extending integrated competition hypothesis, this paper presents an object-based visual attention model, which selects one object of interest using low-dimensional features, resulting that visual perception starts from a fast attentional selection procedure. The proposed attention model involves seven modules: learning of object representations stored in a long-term memory (LTM), preattentive processing, top-down biasing, bottom-up competition, mediation between top-down and bottom-up ways, generation of saliency maps, and perceptual completion processing. It works in two phases: learning phase and attending phase. In the learning phase, the corresponding object representation is trained statistically when one object is attended. A dual-coding object representation consisting of local and global codings is proposed. Intensity, color, and orientation features are used to build the local coding, and a contour feature is employed to constitute the global coding. In the attending phase, the model preattentively segments the visual field into discrete proto-objects using Gestalt rules at first. If a task-specific object is given, the model recalls the corresponding representation from LTM and deduces the task-relevant feature(s) to evaluate top-down biases. The mediation between automatic bottom-up competition and conscious top-down biasing is then performed to yield a location-based saliency map. By combination of location-based saliency within each proto-object, the proto-object-based saliency is evaluated. The most salient proto-object is selected for attention, and it is finally put into the perceptual completion processing module to yield a complete object region. This model has been applied into distinct tasks of robots: detection of task-specific stationary and moving objects. Experimental results under different conditions are shown to validate this model.},
  issn = {1083-4419},
  issue_date = {October 2010},
  keywords = {top–down biasing, top-down biasing, Integrated competition (IC) hypothesis, object-based visual attention, integrated competition (IC) hypothesis, mobile robotics},
  numpages = {15},
  url = {https://doi.org/10.1109/TSMCB.2009.2038895},
}

@INPROCEEDINGS{zhu-et-al:2019:9010305,
  author = {Y. Zhu and B. Xue and L. Zheng and H. Huang and M. Liu and R. Fan},
  booktitle = {2019 IEEE International Conference on Imaging Systems and Techniques (IST)},
  title = {Real-Time, Environmentally-Robust 3D LiDAR Localization},
  pages = {1--6},
  doi = {10.1109/IST48021.2019.9010305},
  publisher = {IEEE Press},
  year = {2019},
  abstract = {Localization, or position fixing, is an important problem in robotics research. In this paper, we propose a novel approach for long-term localization in a changing environment using 3D LiDAR. We first create the map of a real environment using GPS and LiDAR. Then, we divide the map into several small parts as the targets for cloud registration, which can not only improve the robustness but also reduce the registration time. We proposed a localization method called PointLocalization. PointLocalization allows us to fuse different kinds of odometers, which can optimize the accuracy and frequency of localization results. We evaluate our algorithm on an unmanned ground vehicle (UGV) using LiDAR and a wheel encoder, and obtain the localization results at more than 20 Hz after fusion. The algorithm can also localize the UGV in a 180-degree field of view (FOV). Using an outdated map captured six months ago, this algorithm shows great robustness, and the test results show that it can achieve an accuracy of 10 cm. PointLocalization has been tested for a period of more than six months in a crowded factory and has operated successfully over a distance of more than 2000 km.},
  location = {Abu Dhabi, United Arab Emirates},
  numpages = {6},
  url = {https://doi.org/10.1109/IST48021.2019.9010305},
}

@INPROCEEDINGS{hashemifar-et-al:2018:3215531,
  author = {Z. Hashemifar and K. W. Lee and N. Napp and K. Dantu},
  booktitle = {Proceedings of the 1st International Workshop on Internet of People, Assistive Robots and Things},
  title = {Geometric Mapping for Sustained Indoor Autonomy},
  pages = {19--24},
  doi = {10.1145/3215525.3215531},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  year = {2018},
  abstract = {Simultaneous localization and mapping (SLAM) is the first step for enabling autonomous operation in unknown and changing environments. Many applications such as service and assistive robots require constant movement between different regions along with accurate navigation and localization at any point in time. Algorithms for SLAM have matured greatly over the last few years and can accommodate different sensors, computing requirements as well as environments for use. However, for long-term autonomy indoors, reasoning with a large volume of RGB-D data is still a major challenge. In this work, we propose a pipeline that attributes semantics, more specifically cuboidal structure, to observed objects, uses them as landmarks for mapping and thereby reduces the dimensionality of the represented map greatly. We chose cuboids, because many common urban scenes (such as offices, homes, malls) contain cuboidal objects (such as cabinets, tables, shelves). We develop a metric to perform such attribution consistently so they can be used as landmarks for mapping/navigation. We have tested our pipeline on three different datasets and show that we can reduce the map representation significantly while maintaining localization accuracy in all of them. Our vision is that attributing low-level semantics such as one presented in this work would make long-term autonomy computationally tractable.},
  isbn = {9781450358439},
  location = {Munich, Germany},
  numpages = {6},
  series = {IoPARTS'18},
  url = {https://doi.org/10.1145/3215525.3215531},
}

@ARTICLE{hong-et-al:2022:02783649221080483,
  author = {Z. Hong and Y. Petillot and A. Wallace and S. Wang},
  journal = {Int. J. Rob. Res.},
  title = {RadarSLAM: A Robust Simultaneous Localization and Mapping System for All Weather Conditions},
  volume = {41},
  number = {5},
  pages = {519--542},
  doi = {10.1177/02783649221080483},
  publisher = {Sage Publications, Inc.},
  address = {USA},
  year = {2022},
  month = {4},
  abstract = {A Simultaneous Localization and Mapping (SLAM) system must be robust to support long-term mobile vehicle and robot applications. However, camera and LiDAR based SLAM systems can be fragile when facing challenging illumination or weather conditions which degrade the utility of imagery and point cloud data. Radar, whose operating electromagnetic spectrum is less affected by environmental changes, is promising although its distinct sensor model and noise characteristics bring open challenges when being exploited for SLAM. This paper studies the use of a Frequency Modulated Continuous Wave radar for SLAM in large-scale outdoor environments. We propose a full radar SLAM system, including a novel radar motion estimation algorithm that leverages radar geometry for reliable feature tracking. It also optimally compensates motion distortion and estimates pose by joint optimization. Its loop closure component is designed to be simple yet efficient for radar imagery by capturing and exploiting structural information of the surrounding environment. Extensive experiments on three public radar datasets, ranging from city streets and residential areas to countryside and highways, show competitive accuracy and reliability performance of the proposed radar SLAM system compared to the state-of-the-art LiDAR, vision and radar methods. The results show that our system is technically viable in achieving reliable SLAM in extreme weather conditions on the RADIATE Dataset, for example, heavy snow and dense fog, demonstrating the promising potential of using radar for all-weather localization and mapping.},
  issn = {0278-3649},
  issue_date = {Apr 2022},
  keywords = {radar sensing, simultaneous localization and mapping, all-weather perception},
  numpages = {24},
  url = {https://doi.org/10.1177/02783649221080483},
}

@ARTICLE{hashemifar-et-al:2019:z,
  author = {Z. S. Hashemifar and C. Adhivarahan and A. Balakrishnan and K. Dantu},
  journal = {Auton. Robots},
  title = {Augmenting Visual SLAM with Wi-Fi Sensing for Indoor Applications},
  volume = {43},
  number = {8},
  pages = {2245--2260},
  doi = {10.1007/s10514-019-09874-z},
  publisher = {Kluwer Academic Publishers},
  address = {USA},
  year = {2019},
  month = {12},
  abstract = {Recent trends have accelerated the development of spatial applications on mobile devices and robots. These include navigation, augmented reality, human–robot interaction, and others. A key enabling technology for such applications is the understanding of the device’s location and the map of the surrounding environment. This generic problem, referred to as Simultaneous Localization and Mapping (SLAM), is an extensively researched topic in robotics. However, visual SLAM algorithms face several challenges including perceptual aliasing and high computational cost. These challenges affect the accuracy, efficiency, and viability of visual SLAM algorithms, especially for long-term SLAM, and their use in resource-constrained mobile devices. A parallel trend is the ubiquity of Wi-Fi routers for quick Internet access in most urban environments. Most robots and mobile devices are equipped with a Wi-Fi radio as well. We propose a method to utilize Wi-Fi received signal strength to alleviate the challenges faced by visual SLAM algorithms. To demonstrate the utility of this idea, this work makes the following contributions: (i) We propose a generic way to integrate Wi-Fi sensing into visual SLAM algorithms, (ii) We integrate such sensing into three well-known SLAM algorithms, (iii) Using four distinct datasets, we demonstrate the performance of such augmentation in comparison to the original visual algorithms and (iv) We compare our work to Wi-Fi augmented FABMAP algorithm. Overall, we show that our approach can improve the accuracy of visual SLAM algorithms by 11% on average and reduce computation time on average by 15% to 25%.},
  issn = {0929-5593},
  issue_date = {Dec 2019},
  keywords = {Visual SLAM, Perceptual aliasing, Wi-Fi sensing},
  numpages = {16},
  url = {https://doi.org/10.1007/s10514-019-09874-z},
}

@INPROCEEDINGS{wang-et-al:2022:9739599,
  author = {Z. Wang and S. Li and M. Cao and H. Chen and Y. Liu},
  booktitle = {2021 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  title = {Pole-like Objects Mapping and Long-Term Robot Localization in Dynamic Urban Scenarios},
  pages = {998--1003},
  doi = {10.1109/ROBIO54168.2021.9739599},
  publisher = {IEEE Press},
  year = {2022},
  abstract = {Localization on 3D data is a challenging task for unmanned vehicles, especially in long-term dynamic urban scenarios. Due to the generality and long-term stability, the pole-like objects are very suitable as landmarks for unmanned vehicle localization in time-varying scenarios. In this paper, a long-term LiDAR-only localization algorithm based on semantic cluster map is proposed. At first, the Convolutional Neural Network(CNN) is used to infer the semantics of LiDAR point clouds. Combined with the point cloud segmentation, the static objects pole/trunk are extracted and registered into global semantic cluster map. When the unmanned vehicle re-enters the environment again, the relocalization is completed by matching the clusters of current scan with the clusters of the global map. Furthermore, the matching between the local and global maps stably outputs the global pose at 2Hz to correct the drift of the 3D LiDAR odometry. The experimental results on our campus dataset demonstrate that the proposed approach performs better in localization accuracy compared with the current state-of-the-art methods. The source of this paper is available at: http://www.github.com/HITSZ-NRSL/long-term-localization.},
  location = {Sanya, China},
  numpages = {6},
  url = {https://doi.org/10.1109/ROBIO54168.2021.9739599},
}
