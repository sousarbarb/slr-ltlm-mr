@INPROCEEDINGS{9635985,
author={Zhao, Min and Guo, Xin and Song, Le and Qin, Baoxing and Shi, Xuesong and Lee, Gim Hee and Sun, Guanghui},
booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={A General Framework for Lifelong Localization and Mapping in Changing Environment},
year={2021},
volume={},
number={},
pages={3305-3312},
abstract={The environment of most real-world scenarios such as malls and supermarkets changes at all times. A pre-built map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-to-date model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efficient map updating strategy that includes map building, pose graph refinement and sparsification. To mitigate the unbounded increase of memory usage, we propose a map-trimming method based on the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.},
keywords={Location awareness;Simultaneous localization and mapping;Buildings;Intelligent robots},
doi={10.1109/IROS51168.2021.9635985},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{8248292,
author={Shen, Qihui and Sun, Hanxu and Ye, Ping},
booktitle={2017 4th International Conference on Systems and Informatics (ICSAI)}, title={Research of large-scale offline map management in visual SLAM},
year={2017},
volume={},
number={},
pages={215-219},
abstract={This paper presents a novel method of visual simultaneous localization and mapping (SLAM), which is a method of real-time localization and mapping. It is important for a mobile robot to build a map while autonomously navigation. Due to the complexity of the robot work scene, the SLAM method proposed in this paper optimizes map management. It will cost a lot of time and space when a robot long-term works in a same large scene. Therefore, we propose a method in this paper to save a detail map as an offline map in advance. At the same time in order to facilitate the follow-up optimization, the offline map can be divided into several sub-graphs according to the similarity of the scene. Since the segmented offline map has been saved to local system, it can be loaded at any time to localization and obtain the pose of current frame.},
keywords={Simultaneous localization and mapping;Image segmentation;Cameras;Real-time systems;Optimization;Symmetric matrices;SLAM;offline map;segment graph;normalized-cut},
doi={10.1109/ICSAI.2017.8248292},
ISSN={},
month={Nov},}
@INPROCEEDINGS{9421197,
author={Chen, Hongjian and Wang, Zhiqiang and Zhu, Qing},
booktitle={2021 IEEE Asia-Pacific Conference on Image Processing, Electronics and Computers (IPEC)}, title={Map Updating Revisited for Navigation Map : A mathematical way to perform map updating for autonomous mobile robot},
year={2021},
volume={},
number={},
pages={505-508},
abstract={Simultaneous localization and mapping, SLAM can product a Map for autonomous robots and self-driving vehicle in navigation. In the actual environment, the scene changes frequently, which makes the old map no long reliable. Therefore, it is necessary to update such a map by an efficient and safely way. In this paper, we review the existing map updating, long-term localization methods and discuss about the challenges in this situation. We present a Map updating method in mathematical way which can update accurately. Our proposed method are tested in five indoor dataset and demonstrated feasibility.},
keywords={Location awareness;Computers;Simultaneous localization and mapping;Navigation;Image processing;Conferences;Reliability;map;updating;visual;point cloud},
doi={10.1109/IPEC51340.2021.9421197},
ISSN={},
month={April},}
@INPROCEEDINGS{6907397,
author={Pomerleau, Francois and Krüsi, Philipp and Colas, Francis and Furgale, Paul and Siegwart, Roland},
booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)}, title={Long-term 3D map maintenance in dynamic environments},
year={2014},
volume={},
number={},
pages={3712-3719},
abstract={New applications of mobile robotics in dynamic urban areas require more than the single-session geometric maps that have dominated simultaneous localization and mapping (SLAM) research to date; maps must be updated as the environment changes and include a semantic layer (such as road network information) to aid motion planning in dynamic environments. We present an algorithm for long-term localization and mapping in real time using a three-dimensional (3D) laser scanner. The system infers the static or dynamic state of each 3D point in the environment based on repeated observations. The velocity of each dynamic point is estimated without requiring object models or explicit clustering of the points. At any time, the system is able to produce a most-likely representation of underlying static scene geometry. By storing the time history of velocities, we can infer the dominant motion patterns within the map. The result is an online mapping and localization system specifically designed to enable long-term autonomy within highly dynamic environments. We validate the approach using data collected around the campus of ETH Zurich over seven months and several kilometers of navigation. To the best of our knowledge, this is the first work to unify long-term map update with tracking of dynamic objects.},
keywords={Three-dimensional displays;Dynamics;Simultaneous localization and mapping;Heuristic algorithms;Laser modes;Long-term mapping;dynamic obstacles;ICP;kd-tree;registration;scan matching;robot;SLAM},
doi={10.1109/ICRA.2014.6907397},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{8870928,
author={Schaefer, Alexander and Büscher, Daniel and Vertens, Johan and Luft, Lukas and Burgard, Wolfram},
booktitle={2019 European Conference on Mobile Robots (ECMR)}, title={Long-Term Urban Vehicle Localization Using Pole Landmarks Extracted from 3-D Lidar Scans},
year={2019},
volume={},
number={},
pages={1-7},
abstract={Due to their ubiquity and long-term stability, pole-like objects are well suited to serve as landmarks for vehicle localization in urban environments. In this work, we present a complete mapping and long-term localization system based on pole landmarks extracted from 3-D lidar data. Our approach features a novel pole detector, a mapping module, and an online localization module, each of which are described in detail, and for which we provide an open-source implementation [1]. In extensive experiments, we demonstrate that our method improves on the state of the art with respect to long-term reliability and accuracy: First, we prove reliability by tasking the system with localizing a mobile robot over the course of 15 months in an urban area based on an initial map, confronting it with constantly varying routes, differing weather conditions, seasonal changes, and construction sites. Second, we show that the proposed approach clearly outperforms a recently published method in terms of accuracy.},
keywords={Laser radar;Detectors;Reliability;Feature extraction;Urban areas;Trajectory;Roads},
doi={10.1109/ECMR.2019.8870928},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{7759671,
author={Krajník, Tomáš and Pulido Fentanes, Jaime and Hanheide, Marc and Duckett, Tom},
booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Persistent localization and life-long mapping in changing environments using the Frequency Map Enhancement},
year={2016},
volume={},
number={},
pages={4558-4563},
abstract={We present a lifelong mapping and localisation system for long-term autonomous operation of mobile robots in changing environments. The core of the system is a spatio-temporal occupancy grid that explicitly represents the persistence and periodicity of the individual cells and can predict the probability of their occupancy in the future. During navigation, our robot builds temporally local maps and integrates then into the global spatio-temporal grid. Through re-observation of the same locations, the spatio-temporal grid learns the long-term environment dynamics and gains the ability to predict the future environment states. This predictive ability allows to generate time-specific 2d maps used by the robot's localisation and planning modules. By analysing data from a long-term deployment of the robot in a human-populated environment, we show that the proposed representation improves localisation accuracy and the efficiency of path planning. We also show how to integrate the method into the ROS navigation stack for use by other roboticists.},
keywords={Navigation;Two dimensional displays;Robot sensing systems;Planning;Predictive models;Robot kinematics;mobile robotics;long-term autonomy},
doi={10.1109/IROS.2016.7759671},
ISSN={2153-0866},
month={Oct},}
@ARTICLE{8963763,
author={Clement, Lee and Gridseth, Mona and Tomasi, Justin and Kelly, Jonathan},
journal={IEEE Robotics and Automation Letters}, title={Learning Matchable Image Transformations for Long-Term Metric Visual Localization},
year={2020},
volume={5},
number={2},
pages={1492-1499},
abstract={Long-term metric self-localization is an essential capability of autonomous mobile robots, but remains challenging for vision-based systems due to appearance changes caused by lighting, weather, or seasonal variations. While experience-based mapping has proven to be an effective technique for bridging the `appearance gap,' the number of experiences required for reliable metric localization over days or months can be very large, and methods for reducing the necessary number of experiences are needed for this approach to scale. Taking inspiration from color constancy theory, we learn a nonlinear RGB-to-grayscale mapping that explicitly maximizes the number of inlier feature matches for images captured under different lighting and weather conditions, and use it as a pre-processing step in a conventional single-experience localization pipeline to improve its robustness to appearance change. We train this mapping by approximating the target non-differentiable localization pipeline with a deep neural network, and find that incorporating a learned low-dimensional context feature can further improve cross-appearance feature matching. Using synthetic and real-world datasets, we demonstrate substantial improvements in localization performance across day-night cycles, enabling continuous metric localization over a 30-hour period using a single mapping experience, and allowing experience-based localization to scale to long deployments with dramatically reduced data requirements.},
keywords={Pipelines;Feature extraction;Visualization;Training;Measurement;Lighting;Robustness;Deep learning in robotics and automation;visual learning;visual-based navigation;localization},
doi={10.1109/LRA.2020.2967659},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{5940504,
author={Badino, H. and Huber, D. and Kanade, T.},
booktitle={2011 IEEE Intelligent Vehicles Symposium (IV)}, title={Visual topometric localization},
year={2011},
volume={},
number={},
pages={794-799},
abstract={One of the fundamental requirements of an autonomous vehicle is the ability to determine its location on a map. Frequently, solutions to this localization problem rely on GPS information or use expensive three dimensional (3D) sensors. In this paper, we describe a method for long-term vehicle localization based on visual features alone. Our approach utilizes a combination of topological and metric mapping, which we call topometric localization, to encode the coarse topology of the route as well as detailed metric information required for accurate localization. A topometric map is created by driving the route once and recording a database of visual features. The vehicle then localizes by matching features to this database at runtime. Since individual feature matches are unreliable, we employ a discrete Bayes filter to estimate the most likely vehicle position using evidence from a sequence of images along the route. We illustrate the approach using an 8.8 km route through an urban and suburban environment. The method achieves an average localization error of 2.7 m over this route, with isolated worst case errors on the order of 10 m.},
keywords={Vehicles;Visualization;Measurement;Databases;Feature extraction;Global Positioning System;Probability density function},
doi={10.1109/IVS.2011.5940504},
ISSN={1931-0587},
month={June},}
@INPROCEEDINGS{7152387,
author={Pastor-Moreno, Daniel and Shin, Hyo-Sang and Waldock, Antony},
booktitle={2015 International Conference on Unmanned Aircraft Systems (ICUAS)}, title={Optical flow localisation and appearance mapping (OFLAAM) for long-term navigation},
year={2015},
volume={},
number={},
pages={980-988},
abstract={This paper presents a novel method to use optical flow navigation for long term navigation. Unlike standard SLAM approaches for augmented reality, OFLAAM is designed for Micro Air Vehicles (MAV). It uses a optical flow camera pointing downwards, a IMU and a monocular camera pointing frontwards. That configuration avoids the computational expensive mapping and tracking of the 3D features. It only maps these features in a vocabulary list by a localization module to tackle the optical flow drift and the lose of the navigation estimation. That module, based on the well established algorithm DBoW2, will be also used to close the loop and allow long-term navigation in previously visited areas. The combination of high speed optical flow navigation with a low rate localization algorithm allows fully autonomous navigation for MAV, at the same time it reduces the overall computational load. This framework is implemented in ROS (Robot Operating System) and tested attached to a laptop. A representative scenario is used to validate and analyze the performance of the system.},
keywords={Cameras;Optical sensors;Optical imaging;Computers;Vehicles;Adaptive optics;High-speed optical techniques},
doi={10.1109/ICUAS.2015.7152387},
ISSN={},
month={June},}
@INPROCEEDINGS{8675637,
author={Wilbers, Daniel and Rumberg, Lars and Stachniss, Cyrill},
booktitle={2019 Third IEEE International Conference on Robotic Computing (IRC)}, title={Approximating Marginalization with Sparse Global Priors for Sliding Window SLAM-Graphs},
year={2019},
volume={},
number={},
pages={25-31},
abstract={Most autonomous vehicles rely on some kind of map for localization or navigation. Outdated maps however are a risk to the performance of any map-based localization system applied in autonomous vehicles. It is necessary to update the used maps to ensure stable and long-term operation. We address the problem of computing landmark updates live in the vehicle, which requires efficient use of the computational resources. In particular, we employ a graph-based sliding window approach for simultaneous localization and incremental map refinement. We propose a novel method that approximates sliding window marginalization without inducing fill-in. Our method maintains the exact same sparsity pattern as without performing marginalization, but simultaneously improves the landmark estimates. The main novelty of this work is the derivation of sparse global priors that approximate dense marginalization. In comparison to state-of-the-art work, our approach utilizes global instead of local linearization points, but still minimizes linearization errors. We first approximate marginalization via Kullback-Leibler divergence and then recalculate the mean to compensate linearization errors. We evaluate our approach on simulated and real data from a prototype vehicle and compare our approach to state-of-the-art sliding window marginalization.},
keywords={Microsoft Windows;Optimization;Autonomous vehicles;Jacobian matrices;Robots;Navigation;Trajectory;SLAM;Sensor Fusion;Incremental Mapping;Localization;Automated Driving},
doi={10.1109/IRC.2019.00013},
ISSN={},
month={Feb},}
@INPROCEEDINGS{8870347,
author={Banerjee, Nandan and Lisin, Dimitri and Briggs, Jimmy and Llofriu, Martin and Munich, Mario E.},
booktitle={2019 European Conference on Mobile Robots (ECMR)}, title={Lifelong Mapping using Adaptive Local Maps},
year={2019},
volume={},
number={},
pages={1-8},
abstract={Occupancy mapping enables a mobile robot to make intelligent planning decisions to accomplish its tasks. Adaptive local maps is an algorithm which represents the occupancy information as a set of overlapping local maps anchored to poses in the robot's trajectory. At any time, a global occupancy map can be rendered from the local maps to be used for path planning. The advantage of this approach is that the occupancy information stays consistent despite the changes in the pose estimates resulting from loop closures and localization updates. The disadvantage, however, is that the number of local maps grows over time. For long robot runs, or for multiple runs in the same space, this growth will result in redundant occupancy information, which will in turn increase the time it takes to render the global map, as well as the memory footprint of the system. In this paper, we propose a novel approach for the maintenance of an adaptive local maps system, which intelligently prunes redundant local maps, ensuring the robustness and stability required for lifelong mapping.},
keywords={Simultaneous localization and mapping;Uncertainty;Mobile robots;Trajectory},
doi={10.1109/ECMR.2019.8870347},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8814347,
author={Zhang, Mingming and Chen, Yiming and Li, Mingyang},
booktitle={2019 American Control Conference (ACC)}, title={SDF-Loc: Signed Distance Field based 2D Relocalization and Map Update in Dynamic Environments},
year={2019},
volume={},
number={},
pages={1997-2004},
abstract={To empower an autonomous robot to perform long-term navigation in a given area, a concurrent localization and map update algorithm is required. In this paper, we tackle this problem by providing both theoretical analysis and algorithm design for robotic systems equipped with 2D laser range finders. The first key contribution of this paper is that we propose a hybrid signed distance field (SDF) framework for laser based localization. The proposed hybrid SDF integrates two methods with complementary characteristics, namely Euclidean SDF (ESDF) and Truncated SDF (TSDF). With our framework, accurate pose estimation and fast map update can be performed simultaneously. Moreover, we introduce a novel sliding window estimator which attains better accuracy by consistently utilizing sensor and map information with both scan-to-scan and scan-to-map data association. Real-world experimental results demonstrate that the proposed algorithm can be used for commercial robots in various environments with long-term usage. Experiments also show that our approach outperforms competing approaches by a wide margin.},
keywords={Optimization;Robot sensing systems;Lasers;Measurement by laser beam;Two dimensional displays;Pose estimation},
doi={10.23919/ACC.2019.8814347},
ISSN={2378-5861},
month={July},}
@INPROCEEDINGS{7404433,
author={Bichucher, Vittorio and Walls, Jeffrey M. and Ozog, Paul and Skinner, Katherine A. and Eustice, Ryan M.},
booktitle={OCEANS 2015 - MTS/IEEE Washington}, title={Bathymetric factor graph SLAM with sparse point cloud alignment},
year={2015},
volume={},
number={},
pages={1-7},
abstract={This paper reports on a factor graph simultaneous localization and mapping framework for autonomous underwater vehicle localization based on terrain-aided navigation. The method requires no prior bathymetric map and only assumes that the autonomous underwater vehicle has the ability to sparsely sense the local water column depth, such as with a bottom-looking Doppler velocity log. Since dead-reckoned navigation is accurate in short time windows, the vehicle accumulates several water column depth point clouds- or submaps-during the course of its survey. We propose an xy-alignment procedure between these submaps in order to enforce consistent bathymetric structure over time, and therefore attempt to bound long-term navigation drift. We evaluate the submap alignment method in simulation and present performance results from multiple autonomous underwater vehicle field trials.},
keywords={Simultaneous localization and mapping;Three-dimensional displays;Vehicles;Trajectory;Smoothing methods;Global Positioning System},
doi={10.23919/OCEANS.2015.7404433},
ISSN={},
month={Oct},}
@ARTICLE{8633942,
author={Kim, Giseop and Park, Byungjae and Kim, Ayoung},
journal={IEEE Robotics and Automation Letters}, title={1-Day Learning, 1-Year Localization: Long-Term LiDAR Localization Using Scan Context Image},
year={2019},
volume={4},
number={2},
pages={1948-1955},
abstract={In this letter, we present a long-term localization method that effectively exploits the structural information of an environment via an image format. The proposed method presents a robust year-round localization performance even when learned in just a single day. The proposed localizer learns a point cloud descriptor, named Scan Context Image (SCI), and performs robot localization on a grid map by formulating the place recognition problem as place classification using a convolutional neural network. Our method is faster than existing methods proposed for place recognition because it avoids a pairwise comparison between a query and scans in a database. In addition, we provide thorough validations using publicly available long-term datasets, the NCLT dataset and the Oxford RobotCar dataset, and show that the Scan Context Image (SCI) localization attains consistent performance over a year and outperforms existing methods.},
keywords={Three-dimensional displays;Training;Laser radar;Entropy;Databases;Robot localization;Localization;range sensing;SLAM},
doi={10.1109/LRA.2019.2897340},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{8463150,
author={Stenborg, Erik and Toft, Carl and Hammarstrand, Lars},
booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)}, title={Long-Term Visual Localization Using Semantically Segmented Images},
year={2018},
volume={},
number={},
pages={6484-6490},
abstract={Robust cross-seasonal localization is one of the major challenges in long-term visual navigation of autonomous vehicles. In this paper, we exploit recent advances in semantic segmentation of images, i.e., where each pixel is assigned a label related to the type of object it represents, to attack the problem of long-term visual localization. We show that semantically labeled 3D point maps of the environment, together with semantically segmented images, can be efficiently used for vehicle localization without the need for detailed feature descriptors (SIFT, SURF, etc.), Thus, instead of depending on hand-crafted feature descriptors, we rely on the training of an image segmenter. The resulting map takes up much less storage space compared to a traditional descriptor based map. A particle filter based semantic localization solution is compared to one based on SIFT-features, and even with large seasonal variations over the year we perform on par with the larger and more descriptive SIFT-features, and are able to localize with an error below 1 m most of the time.},
keywords={Semantics;Cameras;Roads;Image segmentation;Visualization;Robustness;Feature extraction},
doi={10.1109/ICRA.2018.8463150},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9468884,
author={Wang, Lisai and Chen, Weidong and Wang, Jingchuan},
booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Long-Term Localization With Time Series Map Prediction for Mobile Robots in Dynamic Environments},
year={2020},
volume={},
number={},
pages={1-7},
abstract={In many applications of mobile robot, the environment is constantly changing. How to use historical information to analysis environmental changes and generate a map corresponding with current environment is important to achieve high-precision localization. Inspired by predictive mechanism of brain, this paper presents a long-term localization approach named ArmMPU (ARMA-based Map Prediction and Update) based on time series modeling and prediction. Autoregressive moving average model (ARMA), a kind of time series modeling method, is employed for environmental map modeling and prediction, then predicted map and filtered observation are fused to fix the prediction error. The simulation and experiment results show that the proposed method improves long-term localization performance in dynamic environments.},
keywords={Location awareness;Correlation;Time series analysis;Predictive models;Brain modeling;Information filters;Real-time systems},
doi={10.1109/IROS45743.2020.9468884},
ISSN={2153-0866},
month={Oct},}
@ARTICLE{9358457,
author={Hu, Hanjiang and Wang, Hesheng and Liu, Zhe and Chen, Weidong},
journal={IEEE/CAA Journal of Automatica Sinica}, title={Domain-Invariant Similarity Activation Map Contrastive Learning for Retrieval-Based Long-Term Visual Localization},
year={2022},
volume={9},
number={2},
pages={313-328},
abstract={Visual localization is a crucial component in the application of mobile robot and autonomous driving. Image retrieval is an efficient and effective technique in image-based localization methods. Due to the drastic variability of environmental conditions, e.g., illumination changes, retrieval-based visual localization is severely affected and becomes a challenging problem. In this work, a general architecture is first formulated probabilistically to extract domain-invariant features through multi-domain image translation. Then, a novel gradient-weighted similarity activation mapping loss (Grad-SAM) is incorporated for finer localization with high accuracy. We also propose a new adaptive triplet loss to boost the contrastive learning of the embedding in a self-supervised manner. The final coarse-to-fine image retrieval pipeline is implemented as the sequential combination of models with and without Grad-SAM loss. Extensive experiments have been conducted to validate the effectiveness of the proposed approach on the CMU-Seasons dataset. The strong generalization ability of our approach is verified with the RobotCar dataset using models pre-trained on urban parts of the CMU-Seasons dataset. Our performance is on par with or even outperforms the state-of-the-art image-based localization baselines in medium or high precision, especially under challenging environments with illumination variance, vegetation, and night-time images. Moreover, real-site experiments have been conducted to validate the efficiency and effectiveness of the coarse-to-fine strategy for localization.},
keywords={Location awareness;Visualization;Measurement;Feature extraction;Image recognition;Pipelines;Training;Deep representation learning;place recognition;visual localization},
doi={10.1109/JAS.2021.1003907},
ISSN={2329-9274},
month={February},}
@INPROCEEDINGS{8594456,
author={Rodrigues, Rômulo T. and Aguiar, A. Pedro and Pascoal, António},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={A B-Spline Mapping Framework for Long-Term Autonomous Operations},
year={2018},
volume={},
number={},
pages={3204-3209},
abstract={This paper presents a 2D B-spline mapping framework for representing unstructured environments in a compact manner. While occupancy-grid and landmark-based maps have been successfully employed by the robotics community in indoor scenarios, outdoor long-term autonomous operations require a more compact representation of the environment. This work tackles this problem by interpolating the data of a high frequency sensor using B-spline curves. Compared to lines and circles, splines are more powerful in the sense that they allow for the description of more complex shapes in the scene. In this work, spline curves are continuously tracked and aligned across multiple sensor readings using lightweight methods, making the proposed framework suitable for robot navigation in outdoor missions. In particular, a Simultaneous Localization and Mapping (SLAM) algorithm specifically tailored for B-spline maps is presented here. The efficacy of the proposed framework is demonstrated by Software-in-the-Loop (SiL) simulations in different scenarios.},
keywords={Splines (mathematics);Simultaneous localization and mapping;Three-dimensional displays;Robot kinematics;Two dimensional displays},
doi={10.1109/IROS.2018.8594456},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{8867531,
author={Jang, Junwoo and Kim, Jinwhan},
booktitle={OCEANS 2019 - Marseille}, title={Weighted Grid Partitioning for Panel-Based Bathymetric SLAM},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Bathymetric navigation enables the long-term operation of autonomous underwater vehicles by reducing navigation drift errors with no need for GPS position fixes. In the case that a bathymetric map is not available, the simultaneous localization and mapping (SLAM) algorithm is required, but this increases computational complexity and memory requirement. Panel-based bathymetric SLAM could considerably reduce the computational burden. However, it may suffers from incorrect update when the vehicle does not belong to the updated panel. This study proposes a new update method, called weighted grid partitioning, which considers the probability distribution of a vehicle's location, and is more effective in terms of the map accuracy, computational burden, and memory usage compared to standard update methods. The feasibility of the proposed algorithm is verified through simulations.},
keywords={Simultaneous localization and mapping;Navigation;Probability distribution;Signal processing algorithms;Measurement uncertainty;Uncertainty;Predictive models},
doi={10.1109/OCEANSE.2019.8867531},
ISSN={},
month={June},}
@ARTICLE{9548901,
author={Aitken, Jonathan M. and Evans, Mathew H. and Worley, Rob and Edwards, S. and Zhang, Rui and Dodd, Tony and Mihaylova, Lyudmila and Anderson, Sean R.},
journal={IEEE Access}, title={Simultaneous Localization and Mapping for Inspection Robots in Water and Sewer Pipe Networks: A Review},
year={2021},
volume={9},
number={},
pages={140173-140198},
abstract={At the present time, water and sewer pipe networks are predominantly inspected manually. In the near future, smart cities will perform intelligent autonomous monitoring of buried pipe networks, using teams of small robots. These robots, equipped with all necessary computational facilities and sensors (optical, acoustic, inertial, thermal, pressure and others) will be able to inspect pipes whilst navigating, self-localising and communicating information about the pipe condition and faults such as leaks or blockages to human operators for monitoring and decision support. The predominantly manual inspection of pipe networks will be replaced with teams of autonomous inspection robots that can operate for long periods of time over a large spatial scale. Reliable autonomous navigation and reporting of faults at this scale requires effective localization and mapping, which is the estimation of the robot’s position and its surrounding environment. This survey presents an overview of state-of-the-art works on robot simultaneous localization and mapping (SLAM) with a focus on water and sewer pipe networks. It considers various aspects of the SLAM problem in pipes, from the motivation, to the water industry requirements, modern SLAM methods, map-types and sensors suited to pipes. Future challenges such as robustness for long term robot operation in pipes are discussed, including how making use of prior knowledge, e.g. geographic information systems (GIS) can be used to build map estimates, and improve multi-robot SLAM in the pipe environment.},
keywords={Simultaneous localization and mapping;Robots;Sensors;Inspection;Service robots;Water resources;Location awareness;Water;sewer;network;pipe networks;robots;SLAM;data fusion;Bayesian estimation;visual odometry;laser and lidar scanning},
doi={10.1109/ACCESS.2021.3115981},
ISSN={2169-3536},
month={},}
@INPROCEEDINGS{7487237,
author={Rosen, David M. and Mason, Julian and Leonard, John J.},
booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)}, title={Towards lifelong feature-based mapping in semi-static environments},
year={2016},
volume={},
number={},
pages={1063-1070},
abstract={The feature-based graphical approach to robotic mapping provides a representationally rich and computationally efficient framework for an autonomous agent to learn a model of its environment. However, this formulation does not naturally support long-term autonomy because it lacks a notion of environmental change; in reality, “everything changes and nothing stands still, ” and any mapping and localization system that aims to support truly persistent autonomy must be similarly adaptive. To that end, in this paper we propose a novel feature-based model of environmental evolution over time. Our approach is based upon the development of an expressive probabilistic generative feature persistence model that describes the survival of abstract semi-static environmental features over time. We show that this model admits a recursive Bayesian estimator, the persistence filter, that provides an exact online method for computing, at each moment in time, an explicit Bayesian belief over the persistence of each feature in the environment. By incorporating this feature persistence estimation into current state-of-the-art graphical mapping techniques, we obtain a flexible, computationally efficient, and information-theoretically rigorous framework for lifelong environmental modeling in an ever-changing world.},
keywords={Feature extraction;Detectors;Computational modeling;Adaptation models;Simultaneous localization and mapping;Bayes methods},
doi={10.1109/ICRA.2016.7487237},
ISSN={},
month={May},}
@INPROCEEDINGS{6512139,
author={Anwar, Shahzad and Qingjie Zhao and Qadeer, Nouman and Khan, Saqib Ishaq},
booktitle={Proceedings of 2013 10th International Bhurban Conference on Applied Sciences Technology (IBCAST)}, title={A framework for RF-Visual SLAM},
year={2013},
volume={},
number={},
pages={103-108},
abstract={Simultaneous Localization and Mapping, SLAM, is an important topic in the field of robotics and autonomous navigation. The metric SLAM suffers from sensor inaccuracies and thus cannot be used for long-term navigation. In such case, Visual SLAM or a Hybrid SLAM based on both metric and visual approach is a good alternative. In this paper, in order to speed up a Visual SLAM, we propose a novel concept of dynamic dictionary generated on the results of triangulation done on RF, radio frequency, signals from nearest cell towers of a cellular network. This dynamic dictionary efficiently manages the scalability of a Visual SLAM and make it possible to work in a large-scale environment. A framework is proposed along with triangulation data of a city and with simulations to support the concept.},
keywords={Dictionaries;Simultaneous localization and mapping;Poles and towers;Navigation;Hybrid power systems},
doi={10.1109/IBCAST.2013.6512139},
ISSN={},
month={Jan},}
@INPROCEEDINGS{7784311,
author={Dubé, R. and Gawel, A. and Cadena, C. and Siegwart, R. and Freda, L. and Gianni, M.},
booktitle={2016 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)}, title={3D localization, mapping and path planning for search and rescue operations},
year={2016},
volume={},
number={},
pages={272-273},
abstract={This work presents our results on 3D robot localization, mapping and path planning for the latest joint exercise of the European project “Long-Term Human-Robot Teaming for Robots Assisted Disaster Response” (TRADR)1. The full system is operated and evaluated by firemen end-users in real-world search and rescue experiments. We demonstrate that the system is able to plan a path to a goal position desired by the fireman operator in the TRADR Operational Control Unit (OCU), using a persistent 3D map created by the robot during previous sorties.},
keywords={Three-dimensional displays;Path planning;Simultaneous localization and mapping;Navigation;Lasers},
doi={10.1109/SSRR.2016.7784311},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7989538,
author={McCormac, John and Handa, Ankur and Davison, Andrew and Leutenegger, Stefan},
booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, title={SemanticFusion: Dense 3D semantic mapping with convolutional neural networks},
year={2017},
volume={},
number={},
pages={4628-4635},
abstract={Ever more robust, accurate and detailed mapping using visual sensing has proven to be an enabling factor for mobile robots across a wide variety of applications. For the next level of robot intelligence and intuitive user interaction, maps need to extend beyond geometry and appearance - they need to contain semantics. We address this challenge by combining Convolutional Neural Networks (CNNs) and a state-of-the-art dense Simultaneous Localization and Mapping (SLAM) system, ElasticFusion, which provides long-term dense correspondences between frames of indoor RGB-D video even during loopy scanning trajectories. These correspondences allow the CNN's semantic predictions from multiple view points to be probabilistically fused into a map. This not only produces a useful semantic 3D map, but we also show on the NYUv2 dataset that fusing multiple predictions leads to an improvement even in the 2D semantic labelling over baseline single frame predictions. We also show that for a smaller reconstruction dataset with larger variation in prediction viewpoint, the improvement over single frame segmentation increases. Our system is efficient enough to allow real-time interactive use at frame-rates of ≈25Hz.},
keywords={Semantics;Simultaneous localization and mapping;Three-dimensional displays;Geometry;Two dimensional displays;Labeling;Cameras},
doi={10.1109/ICRA.2017.7989538},
ISSN={},
month={May},}
@INPROCEEDINGS{8968245,
author={Banerjee, Nandan and Connolly, Ryan C. and Lisin, Dimitri and Briggs, Jimmy and Munich, Mario E.},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={View management for lifelong visual maps},
year={2019},
volume={},
number={},
pages={7871-7878},
abstract={The time complexity of making observations and loop closures in a graph-based visual SLAM system is a function of the number of views stored [1], [2]. Clever algorithms, such as approximate nearest neighbor search, can make this function sub-linear. Despite this, over time the number of views can still grow to a point at which the speed and/or accuracy of the system becomes unacceptable, especially in computation- and memory-constrained SLAM systems. However, not all views are created equal. Some views are rarely observed, because they have been created in an unusual lighting condition, or from low quality images, or in a location whose appearance has changed. These views can be removed to improve the overall performance of a SLAM system. In this paper, we propose a method for pruning views in a visual SLAM system to maintain its speed and accuracy for long term use.},
keywords={},
doi={10.1109/IROS40897.2019.8968245},
ISSN={2153-0866},
month={Nov},}
@INPROCEEDINGS{8541483,
author={Zaffar, Mubariz and Ehsan, Shoaib and Stolkin, Rustam and Maier, Klaus McDonald},
booktitle={2018 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)}, title={Sensors, SLAM and Long-term Autonomy: A Review},
year={2018},
volume={},
number={},
pages={285-290},
abstract={Simultaneous Localization and Mapping, commonly known as SLAM, has been an active research area in the field of Robotics over the past three decades. For solving the SLAM problem, every robot is equipped with either a single sensor or a combination of similar/different sensors. This paper attempts to review, discuss, evaluate and compare these sensors. Keeping an eye on future, this paper also assesses the characteristics of these sensors against factors critical to the long-term autonomy challenge.},
keywords={Cameras;Simultaneous localization and mapping;Sensor phenomena and characterization;Laser radar;Acoustic sensors;SLAM;Long-term Autonomy;Sensors},
doi={10.1109/AHS.2018.8541483},
ISSN={2471-769X},
month={Aug},}
@INPROCEEDINGS{8594481,
author={Furuta, Yuki and Okada, Kei and Kakiuchi, Yohei and Inaba, Masayuki},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={An Everyday Robotic System that Maintains Local Rules Using Semantic Map Based on Long-Term Episodic Memory},
year={2018},
volume={},
number={},
pages={1-7},
abstract={To enable robots to work on real home environments, they have to not only consider common knowledge in the global society, but also be aware of existing rules there. Since such “local rules” are not describable beforehand, robot agents must acquire them through their lives after deployment. To achieve this, we developed a framework that a) lets robots record long-term episodic memories in their deployed environments, b) autonomously builds probabilistic object localization map as structurization of logged data and c) make adapted task plans based on the map. We equipped our framework on PR2 and Fetch robots operating and recording episodic memory for 41 days with semantic common knowledge of the environment. We also conducted demonstrations in which a PR2 robot tidied up a room, showing that the robot agent can successfully plan and execute local-rule-aware home assistive tasks by using our proposed framework.},
keywords={Task analysis;Probabilistic logic;Semantics;Planning;Robot sensing systems;Solid modeling;Service Robots;Learning and Adaptive Systems;Big Data in Robotics and Automation},
doi={10.1109/IROS.2018.8594481},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9615417,
author={Ostroumov, Ivan and Kuzmenko, Nataliia},
booktitle={2021 IEEE 6th International Conference on Actual Problems of Unmanned Aerial Vehicles Development (APUAVD)}, title={Vehicle Navigation by Visual Navigational Aids for Automatic Lunar Mission},
year={2021},
volume={},
number={},
pages={71-75},
abstract={Nowadays the question of Moon exploration is one of the key priorities. Many Lunar robotics missions are planned in near future by different space agencies around the world. Moon has considered to be the best place for a research station with long-term human presence for finding answers on fundamental questions about the universe. Automatic navigation of starship during a landing phase on Lunar surface is already solved with a help of inertial reference system aided visual algorithms. However, questions of automatic navigation of moving and flying vehicles on the Lunar surface are still open. Inertial navigation is limited by time, self-localization and mapping algorithms require multiple unique features of relief to guarantee required accuracy for successful automatic mission complication. In the current study, we propose the deployment of a network of visual navigational aids on the Lunar surface to support ground automatic missions. A weak atmosphere of the Moon makes effective visual beacons navigation system for long areas. A network of navigational aids includes primary and secondary ground stations which are blinking synchronously. Synchronization is supported by radio waves from the primary ground station. We consider the nature of crater relief to increase operational area of the system. The Time Difference of Arrival method is used to detect vehicle position by blinking network of visual navigational aids. In the numerical application, we consider different scenarios of network configuration to support automatic vehicle navigation inside of Tycho crater. Also, deployment of visual navigational aids network will increase the number of optical features which improve performance of already used positioning methods.},
keywords={Visualization;Time difference of arrival;Surface waves;Moon;Radio navigation;Unmanned aerial vehicles;Synchronization;visual navigational aids;landing and ground vehicles;automatic mission;Lunar mission;Time Difference of Arrival},
doi={10.1109/APUAVD53804.2021.9615417},
ISSN={},
month={Oct},}
@ARTICLE{7839213,
author={Han, Fei and Yang, Xue and Deng, Yiming and Rentschler, Mark and Yang, Dejun and Zhang, Hao},
journal={IEEE Robotics and Automation Letters}, title={SRAL: Shared Representative Appearance Learning for Long-Term Visual Place Recognition},
year={2017},
volume={2},
number={2},
pages={1172-1179},
abstract={Place recognition, or loop closure detection, is an essential component to address the problem of visual simultaneous localization and mapping (SLAM). Long-term navigation of robots in outdoor environments introduces new challenges to enable life-long SLAM, including the strong appearance change resulting from vegetation, weather, and illumination variations across various times of the day, different days, months, or even seasons. In this paper, we propose a new shared representative appearance learning (SRAL) approach to address long-term visual place recognition. Different from previous methods using a single feature modality or a concatenation of multiple features, our SRAL method autonomously learns representative features that are shared in all scene scenarios, and then fuses the features together to represent the long-term appearance of environments observed by a robot during life-long navigation. By formulating SRAL as a regularized optimization problem, we use structured sparsity-inducing norms to model interrelationships of feature modalities. In addition, an optimization algorithm is developed to efficiently solve the formulated optimization problem, which holds a theoretical convergence guarantee. Extensive empirical study was performed to evaluate the SRAL method using large-scale benchmark datasets, including St Lucia, CMU-VL, and Nordland datasets. Experimental results have shown that our SRAL method obtains superior performance for life-long place recognition using individual images, outperforms previous single image-based methods, and is capable of estimating the importance of feature modalities.},
keywords={Visualization;Image recognition;Feature extraction;Simultaneous localization and mapping;Optimization;Navigation;Loop closure detection;long-term place recognition;simultaneous localization and mapping (SLAM);visual learning},
doi={10.1109/LRA.2017.2662061},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{9274964,
author={Li, ZiYuan and Yu, HuaPeng and Shen, TongSheng and Li, ZhiHui},
booktitle={2020 3rd International Conference on Unmanned Systems (ICUS)}, title={Segmented Matching Method of Multi-Geophysics Field SLAM Data Based on LSTM},
year={2020},
volume={},
number={},
pages={147-151},
abstract={At present, simultaneous localization and mapping (SLAM) has become an important method for autonomous underwater vehicles (AUVs) to realize long-term navigation. However, using only bathymetric data in unknown environment has its own disadvantages, that are low precision and large computational load. To tackle with requirements of high-precision navigation under large-scale and long-term voyage condition, a SLAM method and corresponding matching algorithm for integrating multi-geophysical field data are proposed. By dividing the feature data and location data of geophysical field obtained into various submaps and sub-segments during AUV sailing, the dominant navigation data of each segment is identified using long short-term memory network. Validity of the proposed method is done by simulation experiments. During the simulation, the loop closure detection of each submap is used, and the matching counter is set to check the correct matching rate. Finally, the matching results with single geophysics field data under the same conditions are compared with multi-geophysics field data and analyzed. The experimental results have demonstrated the feasibility and correctness of the proposed method.},
keywords={Technological innovation;Underwater vehicles;Timing;Simultaneous localization and mapping;Navigation;SLAM;LSTM;navigation;multi-geophysics field data;matching},
doi={10.1109/ICUS50048.2020.9274964},
ISSN={},
month={Nov},}
@INPROCEEDINGS{8662397,
author={Li, Ziyun and Chen, Yu and Gong, Luyao and Liu, Lu and Sylvester, Dennis and Blaauw, David and Kim, Hun-Seok},
booktitle={2019 IEEE International Solid- State Circuits Conference - (ISSCC)}, title={An 879GOPS 243mW 80fps VGA Fully Visual CNN-SLAM Processor for Wide-Range Autonomous Exploration},
year={2019},
volume={},
number={},
pages={134-136},
abstract={Simultaneous localization and mapping (SLAM) estimates an agent's trajectory for all six degrees of freedom (6 DoF) and constructs a 3D map of an unknown surrounding. It is a fundamental kernel that enables head-mounted augmented/virtual reality devices and autonomous navigation of micro aerial vehicles. A noticeable recent trend in visual SLAM is to apply computationand memory-intensive convolutional neural networks (CNNs) that outperform traditional hand-designed feature-based methods [1]. For each video frame, CNN-extracted features are matched with stored keypoints to estimate the agent's 6-DoF pose by solving a perspective-n-points (PnP) non-linear optimization problem (Fig. 7.3.1, left). The agent's long-term trajectory over multiple frames is refined by a bundle adjustment process (BA, Fig. 7.3.1 right), which involves a large-scale (~120 variables) non-linear optimization. Visual SLAM requires massive computation (>250GOP/s) in the CNN-based feature extraction and matching, as well as datadependent dynamic memory access and control flow with high-precision operations, creating significant low-power design challenges. Software implementations are impractical, resulting in 0.2s runtime with a ~3GHz CPU+ GPU system with >100MB memory footprint and >100W power consumption. Prior ASICs have implemented either an incomplete SLAM system [2,3] that lacks estimation of ego-motion or employed a simplified (non-CNN) feature extraction and tracking [2,4,5] that limits SLAM quality and range. A recent ASIC [5] augments visual SLAM with an off-chip high-precision inertial measurement unit (IMU), simplifying the computational complexity, but incurring additional power and cost overhead.},
keywords={Simultaneous localization and mapping;Engines;Three-dimensional displays;Two dimensional displays;Feature extraction;Visualization;Trajectory},
doi={10.1109/ISSCC.2019.8662397},
ISSN={2376-8606},
month={Feb},}
@INPROCEEDINGS{9303291,
author={Yin, Huan and Wang, Yue and Tang, Li and Xiong, Rong},
booktitle={2020 IEEE International Conference on Real-time Computing and Robotics (RCAR)}, title={Radar-on-Lidar: metric radar localization on prior lidar maps},
year={2020},
volume={},
number={},
pages={1-7},
abstract={Radar and lidar, provided by two different range sensors, each has pros and cons of various perception tasks on mobile robots or autonomous driving. In this paper, a Monte Carlo system is used to localize the robot with a rotating radar sensor on 2D lidar maps. We first train a conditional generative adversarial network to transfer raw radar data to lidar data, and achieve reliable radar points from generator. Then an efficient radar odometry is included in the Monte Carlo system. Combining the initial guess from odometry, a measurement model is proposed to match the radar data and prior lidar maps for final 2D positioning. We demonstrate the effectiveness of the proposed localization framework on the public multisession dataset. The experimental results show that our system can achieve high accuracy for long-term localization in outdoor scenes.},
keywords={Laser radar;Radar;Sensors;Radar imaging;Robots;Three-dimensional displays;Two dimensional displays},
doi={10.1109/RCAR49640.2020.9303291},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{8593854,
author={Egger, Philipp and Borges, Paulo V K and Catt, Gavin and Pfrunder, Andreas and Siegwart, Roland and Dubé, Renaud},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization},
year={2018},
volume={},
number={},
pages={3430-3437},
abstract={Reliable long-term localization is key for robotic systems in dynamic environments. In this paper, we propose a novel approach for long-term localization using 3D LiDARs, coined PoseMap. In essence, we extract distinctive features from range measurements and bundle these into local views along with observation poses. The sensor's trajectory is then estimated in a sliding window fashion by matching current and old features and minimizing the distances in-between. The map representation facilitates finding a suitable set of old features, by selecting the closest local map(s) for matching. Similarly to a visibility analysis, this procedure provides a suitable set of features for localization but at a fraction of the computational cost. PoseMap also allows for updates and extensions of the map at any time by replacing and adding local maps when necessary. We evaluate our approach using two platforms both equipped with a 3D LiDAR and an IMU, demonstrating localization at 8 Hz and robustness to changes in the environment such as moving vehicles and changing vegetation. PoseMap was implemented on an autonomous vehicle allowing it to drive autonomously over a period of 18 months through a mix of industrial and unstructured off-road environments, covering more than 100 kms without a single localization failure.},
keywords={Simultaneous localization and mapping;Three-dimensional displays;Laser radar;Optimization;Feature extraction},
doi={10.1109/IROS.2018.8593854},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{7138985,
author={Linegar, Chris and Churchill, Winston and Newman, Paul},
booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, title={Work smart, not hard: Recalling relevant experiences for vast-scale but time-constrained localisation},
year={2015},
volume={},
number={},
pages={90-97},
abstract={This paper is about life-long vast-scale localisation in spite of changes in weather, lighting and scene structure. Building upon our previous work in Experience-based Navigation [1], we continually grow and curate a visual map of the world that explicitly supports multiple representations of the same place. We refer to these representations as experiences, where a single experience captures the appearance of an environment under certain conditions. Pedagogically, an experience can be thought of as a visual memory. By accumulating experiences we are able to handle cyclic appearance change (diurnal lighting, seasonal changes, and extreme weather conditions) and also adapt to slow structural change. This strategy, although elegant and effective, poses a new challenge: In a region with many stored representations - which one(s) should we try to localise against given finite computational resources? By learning from our previous use of the experience-map, we can make predictions about which memories we should consider next, conditioned on how the robot is currently localised in the experience-map. During localisation, we prioritise the loading of past experiences in order to minimise the expected computation required. We do this in a probabilistic way and show that this memory policy significantly improves localisation efficiency, enabling long-term autonomy on robots with limited computational resources. We demonstrate and evaluate our system over three challenging datasets, totalling 206km of outdoor travel. We demonstrate the system in a diverse range of lighting and weather conditions, scene clutter, camera occlusions, and permanent structural change in the environment.},
keywords={Robots;Visualization;Cameras;Trajectory;Meteorology;Lighting;Navigation},
doi={10.1109/ICRA.2015.7138985},
ISSN={1050-4729},
month={May},}
@INPROCEEDINGS{8594310,
author={Lázaro, María T. and Capobianco, Roberto and Grisetti, Giorgio},
booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Efficient Long-term Mapping in Dynamic Environments},
year={2018},
volume={},
number={},
pages={153-160},
abstract={As autonomous robots are increasingly being introduced in real-world environments operating for long periods of time, the difficulties of long-term mapping are attracting the attention of the robotics research community. This paper proposes a full SLAM system capable of handling the dynamics of the environment across a single or multiple mapping sessions. Using the pose graph SLAM paradigm, the system works on local maps in the form of 2D point cloud data which are updated over time to store the most up-to-date state of the environment. The core of our system is an efficient ICP-based alignment and merging procedure working on the clouds that copes with non-static entities of the environment. Furthermore, the system retains the graph complexity by removing out-dated nodes upon robust inter- and intra-session loop closure detections while graph coherency is preserved by using condensed measurements. Experiments conducted with real data from longterm SLAM datasets demonstrate the efficiency, accuracy and effectiveness of our system in the management of the mapping problem during long-term robot operation.},
keywords={Simultaneous localization and mapping;Cloud computing;Three-dimensional displays;Two dimensional displays;Merging;Optimization},
doi={10.1109/IROS.2018.8594310},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{884968,
author={Gross, H.-M. and Boehme, H.-J.},
booktitle={Smc 2000 conference proceedings. 2000 ieee international conference on systems, man and cybernetics. 'cybernetics evolving to systems, humans, organizations, and their complex interactions' (cat. no.0}, title={PERSES-a vision-based interactive mobile shopping assistant},
year={2000},
volume={1},
number={},
pages={80-85 vol.1},
abstract={The paper describes the general idea, the application scenario, and selected methodological approaches of our long term research project PERSES (PERsonal SErvice System). The aim of the project consists of the development of an interactive mobile shopping assistant that allows a continuous and intuitively understandable interaction with a customer in a home improvement store. Typical tasks we have to tackle are to detect and contact potential users in the operation area, to guide them to desired areas or articles within the store or to follow them as a mobile information kiosk while continuously observing their behavior. Due to the specificity of the interaction-oriented scenario and the characteristics of the operation area, we have focused on vision based methods for both human-robot interaction and robot navigation. Besides some methodological approaches, we present preliminary results of experiments achieved with our mobile robot PERSES in the store with an emphasis on vision based methods for user localization, map building and self-localization.},
keywords={Navigation;Robot vision systems;Mobile robots;Robustness;Robot kinematics;Human robot interaction;Adaptation model;Context modeling;Programmable control;Adaptive control},
doi={10.1109/ICSMC.2000.884968},
ISSN={1062-922X},
month={Oct},}
@INPROCEEDINGS{6907435,
author={Biswas, Joydeep and Veloso, Manuela},
booktitle={2014 IEEE International Conference on Robotics and Automation (ICRA)}, title={Episodic non-Markov localization: Reasoning about short-term and long-term features},
year={2014},
volume={},
number={},
pages={3969-3974},
abstract={Markov localization and its variants are widely used for localization of mobile robots. These methods assume Markov independence of observations, implying that observations made by a robot correspond to a static map. However, in real human environments, observations include occlusions due to unmapped objects like chairs and tables, and dynamic objects like humans. We introduce an episodic non-Markov localization algorithm that maintains estimates of the belief over the trajectory of the robot while explicitly reasoning about observations and their correlations arising from unmapped static objects, moving objects, as well as objects from the static map. Observations are classified as arising from long-term features, short-term features, or dynamic features, which correspond to mapped objects, unmapped static objects, and unmapped dynamic objects respectively. By detecting time steps along the robot's trajectory where unmapped observations prior to such time steps are unrelated to those afterwards, non-Markov localization limits the history of observations and pose estimates to “episodes” over which the belief is computed. We demonstrate non-Markov localization in challenging real world indoor and outdoor environments over multiple datasets, comparing it with alternative state-of-the-art approaches, showing it to be robust as well as accurate.},
keywords={Markov processes;Cost function;Correlation;Maximum likelihood estimation;Robot kinematics;History},
doi={10.1109/ICRA.2014.6907435},
ISSN={1050-4729},
month={May},}
@ARTICLE{8304792,
author={Fu, Changhong and Sarabakha, Andriy and Kayacan, Erdal and Wagner, Christian and John, Robert and Garibaldi, Jonathan M.},
journal={IEEE/ASME Transactions on Mechatronics}, title={Input Uncertainty Sensitivity Enhanced Nonsingleton Fuzzy Logic Controllers for Long-Term Navigation of Quadrotor UAVs},
year={2018},
volume={23},
number={2},
pages={725-734},
abstract={Input uncertainty, e.g., noise on the on-board camera and inertial measurement unit, in vision-based control of unmanned aerial vehicles (UAVs) is an inevitable problem. In order to handle input uncertainties as well as further analyze the interaction between the input and the antecedent fuzzy sets (FSs) of nonsingleton fuzzy logic controllers (NSFLCs), an input uncertainty sensitivity enhanced NSFLC has been developed in robot operating system using the C++ programming language. Based on recent advances in nonsingleton inference, the centroid of the intersection of the input and antecedent FSs (Cen-NSFLC) is utilized to calculate the firing strength of each rule instead of the maximum of the intersection used in traditional NSFLC (Tra-NSFLC). An 8-shaped trajectory, consisting of straight and curved lines, is used for the real-time validation of the proposed controllers for a trajectory following problem. An accurate monocular keyframe-based visual-inertial simultaneous localization and mapping (SLAM) approach is used to estimate the position of the quadrotor UAV in GPS-denied unknown environments. The performance of the Cen-NSFLC is compared with a conventional proportional-integral derivative (PID) controller, a singleton FLC and a Tra-NSFLC. All controllers are evaluated for different flight speeds, thus introducing different levels of uncertainty into the control problem. Visual-inertial SLAM-based real-time quadrotor UAV flight tests demonstrate that not only does the Cen-NSFLC achieve the best control performance among the four controllers, but it also shows better control performance when compared to their singleton counterparts. Considering the bias in the use of model-based controllers, e.g., PID, for the control of UAVs, this paper advocates an alternative method, namely Cen-NSFLCs, in uncertain working environments.},
keywords={Uncertainty;Simultaneous localization and mapping;Frequency selective surfaces;Real-time systems;IEEE transactions;Mechatronics;Fuzzy logic controller (FLC);input uncertainty sensitivity enhanced nonsingleton FLC (NSFLC);monocular visual-inertial simultaneous localization and mapping (SLAM);NSFLC;unmanned aerial vehicle (UAV)},
doi={10.1109/TMECH.2018.2810947},
ISSN={1941-014X},
month={April},}
@INPROCEEDINGS{7140012,
author={Dong, Jing and Nelson, Erik and Indelman, Vadim and Michael, Nathan and Dellaert, Frank},
booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)}, title={Distributed real-time cooperative localization and mapping using an uncertainty-aware expectation maximization approach},
year={2015},
volume={},
number={},
pages={5807-5814},
abstract={We demonstrate distributed, online, and real-time cooperative localization and mapping between multiple robots operating throughout an unknown environment using indirect measurements. We present a novel Expectation Maximization (EM) based approach to efficiently identify inlier multi-robot loop closures by incorporating robot pose uncertainty, which significantly improves the trajectory accuracy over long-term navigation. An EM and hypothesis based method is used to determine a common reference frame. We detail a 2D laser scan correspondence method to form robust correspondences between laser scans shared amongst robots. The implementation is experimentally validated using teams of aerial vehicles, and analyzed to determine its accuracy, computational efficiency, scalability to many robots, and robustness to varying environments. We demonstrate through multiple experiments that our method can efficiently build maps of large indoor and outdoor environments in a distributed, online, and real-time setting.},
keywords={Trajectory;Robot kinematics;Robot sensing systems;Lasers;Robustness;Uncertainty},
doi={10.1109/ICRA.2015.7140012},
ISSN={1050-4729},
month={May},}
@ARTICLE{9107480,
author={Zhang, Shengkai and Wang, Wei and Tang, Sheyang and Jin, Shi and Jiang, Tao},
journal={IEEE Transactions on Wireless Communications}, title={Robot-Assisted Backscatter Localization for IoT Applications},
year={2020},
volume={19},
number={9},
pages={5807-5818},
abstract={Recent years have witnessed the rapid proliferation of backscatter technologies that realize the ubiquitous and long-term connectivity to empower smart cities and smart homes. Localizing such backscatter tags is crucial for IoT-based smart applications. However, current backscatter localization systems require prior knowledge of the site, either a map or landmarks with known positions, which is laborious for deployment. To empower universal localization service, this paper presents Rover, an indoor localization system that localizes multiple backscatter tags without any start-up cost using a robot equipped with inertial sensors. Rover runs in a joint optimization framework, fusing measurements from backscattered WiFi signals and inertial sensors to simultaneously estimate the locations of both the robot and the connected tags. Our design addresses practical issues including interference among multiple tags, real-time processing, as well as the data marginalization problem in dealing with degenerated motions. We prototype Rover using off-the-shelf WiFi chips and customized backscatter tags. Our experiments show that Rover achieves localization accuracies of 39.3 cm for the robot and 74.6 cm for the tags.},
keywords={Wireless fidelity;Backscatter;Interference;Robot sensing systems;Receivers;Antenna arrays;Backscatter;localization;inertial sensor;channel state information},
doi={10.1109/TWC.2020.2997393},
ISSN={1558-2248},
month={Sep.},}
@INPROCEEDINGS{9649028,
author={Kozlov, Daniil and Myasnikov, Vladislav},
booktitle={2021 International Conference on Information Technology and Nanotechnology (ITNT)}, title={Development of an Autonomous Robotic System Using the Graph-based SPLAM Algorithm},
year={2021},
volume={},
number={},
pages={1-5},
abstract={For long-term planning, localization and mapping, the robot must constantly update the map by the changing environment and new areas that the robot is exploring. At the same time, this map should not take up too much of the robot’s memory, since the robot’s performance is limited due to the small size of the robot and increased performance requirements. The robot must interact with the map on time, updating its location to build a further route to explore areas that have not been visited. In addition to compiling a map, when solving the problem of exploration rooms, the following steps are also important: forming a plan for bypassing an unknown room, calculating the trajectory, resolving collisions with obstacles, and following the trajectory. In the course of this work, an autonomous robotic system was developed, the task of which is to map previously unknown premises. For this, SPLAM algorithms, algorithms for building map and working with graphs, algorithms for following a trajectory were used.},
keywords={Measurement;Space vehicles;Memory management;Robot vision systems;Production;Real-time systems;Trajectory;SPLAM;SLAM;robot;ROS;RTABMap;Voronoi diagram;bang-bang controller;Jetson;Zed;point cloud;odometry;Dijkstra algorithm},
doi={10.1109/ITNT52450.2021.9649028},
ISSN={},
month={Sep.},}
@INPROCEEDINGS{1574594,
author={Newman, P.},
booktitle={2005 The IEE Forum on Autonomous Systems (Ref. No. 2005/11271)}, title={Automating answers to "where am i?"},
year={2005},
volume={},
number={},
pages={7 pp.-},
abstract={In many situations, large-scale, long term deployment of an autonomous vehicle requires an ability to navigate in arbitrary workspaces and must be able to establish "where am I what surrounds me?". This paper describe simultaneous localisation and mapping (SLAM)techniques and implementations in which an autonomous vehicle explores its workspace using onboard sensors and inextricably binds together the tasks of mapping and localisation.},
keywords={},
doi={10.1049/ic:20050473},
ISSN={0537-9989},
month={Nov},}
@INPROCEEDINGS{7831835,
author={Zhang, Yu and Chao, Ainong and Zhao, Boxin and Liu, Huawei and Zhao, Xiaolin},
booktitle={2016 IEEE International Conference on Information and Automation (ICIA)}, title={Migratory birds-inspired navigation system for unmanned aerial vehicles},
year={2016},
volume={},
number={},
pages={276-281},
abstract={Migration birds are able to navigate themselves during a long-distance journey without getting lost. They actually achieve just what is being sought for in the field of Unmanned Aerial Vehicles (UAVs): long-term autonomous navigation. This paper proposes an approach that combines the migration birds' sense principles with Micro-Electro-Mechanical System (MEMS) sensors to estimate UAVs position within GPS-denied environments. Camera, orientation and web-based maps (such as Google/Baidu Maps) are chosen to simulate the birds' localization cues: vision, earth magnetic field and mental maps. The visual odometry, Particle Filter theories are used in the proposed approach to integrate multiple sensor measurements. Real flying experiments are conducted both in indoor and outdoor environments. The results validate that the proposed migration-inspired visual odometry system can estimate the UAV localization effectively.},
keywords={Cameras;Visualization;Unmanned aerial vehicles;Birds;Sensors;Navigation;Optical imaging;Migration birds;Unmanned Aerial Vehicles;Navigation},
doi={10.1109/ICInfA.2016.7831835},
ISSN={},
month={Aug},}
@INPROCEEDINGS{6943205,
author={Krajník, Tomáš and Fentanes, Jaime P. and Mozos, Oscar M. and Duckett, Tom and Ekekrantz, Johan and Hanheide, Marc},
booktitle={2014 IEEE/RSJ International Conference on Intelligent Robots and Systems}, title={Long-term topological localisation for service robots in dynamic environments using spectral maps},
year={2014},
volume={},
number={},
pages={4537-4542},
abstract={This paper presents a new approach for topological localisation of service robots in dynamic indoor environments. In contrast to typical localisation approaches that rely mainly on static parts of the environment, our approach makes explicit use of information about changes by learning and modelling the spatio-temporal dynamics of the environment where the robot is acting. The proposed spatio-temporal world model is able to predict environmental changes in time, allowing the robot to improve its localisation capabilities during long-term operations in populated environments. To investigate the proposed approach, we have enabled a mobile robot to autonomously patrol a populated environment over a period of one week while building the proposed model representation. We demonstrate that the experience learned during one week is applicable for topological localization even after a hiatus of three months by showing that the localization error rate is significantly lower compared to static environment representations.},
keywords={Mathematical model;Three-dimensional displays;Predictive models;Fourier transforms;Feature extraction;Service robots;topological localisation;mobile robotics;spatio-temporal representations},
doi={10.1109/IROS.2014.6943205},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{8814189,
author={Berrio, Julie Stephany and Ward, James and Worrall, Stewart and Nebot, Eduardo},
booktitle={2019 IEEE Intelligent Vehicles Symposium (IV)}, title={Updating the visibility of a feature-based map for long-term maintenance},
year={2019},
volume={},
number={},
pages={1173-1179},
abstract={Mobile vehicles operating in urban navigation applications can achieve high integrity localisation with high accuracy by using maps of the surroundings. To accomplish this, the map should always have an accurate representation of the environment. Thus, it is necessary to detect and remove the map components that no longer exist in the current environment. This maintains the map compactness and dependability while simplifying the data association problem. This paper addresses the problem of deletion of transient map components by taking advantage of the geometric connection between the map and agent poses in order to establish and update the visibility of each feature. Once the map is created an initial visibility vector is associated with every map element and updated over time. The visibility of a map element which no longer exists is reduced and ultimately removed from the map. We demonstrate our approach in a 2D feature-based map composed of poles and corners extracted from information provided by a Iidar sensor. The experimental results show the map update using a seven-month data set collected in the University of Sydney campus.},
keywords={},
doi={10.1109/IVS.2019.8814189},
ISSN={2642-7214},
month={June},}
@INPROCEEDINGS{8968017,
author={Song, Bowen and Chen, Weidong and Wang, Jingchuan and Wang, Hesheng},
booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Long-Term Visual Inertial SLAM based on Time Series Map Prediction},
year={2019},
volume={},
number={},
pages={5364-5369},
abstract={With the advance in the field of mobile robots, autonomous robots are required for long-term deployment in dynamic and complex environments. However, the performance of Visual Inertial SLAM systems in long-term operation is not satisfactory, and most long-term SLAM systems assumes periodic changes in the environment. This paper presents a novel solution for long-term monocular VI SLAM system in dynamic environment based on autoregression(AR) modeling and map prediction. Map points are first classified into static and semi-static map points according to a memory model. Modeling and prediction of the different states of semi-static map points are performed that are derived from time series models. The predicted map is then fused with the current map to achieve a better forecast for the next frame if the prediction is not satisfactory enough. Experiments are carried out on an embedded system. The results indicate that the map prediction is reliable and the proposed approach improves the performance of long-term localization and mapping in dynamic environments.},
keywords={},
doi={10.1109/IROS40897.2019.8968017},
ISSN={2153-0866},
month={Nov},}
@INPROCEEDINGS{5339626,
author={Hochdorfer, Siegfried and Lutz, Matthias and Schlegel, Christian},
booktitle={2009 IEEE International Conference on Technologies for Practical Robot Applications}, title={Lifelong localization of a mobile service-robot in everyday indoor environments using omnidirectional vision},
year={2009},
volume={},
number={},
pages={161-166},
abstract={SLAM (Simultaneous Localization and Mapping) mechanisms are a key component towards advanced service robotics applications. Currently, a major hurdle on the way to lifelong localization is the handling of the ever growing amount of landmarks over time. Therefore, the required resources in terms of memory and processing power are also growing over time.},
keywords={Indoor environments;Simultaneous localization and mapping;Upper bound;Clustering algorithms;Uncertainty;Robot vision systems;Robot localization;Observability;Global Positioning System;Mobile computing},
doi={10.1109/TEPRA.2009.5339626},
ISSN={2325-0534},
month={Nov},}
@INPROCEEDINGS{9010305,
author={Zhu, Yilong and Xue, Bohuan and Zheng, Linwei and Huang, Huaiyang and Liu, Ming and Fan, Rui},
booktitle={2019 IEEE International Conference on Imaging Systems and Techniques (IST)}, title={Real-Time, Environmentally-Robust 3D LiDAR Localization},
year={2019},
volume={},
number={},
pages={1-6},
abstract={Localization, or position fixing, is an important problem in robotics research. In this paper, we propose a novel approach for long-term localization in a changing environment using 3D LiDAR. We first create the map of a real environment using GPS and LiDAR. Then, we divide the map into several small parts as the targets for cloud registration, which can not only improve the robustness but also reduce the registration time. We proposed a localization method called PointLocalization. PointLocalization allows us to fuse different kinds of odometers, which can optimize the accuracy and frequency of localization results. We evaluate our algorithm on an unmanned ground vehicle (UGV) using LiDAR and a wheel encoder, and obtain the localization results at more than 20 Hz after fusion. The algorithm can also localize the UGV in a 180-degree field of view (FOV). Using an outdated map captured six months ago, this algorithm shows great robustness, and the test results show that it can achieve an accuracy of 10 cm. PointLocalization has been tested for a period of more than six months in a crowded factory and has operated successfully over a distance of more than 2000 km.},
keywords={Laser radar;Global Positioning System;Simultaneous localization and mapping;Wheels;Cameras;Three-dimensional displays},
doi={10.1109/IST48021.2019.9010305},
ISSN={1558-2809},
month={Dec},}
@INPROCEEDINGS{6385561,
author={Walcott-Bryant, Aisha and Kaess, Michael and Johannsson, Hordur and Leonard, John J.},
booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems}, title={Dynamic pose graph SLAM: Long-term mapping in low dynamic environments},
year={2012},
volume={},
number={},
pages={1871-1878},
abstract={Maintaining a map of an environment that changes over time is a critical challenge in the development of persistently autonomous mobile robots. Many previous approaches to mapping assume a static world. In this work we incorporate the time dimension into the mapping process to enable a robot to maintain an accurate map while operating in dynamical environments. This paper presents Dynamic Pose Graph SLAM (DPG-SLAM), an algorithm designed to enable a robot to remain localized in an environment that changes substantially over time. Using incremental smoothing and mapping (iSAM) as the underlying SLAM state estimation engine, the Dynamic Pose Graph evolves over time as the robot explores new places and revisits previously mapped areas. The approach has been implemented for planar indoor environments, using laser scan matching to derive constraints for SLAM state estimation. Laser scans for the same portion of the environment at different times are compared to perform change detection; when sufficient change has occurred in a location, the dynamic pose graph is edited to remove old poses and scans that no longer match the current state of the world. Experimental results are shown for two real-world dynamic indoor laser data sets, demonstrating the ability to maintain an up-to-date map despite long-term environmental changes.},
keywords={Simultaneous localization and mapping;Measurement by laser beam;Mobile robots;Heuristic algorithms;Lasers},
doi={10.1109/IROS.2012.6385561},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9263722,
author={Péter, Gábor and Kiss, Bálint},
booktitle={2020 23rd International Symposium on Measurement and Control in Robotics (ISMCR)}, title={Lightweight SLAM with automatic orientation correction using 2D LiDAR scans},
year={2020},
volume={},
number={},
pages={1-6},
abstract={Simultaneous localization and mapping (SLAM) is about consistent maps in the long run. Loop closing is the most popular way for ensure long-term consistency in presence of multiple measurements by the same or multiple robots. Loop closure can be executed using raw odometrical data, but a more sophisticated, yet still light-weight method is presented in this paper: a landmark descriptor-based relative displacement calculation method for diminishing unwanted orientation errors that otherwise often lead to map inconsistency. Landmark descriptors are created using light detection and ranging (LiDAR) scans and the relation is calculated using scan-matching. The novelty of this research is a method providing long-term orientation and position correction without additional overhead between landmark detections, thus enabling simple agents to do the SLAM in a cooperative way.},
keywords={Manganese;SLAM;LiDAR;mapping;orientation;correction;uncertainty},
doi={10.1109/ISMCR51255.2020.9263722},
ISSN={},
month={Oct},}
@INPROCEEDINGS{7759673,
author={Dymczyk, Marcin and Schneider, Thomas and Gilitschenski, Igor and Siegwart, Roland and Stumm, Elena},
booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Erasing bad memories: Agent-side summarization for long-term mapping},
year={2016},
volume={},
number={},
pages={4572-4579},
abstract={Precisely estimating the pose of an agent in a global reference frame is a crucial goal that unlocks a multitude of robotic applications, including autonomous navigation and collaboration. In order to achieve this, current state-of-the-art localization approaches collect data provided by one or more agents and create a single, consistent localization map, maintained over time. However, with the introduction of lengthier sorties and the growing size of the environments, data transfers between the backend server where the global map is stored and the agents are becoming prohibitively large. While some existing methods partially address this issue by building compact summary maps, the data transfer from the agents to the backend can still easily become unmanageable. In this paper, we propose a method that is designed to reduce the amount of data that needs to be transferred from the agent to the backend, functioning in large-scale, multi-session mapping scenarios. Our approach is based upon a landmark selection method that exploits information coming from multiple, possibly weak and correlated, landmark utility predictors; fused using learned feature coefficients. Such a selection yields a drastic reduction in data transfer while maintaining localization performance and the ability to efficiently summarize environments over time. We evaluate our approach on a data set that was autonomously collected in a dynamic indoor environment over a period of several months.},
keywords={Robots;Measurement;Bandwidth;Lighting;Data transfer;Servers;Reliability},
doi={10.1109/IROS.2016.7759673},
ISSN={2153-0866},
month={Oct},}
@ARTICLE{8316929,
author={Cao, Fengkui and Zhuang, Yan and Zhang, Hong and Wang, Wei},
journal={IEEE Sensors Journal}, title={Robust Place Recognition and Loop Closing in Laser-Based SLAM for UGVs in Urban Environments},
year={2018},
volume={18},
number={10},
pages={4242-4252},
abstract={Robust place recognition plays a key role for the long-term autonomy of unmanned ground vehicles (UGVs) working in indoor or outdoor environments. Although most of the state-of-the-art that approaches for place recognition are vision-based, visual sensors lack adaptability in environments with poor or dynamically changing illumination. In this paper, a 3-D-laser-based place recognition algorithm is proposed to accomplish loop closure detection for simultaneous localization and mapping. An image model named bearing angle (BA) is adopted to convert 3-D laser points to 2-D images, and then ORB features extracted from BA images are utilized to perform scene matching. Since the computational cost for matching a query BA image with all the BA images in a database is too high to meet the requirement of performing real-time place recognition, a visual bag of words approach is used to improve search efficiency. Furthermore, a speed normalization algorithm and a 3-D geometry-based verification algorithm are proposed to complete the proposed place recognition algorithm. Experiments were conducted on two self-developed UGV platforms to verify the performance of the proposed method.},
keywords={Three-dimensional displays;Lasers;Visualization;Feature extraction;Sensors;Robustness;Lighting;Laser scanning;place recognition;simultaneous localization and mapping (SLAM);unmanned ground vehicles (UGVs)},
doi={10.1109/JSEN.2018.2815956},
ISSN={1558-1748},
month={May},}
@ARTICLE{9033993,
author={Tang, Dengqing and Fang, Qiang and Shen, Lincheng and Hu, Tianjiang},
journal={IEEE/ASME Transactions on Mechatronics}, title={Onboard Detection-Tracking-Localization},
year={2020},
volume={25},
number={3},
pages={1555-1565},
abstract={This article investigates long-term positioning of moving objects by monocular vision of a miniature fixed-wing unmanned aerial vehicle. It is challenging to perform a real-time onboard vision processing task, due to the strict payload capacity and power budget limitations of microflying vehicles. We propose a parallel onboard architecture that explicitly decouples the long-term positioning task into iteratively operated detection, tracking, and localization. The proposed approach is eventually called onboard detection-tracking-localization, namely oDTL. The detector automatically extracts and identifies the object from image frames captured at in-flight durations. A learning-based network is constructed to improve detection accuracy and robustness against ever-changing outdoor illumination conditions and flying viewpoints. The tracker follows the object within specified region-of-interest from frame to frame with lower computing consumption. To further reduce target-losing rate, a concept of blind zone is proposed and applied, and its boundaries in sequential images are also theoretically inferred. The position estimator maps the flying vehicle pose, the image coordinates, and calibration specifications into real-world positions of the moving target. An extended Kalman filter is developed for rough position estimation, and a smooth module is introduced for the refinement of the position. Three offline comparative experiments and three online experiments have been conducted respectively to testify the real-time capability of our approach. The collected experimental results also demonstrate the feasible accuracy and robustness of the overall solution within the specified flying onboard scenarios.},
keywords={Robustness;Real-time systems;Visualization;Lighting;Cameras;Three-dimensional displays;IEEE transactions;Detection;localization;miniature fixed-wing unmanned aerial vehicle (UAV);monocular;onboard vision;parallel architecture;positioning;tracking},
doi={10.1109/TMECH.2020.2976794},
ISSN={1941-014X},
month={June},}
@ARTICLE{9500238,
author={Ali, Waqas and Liu, Peilin and Ying, Rendong and Gong, Zheng},
journal={IEEE Sensors Journal}, title={A Life-Long SLAM Approach Using Adaptable Local Maps Based on Rasterized LIDAR Images},
year={2021},
volume={21},
number={19},
pages={21740-21749},
abstract={Most real-time autonomous robot applications require a robot to traverse through a dynamic space for a long time. In some cases, a robot needs to work in the same environment. Such applications give rise to the problem of a life-long SLAM system. Life-long SLAM presents two main challenges i.e. the tracking should not fail in a dynamic environment and the need for a robust and efficient mapping strategy. The system should update maps with new information; while also keeping track of older observations. But, mapping for a long time can require higher computational requirements. In this paper, we propose a solution to the problem of life-long SLAM. We represent the global map as a set of rasterized images of local maps along with a map management system responsible for updating local maps and keeping track of older values. We also present an efficient approach of using the bag of visual words method for loop closure detection and relocalization. We evaluate the performance of our system on the KITTI dataset and an indoor dataset. Our loop closure system reported recall and precision of above 90 percent. The computational cost of our system is much lower as compared to state-of-the-art methods. Our method reports lower computational requirements even for long-term operation.},
keywords={Simultaneous localization and mapping;Three-dimensional displays;Feature extraction;Robots;Databases;Laser radar;Sensors;Laser scanning;place recognition;bag of words;rasterization;mapping;simultaneous localization;mapping},
doi={10.1109/JSEN.2021.3100882},
ISSN={1558-1748},
month={Oct},}
@INPROCEEDINGS{9150733,
author={Ott, Felix and Feigl, Tobias and Löffler, Christoffer and Mutschler, Christopher},
booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, title={ViPR: Visual-Odometry-aided Pose Regression for 6DoF Camera Localization},
year={2020},
volume={},
number={},
pages={187-198},
abstract={Visual Odometry (VO) accumulates a positional drift in long-term robot navigation tasks. Although Convolutional Neural Networks (CNNs) improve VO in various aspects, VO still suffers from moving obstacles, discontinuous observation of features, and poor textures or visual information. While recent approaches estimate a 6DoF pose either directly from (a series of) images or by merging depth maps with optical flow (OF), research that combines absolute pose regression with OF is limited.We propose ViPR, a novel modular architecture for longterm 6DoF VO that leverages temporal information and synergies between absolute pose estimates (from PoseNet-like modules) and relative pose estimates (from FlowNet-based modules) by combining both through recurrent layers. Experiments on known datasets and on our own Industry dataset show that our modular design outperforms state ofthe art in long-term navigation tasks.},
keywords={Cameras;Task analysis;Pose estimation;Feature extraction;Navigation;Optical imaging;Sensors},
doi={10.1109/CVPRW50498.2020.00029},
ISSN={2160-7516},
month={June},}
@INPROCEEDINGS{9196906,
author={Gao, Peng and Zhang, Hao},
booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)}, title={Long-term Place Recognition through Worst-case Graph Matching to Integrate Landmark Appearances and Spatial Relationships},
year={2020},
volume={},
number={},
pages={1070-1076},
abstract={Place recognition is an important component for simultaneously localization and mapping in a variety of robotics applications. Recently, several approaches using landmark information to represent a place showed promising performance to address long-term environment changes. However, previous approaches do not explicitly consider changes of the landmarks, i,e., old landmarks may disappear and new ones often appear over time. In addition, representations used in these approaches to represent landmarks are limited, based upon visual or spatial cues only. In this paper, we introduce a novel worst-case graph matching approach that integrates spatial relationships of landmarks with their appearances for long-term place recognition. Our method designs a graph representation to encode distance and angular spatial relationships as well as visual appearances of landmarks in order to represent a place. Then, we formulate place recognition as a graph matching problem under the worst-case scenario. Our approach matches places by computing the similarities of distance and angular spatial relationships of the landmarks that have the least similar appearances (i.e., worst-case). If the worst appearance similarity of landmarks is small, two places are identified to be not the same, even though their graph representations have high spatial relationship similarities. We evaluate our approach over two public benchmark datasets for long-term place recognition, including St. Lucia and CMU-VL. The experimental results have validated that our approach obtains the state-of-the-art place recognition performance, with a changing number of landmarks.},
keywords={Visualization;Simultaneous localization and mapping;Robustness;Strain;Image recognition;Tensile stress},
doi={10.1109/ICRA40945.2020.9196906},
ISSN={2577-087X},
month={May},}
@INPROCEEDINGS{9636530,
author={Kurz, Gerhard and Holoch, Matthias and Biber, Peter},
booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Geometry-based Graph Pruning for Lifelong SLAM},
year={2021},
volume={},
number={},
pages={3313-3320},
abstract={Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case).},
keywords={Simultaneous localization and mapping;Three-dimensional displays;Costs;Density functional theory;Trajectory;Standards;Intelligent robots},
doi={10.1109/IROS51168.2021.9636530},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{7759609,
author={Bürki, Mathias and Gilitschenski, Igor and Stumm, Elena and Siegwart, Roland and Nieto, Juan},
booktitle={2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Appearance-based landmark selection for efficient long-term visual localization},
year={2016},
volume={},
number={},
pages={4137-4143},
abstract={In this paper, we present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments. Sharing a common map for online localization provides a fleet of autonomous vehicles with the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offers the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks are to be observable under the prevailing appearance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. Evaluation is performed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme transition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.},
keywords={Vehicles;Visualization;Servers;Bandwidth;Robots;Redundancy;Mobile computing},
doi={10.1109/IROS.2016.7759609},
ISSN={2153-0866},
month={Oct},}
@INPROCEEDINGS{9413161,
author={Tsamis, Georgios and Kostavelis, Ioannis and Giakoumis, Dimitrios and Tzovaras, Dimitrios},
booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, title={Towards life-long mapping of dynamic environments using temporal persistence modeling},
year={2021},
volume={},
number={},
pages={10480-10485},
abstract={The contemporary SLAM mapping systems assume a static environment and build a map that is then used for mobile robot navigation disregarding the dynamic changes in this environment. The paper at hand presents a novel solution for the problem of life-long mapping that continually updates a metric map represented as a 2D occupancy grid in large scale indoor environments with movable objects such as people, robots, objects etc. suitable for industrial applications. We formalize each cell's occupancy as a failure analysis problem and contribute temporal persistence modeling (TPM), an algorithm for probabilistic prediction of the time that a cell in an observed location is expected to be “occupied” or “empty” given sparse prior observations from a task specific mobile robot. Our work is evaluated in Gazebo simulation environment against the nominal occupancy of cells and the estimated obstacles persistence. We also show that robot navigation with life-long mapping demands less replans and leads to more efficient navigation in highly dynamic environments.},
keywords={Measurement;Simultaneous localization and mapping;Navigation;Service robots;Predictive models;Probabilistic logic;Prediction algorithms},
doi={10.1109/ICPR48806.2021.9413161},
ISSN={1051-4651},
month={Jan},}
@INPROCEEDINGS{744447,
author={Feder, H.J.S. and Leonard, J.J. and Smith, C.M.},
booktitle={Proceedings of the 1998 Workshop on Autonomous Underwater Vehicles (Cat. No.98CH36290)}, title={Incorporating environmental measurements in navigation},
year={1998},
volume={},
number={},
pages={115-122},
abstract={Extended missions in unknown regions present a significant navigational challenge for autonomous underwater vehicles (AUV). This paper investigates the long-term performance of a concurrent mapping and localization (CML) algorithm for the scenario of an AUV making observations of point features in the environment with a forward look sonar. Simulation results demonstrate that position estimates with long-term bounded errors of a few meters can be achieved under realistic assumptions about the vehicle, its sensors, and the environment. Potential failure modes of the algorithm, such as divergence and map slip, are discussed. CML technology can provide a significant improvement in the navigational capabilities of AUVs and can enable new missions in unmapped regions without reliance on acoustic beacons or surfacing for GPS resets.},
keywords={Sonar navigation;Remotely operated vehicles;Underwater acoustics;Performance analysis;Stochastic processes;Sea measurements;Jacobian matrices;Oceans;Automotive engineering;Marine technology},
doi={10.1109/AUV.1998.744447},
ISSN={},
month={Aug},}
@INPROCEEDINGS{8843095,
author={Pitschl, Meredith L. and Pryor, Mitchell W.},
booktitle={2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)}, title={Obstacle Persistent Adaptive Map Maintenance for Autonomous Mobile Robots using Spatio-temporal Reasoning},
year={2019},
volume={},
number={},
pages={1023-1028},
abstract={Mobile robotic systems operate in increasingly realistic scenarios even as users have increased expectations for the duration of autonomous tasks. Mobile robots face unique challenges when operating in environments that change over time, where systems must maintain an accurate representation of the environment with respect to both spatial and temporal dimensions. This paper describes a spatio-temporal technique for extending the autonomy of a mobile robot in a changing environment. This new technique called Obstacle Persistent Adaptive Map Maintenance (OPAMM) uses navigation data collected during normal operations to perform periodic self-maintenance of its environment model. OPAMM implements a probabilistic feature persistence model to predict the survival state of obstacles and update the world model. Maintaining an accurate world model is necessary for extending the long-term autonomy of robots in realistic scenarios. Results show that robots using OPAMM had localizations scores higher than other methods, thus reducing long-term localization degradation.},
keywords={Conferences;Automation;Computer aided software engineering},
doi={10.1109/COASE.2019.8843095},
ISSN={2161-8089},
month={Aug},}
@INPROCEEDINGS{7989749,
author={Fourie, Dehann and Claassens, Samuel and Pillai, Sudeep and Mata, Roxana and Leonard, John},
booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, title={SLAMinDB: Centralized graph databases for mobile robotics},
year={2017},
volume={},
number={},
pages={6331-6337},
abstract={Robotic systems typically require memory recall mechanisms for a variety of tasks including localization, mapping, planning, visualization etc. We argue for a novel memory recall framework that enables more complex inference schemas by separating the computation from its associated data. In this work we propose a shared, centralized data persistence layer that maintains an ensemble of online, situationally-aware robot states. This is realized through a queryable graph-database with an accompanying key-value store for larger data. In turn, this approach is scalable and enables a multitude of capabilities such as experience-based learning and long-term autonomy. Using multi-modal simultaneous localization and mapping and a few example use-cases, we demonstrate the versatility and extensible nature that centralized persistence and SLAMinDB can provide. In order to support the notion of life-long autonomy, we envision robots to be endowed with such a persistence model, enabling them to revisit previous experiences and improve upon their existing task-specific capabilities.},
keywords={Simultaneous localization and mapping;Computer architecture;Relational databases;Navigation},
doi={10.1109/ICRA.2017.7989749},
ISSN={},
month={May},}
@INPROCEEDINGS{9636814,
author={Bujanca, Mihai and Shi, Xuesong and Spear, Matthew and Zhao, Pengpeng and Lennox, Barry and Luján, Mikel},
booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Robust SLAM Systems: Are We There Yet?},
year={2021},
volume={},
number={},
pages={5320-5327},
abstract={Progress in the last decade has brought about significant improvements in the accuracy and speed of SLAM systems, broadening their mapping capabilities. Despite these advancements, long-term operation remains a major challenge, primarily due to the wide spectrum of perturbations robotic systems may encounter.Increasing the robustness of SLAM algorithms is an ongoing effort, however it usually addresses a specific perturbation. Generalisation of robustness across a large variety of challenging scenarios is not well-studied nor understood. This paper presents a systematic evaluation of the robustness of open-source state-of-the-art SLAM algorithms with respect to challenging conditions such as fast motion, non-uniform illumination, and dynamic scenes. The experiments are performed with perturbations present both independently of each other, as well as in combination in long-term deployment settings in unconstrained environments (lifelong operation).The detailed results (approx. 20,000 experiments) along with comprehensive documentation of the benchmarking tool for integrating new datasets and evaluating SLAM algorithms not studied in this work are available at https://robustslam.github.io/evaluation.},
keywords={Simultaneous localization and mapping;Systematics;Three-dimensional displays;Heuristic algorithms;Perturbation methods;Dynamics;Lighting},
doi={10.1109/IROS51168.2021.9636814},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{8833730,
author={Chen, Shilang and Wu, Junjun and Wang, Yanran and Zhou, Lin and Lu, Qinghua and Zhang, Yunzhi},
booktitle={2019 IEEE 4th International Conference on Advanced Robotics and Mechatronics (ICARM)}, title={Robust Loop-Closure Detection with a Learned Illumination Invariant Representation for Robot vSLAM},
year={2019},
volume={},
number={},
pages={342-347},
abstract={Robust loop-closure detection plays a key role for the long-term robot visual Simultaneous Localization and Mapping (SLAM) in indoor or outdoor environment, due to illumination changes can greatly affect the accuracy of online image matching, and keypoints may fail to match between images taken at the same location but different seasons. In this paper, we propose a robust loop-closure detection method for robot visual SLAM, which adopts invariant representation as image descriptors composed of learned features and adapts to changes in illumination and seasons. We evaluate our method on real datasets and demonstrate its excellent ability to handle illumination changes.},
keywords={Visualization;Simultaneous localization and mapping;Lighting;Feature extraction;Mechatronics;Image matching;Visual SLAM;Loop Closure Detection;Visual Place Recognition;Illumination Invariant Feature;Moblie Robot;Convolutional Neural Network},
doi={10.1109/ICARM.2019.8833730},
ISSN={},
month={July},}
@INPROCEEDINGS{6088615,
author={Devaux, Jean-Clément and Nadrag, Paul and Colle, Etienne and Hoppenot, Philippe},
booktitle={2011 15th International Conference on Advanced Robotics (ICAR)}, title={High level assisted control mode based on SLAM for a remotely controlled robot},
year={2011},
volume={},
number={},
pages={186-191},
abstract={One aim of ambient assistive technologies is to reduce long term hospitalization for elderly people, especially with pathologies such as Mild Cognitive Impairment (MCI). The smart environment assists these people and their families with safety and cognitive stimulation, so they stay as long as possible at home. The originality comes from using the robot in the elderly person's home. This robot is remote controlled by a distant user, a therapist or a relative, for determining alarming situations or for participating in stimulation exercises. Several modes are available for controlling the robot. This paper deals with an assisted control mode in which the remote user gives to the robot one goal and the robot reaches the goal by itself. During the robot movement, the user can dynamically change the current goal. An important hypothesis is that the robot has no a priori knowledge of its environment at the beginning. The knowledge will increase with time and the planned trajectory will be refreshed at two levels: a local one - faster but not always sufficient - and a global one - slower but which always finds a path if one exists. The idea is to work only with local information, using the robot sensors, the operator keeping the high level control. To assure that control, the remote operator uses video feedback and information from a laser range scanner.},
keywords={Trajectory;Planning;Simultaneous localization and mapping;Navigation},
doi={10.1109/ICAR.2011.6088615},
ISSN={},
month={June},}
@ARTICLE{8950110,
author={Giubilato, Riccardo and Vayugundla, Mallikarjuna and Schuster, Martin J. and Stürzl, Wolfgang and Wedler, Armin and Triebel, Rudolph and Debei, Stefano},
journal={IEEE Robotics and Automation Letters}, title={Relocalization With Submaps: Multi-Session Mapping for Planetary Rovers Equipped With Stereo Cameras},
year={2020},
volume={5},
number={2},
pages={580-587},
abstract={To enable long term exploration of extreme environments such as planetary surfaces, heterogeneous robotic teams need the ability to localize themselves on previously built maps. While the Localization and Mapping problem for single sessions can be efficiently solved with many state of the art solutions, place recognition in natural environments still poses great challenges for the perception system of a robotic agent. In this paper we propose a relocalization pipeline which exploits both 3D and visual information from stereo cameras to detect matches across local point clouds of multiple SLAM sessions. Our solution is based on a Bag of Binary Words scheme where binarized SHOT descriptors are enriched with visual cues to recall in a fast and efficient way previously visited places. The proposed relocalization scheme is validated on challenging datasets captured using a planetary rover prototype on Mount Etna, designated as a Moon analogue environment.},
keywords={Three-dimensional displays;Visualization;Simultaneous localization and mapping;Vocabulary;Pipelines;Cameras;Localization;space robotics and automation;mapping},
doi={10.1109/LRA.2020.2964157},
ISSN={2377-3766},
month={April},}
@INPROCEEDINGS{5986295,
author={Yang, Jin-fu and Wang, Kai and Li, Ming-ai and Liu, Lu},
booktitle={2011 IEEE International Conference on Mechatronics and Automation}, title={Research on object recognition using bag of word model for mobile robot navigation},
year={2011},
volume={},
number={},
pages={1735-1740},
abstract={Robust long term positioning for autonomous mobile robots is essential for many applications. Key to a successful visual SLAM system is correctly recognizing the objects and labeling where the robot is. Local image features are popular with constructing object recognition system, which are invariant to image scaling, translation, rotation, and partially invariant to illumination changes and affine. In this paper, we proposed an object recognition method based on the bag of word model, mainly idea includes three steps as follows: firstly, a set of local image patches are sampled using a key point detector, and each patch is a descriptor based on scale invariant feature transform. Then outliers are removed by RANSAC algorithm, and the resulting distribution of descriptors is quantified by using vector quantization against a pre-specified codebook to convert it to a histogram of votes for codebook centers. Finally, a KNN algorithm is used to classify images through the resulting global descriptor vector. The experimental results show that our proposed method has a better performance against the previous methods.},
keywords={Feature extraction;Object recognition;Computational modeling;Training;Databases;Testing;Visualization;scale invariant feature transform (SIFT);bag of word (BOW);object recognition;robot navigation},
doi={10.1109/ICMA.2011.5986295},
ISSN={2152-744X},
month={Aug},}
@INPROCEEDINGS{5174794,
author={Hochdorfer, Siegfried and Schlegel, Christian},
booktitle={2009 International Conference on Advanced Robotics}, title={Towards a robust visual SLAM approach: Addressing the challenge of life-long operation},
year={2009},
volume={},
number={},
pages={1-6},
url={https://ieeexplore.ieee.org/document/5174794},
abstract={Localization and mapping are fundamental problems in service robotics. Knowledge about the own pose and representations of the environment are needed for a series of high level applications. Service robots should be designed for life-long and robust operation in dynamic environments. The contribution of this paper is twofold. First, an approach to address the ever growing number of landmarks in life-long operation is presented. Typically, SLAM approaches just accumulate features over time and do not discard them anymore. Therefore, the required resources in terms of memory and processing power are growing over time. In our approach, the absolute number of landmarks can be restricted by an upper bound since we introduce a method to specifically select and replace landmarks once the upper bound has been reached. The second contribution is related to improving the robustness of the landmark assignment problem in case of image based features as needed with natural landmarks. The approach has been successfully evaluated in a real world experiment on a Pioneer-3DX platform within a complex unmodified indoor environment.},
keywords={Robustness;Simultaneous localization and mapping;Upper bound;Service robots;Computer science;Application software;Indoor environments;Collaboration;Euclidean distance},
doi={},
ISSN={},
month={June},}
@INPROCEEDINGS{4650701,
author={Dayoub, Feras and Duckett, Tom},
booktitle={2008 IEEE/RSJ International Conference on Intelligent Robots and Systems}, title={An adaptive appearance-based map for long-term topological localization of mobile robots},
year={2008},
volume={},
number={},
pages={3364-3369},
abstract={This work considers a mobile service robot which uses an appearance-based representation of its workplace as a map, where the current view and the map are used to estimate the current position in the environment. Due to the nature of real-world environments such as houses and offices, where the appearance keeps changing, the internal representation may become out of date after some time. To solve this problem the robot needs to be able to adapt its internal representation continually to the changes in the environment. This paper presents a method for creating an adaptive map for long-term appearance-based localization of a mobile robot using long-term and short-term memory concepts, with omni-directional vision as the external sensor.},
keywords={Feature extraction;Robots;Robot sensing systems;Noise;Approximation algorithms;Robot vision systems;Cameras},
doi={10.1109/IROS.2008.4650701},
ISSN={2153-0866},
month={Sep.},}
@INPROCEEDINGS{174711,
author={Leonard, J.J. and Durrant-Whyte, H.F.},
booktitle={Proceedings IROS '91:IEEE/RSJ International Workshop on Intelligent Robots and Systems '91}, title={Simultaneous map building and localization for an autonomous mobile robot},
year={1991},
volume={},
number={},
pages={1442-1447 vol.3},
abstract={Discusses a significant open problem in mobile robotics: simultaneous map building and localization, which the authors define as long-term globally referenced position estimation without a priori information. This problem is difficult because of the following paradox: to move precisely, a mobile robot must have an accurate environment map; however, to build an accurate map, the mobile robot's sensing locations must be known precisely. In this way, simultaneous map building and localization can be seen to present a question of 'which came first, the chicken or the egg?' (The map or the motion?) When using ultrasonic sensing, to overcome this issue the authors equip the vehicle with multiple servo-mounted sonar sensors, to provide a means in which a subset of environment features can be precisely learned from the robot's initial location and subsequently tracked to provide precise positioning.<>},
keywords={Mobile robots;Vehicles;Sonar navigation;Robot sensing systems;Stochastic resonance;Sensor phenomena and characterization;Target tracking;Testing;National electric code;Humans},
doi={10.1109/IROS.1991.174711},
ISSN={},
month={Nov},}
@ARTICLE{8333748,
author={Tang, Yazhe and Hu, Yuchao and Cui, Jinqiang and Liao, Fang and Lao, Mingjie and Lin, Feng and Teo, Rodney S. H.},
journal={IEEE Transactions on Industrial Electronics}, title={Vision-Aided Multi-UAV Autonomous Flocking in GPS-Denied Environment},
year={2019},
volume={66},
number={1},
pages={616-626},
abstract={This paper presents a sophisticated vision-aided flocking system for unmanned aerial vehicles (UAVs), which is able to operate in GPS-denied unknown environments for exploring and searching missions, and also able to adopt two types of vision sensors, day and thermal cameras, to measure relative motion between UAVs in different lighting conditions without using wireless communication. In order to realize robust vision-aided flocking, an integrated framework of tracking-learning-detection on the basis of multifeature coded correlation filter has been developed. To achieve long-term tracking, a redetector is trained online to adaptively reinitialize target for global sensing. An advanced flocking strategy is developed to address the autonomous multi-UAVs' cooperative flight. Light detection and ranging (LiDAR)-based navigation modules are developed for autonomous localization, mapping, and obstacle avoidance. Flight experiments of a team of UAVs have been conducted to verify the performance of this flocking system in a GPS-denied environment. The extensive experiments validate the robustness of the proposed vision algorithms in challenging scenarios.},
keywords={Target tracking;Sensors;Cameras;Correlation;Trajectory;Robustness;Visualization;Flocking;unmanned system;visual sensing},
doi={10.1109/TIE.2018.2824766},
ISSN={1557-9948},
month={Jan},}
@INPROCEEDINGS{7313525,
author={Dominguez, Salvador and Khomutenko, Bodgan and Garcia, Gaëtan and Martinet, Philippe},
booktitle={2015 IEEE 18th International Conference on Intelligent Transportation Systems}, title={An Optimization Technique for Positioning Multiple Maps for Self-Driving Car's Autonomous Navigation},
year={2015},
volume={},
number={},
pages={2694-2699},
abstract={Self-driving car's navigation requires a very precise localization covering wide areas and long distances. Moreover, they have to do it at faster speeds than conventional mobile robots. This paper reports on an efficient technique to optimize the position of a sequence of maps along a journey. We take advantage of the short-term precision and reduced space on disk of the localization using 2D occupancy grid maps, from now on called sub-maps, as well as, the long-term global consistency of a Kalman filter that fuses odometry and GPS measurements. In our approach, horizontal planar LiDARs and odometry measurements are used to perform 2D-SLAM generating the sub-maps, and the EKF to generate the trajectory followed by the car in global coordinates. During the trip, after finishing each sub-map, a relaxation process is applied to a set of the last sub-maps to position them globally using both, global and map's local path. The importance of this method lies on its performance, expending low computing resources, so it can work in real time on a computer with conventional characteristics and on its robustness which makes it suitable for being used on a self-driving car as it doesn't depend excessively on the availability of GPS signal or the eventual appearance of moving objects around the car. Extensive testing has been performed in the suburbs and in the down-town of Nantes (France) covering a distance of 25 kilometers with different traffic conditions obtaining satisfactory results for autonomous driving.},
keywords={Laser radar;Global Positioning System;Splines (mathematics);Force;Trajectory;Simultaneous localization and mapping;Buildings},
doi={10.1109/ITSC.2015.433},
ISSN={2153-0017},
month={Sep.},}
@INPROCEEDINGS{7354193,
author={Limosani, R. and Morales, L. Yoichi and Even, J. and Ferreri, F. and Watanabe, A. and Cavallo, F. and Dario, P. and Hagita, N.},
booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={Long-term human affordance maps},
year={2015},
volume={},
number={},
pages={5748-5754},
abstract={This paper presents a work on mapping the use of space by humans in long periods of time. Daily geometric maps with the same coordinate frame were generated with SLAM, and in a similar manner, daily affordance density maps (places people use) were generated with the output of a human tracker running on the robot. The contribution of the paper is two-fold: an approach to detect geometric changes to cluster them in similar geometric configurations and the building of geometric and affordance composite maps on each cluster. This approach avoids the loss of long term retrieved information. Geometric similarity was computed using a normal distance approach on the maps. The analysis was performed on data collected by a mobile robot for a period of 4 months accumulating data equivalent to 70 days. Experimental results show that the system is capable of detecting geometric changes in the environment and clustering similar geometric configurations.},
keywords={Robot kinematics;Buildings;Navigation;Robot sensing systems;Layout;Geometry},
doi={10.1109/IROS.2015.7354193},
ISSN={},
month={Sep.},}